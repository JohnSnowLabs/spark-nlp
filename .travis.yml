sudo: required

language: scala
scala:
  - 2.11.12
os:
  - linux
jdk:
  - openjdk8
env:
  global:
    JAVA_OPTS=-Xmx4g
before_install:
  - if [[ "$TRAVIS_OS_NAME" = "osx" ]]; then
    brew update;
    brew install sbt;
    fi

jobs:
  include:
    - stage: "Spark NLP Build"
      name: "Apache Spark 2.4"
      language: scala
      script:
        - sbt ++$TRAVIS_SCALA_VERSION clean
        - sbt ++$TRAVIS_SCALA_VERSION compile
        - sbt ++$TRAVIS_SCALA_VERSION assemblyAndCopy
      workspaces:
        create:
          name: sparknlp24
          paths:
            - /home/travis/build/JohnSnowLabs/spark-nlp/python/lib/sparknlp.jar
    - name: "Apache Spark 2.3"
      language: scala
      script:
        - sbt -Dis_spark23=true ++$TRAVIS_SCALA_VERSION clean
        - sbt -Dis_spark23=true ++$TRAVIS_SCALA_VERSION compile
        - sbt -Dis_spark23=true ++$TRAVIS_SCALA_VERSION assemblyAndCopy
      workspaces:
        create:
          name: sparknlp23
          paths:
            - /home/travis/build/JohnSnowLabs/spark-nlp/python/lib/sparknlp.jar

    - stage: "Spark NLP Test"
      name: "Scala Tests - Apache Spark 2.4"
      workspaces:
        use: sparknlp24
      script:
        - sbt ++$TRAVIS_SCALA_VERSION test
    - name: "Python Tests - Apache Spark 2.4"
      workspaces:
        use: sparknlp24
      language: python
      python:
         - "3.6"
         - "3.7"
         - "pypy3"
      env:
        - export PYSPARK_PYTHON=python3.6
        - export PYSPARK_DRIVER_PYTHON=python3.6
        - JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-amd64"
      install:
        - pip install pyspark==2.4.4 numpy
      script:
        - cd python; python3 run-tests.py || python run-tests.py;

    - name: "Scala Tests - Apache Spark 2.3"
      workspaces:
        use: sparknlp23
      script:
        - sbt -Dis_spark23=true ++$TRAVIS_SCALA_VERSION test
    - name: "Python Tests - Apache Spark 2.3"
      workspaces:
        use: sparknlp23
      language: python
      python:
        - "3.6"
        - "3.7"
        - "pypy3"
      env:
        - export PYSPARK_PYTHON=python3.6
        - export PYSPARK_DRIVER_PYTHON=python3.6
        - JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-amd64"
      install:
        - pip install pyspark==2.3.4 numpy
      script:
        - cd python; python3 run-tests.py || python run-tests.py;

cache:
  directories:
    - $HOME/.ivy2/cache
    - $HOME/.sbt/boot/
    - $HOME/.spark_nlp.dep.cache
before_cache:
  - find $HOME/.ivy2 -name "ivydata-*.properties" -delete
  - find $HOME/.sbt -name "*.lock" -delete