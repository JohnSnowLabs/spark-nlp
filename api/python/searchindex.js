Search.setIndex({"docnames": ["getting_started/index", "index", "reference/autosummary/sparknlp/annotation/index", "reference/autosummary/sparknlp/annotation_audio/index", "reference/autosummary/sparknlp/annotation_image/index", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index", "reference/autosummary/sparknlp/annotator/audio/index", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/sparknlp/annotator/chunk2_doc/index", "reference/autosummary/sparknlp/annotator/chunker/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_zero_shot_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/sparknlp/annotator/coref/index", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/sparknlp/annotator/cv/convnext_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/index", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/sparknlp/annotator/date2_chunk/index", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/sparknlp/annotator/dependency/index", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/sparknlp/annotator/document_normalizer/index", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/sparknlp/annotator/er/index", "reference/autosummary/sparknlp/annotator/graph_extraction/index", "reference/autosummary/sparknlp/annotator/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/sparknlp/annotator/ld_dl/index", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/sparknlp/annotator/lemmatizer/index", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/index", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/sparknlp/annotator/ner/index", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index", "reference/autosummary/sparknlp/annotator/normalizer/index", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/sparknlp/annotator/param/index", "reference/autosummary/sparknlp/annotator/pos/index", "reference/autosummary/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/sparknlp/annotator/sentence/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/sparknlp/annotator/sentiment/index", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/index", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/sparknlp/annotator/spell_check/index", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/sparknlp/annotator/stemmer/index", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/index", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/sparknlp/annotator/ws/index", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/sparknlp/base/audio_assembler/index", "reference/autosummary/sparknlp/base/doc2_chunk/index", "reference/autosummary/sparknlp/base/document_assembler/index", "reference/autosummary/sparknlp/base/embeddings_finisher/index", "reference/autosummary/sparknlp/base/finisher/index", "reference/autosummary/sparknlp/base/graph_finisher/index", "reference/autosummary/sparknlp/base/has_recursive_fit/index", "reference/autosummary/sparknlp/base/has_recursive_transform/index", "reference/autosummary/sparknlp/base/image_assembler/index", "reference/autosummary/sparknlp/base/index", "reference/autosummary/sparknlp/base/light_pipeline/index", "reference/autosummary/sparknlp/base/multi_document_assembler/index", "reference/autosummary/sparknlp/base/recursive_pipeline/index", "reference/autosummary/sparknlp/base/table_assembler/index", "reference/autosummary/sparknlp/base/token2_chunk/index", "reference/autosummary/sparknlp/base/token_assembler/index", "reference/autosummary/sparknlp/common/annotator_approach/index", "reference/autosummary/sparknlp/common/annotator_model/index", "reference/autosummary/sparknlp/common/annotator_properties/index", "reference/autosummary/sparknlp/common/annotator_type/index", "reference/autosummary/sparknlp/common/coverage_result/index", "reference/autosummary/sparknlp/common/index", "reference/autosummary/sparknlp/common/properties/index", "reference/autosummary/sparknlp/common/read_as/index", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/sparknlp/common/storage/index", "reference/autosummary/sparknlp/common/utils/index", "reference/autosummary/sparknlp/functions/index", "reference/autosummary/sparknlp/index", "reference/autosummary/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/sparknlp/internal/annotator_transformer/index", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/sparknlp/internal/index", "reference/autosummary/sparknlp/internal/params_getters_setters/index", "reference/autosummary/sparknlp/internal/recursive/index", "reference/autosummary/sparknlp/logging/comet/index", "reference/autosummary/sparknlp/logging/index", "reference/autosummary/sparknlp/pretrained/index", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/sparknlp/pretrained/utils/index", "reference/autosummary/sparknlp/training/conll/index", "reference/autosummary/sparknlp/training/conllu/index", "reference/autosummary/sparknlp/training/index", "reference/autosummary/sparknlp/training/pos/index", "reference/autosummary/sparknlp/training/pub_tator/index", "reference/autosummary/sparknlp/training/spacy_to_annotation/index", "reference/autosummary/sparknlp/training/tfgraphs/index", "reference/autosummary/sparknlp/upload_to_hub/index", "reference/autosummary/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["getting_started/index.rst", "index.rst", "reference/autosummary/sparknlp/annotation/index.rst", "reference/autosummary/sparknlp/annotation_audio/index.rst", "reference/autosummary/sparknlp/annotation_image/index.rst", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/audio/index.rst", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/chunk2_doc/index.rst", "reference/autosummary/sparknlp/annotator/chunker/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_zero_shot_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/coref/index.rst", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/sparknlp/annotator/cv/convnext_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/index.rst", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/date2_chunk/index.rst", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/dependency/index.rst", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/sparknlp/annotator/er/index.rst", "reference/autosummary/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/sparknlp/annotator/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/sparknlp/annotator/ner/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.rst", "reference/autosummary/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/sparknlp/annotator/param/index.rst", "reference/autosummary/sparknlp/annotator/pos/index.rst", "reference/autosummary/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/sparknlp/annotator/sentence/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/index.rst", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/ws/index.rst", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/sparknlp/base/document_assembler/index.rst", "reference/autosummary/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/sparknlp/base/finisher/index.rst", "reference/autosummary/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/sparknlp/base/image_assembler/index.rst", "reference/autosummary/sparknlp/base/index.rst", "reference/autosummary/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/sparknlp/base/table_assembler/index.rst", "reference/autosummary/sparknlp/base/token2_chunk/index.rst", "reference/autosummary/sparknlp/base/token_assembler/index.rst", "reference/autosummary/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/sparknlp/common/annotator_model/index.rst", "reference/autosummary/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/sparknlp/common/annotator_type/index.rst", "reference/autosummary/sparknlp/common/coverage_result/index.rst", "reference/autosummary/sparknlp/common/index.rst", "reference/autosummary/sparknlp/common/properties/index.rst", "reference/autosummary/sparknlp/common/read_as/index.rst", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/sparknlp/common/storage/index.rst", "reference/autosummary/sparknlp/common/utils/index.rst", "reference/autosummary/sparknlp/functions/index.rst", "reference/autosummary/sparknlp/index.rst", "reference/autosummary/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/sparknlp/internal/index.rst", "reference/autosummary/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/sparknlp/internal/recursive/index.rst", "reference/autosummary/sparknlp/logging/comet/index.rst", "reference/autosummary/sparknlp/logging/index.rst", "reference/autosummary/sparknlp/pretrained/index.rst", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/sparknlp/pretrained/utils/index.rst", "reference/autosummary/sparknlp/training/conll/index.rst", "reference/autosummary/sparknlp/training/conllu/index.rst", "reference/autosummary/sparknlp/training/index.rst", "reference/autosummary/sparknlp/training/pos/index.rst", "reference/autosummary/sparknlp/training/pub_tator/index.rst", "reference/autosummary/sparknlp/training/spacy_to_annotation/index.rst", "reference/autosummary/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/sparknlp/upload_to_hub/index.rst", "reference/autosummary/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.hubert_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.convnext_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.swin_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.date2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.zero_shot_ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.bart_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_type</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.spacy_to_annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], "thi": [0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 82, 83, 84, 87, 88, 89, 92, 93, 94, 95, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 124, 125, 127, 128, 130, 131, 133, 136, 138, 139, 140, 141, 142, 143, 145, 146, 150, 156, 157, 161, 162, 163, 166, 167, 172, 174, 178, 179, 182, 183, 184, 186, 187, 188], "can": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 87, 92, 93, 94, 95, 96, 102, 104, 105, 107, 109, 110, 112, 113, 114, 116, 117, 119, 127, 130, 131, 139, 140, 141, 142, 154, 163, 166, 167, 169, 170, 172, 179, 181, 183, 184, 186, 187, 188, 189], "quick": [0, 179, 184], "refer": [0, 1, 5, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 79, 96, 104, 105, 108, 109, 110, 112, 113, 114, 116, 117, 127, 129, 130, 139, 183, 185, 186], "how": [0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 50, 52, 54, 55, 57, 58, 59, 60, 62, 64, 65, 67, 71, 73, 74, 76, 81, 82, 83, 87, 88, 92, 93, 94, 97, 99, 104, 107, 116, 117, 124, 125, 127, 130, 133, 139, 151, 154, 156, 169, 170, 174, 179, 183, 188], "set": [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 143, 145, 146, 150, 154, 156, 161, 162, 163, 167, 169, 179, 183, 186, 187], "up": [0, 1, 5, 20, 32, 61, 64, 67, 69, 79, 109, 110, 113, 156, 179, 183, 186, 187], "your": [0, 1, 20, 32, 36, 50, 60, 61, 65, 67, 69, 82, 83, 87, 88, 92, 93, 94, 97, 102, 107, 108, 114, 116, 121, 123, 127, 131, 181, 183, 186, 187, 189], "environ": [0, 180], "pypi": 0, "pip": 0, "anaconda": 0, "c": [0, 57, 61, 69, 79, 112, 127], "johnsnowlab": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 81, 82, 83, 87, 88, 93, 94, 96, 97, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 125, 127, 131, 132, 141, 156], "load": [0, 1, 3, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 79, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 136, 166, 167, 174, 183, 186], "shell": 0, "packag": [0, 54, 59, 163, 180, 181], "com": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 81, 82, 83, 87, 88, 93, 94, 96, 97, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 125, 127, 141, 156], "nlp_2": [0, 156], "12": [0, 54, 71, 72, 73, 79, 84, 86, 92, 102, 114, 138, 142, 155, 156, 166, 172, 174, 182], "pyspark": [0, 2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 136, 138, 139, 141, 142, 143, 155, 156, 159, 162, 163, 166, 169, 170, 172, 173, 183, 184], "submit": [0, 163, 179], "extern": [0, 79, 82, 87, 88, 94, 114, 120, 140, 154, 169, 170, 172, 173], "jar": [0, 156], "after": [0, 49, 50, 52, 61, 65, 66, 69, 84, 86, 92, 123, 143, 163, 182, 183], "compil": 0, "build": [0, 59, 60, 65, 66, 76, 79, 83, 110, 163, 179], "sbt": 0, "assembli": 0, "i": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 143, 154, 155, 156, 162, 163, 167, 169, 172, 173, 174, 179, 180, 182, 183, 184, 186, 187, 188, 189], "built": [0, 20, 32, 139], "top": [0, 5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 45, 47, 54, 79, 109, 110, 113, 139], "apach": [0, 139, 156], "x": [0, 32, 155, 169, 189], "For": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 125, 127, 130, 131, 132, 139, 143, 163, 166, 173, 179, 180, 182, 183, 184, 185, 186, 187], "you": [0, 50, 52, 58, 60, 65, 67, 76, 84, 95, 131, 133, 138, 156, 163, 167, 172, 174, 179, 181, 183, 184, 187, 188, 189], "need": [0, 5, 7, 9, 50, 52, 60, 65, 70, 74, 76, 79, 84, 87, 93, 94, 97, 99, 102, 105, 108, 110, 114, 116, 117, 124, 125, 128, 136, 138, 163, 167, 169, 170, 172, 179, 181, 183, 184, 187, 189], "java": [0, 81, 144, 145, 152, 158, 159, 162, 167], "8": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 50, 52, 53, 54, 55, 56, 57, 59, 60, 64, 65, 66, 71, 72, 73, 84, 89, 94, 95, 99, 110, 114, 127, 142, 169, 174], "ar": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 48, 50, 52, 54, 55, 57, 59, 60, 62, 64, 65, 68, 70, 71, 72, 73, 74, 76, 79, 81, 82, 84, 87, 89, 92, 94, 95, 96, 97, 102, 104, 105, 108, 109, 110, 112, 113, 114, 118, 120, 127, 131, 138, 140, 141, 151, 155, 156, 163, 167, 173, 174, 179, 180, 181, 182, 183, 184, 187, 188, 189], "note": [0, 5, 7, 20, 32, 36, 54, 60, 62, 65, 67, 70, 71, 73, 79, 94, 109, 110, 112, 113, 138, 156, 188], "sinc": [0, 53, 79, 110, 156, 183, 184, 188], "version": [0, 53, 60, 98, 99, 120, 146, 150, 156, 161, 162, 166, 167, 183, 188], "6": [0, 20, 36, 47, 55, 56, 59, 62, 79, 83, 88, 89, 95, 102, 109, 116, 142, 156, 170, 174, 183], "deprec": [0, 156], "If": [0, 11, 14, 16, 18, 20, 22, 25, 27, 30, 32, 34, 36, 39, 41, 45, 47, 48, 67, 70, 74, 81, 84, 86, 92, 93, 94, 97, 99, 104, 105, 109, 110, 113, 114, 120, 156, 162, 163, 167, 179, 181, 183], "consid": [0, 70, 76, 79, 114, 116, 117, 119, 123, 156, 167], "stick": [0, 156], "lower": [0, 53, 54, 79, 114, 129, 156], "7": [0, 8, 36, 47, 55, 56, 59, 84, 86, 102, 110, 132, 172, 174, 182], "we": [0, 5, 7, 20, 32, 45, 47, 48, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 79, 93, 94, 97, 105, 109, 110, 112, 113, 114, 116, 125, 138, 155, 179, 182, 183, 184, 187, 188, 189], "recommend": [0, 62, 73, 107, 108, 109, 110, 112, 113], "It": [0, 11, 14, 16, 20, 22, 25, 27, 30, 32, 34, 36, 37, 39, 41, 45, 47, 53, 55, 56, 57, 59, 60, 61, 64, 65, 66, 69, 71, 72, 74, 79, 89, 108, 109, 112, 114, 116, 117, 123, 132, 138, 167, 182, 187], "have": [0, 5, 20, 32, 36, 54, 57, 60, 65, 66, 70, 79, 87, 89, 92, 93, 94, 95, 102, 104, 105, 110, 117, 142, 143, 158, 183, 184, 187], "basic": [0, 47, 79, 104, 182], "knowledg": [0, 60, 79, 133], "framework": [0, 7, 109, 112, 113], "work": [0, 45, 60, 64, 81, 109, 113, 121, 182, 184, 188], "befor": [0, 53, 70, 84, 86, 109, 113, 116, 124, 127, 145, 162, 179], "pleas": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 55, 56, 57, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 81, 82, 83, 84, 87, 88, 93, 94, 97, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 127, 130, 139, 140, 180, 181, 185, 188], "document": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 130, 131, 132, 133, 138, 139, 141, 142, 143, 163, 166, 169, 170, 172, 174, 179, 183, 184, 186, 187, 188], "first": [0, 2, 59, 61, 62, 69, 71, 72, 79, 87, 93, 94, 95, 104, 109, 113, 114, 119, 124, 131, 143, 179, 183, 184, 188], "let": [0, 60, 123, 183], "": [0, 1, 10, 13, 16, 17, 21, 24, 27, 29, 33, 38, 45, 47, 48, 53, 54, 57, 59, 60, 61, 64, 65, 66, 69, 71, 72, 74, 79, 87, 94, 97, 108, 109, 110, 112, 113, 114, 116, 117, 123, 124, 125, 127, 128, 132, 138, 144, 145, 152, 155, 158, 162, 163, 179, 182, 183, 184, 187], "make": [0, 45, 47, 53, 57, 64, 71, 72, 79, 105, 108, 109, 116, 185, 189], "sure": [0, 108], "oracl": 0, "openjdk": 0, "0_292": 0, "creat": [0, 2, 3, 4, 20, 32, 36, 55, 56, 61, 65, 69, 70, 76, 94, 99, 102, 121, 127, 138, 140, 155, 169, 170, 172, 173, 183, 184, 187, 189], "new": [0, 2, 3, 4, 8, 36, 44, 47, 49, 54, 55, 56, 59, 62, 64, 70, 73, 95, 96, 98, 99, 109, 110, 113, 114, 120, 132, 146, 150, 161, 162, 182, 183], "manag": [0, 79, 167, 180], "all": [0, 2, 3, 4, 11, 14, 16, 18, 22, 25, 27, 30, 34, 37, 39, 41, 47, 53, 54, 55, 56, 57, 67, 70, 73, 74, 77, 81, 84, 94, 97, 109, 110, 113, 114, 119, 124, 127, 131, 133, 163, 167, 178, 183, 188], "depend": [0, 2, 44, 57, 67, 73, 74, 76, 77, 79, 81, 94, 112, 114, 127, 156], "Then": [0, 20, 32, 93, 94, 143, 163, 183], "sparknlp": [0, 179, 182, 183, 184, 185, 187, 188, 189], "n": [0, 72, 79, 89, 92, 93, 94, 104, 105, 109, 110, 113, 123, 138, 141, 155, 166], "y": [0, 32], "activ": [0, 11, 14, 16, 18, 25, 27, 30, 34, 39, 41, 79], "jupyt": [0, 163, 179], "now": [0, 57, 105, 138, 184], "should": [0, 2, 3, 4, 9, 20, 32, 36, 45, 47, 48, 61, 69, 71, 79, 81, 88, 89, 93, 94, 99, 104, 105, 112, 114, 124, 138, 145, 146, 158, 162, 166, 169, 170], "readi": [0, 20, 166, 183], "notebook": [0, 163, 179], "run": [0, 60, 79, 163, 167, 180, 188], "also": [0, 20, 32, 36, 45, 47, 48, 53, 54, 62, 64, 70, 71, 72, 74, 76, 79, 84, 87, 92, 93, 94, 98, 99, 105, 108, 109, 119, 138, 141, 146, 150, 161, 179, 183, 184, 185, 186, 188], "python3": 0, "sourc": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 166, 167, 169, 170, 172, 173, 174, 180], "bin": 0, "A": [0, 5, 7, 36, 44, 45, 54, 65, 66, 70, 74, 79, 82, 83, 87, 88, 89, 96, 97, 107, 109, 110, 112, 113, 116, 117, 124, 125, 163, 172, 181, 183, 189], "retriev": [0, 70, 82, 116, 117, 118, 163, 166, 179, 183, 184], "import": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 136, 138, 139, 140, 141, 142, 143, 155, 163, 166, 169, 170, 172, 173, 174, 179, 182, 183, 186, 187, 188, 189], "manual": [0, 182], "sparksess": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 70, 71, 72, 73, 83, 109, 110, 112, 113, 156, 169, 170, 172, 173], "becaus": [0, 107, 145, 162], "other": [0, 5, 8, 32, 45, 57, 67, 68, 76, 79, 97, 107, 109, 110, 113, 114, 121, 123, 131, 132, 183], "configur": [0, 45, 67, 125, 156], "includ": [0, 47, 53, 55, 56, 61, 62, 69, 71, 72, 73, 76, 79, 84, 92, 93, 94, 109, 110, 113, 114, 132, 163, 173, 180, 182, 183, 184, 189], "them": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 45, 47, 48, 54, 55, 57, 59, 60, 64, 65, 71, 73, 74, 76, 79, 84, 87, 105, 114, 119, 127, 140, 143, 183, 184], "builder": [0, 120, 156], "appnam": [0, 156], "master": [0, 156], "local": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 79, 109, 110, 112, 113, 119, 138, 156, 166, 187], "config": [0, 156, 180], "driver": [0, 156], "memori": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 54, 62, 70, 156], "16g": [0, 156], "maxresults": [0, 156], "0": [0, 5, 7, 8, 9, 20, 32, 36, 44, 45, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 79, 81, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 109, 110, 113, 114, 117, 120, 125, 127, 130, 131, 132, 138, 139, 141, 142, 143, 146, 150, 155, 156, 159, 161, 162, 163, 166, 167, 170, 172, 173, 174, 179, 182, 183, 188, 189], "kryoseri": [0, 156], "buffer": [0, 56, 70, 156], "max": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 54, 55, 56, 57, 59, 60, 64, 65, 66, 71, 72, 73, 79, 117, 156], "2000m": [0, 156], "getorcr": [0, 156], "main": [1, 74, 125, 182, 186, 189], "page": [1, 53, 110, 166, 178, 186, 188], "github": [1, 59, 65, 112, 166], "issu": [1, 127], "workshop": [1, 186], "model": [1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 81, 82, 83, 87, 88, 92, 93, 94, 96, 97, 99, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 121, 123, 125, 127, 145, 156, 162, 163, 166, 167, 179, 180, 182, 186, 188, 189], "hub": [1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 81, 82, 93, 94, 102, 105, 109, 110, 112, 113, 114, 116, 117, 119, 127], "welcom": [1, 5, 7], "python": [1, 81, 156], "contain": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 169, 170, 172, 173, 177, 179, 182, 183], "inform": [1, 50, 52, 70, 71, 79, 84, 92, 109, 114, 130, 139, 173, 179, 180, 181, 182, 183, 189], "us": [1, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 96, 99, 102, 104, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 124, 125, 127, 129, 130, 131, 132, 138, 139, 140, 141, 142, 143, 155, 156, 163, 166, 167, 169, 170, 172, 173, 180, 181, 182, 183, 184, 186], "librari": [1, 45, 47, 48, 81, 129, 130, 131, 139, 143, 188], "exampl": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 140, 141, 142, 143, 155, 163, 166, 167, 169, 170, 172, 173, 174, 179, 182, 183, 184, 186, 187, 188, 189], "get": [1, 20, 32, 79, 91, 102, 114, 120, 125, 127, 128, 130, 131, 132, 136, 138, 139, 146, 150, 161, 179, 183, 188, 189], "start": [1, 5, 10, 13, 17, 21, 24, 29, 33, 38, 64, 76, 79, 93, 94, 105, 129, 156, 163, 179, 182, 184, 187, 188], "cheat": 1, "sheet": [1, 53], "requir": [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 50, 52, 54, 56, 59, 62, 68, 71, 72, 79, 94, 97, 108, 114, 127, 129, 131, 142, 143, 182, 183, 184], "instal": [1, 163, 181], "session": [1, 156, 169, 170, 172, 173], "from": [1, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 140, 141, 142, 143, 145, 155, 156, 159, 162, 163, 166, 169, 170, 172, 173, 174, 179, 182, 183, 184, 187, 188, 189], "user": [1, 92, 93, 125, 140, 156, 163, 179], "guid": [1, 180], "annot": [1, 3, 4, 128, 129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 154, 155, 156, 157, 158, 160, 162, 163, 166, 167, 168, 172, 174, 179, 180, 185, 186, 187, 188, 189], "own": [1, 20, 32, 36, 50, 61, 69, 82, 83, 87, 88, 93, 94, 97, 102, 107, 108, 114, 116, 121, 123, 127, 186, 187, 189], "pipelin": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 136, 138, 139, 140, 141, 142, 143, 156, 162, 163, 165, 166, 167, 168, 180, 182, 183, 186], "pretrain": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 81, 82, 83, 84, 87, 88, 93, 94, 95, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 131, 132, 138, 155, 156, 163, 179, 182, 186], "dataset": [1, 20, 32, 36, 50, 52, 57, 61, 64, 65, 66, 69, 70, 79, 81, 93, 94, 99, 105, 110, 114, 127, 162, 166, 169, 170, 172, 173, 186], "train": [1, 5, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 79, 81, 82, 83, 87, 88, 91, 93, 94, 97, 98, 99, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 121, 123, 127, 129, 138, 156, 163, 166, 179, 183, 184, 186, 187], "light": [1, 5, 60, 73, 79, 138, 186, 188], "helper": [1, 102, 127, 133, 155, 172, 173, 174, 186, 189], "function": [1, 62, 70, 109, 113, 131, 167, 178, 186], "third": [1, 104, 119, 164, 169], "parti": [1, 164], "project": [1, 79, 112, 163, 180], "log": [1, 20, 32, 36, 94, 99, 105, 110, 156], "api": [1, 179, 183, 186], "modul": [1, 28, 51, 63, 75, 77, 78, 80, 85, 90, 100, 101, 103, 106, 111, 115, 122, 126, 137, 149, 160, 165, 171], "data": [2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 136, 138, 139, 140, 141, 142, 143, 155, 163, 166, 169, 170, 171, 172, 173, 180, 182, 183, 187, 188, 189], "format": [2, 3, 4, 45, 47, 48, 50, 52, 74, 76, 82, 83, 84, 86, 87, 88, 93, 94, 97, 99, 107, 109, 113, 116, 117, 125, 127, 128, 130, 132, 133, 136, 139, 141, 169, 170, 172, 173, 174, 180, 189], "annotatortyp": [2, 3, 4, 58, 89, 129, 130, 136, 139, 182], "begin": [2, 44, 92, 110, 123, 125, 129, 130, 139, 155, 182], "end": [2, 10, 13, 17, 21, 24, 29, 33, 38, 44, 94, 105, 109, 123, 125, 127, 130, 139, 155, 163, 169, 179, 182, 184], "result": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 142, 143, 155, 156, 163, 166, 169, 170, 174, 179, 180, 182, 183, 184, 187, 188], "metadata": [2, 3, 4, 37, 44, 49, 79, 88, 93, 94, 96, 102, 130, 132, 136, 138, 139, 155, 163, 167, 182, 184], "embed": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 76, 77, 93, 94, 95, 130, 131, 132, 138, 139, 150, 155, 156, 162, 166, 182], "repres": [2, 3, 4, 50, 52, 54, 59, 73, 74, 76, 83, 88, 89, 125, 163, 166, 183], "output": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 142, 143, 146, 155, 156, 163, 172, 179, 182, 183, 184], "spark": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 149, 151, 155, 156, 158, 159, 160, 163, 166, 167, 169, 170, 172, 173, 174, 178, 180, 181, 182, 183, 185, 186, 187, 189], "nlp": [2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 81, 82, 83, 87, 88, 93, 94, 95, 96, 97, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 125, 127, 129, 130, 131, 132, 136, 137, 138, 139, 140, 141, 143, 149, 156, 160, 163, 166, 167, 169, 170, 172, 173, 178, 180, 181, 182, 183, 184, 185, 186, 187, 189], "detail": [2, 3, 4, 71, 72, 79, 96, 109, 110, 113], "paramet": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 142, 143, 146, 150, 154, 155, 156, 161, 162, 163, 166, 167, 169, 170, 172, 173], "annotator_typ": [2, 3, 4], "str": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 143, 146, 154, 155, 156, 161, 163, 166, 167, 169, 170, 172, 173], "The": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 124, 125, 127, 130, 132, 138, 139, 141, 155, 156, 163, 166, 167, 169, 170, 172, 173, 174, 179, 182, 183, 184, 186, 187, 189], "type": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 142, 143, 155, 157, 166, 172, 182, 183, 186], "possibl": [2, 3, 4, 58, 60, 71, 72, 74, 104, 114, 117, 130, 139, 151, 163, 179], "valu": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 74, 76, 79, 81, 82, 84, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 108, 109, 110, 112, 113, 114, 116, 119, 120, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 143, 146, 150, 151, 161, 163, 179, 189], "token": [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 79, 82, 83, 88, 89, 91, 92, 93, 94, 95, 96, 97, 99, 102, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 127, 129, 131, 138, 140, 142, 143, 156, 166, 169, 173, 174, 183, 187, 188], "wordpiec": 2, "word_embed": [2, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 69, 71, 73, 77, 93, 94, 99], "sentence_embed": [2, 20, 32, 36, 56, 61, 63, 66, 68, 72, 77, 163, 179, 183], "categori": [2, 11, 14, 16, 18, 20, 22, 25, 27, 30, 32, 34, 36, 39, 41, 45, 47, 48, 163, 179, 183], "date": [2, 49, 84, 86, 87], "entiti": [2, 8, 12, 15, 19, 23, 26, 31, 35, 40, 42, 44, 47, 49, 57, 74, 75, 76, 83, 88, 90, 91, 92, 93, 94, 95, 96, 121, 132, 138, 142, 166], "sentiment": [2, 20, 32, 36, 62, 73, 77, 113, 156, 183, 184], "po": [2, 9, 11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 50, 52, 76, 77, 93, 94, 123, 127, 138, 155, 156, 166, 169, 171, 182, 186, 187, 188], "chunk": [2, 8, 9, 10, 13, 17, 21, 24, 29, 33, 37, 38, 49, 58, 61, 69, 74, 79, 83, 87, 88, 89, 92, 121, 129, 132, 142, 155, 163, 173, 179, 189], "named_ent": [2, 12, 15, 19, 23, 26, 31, 35, 40, 42, 76, 92, 93, 94, 95, 96, 99, 138, 166], "negex": 2, "labeled_depend": [2, 52], "languag": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 79, 80, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 129, 139, 143, 167, 183], "keyword": [2, 78, 79, 107], "dummi": [2, 53], "int": [2, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 70, 71, 72, 73, 76, 79, 81, 84, 89, 91, 93, 94, 97, 98, 99, 102, 104, 105, 108, 109, 110, 112, 113, 114, 117, 120, 124, 125, 127, 150, 156, 163, 169], "index": [2, 79, 83, 124, 156, 169], "charact": [2, 53, 62, 64, 74, 81, 87, 89, 97, 104, 105, 114, 116, 117, 124, 125, 127, 132], "under": [2, 60, 73, 79, 156], "last": [2, 84, 86, 121, 174, 187], "string": [2, 20, 32, 36, 44, 50, 53, 74, 87, 89, 95, 97, 105, 113, 117, 119, 123, 129, 130, 132, 136, 138, 139, 187], "dict": [2, 3, 4, 50, 52, 74, 82, 83, 87, 88, 93, 95, 96, 97, 99, 107, 114, 116, 117, 125, 138, 154, 156, 162, 163, 166], "associ": [2, 3, 4, 32, 68, 74, 87, 92, 163], "list": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 53, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 74, 76, 79, 81, 84, 87, 91, 92, 94, 95, 96, 97, 98, 104, 105, 109, 110, 112, 113, 114, 119, 123, 125, 131, 132, 138, 139, 146, 155, 162, 163, 166, 167, 174, 178, 183], "vector": [2, 32, 55, 56, 58, 59, 61, 62, 68, 69, 70, 131, 132, 182], "where": [2, 32, 59, 62, 74, 79, 82, 83, 87, 88, 89, 102, 105, 107, 109, 110, 113, 116, 117, 127, 129, 172], "applic": [2, 48, 79, 109, 163, 164, 179, 181], "copi": [2, 3, 4], "differ": [2, 3, 4, 45, 47, 50, 52, 62, 65, 66, 71, 73, 79, 84, 104, 105, 114, 125, 127, 138, 163, 187], "return": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 79, 81, 82, 83, 88, 89, 91, 93, 94, 96, 102, 104, 105, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 123, 125, 127, 129, 138, 154, 155, 156, 157, 162, 166, 167, 169, 170, 172, 173], "newli": [2, 3, 4], "static": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 167, 183], "datatyp": [2, 155], "structtyp": 2, "schema": [2, 92, 163, 179], "look": [2, 94, 116, 182], "like": [2, 5, 10, 13, 17, 20, 21, 24, 29, 33, 38, 44, 53, 54, 58, 60, 64, 67, 73, 76, 79, 87, 92, 105, 108, 110, 114, 125, 127, 163, 179, 181, 182], "struct": [2, 130, 136, 139], "containsnul": [2, 32, 128, 130, 136, 139], "true": [2, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 45, 47, 48, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 81, 83, 84, 86, 88, 92, 94, 97, 104, 105, 114, 116, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139, 141, 163, 169, 170, 173, 174, 179, 183, 184], "nullabl": [2, 32, 128, 130, 136, 139], "fals": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 130, 131, 132, 133, 138, 139, 141, 142, 143, 155, 156, 163, 166, 169, 170, 172, 174, 179, 182, 183, 184, 189], "integ": [2, 45, 47, 48, 130, 136, 139], "map": [2, 9, 32, 70, 74, 98, 99, 102, 114, 130, 136, 139, 146, 150, 155, 161, 162, 182], "kei": [2, 5, 45, 50, 52, 65, 66, 71, 72, 82, 96, 130, 136, 138, 139, 163, 166, 179], "valuecontainsnul": [2, 130, 136, 139], "arrai": [2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 67, 68, 71, 72, 73, 81, 82, 89, 94, 98, 102, 104, 105, 109, 110, 112, 113, 114, 121, 123, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 155, 184, 187], "element": [2, 32, 89, 128, 130, 136, 139], "float": [2, 3, 5, 7, 20, 32, 36, 45, 49, 81, 93, 94, 96, 98, 99, 105, 109, 110, 113, 114, 127, 128, 130, 131, 138, 139], "sql": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 70, 71, 72, 73, 83, 109, 110, 112, 113, 138, 155, 162, 166, 169, 170, 172, 173], "arraytyp": [2, 129, 155], "fromrow": 2, "row": [2, 37, 70, 104, 105, 108, 130, 139, 141, 155, 169], "column": [2, 8, 20, 32, 36, 53, 70, 82, 91, 93, 94, 98, 99, 102, 108, 120, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139, 143, 146, 155, 166, 169, 172, 183], "torow": 2, "transform": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 141, 142, 143, 155, 158, 162, 163, 166, 179, 182, 183, 184, 187, 188, 189], "an": [2, 5, 7, 9, 20, 32, 36, 37, 45, 47, 48, 50, 53, 57, 59, 62, 64, 73, 74, 79, 81, 83, 84, 86, 87, 88, 89, 93, 94, 96, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 121, 125, 127, 129, 130, 131, 132, 133, 138, 139, 143, 146, 150, 154, 155, 157, 161, 162, 163, 169, 170, 172, 173, 178, 180, 182, 183, 184, 186, 187], "annotationaudio": 3, "audio": [3, 128, 163], "alreadi": [3, 76, 79, 93, 94, 95, 125, 138, 142, 166, 187], "process": [3, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 69, 71, 72, 73, 76, 79, 81, 92, 93, 94, 99, 105, 109, 110, 113, 127, 128, 129, 130, 131, 132, 136, 139, 140, 143, 163, 179, 182, 183, 184, 185], "file": [3, 5, 7, 20, 32, 36, 50, 52, 53, 68, 70, 74, 82, 83, 87, 88, 93, 94, 97, 99, 105, 107, 114, 116, 117, 120, 125, 128, 141, 151, 156, 163, 169, 170, 172, 173, 179, 189], "byte": [3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 81, 94, 98, 109, 110, 112, 113, 114, 163], "annotationimag": [4, 138, 166], "origin": [4, 45, 47, 48, 54, 61, 64, 65, 69, 92, 105, 109, 136], "height": [4, 45, 47, 48, 136], "width": [4, 45, 47, 48, 136], "nchannel": [4, 136], "mode": [4, 20, 32, 36, 94, 99, 116, 130, 136, 139, 163], "imag": [4, 45, 47, 48, 136, 138, 166], "uri": 4, "pixel": [4, 47], "number": [4, 16, 20, 27, 32, 36, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 79, 89, 91, 93, 94, 98, 102, 104, 105, 109, 110, 113, 114, 120, 127, 169, 170], "color": 4, "channel": [4, 45, 47, 48, 114], "opencv": 4, "concern": [5, 7, 11, 45, 47, 48, 49, 54], "hubertforctc": 5, "classnam": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 81, 82, 83, 87, 88, 93, 94, 96, 97, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 125, 127, 141, 144, 145, 152, 158], "java_model": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 81, 82, 83, 87, 88, 93, 94, 96, 97, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 123, 125, 127, 135, 141, 145, 162], "none": [5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 81, 82, 83, 87, 88, 93, 94, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 139, 141, 142, 145, 156, 162, 163, 166, 167, 184], "hubert": 5, "head": [5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 54, 73, 92, 93, 94, 138, 155, 166, 183], "connectionist": [5, 7], "tempor": [5, 7], "classif": [5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 45, 47, 48, 54, 68, 108, 109, 113, 183], "ctc": [5, 7], "wa": [5, 7, 11, 12, 14, 15, 16, 20, 22, 23, 25, 26, 27, 30, 31, 34, 35, 36, 39, 40, 41, 42, 45, 47, 53, 57, 59, 60, 64, 65, 66, 70, 71, 72, 79, 108, 109, 110, 114, 166, 183, 184], "propos": [5, 7, 45, 47, 54, 57, 59, 60, 65, 66, 71, 72, 73], "self": [5, 7, 47, 54, 64, 112], "supervis": [5, 7, 54, 62, 68, 79, 109, 110], "speech": [5, 7, 9, 57, 101, 102, 127, 172, 189], "represent": [5, 7, 47, 54, 55, 56, 60, 61, 62, 69, 70, 71, 72, 73, 92, 113, 141, 154], "learn": [5, 7, 20, 32, 36, 49, 54, 60, 61, 62, 65, 66, 68, 69, 71, 72, 73, 79, 93, 94, 98, 105, 109, 110, 113, 114, 163, 181], "mask": [5, 47, 59, 71, 72, 73, 109, 124], "predict": [5, 47, 59, 94, 110, 113, 163, 179], "hidden": [5, 10, 12, 13, 15, 17, 19, 21, 23, 24, 26, 29, 31, 33, 35, 38, 40, 42, 54, 62, 73, 120], "unit": [5, 110, 120], "wei": [5, 47], "ning": 5, "hsu": 5, "benjamin": [5, 57], "bolt": 5, "yao": 5, "hung": 5, "tsai": 5, "kushal": 5, "lakhotia": 5, "ruslan": 5, "salakhutdinov": 5, "abdelrahman": [5, 7], "moham": [5, 7], "take": [5, 7, 37, 57, 76, 88, 98, 99, 116, 119, 125, 140, 146, 150, 161, 169, 182, 183, 187, 188], "transcrib": [5, 7], "text": [5, 7, 8, 9, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 44, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 139, 141, 142, 143, 151, 154, 155, 163, 169, 170, 172, 173, 179, 182, 183, 184, 188, 189], "provid": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 81, 82, 83, 84, 86, 87, 88, 93, 94, 97, 98, 99, 102, 105, 107, 109, 110, 112, 113, 114, 116, 117, 127, 138, 146, 150, 155, 157, 161, 166, 184], "pre": [5, 7, 20, 32, 36, 48, 55, 56, 59, 60, 62, 68, 94, 99, 109, 113, 130, 132, 139, 143, 170, 183], "current": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 70, 71, 72, 73, 79, 83, 84, 86, 105, 109, 110, 112, 113, 120, 138, 141, 146, 156, 182, 183, 184], "support": [5, 7, 20, 32, 54, 64, 79, 94, 97, 105, 119, 141, 156, 180], "appl": [5, 7, 56, 66, 72, 156], "silicon": [5, 7, 156], "processor": [5, 7], "m1": [5, 7], "due": [5, 7, 11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 54, 64, 109], "instruct": [5, 7], "xla": [5, 7], "companion": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 93, 94, 96, 102, 105, 109, 110, 112, 113, 114, 116, 117, 119, 127, 159], "object": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 93, 94, 96, 102, 105, 109, 110, 112, 113, 114, 116, 117, 118, 119, 127, 151, 158, 159, 163, 182, 183], "speechtotext": [5, 7], "setinputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139, 141, 142, 143, 146, 163, 179, 183, 184], "audio_assembl": [5, 7, 137, 156], "setoutputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139, 141, 142, 143, 146, 163, 179, 183, 184], "default": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 123, 124, 125, 127, 129, 130, 131, 132, 133, 138, 139, 141, 154, 155, 156, 163, 166, 167, 169, 170, 172, 173, 183], "asr_hubert_large_ls960": 5, "name": [5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 88, 90, 91, 93, 94, 96, 98, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 121, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139, 141, 143, 146, 155, 161, 163, 166, 167, 169, 172, 179, 183], "avail": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 77, 79, 81, 82, 84, 87, 93, 94, 102, 105, 109, 110, 112, 113, 114, 116, 117, 119, 127, 158, 166, 167, 179, 186], "see": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 125, 127, 130, 131, 132, 133, 139, 143, 163, 166, 173, 179, 180, 181, 186, 188, 189], "To": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 45, 47, 48, 54, 55, 57, 59, 60, 64, 65, 71, 73, 79, 84, 87, 102, 104, 109, 110, 113, 127, 133, 138, 140, 163, 179, 187], "which": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 73, 76, 79, 84, 86, 87, 94, 96, 97, 104, 105, 107, 109, 110, 112, 113, 116, 124, 127, 131, 138, 155, 167, 169, 170, 183, 184], "compat": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 45, 47, 48, 54, 55, 57, 59, 60, 64, 65, 71, 73, 94, 131, 167], "5669": [5, 7, 45, 47, 48, 57], "more": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 48, 53, 57, 60, 62, 67, 71, 72, 76, 79, 89, 92, 96, 105, 109, 110, 113, 116, 124, 125, 130, 131, 132, 139, 143, 163, 166, 173, 179, 180, 181, 183, 186, 189], "extend": [5, 7, 9, 20, 32, 36, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 60, 62, 65, 67, 68, 70, 71, 73, 79, 81, 82, 84, 86, 87, 88, 89, 93, 94, 96, 97, 99, 102, 104, 105, 107, 108, 109, 112, 113, 114, 116, 118, 119, 123, 125, 127, 130, 131, 132, 139, 143, 166], "hubertforctctestspec": 5, "paper": [5, 45, 47, 48, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 73, 79, 105, 108, 109, 110, 112, 113, 127, 173, 189], "abstract": [5, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 79, 109, 110, 112, 113, 120, 173, 189], "approach": [5, 45, 47, 65, 66, 73, 79, 91, 93, 94, 96, 105, 107, 109, 110, 113, 114, 116, 117, 144, 186], "challeng": [5, 32, 47, 60, 62, 65, 66, 79], "three": [5, 114, 142], "uniqu": [5, 109], "problem": [5, 32, 54, 62, 109, 113, 114, 127], "multipl": [5, 32, 48, 57, 74, 79, 84, 104, 109, 125, 155, 163, 169], "sound": 5, "each": [5, 7, 16, 20, 27, 32, 36, 45, 47, 48, 59, 61, 67, 69, 70, 74, 76, 79, 82, 83, 84, 87, 88, 89, 91, 93, 94, 96, 97, 99, 102, 104, 105, 107, 109, 114, 116, 117, 124, 125, 127, 130, 139, 155, 162, 172, 184], "input": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 141, 142, 143, 146, 155, 162, 166, 169, 170, 172, 173, 183, 184, 187, 189], "utter": 5, "lexicon": 5, "dure": [5, 20, 32, 36, 60, 93, 94, 99, 104, 114, 156, 163, 179], "phase": [5, 60, 109], "variabl": [5, 61, 69], "length": [5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 69, 71, 72, 73, 89, 97, 104, 105, 109, 110, 112, 113, 114, 124, 125], "explicit": [5, 104, 110], "segment": [5, 44, 45, 47, 60, 65, 126, 127], "deal": [5, 138, 187], "bert": [5, 11, 13, 14, 15, 16, 18, 22, 25, 26, 30, 34, 37, 39, 41, 54, 55, 56, 59, 60, 64, 65, 66, 71, 72, 73, 94, 95, 96, 109, 113], "util": [5, 58, 93, 96, 104, 105, 117, 140, 148, 149, 151, 153, 156, 157, 161, 165], "offlin": [5, 163], "cluster": [5, 68, 156], "step": [5, 20, 32, 36, 61, 69, 94, 99, 163, 179, 183], "align": 5, "target": [5, 68, 109, 112, 125, 129, 138, 166], "label": [5, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 45, 47, 48, 50, 52, 74, 81, 91, 92, 93, 94, 96, 98, 99, 107, 108, 113, 114, 120, 127, 163, 169, 179, 183], "loss": [5, 54, 60, 94, 113, 179], "ingredi": 5, "our": [5, 54, 57, 60, 61, 62, 64, 65, 66, 68, 69, 71, 72, 79, 105, 109, 110, 113, 155, 166, 188], "appli": [5, 8, 20, 32, 36, 45, 48, 53, 74, 76, 94, 95, 99, 104, 113, 114, 116, 132, 155, 169], "over": [5, 60, 71, 72, 73, 109, 116, 125, 155, 163, 179], "region": 5, "onli": [5, 45, 47, 48, 50, 52, 53, 62, 68, 73, 84, 87, 97, 104, 105, 109, 110, 113, 123, 127, 140, 169], "forc": 5, "combin": [5, 16, 27, 60, 64, 70, 79, 109, 113, 114, 116, 127], "acoust": 5, "continu": [5, 92, 110, 133, 179], "reli": [5, 50, 52, 73, 79], "primarili": 5, "consist": [5, 54, 59, 64, 87, 102, 108, 127, 141, 172], "unsupervis": [5, 71, 72, 73, 79, 109, 110], "rather": [5, 45], "than": [5, 32, 36, 45, 60, 61, 69, 71, 72, 73, 79, 81, 89, 93, 110, 116, 117, 183], "intrins": [5, 45], "qualiti": [5, 47, 110], "assign": [5, 32, 74, 95, 107], "simpl": [5, 55, 56, 74, 110, 184], "k": [5, 109, 110, 113, 131], "mean": [5, 9, 16, 27, 32, 45, 47, 48, 71, 79, 81, 84, 86, 109, 110, 112, 113, 124, 131, 138, 183, 184, 187], "teacher": 5, "100": [5, 20, 32, 37, 48, 61, 69, 71, 79, 105, 141], "two": [5, 32, 47, 50, 52, 54, 59, 68, 70, 71, 72, 76, 142, 169, 183], "iter": [5, 50, 52, 54, 61, 69, 102, 127, 163, 179], "either": [5, 20, 36, 48, 52, 57, 58, 67, 74, 79, 81, 87, 107, 108, 113, 127, 129, 130, 138, 139, 141, 166, 184], "match": [5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 69, 71, 72, 73, 74, 83, 84, 85, 86, 87, 88, 97, 102, 104, 109, 110, 125, 127, 129, 182], "improv": [5, 54, 55, 56, 57, 59, 62, 65, 66, 71, 72, 93, 94, 110, 188], "upon": [5, 79], "state": [5, 10, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 29, 31, 32, 33, 35, 36, 38, 40, 42, 45, 47, 48, 54, 55, 56, 57, 62, 64, 65, 66, 73, 79, 94, 109, 110, 113, 139, 180, 183], "art": [5, 20, 32, 45, 47, 48, 54, 55, 56, 57, 62, 64, 65, 66, 73, 79, 94, 109, 110, 113, 139], "wav2vec": [5, 7], "perform": [5, 45, 47, 48, 53, 54, 57, 59, 60, 62, 65, 66, 68, 70, 71, 72, 73, 94, 108, 109, 110, 116], "librispeech": 5, "960h": 5, "libri": 5, "60": [5, 60, 104], "000h": 5, "benchmark": [5, 48, 54, 59, 60, 62, 71, 72, 109, 113], "10min": 5, "1h": 5, "10h": 5, "100h": 5, "fine": [5, 44, 55, 56, 60, 96, 109, 113, 174], "tune": [5, 44, 55, 56, 60, 96, 109, 113], "subset": 5, "1b": 5, "show": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 139, 141, 142, 143, 155, 167, 169, 170, 172, 173, 174, 179, 182, 183, 184, 188], "19": [5, 49, 89, 172, 174], "13": [5, 8, 9, 44, 71, 72, 76, 102, 132, 174], "rel": [5, 57, 59, 71, 84, 86, 93, 114, 182], "wer": 5, "reduct": [5, 54, 116], "dev": [5, 47, 54, 62, 68], "test": [5, 20, 32, 36, 45, 47, 48, 50, 52, 55, 56, 68, 70, 82, 83, 87, 88, 93, 94, 99, 102, 110, 116, 117, 121, 127, 169, 170, 172, 173, 174, 183, 189], "evalu": [5, 20, 32, 36, 57, 64, 71, 72, 99, 109, 146, 163], "batchsiz": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 71, 72, 73, 94, 109, 112, 114], "size": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 72, 73, 76, 79, 94, 98, 109, 110, 112, 113, 114, 116, 182, 187, 188], "batch": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 71, 72, 73, 94, 98, 109, 112, 114], "base": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 144, 145, 146, 149, 152, 156, 158, 162, 163, 179, 183, 184, 187], "ml": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 128, 129, 130, 131, 136, 138, 139, 140, 141, 142, 143, 163, 179, 183, 187], "audioassembl": [5, 7, 128], "audio_cont": [5, 7, 128], "setstag": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 131, 141, 142, 143, 183, 184], "processedaudiofloat": [5, 7], "createdatafram": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 130, 131, 132, 139, 141, 142, 143, 155, 163, 179, 182, 183, 184, 188], "rawfloat": [5, 7], "todf": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 130, 131, 132, 136, 139, 141, 142, 143, 155, 182, 183, 184, 188], "fit": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 129, 131, 138, 140, 141, 142, 143, 162, 163, 179, 183, 184, 187], "select": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 49, 58, 60, 70, 76, 79, 81, 93, 94, 96, 108, 109, 110, 113, 114, 116, 117, 123, 127, 128, 130, 132, 133, 136, 139, 141, 143, 155, 163, 179, 184], "truncat": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 70, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 130, 132, 133, 139, 141, 142, 143, 155, 172, 182, 183, 184], "mister": [5, 7], "quilter": [5, 7], "THE": [5, 7, 53], "apostl": [5, 7], "OF": [5, 7, 54], "midl": [5, 7], "clase": [5, 7], "AND": [5, 7], "glad": [5, 7], "TO": [5, 7, 169, 189], "hi": [5, 7, 96, 105], "gospel": [5, 7], "setconfigprotobyt": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 81, 94, 98, 109, 110, 112, 113, 114], "b": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 81, 83, 88, 92, 93, 94, 95, 96, 98, 104, 109, 110, 112, 113, 114, 127, 138, 155, 166, 169, 173, 189], "configproto": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 81, 94, 98, 109, 110, 112, 113, 114], "tensorflow": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 79, 81, 94, 98, 109, 110, 112, 113, 114], "serial": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 74, 81, 94, 98, 109, 110, 112, 113, 114, 156], "loadsavedmodel": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 109, 110, 112, 113], "folder": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 94, 99, 105, 109, 110, 112, 113, 114, 117, 120, 167, 169], "spark_sess": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 109, 110, 112, 113], "save": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 94, 99, 105, 109, 110, 112, 113, 156, 163, 179, 183], "restor": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127], "lang": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 76, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 166, 167, 183, 188], "en": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 73, 76, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 166, 167, 170, 183, 188, 189], "remote_loc": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 166, 167], "download": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 76, 81, 82, 83, 88, 93, 94, 95, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 156, 166, 167, 182, 183, 186, 187], "option": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 79, 81, 82, 83, 87, 88, 93, 94, 96, 97, 99, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 128, 130, 134, 135, 138, 139, 154, 155, 156, 162, 163, 166, 167, 169, 170, 172, 173, 183], "remot": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 166, 167], "address": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127], "resourc": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 81, 82, 83, 87, 88, 93, 94, 96, 97, 99, 102, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 121, 125, 127, 140, 151, 154, 165, 167, 169, 170, 172, 173, 174, 183, 189], "Will": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 104, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127], "repositori": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 166, 180], "otherwis": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 81, 82, 83, 88, 93, 94, 96, 102, 105, 108, 109, 110, 112, 113, 114, 116, 117, 119, 125, 127, 129, 163], "hubert_for_ctc": 6, "wav2vec2_for_ctc": 6, "wav2vec2forctc": 7, "wav2vec2": 7, "alexei": 7, "baevski": 7, "henri": 7, "zhou": 7, "michael": [7, 121], "auli": 7, "asr_wav2vec2_base_960h": 7, "wav2vec2forctctestspec": 7, "chunk2doc": [8, 129], "convert": [8, 49, 53, 58, 67, 70, 84, 86, 89, 92, 97, 109, 113, 124, 127, 129, 132, 133, 142, 163, 179, 186], "back": [8, 109], "when": [8, 9, 11, 14, 16, 22, 25, 27, 30, 34, 39, 41, 45, 47, 48, 53, 54, 76, 84, 86, 89, 94, 109, 110, 114, 116, 119, 123, 127, 138, 169, 183, 184, 187], "try": [8, 114, 169], "re": [8, 183], "do": [8, 68, 79, 92, 119, 125, 138, 179, 183, 187], "further": [8, 54, 79, 93, 94, 143], "analysi": [8, 20, 32, 36, 62, 73, 106, 107, 113, 148, 184], "doc2chunk": [8, 129], "pretrainedpipelin": [8, 132, 138, 155, 166, 182, 187, 188], "locat": [8, 74, 104, 156, 166, 183], "extract": [8, 9, 10, 13, 17, 21, 24, 29, 33, 38, 45, 47, 48, 50, 58, 70, 74, 75, 76, 78, 79, 83, 84, 86, 88, 92, 93, 94, 95, 104, 105, 107, 114, 117, 121, 131, 132, 133, 138, 142, 156, 163, 166, 179], "york": [8, 96, 132], "jersei": [8, 132], "aren": [8, 132], "t": [8, 16, 27, 60, 65, 82, 97, 105, 107, 125, 132], "far": [8, 110, 132], "apart": [8, 50, 52, 132], "actual": [8, 89, 132, 143], "id": [8, 32, 53, 71, 74, 109, 110, 112, 113, 114, 129, 130, 132, 139, 143, 163, 169], "defin": [8, 9, 92, 93, 94, 114, 119, 123, 132, 155, 163, 166, 179, 183, 187], "amongst": [8, 132], "thing": [8, 114, 132], "explain_document_dl": [8, 132, 138, 155, 166], "chunktodoc": 8, "chunkconvert": 8, "explainresult": [8, 132], "selectexpr": [8, 9, 20, 37, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 79, 82, 83, 84, 86, 87, 88, 89, 92, 95, 96, 97, 102, 104, 105, 107, 112, 118, 119, 121, 124, 125, 129, 131, 132, 142, 155, 169, 170, 172, 182, 183, 188], "explod": [8, 9, 20, 37, 44, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 79, 83, 86, 87, 88, 89, 92, 95, 96, 102, 104, 105, 112, 131, 132, 142, 155, 169, 172, 182, 183, 188], "col": [8, 50, 52, 74, 83, 92, 95, 132, 155, 182], "loc": [8, 12, 15, 19, 23, 26, 31, 35, 40, 42, 76, 92, 93, 94, 132, 138, 155, 166, 169], "sentenc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 81, 82, 83, 84, 86, 87, 88, 89, 92, 93, 94, 95, 96, 102, 108, 109, 112, 114, 119, 121, 124, 127, 130, 132, 138, 139, 141, 142, 143, 156, 166, 169, 170, 172, 173, 174, 183, 187, 188], "22": [8, 132, 169, 182], "pattern": [9, 53, 74, 84, 87, 97, 116, 117, 124, 125, 127], "part": [9, 57, 79, 82, 101, 102, 118, 127, 129, 172, 189], "tag": [9, 20, 32, 36, 53, 57, 91, 92, 93, 94, 95, 101, 102, 127, 155, 163, 169, 172, 173, 189], "order": [9, 73, 74, 79, 109, 116, 117, 138, 143, 155, 183, 184, 187, 189], "meaning": [9, 118], "phrase": [9, 57, 61, 69, 83, 88], "onto": [9, 155, 184], "pars": [9, 50, 51, 52, 57, 74, 82, 84, 86, 114, 116, 117, 138, 141, 166, 169, 172], "regular": [9, 87, 93, 104], "express": [9, 36, 44, 84, 87, 104], "wrap": [9, 144, 145, 152, 158, 162], "angl": 9, "bracket": 9, "easili": [9, 62, 102, 131, 179], "distinguish": 9, "itself": [9, 79, 113, 127, 140, 184], "form": [9, 20, 32, 36, 70, 74, 82, 83, 84, 87, 88, 105, 107, 116, 117, 127, 131, 163, 169, 170, 183], "peter": [9, 64, 82, 97, 102, 105, 116, 118, 169], "piper": [9, 82, 102, 118], "employe": [9, 82, 102, 118], "pick": [9, 82, 102, 118], "peck": [9, 82, 102, 118], "pickl": [9, 82, 102, 118], "pepper": [9, 82, 102, 118], "nnp": [9, 102, 138, 155, 169, 170, 172, 173, 182, 187, 188, 189], "nn": [9, 102, 169, 170, 172, 173, 189], "vbp": [9, 102, 138, 170, 182, 187, 188], "vbg": [9, 102], "IN": [9, 102, 138, 155, 170, 172, 173, 182, 187, 188], "jj": [9, 102, 138, 155, 169, 172, 182, 187, 188, 189], "regexpars": 9, "e": [9, 11, 12, 14, 15, 18, 19, 22, 23, 25, 26, 30, 31, 34, 35, 39, 40, 41, 42, 45, 52, 53, 62, 64, 74, 76, 93, 94, 109, 110, 112, 113, 114, 119, 141, 163, 179], "g": [9, 11, 12, 14, 15, 18, 19, 22, 23, 25, 26, 30, 31, 34, 35, 39, 40, 41, 42, 45, 52, 53, 62, 76, 93, 94, 109, 110, 112, 113, 114, 119, 141, 163, 179], "setregexpars": 9, "enclos": 9, "treat": [9, 114, 127], "group": [9, 125], "so": [9, 20, 36, 79, 92, 105, 140, 163, 179], "here": [9, 82, 155, 183], "specif": [9, 37, 50, 52, 53, 55, 56, 60, 68, 76, 79, 94, 109, 110, 120, 138, 140, 163, 187], "noun": [9, 170], "success": [9, 57, 110], "grammar": 9, "parser": [9, 50, 52, 76], "perceptronmodel": [9, 50, 52, 76, 93, 102, 169], "Of": [9, 54, 127], "documentassembl": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 125, 127, 129, 130, 131, 139, 140, 141, 142, 143, 163, 169, 179, 183], "sentencedetector": [9, 20, 37, 44, 50, 52, 56, 58, 66, 68, 72, 76, 79, 82, 87, 89, 93, 94, 95, 96, 102, 104, 105, 119, 121, 140, 143, 169, 183, 184], "postag": 9, "11": [9, 49, 71, 72, 84, 86, 89, 102, 174], "21": [9, 84, 86, 95, 102, 174], "35": [9, 102, 174], "39": [9, 95, 102, 172, 174], "52": [9, 95, 102, 172], "58": [9, 47, 102], "albertforquestionansw": 10, "classifi": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 79, 131, 183], "dl": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 81, 94, 96, 116, 117], "albert": [10, 11, 12, 54], "span": [10, 13, 17, 21, 24, 29, 33, 38, 109, 113], "question": [10, 13, 17, 21, 24, 29, 33, 37, 38, 50, 52, 55, 56, 62, 65, 66, 73, 96, 102, 109, 110, 113, 138], "answer": [10, 13, 17, 21, 24, 29, 33, 37, 38, 50, 52, 55, 56, 62, 73, 96, 109, 110, 113, 138], "task": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 47, 48, 54, 55, 56, 57, 59, 60, 64, 68, 71, 72, 73, 79, 96, 109, 110, 112, 113, 140], "squad": [10, 13, 17, 21, 24, 29, 33, 38, 54, 55, 56, 59, 65, 66, 109], "linear": [10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 47, 110], "layer": [10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 54, 55, 56, 59, 62, 73], "comput": [10, 13, 17, 21, 24, 29, 33, 38, 45, 47, 48, 54, 59, 60, 68, 110, 112, 117, 127, 138, 187], "logit": [10, 11, 13, 14, 16, 17, 18, 21, 24, 25, 27, 29, 30, 33, 34, 38, 39, 41], "spanclassifi": [10, 13, 17, 21, 24, 29, 33, 38], "document_quest": [10, 13, 17, 21, 24, 29, 33, 37, 38], "document_context": [10, 13, 17, 21, 24, 29, 33, 38], "albert_base_qa_squad2": 10, "larg": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 47, 48, 54, 59, 60, 62, 71, 72, 73, 79, 81, 83, 88, 94, 109, 110], "allow": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 47, 62, 68, 93, 94, 97, 104, 105, 109, 124, 125, 140], "faster": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 60, 62, 116, 117], "casesensit": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 71, 72, 73, 83, 88, 116, 119], "whether": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 74, 76, 83, 84, 86, 88, 89, 92, 93, 94, 97, 99, 104, 105, 109, 110, 113, 114, 116, 119, 124, 125, 127, 129, 131, 132, 133, 138, 141, 143, 146, 156, 166, 169, 173, 184], "ignor": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 71, 72, 73, 83, 89, 92, 109, 110, 112, 113, 116, 119, 138], "case": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 71, 72, 73, 74, 81, 83, 88, 114, 116, 119, 125, 129, 169, 170, 183], "configprotobyt": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 47, 48, 54, 55, 56, 57, 59, 60, 62, 64, 65, 66, 68, 71, 72, 73, 81, 94, 109, 110, 112, 113, 114], "maxsentencelength": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 69, 71, 72, 73], "128": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 54, 55, 56, 57, 59, 60, 65, 66, 71, 72, 73, 163, 179], "multidocumentassembl": [10, 13, 17, 21, 24, 29, 33, 37, 38, 139], "context": [10, 13, 17, 21, 24, 29, 33, 38, 55, 56, 61, 62, 69, 73, 108, 114, 125], "setcasesensit": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 58, 60, 64, 65, 71, 83, 88, 93, 116, 119, 131, 143], "what": [10, 13, 17, 21, 24, 29, 33, 36, 38, 45, 50, 52, 79, 81, 96, 112, 114, 123, 170, 180], "my": [10, 12, 13, 15, 17, 20, 21, 23, 24, 26, 29, 31, 33, 35, 36, 38, 40, 42, 53, 87, 89, 96, 104, 110, 119, 121, 124, 183], "clara": [10, 13, 17, 21, 24, 29, 33, 38, 96], "live": [10, 12, 13, 15, 17, 21, 23, 24, 26, 29, 31, 33, 35, 38, 40, 42, 96, 110, 163, 179], "berkelei": [10, 13, 17, 21, 24, 29, 33, 38], "setmaxsentencelength": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 42, 44, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 69, 71, 72, 73], "albertforsequenceclassif": [11, 22], "sequenc": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 45, 47, 48, 64, 109, 110, 111, 112, 113, 114, 119], "regress": [11, 14, 18, 22, 25, 30, 34, 39, 41, 109, 113], "pool": [11, 14, 18, 22, 25, 30, 34, 39, 41, 58, 62, 67], "multi": [11, 14, 18, 20, 22, 25, 30, 32, 34, 36, 39, 41, 54, 68, 71, 72, 79, 81, 112], "sequenceclassifi": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41], "albert_base_sequence_classifier_imdb": 11, "coalescesent": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 81], "instead": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 56, 79, 81, 84, 86, 113, 131, 132, 138, 187], "per": [11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 34, 35, 36, 39, 40, 41, 42, 71, 72, 81, 84, 89, 91, 92, 93, 94, 127, 138, 155, 166, 169], "inputcol": [11, 14, 16, 18, 20, 22, 25, 27, 30, 32, 34, 36, 39, 41, 67, 81, 128, 130, 131, 132, 133, 136, 139], "averag": [11, 14, 16, 18, 22, 25, 27, 30, 34, 37, 39, 41, 58, 67, 71, 72, 81, 94, 102], "probabl": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 79, 109, 110, 113, 116], "calcul": [11, 14, 16, 18, 20, 25, 27, 30, 32, 34, 36, 39, 41, 70, 89, 94, 99, 107], "via": [11, 14, 16, 18, 25, 27, 30, 34, 39, 41, 68, 136, 156], "softmax": [11, 14, 16, 18, 25, 27, 30, 34, 39, 41, 59, 61, 69, 114], "sigmoid": [11, 14, 16, 18, 25, 27, 30, 34, 39, 41], "love": [11, 14, 16, 20, 22, 25, 27, 30, 34, 39, 41, 56, 66, 72, 105, 108, 183], "movi": [11, 14, 16, 20, 22, 25, 27, 30, 34, 36, 39, 41, 108, 183], "child": [11, 14, 16, 22, 25, 27, 30, 34, 39, 41], "pretti": [11, 14, 16, 22, 25, 27, 30, 32, 34, 39, 41, 79], "bore": [11, 14, 16, 22, 25, 27, 30, 34, 39, 41], "neg": [11, 14, 16, 18, 22, 25, 27, 30, 34, 36, 39, 41, 107, 108, 163, 179], "getclass": [11, 12, 14, 15, 16, 18, 19, 22, 23, 25, 26, 27, 30, 31, 34, 35, 39, 40, 41, 42, 45, 47, 48, 96], "setcoalescesent": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 81], "limit": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 45, 47, 48, 54, 57, 64, 70, 73, 79, 113, 116], "almost": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41], "512": [11, 14, 16, 18, 22, 25, 27, 30, 34, 37, 39, 41, 62], "help": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 50, 52, 54, 112, 125, 163, 179, 184, 188], "feed": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41], "entir": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 45, 112], "bool": [11, 14, 16, 18, 22, 25, 27, 30, 34, 39, 41, 53, 56, 58, 68, 74, 76, 81, 83, 84, 88, 89, 92, 93, 94, 97, 99, 104, 105, 109, 110, 113, 114, 116, 119, 124, 125, 127, 129, 131, 132, 133, 138, 141, 146, 156, 163, 166, 169], "one": [11, 14, 16, 18, 22, 25, 27, 30, 32, 34, 39, 41, 44, 45, 47, 48, 50, 52, 53, 55, 56, 67, 71, 72, 73, 79, 81, 84, 87, 92, 105, 116, 121, 143, 179, 183], "albertfortokenclassif": [12, 54], "recognit": [12, 15, 19, 23, 26, 31, 35, 40, 42, 45, 48, 57, 90, 93, 94, 96], "ner": [12, 15, 19, 23, 26, 31, 35, 40, 42, 71, 72, 76, 77, 121, 138, 155, 156, 163, 166, 179], "token_classifi": [12, 19, 31, 35, 40, 42], "albert_base_token_classifier_conll03": 12, "albertembed": [12, 54], "level": [12, 20, 32, 36, 55, 56, 64, 65, 66, 68, 70, 72, 74, 93, 94, 99, 114, 156, 169], "tokenclassifi": [12, 15, 19, 23, 26, 31, 35, 40, 42], "john": [12, 15, 23, 26, 31, 35, 40, 42, 44, 56, 66, 72, 74, 76, 95, 97, 105, 133, 174], "lenon": [12, 15, 23, 26, 31, 35, 40, 42], "born": [12, 15, 23, 26, 31, 35, 40, 42, 110], "london": [12, 15, 23, 26, 31, 35, 40, 42], "pari": [12, 15, 23, 26, 31, 35, 40, 42, 96], "sarah": [12, 15, 23, 26, 31, 35, 40, 42], "o": [12, 15, 19, 23, 26, 31, 35, 40, 42, 92, 93, 94, 95, 138, 155, 166, 169, 173, 189], "bertforquestionansw": [13, 37], "bert_base_cased_qa_squad2": 13, "bertforsequenceclassif": [14, 16], "bert_base_sequence_classifier_imdb": 14, "bertfortokenclassif": 15, "bert_base_token_classifier_conll03": 15, "bertforzeroshotclassif": 16, "modelforsequenceclassif": [16, 27], "nli": [16, 27], "natur": [16, 27, 36, 48, 54, 55, 56, 57, 59, 60, 61, 68, 69, 73, 81, 109, 110, 113, 129, 139, 143], "infer": [16, 27, 55, 56, 57, 60, 73], "equival": [16, 27, 138, 156, 187], "don": [16, 27, 60, 65, 97], "hardcod": [16, 27], "potenti": [16, 27, 47, 114], "thei": [16, 27, 37, 50, 52, 94, 97, 110, 140, 158, 170, 183], "chosen": [16, 27, 50, 52, 94], "runtim": [16, 27], "usual": [16, 27, 48, 143, 167], "slower": [16, 27], "much": [16, 20, 27, 37, 54, 65, 66, 97, 127, 156, 183], "flexibl": [16, 27, 47], "ani": [16, 27, 61, 68, 69, 74, 79, 94, 110, 113, 114, 131, 132, 167, 180, 183, 184, 189], "pass": [16, 27], "pose": [16, 27], "premis": [16, 27], "hypothesi": [16, 27], "pair": [16, 27, 76, 163], "bert_base_cased_zero_shot_classifier_xnli": 16, "camembertforquestionansw": 17, "camembert": [17, 18, 19, 57], "camembert_base_qa_fquad": 17, "fr": [17, 18, 57, 81], "camembertforsequenceclassif": 18, "sequence_classifi": 18, "camembert_base_sequence_classifier_allocin": 18, "j": [18, 74], "ai": [18, 109, 163, 179], "ador\u00e9": 18, "ce": 18, "film": 18, "lorsqu": 18, "\u00e9tai": 18, "enfant": 18, "je": 18, "d\u00e9test": 18, "\u00e7a": 18, "camembertfortokenclassif": 19, "camembert_base_token_classifier_wikin": 19, "georg": 19, "washington": 19, "est": [19, 57, 81, 112], "all\u00e9": 19, "\u00e0": 19, "classifierdl": [20, 183], "classifierdlapproach": [20, 32, 183], "gener": [20, 32, 45, 47, 54, 58, 60, 64, 67, 73, 76, 79, 93, 94, 96, 105, 109, 110, 113, 114, 116, 117, 132, 133, 163, 179, 182, 183, 184], "univers": [20, 50, 52, 68, 112], "encod": [20, 53, 55, 56, 59, 64, 68, 96, 109, 112, 163], "deep": [20, 55, 56, 62, 79, 93, 105, 114], "dnn": 20, "insid": [20, 32, 92, 102, 125, 169], "instanti": [20, 32, 36, 50, 52, 61, 69, 70, 74, 82, 83, 87, 88, 93, 94, 97, 102, 105, 107, 108, 114, 116, 117, 121, 123, 127, 169, 170], "classifierdlmodel": [20, 32, 183], "monitor": [20, 32, 36, 94, 163, 179], "metric": [20, 32, 36, 94, 117, 163], "done": [20, 32, 36, 65, 66, 93, 94, 184], "settestdataset": [20, 32, 36, 94, 99], "method": [20, 32, 36, 54, 60, 61, 69, 73, 79, 94, 167, 178], "expect": [20, 32, 36, 73, 94, 125, 155], "path": [20, 32, 36, 50, 52, 61, 69, 70, 74, 76, 82, 83, 87, 88, 93, 94, 96, 97, 99, 105, 107, 110, 114, 116, 117, 120, 125, 136, 138, 154, 163, 166, 169, 170, 172, 173, 179], "parquet": [20, 32, 36, 94, 99, 128], "datafram": [20, 32, 36, 48, 70, 94, 99, 102, 127, 138, 151, 155, 162, 163, 166, 169, 170, 172, 173, 179, 183, 187, 189], "ha": [20, 32, 36, 37, 45, 47, 48, 53, 54, 59, 60, 62, 65, 66, 70, 79, 82, 87, 94, 99, 105, 107, 109, 113, 116, 117, 127, 128, 129, 136, 138, 163, 167, 172, 179, 183, 184], "same": [20, 32, 36, 44, 54, 65, 70, 71, 74, 76, 94, 99, 113, 140, 163, 184], "follow": [20, 32, 36, 44, 49, 53, 62, 64, 70, 79, 84, 86, 87, 92, 94, 97, 104, 141, 142, 179, 181, 184], "universalsentenceencod": [20, 32, 36, 68, 163, 179, 183], "preprocessingpipelin": [20, 32, 36, 94, 99], "randomsplit": [20, 32, 36, 94, 99], "write": [20, 32, 36, 70, 94, 99, 116, 117, 184], "overwrit": [20, 32, 36, 94, 95, 99, 163], "test_data": [20, 32, 36, 94, 99], "setlabelcolumn": [20, 32, 36, 91, 93, 94, 98, 120, 163, 179, 183], "usag": [20, 32, 36, 44, 50, 52, 53, 54, 55, 56, 57, 58, 60, 62, 65, 68, 70, 71, 73, 74, 79, 81, 82, 84, 86, 87, 88, 93, 94, 97, 102, 104, 105, 107, 108, 109, 112, 113, 114, 116, 118, 119, 123, 125, 127], "64": [20, 32, 36, 54, 94, 98, 183], "dropout": [20, 36, 94], "coeffici": [20, 36, 93, 94], "5": [20, 32, 36, 44, 47, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 79, 81, 84, 86, 89, 92, 94, 102, 110, 127, 131, 138, 155, 163, 166, 170, 172, 173, 174, 179, 182, 183, 189], "enableoutputlog": [20, 32, 36, 94], "stdout": [20, 32, 36, 94, 99], "addit": [20, 32, 36, 50, 52, 55, 56, 74, 93, 94, 99, 104, 110, 125, 163, 182, 183], "evaluationlogextend": [20, 32, 36, 94], "valid": [20, 32, 36, 84, 94, 99, 105, 114, 179], "displai": [20, 32, 36, 99, 110, 163, 179], "time": [20, 32, 36, 54, 61, 69, 71, 72, 79, 84, 99, 108, 114, 127, 156, 182, 183, 187, 188], "labelcolumn": [20, 32, 36, 93, 94], "lr": [20, 32, 36, 94, 127], "rate": [20, 32, 36, 49, 61, 65, 66, 69, 70, 94, 98, 114], "005": [20, 36, 94, 98], "maxepoch": [20, 32, 36, 93, 94], "maximum": [20, 32, 36, 44, 61, 69, 76, 79, 91, 93, 94, 97, 98, 104, 105, 109, 110, 112, 113, 114, 116, 124, 125], "epoch": [20, 32, 36, 91, 93, 94, 98, 99, 105, 114, 163], "30": [20, 36, 79, 84, 86, 92, 98, 112, 138, 155, 166, 174, 182], "outputlogspath": [20, 32, 36, 94, 105], "randomse": [20, 32, 36, 93, 94], "random": [20, 32, 36, 61, 69, 91, 93, 94, 98, 131], "seed": [20, 32, 36, 61, 69, 91, 93, 94, 98], "shuffl": [20, 32, 91, 98, 109], "testdataset": [20, 32, 36, 94, 163, 179], "statist": [20, 32, 36, 70, 79, 94, 99], "validationsplit": [20, 32, 36, 94, 105], "choos": [20, 32, 36, 58, 67, 94, 105, 116], "proport": [20, 32, 36, 94, 99, 105], "against": [20, 32, 36, 74, 79, 83, 88, 94, 99, 105, 140], "between": [20, 32, 36, 47, 50, 52, 65, 66, 68, 71, 72, 73, 76, 94, 99, 104, 105, 114], "off": [20, 32, 36, 68, 71, 72, 94, 99, 105], "verbos": [20, 32, 36, 93, 94, 99], "multiclassifierdlapproach": [20, 32, 163, 179], "sentimentdlapproach": [20, 32, 36], "accept": [20, 32, 36], "singl": [20, 32, 36, 70, 76, 79, 109, 121, 123, 125, 169], "item": [20, 36, 70, 163, 169, 179], "doubl": [20, 36, 128, 141], "sentenceembed": [20, 32, 36, 67, 70, 131], "In": [20, 32, 36, 45, 48, 57, 59, 60, 64, 70, 73, 74, 79, 81, 82, 83, 87, 88, 104, 105, 107, 109, 110, 113, 116, 117, 127, 163, 172, 179, 183, 184, 188, 189], "csv": [20, 36, 74, 99, 141, 183], "best": [20, 36, 54, 57, 65, 66, 79, 81, 94, 109, 183], "wach": [20, 183], "ever": [20, 36, 53, 183], "opinion": [20, 36, 183], "win": [20, 36, 183], "award": [20, 36, 183], "terribl": [20, 36, 183], "act": [20, 36, 183], "bad": [20, 36, 107, 163, 179, 183], "realli": [20, 36, 108, 183], "trane": 20, "smallcorpu": [20, 36, 183], "read": [20, 36, 45, 47, 48, 50, 52, 61, 69, 79, 82, 83, 84, 86, 87, 88, 93, 96, 97, 99, 105, 107, 110, 114, 116, 117, 125, 127, 128, 130, 136, 139, 151, 154, 156, 157, 163, 167, 169, 170, 172, 173, 179, 183, 189], "header": [20, 36, 37, 141, 183], "src": [20, 36, 45, 47, 48, 50, 52, 70, 82, 83, 87, 88, 93, 94, 102, 116, 117, 121, 127, 169, 170, 172, 173, 174, 183, 189], "useembed": [20, 32, 36, 68, 183], "docclassifi": [20, 32, 36, 183], "setbatchs": [20, 32, 36, 62, 94, 98, 114, 163, 179, 183], "setmaxepoch": [20, 32, 36, 91, 93, 94, 98, 163, 179, 183], "20": [20, 37, 45, 73, 92, 109, 110, 138, 141, 155, 166, 183], "setlr": [20, 32, 36, 94, 98, 163, 179, 183], "5e": [20, 36, 183], "setdropout": [20, 36, 94, 183], "pipelinemodel": [20, 32, 36, 50, 52, 53, 61, 69, 93, 94, 108, 114, 116, 117, 127, 138, 140, 163, 167, 183, 186], "v": [20, 32, 36, 49, 59, 70, 79, 81, 83, 94, 98, 99, 117, 155], "classifierdl_use_trec6": [20, 183], "trec": 20, "multiclassifierdlmodel": [20, 32], "sentimentdlmodel": [20, 32, 36], "sarcasmdl": [20, 183], "classifierdl_use_sarcasm": [20, 183], "sarcasm": [20, 183], "m": [20, 84, 86, 174, 183], "could": [20, 60, 79, 87, 99, 114, 182, 183, 184], "put": [20, 155, 183], "word": [20, 47, 48, 50, 52, 54, 58, 59, 61, 62, 65, 67, 68, 69, 70, 73, 74, 76, 79, 82, 89, 92, 95, 96, 97, 102, 107, 109, 110, 112, 113, 114, 116, 117, 118, 119, 123, 125, 126, 127, 138, 155, 166, 172, 173, 182, 183], "wake": [20, 183], "am": [20, 84, 86, 110, 121, 183], "mondai": [20, 183], "would": [20, 44, 58, 67, 84, 105, 156, 183], "arrays_zip": [20, 50, 52, 79, 183], "out": [20, 79, 82, 97, 109, 110, 112, 113, 118, 119, 183], "normal": [20, 45, 47, 48, 53, 77, 83, 105, 108, 119, 131, 140, 143, 156, 183, 184], "debertaforquestionansw": 21, "deberta": [21, 22, 23, 59], "deberta_v3_xsmall_qa_squad2": 21, "debertaforsequenceclassif": 22, "v2": [22, 23, 55, 56, 59], "v3": [22, 23], "deberta_v3_xsmall_sequence_classifier_imdb": 22, "deberta_base_sequence_classifier_imdb": 22, "debertafortokenclassif": 23, "deberta_v3_xsmall_token_classifier_conll03": 23, "distilbertforquestionansw": 24, "distilbert": [24, 25, 27, 60], "distilbert_base_cased_qa_squad2": 24, "distilbertforsequenceclassif": [25, 27], "distilbert_base_sequence_classifier_imdb": 25, "distilbertfortokenclassif": 26, "distilbert_base_token_classifier_conll03": 26, "distilbertforzeroshotclassif": 27, "distilbert_base_zero_shot_classifier_uncased_mnli": 27, "albert_for_sequence_classif": [28, 77], "albert_for_token_classif": [28, 77], "bert_for_sequence_classif": [28, 77], "bert_for_token_classif": [28, 77], "bert_for_zero_shot_classif": [28, 77], "camembert_for_sequence_classif": [28, 77], "camembert_for_token_classif": [28, 77], "deberta_for_sequence_classif": [28, 77], "deberta_for_token_classif": [28, 77], "distil_bert_for_sequence_classif": [28, 77], "distil_bert_for_token_classif": [28, 77], "distil_bert_for_zero_shot_classif": [28, 77], "longformer_for_sequence_classif": [28, 77], "longformer_for_token_classif": [28, 77], "multi_classifier_dl": [28, 77], "roberta_for_sequence_classif": [28, 77], "roberta_for_token_classif": [28, 77], "sentiment_dl": [28, 77], "xlm_roberta_for_sequence_classif": [28, 77], "xlm_roberta_for_token_classif": [28, 77], "xlnet_for_sequence_classif": [28, 77], "xlnet_for_token_classif": [28, 77], "longformerforquestionansw": 29, "longform": [29, 30, 31, 64], "longformer_base_base_qa_squad2": 29, "longformerforsequenceclassif": 30, "longformer_base_sequence_classifier_imdb": 30, "4096": [30, 54, 64], "longformerfortokenclassif": 31, "xlnet_base_token_classifier_conll03": [31, 42], "longformer_base_token_classifier_conll03": 31, "multiclassifierdl": 32, "bidirect": [32, 55, 56, 62, 73, 109], "gru": 32, "convolut": [32, 45, 48], "machin": [32, 45, 61, 69, 79, 93, 109, 110, 112, 113, 163, 181], "strongli": 32, "relat": [32, 50, 52, 76, 188], "variant": [32, 49, 64, 68], "mai": [32, 129, 182, 183, 184, 187, 188], "instanc": [32, 96, 98, 99, 146, 150, 156, 157, 161], "multiclass": 32, "categor": [32, 167], "precis": [32, 50, 52], "constraint": 32, "mani": [32, 59, 65, 66, 79, 109, 110, 112, 113, 127], "formal": 32, "find": [32, 50, 52, 65, 66, 68, 74, 76, 82, 84, 109, 110], "binari": [32, 136, 151, 163], "bertsentenceembed": [32, 36, 56, 66, 72], "multiclassifi": [32, 163, 179], "001": [32, 49, 93, 94], "10": [32, 44, 50, 79, 84, 86, 95, 116, 163, 174, 182], "44": [32, 61, 69, 102], "shuffleperepoch": 32, "threshold": [32, 36, 61, 69, 79, 81, 93, 96, 114, 127], "minimum": [32, 36, 61, 69, 76, 79, 81, 91, 93, 94, 97, 104, 105, 109, 110, 113, 116, 117, 124, 125, 169], "ed58abb40640f983": 32, "pn": 32, "newsyou": 32, "toxic": 32, "a1237f726b5f5d89": 32, "dude": 32, "place": [32, 48], "obscen": 32, "insult": 32, "24b0d6c8733c2abe": 32, "thank": [32, 73, 79, 174], "8c4478fb239bcfc0": 32, "gee": 32, "minut": 32, "traindataset": [32, 163, 179], "printschema": [32, 128, 130, 136, 139], "root": [32, 44, 50, 52, 76, 128, 130, 136, 139, 170], "setcleanupmod": [32, 130, 139], "shrink": [32, 130, 139], "1e": [32, 163, 179], "setthreshold": [32, 36, 79, 81, 163, 179], "setvalidationsplit": [32, 99, 105], "setverbos": [32, 93, 94, 99], "multiclassifierdl_use_tox": 32, "comment": [32, 79], "jigsaw": 32, "good": [32, 57, 60, 68, 108], "stuff": 32, "wtf": 32, "kind": [32, 79, 84, 86], "crap": 32, "robertaforquestionansw": [33, 96], "roberta": [33, 34, 35, 38, 39, 40, 57, 59, 64, 65, 66, 71, 72, 96, 109], "roberta_base_qa_squad2": [33, 96], "robertaforsequenceclassif": 34, "roberta_base_sequence_classifier_imdb": 34, "robertafortokenclassif": 35, "roberta_base_token_classifier_conll03": 35, "sentimentdl": 36, "affect": [36, 125], "subject": [36, 50, 52], "view": 36, "common": [36, 74, 121, 129, 156, 186], "product": 36, "review": [36, 159], "tweet": 36, "interpret": [36, 74], "posit": [36, 59, 60, 71, 72, 73, 79, 92, 107, 108, 124, 127, 143, 163, 179], "final": [36, 64, 65, 66, 71, 72, 81, 94, 114, 183], "otheriws": [36, 81], "neutral": [36, 81], "thresholdlabel": [36, 81], "score": [36, 55, 56, 71, 72, 79, 81, 93, 94, 96, 107, 108, 110], "less": [36, 60, 81, 89, 93, 116], "watch": [36, 108], "32": [36, 54, 62, 174, 182, 188], "setthresholdlabel": [36, 81], "p": [36, 53, 61, 69, 81, 94, 99, 123], "sentimentdl_use_imdb": 36, "english": [36, 57, 79, 116, 119, 127, 167], "imdb": 36, "sentimentdl_use_twitt": 36, "wow": 36, "video": [36, 79], "awesom": 36, "bruh": 36, "damn": 36, "wast": [36, 108], "tapasforquestionansw": 37, "implement": [37, 61, 69, 71, 96, 105, 114, 134, 135, 144, 145, 152, 158, 162], "tapa": 37, "design": [37, 45, 47, 49, 55, 56, 65, 66, 83, 109, 112, 163, 179], "about": [37, 50, 52, 65, 66, 70, 79, 96, 104, 117, 138, 140, 182, 184, 187, 188], "tabular": [37, 141], "tabl": [37, 141], "tri": 37, "share": [37, 79, 184], "its": [37, 48, 59, 60, 64, 73, 79, 102, 107, 109, 112, 119, 163, 172], "table_qa_tapas_base_finetuned_wtq": 37, "document_assembl": [37, 96, 137, 141, 156], "table_json": 37, "document_t": [37, 141], "sentence_detector": [37, 77, 96, 103], "table_assembl": [37, 137, 156], "tableassembl": [37, 141], "stage": [37, 138, 140, 163, 179, 183, 184, 187], "json_data": 37, "monei": [37, 141], "ag": [37, 141], "donald": [37, 141], "trump": [37, 141], "000": [37, 79, 110, 127, 141], "75": [37, 79, 141], "elon": [37, 141], "musk": [37, 141], "55": [37, 95, 141, 174], "AS": [37, 44, 96], "who": [37, 123, 183], "earn": 37, "count": [37, 114], "old": [37, 44, 172], "xlmrobertaforquestionansw": 38, "xlm": [38, 39, 40, 71, 72], "xlm_roberta_base_qa_squad2": 38, "xlmrobertaforsequenceclassif": 39, "xlm_roberta_base_sequence_classifier_imdb": 39, "xlmrobertafortokenclassif": 40, "xlm_roberta_base_token_classifier_conll03": 40, "xlnetforsequenceclassif": 41, "xlnet": [41, 42, 73], "xlnet_base_sequence_classifier_imdb": 41, "xlnetfortokenclassif": 42, "spanbert_coref": 43, "spanbertcorefmodel": 44, "corefer": 44, "resolut": [44, 47], "spanbert": 44, "identifi": [44, 70, 79, 83, 87, 124, 125, 163, 184], "given": [44, 45, 47, 48, 74, 79, 96, 109, 110, 113, 114, 116, 117, 119, 162, 163], "told": [44, 86], "mari": [44, 56, 66, 72, 105], "he": [44, 59, 86, 123, 174], "borrow": 44, "book": [44, 53, 110, 114, 170], "her": [44, 96], "link": [44, 166], "ontonot": 44, "corefresolut": 44, "spanbert_base_coref": 44, "maxsegmentlength": 44, "textgenr": 44, "genr": 44, "One": [44, 79, 123, 142], "bc": 44, "broadcast": 44, "convers": 44, "bn": 44, "nw": 44, "wire": 44, "pt": 44, "pivot": 44, "testament": 44, "tc": 44, "telephon": 44, "wb": 44, "web": [44, 53, 57, 110, 163, 179], "setmaxsegmentlength": 44, "settextgenr": 44, "code": [44, 59, 61, 64, 65, 66, 69, 71, 72, 79, 81, 109, 113, 180, 188], "convnextforimageclassif": 45, "convnet": 45, "convnext": 45, "2020": [45, 79, 84, 86, 105], "zhuang": 45, "liu": [45, 47, 59, 65, 66], "hanzi": 45, "mao": 45, "chao": 45, "yuan": 45, "wu": 45, "christoph": 45, "feichtenhof": 45, "trevor": 45, "darrel": 45, "sain": 45, "xie": 45, "pure": [45, 48, 112], "inspir": [45, 108, 116, 117, 159], "vision": [45, 47, 48], "claim": 45, "outperform": [45, 64, 68, 71, 72, 73, 79, 110], "huggingfac": [45, 47, 48, 57], "convnextforimageclassificationtestspec": 45, "roar": 45, "visual": [45, 47, 163], "began": 45, "introduct": 45, "vit": [45, 48], "quickli": 45, "supersed": 45, "vanilla": 45, "hand": [45, 123], "face": 45, "difficulti": 45, "detect": [45, 47, 68, 80, 81, 103, 104, 105], "semant": [45, 47, 62, 68, 127], "hierarch": [45, 47, 61, 69], "swin": [45, 47], "reintroduc": 45, "sever": [45, 189], "prior": [45, 60, 64, 114], "practic": [45, 57, 109, 113], "viabl": 45, "backbon": [45, 47, 73], "demonstr": [45, 47, 60, 64, 79, 110, 112], "remark": 45, "wide": [45, 53, 55, 56, 59, 60, 71, 72, 109], "varieti": [45, 64, 71, 72, 188], "howev": [45, 54, 67, 73, 79, 97, 167, 182], "effect": [45, 47, 48, 64, 104, 109, 113], "hybrid": 45, "still": [45, 110, 163], "credit": 45, "superior": 45, "inher": 45, "induct": [45, 60], "bias": [45, 60], "reexamin": 45, "space": [45, 61, 69, 70, 89, 143], "achiev": [45, 59, 64, 65, 66, 71, 72, 73, 94, 109, 110, 112, 113, 138, 187], "gradual": 45, "modern": 45, "standard": [45, 47, 48, 53, 64, 84, 86, 109, 116, 117, 125], "resnet": 45, "toward": [45, 110], "discov": [45, 180], "compon": [45, 48, 98, 99, 128, 136, 146, 150, 161, 187], "contribut": 45, "along": [45, 76], "wai": [45, 50, 52, 74, 76, 140, 166], "outcom": 45, "explor": [45, 109, 113], "famili": [45, 53], "dub": [45, 71, 72], "construct": [45, 61, 69, 125, 166, 186], "compet": 45, "favor": 45, "term": [45, 79], "accuraci": [45, 47, 50, 52, 55, 56, 61, 68, 69, 71, 72, 93, 94, 102, 116, 127, 179], "scalabl": 45, "87": [45, 47], "imagenet": [45, 47, 48], "coco": [45, 47], "ade20k": [45, 47], "while": [45, 47, 48, 54, 60, 70, 79, 99, 110, 163, 179, 184], "maintain": 45, "simplic": [45, 109], "effici": [45, 47, 59, 61, 68, 69, 112, 182], "dores": [45, 47, 48], "resiz": [45, 47, 48], "certain": [45, 47, 48, 114], "donorm": [45, 47, 48], "deviat": [45, 47, 48], "featureextractortyp": [45, 47, 48], "architectur": [45, 47, 48, 54, 55, 56, 59, 65, 81, 94, 105, 109, 113], "featur": [45, 47, 48, 50, 61, 69, 79, 89, 93, 99, 163, 186], "imagemean": [45, 47, 48], "imagestd": [45, 47, 48], "resampl": [45, 47, 48], "filter": [45, 47, 48, 71, 72, 79, 92, 93, 109, 110, 112, 113, 119, 155, 167], "pil": [45, 47, 48], "nearest": [45, 47, 48], "bilinear": [45, 47, 48], "bicub": [45, 47, 48], "do_res": [45, 47, 48], "tupl": [45, 47, 48, 162], "dorescal": [45, 47], "rescal": [45, 47], "rescalefactor": [45, 47], "factor": [45, 47, 71, 72, 73, 109, 113, 114], "scale": [45, 47, 48, 54, 60, 64, 71, 72, 109, 110, 113], "croppct": 45, "percentag": [45, 70, 114, 127], "crop": 45, "imagedf": [45, 47, 48], "dropinvalid": [45, 47, 48], "imageassembl": [45, 47, 48, 136], "image_assembl": [45, 47, 48, 137, 156], "imageclassifi": [45, 47, 48], "pipelinedf": [45, 47, 48], "revers": [45, 47, 48], "split": [45, 47, 48, 104, 105, 121, 123, 124, 127], "image_nam": [45, 47, 48], "bluetick": [45, 47, 48], "jpg": [45, 47, 48], "chihuahua": [45, 47, 48], "egyptian_cat": [45, 47, 48], "jpeg": [45, 47, 48], "tabbi": [45, 47], "cat": [45, 47, 48], "hen": [45, 47, 48], "hippopotamu": [45, 47, 48], "hippo": [45, 47, 48], "river": [45, 47, 48], "hors": [45, 47, 48], "amphibiu": [45, 47, 48], "junco": [45, 47, 48], "snowbird": [45, 47, 48], "ostrich": [45, 47, 48], "struthio": [45, 47, 48], "camelu": [45, 47, 48], "ox": [45, 47, 48], "palac": [45, 47, 48], "tractor": [45, 47, 48], "thresher": 45, "thrasher": 45, "thresh": 45, "setdorescal": [45, 47], "boolean": [45, 47], "setrescalefactor": [45, 47], "255": [45, 47], "setcroppct": 45, "determin": [45, 71], "smaller": [45, 60, 61, 69], "224": 45, "256": 45, "specifi": [45, 95, 96, 105, 169, 170], "edg": [45, 60, 76], "afterward": 45, "image_classifier_convnext_tiny_224_loc": 45, "convnext_for_image_classif": 46, "swin_for_image_classif": 46, "vit_for_image_classif": 46, "swinforimageclassif": 47, "swinimageclassif": 47, "shift": 47, "window": [47, 61, 64, 69, 79, 94, 114], "ze": 47, "yutong": 47, "lin": 47, "yue": 47, "cao": 47, "han": 47, "hu": 47, "yixuan": 47, "zheng": 47, "zhang": 47, "stephen": 47, "bain": 47, "guo": 47, "whose": 47, "scheme": [47, 65, 109], "bring": [47, 183], "greater": [47, 79], "attent": [47, 48, 59, 64], "non": [47, 125, 127], "overlap": [47, 83, 88], "cross": [47, 71, 72, 95], "connect": 47, "image_classifier_swin_base_patch4_window7_224": 47, "swinforimageclassificationtest": 47, "present": [47, 54, 62, 64, 65, 66, 68, 71, 72, 76, 99, 105, 109, 112], "call": [47, 55, 56, 60, 79, 110, 162, 167, 169, 183, 189], "capabl": [47, 60, 73, 110], "serv": [47, 180], "purpos": [47, 60, 105], "adapt": 47, "aris": 47, "domain": [47, 79, 110], "variat": 47, "high": [47, 68, 71, 72, 109, 112], "compar": [47, 48, 54, 59, 60, 62, 73, 79, 105, 109, 113, 114, 163, 179], "variou": [47, 73, 177], "complex": [47, 62, 68, 79, 116, 117], "respect": [47, 59, 70, 93, 94, 172], "These": [47, 54, 65, 66, 73, 79, 93, 110, 166, 181], "broad": [47, 110], "rang": [47, 55, 56, 59, 60, 71, 72, 109], "1k": 47, "dens": [47, 55, 56], "box": 47, "ap": 47, "51": [47, 130, 139, 172], "53": [47, 83, 88], "miou": 47, "val": 47, "Its": [47, 52, 96, 109], "surpass": [47, 59], "previou": [47, 71, 72, 110, 183], "margin": [47, 73], "prove": 47, "benefici": [47, 79], "mlp": 47, "vitforimageclassif": 48, "altern": [48, 79, 107, 114, 116, 117, 138, 141, 183, 188], "neural": [48, 55, 56, 59, 94, 105, 109, 112], "network": [48, 55, 56, 62, 94, 105], "image_classifier_vit_base_patch16_224": 48, "vitimageclassificationtestspec": 48, "becom": [48, 54, 60, 79], "de": [48, 57, 79, 81, 112], "facto": [48, 79], "remain": [48, 53, 54, 60, 79], "conjunct": 48, "replac": [48, 53, 59, 64, 81, 82, 95, 105, 109, 116, 117, 183], "keep": [48, 79, 97, 109, 110, 113], "overal": [48, 70, 73], "structur": [48, 96, 143, 182], "relianc": 48, "cnn": [48, 81, 94, 105], "necessari": [48, 60, 179, 186], "directli": [48, 138, 163, 167, 179], "patch": 48, "veri": [48, 57, 62, 71, 72, 73, 109, 110, 112, 113, 138, 182, 184, 187, 188], "well": [48, 50, 52, 68, 71, 72, 79, 109, 141], "amount": [48, 68, 79, 88, 110, 127, 138, 187], "transfer": [48, 60, 68, 71, 72, 109, 110, 113], "mid": 48, "small": [48, 53, 54, 57, 60, 61, 69, 82, 102, 138, 172, 187], "cifar": 48, "vtab": 48, "etc": [48, 58, 131, 143, 179], "attain": 48, "excel": [48, 73], "substanti": [48, 55, 56], "fewer": [48, 54], "worth": 48, "16x16": 48, "egyptian": 48, "date2chunk": 49, "datematch": [49, 84], "multidatematch": [49, 84, 86], "entitynam": 49, "date_chunk": 49, "omicron": 49, "covid": 49, "world": [49, 53, 121, 163, 174, 179], "health": 49, "organ": [49, 79, 112], "nov": [49, 84, 86, 172], "26": [49, 92, 138, 155, 166, 174], "2021": [49, 84, 86], "118": [49, 141], "121": 49, "01": [49, 84, 86, 87], "setentitynam": 49, "dependencypars": [50, 52, 76], "dependencyparserapproach": [50, 170, 189], "unlabel": [50, 55, 56, 109, 110, 113], "grammat": [50, 52], "dependencyparsermodel": [50, 52, 76], "relationship": [50, 52, 68, 76], "tell": [50, 52, 79, 155], "verb": [50, 52, 170], "modifi": [50, 52, 65, 66, 92, 105], "describ": [50, 52, 76, 79, 112], "particular": [50, 52, 79, 167, 183], "treebank": 50, "penn": 50, "setdependencytreebank": 50, "conll": [50, 52, 93, 94, 156, 170, 171, 186], "u": [50, 52, 59, 60, 79, 86, 92, 93, 94, 138, 155, 166, 170, 181, 184, 189], "setconllu": [50, 52], "dependencytreebank": 50, "conllu": [50, 52, 82, 156, 171, 186], "numberofiter": [50, 52], "converg": [50, 52, 102, 127], "better": [50, 52, 54, 59, 73, 79, 93, 102, 104, 105, 108, 109, 127], "typeddependencyparserapproach": [50, 52], "postagg": [50, 52, 76, 93, 102], "dependency_treebank": 50, "emptydataset": [50, 52], "tree": [50, 76], "bank": 50, "setnumberofiter": [50, 52], "read_a": [50, 52, 74, 82, 83, 87, 88, 93, 97, 99, 107, 116, 117, 125, 149, 154, 156, 169, 170], "reada": [50, 52, 70, 74, 82, 83, 87, 88, 93, 97, 99, 107, 116, 117, 121, 125, 151, 154, 169, 170], "dep": 50, "dependency_conllu": [50, 76], "perceptron": [50, 77, 101], "typeddependencyparsermdoel": 50, "union": [50, 52], "worker": [50, 52], "turner": [50, 52], "newal": [50, 52], "sai": [50, 52, 79, 125], "disappoint": [50, 52], "talk": [50, 52], "stricken": [50, 52], "parent": [50, 52], "firm": [50, 52], "feder": [50, 52], "mogul": [50, 52], "dependency_pars": [51, 77, 167, 188], "typed_dependency_pars": [51, 77], "typeddependencypars": [52, 76], "conll2009": 52, "typeddependencyparsermodel": [52, 76], "beforehand": 52, "2009": 52, "setconll2009": 52, "dependency_typ": [52, 76], "train_smal": 52, "txt": [52, 61, 69, 70, 82, 83, 87, 88, 102, 105, 107, 114, 116, 117, 121, 125, 172, 173, 189], "descript": [52, 67, 79, 84, 116, 123, 151], "typdep": 52, "dependency_typed_conllu": [52, 76], "amod": 52, "flat": [52, 76, 133], "nsubj": [52, 76, 133, 170], "parataxi": 52, "documentnorm": 53, "raw": [53, 110, 123, 125, 127, 182, 184], "scrape": 53, "xml": 53, "remov": [53, 65, 66, 97, 108, 124, 131, 132, 133], "dirti": [53, 97], "regex": [53, 74, 84, 87, 97, 114, 116, 117, 124, 125, 127], "want": [53, 74, 95, 167, 184], "polici": 53, "__": [53, 109, 131, 132], "action": 53, "clean": [53, 97, 109, 113, 143, 184], "lowercas": [53, 97, 124, 127, 129], "pretty_al": 53, "utf": 53, "cleanuppattern": [53, 97], "normalizeddocu": 53, "setact": 53, "setpattern": [53, 124, 127], "setreplac": 53, "setpolici": 53, "setlowercas": [53, 97, 129, 143], "div": 53, "theworldsgreatest": 53, "right": [53, 55, 56, 109, 127], "hide": 53, "toptext": 53, "style": [53, 81, 113], "font": 53, "sego": 53, "ui": 53, "arial": 53, "san": [53, 79], "serif": 53, "largest": [53, 79, 110], "develop": [53, 79, 112, 160], "site": [53, 79], "h1": 53, "300": 53, "160": 53, "lorem": [53, 83, 88], "ipsum": [53, 83, 88], "simpli": [53, 184], "print": [53, 156, 167], "typeset": 53, "industri": 53, "been": [53, 57, 110, 142, 143, 167], "1500": 53, "unknown": [53, 81], "printer": 53, "took": 53, "gallei": 53, "scrambl": 53, "specimen": 53, "surviv": 53, "five": [53, 95], "centuri": [53, 127], "leap": 53, "electron": 53, "essenti": [53, 110], "unchang": 53, "popularis": 53, "1960": 53, "releas": [53, 54, 57, 59, 65, 66, 71, 72, 109, 113, 156], "letraset": 53, "passag": 53, "recent": [53, 55, 56, 59, 65, 66, 79, 109], "desktop": 53, "publish": [53, 65, 66], "softwar": 53, "aldu": 53, "pagemak": 53, "setencod": 53, "lite": 54, "googl": [54, 55, 56, 59, 61, 62, 65, 66, 68, 69, 79, 113, 170], "research": [54, 55, 56, 59, 61, 69, 112, 113], "toyota": 54, "technolog": 54, "institut": 54, "chicago": 54, "offici": [54, 79, 92, 93, 94, 138, 155, 166, 180], "tf": [54, 68], "wrapper": [54, 159], "port": 54, "properti": [54, 134, 135, 146, 149, 156], "albert_base_uncas": 54, "albert_bas": 54, "768": [54, 55, 56, 57, 59, 60, 64, 65, 66, 71, 72, 73], "emb": 54, "dim": 54, "12m": 54, "albert_large_uncas": 54, "albert_larg": 54, "1024": [54, 62, 64, 73], "24": [54, 73, 83, 88, 92, 114, 138, 155, 166, 182], "16": [54, 73, 95, 172, 182], "18m": 54, "albert_xlarge_uncas": 54, "albert_xlarg": 54, "2048": 54, "60m": 54, "albert_xxlarge_uncas": 54, "albert_xxlarg": 54, "235m": 54, "sentencepiec": [54, 59, 68], "everi": [54, 55, 56, 57, 59, 60, 64, 65, 66, 71, 72, 73, 94, 108, 112, 114, 130, 139, 140, 184], "dimens": [54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 150], "repeat": 54, "footprint": 54, "cost": [54, 114, 116], "similar": [54, 68, 79, 81], "through": [54, 76, 79, 133, 184], "FOR": 54, "http": [54, 57, 59, 61, 62, 68, 69, 109, 127, 180], "tfhub": [54, 62, 68], "q": 54, "increas": [54, 70, 79, 109, 110, 116], "often": [54, 65, 66, 73], "downstream": [54, 57, 59, 62, 64, 73, 109, 110, 113], "some": [54, 56, 71, 79, 94, 105, 110, 140, 163, 174, 182, 183, 187, 188], "point": [54, 55, 56, 104, 105, 130, 139, 169], "harder": 54, "gpu": [54, 109, 110, 112, 113, 156], "tpu": 54, "longer": [54, 61, 64, 69, 81, 188], "techniqu": [54, 59, 109, 110, 113], "consumpt": [54, 68, 70], "speed": [54, 93, 112], "devlin": [54, 65, 66], "et": [54, 65, 66, 81], "al": [54, 65, 66], "2019": [54, 57, 59, 65, 66, 71, 72, 109], "comprehens": [54, 109, 110], "empir": [54, 55, 56, 71, 72, 73], "evid": 54, "lead": [54, 57, 71, 72], "focus": [54, 79], "inter": 54, "coher": [54, 110], "As": [54, 55, 56, 60, 79], "establish": 54, "glue": [54, 55, 56, 60, 65, 66, 71, 72, 109], "race": [54, 59, 65, 66], "embeddingsfinish": [54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 131], "finished_embed": [54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73], "setoutputasvector": [54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 131], "setcleanannot": [54, 59, 60, 62, 64, 65, 67, 68, 70, 71, 73, 131, 132, 133], "80": [54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 87, 131, 143], "1342473030090332": [54, 59], "3855540752410889": [54, 59], "9818322062492371": [54, 59], "784737348556518": [54, 59], "847029983997345": [54, 59], "047153353691101": [54, 59], "1520637571811676": [54, 59], "6245765686035156": [54, 59], "009860038757324219": [54, 59], "13450059294700623": [54, 59], "707749128341675": [54, 59], "2916892766952": [54, 59], "04192575812339783": [54, 59], "5764210224151611": [54, 59], "3196685314178467": [54, 59], "527840495109": [54, 59], "15583214163780212": [54, 59], "1614152491092682": [54, 59], "28423872590065": [54, 59], "135491415858268": [54, 59], "bertembed": [55, 58, 67, 94, 131], "small_bert_l2_768": 55, "understand": [55, 56, 60, 71, 73, 79, 109, 113, 127, 182], "introduc": [55, 56, 60, 62, 64, 109, 113], "stand": [55, 56], "unlik": [55, 56, 71, 79, 123], "jointli": [55, 56], "condit": [55, 56, 109, 110, 113], "both": [55, 56, 62, 68, 76, 109, 183, 184], "left": [55, 56, 109, 127], "just": [55, 56, 60, 65, 89, 94], "without": [55, 56, 71, 72, 79, 110, 127], "modif": [55, 56], "conceptu": [55, 56], "power": [55, 56, 109, 113], "obtain": [55, 56, 57, 68], "eleven": [55, 56], "push": [55, 56], "absolut": [55, 56], "multinli": [55, 56], "86": [55, 56, 59], "v1": [55, 56], "f1": [55, 56, 71, 72, 94, 110], "93": [55, 56], "83": [55, 56, 59, 172, 173, 189], "small_bert_l2_128": 55, "3497989177703857": 55, "480538547039032": 55, "3238905668258667": 55, "612930893898010": 55, "1357314586639404": 55, "32984697818756104": 55, "6032363176345825": 55, "6791689395904": 55, "8244884014129639": 55, "27088963985443115": 55, "059438943862915": 55, "9817547798156": 55, "1648050546646118": 55, "4725411534309387": 55, "5938255786895752": 55, "5780693292617": 55, "9125322699546814": 55, "4563939869403839": 55, "3975459933280945": 55, "81611204147338": 55, "sentence_bert_embed": 56, "sent_small_bert_l2_768": 56, "islong": 56, "long": [56, 64, 73], "sent_small_bert_l2_128": 56, "orang": [56, 66, 72], "8951074481010437": [56, 66, 72], "13753940165042877": [56, 66, 72], "3108254075050354": [56, 66, 72], "65693199634552": [56, 66, 72], "6180210709571838": [56, 66, 72], "12179657071828842": [56, 66, 72], "191165953874588": [56, 66, 72], "4497021436691": [56, 66, 72], "822715163230896": [56, 66, 72], "7568016648292542": [56, 66, 72], "1165061742067337": [56, 66, 72], "59048593044281": [56, 66, 72], "setislong": 56, "camembertembed": 57, "tasti": 57, "french": [57, 79, 112, 119], "loui": 57, "martin": 57, "muller": 57, "pedro": 57, "javier": 57, "ortiz": 57, "su\u00e1rez": 57, "yoann": 57, "dupont": 57, "laurent": 57, "romari": 57, "\u00e9ric": 57, "villemont": 57, "la": [57, 112], "clergeri": 57, "djam\u00e9": 57, "seddah": 57, "beno\u00eet": 57, "sagot": 57, "facebook": [57, 59, 71, 72, 109], "138gb": 57, "camembert_bas": 57, "camembertembeddingstestspec": 57, "co": [57, 79], "ubiquit": 57, "despit": [57, 109], "most": [57, 60, 64, 79, 94, 109, 110, 112, 113], "concaten": [57, 127], "except": [57, 89, 94, 125], "investig": [57, 60, 68], "feasibl": 57, "monolingu": [57, 71, 72], "crawl": [57, 109, 113], "prefer": [57, 76, 133], "wikipedia": [57, 81, 110], "surprisingli": [57, 68], "4gb": 57, "those": [57, 76, 95, 183, 184], "larger": [57, 60, 65, 66, 109, 110, 112, 113], "130": 57, "gb": 57, "reach": [57, 79, 110, 127], "four": [57, 105, 127, 142], "un": [57, 81], "08442357927560806": 57, "12863239645957947": 57, "03835778683423996": 57, "200479581952": 57, "048462312668561935": 57, "12637358903884888": 57, "27429091930389404": 57, "07516729831": 57, "02690504491329193": 57, "12104076147079468": 57, "012526623904705048": 57, "031543646007": 57, "05877285450696945": 57, "08773420006036758": 57, "06381352990865707": 57, "122621834278": 57, "chunkembed": [58, 131], "wordembed": [58, 67, 70, 94, 131, 156], "chunker": [58, 77, 156], "ngramgener": [58, 89], "nerconvert": [58, 92, 93, 94, 163, 179], "poolingstrategi": [58, 67], "aggreg": [58, 67], "sum": [58, 62, 67], "skipoov": 58, "discard": [58, 96], "oov": 58, "ngram": [58, 89, 109, 110, 113], "setn": [58, 89], "wordembeddingsmodel": [58, 67, 70, 76, 93, 94, 95, 131], "setpoolingstrategi": [58, 67], "55661": 58, "42829502": 58, "86661": 58, "409785": 58, "06316501": 58, "120775": 58, "0732005": 58, "40674996": 58, "22938299": 58, "50597": 58, "288195": 58, "555655": 58, "465145": 58, "140118": 58, "17417": 58, "095253006": 58, "0530925": 58, "218465": 58, "714395": 58, "79860497": 58, "0129999": 58, "139705": 58, "177955": 58, "1887775": 58, "45545": 58, "20030999": 58, "461557": 58, "07891501": 58, "strategi": [58, 67, 87, 104, 114], "setskipoov": 58, "debertaembed": 59, "decod": [59, 64, 109, 110, 112, 113], "enhanc": [59, 108], "disentangl": 59, "pengcheng": 59, "xiaodong": 59, "jianfeng": 59, "gao": 59, "weizhu": 59, "chen": [59, 65, 66], "2018": [59, 65, 66], "half": [59, 79], "deberta_v3_bas": 59, "microsoft": [59, 112], "www": 59, "blog": 59, "human": [59, 79], "superglu": 59, "progress": [59, 105, 124], "significantli": [59, 62, 65, 66, 71, 72, 79], "novel": [59, 73, 79, 109], "mechan": [59, 64], "weight": [59, 62, 79, 93, 95, 114], "among": 59, "matric": 59, "second": [59, 62, 87, 104, 119, 124, 183], "mnli": 59, "9": [59, 71, 72, 89, 182, 187, 188], "90": 59, "91": 59, "88": 59, "made": [59, 68, 179], "publicli": [59, 71, 72], "distilbertembed": 60, "fast": [60, 108, 112, 138, 187], "cheap": 60, "distil": 60, "40": [60, 95, 112], "uncas": 60, "preserv": [60, 92, 124, 143], "95": 60, "measur": [60, 65, 66, 109, 163], "distilbert_base_cas": 60, "doesn": [60, 65], "token_type_id": [60, 65], "indic": [60, 65, 124, 127], "belong": [60, 65], "separ": [60, 65, 87, 89, 104, 105, 116, 125, 127, 132, 155, 169, 181], "sep_token": [60, 65], "sep": 60, "position_id": 60, "ad": [60, 62, 114], "though": [60, 79], "know": [60, 112, 140], "cheaper": 60, "lighter": 60, "preval": 60, "oper": [60, 64, 114, 123, 182], "constrain": 60, "budget": 60, "counterpart": 60, "leverag": [60, 163, 179], "reduc": [60, 116, 117, 143], "retain": 60, "97": [60, 84, 86, 127], "being": [60, 94, 99, 109, 112, 113], "tripl": [60, 76], "cosin": 60, "distanc": [60, 114, 116, 117], "devic": 60, "proof": 60, "concept": [60, 184], "experi": [60, 73, 109, 163, 180], "studi": [60, 65, 66, 109, 113], "1127224713563919": 60, "1982710212469101": 60, "5360898375511169": 60, "272536993026733": 60, "35534414649009705": 60, "13215228915214539": 60, "40981462597846985": 60, "14036104083061": 60, "328085333108902": 60, "06269335001707077": 60, "017595693469047546": 60, "024373905733": 60, "15617232024669647": 60, "2967822253704071": 60, "22324979305267334": 60, "04568954557180": 60, "45411425828933716": 60, "01173491682857275": 60, "190129816532135": 60, "1178255230188369": 60, "doc2vecapproach": 61, "word2vec": [61, 63, 77], "corpu": [61, 62, 69, 79, 82, 102, 109, 113, 114, 172, 189], "algorithm": [61, 69, 79, 93, 108, 114, 116, 117], "vocabulari": [61, 69, 109, 110, 113, 114], "skip": [61, 69, 76, 114], "gram": [61, 69, 79, 89, 109, 110, 113], "doc2vecmodel": 61, "vectors": [61, 69], "windows": [61, 69, 79], "numpartit": [61, 69], "partit": [61, 69, 169], "mincount": [61, 69, 114], "must": [61, 69, 82, 83, 87, 88, 99, 107, 108, 116, 117, 129, 155, 156, 163, 169], "appear": [61, 69, 114], "divid": [61, 69], "1000": [61, 69, 76, 93], "stepsiz": [61, 69], "optim": [61, 65, 66, 69, 94, 96, 105], "025": [61, 69], "maxit": [61, 69], "estim": [61, 69, 120, 134, 144, 152, 162, 183], "distribut": [61, 69], "composition": [61, 69], "sherlockholm": [61, 69, 114, 189], "setvectors": [61, 69], "setwindows": [61, 69, 79], "setsteps": [61, 69], "initi": [61, 69, 114, 124, 140, 156, 169, 170, 172, 173, 179], "setnumpartit": [61, 69], "setmaxit": [61, 69], "numiter": [61, 69], "equal": [61, 69], "setse": [61, 69], "setmincount": [61, 69, 114], "doc2vec_gigaword_300": 61, "06222493574023247": [61, 69], "011579325422644615": [61, 69], "009919632226228714": [61, 69], "109361454844": [61, 69], "doc2vec_wiki": 61, "elmoembed": 62, "elmo": 62, "billion": [62, 110], "computation": [62, 65, 66, 73, 109, 110, 112, 113], "expens": [62, 65, 66, 73, 107, 109, 110, 112, 113, 116], "lookup": [62, 70, 73, 83, 116, 117], "acceler": [62, 73, 109, 110, 112, 113, 156], "setpoolinglay": 62, "word_emb": 62, "shape": 62, "batch_siz": 62, "max_length": 62, "lstm_outputs1": 62, "lstm": [62, 94], "lstm_outputs2": 62, "trainabl": 62, "tensor": 62, "poolinglay": 62, "contextu": [62, 109, 114], "characterist": 62, "syntax": 62, "vari": 62, "across": [62, 110], "linguist": [62, 127], "polysemi": 62, "intern": [62, 98, 99, 114, 125, 127, 141, 146, 150, 156], "bilm": 62, "exist": [62, 114, 131, 133, 163], "six": [62, 116, 117], "textual": 62, "entail": 62, "expos": 62, "crucial": 62, "mix": [62, 145, 162], "semi": 62, "signal": 62, "662458181381226e": 62, "2541114091873169": 62, "6275503039360046": 62, "5787073969841": 62, "19154725968837738": 62, "22998669743537903": 62, "2894386649131775": 62, "21524395048618": 62, "10400570929050446": 62, "12288510054349899": 62, "07056470215320587": 62, "246389418840": 62, "49932169914245605": 62, "12706467509269714": 62, "30969417095184326": 62, "2643227577209": 62, "8871506452560425": 62, "20039963722229004": 62, "0601330995559692": 62, "0348707810044": 62, "albert_embed": [63, 77], "bert_embed": [63, 77], "bert_sentence_embed": [63, 77], "camembert_embed": [63, 77], "chunk_embed": [63, 77], "deberta_embed": [63, 77], "distil_bert_embed": [63, 77], "doc2vec": [63, 77], "elmo_embed": [63, 77], "longformer_embed": [63, 77], "roberta_embed": [63, 77], "roberta_sentence_embed": [63, 77], "universal_sentence_encod": [63, 77], "xlm_roberta_embed": [63, 77], "xlm_roberta_sentence_embed": [63, 77], "xlnet_embed": [63, 77], "longformerembed": 64, "iz": 64, "beltagi": 64, "matthew": 64, "arman": 64, "cohan": 64, "checkpoint": 64, "mlm": 64, "096": 64, "longformer_base_4096": 64, "unabl": 64, "quadrat": 64, "linearli": 64, "easi": 64, "thousand": 64, "drop": [64, 119], "motiv": 64, "global": 64, "text8": 64, "enwik8": 64, "contrast": [64, 83, 113], "finetun": [64, 73], "wikihop": 64, "triviaqa": 64, "led": [64, 65, 66, 79], "arxiv": [64, 109], "summar": [64, 79, 109, 110, 112, 113], "found": [64, 70, 79, 116, 123, 129, 169, 186], "18792399764060974": [64, 65], "14591649174690247": [64, 65], "20547787845134735": [64, 65], "1468472778797": [64, 65], "22845706343650818": [64, 65], "18073144555091858": [64, 65], "09725798666477203": [64, 65], "0417917296290": [64, 65], "07037967443466187": [64, 65], "14801117777824402": [64, 65], "03603338822722435": [64, 65], "17893412709": [64, 65], "08734266459941864": [64, 65], "2486150562763214": [64, 65], "009067727252840996": [64, 65], "24408400058": [64, 65], "22409197688102722": [64, 65], "4312366545200348": [64, 65], "1401449590921402": [64, 65], "356410235166549": [64, 65], "robertaembed": [65, 71], "robustli": [65, 66, 96], "yinhan": [65, 66], "myle": [65, 66, 71, 72], "ott": [65, 66, 71, 72], "naman": [65, 66, 71, 72], "goyal": [65, 66, 71, 72], "jingfei": [65, 66], "du": [65, 66, 81], "mandar": [65, 66], "joshi": [65, 66], "danqi": [65, 66], "omer": [65, 66], "levi": [65, 66], "mike": [65, 66], "lewi": [65, 66], "luke": [65, 66, 71, 72], "zettlemoy": [65, 66, 71, 72], "veselin": [65, 66, 71, 72], "stoyanov": [65, 66, 71, 72], "hyperparamet": [65, 66], "next": [65, 66, 79, 84, 86, 109, 110, 113], "mini": [65, 66], "roberta_bas": 65, "bpe": 65, "gpt": [65, 109, 110], "signific": [65, 66, 71, 72, 79, 82], "gain": [65, 66, 71, 72, 109], "care": [65, 66, 125], "comparison": [65, 66, 68, 119], "privat": [65, 66, 157], "choic": [65, 66, 87], "impact": [65, 66], "replic": [65, 66, 109], "carefulli": [65, 66], "undertrain": [65, 66], "exce": [65, 66], "highlight": [65, 66], "previous": [65, 66, 79], "overlook": [65, 66], "rais": [65, 66, 79, 89, 94, 163], "report": [65, 66, 68, 109, 163, 179], "robertasentenceembed": 66, "sent_roberta_bas": 66, "embeddingssent": 67, "22093398869037628": 67, "25130119919776917": 67, "41810303926467896": 67, "380883991718": 67, "dimension": 68, "tfhub_us": 68, "loadsp": 68, "op": 68, "lingual": [68, 71, 72, 79, 81, 112], "accur": [68, 108, 109, 116], "divers": [68, 109, 110, 113, 180], "trade": [68, 71, 72], "baselin": [68, 110], "tend": 68, "With": [68, 73, 79], "observ": 68, "minim": [68, 96, 112], "encourag": 68, "weat": 68, "bia": 68, "freeli": 68, "04616805538535118": 68, "022307956591248512": 68, "044395286589860916": 68, "0016493503": 68, "setloadsp": 68, "word2vecapproach": 69, "word2vecmodel": 69, "word2vec_gigaword_300": 69, "word2vec_wiki": 69, "custom": [70, 93, 94, 104, 105, 125, 156, 163], "dictionari": [70, 79, 82, 87, 93, 95, 96, 97, 107, 116, 117, 163], "setstoragepath": [70, 83], "line": [70, 74, 83, 88, 105, 107, 114, 166, 169, 172], "delimit": [70, 74, 76, 82, 87, 89, 93, 97, 107, 124, 141, 169, 172], "39658191506190343": 70, "630968081620067": 70, "5393722253731201": 70, "8428180123359783": 70, "were": [70, 94, 163, 179], "7535235923631415": 70, "9699218875629833": 70, "10397182122983872": 70, "11833962569383116": 70, "stress": 70, "0492683418305907": 70, "9415954572751959": 70, "47624463167525755": 70, "16790967216778263": 70, "induc": 70, "1535748762292387": 70, "33498936903209897": 70, "9235178224122094": 70, "1158772920395934": 70, "zero": [70, 96, 110], "withcoveragecolumn": 70, "overallcoverag": 70, "writebuffers": 70, "dump": 70, "disk": [70, 183, 184], "storag": [70, 74, 83, 149, 156], "10000": 70, "readcaches": 70, "cach": [70, 167], "higher": [70, 79, 108, 109, 110, 113], "random_embeddings_dim4": 70, "abov": [70, 76, 172], "setstorageref": 70, "glove_4d": 70, "setdimens": [70, 150], "patient": 70, "diagnos": 70, "diabet": 70, "9439099431037903": 70, "4707513153553009": 70, "806300163269043": 70, "16176554560661316": 70, "7966810464859009": 70, "5551124811172485": 70, "8861005902290344": 70, "28284206986427307": 70, "025029370561242104": 70, "35177749395370483": 70, "052506182342767715": 70, "1887107789516449": 70, "08617766946554184": 70, "8399239182472229": 70, "5395117998123169": 70, "7864698767662048": 70, "6599600911140442": 70, "16109347343444824": 70, "6041093468666077": 70, "8913561105728149": 70, "5955275893211365": 70, "01899011991918087": 70, "4397728443145752": 70, "8911281824111938": 70, "9840458631515503": 70, "7599489092826843": 70, "9417727589607239": 70, "8624503016471863": 70, "setwritebuffers": 70, "setreadcaches": 70, "glove_100d": [70, 94], "There": [70, 74, 76, 123, 181, 183, 184, 189], "conveni": 70, "coverag": [70, 148], "add": [70, 84, 86, 104, 109, 110, 113, 114, 125, 183], "stat": 70, "field": [70, 74, 88], "whole": [70, 166], "570580005645752": 70, "44183000922203064": 70, "7010200023651123": 70, "417129993438720": 70, "542639970779419": 70, "4147599935531616": 70, "0321999788284302": 70, "4024400115013122": 70, "2708599865436554": 70, "04400600120425224": 70, "020260000601410866": 70, "17395000159": 70, "6191999912261963": 70, "14650000631809235": 70, "08592499792575836": 70, "2629800140857": 70, "3397899866104126": 70, "20940999686717987": 70, "46347999572753906": 70, "6479200124740": 70, "embeddings_col": 70, "coverageresult": 70, "coverateresult": 70, "wordsoverallcoverag": 70, "resultdf": 70, "output_col": 70, "wordscoverag": 70, "cov_embed": 70, "loadstorag": [70, 83], "storage_ref": [70, 83], "xlmrobertaembed": 71, "alexi": [71, 72], "conneau": [71, 72], "kartikai": [71, 72], "khandelw": [71, 72], "vishrav": [71, 72], "chaudhari": [71, 72], "guillaum": [71, 72], "wenzek": [71, 72], "francisco": [71, 72, 79], "guzman": 71, "edouard": [71, 72], "grave": [71, 72], "5tb": [71, 72], "commoncrawl": [71, 72], "xlm_roberta_bas": 71, "xx": [71, 72, 81, 112], "multilingu": [71, 72, 127], "doe": [71, 79, 92, 138, 140, 167, 184, 187, 188], "abl": [71, 113, 163, 182], "correct": [71, 114, 116, 117, 127], "hundr": [71, 72], "terabyt": [71, 72], "r": [71, 72, 79], "mbert": [71, 72], "xnli": [71, 72], "mlqa": [71, 72], "particularli": [71, 72, 109], "low": [71, 72, 114], "swahili": [71, 72], "urdu": [71, 72], "capac": [71, 72, 110], "dilut": [71, 72], "sacrif": [71, 72], "ri": [71, 72], "competit": [71, 72, 79], "strong": [71, 72], "05969233065843582": 71, "030789051204919815": 71, "04443822056055069": 71, "09564960747": 71, "038839809596538544": 71, "011712731793522835": 71, "019954433664679527": 71, "0667808502": 71, "03952755779027939": 71, "03455188870429993": 71, "019103847444057465": 71, "04311436787": 71, "09579929709434509": 71, "02494969218969345": 71, "014753809198737144": 71, "10259044915": 71, "004710011184215546": 71, "022148698568344116": 71, "011723337695002556": 71, "013356896": 71, "xlmrobertasentenceembed": 72, "guzm\u00e3": 72, "sent_xlm_roberta_bas": 72, "xlnetembed": 73, "autoregress": 73, "permut": 73, "addition": [73, 94, 102, 130, 139, 166], "emploi": 73, "xl": 73, "exhibit": 73, "involv": [73, 105], "sota": 73, "rank": [73, 114], "xlnet_large_cas": 73, "xlnet_base_cas": 73, "full": [73, 183], "zihangdai": 73, "denois": [73, 109], "autoencod": [73, 109], "corrupt": [73, 109], "neglect": 73, "suffer": 73, "discrep": 73, "pro": 73, "con": 73, "enabl": [73, 94, 116, 156], "maxim": [73, 114], "likelihood": 73, "overcom": 73, "formul": 73, "furthermor": 73, "integr": [73, 79, 112, 163, 179, 181], "idea": 73, "6287205219268799": 73, "4865287244319916": 73, "186111718416214": 73, "234187275171279": 73, "1967450380325317": 73, "2746637463569641": 73, "9481253027915955": 73, "3431355059146881": 73, "0777631998062134": 73, "092679977416992": 73, "5331977605819702": 73, "11190271377563": 73, "8349916934967041": 73, "45627787709236145": 73, "7890847325325012": 73, "028069257736": 73, "134845569729805": 73, "11672890186309814": 73, "4945235550403595": 73, "66587203741073": 73, "entityrul": 74, "entityrulerapproach": 74, "exact": [74, 83, 88], "definit": [74, 96, 169], "json": [74, 141, 163, 174], "jsonl": 74, "setpatternsresourc": 74, "might": [74, 94, 127, 188], "rule": [74, 87, 107, 123, 125], "person": [74, 170], "w": [74, 77, 87, 93, 97, 123, 125, 156], "winterfel": 74, "jon": 74, "snow": [74, 95, 114], "stark": 74, "eddard": 74, "patternsresourc": 74, "usestorag": 74, "rocksdb": 74, "lord": 74, "29": [74, 95, 127, 172, 174], "38": [74, 174], "setusestorag": 74, "setsentencematch": 74, "setalphabetresourc": 74, "alphabet": [74, 97], "plain": [74, 189], "entityrulermodel": 74, "entity_rul": [75, 77], "graphextract": [76, 133], "graph": [76, 94, 112, 114, 120, 133], "nerdlmodel": [76, 92, 93, 94, 95, 163, 167, 179], "store": [76, 98, 99, 141, 146, 150, 161, 166, 174, 180], "node": 76, "relev": [76, 79], "taken": 76, "implicitli": 76, "setmergeent": 76, "automat": [76, 79, 96, 112, 116, 182, 183], "setdependencyparsermodel": 76, "settypeddependencyparsermodel": 76, "setrelationshiptyp": 76, "public": [76, 167, 183], "relationshiptyp": 76, "entitytyp": 76, "explodeent": 76, "roottoken": 76, "travers": 76, "maxsentences": 76, "minsentences": 76, "below": [76, 188], "mergeent": 76, "merg": [76, 83, 88], "neighbor": 76, "includeedg": 76, "symbol": [76, 114, 127], "posmodel": 76, "coordin": [76, 104], "remoteloc": 76, "graphfinish": [76, 133], "rdf": [76, 133], "nertagg": [76, 93, 94, 95], "morn": [76, 133], "flight": [76, 133], "denver": [76, 133], "18": [76, 84, 86, 89, 92, 95, 138, 155, 166, 182], "path1": 76, "setentitytyp": 76, "setexplodeent": 76, "setroottoken": 76, "setmaxsentences": 76, "setminsentences": 76, "setmergeentitiesiobformat": 76, "iob": [76, 92, 93, 94], "iob2": [76, 92], "setincludeedg": 76, "setdelimit": [76, 87, 89], "setposmodel": 76, "class": [77, 149, 153, 160, 171, 178, 179, 187, 189], "classifier_dl": [77, 156], "er": [77, 156], "keyword_extract": [77, 156], "yake_keyword_extract": [77, 78], "ld_dl": [77, 156], "language_detector_dl": [77, 80], "matcher": [77, 156], "big_text_match": [77, 85], "date_match": [77, 85], "multi_date_match": [77, 85], "regex_match": [77, 85], "text_match": [77, 85], "ner_approach": [77, 90], "ner_convert": [77, 90], "ner_crf": [77, 90], "ner_dl": [77, 90], "ner_overwrit": [77, 90], "param": [77, 93, 145, 146, 150, 156, 161, 162], "sentence_detector_dl": [77, 103, 112], "sentiment_detector": [77, 106], "vivekn_senti": [77, 106], "seq2seq": [77, 156], "bart_transform": [77, 111], "gpt2_transform": [77, 111], "marian_transform": [77, 111], "t5_transform": [77, 111], "spell_check": [77, 156], "context_spell_check": [77, 115], "norvig_sweet": [77, 115], "symmetric_delet": [77, 115], "chunk_token": [77, 122], "recursive_token": [77, 122], "regex_token": [77, 122], "word_segment": [77, 126], "chunk2_doc": [77, 156], "date2_chunk": [77, 156], "document_norm": [77, 156], "graph_extract": [77, 156], "lemmat": [77, 107, 119, 140, 143, 156], "n_gram_gener": [77, 156], "stemmer": [77, 119, 156], "stop_words_clean": [77, 156], "yakekeywordextract": 79, "yake": 79, "independ": [79, 116, 117, 123], "individu": [79, 114], "grow": 79, "autom": 79, "adequ": 79, "manner": 79, "emerg": [79, 109, 113], "tool": [79, 109], "system": [79, 109, 110], "nor": 79, "thesauri": 79, "neither": 79, "corpora": [79, 83], "thu": 79, "written": [79, 112], "plethora": 79, "situat": [79, 105], "access": 79, "restrict": 79, "therefor": [79, 187], "sent": 79, "boundari": [79, 104, 105, 108, 125, 127], "detector": [79, 84, 107], "section": [79, 130, 139, 179, 181, 187], "tweakabl": 79, "upper": 79, "bound": [79, 104, 105, 108], "minngram": 79, "maxngram": 79, "occurr": 79, "nkeyword": 79, "stopword": [79, 95, 119], "stop": [79, 93, 119], "campo": 79, "mangaravit": 79, "pasquali": 79, "jatowt": 79, "jorg": 79, "nune": 79, "scienc": [79, 180], "journal": [79, 127], "elsevi": 79, "vol": 79, "509": 79, "pp": [79, 127], "257": 79, "289": 79, "collect": [79, 163, 179], "turn": [79, 143, 183], "come": [79, 92], "fly": 79, "demand": 79, "abil": [79, 109, 110], "within": [79, 102, 108, 109, 110, 125, 129], "resort": 79, "alwai": [79, 113], "solut": 79, "articl": [79, 114], "rest": [79, 92], "merit": 79, "ten": 79, "experiment": 79, "carri": 79, "twenti": 79, "setcontextchar": [79, 125], "setminngram": 79, "setnkeyword": 79, "acquir": 79, "kaggl": 79, "platform": [79, 163, 181], "host": 79, "transact": 79, "somewhat": 79, "vagu": 79, "cloud": 79, "confer": 79, "week": [79, 84, 86, 121], "announc": [79, 95], "earli": 79, "tomorrow": [79, 84, 86], "phone": 79, "founder": 79, "ceo": 79, "anthoni": 79, "goldbloom": 79, "declin": 79, "deni": 79, "acquisit": 79, "happen": 79, "rumor": 79, "million": [79, 95, 110], "scientist": 79, "ben": 79, "hamner": 79, "2010": 79, "servic": [79, 112], "got": 79, "even": [79, 113], "few": [79, 125, 172, 189], "competitor": 79, "drivendata": 79, "topcod": 79, "hackerrank": 79, "stai": 79, "ahead": 79, "nich": 79, "home": [79, 156], "bui": [79, 170], "commun": 79, "mindshar": 79, "too": [79, 107, 182], "plenti": 79, "bit": [79, 105, 188], "histori": [79, 105, 114], "earlier": 79, "month": [79, 84, 86, 172, 189], "team": [79, 112, 163, 179], "around": 79, "youtub": 79, "That": [79, 123, 163, 179, 184], "had": 79, "technologi": 79, "did": 79, "interest": 79, "kernel": 79, "On": [79, 110, 112], "analyz": [79, 108], "compani": [79, 112], "script": 79, "centric": 79, "job": [79, 129], "board": [79, 102, 172], "unclear": 79, "accord": [79, 114, 169], "crunchbas": 79, "pitchbook": 79, "launch": 79, "investor": 79, "ventur": 79, "sv": 79, "angel": 79, "levchin": 79, "naravik": 79, "chie": 79, "economist": 79, "hal": 79, "varian": 79, "khosla": 79, "yuri": 79, "milner": 79, "resulttupl": 79, "ascend": 79, "orderbi": 79, "32051516486864573": 79, "37786450577630676": 79, "39922830978423146": 79, "40224744669493756": 79, "41584827825302534": 79, "setmaxngram": 79, "setstopword": [79, 95, 119], "getstopword": 79, "loaddefaultstopword": [79, 119], "danish": [79, 119], "dutch": [79, 119], "finnish": [79, 119], "german": [79, 119, 169, 189], "hungarian": [79, 119], "italian": [79, 114, 119], "norwegian": [79, 119], "portugues": [79, 119], "russian": [79, 119], "spanish": [79, 119], "swedish": [79, 119], "turkish": [79, 119], "languagedetectordl": 81, "ld": 81, "identif": 81, "rnn": 81, "tatoeba": 81, "140": 81, "wiki": 81, "languagedetector": 81, "ld_wiki_tatoeba_cnn_21": 81, "open": [81, 125, 129, 130, 131, 139, 143, 180], "advanc": [81, 129, 143], "scala": [81, 144, 145, 152, 158, 162], "program": 81, "biblioth\u00e8qu": 81, "traitement": 81, "pour": 81, "le": [81, 112], "avanc\u00e9": 81, "langag": 81, "naturel": 81, "programm": 81, "ist": 81, "ein": 81, "textverarbeitungsbibliothek": 81, "f\u00fcr": 81, "fortgeschritten": 81, "nat\u00fcrlich": 81, "sprachverarbeitung": 81, "die": 81, "programmiersprachen": 81, "und": 81, "lemma": [82, 107, 138, 166, 170, 184, 187, 188], "predefin": [82, 83, 87, 88, 107], "setdictionari": [82, 107, 116, 117], "lemmatizermodel": 82, "lemmas_smal": [82, 107], "setformcol": 82, "correspend": 82, "formcol": [82, 170], "setlemmacol": 82, "fromlemma": 82, "key_delimit": 82, "value_delimit": 82, "lemma_antbnc": 82, "bigtextmatch": [83, 88], "textmatch": [83, 88, 121], "externalresourc": [83, 88, 154], "mergeoverlap": [83, 88], "tokenizermodel": [83, 125], "trie": 83, "dolor": [83, 88], "magna": [83, 88], "aliqua": [83, 88], "sit": [83, 88], "laborum": [83, 88], "hello": [83, 88, 121, 174], "entityextractor": [83, 88, 121], "extractor": [83, 88, 121], "59": [83, 84, 86, 88], "setent": [83, 88, 91, 121], "setmergeoverlap": [83, 88], "settoken": 83, "tokenizer_model": 83, "bigtextmatchermodel": 83, "btm": 83, "textmatchermodel": [83, 88], "searchtri": 83, "datematcherutil": 84, "setinputformat": [84, 141], "setoutputformat": [84, 86], "desir": [84, 86], "yyyi": [84, 86], "mm": [84, 86, 127], "dd": [84, 86, 87], "Not": [84, 94, 140], "setreadmonthfirst": 84, "juli": 84, "5th": 84, "2015": 84, "07": 84, "05": 84, "setdefaultdaywhenmiss": 84, "dai": [84, 86, 114], "miss": [84, 86, 129], "setanchordateyear": [84, 86], "anchor": [84, 86], "year": [84, 86, 110, 121, 172], "setanchordatemonth": [84, 86], "januari": [84, 86], "setanchordatedai": [84, 86], "1978": [84, 86], "28": [84, 86, 92, 138, 155, 166, 174, 182], "1984": [84, 86], "04": [84, 86], "02": [84, 86], "1980": [84, 86], "79": [84, 86], "31st": [84, 86], "april": [84, 86], "2008": [84, 86], "fri": [84, 86], "1997": [84, 86], "jan": [84, 86], "sun": [84, 86], "1st": [84, 86], "thursdai": [84, 86], "wednesdai": [84, 86], "todai": [84, 86, 174], "yesterdai": [84, 86], "0600h": [84, 86], "06": [84, 86], "00": [84, 86], "hour": [84, 86], "6pm": [84, 86], "23": [84, 86, 87, 95, 102, 172, 173, 174, 189], "1988": [84, 86], "31": [84, 86, 87, 95, 102, 172], "dateformat": [84, 86], "readmonthfirst": [84, 86], "defaultdaywhenmiss": [84, 86], "anchordateyear": [84, 86], "anchordatemonth": [84, 86], "anchordatedai": [84, 86], "15": [84, 174], "saw": 86, "him": 86, "me": 86, "visit": 86, "57": [86, 95], "65": [86, 95], "regexmatch": 87, "d": [87, 97, 125, 181], "1970": 87, "setrul": 87, "setexternalrul": 87, "match_first": 87, "match_al": 87, "match_complet": 87, "externalrul": 87, "ceremoni": 87, "setstrategi": 87, "71": 87, "short_dat": 87, "regexmatchermodel": 87, "regardless": 88, "entityvalu": 88, "buildfromtoken": 88, "27": [88, 102, 104, 172], "48": [88, 127, 174], "setentityvalu": 88, "setbuildfromtoken": 88, "null": 89, "empti": [89, 129], "enablecumul": 89, "join": [89, 102, 141, 172], "setenablecumul": 89, "nerapproach": 91, "recogn": [91, 92, 93, 94, 95, 96, 114], "setminepoch": [91, 93], "setrandomse": [91, 94, 98], "getlabelcolumn": [91, 120], "friendli": [92, 112], "whitelist": [92, 123], "setwhitelist": [92, 123], "outsid": 92, "prefix": [92, 123, 125, 163, 179], "preserveposit": [92, 124, 143], "org": [92, 93, 94, 95, 109, 127, 138, 155, 156, 166, 169, 180, 189], "14": [92, 102, 138, 142, 155, 166, 172], "ekeu": [92, 93, 94, 138, 155, 166], "36": [92, 102, 138, 155, 166, 172, 174], "baghdad": [92, 93, 94, 138, 155, 166], "37": [92, 138, 155, 166], "setpreserveposit": [92, 124, 143], "setnerhasnoschema": 92, "nercrf": 93, "nercrfapproach": [93, 94], "nercrfmodel": [93, 94], "crf": [93, 94], "2003": [93, 94, 127, 169, 189], "exclud": [93, 94], "setexternalfeatur": 93, "minepoch": [93, 94], "l2": 93, "c0": 93, "decai": [93, 94], "gradient": 93, "2250000": 93, "lossep": 93, "ep": 93, "minw": 93, "includeconfid": [93, 94], "confid": [93, 94, 96], "externalfeatur": 93, "nerdlapproach": [93, 94, 169, 189], "trainingdata": [93, 94, 105, 116, 117, 169], "readdataset": [93, 94, 102, 127, 169, 170, 172, 173, 174, 189], "conll2003": [93, 94, 169, 189], "eng": [93, 94, 169, 189], "setl2": 93, "l2valu": 93, "setc0": 93, "c0valu": 93, "setlossep": 93, "setminw": 93, "setincludeconfid": [93, 94], "verbosevalu": 93, "prerequisit": [93, 94, 95, 183], "nerdl": 94, "char": [94, 97, 105], "bilstm": 94, "tagger": [94, 172, 189], "50": [94, 95, 102, 109, 110, 174], "real": [94, 156, 163, 179], "rage": 94, "graphfold": [94, 114], "usecontrib": 94, "contrib": 94, "cell": [94, 141], "slightli": [94, 105], "includeallconfidencescor": 94, "enablememoryoptim": 94, "slow": 94, "down": [94, 183, 184], "usebestmodel": 94, "bestmodelmetr": 94, "check": [94, 104, 114, 115, 116, 117, 138, 143, 166, 183, 188], "micro": 94, "macro": 94, "setgraphfold": [94, 114, 120], "setusecontrib": 94, "setpo": 94, "setincludeallconfidencescor": 94, "setenablememoryoptim": 94, "setusebestmodel": 94, "setbestmodelmetr": 94, "nermodel": 94, "neroverwrit": 95, "setnewresult": 95, "nerword": 95, "overwritten": 95, "newnerent": 95, "lab": 95, "42": [95, 102], "45": [95, 102, 172, 174], "47": [95, 172, 174], "66": 95, "ner_overwritten": 95, "setnerword": 95, "setnewnerent": 95, "cardin": 95, "setreplaceent": 95, "rw": 95, "zeroshotnermodel": 96, "shot": [96, 110], "zeroshotn": 96, "zer_shot_n": 96, "entitydefinit": 96, "citi": 96, "town": 96, "predictionthreshold": 96, "01f": 96, "ignoreent": 96, "zero_shot_n": 96, "setentitydefinit": 96, "hellen": 96, "5328949": 96, "9360068": 96, "83294415": 96, "45366877": 96, "setpredictionthreshold": 96, "zero_shot_ner_roberta": 96, "shortcut": 96, "stem": [97, 118, 138, 166, 187, 188], "henc": 97, "pl": 97, "slangdictionari": 97, "slang": 97, "minlength": [97, 104, 105, 124, 125], "maxlength": [97, 104, 105, 124, 125], "setcleanuppattern": 97, "punctuat": [97, 104], "alphanumer": 97, "letter": [97, 110, 114, 172, 189], "za": 97, "z": [97, 125], "brother": 97, "dont": [97, 108], "setslangdictionari": 97, "setminlength": [97, 104, 105, 124, 125], "setmaxlength": [97, 104, 105, 124, 125], "normalizermodel": 97, "classifierencod": 98, "attach": [98, 99, 146, 150, 161, 163], "evaluationdlparam": 99, "setevaluationlogextend": 99, "setenableoutputlog": [99, 163, 179], "setoutputlogspath": [99, 105, 163, 179], "assum": 99, "perceptronapproach": [102, 172, 189], "member": [102, 166], "datasetpath": 102, "pierr": [102, 172], "vinken": [102, 172], "34": [102, 172, 174], "md": [102, 172], "vb": [102, 169, 172, 189], "41": [102, 104, 172, 174], "43": [102, 104, 172, 174], "dt": [102, 172, 173, 189], "49": [102, 172], "poscol": [102, 127, 169], "niter": [102, 127], "anc": [102, 172, 189], "trainingperceptrondf": 102, "trainedpo": 102, "setposcolumn": [102, 127], "cd": [102, 169, 172], "setiter": 102, "getniter": [102, 127], "pos_anc": 102, "25": [102, 104, 172, 174], "33": [102, 174], "sentencedetectorparam": 104, "ii": 104, "abbrevi": 104, "period": 104, "geo": 104, "1026": 104, "253": 104, "553": 104, "ellipsi": 104, "quotat": 104, "mark": [104, 105, 127], "exclam": 104, "breaker": 104, "pragmaticcontentformatt": 104, "custombound": [104, 105], "setcustombound": [104, 105], "usecustomboundsonli": [104, 105], "explodesent": [104, 105, 169, 170], "useabbrevi": 104, "explicitli": [104, 105, 119, 155, 183], "customboundsstrategi": 104, "prepend": [104, 129], "break": 104, "append": [104, 114, 183], "parallel": [104, 105, 138, 169, 187], "splitlength": [104, 105], "forcibli": [104, 105], "99999": [104, 105, 125], "detectlist": 104, "nhow": 104, "setcustomboundsstrategi": 104, "setuseabbrevi": 104, "setdetectlist": 104, "setusecustomboundsonli": [104, 105], "setexplodesent": [104, 105], "setsplitlength": [104, 105], "sentencedetectordl": 105, "sentencedetectordlapproach": 105, "futur": [105, 109, 113], "setmodel": 105, "sentencedetectordlmodel": [105, 112], "modelarchitectur": 105, "impossiblepenultim": 105, "imposs": [105, 127], "penultim": 105, "epochsnumb": 105, "eo": 105, "stefan": 105, "schweter": 105, "sajawel": 105, "ahm": 105, "littl": [105, 188], "cover": [105, 109, 113, 127], "broken": 105, "moder": 105, "lack": 105, "easier": [105, 132, 185, 189], "polit": 105, "successor": 105, "great": 105, "respons": 105, "heritag": 105, "bequeath": 105, "nelson": 105, "mandela": 105, "setepochsnumb": 105, "model_architectur": 105, "validation_split": 105, "epochs_numb": 105, "output_logs_path": 105, "setimpossiblepenultim": 105, "impossible_penultim": 105, "sentencedl": 105, "sentencesdl": 105, "helen": 105, "total": [105, 127], "peopl": 105, "sentimentdetector": 107, "By": [107, 109, 113, 119, 124, 131, 156, 163, 179], "els": 107, "viveknsentimentapproach": [107, 108], "cool": 107, "superb": 107, "uninspir": 107, "sentimentscor": 107, "staff": 107, "restaur": 107, "nice": [107, 163, 179], "avoid": 107, "entri": [107, 130, 139, 167], "sttr": 107, "sentimentdetectormodel": 107, "sda": [107, 108], "pragmat": 107, "viveknsenti": 108, "analys": 108, "vivek": 108, "narayanan": 108, "give": 108, "transit": [108, 114], "sentimentcol": 108, "prunecorpu": 108, "unfrequ": 108, "scenario": 108, "scope": 108, "naiv": 108, "bay": 108, "vivekn": 108, "setsentimentcol": 108, "train_senti": 108, "result_senti": 108, "finish": [108, 131, 133, 137, 140, 156], "final_senti": 108, "cast": [108, 128], "horribl": 108, "never": [108, 183], "go": [108, 183], "again": [108, 123], "anyon": 108, "protagonist": 108, "music": 108, "setprunecorpu": 108, "frequenc": [108, 114, 116, 117, 127], "viveknsentimentmodel": 108, "sentiment_vivekn": 108, "barttransform": 109, "bart": 109, "translat": [109, 110, 112, 113, 127], "auto": [109, 120], "handl": [109, 153, 171], "captur": 109, "past": [109, 112], "incorpor": 109, "versatil": 109, "valuabl": 109, "t5": [109, 113], "settask": [109, 110, 113], "summari": [109, 110, 113], "distilbart_xsum_12_6": 109, "barttestspec": 109, "minoutputlength": [109, 110, 113], "maxoutputlength": [109, 110, 112, 113], "dosampl": [109, 110, 113], "sampl": [109, 110, 113], "greedi": [109, 110, 113], "temperatur": [109, 110, 113], "topk": [109, 110, 113], "highest": [109, 110, 113, 116], "beamsiz": 109, "beam": 109, "search": [109, 116], "topp": [109, 110, 113], "cumul": [109, 110, 113], "kept": [109, 110, 113], "repetitionpenalti": [109, 110, 113], "repetit": [109, 110, 113], "penalti": [109, 110, 113], "norepeatngrams": [109, 110, 113], "occur": [109, 110, 113], "onc": [109, 110, 113], "ignoretokenid": [109, 110, 113], "especi": [109, 110, 112, 113], "ab": 109, "1910": 109, "13461": 109, "pytorch": 109, "fairseq": 109, "arbitrari": 109, "nois": 109, "reconstruct": [109, 143], "tranform": 109, "seen": 109, "randomli": 109, "fill": 109, "dialogu": 109, "roug": 109, "bleu": 109, "ablat": 109, "influenc": [109, 114], "setmaxoutputlength": [109, 110, 112, 113], "200": [109, 113], "rich": [109, 113], "rise": [109, 113], "methodologi": [109, 113], "landscap": [109, 113], "unifi": [109, 113], "systemat": [109, 113], "dozen": [109, 113], "insight": [109, 113], "coloss": [109, 113], "facilit": [109, 113], "setignoretokenid": [109, 110, 112, 113], "setminoutputlength": [109, 110, 113], "setdosampl": [109, 110, 113], "settemperatur": [109, 110, 113], "settopk": [109, 110, 113], "settopp": [109, 110, 113], "setrepetitionpenalti": [109, 110, 113], "ctrl": [109, 110, 113], "control": [109, 110, 112, 113, 114], "setnorepeatngrams": [109, 110, 113], "setbeams": 109, "gpt2transform": 110, "gpt2": 110, "openai": 110, "caus": [110, 125], "goal": [110, 127], "direct": 110, "10x": 110, "synthet": 110, "unpreced": 110, "prime": 110, "lengthi": 110, "suggest": 110, "benefit": 110, "suffici": 110, "multitask": 110, "learner": 110, "typic": 110, "taskspecif": 110, "webpag": [110, 180], "webtext": 110, "plu": 110, "coqa": 110, "exceed": 110, "127": 110, "fashion": 110, "5b": 110, "underfit": 110, "reflect": 110, "paragraph": [110, 114], "promis": 110, "leonardo": 110, "man": 110, "1776": 110, "came": 110, "kingdom": 110, "mariantransform": 112, "marian": 112, "free": 112, "mainli": 112, "academ": 112, "notabl": 112, "edinburgh": 112, "adam": 112, "mickiewicz": 112, "pozna\u0144": 112, "commerci": 112, "contributor": 112, "mariannmt": 112, "engin": [112, 121], "behind": 112, "deploi": [112, 180], "opus_mt_en_fr": 112, "langid": 112, "maxinputlength": 112, "differenti": 112, "dynam": 112, "toolkit": 112, "setmaxinputlength": 112, "capit": [112, 114], "franc": 112, "quell": 112, "capital": 112, "devrait": 112, "savoir": 112, "fran\u00e7ai": 112, "setlangid": 112, "t5transform": 113, "reconsid": 113, "hyper": 113, "t5_small": 113, "contextspellcheck": 114, "contextspellcheckerapproach": [114, 116, 117], "noisi": 114, "spell": [114, 115, 116, 117, 138, 143, 186, 187, 188], "candid": [114, 116, 117, 125], "contextspellcheckermodel": [114, 116, 117], "error": 114, "surround": [114, 141], "edit": [114, 116, 117], "subword": 114, "checker": [114, 116, 117, 186], "languagemodelclass": 114, "lm": 114, "wordmaxdist": 114, "maxcandid": 114, "casestrategi": 114, "uppercas": 114, "errorthreshold": 114, "perplex": 114, "nlm": 114, "initialr": 114, "finalr": 114, "validationfract": 114, "datapoint": 114, "min": 114, "vocab": 114, "compoundcount": 114, "compound": 114, "classcount": 114, "special": [114, 127, 157, 184], "tradeoff": 114, "weighteddistpath": 114, "levenshtein": [114, 116, 117], "maxwindowlen": 114, "rememb": 114, "maxsentlen": 114, "norvigsweetingapproach": [114, 116, 117, 189], "symmetricdeleteapproach": [114, 116, 117, 189], "depth": [114, 186], "explan": [114, 186], "awar": 114, "sherlock": 114, "holm": 114, "spellcheck": [114, 116, 117], "setwordmaxdist": 114, "setepoch": 114, "setlanguagemodelclass": 114, "1650": 114, "addvocabclass": 114, "_name_": 114, "extra": [114, 116, 183], "dist": 114, "setmaxcandid": 114, "setcasestrategi": 114, "seterrorthreshold": 114, "setinitialr": 114, "setfinalr": 114, "setvalidationfract": 114, "fraction": 114, "setcompoundcount": 114, "setclasscount": 114, "settradeoff": 114, "alpha": 114, "setweighteddistpath": 114, "setmaxwindowlen": 114, "setmaxsentlen": 114, "sentlen": 114, "userdist": 114, "addregexclass": 114, "spellcheck_dl": 114, "gamma": 114, "decis": 114, "correctsymbol": 114, "comparelowcas": 114, "vocabfreq": 114, "idsvocab": 114, "vocabid": 114, "usenewlin": 114, "newlin": 114, "norvigsweetingmodel": [114, 116, 117], "symmetricdeletemodel": [114, 116, 117], "doc": [114, 173, 189], "cold": 114, "dreari": 114, "countri": 114, "white": 114, "smow": 114, "setweight": 114, "setgamma": 114, "setvocabfreq": 114, "setidsvocab": 114, "setvocabid": 114, "setclass": 114, "getwordclass": 114, "updateregexclass": 114, "updat": 114, "updatevocabclass": 114, "setcorrectsymbol": 114, "setcomparelowcas": 114, "norvigsweet": 116, "norvig": 116, "bayesian": 116, "tokenpattern": 116, "sensit": [116, 119, 125], "doublevari": 116, "shortcircuit": 116, "frequencyprior": 116, "ham": 116, "intersect": 116, "prioriti": [116, 125], "wordsizeignor": 116, "dupslimit": 116, "duplic": 116, "reductlimit": 116, "attempt": 116, "vowelswaplimit": 116, "vowel": 116, "swap": 116, "corrector": 116, "gummi": [116, 117], "gummic": [116, 117], "gummier": [116, 117], "gummiest": [116, 117], "gummifer": [116, 117], "basi": [116, 117], "token_pattern": [116, 117], "setdoublevari": 116, "setshortcircuit": 116, "setfrequencyprior": 116, "symmetr": [116, 117], "delet": [116, 117, 183], "damerau": [116, 117], "magnitud": [116, 117], "transpos": [116, 117], "insert": [116, 117, 183], "spellcheck_norvig": 116, "symspel": [116, 117], "somtim": 116, "wrrite": [116, 117], "wordz": [116, 117], "erong": [116, 117], "sometim": [116, 117, 183], "wrong": [116, 117], "symmetricdelet": 117, "deriv": 117, "teach": 117, "maxeditdist": 117, "frequencythreshold": [117, 127], "deletesthreshold": 117, "patttern": 117, "setmaxeditdist": 117, "setfrequencythreshold": [117, 127], "setdeletesthreshold": 117, "spellcheck_sd": 117, "spmetim": 117, "hard": 118, "employ": 118, "stopwordsclean": [119, 131, 143], "mllib": [119, 180], "stopwordsremov": 119, "cleantoken": [119, 131, 143], "stopwords_en": 119, "jvm": [119, 156], "forth": 119, "setlocal": 119, "tfnerdlgraphbuildermodel": 120, "tfnerdlgraphbuild": 120, "sethiddenunitsnumb": 120, "assertiondlapproach": 120, "medicalnerapproach": 120, "gethiddenunitsnumb": 120, "getinputcol": [120, 131, 132, 146], "srt": 120, "getgraphfold": 120, "setgraphfil": 120, "greaph": 120, "getgraphfil": 120, "chunktoken": 121, "flatten": 121, "artist": 121, "benezar": 121, "robert": 121, "farendel": 121, "graduat": 121, "luca": 121, "chunktokenizermodel": 121, "recursivetoken": 123, "recurs": [123, 140, 152, 156, 160], "suffix": [123, 125, 183], "infix": [123, 125], "middl": [123, 127], "she": 123, "qam": 123, "setprefix": 123, "setsuffix": 123, "setinfix": 123, "recursivetokenizermodel": 123, "regextoken": [124, 127, 184], "whitespac": [124, 127, 129], "tolowercas": [124, 127], "positionalmask": 124, "guarante": 124, "increment": 124, "trimwhitespac": 124, "flag": 124, "eventu": 124, "settolowercas": [124, 127], "nthi": 124, "setpositionalmask": 124, "settrimwhitespac": 124, "tokenizedsent": 125, "rulefactori": 125, "targetpattern": 125, "grab": 125, "prefixpattern": 125, "suffixpattern": 125, "infixpattern": 125, "sub": 125, "won": 125, "exceptionspath": 125, "casesensitiveexcept": 125, "contextchar": 125, "splitpattern": 125, "splitchar": 125, "didn": 125, "jane": 125, "boyfriend": 125, "getinfixpattern": 125, "getsuffixpattern": 125, "getprefixpattern": 125, "getcontextchar": 125, "getsplitchar": 125, "settargetpattern": 125, "setprefixpattern": 125, "setsuffixpattern": 125, "setinfixpattern": 125, "addinfixpattern": 125, "setexcept": 125, "getexcept": 125, "setexceptionspath": 125, "addexcept": 125, "setcasesensitiveexcept": 125, "getcasesensitiveexcept": 125, "addcontextchar": 125, "setsplitpattern": 125, "setsplitchar": 125, "addsplitchar": 125, "piec": 125, "token_rul": 125, "wordsegment": 127, "wordsegmenterapproach": 127, "korean": 127, "japanes": 127, "chines": 127, "correspond": [127, 163], "ll": 127, "rr": 127, "likewis": 127, "side": 127, "themselv": 127, "\u4e0a\u6d77": 127, "\u8ba1\u5212": 127, "\u5230": 127, "\u672c": 127, "\u4e16\u7eaa": 127, "\u672b": 127, "\u5b9e\u73b0": 127, "\u4eba\u5747": 127, "\u56fd\u5185": 127, "\u751f\u4ea7": 127, "\u603b\u503c": 127, "\u4e94\u5343": 127, "\u7f8e\u5143": 127, "\u4e0a": 127, "\u6d77": 127, "\u8ba1": 127, "\u5212": 127, "\u4e16": 127, "\u7eaa": 127, "\u5b9e": 127, "\u73b0": 127, "\u4eba": 127, "\u5747": 127, "\u56fd": 127, "\u5185": 127, "\u751f": 127, "\u4ea7": 127, "\u603b": 127, "ll\u503c": 127, "\u4e94": 127, "\u5343": 127, "\u7f8e": 127, "\u5143": 127, "shanghai": 127, "plan": 127, "dollar": 127, "capita": 127, "gdp": 127, "wordsegmentermodel": 127, "tip": 127, "frame": 127, "least": 127, "frequent": 127, "ambiguitythreshold": 127, "enableregextoken": 127, "xue": 127, "nianwen": 127, "volum": 127, "februari": 127, "aclweb": 127, "aclanthologi": 127, "o03": 127, "4002": 127, "chinese_train": 127, "utf8": 127, "\u5341": 127, "\u56db": 127, "\u4e0d": 127, "\u662f": 127, "setniter": 127, "trainingdataset": 127, "setambiguitythreshold": 127, "getfrequencythreshold": 127, "getambiguitythreshold": 127, "setenableregextoken": 127, "plit": 127, "words_seg": 127, "wordseg_pku": 127, "zh": 127, "\u7136\u800c": 127, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 127, "\u9019\u6a23": 127, "\u7684": 127, "\u8655\u7406": 127, "\u4e5f": 127, "\u884d\u751f": 127, "\u4e86": 127, "\u4e00\u4e9b": 127, "\u554f\u984c": 127, "prepar": [128, 130, 136, 139], "outputcol": [128, 130, 131, 132, 133, 136, 139], "inferschema": 128, "tmp": [128, 136, 156, 179], "librispeech_asr_dummy_clean_audio_array_parquet": 128, "float_arrai": 128, "getoutputcol": [128, 130, 131, 132, 136, 139, 146], "chunkcol": 129, "stringtyp": 129, "setisarrai": 129, "startcol": 129, "startcolbytokenindex": 129, "isarrai": 129, "failonmiss": 129, "fail": 129, "chunkassembl": 129, "setchunkcol": 129, "setstartcol": 129, "setstartcolbytokenindex": 129, "setfailonmiss": 129, "disabl": [130, 139], "idcol": [130, 139], "metadatacol": [130, 139], "cleanupmod": [130, 139], "cleanup": [130, 139], "inplac": [130, 139], "inplace_ful": [130, 139], "shrink_ful": [130, 139], "each_ful": [130, 139], "delete_ful": [130, 139], "setidcol": [130, 139], "setmetadatacol": [130, 139], "usabl": 131, "lda": 131, "forest": 131, "featurecol": 131, "cleanannot": [131, 132, 133], "outputasvector": 131, "gloveembed": 131, "finished_sentence_embed": 131, "resultwiths": 131, "1619900017976761": 131, "045552998781204224": 131, "03229299932718277": 131, "685609996318": 131, "42416998744010925": 131, "1378999948501587": 131, "5717899799346924": 131, "5078899860382": 131, "08621499687433243": 131, "15772999823093414": 131, "06067200005054474": 131, "395359992980": 131, "4970499873161316": 131, "7164199948310852": 131, "40119001269340515": 131, "05761000141501": 131, "08170200139284134": 131, "7159299850463867": 131, "20677000284194946": 131, "0295659992843": 131, "valuesplitsymbol": 132, "annotationsplitsymbol": 132, "includemetadata": 132, "outputasarrai": [132, 133], "parseembeddingsvector": 132, "setvaluesplitsymbol": 132, "setannotationsplitsymbol": 132, "setincludemetadata": [132, 184], "setoutputasarrai": [132, 133], "setparseembeddingsvector": 132, "finishedresult": 133, "hasrecursivefit": [134, 135], "java_obj": [134, 159, 162], "py4j": [134, 135, 162], "java_gatewai": [134, 135, 162], "javaobject": [134, 135, 162], "recursivepipelin": [134, 135, 140, 146], "hasrecursivetransform": 135, "doc2_chunk": [137, 156], "embeddings_finish": [137, 156], "graph_finish": [137, 156], "has_recursive_fit": [137, 156], "has_recursive_transform": [137, 156], "light_pipelin": [137, 156], "recursive_pipelin": [137, 156], "token2_chunk": [137, 156], "token_assembl": [137, 156], "lightpipelin": [138, 166, 187], "parse_embed": [138, 166], "execut": [138, 183, 187], "hold": [138, 187], "principl": [138, 187], "everyth": [138, 187, 188], "fullannot": [138, 166], "happi": [138, 182, 184, 187, 188], "prp": [138, 170, 172, 182, 187, 188, 189], "rb": [138, 172, 182, 187, 188, 189], "optional_target": [138, 166], "explain_document_pipelin": [138, 155, 166, 182, 187, 188], "dict_kei": [138, 166], "fullannotateimag": [138, 166], "path_to_imag": [138, 166], "setignoreunsupport": 138, "unsupport": 138, "annotatormodel": [138, 145, 167], "getignoreunsupport": 138, "text2": 139, "document1": 139, "document2": 139, "arg": [140, 159], "kwarg": 140, "decid": 140, "advantag": 140, "behav": 140, "exactli": 140, "intent": 140, "recursivepipelinemodel": 140, "pipeline_model": [140, 163, 179], "intend": 140, "tab": [141, 163, 179], "escap": 141, "quot": 141, "inputformat": 141, "csvdelimit": 141, "defailt": 141, "comma": 141, "escapecsvdelimit": 141, "table_csv": 141, "csv_data": 141, "input_format": 141, "setcsvdelimit": 141, "setescapecsvdelimit": 141, "token2chunk": 142, "17": [142, 172, 174], "tokenassembl": 143, "cleantext": 143, "opensourc": 143, "annotatorapproach": [144, 152, 163], "py": [144, 145, 152, 158, 162], "subclass": [145, 158, 162], "inherit": [145, 162], "ins": [145, 162], "uid": [145, 162], "annotatorproperti": 146, "setlazyannot": 146, "lazili": 146, "getlazyannot": 146, "annotator_approach": [149, 156], "annotator_model": [149, 156], "annotator_properti": [149, 156], "coverage_result": [149, 156], "recursive_annotator_approach": [149, 156], "hasembeddingsproperti": 150, "getdimens": 150, "constant": 151, "recursiveannotatorapproach": 152, "fo": 154, "assist": 155, "map_annot": 155, "f": [155, 163, 179], "output_typ": 155, "udf": 155, "userdefinedfunct": 155, "def": 155, "nnp_token": 155, "lambda": 155, "alia": 155, "epeu": 155, "map_annotations_arrai": 155, "map_annotations_strict": 155, "map_annotations_col": 155, "output_column": 155, "annotatyon_typ": 155, "chunks_df": 155, "pos_chunk": 155, "vbz": [155, 169, 189], "filter_by_annotations_col": 155, "filter_po": 155, "explode_annotations_col": 155, "annotator_java_ml": [156, 160], "annotator_transform": [156, 160], "extended_java_wrapp": [156, 160], "params_getters_sett": [156, 160], "comet": [156, 164, 181], "pretrained_pipelin": [156, 165], "resource_download": [156, 165], "pub_tat": [156, 171], "annotation_audio": 156, "annotation_imag": 156, "apple_silicon": 156, "aarch64": 156, "cache_fold": 156, "log_fold": 156, "cluster_tmp_dir": 156, "real_time_output": 156, "output_level": 156, "correctli": 156, "maco": 156, "linux": 156, "alloc": 156, "directori": [156, 167, 179], "cache_pretrain": 156, "temporarili": 156, "unpack": 156, "hadoop": 156, "dir": 156, "s3": 156, "hdf": 156, "dbf": 156, "annotator_log": 156, "annotatorjavamlread": 157, "mixin": 157, "javamlread": 157, "classmethod": 157, "mlreader": 157, "clazz": 157, "rl": 157, "javaparam": 157, "annotatortransform": 158, "ensur": 158, "_java_obj": 158, "extens": 159, "javawrapp": 159, "extendedjavawrapp": 159, "new_java_arrai": 159, "pylist": 159, "java_class": 159, "todo": 159, "chang": 159, "paramsgetterssett": 161, "getparamvalu": 161, "paramnam": 161, "setparamvalu": 161, "recursiveestim": 162, "overrid": 162, "recursivetransform": 162, "cometlogg": [163, 179], "workspac": 163, "project_nam": [163, 179], "comet_mod": [163, 179], "experiment_id": 163, "experiment_kwarg": 163, "logger": [163, 179], "meta": [163, 181], "practition": [163, 179], "reliabl": [163, 179], "streamlin": [163, 179], "lifecycl": [163, 179, 181], "track": [163, 179, 180], "explain": [163, 179, 186, 188], "reproduc": [163, 179, 180], "outputlogpath": [163, 179], "onlin": [163, 179], "reus": 163, "importerror": 163, "output_log_path": [163, 179], "embd": [163, 179], "setshuffleperepoch": [163, 179], "logdir": [163, 179], "interfac": [163, 179, 187], "chart": [163, 179], "attribut": 163, "comet_ml": [163, 179], "log_pipeline_paramet": [163, 179], "log_visu": [163, 179], "html": [163, 179], "viz": [163, 179], "upload": 163, "colum": [163, 179], "ner_chunk": [163, 179], "sparknlp_displai": [163, 179], "nervisu": [163, 179], "idx": [163, 179], "enumer": [163, 179], "label_col": [163, 179], "document_col": [163, 179], "return_html": [163, 179], "log_metr": [163, 179], "sklearn": [163, 179], "preprocess": [163, 179], "multilabelbinar": [163, 179], "classification_report": [163, 179], "preds_df": [163, 179], "topanda": [163, 179], "mlb": [163, 179], "y_true": [163, 179], "fit_transform": [163, 179], "y_pred": [163, 179], "output_dict": [163, 179], "log_paramet": 163, "log_completed_run": 163, "log_file_path": 163, "complet": [163, 180, 183], "log_asset": 163, "asset_path": 163, "asset": 163, "log_asset_data": 163, "interv": 163, "refresh": 163, "outstand": 163, "disk_loc": 166, "fulli": 166, "light_model": 166, "gather": 166, "langaug": 166, "resourcedownload": [167, 183, 188], "showpublicmodel": [167, 183], "onto_100": 167, "onto_300": 167, "ner_dl_bert": 167, "similarli": 167, "showpublicpipelin": [167, 188], "check_spel": [167, 188], "match_datetim": [167, 188], "downloadmodel": 167, "reader": 167, "j_dwn": 167, "pythonresourcedownload": 167, "downloadmodeldirectli": 167, "downloadpipelin": 167, "clearcach": 167, "clear": 167, "argument": 167, "filer": 167, "showuncategorizedresourc": 167, "yet": 167, "showavailableannot": 167, "documentcol": [169, 170], "sentencecol": [169, 170], "tokencol": 169, "conlllabelindex": 169, "conllposindex": 169, "conlldocidcol": 169, "doc_id": [169, 173], "textcol": [169, 170], "labelcol": 169, "includedocid": 169, "docstart": [169, 189], "eu": [169, 189], "np": [169, 189], "reject": [169, 189], "vp": [169, 189], "misc": [169, 189], "boycott": [169, 189], "british": [169, 189], "lamb": [169, 189], "blackburn": 169, "brussel": 169, "1996": 169, "08": 169, "storage_level": 169, "storagelevel": 169, "disk_onli": 169, "lift": 169, "persist": 169, "uposcol": 170, "upo": 170, "xposcol": 170, "xpo": 170, "lemmacol": 170, "sent_id": 170, "sell": 170, "pron": 170, "nom": 170, "plur": 170, "_": 170, "tens": 170, "conj": 170, "cc": 170, "obj": 170, "spaceaft": 170, "No": [170, 182], "punct": 170, "conllufil": [170, 189], "conlldataset": [170, 189], "morph": 170, "Into": 170, "googleo": 170, "sconj": 170, "propn": 170, "adp": 170, "wp": 170, "vbd": [170, 172, 189], "ago": [172, 189], "receiv": [172, 189], "posdf": 172, "61": 172, "56": 172, "67": [172, 173, 189], "nonexecut": 172, "69": 172, "76": 172, "director": 172, "78": 172, "81": 172, "84": 172, "outputposcol": 172, "outputdocumentcol": 172, "outputtextcol": 172, "pubtat": [173, 186], "medic": [173, 189], "titl": [173, 189], "medment": [173, 189], "25763772": [173, 189], "dctn4": [173, 189], "t116": [173, 189], "t123": [173, 189], "c4308010": [173, 189], "63": [173, 189], "chronic": [173, 189], "pseudomona": [173, 189], "aeruginosa": [173, 189], "infect": [173, 189], "t047": [173, 189], "c0854135": [173, 189], "82": [173, 189], "cystic": [173, 189], "fibrosi": [173, 189], "c0010674": [173, 189], "120": [173, 189], "pa": [173, 189], "124": [173, 189], "139": [173, 189], "pubtatorfil": 173, "corpus_pubtator_sampl": 173, "pubtatordataset": 173, "finished_token": [173, 184], "finished_po": 173, "finished_n": 173, "finished_token_metadata": 173, "finished_pos_metadata": 173, "finished_label_metadata": 173, "mo": 173, "ispaddedtoken": 173, "pad": 173, "spacytoannot": 174, "token_spac": 174, "sentence_end": 174, "spaci": 174, "multi_doc_token": 174, "went": 174, "night": 174, "bought": 174, "bread": 174, "54": 174, "46": 174, "overview": [178, 186], "workflow": 179, "dedic": 179, "account": 179, "inspect": 179, "init": 179, "sparknlp_experi": 179, "offline_directori": 179, "later": 179, "nativ": 180, "record": 180, "queri": 180, "registri": 180, "central": 180, "send": 181, "messag": 181, "mlflow": 181, "content": [182, 188], "clearli": 182, "explain_document_ml": [182, 187, 188], "approx": [182, 187, 188], "mb": [182, 187, 188], "ok": [182, 187, 188], "spearhead": 183, "produc": 183, "declar": 183, "accordingli": 183, "extra_loc": 183, "offer": [183, 185, 188], "classifierdl_use_trec50": 183, "classifierdl_use_spam": 183, "column_nam": 183, "preced": 183, "interchang": 184, "anoth": 184, "road": 184, "proce": 184, "At": 184, "sens": 188, "constantli": 188, "server": 188, "train_po": 189, "training_conl": 189, "train_corpu": 189, "withcolumnrenam": 189, "trainingpubtatordf": 189, "corpus_pubt": 189}, "objects": {"": [[156, 0, 0, "-", "sparknlp"]], "sparknlp": [[2, 0, 0, "-", "annotation"], [3, 0, 0, "-", "annotation_audio"], [4, 0, 0, "-", "annotation_image"], [77, 0, 0, "-", "annotator"], [137, 0, 0, "-", "base"], [149, 0, 0, "-", "common"], [155, 0, 0, "-", "functions"], [160, 0, 0, "-", "internal"], [164, 0, 0, "-", "logging"], [165, 0, 0, "-", "pretrained"], [156, 3, 1, "", "start"], [171, 0, 0, "-", "training"], [176, 0, 0, "-", "upload_to_hub"], [177, 0, 0, "-", "util"], [156, 3, 1, "", "version"]], "sparknlp.annotation": [[2, 1, 1, "", "Annotation"]], "sparknlp.annotation.Annotation": [[2, 2, 1, "", "arrayType"], [2, 2, 1, "", "copy"], [2, 2, 1, "", "dataType"], [2, 2, 1, "", "fromRow"], [2, 2, 1, "", "toRow"]], "sparknlp.annotation_audio": [[3, 1, 1, "", "AnnotationAudio"]], "sparknlp.annotation_audio.AnnotationAudio": [[3, 2, 1, "", "copy"]], "sparknlp.annotation_image": [[4, 1, 1, "", "AnnotationImage"]], "sparknlp.annotation_image.AnnotationImage": [[4, 2, 1, "", "copy"]], "sparknlp.annotator": [[6, 0, 0, "-", "audio"], [8, 0, 0, "-", "chunk2_doc"], [9, 0, 0, "-", "chunker"], [28, 0, 0, "-", "classifier_dl"], [43, 0, 0, "-", "coref"], [46, 0, 0, "-", "cv"], [49, 0, 0, "-", "date2_chunk"], [51, 0, 0, "-", "dependency"], [53, 0, 0, "-", "document_normalizer"], [63, 0, 0, "-", "embeddings"], [75, 0, 0, "-", "er"], [76, 0, 0, "-", "graph_extraction"], [78, 0, 0, "-", "keyword_extraction"], [80, 0, 0, "-", "ld_dl"], [82, 0, 0, "-", "lemmatizer"], [85, 0, 0, "-", "matcher"], [89, 0, 0, "-", "n_gram_generator"], [90, 0, 0, "-", "ner"], [97, 0, 0, "-", "normalizer"], [100, 0, 0, "-", "param"], [101, 0, 0, "-", "pos"], [103, 0, 0, "-", "sentence"], [106, 0, 0, "-", "sentiment"], [111, 0, 0, "-", "seq2seq"], [115, 0, 0, "-", "spell_check"], [118, 0, 0, "-", "stemmer"], [119, 0, 0, "-", "stop_words_cleaner"], [120, 0, 0, "-", "tf_ner_dl_graph_builder"], [122, 0, 0, "-", "token"], [126, 0, 0, "-", "ws"]], "sparknlp.annotator.audio": [[5, 0, 0, "-", "hubert_for_ctc"], [7, 0, 0, "-", "wav2vec2_for_ctc"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, 1, 1, "", "HubertForCTC"]], "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC": [[5, 2, 1, "", "loadSavedModel"], [5, 2, 1, "", "pretrained"], [5, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, 1, 1, "", "Wav2Vec2ForCTC"]], "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[7, 2, 1, "", "loadSavedModel"], [7, 2, 1, "", "pretrained"], [7, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.chunk2_doc": [[8, 1, 1, "", "Chunk2Doc"]], "sparknlp.annotator.chunker": [[9, 1, 1, "", "Chunker"]], "sparknlp.annotator.chunker.Chunker": [[9, 2, 1, "", "setRegexParsers"]], "sparknlp.annotator.classifier_dl": [[10, 0, 0, "-", "albert_for_question_answering"], [11, 0, 0, "-", "albert_for_sequence_classification"], [12, 0, 0, "-", "albert_for_token_classification"], [13, 0, 0, "-", "bert_for_question_answering"], [14, 0, 0, "-", "bert_for_sequence_classification"], [15, 0, 0, "-", "bert_for_token_classification"], [16, 0, 0, "-", "bert_for_zero_shot_classification"], [17, 0, 0, "-", "camembert_for_question_answering"], [18, 0, 0, "-", "camembert_for_sequence_classification"], [19, 0, 0, "-", "camembert_for_token_classification"], [20, 0, 0, "-", "classifier_dl"], [21, 0, 0, "-", "deberta_for_question_answering"], [22, 0, 0, "-", "deberta_for_sequence_classification"], [23, 0, 0, "-", "deberta_for_token_classification"], [24, 0, 0, "-", "distil_bert_for_question_answering"], [25, 0, 0, "-", "distil_bert_for_sequence_classification"], [26, 0, 0, "-", "distil_bert_for_token_classification"], [27, 0, 0, "-", "distil_bert_for_zero_shot_classification"], [29, 0, 0, "-", "longformer_for_question_answering"], [30, 0, 0, "-", "longformer_for_sequence_classification"], [31, 0, 0, "-", "longformer_for_token_classification"], [32, 0, 0, "-", "multi_classifier_dl"], [33, 0, 0, "-", "roberta_for_question_answering"], [34, 0, 0, "-", "roberta_for_sequence_classification"], [35, 0, 0, "-", "roberta_for_token_classification"], [36, 0, 0, "-", "sentiment_dl"], [37, 0, 0, "-", "tapas_for_question_answering"], [38, 0, 0, "-", "xlm_roberta_for_question_answering"], [39, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [40, 0, 0, "-", "xlm_roberta_for_token_classification"], [41, 0, 0, "-", "xlnet_for_sequence_classification"], [42, 0, 0, "-", "xlnet_for_token_classification"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, 1, 1, "", "AlbertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[10, 2, 1, "", "loadSavedModel"], [10, 2, 1, "", "pretrained"], [10, 2, 1, "", "setConfigProtoBytes"], [10, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, 1, 1, "", "AlbertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[11, 2, 1, "", "getClasses"], [11, 2, 1, "", "loadSavedModel"], [11, 2, 1, "", "pretrained"], [11, 2, 1, "", "setCoalesceSentences"], [11, 2, 1, "", "setConfigProtoBytes"], [11, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, 1, 1, "", "AlbertForTokenClassification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[12, 2, 1, "", "getClasses"], [12, 2, 1, "", "loadSavedModel"], [12, 2, 1, "", "pretrained"], [12, 2, 1, "", "setConfigProtoBytes"], [12, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, 1, 1, "", "BertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[13, 2, 1, "", "loadSavedModel"], [13, 2, 1, "", "pretrained"], [13, 2, 1, "", "setConfigProtoBytes"], [13, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, 1, 1, "", "BertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[14, 2, 1, "", "getClasses"], [14, 2, 1, "", "loadSavedModel"], [14, 2, 1, "", "pretrained"], [14, 2, 1, "", "setCoalesceSentences"], [14, 2, 1, "", "setConfigProtoBytes"], [14, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, 1, 1, "", "BertForTokenClassification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[15, 2, 1, "", "getClasses"], [15, 2, 1, "", "loadSavedModel"], [15, 2, 1, "", "pretrained"], [15, 2, 1, "", "setConfigProtoBytes"], [15, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification": [[16, 1, 1, "", "BertForZeroShotClassification"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification": [[16, 2, 1, "", "getClasses"], [16, 2, 1, "", "loadSavedModel"], [16, 2, 1, "", "pretrained"], [16, 2, 1, "", "setCoalesceSentences"], [16, 2, 1, "", "setConfigProtoBytes"], [16, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[17, 1, 1, "", "CamemBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering": [[17, 2, 1, "", "loadSavedModel"], [17, 2, 1, "", "pretrained"], [17, 2, 1, "", "setConfigProtoBytes"], [17, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[18, 1, 1, "", "CamemBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification": [[18, 2, 1, "", "getClasses"], [18, 2, 1, "", "loadSavedModel"], [18, 2, 1, "", "pretrained"], [18, 2, 1, "", "setCoalesceSentences"], [18, 2, 1, "", "setConfigProtoBytes"], [18, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[19, 1, 1, "", "CamemBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[19, 2, 1, "", "getClasses"], [19, 2, 1, "", "loadSavedModel"], [19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setConfigProtoBytes"], [19, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[20, 1, 1, "", "ClassifierDLApproach"], [20, 1, 1, "", "ClassifierDLModel"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[20, 2, 1, "", "setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[21, 1, 1, "", "DeBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[22, 1, 1, "", "DeBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[22, 2, 1, "", "getClasses"], [22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setCoalesceSentences"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[23, 1, 1, "", "DeBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[23, 2, 1, "", "getClasses"], [23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[24, 1, 1, "", "DistilBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[25, 1, 1, "", "DistilBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[25, 2, 1, "", "getClasses"], [25, 2, 1, "", "loadSavedModel"], [25, 2, 1, "", "pretrained"], [25, 2, 1, "", "setCoalesceSentences"], [25, 2, 1, "", "setConfigProtoBytes"], [25, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[26, 1, 1, "", "DistilBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[26, 2, 1, "", "getClasses"], [26, 2, 1, "", "loadSavedModel"], [26, 2, 1, "", "pretrained"], [26, 2, 1, "", "setConfigProtoBytes"], [26, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification": [[27, 1, 1, "", "DistilBertForZeroShotClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification": [[27, 2, 1, "", "getClasses"], [27, 2, 1, "", "loadSavedModel"], [27, 2, 1, "", "pretrained"], [27, 2, 1, "", "setCoalesceSentences"], [27, 2, 1, "", "setConfigProtoBytes"], [27, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[29, 1, 1, "", "LongformerForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[29, 2, 1, "", "loadSavedModel"], [29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[30, 1, 1, "", "LongformerForSequenceClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[30, 2, 1, "", "getClasses"], [30, 2, 1, "", "loadSavedModel"], [30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setCoalesceSentences"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[31, 1, 1, "", "LongformerForTokenClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[31, 2, 1, "", "getClasses"], [31, 2, 1, "", "loadSavedModel"], [31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[32, 1, 1, "", "MultiClassifierDLApproach"], [32, 1, 1, "", "MultiClassifierDLModel"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[32, 2, 1, "", "setThreshold"], [32, 2, 1, "", "setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[32, 2, 1, "", "pretrained"], [32, 2, 1, "", "setConfigProtoBytes"], [32, 2, 1, "", "setThreshold"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[33, 1, 1, "", "RoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[33, 2, 1, "", "loadSavedModel"], [33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[34, 1, 1, "", "RoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[34, 2, 1, "", "getClasses"], [34, 2, 1, "", "loadSavedModel"], [34, 2, 1, "", "pretrained"], [34, 2, 1, "", "setCoalesceSentences"], [34, 2, 1, "", "setConfigProtoBytes"], [34, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[35, 1, 1, "", "RoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[35, 2, 1, "", "getClasses"], [35, 2, 1, "", "loadSavedModel"], [35, 2, 1, "", "pretrained"], [35, 2, 1, "", "setConfigProtoBytes"], [35, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[36, 1, 1, "", "SentimentDLApproach"], [36, 1, 1, "", "SentimentDLModel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[36, 2, 1, "", "setDropout"], [36, 2, 1, "", "setThreshold"], [36, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[36, 2, 1, "", "pretrained"], [36, 2, 1, "", "setConfigProtoBytes"], [36, 2, 1, "", "setThreshold"], [36, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[37, 1, 1, "", "TapasForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[38, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[39, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[39, 2, 1, "", "getClasses"], [39, 2, 1, "", "loadSavedModel"], [39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setCoalesceSentences"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[40, 1, 1, "", "XlmRoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[40, 2, 1, "", "getClasses"], [40, 2, 1, "", "loadSavedModel"], [40, 2, 1, "", "pretrained"], [40, 2, 1, "", "setConfigProtoBytes"], [40, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[41, 1, 1, "", "XlnetForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[41, 2, 1, "", "getClasses"], [41, 2, 1, "", "loadSavedModel"], [41, 2, 1, "", "pretrained"], [41, 2, 1, "", "setCoalesceSentences"], [41, 2, 1, "", "setConfigProtoBytes"], [41, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[42, 1, 1, "", "XlnetForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[42, 2, 1, "", "getClasses"], [42, 2, 1, "", "loadSavedModel"], [42, 2, 1, "", "pretrained"], [42, 2, 1, "", "setConfigProtoBytes"], [42, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.coref": [[44, 0, 0, "-", "spanbert_coref"]], "sparknlp.annotator.coref.spanbert_coref": [[44, 1, 1, "", "SpanBertCorefModel"]], "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"], [44, 2, 1, "", "setConfigProtoBytes"], [44, 2, 1, "", "setMaxSegmentLength"], [44, 2, 1, "", "setMaxSentenceLength"], [44, 2, 1, "", "setTextGenre"]], "sparknlp.annotator.cv": [[45, 0, 0, "-", "convnext_for_image_classification"], [47, 0, 0, "-", "swin_for_image_classification"], [48, 0, 0, "-", "vit_for_image_classification"]], "sparknlp.annotator.cv.convnext_for_image_classification": [[45, 1, 1, "", "ConvNextForImageClassification"]], "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification": [[45, 2, 1, "", "getClasses"], [45, 2, 1, "", "loadSavedModel"], [45, 2, 1, "", "pretrained"], [45, 2, 1, "", "setConfigProtoBytes"], [45, 2, 1, "", "setCropPct"], [45, 2, 1, "", "setDoRescale"], [45, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[47, 1, 1, "", "SwinForImageClassification"]], "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification": [[47, 2, 1, "", "getClasses"], [47, 2, 1, "", "loadSavedModel"], [47, 2, 1, "", "pretrained"], [47, 2, 1, "", "setConfigProtoBytes"], [47, 2, 1, "", "setDoRescale"], [47, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.vit_for_image_classification": [[48, 1, 1, "", "ViTForImageClassification"]], "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[48, 2, 1, "", "getClasses"], [48, 2, 1, "", "loadSavedModel"], [48, 2, 1, "", "pretrained"], [48, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.date2_chunk": [[49, 1, 1, "", "Date2Chunk"]], "sparknlp.annotator.date2_chunk.Date2Chunk": [[49, 2, 1, "", "setEntityName"]], "sparknlp.annotator.dependency": [[50, 0, 0, "-", "dependency_parser"], [52, 0, 0, "-", "typed_dependency_parser"]], "sparknlp.annotator.dependency.dependency_parser": [[50, 1, 1, "", "DependencyParserApproach"], [50, 1, 1, "", "DependencyParserModel"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[50, 2, 1, "", "setConllU"], [50, 2, 1, "", "setDependencyTreeBank"], [50, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[50, 2, 1, "", "pretrained"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[52, 1, 1, "", "TypedDependencyParserApproach"], [52, 1, 1, "", "TypedDependencyParserModel"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[52, 2, 1, "", "setConll2009"], [52, 2, 1, "", "setConllU"], [52, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[52, 2, 1, "", "pretrained"]], "sparknlp.annotator.document_normalizer": [[53, 1, 1, "", "DocumentNormalizer"]], "sparknlp.annotator.document_normalizer.DocumentNormalizer": [[53, 2, 1, "", "setAction"], [53, 2, 1, "", "setEncoding"], [53, 2, 1, "", "setLowercase"], [53, 2, 1, "", "setPatterns"], [53, 2, 1, "", "setPolicy"], [53, 2, 1, "", "setReplacement"]], "sparknlp.annotator.embeddings": [[54, 0, 0, "-", "albert_embeddings"], [55, 0, 0, "-", "bert_embeddings"], [56, 0, 0, "-", "bert_sentence_embeddings"], [57, 0, 0, "-", "camembert_embeddings"], [58, 0, 0, "-", "chunk_embeddings"], [59, 0, 0, "-", "deberta_embeddings"], [60, 0, 0, "-", "distil_bert_embeddings"], [61, 0, 0, "-", "doc2vec"], [62, 0, 0, "-", "elmo_embeddings"], [64, 0, 0, "-", "longformer_embeddings"], [65, 0, 0, "-", "roberta_embeddings"], [66, 0, 0, "-", "roberta_sentence_embeddings"], [67, 0, 0, "-", "sentence_embeddings"], [68, 0, 0, "-", "universal_sentence_encoder"], [69, 0, 0, "-", "word2vec"], [70, 0, 0, "-", "word_embeddings"], [71, 0, 0, "-", "xlm_roberta_embeddings"], [72, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [73, 0, 0, "-", "xlnet_embeddings"]], "sparknlp.annotator.embeddings.albert_embeddings": [[54, 1, 1, "", "AlbertEmbeddings"]], "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[54, 2, 1, "", "loadSavedModel"], [54, 2, 1, "", "pretrained"], [54, 2, 1, "", "setConfigProtoBytes"], [54, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[55, 1, 1, "", "BertEmbeddings"]], "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[55, 2, 1, "", "loadSavedModel"], [55, 2, 1, "", "pretrained"], [55, 2, 1, "", "setConfigProtoBytes"], [55, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[56, 1, 1, "", "BertSentenceEmbeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[56, 2, 1, "", "loadSavedModel"], [56, 2, 1, "", "pretrained"], [56, 2, 1, "", "setConfigProtoBytes"], [56, 2, 1, "", "setIsLong"], [56, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[57, 1, 1, "", "CamemBertEmbeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[57, 2, 1, "", "loadSavedModel"], [57, 2, 1, "", "pretrained"], [57, 2, 1, "", "setConfigProtoBytes"], [57, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[58, 1, 1, "", "ChunkEmbeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[58, 2, 1, "", "setPoolingStrategy"], [58, 2, 1, "", "setSkipOOV"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[59, 1, 1, "", "DeBertaEmbeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[59, 2, 1, "", "loadSavedModel"], [59, 2, 1, "", "pretrained"], [59, 2, 1, "", "setConfigProtoBytes"], [59, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[60, 1, 1, "", "DistilBertEmbeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[60, 2, 1, "", "loadSavedModel"], [60, 2, 1, "", "pretrained"], [60, 2, 1, "", "setConfigProtoBytes"], [60, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.doc2vec": [[61, 1, 1, "", "Doc2VecApproach"], [61, 1, 1, "", "Doc2VecModel"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[61, 2, 1, "", "setMaxIter"], [61, 2, 1, "", "setMaxSentenceLength"], [61, 2, 1, "", "setMinCount"], [61, 2, 1, "", "setNumPartitions"], [61, 2, 1, "", "setSeed"], [61, 2, 1, "", "setStepSize"], [61, 2, 1, "", "setVectorSize"], [61, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[62, 1, 1, "", "ElmoEmbeddings"]], "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[62, 2, 1, "", "loadSavedModel"], [62, 2, 1, "", "pretrained"], [62, 2, 1, "", "setBatchSize"], [62, 2, 1, "", "setConfigProtoBytes"], [62, 2, 1, "", "setPoolingLayer"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[64, 1, 1, "", "LongformerEmbeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[64, 2, 1, "", "loadSavedModel"], [64, 2, 1, "", "pretrained"], [64, 2, 1, "", "setConfigProtoBytes"], [64, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[65, 1, 1, "", "RoBertaEmbeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[65, 2, 1, "", "loadSavedModel"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setConfigProtoBytes"], [65, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[66, 1, 1, "", "RoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[66, 2, 1, "", "loadSavedModel"], [66, 2, 1, "", "pretrained"], [66, 2, 1, "", "setConfigProtoBytes"], [66, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[67, 1, 1, "", "SentenceEmbeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[67, 2, 1, "", "setPoolingStrategy"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[68, 1, 1, "", "UniversalSentenceEncoder"]], "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[68, 2, 1, "", "loadSavedModel"], [68, 2, 1, "", "pretrained"], [68, 2, 1, "", "setConfigProtoBytes"], [68, 2, 1, "", "setLoadSP"]], "sparknlp.annotator.embeddings.word2vec": [[69, 1, 1, "", "Word2VecApproach"], [69, 1, 1, "", "Word2VecModel"]], "sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[69, 2, 1, "", "setMaxIter"], [69, 2, 1, "", "setMaxSentenceLength"], [69, 2, 1, "", "setMinCount"], [69, 2, 1, "", "setNumPartitions"], [69, 2, 1, "", "setSeed"], [69, 2, 1, "", "setStepSize"], [69, 2, 1, "", "setVectorSize"], [69, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[69, 2, 1, "", "pretrained"], [69, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[70, 1, 1, "", "WordEmbeddings"], [70, 1, 1, "", "WordEmbeddingsModel"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[70, 2, 1, "", "setReadCacheSize"], [70, 2, 1, "", "setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[70, 2, 1, "", "loadStorage"], [70, 2, 1, "", "overallCoverage"], [70, 2, 1, "", "pretrained"], [70, 2, 1, "", "setReadCacheSize"], [70, 2, 1, "", "withCoverageColumn"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[71, 1, 1, "", "XlmRoBertaEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[71, 2, 1, "", "loadSavedModel"], [71, 2, 1, "", "pretrained"], [71, 2, 1, "", "setConfigProtoBytes"], [71, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[72, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[72, 2, 1, "", "loadSavedModel"], [72, 2, 1, "", "pretrained"], [72, 2, 1, "", "setConfigProtoBytes"], [72, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[73, 1, 1, "", "XlnetEmbeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[73, 2, 1, "", "loadSavedModel"], [73, 2, 1, "", "pretrained"], [73, 2, 1, "", "setConfigProtoBytes"], [73, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.er": [[74, 0, 0, "-", "entity_ruler"]], "sparknlp.annotator.er.entity_ruler": [[74, 1, 1, "", "EntityRulerApproach"], [74, 1, 1, "", "EntityRulerModel"]], "sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[74, 2, 1, "", "setAlphabetResource"], [74, 2, 1, "", "setPatternsResource"], [74, 2, 1, "", "setSentenceMatch"], [74, 2, 1, "", "setUseStorage"]], "sparknlp.annotator.graph_extraction": [[76, 1, 1, "", "GraphExtraction"]], "sparknlp.annotator.graph_extraction.GraphExtraction": [[76, 2, 1, "", "setDelimiter"], [76, 2, 1, "", "setDependencyParserModel"], [76, 2, 1, "", "setEntityTypes"], [76, 2, 1, "", "setExplodeEntities"], [76, 2, 1, "", "setIncludeEdges"], [76, 2, 1, "", "setMaxSentenceSize"], [76, 2, 1, "", "setMergeEntities"], [76, 2, 1, "", "setMergeEntitiesIOBFormat"], [76, 2, 1, "", "setMinSentenceSize"], [76, 2, 1, "", "setPosModel"], [76, 2, 1, "", "setRelationshipTypes"], [76, 2, 1, "", "setRootTokens"], [76, 2, 1, "", "setTypedDependencyParserModel"]], "sparknlp.annotator.keyword_extraction": [[79, 0, 0, "-", "yake_keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[79, 1, 1, "", "YakeKeywordExtraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[79, 2, 1, "", "getStopWords"], [79, 2, 1, "", "loadDefaultStopWords"], [79, 2, 1, "", "setMaxNGrams"], [79, 2, 1, "", "setMinNGrams"], [79, 2, 1, "", "setNKeywords"], [79, 2, 1, "", "setStopWords"], [79, 2, 1, "", "setThreshold"], [79, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.ld_dl": [[81, 0, 0, "-", "language_detector_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[81, 1, 1, "", "LanguageDetectorDL"]], "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[81, 2, 1, "", "pretrained"], [81, 2, 1, "", "setCoalesceSentences"], [81, 2, 1, "", "setConfigProtoBytes"], [81, 2, 1, "", "setThreshold"], [81, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.lemmatizer": [[82, 1, 1, "", "Lemmatizer"], [82, 1, 1, "", "LemmatizerModel"]], "sparknlp.annotator.lemmatizer.Lemmatizer": [[82, 2, 1, "", "setDictionary"], [82, 2, 1, "", "setFormCol"], [82, 2, 1, "", "setLemmaCol"]], "sparknlp.annotator.lemmatizer.LemmatizerModel": [[82, 2, 1, "", "pretrained"]], "sparknlp.annotator.matcher": [[83, 0, 0, "-", "big_text_matcher"], [84, 0, 0, "-", "date_matcher"], [86, 0, 0, "-", "multi_date_matcher"], [87, 0, 0, "-", "regex_matcher"], [88, 0, 0, "-", "text_matcher"]], "sparknlp.annotator.matcher.big_text_matcher": [[83, 1, 1, "", "BigTextMatcher"], [83, 1, 1, "", "BigTextMatcherModel"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[83, 2, 1, "", "setCaseSensitive"], [83, 2, 1, "", "setEntities"], [83, 2, 1, "", "setMergeOverlapping"], [83, 2, 1, "", "setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[83, 2, 1, "", "loadStorage"], [83, 2, 1, "", "pretrained"], [83, 2, 1, "", "setCaseSensitive"], [83, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.date_matcher": [[84, 1, 1, "", "DateMatcher"], [84, 1, 1, "", "DateMatcherUtils"]], "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[84, 2, 1, "", "setAnchorDateDay"], [84, 2, 1, "", "setAnchorDateMonth"], [84, 2, 1, "", "setAnchorDateYear"], [84, 2, 1, "", "setDefaultDayWhenMissing"], [84, 2, 1, "", "setInputFormats"], [84, 2, 1, "", "setOutputFormat"], [84, 2, 1, "", "setReadMonthFirst"]], "sparknlp.annotator.matcher.multi_date_matcher": [[86, 1, 1, "", "MultiDateMatcher"]], "sparknlp.annotator.matcher.regex_matcher": [[87, 1, 1, "", "RegexMatcher"], [87, 1, 1, "", "RegexMatcherModel"]], "sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[87, 2, 1, "", "setDelimiter"], [87, 2, 1, "", "setExternalRules"], [87, 2, 1, "", "setRules"], [87, 2, 1, "", "setStrategy"]], "sparknlp.annotator.matcher.text_matcher": [[88, 1, 1, "", "TextMatcher"], [88, 1, 1, "", "TextMatcherModel"]], "sparknlp.annotator.matcher.text_matcher.TextMatcher": [[88, 2, 1, "", "setBuildFromTokens"], [88, 2, 1, "", "setCaseSensitive"], [88, 2, 1, "", "setEntities"], [88, 2, 1, "", "setEntityValue"], [88, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[88, 2, 1, "", "pretrained"], [88, 2, 1, "", "setBuildFromTokens"], [88, 2, 1, "", "setEntityValue"], [88, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.n_gram_generator": [[89, 1, 1, "", "NGramGenerator"]], "sparknlp.annotator.n_gram_generator.NGramGenerator": [[89, 2, 1, "", "setDelimiter"], [89, 2, 1, "", "setEnableCumulative"], [89, 2, 1, "", "setN"]], "sparknlp.annotator.ner": [[91, 0, 0, "-", "ner_approach"], [92, 0, 0, "-", "ner_converter"], [93, 0, 0, "-", "ner_crf"], [94, 0, 0, "-", "ner_dl"], [95, 0, 0, "-", "ner_overwriter"], [96, 0, 0, "-", "zero_shot_ner_model"]], "sparknlp.annotator.ner.ner_approach": [[91, 1, 1, "", "NerApproach"]], "sparknlp.annotator.ner.ner_approach.NerApproach": [[91, 2, 1, "", "getLabelColumn"], [91, 2, 1, "", "setEntities"], [91, 2, 1, "", "setLabelColumn"], [91, 2, 1, "", "setMaxEpochs"], [91, 2, 1, "", "setMinEpochs"], [91, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.ner.ner_converter": [[92, 1, 1, "", "NerConverter"]], "sparknlp.annotator.ner.ner_converter.NerConverter": [[92, 2, 1, "", "setNerHasNoSchema"], [92, 2, 1, "", "setPreservePosition"], [92, 2, 1, "", "setWhiteList"]], "sparknlp.annotator.ner.ner_crf": [[93, 1, 1, "", "NerCrfApproach"], [93, 1, 1, "", "NerCrfModel"]], "sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[93, 2, 1, "", "setC0"], [93, 2, 1, "", "setExternalFeatures"], [93, 2, 1, "", "setIncludeConfidence"], [93, 2, 1, "", "setL2"], [93, 2, 1, "", "setLossEps"], [93, 2, 1, "", "setMinW"], [93, 2, 1, "", "setVerbose"]], "sparknlp.annotator.ner.ner_crf.NerCrfModel": [[93, 2, 1, "", "pretrained"], [93, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_dl": [[94, 1, 1, "", "NerDLApproach"], [94, 1, 1, "", "NerDLModel"]], "sparknlp.annotator.ner.ner_dl.NerDLApproach": [[94, 2, 1, "", "setBatchSize"], [94, 2, 1, "", "setBestModelMetric"], [94, 2, 1, "", "setConfigProtoBytes"], [94, 2, 1, "", "setDropout"], [94, 2, 1, "", "setEnableMemoryOptimizer"], [94, 2, 1, "", "setGraphFolder"], [94, 2, 1, "", "setIncludeAllConfidenceScores"], [94, 2, 1, "", "setIncludeConfidence"], [94, 2, 1, "", "setLr"], [94, 2, 1, "", "setPo"], [94, 2, 1, "", "setUseBestModel"], [94, 2, 1, "", "setUseContrib"]], "sparknlp.annotator.ner.ner_dl.NerDLModel": [[94, 2, 1, "", "pretrained"], [94, 2, 1, "", "setConfigProtoBytes"], [94, 2, 1, "", "setIncludeAllConfidenceScores"], [94, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_overwriter": [[95, 1, 1, "", "NerOverwriter"]], "sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[95, 2, 1, "", "setNerWords"], [95, 2, 1, "", "setNewNerEntity"], [95, 2, 1, "", "setReplaceEntities"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[96, 1, 1, "", "ZeroShotNerModel"]], "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel": [[96, 2, 1, "", "getClasses"], [96, 2, 1, "", "load"], [96, 2, 1, "", "pretrained"], [96, 2, 1, "", "setEntityDefinitions"], [96, 2, 1, "", "setPredictionThreshold"]], "sparknlp.annotator.normalizer": [[97, 1, 1, "", "Normalizer"], [97, 1, 1, "", "NormalizerModel"]], "sparknlp.annotator.normalizer.Normalizer": [[97, 2, 1, "", "setCleanupPatterns"], [97, 2, 1, "", "setLowercase"], [97, 2, 1, "", "setMaxLength"], [97, 2, 1, "", "setMinLength"], [97, 2, 1, "", "setSlangDictionary"]], "sparknlp.annotator.param": [[98, 0, 0, "-", "classifier_encoder"], [99, 0, 0, "-", "evaluation_dl_params"]], "sparknlp.annotator.param.classifier_encoder": [[98, 1, 1, "", "ClassifierEncoder"]], "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[98, 2, 1, "", "setBatchSize"], [98, 2, 1, "", "setConfigProtoBytes"], [98, 2, 1, "", "setLabelColumn"], [98, 2, 1, "", "setLr"], [98, 2, 1, "", "setMaxEpochs"], [98, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.param.evaluation_dl_params": [[99, 1, 1, "", "EvaluationDLParams"]], "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[99, 2, 1, "", "setEnableOutputLogs"], [99, 2, 1, "", "setEvaluationLogExtended"], [99, 2, 1, "", "setOutputLogsPath"], [99, 2, 1, "", "setTestDataset"], [99, 2, 1, "", "setValidationSplit"], [99, 2, 1, "", "setVerbose"]], "sparknlp.annotator.pos": [[102, 0, 0, "-", "perceptron"]], "sparknlp.annotator.pos.perceptron": [[102, 1, 1, "", "PerceptronApproach"], [102, 1, 1, "", "PerceptronModel"]], "sparknlp.annotator.pos.perceptron.PerceptronApproach": [[102, 2, 1, "", "getNIterations"], [102, 2, 1, "", "setIterations"], [102, 2, 1, "", "setPosColumn"]], "sparknlp.annotator.pos.perceptron.PerceptronModel": [[102, 2, 1, "", "pretrained"]], "sparknlp.annotator.sentence": [[104, 0, 0, "-", "sentence_detector"], [105, 0, 0, "-", "sentence_detector_dl"]], "sparknlp.annotator.sentence.sentence_detector": [[104, 1, 1, "", "SentenceDetector"], [104, 1, 1, "", "SentenceDetectorParams"]], "sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[104, 2, 1, "", "setCustomBounds"], [104, 2, 1, "", "setCustomBoundsStrategy"], [104, 2, 1, "", "setDetectLists"], [104, 2, 1, "", "setExplodeSentences"], [104, 2, 1, "", "setMaxLength"], [104, 2, 1, "", "setMinLength"], [104, 2, 1, "", "setSplitLength"], [104, 2, 1, "", "setUseAbbreviations"], [104, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[105, 1, 1, "", "SentenceDetectorDLApproach"], [105, 1, 1, "", "SentenceDetectorDLModel"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[105, 2, 1, "", "setEpochsNumber"], [105, 2, 1, "", "setExplodeSentences"], [105, 2, 1, "", "setImpossiblePenultimates"], [105, 2, 1, "", "setModel"], [105, 2, 1, "", "setOutputLogsPath"], [105, 2, 1, "", "setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[105, 2, 1, "", "pretrained"], [105, 2, 1, "", "setCustomBounds"], [105, 2, 1, "", "setExplodeSentences"], [105, 2, 1, "", "setImpossiblePenultimates"], [105, 2, 1, "", "setMaxLength"], [105, 2, 1, "", "setMinLength"], [105, 2, 1, "", "setModel"], [105, 2, 1, "", "setSplitLength"], [105, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentiment": [[107, 0, 0, "-", "sentiment_detector"], [108, 0, 0, "-", "vivekn_sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[107, 1, 1, "", "SentimentDetector"], [107, 1, 1, "", "SentimentDetectorModel"]], "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[107, 2, 1, "", "setDictionary"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[108, 1, 1, "", "ViveknSentimentApproach"], [108, 1, 1, "", "ViveknSentimentModel"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[108, 2, 1, "", "setPruneCorpus"], [108, 2, 1, "", "setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[108, 2, 1, "", "pretrained"]], "sparknlp.annotator.seq2seq": [[109, 0, 0, "-", "bart_transformer"], [110, 0, 0, "-", "gpt2_transformer"], [112, 0, 0, "-", "marian_transformer"], [113, 0, 0, "-", "t5_transformer"]], "sparknlp.annotator.seq2seq.bart_transformer": [[109, 1, 1, "", "BartTransformer"]], "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer": [[109, 2, 1, "", "loadSavedModel"], [109, 2, 1, "", "pretrained"], [109, 2, 1, "", "setBeamSize"], [109, 2, 1, "", "setConfigProtoBytes"], [109, 2, 1, "", "setDoSample"], [109, 2, 1, "", "setIgnoreTokenIds"], [109, 2, 1, "", "setMaxOutputLength"], [109, 2, 1, "", "setMinOutputLength"], [109, 2, 1, "", "setNoRepeatNgramSize"], [109, 2, 1, "", "setRepetitionPenalty"], [109, 2, 1, "", "setTask"], [109, 2, 1, "", "setTemperature"], [109, 2, 1, "", "setTopK"], [109, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[110, 1, 1, "", "GPT2Transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[110, 2, 1, "", "loadSavedModel"], [110, 2, 1, "", "pretrained"], [110, 2, 1, "", "setConfigProtoBytes"], [110, 2, 1, "", "setDoSample"], [110, 2, 1, "", "setIgnoreTokenIds"], [110, 2, 1, "", "setMaxOutputLength"], [110, 2, 1, "", "setMinOutputLength"], [110, 2, 1, "", "setNoRepeatNgramSize"], [110, 2, 1, "", "setRepetitionPenalty"], [110, 2, 1, "", "setTask"], [110, 2, 1, "", "setTemperature"], [110, 2, 1, "", "setTopK"], [110, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.marian_transformer": [[112, 1, 1, "", "MarianTransformer"]], "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[112, 2, 1, "", "loadSavedModel"], [112, 2, 1, "", "pretrained"], [112, 2, 1, "", "setConfigProtoBytes"], [112, 2, 1, "", "setIgnoreTokenIds"], [112, 2, 1, "", "setLangId"], [112, 2, 1, "", "setMaxInputLength"], [112, 2, 1, "", "setMaxOutputLength"]], "sparknlp.annotator.seq2seq.t5_transformer": [[113, 1, 1, "", "T5Transformer"]], "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[113, 2, 1, "", "loadSavedModel"], [113, 2, 1, "", "pretrained"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setDoSample"], [113, 2, 1, "", "setIgnoreTokenIds"], [113, 2, 1, "", "setMaxOutputLength"], [113, 2, 1, "", "setMinOutputLength"], [113, 2, 1, "", "setNoRepeatNgramSize"], [113, 2, 1, "", "setRepetitionPenalty"], [113, 2, 1, "", "setTask"], [113, 2, 1, "", "setTemperature"], [113, 2, 1, "", "setTopK"], [113, 2, 1, "", "setTopP"]], "sparknlp.annotator.spell_check": [[114, 0, 0, "-", "context_spell_checker"], [116, 0, 0, "-", "norvig_sweeting"], [117, 0, 0, "-", "symmetric_delete"]], "sparknlp.annotator.spell_check.context_spell_checker": [[114, 1, 1, "", "ContextSpellCheckerApproach"], [114, 1, 1, "", "ContextSpellCheckerModel"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[114, 2, 1, "", "addRegexClass"], [114, 2, 1, "", "addVocabClass"], [114, 2, 1, "", "setBatchSize"], [114, 2, 1, "", "setCaseStrategy"], [114, 2, 1, "", "setClassCount"], [114, 2, 1, "", "setCompoundCount"], [114, 2, 1, "", "setConfigProtoBytes"], [114, 2, 1, "", "setEpochs"], [114, 2, 1, "", "setErrorThreshold"], [114, 2, 1, "", "setFinalRate"], [114, 2, 1, "", "setGraphFolder"], [114, 2, 1, "", "setInitialRate"], [114, 2, 1, "", "setLanguageModelClasses"], [114, 2, 1, "", "setMaxCandidates"], [114, 2, 1, "", "setMaxSentLen"], [114, 2, 1, "", "setMaxWindowLen"], [114, 2, 1, "", "setMinCount"], [114, 2, 1, "", "setTradeoff"], [114, 2, 1, "", "setValidationFraction"], [114, 2, 1, "", "setWeightedDistPath"], [114, 2, 1, "", "setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[114, 2, 1, "", "getWordClasses"], [114, 2, 1, "", "pretrained"], [114, 2, 1, "", "setCaseStrategy"], [114, 2, 1, "", "setClasses"], [114, 2, 1, "", "setCompareLowcase"], [114, 2, 1, "", "setConfigProtoBytes"], [114, 2, 1, "", "setCorrectSymbols"], [114, 2, 1, "", "setErrorThreshold"], [114, 2, 1, "", "setGamma"], [114, 2, 1, "", "setIdsVocab"], [114, 2, 1, "", "setMaxCandidates"], [114, 2, 1, "", "setMaxWindowLen"], [114, 2, 1, "", "setTradeoff"], [114, 2, 1, "", "setVocabFreq"], [114, 2, 1, "", "setVocabIds"], [114, 2, 1, "", "setWeights"], [114, 2, 1, "", "setWordMaxDistance"], [114, 2, 1, "", "updateRegexClass"], [114, 2, 1, "", "updateVocabClass"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[116, 1, 1, "", "NorvigSweetingApproach"], [116, 1, 1, "", "NorvigSweetingModel"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[116, 2, 1, "", "setCaseSensitive"], [116, 2, 1, "", "setDictionary"], [116, 2, 1, "", "setDoubleVariants"], [116, 2, 1, "", "setFrequencyPriority"], [116, 2, 1, "", "setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[116, 2, 1, "", "pretrained"]], "sparknlp.annotator.spell_check.symmetric_delete": [[117, 1, 1, "", "SymmetricDeleteApproach"], [117, 1, 1, "", "SymmetricDeleteModel"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[117, 2, 1, "", "setDeletesThreshold"], [117, 2, 1, "", "setDictionary"], [117, 2, 1, "", "setFrequencyThreshold"], [117, 2, 1, "", "setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[117, 2, 1, "", "pretrained"]], "sparknlp.annotator.stemmer": [[118, 1, 1, "", "Stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[119, 1, 1, "", "StopWordsCleaner"]], "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[119, 2, 1, "", "loadDefaultStopWords"], [119, 2, 1, "", "pretrained"], [119, 2, 1, "", "setCaseSensitive"], [119, 2, 1, "", "setLocale"], [119, 2, 1, "", "setStopWords"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[120, 1, 1, "", "TFNerDLGraphBuilder"], [120, 1, 1, "", "TFNerDLGraphBuilderModel"]], "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[120, 2, 1, "", "getGraphFile"], [120, 2, 1, "", "getGraphFolder"], [120, 2, 1, "", "getHiddenUnitsNumber"], [120, 2, 1, "", "getInputCols"], [120, 2, 1, "", "getLabelColumn"], [120, 2, 1, "", "setGraphFile"], [120, 2, 1, "", "setGraphFolder"], [120, 2, 1, "", "setHiddenUnitsNumber"], [120, 2, 1, "", "setInputCols"], [120, 2, 1, "", "setLabelColumn"]], "sparknlp.annotator.token": [[121, 0, 0, "-", "chunk_tokenizer"], [123, 0, 0, "-", "recursive_tokenizer"], [124, 0, 0, "-", "regex_tokenizer"], [125, 0, 0, "-", "tokenizer"]], "sparknlp.annotator.token.chunk_tokenizer": [[121, 1, 1, "", "ChunkTokenizer"], [121, 1, 1, "", "ChunkTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer": [[123, 1, 1, "", "RecursiveTokenizer"], [123, 1, 1, "", "RecursiveTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[123, 2, 1, "", "setInfixes"], [123, 2, 1, "", "setPrefixes"], [123, 2, 1, "", "setSuffixes"], [123, 2, 1, "", "setWhitelist"]], "sparknlp.annotator.token.regex_tokenizer": [[124, 1, 1, "", "RegexTokenizer"]], "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[124, 2, 1, "", "setMaxLength"], [124, 2, 1, "", "setMinLength"], [124, 2, 1, "", "setPattern"], [124, 2, 1, "", "setPositionalMask"], [124, 2, 1, "", "setPreservePosition"], [124, 2, 1, "", "setToLowercase"], [124, 2, 1, "", "setTrimWhitespace"]], "sparknlp.annotator.token.tokenizer": [[125, 1, 1, "", "Tokenizer"], [125, 1, 1, "", "TokenizerModel"]], "sparknlp.annotator.token.tokenizer.Tokenizer": [[125, 2, 1, "", "addContextChars"], [125, 2, 1, "", "addException"], [125, 2, 1, "", "addInfixPattern"], [125, 2, 1, "", "addSplitChars"], [125, 2, 1, "", "getCaseSensitiveExceptions"], [125, 2, 1, "", "getContextChars"], [125, 2, 1, "", "getExceptions"], [125, 2, 1, "", "getInfixPatterns"], [125, 2, 1, "", "getPrefixPattern"], [125, 2, 1, "", "getSplitChars"], [125, 2, 1, "", "getSuffixPattern"], [125, 2, 1, "", "setCaseSensitiveExceptions"], [125, 2, 1, "", "setContextChars"], [125, 2, 1, "", "setExceptions"], [125, 2, 1, "", "setExceptionsPath"], [125, 2, 1, "", "setInfixPatterns"], [125, 2, 1, "", "setMaxLength"], [125, 2, 1, "", "setMinLength"], [125, 2, 1, "", "setPrefixPattern"], [125, 2, 1, "", "setSplitChars"], [125, 2, 1, "", "setSplitPattern"], [125, 2, 1, "", "setSuffixPattern"], [125, 2, 1, "", "setTargetPattern"]], "sparknlp.annotator.token.tokenizer.TokenizerModel": [[125, 2, 1, "", "addSplitChars"], [125, 2, 1, "", "pretrained"], [125, 2, 1, "", "setSplitChars"], [125, 2, 1, "", "setSplitPattern"]], "sparknlp.annotator.ws": [[127, 0, 0, "-", "word_segmenter"]], "sparknlp.annotator.ws.word_segmenter": [[127, 1, 1, "", "WordSegmenterApproach"], [127, 1, 1, "", "WordSegmenterModel"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[127, 2, 1, "", "getAmbiguityThreshold"], [127, 2, 1, "", "getFrequencyThreshold"], [127, 2, 1, "", "getNIterations"], [127, 2, 1, "", "setAmbiguityThreshold"], [127, 2, 1, "", "setEnableRegexTokenizer"], [127, 2, 1, "", "setFrequencyThreshold"], [127, 2, 1, "", "setNIterations"], [127, 2, 1, "", "setPattern"], [127, 2, 1, "", "setPosColumn"], [127, 2, 1, "", "setToLowercase"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[127, 2, 1, "", "pretrained"], [127, 2, 1, "", "setEnableRegexTokenizer"], [127, 2, 1, "", "setPattern"], [127, 2, 1, "", "setToLowercase"]], "sparknlp.base": [[128, 0, 0, "-", "audio_assembler"], [129, 0, 0, "-", "doc2_chunk"], [130, 0, 0, "-", "document_assembler"], [131, 0, 0, "-", "embeddings_finisher"], [132, 0, 0, "-", "finisher"], [133, 0, 0, "-", "graph_finisher"], [134, 0, 0, "-", "has_recursive_fit"], [135, 0, 0, "-", "has_recursive_transform"], [136, 0, 0, "-", "image_assembler"], [138, 0, 0, "-", "light_pipeline"], [139, 0, 0, "-", "multi_document_assembler"], [140, 0, 0, "-", "recursive_pipeline"], [141, 0, 0, "-", "table_assembler"], [142, 0, 0, "-", "token2_chunk"], [143, 0, 0, "-", "token_assembler"]], "sparknlp.base.audio_assembler": [[128, 1, 1, "", "AudioAssembler"]], "sparknlp.base.audio_assembler.AudioAssembler": [[128, 2, 1, "", "getOutputCol"], [128, 2, 1, "", "setInputCol"], [128, 2, 1, "", "setOutputCol"]], "sparknlp.base.doc2_chunk": [[129, 1, 1, "", "Doc2Chunk"]], "sparknlp.base.doc2_chunk.Doc2Chunk": [[129, 2, 1, "", "setChunkCol"], [129, 2, 1, "", "setFailOnMissing"], [129, 2, 1, "", "setIsArray"], [129, 2, 1, "", "setLowerCase"], [129, 2, 1, "", "setStartCol"], [129, 2, 1, "", "setStartColByTokenIndex"]], "sparknlp.base.document_assembler": [[130, 1, 1, "", "DocumentAssembler"]], "sparknlp.base.document_assembler.DocumentAssembler": [[130, 2, 1, "", "getOutputCol"], [130, 2, 1, "", "setCleanupMode"], [130, 2, 1, "", "setIdCol"], [130, 2, 1, "", "setInputCol"], [130, 2, 1, "", "setMetadataCol"], [130, 2, 1, "", "setOutputCol"]], "sparknlp.base.embeddings_finisher": [[131, 1, 1, "", "EmbeddingsFinisher"]], "sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[131, 2, 1, "", "getInputCols"], [131, 2, 1, "", "getOutputCols"], [131, 2, 1, "", "setCleanAnnotations"], [131, 2, 1, "", "setInputCols"], [131, 2, 1, "", "setOutputAsVector"], [131, 2, 1, "", "setOutputCols"]], "sparknlp.base.finisher": [[132, 1, 1, "", "Finisher"]], "sparknlp.base.finisher.Finisher": [[132, 2, 1, "", "getInputCols"], [132, 2, 1, "", "getOutputCols"], [132, 2, 1, "", "setAnnotationSplitSymbol"], [132, 2, 1, "", "setCleanAnnotations"], [132, 2, 1, "", "setIncludeMetadata"], [132, 2, 1, "", "setInputCols"], [132, 2, 1, "", "setOutputAsArray"], [132, 2, 1, "", "setOutputCols"], [132, 2, 1, "", "setParseEmbeddingsVectors"], [132, 2, 1, "", "setValueSplitSymbol"]], "sparknlp.base.graph_finisher": [[133, 1, 1, "", "GraphFinisher"]], "sparknlp.base.graph_finisher.GraphFinisher": [[133, 2, 1, "", "setCleanAnnotations"], [133, 2, 1, "", "setInputCol"], [133, 2, 1, "", "setOutputAsArray"], [133, 2, 1, "", "setOutputCol"]], "sparknlp.base.has_recursive_fit": [[134, 1, 1, "", "HasRecursiveFit"]], "sparknlp.base.has_recursive_transform": [[135, 1, 1, "", "HasRecursiveTransform"]], "sparknlp.base.image_assembler": [[136, 1, 1, "", "ImageAssembler"]], "sparknlp.base.image_assembler.ImageAssembler": [[136, 2, 1, "", "getOutputCol"], [136, 2, 1, "", "setInputCol"], [136, 2, 1, "", "setOutputCol"]], "sparknlp.base.light_pipeline": [[138, 1, 1, "", "LightPipeline"]], "sparknlp.base.light_pipeline.LightPipeline": [[138, 2, 1, "", "annotate"], [138, 2, 1, "", "fullAnnotate"], [138, 2, 1, "", "fullAnnotateImage"], [138, 2, 1, "", "getIgnoreUnsupported"], [138, 2, 1, "", "setIgnoreUnsupported"], [138, 2, 1, "", "transform"]], "sparknlp.base.multi_document_assembler": [[139, 1, 1, "", "MultiDocumentAssembler"]], "sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[139, 2, 1, "", "getOutputCols"], [139, 2, 1, "", "setCleanupMode"], [139, 2, 1, "", "setIdCol"], [139, 2, 1, "", "setInputCols"], [139, 2, 1, "", "setMetadataCol"], [139, 2, 1, "", "setOutputCols"]], "sparknlp.base.recursive_pipeline": [[140, 1, 1, "", "RecursivePipeline"], [140, 1, 1, "", "RecursivePipelineModel"]], "sparknlp.base.table_assembler": [[141, 1, 1, "", "TableAssembler"]], "sparknlp.base.table_assembler.TableAssembler": [[141, 2, 1, "", "setCsvDelimiter"], [141, 2, 1, "", "setEscapeCsvDelimiter"], [141, 2, 1, "", "setInputFormat"]], "sparknlp.base.token2_chunk": [[142, 1, 1, "", "Token2Chunk"]], "sparknlp.base.token_assembler": [[143, 1, 1, "", "TokenAssembler"]], "sparknlp.base.token_assembler.TokenAssembler": [[143, 2, 1, "", "setPreservePosition"]], "sparknlp.common": [[144, 0, 0, "-", "annotator_approach"], [145, 0, 0, "-", "annotator_model"], [146, 0, 0, "-", "annotator_properties"], [147, 0, 0, "-", "annotator_type"], [148, 0, 0, "-", "coverage_result"], [150, 0, 0, "-", "properties"], [151, 0, 0, "-", "read_as"], [152, 0, 0, "-", "recursive_annotator_approach"], [153, 0, 0, "-", "storage"], [154, 0, 0, "-", "utils"]], "sparknlp.common.annotator_approach": [[144, 1, 1, "", "AnnotatorApproach"]], "sparknlp.common.annotator_model": [[145, 1, 1, "", "AnnotatorModel"]], "sparknlp.common.annotator_properties": [[146, 1, 1, "", "AnnotatorProperties"]], "sparknlp.common.annotator_properties.AnnotatorProperties": [[146, 2, 1, "", "getInputCols"], [146, 2, 1, "", "getLazyAnnotator"], [146, 2, 1, "", "getOutputCol"], [146, 2, 1, "", "setInputCols"], [146, 2, 1, "", "setLazyAnnotator"], [146, 2, 1, "", "setOutputCol"]], "sparknlp.common.properties": [[150, 1, 1, "", "HasEmbeddingsProperties"]], "sparknlp.common.properties.HasEmbeddingsProperties": [[150, 2, 1, "", "getDimension"], [150, 2, 1, "", "setDimension"]], "sparknlp.common.read_as": [[151, 1, 1, "", "ReadAs"]], "sparknlp.common.recursive_annotator_approach": [[152, 1, 1, "", "RecursiveAnnotatorApproach"]], "sparknlp.common.utils": [[154, 3, 1, "", "ExternalResource"]], "sparknlp.functions": [[155, 3, 1, "", "explode_annotations_col"], [155, 3, 1, "", "filter_by_annotations_col"], [155, 3, 1, "", "map_annotations"], [155, 3, 1, "", "map_annotations_array"], [155, 3, 1, "", "map_annotations_col"], [155, 3, 1, "", "map_annotations_cols"], [155, 3, 1, "", "map_annotations_strict"]], "sparknlp.internal": [[157, 0, 0, "-", "annotator_java_ml"], [158, 0, 0, "-", "annotator_transformer"], [159, 0, 0, "-", "extended_java_wrapper"], [161, 0, 0, "-", "params_getters_setters"], [162, 0, 0, "-", "recursive"]], "sparknlp.internal.annotator_java_ml": [[157, 1, 1, "", "AnnotatorJavaMLReadable"], [157, 1, 1, "", "AnnotatorJavaMLReader"]], "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[157, 2, 1, "", "read"]], "sparknlp.internal.annotator_transformer": [[158, 1, 1, "", "AnnotatorTransformer"]], "sparknlp.internal.extended_java_wrapper": [[159, 1, 1, "", "ExtendedJavaWrapper"]], "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[159, 2, 1, "", "new_java_array"]], "sparknlp.internal.params_getters_setters": [[161, 1, 1, "", "ParamsGettersSetters"]], "sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[161, 2, 1, "", "getParamValue"], [161, 2, 1, "", "setParamValue"]], "sparknlp.internal.recursive": [[162, 1, 1, "", "RecursiveEstimator"], [162, 1, 1, "", "RecursiveTransformer"]], "sparknlp.internal.recursive.RecursiveEstimator": [[162, 2, 1, "", "fit"]], "sparknlp.logging": [[163, 0, 0, "-", "comet"]], "sparknlp.logging.comet": [[163, 1, 1, "", "CometLogger"]], "sparknlp.logging.comet.CometLogger": [[163, 2, 1, "", "end"], [163, 2, 1, "", "log_asset"], [163, 2, 1, "", "log_asset_data"], [163, 2, 1, "", "log_completed_run"], [163, 2, 1, "", "log_metrics"], [163, 2, 1, "", "log_parameters"], [163, 2, 1, "", "log_pipeline_parameters"], [163, 2, 1, "", "log_visualization"], [163, 2, 1, "", "monitor"]], "sparknlp.pretrained": [[166, 0, 0, "-", "pretrained_pipeline"], [167, 0, 0, "-", "resource_downloader"], [168, 0, 0, "-", "utils"]], "sparknlp.pretrained.pretrained_pipeline": [[166, 1, 1, "", "PretrainedPipeline"]], "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[166, 2, 1, "", "annotate"], [166, 2, 1, "", "fullAnnotate"], [166, 2, 1, "", "fullAnnotateImage"], [166, 2, 1, "", "transform"]], "sparknlp.pretrained.resource_downloader": [[167, 1, 1, "", "ResourceDownloader"]], "sparknlp.pretrained.resource_downloader.ResourceDownloader": [[167, 2, 1, "", "clearCache"], [167, 2, 1, "", "downloadModel"], [167, 2, 1, "", "downloadModelDirectly"], [167, 2, 1, "", "downloadPipeline"], [167, 2, 1, "", "showAvailableAnnotators"], [167, 2, 1, "", "showPublicModels"], [167, 2, 1, "", "showPublicPipelines"], [167, 2, 1, "", "showUnCategorizedResources"]], "sparknlp.training": [[169, 0, 0, "-", "conll"], [170, 0, 0, "-", "conllu"], [172, 0, 0, "-", "pos"], [173, 0, 0, "-", "pub_tator"], [174, 0, 0, "-", "spacy_to_annotation"], [175, 0, 0, "-", "tfgraphs"]], "sparknlp.training.conll": [[169, 1, 1, "", "CoNLL"]], "sparknlp.training.conll.CoNLL": [[169, 2, 1, "", "readDataset"]], "sparknlp.training.conllu": [[170, 1, 1, "", "CoNLLU"]], "sparknlp.training.conllu.CoNLLU": [[170, 2, 1, "", "readDataset"]], "sparknlp.training.pos": [[172, 1, 1, "", "POS"]], "sparknlp.training.pos.POS": [[172, 2, 1, "", "readDataset"]], "sparknlp.training.pub_tator": [[173, 1, 1, "", "PubTator"]], "sparknlp.training.pub_tator.PubTator": [[173, 2, 1, "", "readDataset"]], "sparknlp.training.spacy_to_annotation": [[174, 1, 1, "", "SpacyToAnnotation"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"get": [0, 184], "start": 0, "spark": [0, 1, 179, 184, 188], "nlp": [0, 1, 179, 188], "cheat": 0, "sheet": 0, "requir": 0, "instal": [0, 179], "us": [0, 179, 188], "conda": 0, "virtualenv": 0, "session": 0, "from": 0, "python": 0, "document": 1, "content": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 166, 167, 169, 170, 172, 173, 174], "sparknlp": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177], "annot": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 182, 183, 184], "modul": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 154, 155, 157, 158, 159, 161, 162, 163, 166, 167, 169, 170, 172, 173, 174, 178], "class": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 157, 158, 159, 161, 162, 163, 166, 167, 169, 170, 172, 173, 174], "annotation_audio": 3, "annotation_imag": 4, "audio": [5, 6, 7], "hubert_for_ctc": 5, "submodul": [6, 28, 43, 46, 51, 63, 75, 77, 78, 80, 85, 90, 101, 103, 106, 111, 115, 122, 126, 137, 149, 156, 160, 164, 165, 171], "wav2vec2_for_ctc": 7, "chunk2_doc": 8, "chunker": 9, "classifier_dl": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42], "albert_for_question_answ": 10, "albert_for_sequence_classif": 11, "albert_for_token_classif": 12, "bert_for_question_answ": 13, "bert_for_sequence_classif": 14, "bert_for_token_classif": 15, "bert_for_zero_shot_classif": 16, "camembert_for_question_answ": 17, "camembert_for_sequence_classif": 18, "camembert_for_token_classif": 19, "deberta_for_question_answ": 21, "deberta_for_sequence_classif": 22, "deberta_for_token_classif": 23, "distil_bert_for_question_answ": 24, "distil_bert_for_sequence_classif": 25, "distil_bert_for_token_classif": 26, "distil_bert_for_zero_shot_classif": 27, "longformer_for_question_answ": 29, "longformer_for_sequence_classif": 30, "longformer_for_token_classif": 31, "multi_classifier_dl": 32, "roberta_for_question_answ": 33, "roberta_for_sequence_classif": 34, "roberta_for_token_classif": 35, "sentiment_dl": 36, "tapas_for_question_answ": 37, "xlm_roberta_for_question_answ": 38, "xlm_roberta_for_sequence_classif": 39, "xlm_roberta_for_token_classif": 40, "xlnet_for_sequence_classif": 41, "xlnet_for_token_classif": 42, "coref": [43, 44], "spanbert_coref": 44, "cv": [45, 46, 47, 48], "convnext_for_image_classif": 45, "swin_for_image_classif": 47, "vit_for_image_classif": 48, "date2_chunk": 49, "depend": [50, 51, 52], "dependency_pars": 50, "typed_dependency_pars": 52, "document_norm": 53, "embed": [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73], "albert_embed": 54, "bert_embed": 55, "bert_sentence_embed": 56, "camembert_embed": 57, "chunk_embed": 58, "deberta_embed": 59, "distil_bert_embed": 60, "doc2vec": 61, "elmo_embed": 62, "longformer_embed": 64, "roberta_embed": 65, "roberta_sentence_embed": 66, "sentence_embed": 67, "universal_sentence_encod": 68, "word2vec": 69, "word_embed": 70, "xlm_roberta_embed": 71, "xlm_roberta_sentence_embed": 72, "xlnet_embed": 73, "er": [74, 75], "entity_rul": 74, "graph_extract": 76, "subpackag": [77, 156], "keyword_extract": [78, 79], "yake_keyword_extract": 79, "ld_dl": [80, 81], "language_detector_dl": 81, "lemmat": 82, "matcher": [83, 84, 85, 86, 87, 88], "big_text_match": 83, "date_match": 84, "multi_date_match": 86, "regex_match": 87, "text_match": 88, "n_gram_gener": 89, "ner": [90, 91, 92, 93, 94, 95, 96], "ner_approach": 91, "ner_convert": 92, "ner_crf": 93, "ner_dl": 94, "ner_overwrit": 95, "zero_shot_ner_model": 96, "normal": 97, "param": [98, 99, 100], "classifier_encod": 98, "evaluation_dl_param": 99, "po": [101, 102, 172, 189], "perceptron": 102, "sentenc": [103, 104, 105, 184], "sentence_detector": 104, "sentence_detector_dl": 105, "sentiment": [106, 107, 108], "sentiment_detector": 107, "vivekn_senti": 108, "seq2seq": [109, 110, 111, 112, 113], "bart_transform": 109, "gpt2_transform": 110, "marian_transform": 112, "t5_transform": 113, "spell_check": [114, 115, 116, 117], "context_spell_check": 114, "norvig_sweet": 116, "symmetric_delet": 117, "stemmer": 118, "stop_words_clean": 119, "tf_ner_dl_graph_build": 120, "token": [121, 122, 123, 124, 125, 184], "chunk_token": 121, "recursive_token": 123, "regex_token": 124, "w": [126, 127], "word_segment": 127, "base": [128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], "audio_assembl": 128, "doc2_chunk": 129, "document_assembl": 130, "embeddings_finish": 131, "finish": [132, 184], "graph_finish": 133, "has_recursive_fit": 134, "has_recursive_transform": 135, "image_assembl": 136, "light_pipelin": 138, "multi_document_assembl": 139, "recursive_pipelin": 140, "table_assembl": 141, "token2_chunk": 142, "token_assembl": 143, "common": [144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 183], "annotator_approach": 144, "annotator_model": 145, "annotator_properti": 146, "annotator_typ": 147, "coverage_result": 148, "properti": 150, "read_a": 151, "recursive_annotator_approach": 152, "storag": 153, "util": [154, 168, 177], "function": [154, 155, 156, 183, 185], "packag": 156, "intern": [157, 158, 159, 160, 161, 162], "annotator_java_ml": 157, "annotator_transform": 158, "extended_java_wrapp": 159, "params_getters_sett": 161, "recurs": 162, "log": [163, 164, 179, 181], "comet": [163, 179], "pretrain": [165, 166, 167, 168, 183, 187, 188], "pretrained_pipelin": 166, "resource_download": 167, "train": [169, 170, 171, 172, 173, 174, 175, 189], "conll": [169, 189], "conllu": [170, 189], "pub_tat": 173, "spacy_to_annot": 174, "tfgraph": 175, "upload_to_hub": 176, "api": 178, "refer": 178, "A": 179, "meta": 179, "machin": [179, 180], "learn": [179, 180], "platform": [179, 180], "pipelin": [179, 184, 187, 188], "paramet": 179, "evalu": 179, "metric": 179, "visual": 179, "run": 179, "an": 179, "offlin": 179, "experi": 179, "mlflow": 180, "lifecycl": 180, "third": 181, "parti": 181, "project": 181, "approach": 183, "model": 183, "note": 183, "avail": [183, 188], "set": 184, "up": 184, "your": 184, "own": 184, "type": 184, "necessari": 184, "import": 184, "construct": 184, "documentassembl": 184, "data": 184, "detect": 184, "out": 184, "put": 184, "all": 184, "togeth": 184, "ml": [184, 188], "helper": 185, "user": 186, "guid": 186, "light": 187, "convert": 187, "pipelinemodel": 187, "download": 188, "As": 188, "lightpipelin": 188, "load": 189, "dataset": 189, "spell": 189, "checker": 189, "pubtat": 189}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Getting Started": [[0, "getting-started"]], "Spark NLP Cheat Sheet": [[0, "spark-nlp-cheat-sheet"]], "Requirements": [[0, "requirements"]], "Installation": [[0, "installation"], [179, "installation"]], "Using Conda": [[0, "using-conda"]], "Using Virtualenv": [[0, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[0, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[1, "spark-nlp-documentation"]], "Content": [[1, "content"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "Module Contents": [[2, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [8, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [44, "module-contents"], [45, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [50, "module-contents"], [52, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [76, "module-contents"], [79, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [86, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [102, "module-contents"], [104, "module-contents"], [105, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [110, "module-contents"], [112, "module-contents"], [113, "module-contents"], [114, "module-contents"], [116, "module-contents"], [117, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [121, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [145, "module-contents"], [146, "module-contents"], [150, "module-contents"], [151, "module-contents"], [152, "module-contents"], [154, "module-contents"], [155, "module-contents"], [157, "module-contents"], [158, "module-contents"], [159, "module-contents"], [161, "module-contents"], [162, "module-contents"], [163, "module-contents"], [166, "module-contents"], [167, "module-contents"], [169, "module-contents"], [170, "module-contents"], [172, "module-contents"], [173, "module-contents"], [174, "module-contents"]], "Classes": [[2, "classes"], [3, "classes"], [4, "classes"], [5, "classes"], [7, "classes"], [8, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [42, "classes"], [44, "classes"], [45, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [50, "classes"], [52, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [76, "classes"], [79, "classes"], [81, "classes"], [82, "classes"], [83, "classes"], [84, "classes"], [86, "classes"], [87, "classes"], [88, "classes"], [89, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [95, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [99, "classes"], [102, "classes"], [104, "classes"], [105, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [110, "classes"], [112, "classes"], [113, "classes"], [114, "classes"], [116, "classes"], [117, "classes"], [118, "classes"], [119, "classes"], [120, "classes"], [121, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [145, "classes"], [146, "classes"], [150, "classes"], [151, "classes"], [152, "classes"], [157, "classes"], [158, "classes"], [159, "classes"], [161, "classes"], [162, "classes"], [163, "classes"], [166, "classes"], [167, "classes"], [169, "classes"], [170, "classes"], [172, "classes"], [173, "classes"], [174, "classes"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "Submodules": [[6, "submodules"], [28, "submodules"], [43, "submodules"], [46, "submodules"], [51, "submodules"], [63, "submodules"], [75, "submodules"], [77, "submodules"], [78, "submodules"], [80, "submodules"], [85, "submodules"], [90, "submodules"], [101, "submodules"], [103, "submodules"], [106, "submodules"], [111, "submodules"], [115, "submodules"], [122, "submodules"], [126, "submodules"], [137, "submodules"], [149, "submodules"], [156, "submodules"], [160, "submodules"], [164, "submodules"], [165, "submodules"], [171, "submodules"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "sparknlp.annotator.chunk2_doc": [[8, "module-sparknlp.annotator.chunk2_doc"]], "sparknlp.annotator.chunker": [[9, "module-sparknlp.annotator.chunker"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification": [[16, "module-sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[18, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[19, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[20, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[22, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[23, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[26, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification": [[27, "module-sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification"]], "sparknlp.annotator.classifier_dl": [[28, "module-sparknlp.annotator.classifier_dl"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[29, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[30, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[31, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[32, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[33, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[34, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[35, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[36, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[37, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[40, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[41, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[42, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[43, "module-sparknlp.annotator.coref"]], "sparknlp.annotator.coref.spanbert_coref": [[44, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv.convnext_for_image_classification": [[45, "module-sparknlp.annotator.cv.convnext_for_image_classification"]], "sparknlp.annotator.cv": [[46, "module-sparknlp.annotator.cv"]], "sparknlp.annotator.cv.swin_for_image_classification": [[47, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "sparknlp.annotator.cv.vit_for_image_classification": [[48, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "sparknlp.annotator.date2_chunk": [[49, "module-sparknlp.annotator.date2_chunk"]], "sparknlp.annotator.dependency.dependency_parser": [[50, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[51, "module-sparknlp.annotator.dependency"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[52, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "sparknlp.annotator.document_normalizer": [[53, "module-sparknlp.annotator.document_normalizer"]], "sparknlp.annotator.embeddings.albert_embeddings": [[54, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "sparknlp.annotator.embeddings.bert_embeddings": [[55, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[56, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[57, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[58, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[59, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[60, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "sparknlp.annotator.embeddings.doc2vec": [[61, "module-sparknlp.annotator.embeddings.doc2vec"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[62, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[63, "module-sparknlp.annotator.embeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[64, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[65, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[66, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[67, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[68, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "sparknlp.annotator.embeddings.word2vec": [[69, "module-sparknlp.annotator.embeddings.word2vec"]], "sparknlp.annotator.embeddings.word_embeddings": [[70, "module-sparknlp.annotator.embeddings.word_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[71, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[72, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[73, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "sparknlp.annotator.er.entity_ruler": [[74, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[75, "module-sparknlp.annotator.er"]], "sparknlp.annotator.graph_extraction": [[76, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[77, "module-sparknlp.annotator"]], "Subpackages": [[77, "subpackages"], [156, "subpackages"]], "sparknlp.annotator.keyword_extraction": [[78, "module-sparknlp.annotator.keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[79, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[80, "module-sparknlp.annotator.ld_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[81, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "sparknlp.annotator.lemmatizer": [[82, "module-sparknlp.annotator.lemmatizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[83, "module-sparknlp.annotator.matcher.big_text_matcher"]], "sparknlp.annotator.matcher.date_matcher": [[84, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[85, "module-sparknlp.annotator.matcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[86, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "sparknlp.annotator.matcher.regex_matcher": [[87, "module-sparknlp.annotator.matcher.regex_matcher"]], "sparknlp.annotator.matcher.text_matcher": [[88, "module-sparknlp.annotator.matcher.text_matcher"]], "sparknlp.annotator.n_gram_generator": [[89, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[90, "module-sparknlp.annotator.ner"]], "sparknlp.annotator.ner.ner_approach": [[91, "module-sparknlp.annotator.ner.ner_approach"]], "sparknlp.annotator.ner.ner_converter": [[92, "module-sparknlp.annotator.ner.ner_converter"]], "sparknlp.annotator.ner.ner_crf": [[93, "module-sparknlp.annotator.ner.ner_crf"]], "sparknlp.annotator.ner.ner_dl": [[94, "module-sparknlp.annotator.ner.ner_dl"]], "sparknlp.annotator.ner.ner_overwriter": [[95, "module-sparknlp.annotator.ner.ner_overwriter"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[96, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "sparknlp.annotator.normalizer": [[97, "module-sparknlp.annotator.normalizer"]], "sparknlp.annotator.param.classifier_encoder": [[98, "module-sparknlp.annotator.param.classifier_encoder"]], "sparknlp.annotator.param.evaluation_dl_params": [[99, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[100, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[101, "module-sparknlp.annotator.pos"]], "sparknlp.annotator.pos.perceptron": [[102, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[103, "module-sparknlp.annotator.sentence"]], "sparknlp.annotator.sentence.sentence_detector": [[104, "module-sparknlp.annotator.sentence.sentence_detector"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[105, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[106, "module-sparknlp.annotator.sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[107, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[108, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "sparknlp.annotator.seq2seq.bart_transformer": [[109, "module-sparknlp.annotator.seq2seq.bart_transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[110, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[111, "module-sparknlp.annotator.seq2seq"]], "sparknlp.annotator.seq2seq.marian_transformer": [[112, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "sparknlp.annotator.seq2seq.t5_transformer": [[113, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "sparknlp.annotator.spell_check.context_spell_checker": [[114, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "sparknlp.annotator.spell_check": [[115, "module-sparknlp.annotator.spell_check"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[116, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "sparknlp.annotator.spell_check.symmetric_delete": [[117, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "sparknlp.annotator.stemmer": [[118, "module-sparknlp.annotator.stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[119, "module-sparknlp.annotator.stop_words_cleaner"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[120, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "sparknlp.annotator.token.chunk_tokenizer": [[121, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[122, "module-sparknlp.annotator.token"]], "sparknlp.annotator.token.recursive_tokenizer": [[123, "module-sparknlp.annotator.token.recursive_tokenizer"]], "sparknlp.annotator.token.regex_tokenizer": [[124, "module-sparknlp.annotator.token.regex_tokenizer"]], "sparknlp.annotator.token.tokenizer": [[125, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[126, "module-sparknlp.annotator.ws"]], "sparknlp.annotator.ws.word_segmenter": [[127, "module-sparknlp.annotator.ws.word_segmenter"]], "sparknlp.base.audio_assembler": [[128, "module-sparknlp.base.audio_assembler"]], "sparknlp.base.doc2_chunk": [[129, "module-sparknlp.base.doc2_chunk"]], "sparknlp.base.document_assembler": [[130, "module-sparknlp.base.document_assembler"]], "sparknlp.base.embeddings_finisher": [[131, "module-sparknlp.base.embeddings_finisher"]], "sparknlp.base.finisher": [[132, "module-sparknlp.base.finisher"]], "sparknlp.base.graph_finisher": [[133, "module-sparknlp.base.graph_finisher"]], "sparknlp.base.has_recursive_fit": [[134, "module-sparknlp.base.has_recursive_fit"]], "sparknlp.base.has_recursive_transform": [[135, "module-sparknlp.base.has_recursive_transform"]], "sparknlp.base.image_assembler": [[136, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[137, "module-sparknlp.base"]], "sparknlp.base.light_pipeline": [[138, "module-sparknlp.base.light_pipeline"]], "sparknlp.base.multi_document_assembler": [[139, "module-sparknlp.base.multi_document_assembler"]], "sparknlp.base.recursive_pipeline": [[140, "module-sparknlp.base.recursive_pipeline"]], "sparknlp.base.table_assembler": [[141, "module-sparknlp.base.table_assembler"]], "sparknlp.base.token2_chunk": [[142, "module-sparknlp.base.token2_chunk"]], "sparknlp.base.token_assembler": [[143, "module-sparknlp.base.token_assembler"]], "sparknlp.common.annotator_approach": [[144, "module-sparknlp.common.annotator_approach"]], "sparknlp.common.annotator_model": [[145, "module-sparknlp.common.annotator_model"]], "sparknlp.common.annotator_properties": [[146, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[147, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[148, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[149, "module-sparknlp.common"]], "sparknlp.common.properties": [[150, "module-sparknlp.common.properties"]], "sparknlp.common.read_as": [[151, "module-sparknlp.common.read_as"]], "sparknlp.common.recursive_annotator_approach": [[152, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[153, "module-sparknlp.common.storage"]], "sparknlp.common.utils": [[154, "module-sparknlp.common.utils"]], "Functions": [[154, "functions"], [155, "functions"], [156, "functions"]], "sparknlp.functions": [[155, "module-sparknlp.functions"]], "sparknlp": [[156, "module-sparknlp"]], "Package Contents": [[156, "package-contents"]], "sparknlp.internal.annotator_java_ml": [[157, "module-sparknlp.internal.annotator_java_ml"]], "sparknlp.internal.annotator_transformer": [[158, "module-sparknlp.internal.annotator_transformer"]], "sparknlp.internal.extended_java_wrapper": [[159, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[160, "module-sparknlp.internal"]], "sparknlp.internal.params_getters_setters": [[161, "module-sparknlp.internal.params_getters_setters"]], "sparknlp.internal.recursive": [[162, "module-sparknlp.internal.recursive"]], "sparknlp.logging.comet": [[163, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[164, "module-sparknlp.logging"]], "sparknlp.pretrained": [[165, "module-sparknlp.pretrained"]], "sparknlp.pretrained.pretrained_pipeline": [[166, "module-sparknlp.pretrained.pretrained_pipeline"]], "sparknlp.pretrained.resource_downloader": [[167, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[168, "module-sparknlp.pretrained.utils"]], "sparknlp.training.conll": [[169, "module-sparknlp.training.conll"]], "sparknlp.training.conllu": [[170, "module-sparknlp.training.conllu"]], "sparknlp.training": [[171, "module-sparknlp.training"]], "sparknlp.training.pos": [[172, "module-sparknlp.training.pos"]], "sparknlp.training.pub_tator": [[173, "module-sparknlp.training.pub_tator"]], "sparknlp.training.spacy_to_annotation": [[174, "module-sparknlp.training.spacy_to_annotation"]], "sparknlp.training.tfgraphs": [[175, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[176, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[177, "module-sparknlp.util"]], "API Reference": [[178, "api-reference"]], "Modules": [[178, "modules"]], "Comet - A meta machine learning platform": [[179, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[179, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[179, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[179, "logging-evaluation-metrics"]], "Logging Visualizations": [[179, "logging-visualizations"]], "Running An Offline Experiment": [[179, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[180, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[181, "third-party-projects"]], "Logging": [[181, "logging"]], "Annotation": [[182, "annotation"]], "Annotators": [[183, "annotators"]], "Annotator Approaches": [[183, "annotator-approaches"]], "Annotator Models": [[183, "annotator-models"]], "Note": [[183, "note"]], "Pretrained Models": [[183, "pretrained-models"]], "Common Functions": [[183, "common-functions"]], "Available Annotators": [[183, "available-annotators"]], "Setting up your own pipeline": [[184, "setting-up-your-own-pipeline"]], "Annotator types": [[184, "annotator-types"]], "Necessary imports": [[184, "necessary-imports"]], "Constructing the Pipeline": [[184, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[184, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[184, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[184, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[184, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[185, "helper-functions"]], "User Guide": [[186, "user-guide"]], "Light Pipelines": [[187, "light-pipelines"]], "Converting PipelineModels": [[187, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[187, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[188, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[188, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[188, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[188, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[188, "available-pipelines"]], "Loading datasets for training": [[189, "loading-datasets-for-training"]], "POS Dataset": [[189, "pos-dataset"]], "CoNLL Dataset": [[189, "conll-dataset"]], "CoNLLU Dataset": [[189, "conllu-dataset"]], "Spell Checkers Dataset": [[189, "spell-checkers-dataset"]], "PubTator Dataset": [[189, "pubtator-dataset"]]}, "indexentries": {"annotation (class in sparknlp.annotation)": [[2, "sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[2, "sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.fromRow"]], "module": [[2, "module-sparknlp.annotation"], [3, "module-sparknlp.annotation_audio"], [4, "module-sparknlp.annotation_image"], [5, "module-sparknlp.annotator.audio.hubert_for_ctc"], [6, "module-sparknlp.annotator.audio"], [7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"], [8, "module-sparknlp.annotator.chunk2_doc"], [9, "module-sparknlp.annotator.chunker"], [10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"], [11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"], [13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"], [14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"], [16, "module-sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification"], [17, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"], [18, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"], [19, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [20, "module-sparknlp.annotator.classifier_dl.classifier_dl"], [21, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [22, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [23, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [26, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [27, "module-sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification"], [28, "module-sparknlp.annotator.classifier_dl"], [29, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [30, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [31, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [32, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"], [33, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [34, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [35, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [36, "module-sparknlp.annotator.classifier_dl.sentiment_dl"], [37, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [39, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [40, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [41, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [42, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [43, "module-sparknlp.annotator.coref"], [44, "module-sparknlp.annotator.coref.spanbert_coref"], [45, "module-sparknlp.annotator.cv.convnext_for_image_classification"], [46, "module-sparknlp.annotator.cv"], [47, "module-sparknlp.annotator.cv.swin_for_image_classification"], [48, "module-sparknlp.annotator.cv.vit_for_image_classification"], [49, "module-sparknlp.annotator.date2_chunk"], [50, "module-sparknlp.annotator.dependency.dependency_parser"], [51, "module-sparknlp.annotator.dependency"], [52, "module-sparknlp.annotator.dependency.typed_dependency_parser"], [53, "module-sparknlp.annotator.document_normalizer"], [54, "module-sparknlp.annotator.embeddings.albert_embeddings"], [55, "module-sparknlp.annotator.embeddings.bert_embeddings"], [56, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"], [57, "module-sparknlp.annotator.embeddings.camembert_embeddings"], [58, "module-sparknlp.annotator.embeddings.chunk_embeddings"], [59, "module-sparknlp.annotator.embeddings.deberta_embeddings"], [60, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"], [61, "module-sparknlp.annotator.embeddings.doc2vec"], [62, "module-sparknlp.annotator.embeddings.elmo_embeddings"], [63, "module-sparknlp.annotator.embeddings"], [64, "module-sparknlp.annotator.embeddings.longformer_embeddings"], [65, "module-sparknlp.annotator.embeddings.roberta_embeddings"], [66, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [67, "module-sparknlp.annotator.embeddings.sentence_embeddings"], [68, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"], [69, "module-sparknlp.annotator.embeddings.word2vec"], [70, "module-sparknlp.annotator.embeddings.word_embeddings"], [71, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [72, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [73, "module-sparknlp.annotator.embeddings.xlnet_embeddings"], [74, "module-sparknlp.annotator.er.entity_ruler"], [75, "module-sparknlp.annotator.er"], [76, "module-sparknlp.annotator.graph_extraction"], [77, "module-sparknlp.annotator"], [78, "module-sparknlp.annotator.keyword_extraction"], [79, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [80, "module-sparknlp.annotator.ld_dl"], [81, "module-sparknlp.annotator.ld_dl.language_detector_dl"], [82, "module-sparknlp.annotator.lemmatizer"], [83, "module-sparknlp.annotator.matcher.big_text_matcher"], [84, "module-sparknlp.annotator.matcher.date_matcher"], [85, "module-sparknlp.annotator.matcher"], [86, "module-sparknlp.annotator.matcher.multi_date_matcher"], [87, "module-sparknlp.annotator.matcher.regex_matcher"], [88, "module-sparknlp.annotator.matcher.text_matcher"], [89, "module-sparknlp.annotator.n_gram_generator"], [90, "module-sparknlp.annotator.ner"], [91, "module-sparknlp.annotator.ner.ner_approach"], [92, "module-sparknlp.annotator.ner.ner_converter"], [93, "module-sparknlp.annotator.ner.ner_crf"], [94, "module-sparknlp.annotator.ner.ner_dl"], [95, "module-sparknlp.annotator.ner.ner_overwriter"], [96, "module-sparknlp.annotator.ner.zero_shot_ner_model"], [97, "module-sparknlp.annotator.normalizer"], [98, "module-sparknlp.annotator.param.classifier_encoder"], [99, "module-sparknlp.annotator.param.evaluation_dl_params"], [100, "module-sparknlp.annotator.param"], [101, "module-sparknlp.annotator.pos"], [102, "module-sparknlp.annotator.pos.perceptron"], [103, "module-sparknlp.annotator.sentence"], [104, "module-sparknlp.annotator.sentence.sentence_detector"], [105, "module-sparknlp.annotator.sentence.sentence_detector_dl"], [106, "module-sparknlp.annotator.sentiment"], [107, "module-sparknlp.annotator.sentiment.sentiment_detector"], [108, "module-sparknlp.annotator.sentiment.vivekn_sentiment"], [109, "module-sparknlp.annotator.seq2seq.bart_transformer"], [110, "module-sparknlp.annotator.seq2seq.gpt2_transformer"], [111, "module-sparknlp.annotator.seq2seq"], [112, "module-sparknlp.annotator.seq2seq.marian_transformer"], [113, "module-sparknlp.annotator.seq2seq.t5_transformer"], [114, "module-sparknlp.annotator.spell_check.context_spell_checker"], [115, "module-sparknlp.annotator.spell_check"], [116, "module-sparknlp.annotator.spell_check.norvig_sweeting"], [117, "module-sparknlp.annotator.spell_check.symmetric_delete"], [118, "module-sparknlp.annotator.stemmer"], [119, "module-sparknlp.annotator.stop_words_cleaner"], [120, "module-sparknlp.annotator.tf_ner_dl_graph_builder"], [121, "module-sparknlp.annotator.token.chunk_tokenizer"], [122, "module-sparknlp.annotator.token"], [123, "module-sparknlp.annotator.token.recursive_tokenizer"], [124, "module-sparknlp.annotator.token.regex_tokenizer"], [125, "module-sparknlp.annotator.token.tokenizer"], [126, "module-sparknlp.annotator.ws"], [127, "module-sparknlp.annotator.ws.word_segmenter"], [128, "module-sparknlp.base.audio_assembler"], [129, "module-sparknlp.base.doc2_chunk"], [130, "module-sparknlp.base.document_assembler"], [131, "module-sparknlp.base.embeddings_finisher"], [132, "module-sparknlp.base.finisher"], [133, "module-sparknlp.base.graph_finisher"], [134, "module-sparknlp.base.has_recursive_fit"], [135, "module-sparknlp.base.has_recursive_transform"], [136, "module-sparknlp.base.image_assembler"], [137, "module-sparknlp.base"], [138, "module-sparknlp.base.light_pipeline"], [139, "module-sparknlp.base.multi_document_assembler"], [140, "module-sparknlp.base.recursive_pipeline"], [141, "module-sparknlp.base.table_assembler"], [142, "module-sparknlp.base.token2_chunk"], [143, "module-sparknlp.base.token_assembler"], [144, "module-sparknlp.common.annotator_approach"], [145, "module-sparknlp.common.annotator_model"], [146, "module-sparknlp.common.annotator_properties"], [147, "module-sparknlp.common.annotator_type"], [148, "module-sparknlp.common.coverage_result"], [149, "module-sparknlp.common"], [150, "module-sparknlp.common.properties"], [151, "module-sparknlp.common.read_as"], [152, "module-sparknlp.common.recursive_annotator_approach"], [153, "module-sparknlp.common.storage"], [154, "module-sparknlp.common.utils"], [155, "module-sparknlp.functions"], [156, "module-sparknlp"], [157, "module-sparknlp.internal.annotator_java_ml"], [158, "module-sparknlp.internal.annotator_transformer"], [159, "module-sparknlp.internal.extended_java_wrapper"], [160, "module-sparknlp.internal"], [161, "module-sparknlp.internal.params_getters_setters"], [162, "module-sparknlp.internal.recursive"], [163, "module-sparknlp.logging.comet"], [164, "module-sparknlp.logging"], [165, "module-sparknlp.pretrained"], [166, "module-sparknlp.pretrained.pretrained_pipeline"], [167, "module-sparknlp.pretrained.resource_downloader"], [168, "module-sparknlp.pretrained.utils"], [169, "module-sparknlp.training.conll"], [170, "module-sparknlp.training.conllu"], [171, "module-sparknlp.training"], [172, "module-sparknlp.training.pos"], [173, "module-sparknlp.training.pub_tator"], [174, "module-sparknlp.training.spacy_to_annotation"], [175, "module-sparknlp.training.tfgraphs"], [176, "module-sparknlp.upload_to_hub"], [177, "module-sparknlp.util"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "torow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in sparknlp.annotation_audio)": [[3, "sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[3, "sparknlp.annotation_audio.AnnotationAudio.copy"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "annotationimage (class in sparknlp.annotation_image)": [[4, "sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[4, "sparknlp.annotation_image.AnnotationImage.copy"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "hubertforctc (class in sparknlp.annotator.audio.hubert_for_ctc)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC"]], "loadsavedmodel() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.loadSavedModel"]], "pretrained() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.pretrained"]], "setconfigprotobytes() (hubertforctc method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "wav2vec2forctc (class in sparknlp.annotator.audio.wav2vec2_for_ctc)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "setconfigprotobytes() (wav2vec2forctc method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "chunk2doc (class in sparknlp.annotator.chunk2_doc)": [[8, "sparknlp.annotator.chunk2_doc.Chunk2Doc"]], "sparknlp.annotator.chunk2_doc": [[8, "module-sparknlp.annotator.chunk2_doc"]], "chunker (class in sparknlp.annotator.chunker)": [[9, "sparknlp.annotator.chunker.Chunker"]], "setregexparsers() (chunker method)": [[9, "sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "sparknlp.annotator.chunker": [[9, "module-sparknlp.annotator.chunker"]], "albertforquestionanswering (class in sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (albertforquestionanswering method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "albertforsequenceclassification (class in sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "setcoalescesentences() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "albertfortokenclassification (class in sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "setconfigprotobytes() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "bertforquestionanswering (class in sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (bertforquestionanswering method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "bertforsequenceclassification (class in sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "setcoalescesentences() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "bertfortokenclassification (class in sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "setconfigprotobytes() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "bertforzeroshotclassification (class in sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification"]], "getclasses() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.getClasses"]], "loadsavedmodel() (bertforzeroshotclassification static method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.loadSavedModel"]], "pretrained() (bertforzeroshotclassification static method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.pretrained"]], "setcoalescesentences() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification": [[16, "module-sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification"]], "camembertforquestionanswering (class in sparknlp.annotator.classifier_dl.camembert_for_question_answering)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering"]], "loadsavedmodel() (camembertforquestionanswering static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.loadSavedModel"]], "pretrained() (camembertforquestionanswering static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (camembertforquestionanswering method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforquestionanswering method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "camembertforsequenceclassification (class in sparknlp.annotator.classifier_dl.camembert_for_sequence_classification)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification"]], "getclasses() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.getClasses"]], "loadsavedmodel() (camembertforsequenceclassification static method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.loadSavedModel"]], "pretrained() (camembertforsequenceclassification static method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.pretrained"]], "setcoalescesentences() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[18, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "camembertfortokenclassification (class in sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[19, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "classifierdlapproach (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "setconfigprotobytes() (classifierdlmodel method)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[20, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "debertaforquestionanswering (class in sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "debertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[22, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "debertafortokenclassification (class in sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (debertafortokenclassification method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[23, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "distilbertforquestionanswering (class in sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "distilbertforsequenceclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "distilbertfortokenclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[26, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "distilbertforzeroshotclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification"]], "getclasses() (distilbertforzeroshotclassification method)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification.getClasses"]], "loadsavedmodel() (distilbertforzeroshotclassification static method)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification.loadSavedModel"]], "pretrained() (distilbertforzeroshotclassification static method)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification.pretrained"]], "setcoalescesentences() (distilbertforzeroshotclassification method)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforzeroshotclassification method)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforzeroshotclassification method)": [[27, "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification": [[27, "module-sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification"]], "sparknlp.annotator.classifier_dl": [[28, "module-sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[29, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "longformerforsequenceclassification (class in sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[30, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "longformerfortokenclassification (class in sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[31, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[31, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[31, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[31, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[31, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[31, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[31, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "multiclassifierdlapproach (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[32, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[32, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "robertaforquestionanswering (class in sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[33, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "robertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[34, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "robertafortokenclassification (class in sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[35, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[35, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[35, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[35, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (robertafortokenclassification method)": [[35, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[35, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[35, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sentimentdlapproach (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "setconfigprotobytes() (sentimentdlmodel method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[36, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[36, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "tapasforquestionanswering (class in sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[37, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[37, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[37, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[37, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "xlmrobertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "xlmrobertafortokenclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[40, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[40, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[40, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[40, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "xlnetforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[41, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "xlnetfortokenclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[42, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[42, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[42, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[42, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[42, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[42, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[42, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[43, "module-sparknlp.annotator.coref"]], "spanbertcorefmodel (class in sparknlp.annotator.coref.spanbert_coref)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[44, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "sparknlp.annotator.coref.spanbert_coref": [[44, "module-sparknlp.annotator.coref.spanbert_coref"]], "convnextforimageclassification (class in sparknlp.annotator.cv.convnext_for_image_classification)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification"]], "getclasses() (convnextforimageclassification method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.getClasses"]], "loadsavedmodel() (convnextforimageclassification static method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.loadSavedModel"]], "pretrained() (convnextforimageclassification static method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.pretrained"]], "setconfigprotobytes() (convnextforimageclassification method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setConfigProtoBytes"]], "setcroppct() (convnextforimageclassification method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setCropPct"]], "setdorescale() (convnextforimageclassification method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setDoRescale"]], "setrescalefactor() (convnextforimageclassification method)": [[45, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.convnext_for_image_classification": [[45, "module-sparknlp.annotator.cv.convnext_for_image_classification"]], "sparknlp.annotator.cv": [[46, "module-sparknlp.annotator.cv"]], "swinforimageclassification (class in sparknlp.annotator.cv.swin_for_image_classification)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification"]], "getclasses() (swinforimageclassification method)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.getClasses"]], "loadsavedmodel() (swinforimageclassification static method)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.loadSavedModel"]], "pretrained() (swinforimageclassification static method)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.pretrained"]], "setconfigprotobytes() (swinforimageclassification method)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setConfigProtoBytes"]], "setdorescale() (swinforimageclassification method)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setDoRescale"]], "setrescalefactor() (swinforimageclassification method)": [[47, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[47, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "vitforimageclassification (class in sparknlp.annotator.cv.vit_for_image_classification)": [[48, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[48, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[48, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[48, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "setconfigprotobytes() (vitforimageclassification method)": [[48, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "sparknlp.annotator.cv.vit_for_image_classification": [[48, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "date2chunk (class in sparknlp.annotator.date2_chunk)": [[49, "sparknlp.annotator.date2_chunk.Date2Chunk"]], "setentityname() (date2chunk method)": [[49, "sparknlp.annotator.date2_chunk.Date2Chunk.setEntityName"]], "sparknlp.annotator.date2_chunk": [[49, "module-sparknlp.annotator.date2_chunk"]], "dependencyparserapproach (class in sparknlp.annotator.dependency.dependency_parser)": [[50, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in sparknlp.annotator.dependency.dependency_parser)": [[50, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[50, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "setconllu() (dependencyparserapproach method)": [[50, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[50, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[50, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser": [[50, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[51, "module-sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[52, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[52, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[52, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "setconll2009() (typeddependencyparserapproach method)": [[52, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[52, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[52, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[52, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "documentnormalizer (class in sparknlp.annotator.document_normalizer)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "setaction() (documentnormalizer method)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[53, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "sparknlp.annotator.document_normalizer": [[53, "module-sparknlp.annotator.document_normalizer"]], "albertembeddings (class in sparknlp.annotator.embeddings.albert_embeddings)": [[54, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[54, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[54, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "setconfigprotobytes() (albertembeddings method)": [[54, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[54, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.albert_embeddings": [[54, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "bertembeddings (class in sparknlp.annotator.embeddings.bert_embeddings)": [[55, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[55, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[55, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "setconfigprotobytes() (bertembeddings method)": [[55, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[55, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[55, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "bertsentenceembeddings (class in sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[56, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[56, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[56, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[56, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[56, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[56, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[56, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "camembertembeddings (class in sparknlp.annotator.embeddings.camembert_embeddings)": [[57, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[57, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[57, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "setconfigprotobytes() (camembertembeddings method)": [[57, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[57, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[57, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "chunkembeddings (class in sparknlp.annotator.embeddings.chunk_embeddings)": [[58, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[58, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[58, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[58, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "debertaembeddings (class in sparknlp.annotator.embeddings.deberta_embeddings)": [[59, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[59, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[59, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "setconfigprotobytes() (debertaembeddings method)": [[59, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[59, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[59, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "distilbertembeddings (class in sparknlp.annotator.embeddings.distil_bert_embeddings)": [[60, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[60, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[60, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "setconfigprotobytes() (distilbertembeddings method)": [[60, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[60, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[60, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "doc2vecapproach (class in sparknlp.annotator.embeddings.doc2vec)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in sparknlp.annotator.embeddings.doc2vec)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "setmaxiter() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[61, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec": [[61, "module-sparknlp.annotator.embeddings.doc2vec"]], "elmoembeddings (class in sparknlp.annotator.embeddings.elmo_embeddings)": [[62, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[62, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[62, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "setbatchsize() (elmoembeddings method)": [[62, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[62, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[62, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[62, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[63, "module-sparknlp.annotator.embeddings"]], "longformerembeddings (class in sparknlp.annotator.embeddings.longformer_embeddings)": [[64, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[64, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[64, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "setconfigprotobytes() (longformerembeddings method)": [[64, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[64, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[64, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "robertaembeddings (class in sparknlp.annotator.embeddings.roberta_embeddings)": [[65, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[65, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[65, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (robertaembeddings method)": [[65, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[65, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[65, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "robertasentenceembeddings (class in sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[66, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[66, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[66, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[66, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[66, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[66, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sentenceembeddings (class in sparknlp.annotator.embeddings.sentence_embeddings)": [[67, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[67, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[67, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "universalsentenceencoder (class in sparknlp.annotator.embeddings.universal_sentence_encoder)": [[68, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[68, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[68, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "setconfigprotobytes() (universalsentenceencoder method)": [[68, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[68, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[68, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "word2vecapproach (class in sparknlp.annotator.embeddings.word2vec)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in sparknlp.annotator.embeddings.word2vec)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "setmaxiter() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[69, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.word2vec": [[69, "module-sparknlp.annotator.embeddings.word2vec"]], "wordembeddings (class in sparknlp.annotator.embeddings.word_embeddings)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in sparknlp.annotator.embeddings.word_embeddings)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "setreadcachesize() (wordembeddings method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[70, "module-sparknlp.annotator.embeddings.word_embeddings"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[70, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[71, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "xlmrobertasentenceembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[72, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[72, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[72, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[72, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[72, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[72, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "xlnetembeddings (class in sparknlp.annotator.embeddings.xlnet_embeddings)": [[73, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[73, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[73, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "setconfigprotobytes() (xlnetembeddings method)": [[73, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[73, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[73, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "entityrulerapproach (class in sparknlp.annotator.er.entity_ruler)": [[74, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in sparknlp.annotator.er.entity_ruler)": [[74, "sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "setalphabetresource() (entityrulerapproach method)": [[74, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setpatternsresource() (entityrulerapproach method)": [[74, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[74, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[74, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "sparknlp.annotator.er.entity_ruler": [[74, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[75, "module-sparknlp.annotator.er"]], "graphextraction (class in sparknlp.annotator.graph_extraction)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction"]], "setdelimiter() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[76, "sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "sparknlp.annotator.graph_extraction": [[76, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[77, "module-sparknlp.annotator"]], "sparknlp.annotator.keyword_extraction": [[78, "module-sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "setmaxngrams() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[79, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[79, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[80, "module-sparknlp.annotator.ld_dl"]], "languagedetectordl (class in sparknlp.annotator.ld_dl.language_detector_dl)": [[81, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[81, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "setcoalescesentences() (languagedetectordl method)": [[81, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[81, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[81, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[81, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[81, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "lemmatizer (class in sparknlp.annotator.lemmatizer)": [[82, "sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in sparknlp.annotator.lemmatizer)": [[82, "sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[82, "sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "setdictionary() (lemmatizer method)": [[82, "sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[82, "sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[82, "sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "sparknlp.annotator.lemmatizer": [[82, "module-sparknlp.annotator.lemmatizer"]], "bigtextmatcher (class in sparknlp.annotator.matcher.big_text_matcher)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in sparknlp.annotator.matcher.big_text_matcher)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "setcasesensitive() (bigtextmatcher method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[83, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[83, "module-sparknlp.annotator.matcher.big_text_matcher"]], "datematcher (class in sparknlp.annotator.matcher.date_matcher)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in sparknlp.annotator.matcher.date_matcher)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "setanchordateday() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[84, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "sparknlp.annotator.matcher.date_matcher": [[84, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[85, "module-sparknlp.annotator.matcher"]], "multidatematcher (class in sparknlp.annotator.matcher.multi_date_matcher)": [[86, "sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[86, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in sparknlp.annotator.matcher.regex_matcher)": [[87, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in sparknlp.annotator.matcher.regex_matcher)": [[87, "sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "setdelimiter() (regexmatcher method)": [[87, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setDelimiter"]], "setexternalrules() (regexmatcher method)": [[87, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setrules() (regexmatcher method)": [[87, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setRules"]], "setstrategy() (regexmatcher method)": [[87, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "sparknlp.annotator.matcher.regex_matcher": [[87, "module-sparknlp.annotator.matcher.regex_matcher"]], "textmatcher (class in sparknlp.annotator.matcher.text_matcher)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in sparknlp.annotator.matcher.text_matcher)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "setbuildfromtokens() (textmatcher method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[88, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher": [[88, "module-sparknlp.annotator.matcher.text_matcher"]], "ngramgenerator (class in sparknlp.annotator.n_gram_generator)": [[89, "sparknlp.annotator.n_gram_generator.NGramGenerator"]], "setdelimiter() (ngramgenerator method)": [[89, "sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[89, "sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[89, "sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "sparknlp.annotator.n_gram_generator": [[89, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[90, "module-sparknlp.annotator.ner"]], "nerapproach (class in sparknlp.annotator.ner.ner_approach)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "setentities() (nerapproach method)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[91, "sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "sparknlp.annotator.ner.ner_approach": [[91, "module-sparknlp.annotator.ner.ner_approach"]], "nerconverter (class in sparknlp.annotator.ner.ner_converter)": [[92, "sparknlp.annotator.ner.ner_converter.NerConverter"]], "setnerhasnoschema() (nerconverter method)": [[92, "sparknlp.annotator.ner.ner_converter.NerConverter.setNerHasNoSchema"]], "setpreserveposition() (nerconverter method)": [[92, "sparknlp.annotator.ner.ner_converter.NerConverter.setPreservePosition"]], "setwhitelist() (nerconverter method)": [[92, "sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "sparknlp.annotator.ner.ner_converter": [[92, "module-sparknlp.annotator.ner.ner_converter"]], "nercrfapproach (class in sparknlp.annotator.ner.ner_crf)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in sparknlp.annotator.ner.ner_crf)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "setc0() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[93, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "sparknlp.annotator.ner.ner_crf": [[93, "module-sparknlp.annotator.ner.ner_crf"]], "nerdlapproach (class in sparknlp.annotator.ner.ner_dl)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in sparknlp.annotator.ner.ner_dl)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "setbatchsize() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[94, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "sparknlp.annotator.ner.ner_dl": [[94, "module-sparknlp.annotator.ner.ner_dl"]], "neroverwriter (class in sparknlp.annotator.ner.ner_overwriter)": [[95, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "setnerwords() (neroverwriter method)": [[95, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[95, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[95, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "sparknlp.annotator.ner.ner_overwriter": [[95, "module-sparknlp.annotator.ner.ner_overwriter"]], "zeroshotnermodel (class in sparknlp.annotator.ner.zero_shot_ner_model)": [[96, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel"]], "getclasses() (zeroshotnermodel method)": [[96, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.getClasses"]], "load() (zeroshotnermodel static method)": [[96, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.load"]], "pretrained() (zeroshotnermodel static method)": [[96, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.pretrained"]], "setentitydefinitions() (zeroshotnermodel method)": [[96, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setEntityDefinitions"]], "setpredictionthreshold() (zeroshotnermodel method)": [[96, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setPredictionThreshold"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[96, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "normalizer (class in sparknlp.annotator.normalizer)": [[97, "sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in sparknlp.annotator.normalizer)": [[97, "sparknlp.annotator.normalizer.NormalizerModel"]], "setcleanuppatterns() (normalizer method)": [[97, "sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[97, "sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[97, "sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[97, "sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[97, "sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "sparknlp.annotator.normalizer": [[97, "module-sparknlp.annotator.normalizer"]], "classifierencoder (class in sparknlp.annotator.param.classifier_encoder)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "setbatchsize() (classifierencoder method)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[98, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "sparknlp.annotator.param.classifier_encoder": [[98, "module-sparknlp.annotator.param.classifier_encoder"]], "evaluationdlparams (class in sparknlp.annotator.param.evaluation_dl_params)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "setenableoutputlogs() (evaluationdlparams method)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[99, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "sparknlp.annotator.param.evaluation_dl_params": [[99, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[100, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[101, "module-sparknlp.annotator.pos"]], "perceptronapproach (class in sparknlp.annotator.pos.perceptron)": [[102, "sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in sparknlp.annotator.pos.perceptron)": [[102, "sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[102, "sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[102, "sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "setiterations() (perceptronapproach method)": [[102, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[102, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "sparknlp.annotator.pos.perceptron": [[102, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[103, "module-sparknlp.annotator.sentence"]], "sentencedetector (class in sparknlp.annotator.sentence.sentence_detector)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in sparknlp.annotator.sentence.sentence_detector)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "setcustombounds() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[104, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector": [[104, "module-sparknlp.annotator.sentence.sentence_detector"]], "sentencedetectordlapproach (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "setcustombounds() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[105, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[105, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[106, "module-sparknlp.annotator.sentiment"]], "sentimentdetector (class in sparknlp.annotator.sentiment.sentiment_detector)": [[107, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in sparknlp.annotator.sentiment.sentiment_detector)": [[107, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "setdictionary() (sentimentdetector method)": [[107, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "sparknlp.annotator.sentiment.sentiment_detector": [[107, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "viveknsentimentapproach (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[108, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[108, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[108, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "setprunecorpus() (viveknsentimentapproach method)": [[108, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[108, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[108, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "barttransformer (class in sparknlp.annotator.seq2seq.bart_transformer)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer"]], "loadsavedmodel() (barttransformer static method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.loadSavedModel"]], "pretrained() (barttransformer static method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained"]], "setbeamsize() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setBeamSize"]], "setconfigprotobytes() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setConfigProtoBytes"]], "setdosample() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setDoSample"]], "setignoretokenids() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setIgnoreTokenIds"]], "setmaxoutputlength() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMaxOutputLength"]], "setminoutputlength() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMinOutputLength"]], "setnorepeatngramsize() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setRepetitionPenalty"]], "settask() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTask"]], "settemperature() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTemperature"]], "settopk() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopK"]], "settopp() (barttransformer method)": [[109, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopP"]], "sparknlp.annotator.seq2seq.bart_transformer": [[109, "module-sparknlp.annotator.seq2seq.bart_transformer"]], "gpt2transformer (class in sparknlp.annotator.seq2seq.gpt2_transformer)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "setconfigprotobytes() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[110, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[110, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[111, "module-sparknlp.annotator.seq2seq"]], "mariantransformer (class in sparknlp.annotator.seq2seq.marian_transformer)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "setconfigprotobytes() (mariantransformer method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[112, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "sparknlp.annotator.seq2seq.marian_transformer": [[112, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "t5transformer (class in sparknlp.annotator.seq2seq.t5_transformer)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "setconfigprotobytes() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[113, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "sparknlp.annotator.seq2seq.t5_transformer": [[113, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "contextspellcheckerapproach (class in sparknlp.annotator.spell_check.context_spell_checker)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in sparknlp.annotator.spell_check.context_spell_checker)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "setbatchsize() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setclasses() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setClasses"]], "setcomparelowcase() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setgraphfolder() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setGraphFolder"]], "setidsvocab() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setIdsVocab"]], "setinitialrate() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxsentlen() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxSentLen"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setvocabfreq() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setVocabFreq"]], "setvocabids() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setVocabIds"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker": [[114, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "updateregexclass() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[114, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "sparknlp.annotator.spell_check": [[115, "module-sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "setcasesensitive() (norvigsweetingapproach method)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[116, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[116, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "symmetricdeleteapproach (class in sparknlp.annotator.spell_check.symmetric_delete)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in sparknlp.annotator.spell_check.symmetric_delete)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[117, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete": [[117, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "stemmer (class in sparknlp.annotator.stemmer)": [[118, "sparknlp.annotator.stemmer.Stemmer"]], "sparknlp.annotator.stemmer": [[118, "module-sparknlp.annotator.stemmer"]], "stopwordscleaner (class in sparknlp.annotator.stop_words_cleaner)": [[119, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[119, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[119, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "setcasesensitive() (stopwordscleaner method)": [[119, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[119, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[119, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "sparknlp.annotator.stop_words_cleaner": [[119, "module-sparknlp.annotator.stop_words_cleaner"]], "tfnerdlgraphbuilder (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[120, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[120, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "chunktokenizer (class in sparknlp.annotator.token.chunk_tokenizer)": [[121, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in sparknlp.annotator.token.chunk_tokenizer)": [[121, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "sparknlp.annotator.token.chunk_tokenizer": [[121, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[122, "module-sparknlp.annotator.token"]], "recursivetokenizer (class in sparknlp.annotator.token.recursive_tokenizer)": [[123, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in sparknlp.annotator.token.recursive_tokenizer)": [[123, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "setinfixes() (recursivetokenizer method)": [[123, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[123, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[123, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[123, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "sparknlp.annotator.token.recursive_tokenizer": [[123, "module-sparknlp.annotator.token.recursive_tokenizer"]], "regextokenizer (class in sparknlp.annotator.token.regex_tokenizer)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "setmaxlength() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[124, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "sparknlp.annotator.token.regex_tokenizer": [[124, "module-sparknlp.annotator.token.regex_tokenizer"]], "tokenizer (class in sparknlp.annotator.token.tokenizer)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in sparknlp.annotator.token.tokenizer)": [[125, "sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[125, "sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[125, "sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "setcasesensitiveexceptions() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[125, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[125, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[125, "sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "sparknlp.annotator.token.tokenizer": [[125, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[126, "module-sparknlp.annotator.ws"]], "wordsegmenterapproach (class in sparknlp.annotator.ws.word_segmenter)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in sparknlp.annotator.ws.word_segmenter)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setenableregextokenizer() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setEnableRegexTokenizer"]], "setenableregextokenizer() (wordsegmentermodel method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setEnableRegexTokenizer"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setpattern() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPattern"]], "setpattern() (wordsegmentermodel method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setPattern"]], "setposcolumn() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "settolowercase() (wordsegmenterapproach method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setToLowercase"]], "settolowercase() (wordsegmentermodel method)": [[127, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setToLowercase"]], "sparknlp.annotator.ws.word_segmenter": [[127, "module-sparknlp.annotator.ws.word_segmenter"]], "audioassembler (class in sparknlp.base.audio_assembler)": [[128, "sparknlp.base.audio_assembler.AudioAssembler"]], "getoutputcol() (audioassembler method)": [[128, "sparknlp.base.audio_assembler.AudioAssembler.getOutputCol"]], "setinputcol() (audioassembler method)": [[128, "sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[128, "sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "sparknlp.base.audio_assembler": [[128, "module-sparknlp.base.audio_assembler"]], "doc2chunk (class in sparknlp.base.doc2_chunk)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk"]], "setchunkcol() (doc2chunk method)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[129, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "sparknlp.base.doc2_chunk": [[129, "module-sparknlp.base.doc2_chunk"]], "documentassembler (class in sparknlp.base.document_assembler)": [[130, "sparknlp.base.document_assembler.DocumentAssembler"]], "getoutputcol() (documentassembler method)": [[130, "sparknlp.base.document_assembler.DocumentAssembler.getOutputCol"]], "setcleanupmode() (documentassembler method)": [[130, "sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[130, "sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[130, "sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[130, "sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[130, "sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "sparknlp.base.document_assembler": [[130, "module-sparknlp.base.document_assembler"]], "embeddingsfinisher (class in sparknlp.base.embeddings_finisher)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "getinputcols() (embeddingsfinisher method)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getInputCols"]], "getoutputcols() (embeddingsfinisher method)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getOutputCols"]], "setcleanannotations() (embeddingsfinisher method)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[131, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "sparknlp.base.embeddings_finisher": [[131, "module-sparknlp.base.embeddings_finisher"]], "finisher (class in sparknlp.base.finisher)": [[132, "sparknlp.base.finisher.Finisher"]], "getinputcols() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.getInputCols"]], "getoutputcols() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.getOutputCols"]], "setannotationsplitsymbol() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[132, "sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "sparknlp.base.finisher": [[132, "module-sparknlp.base.finisher"]], "graphfinisher (class in sparknlp.base.graph_finisher)": [[133, "sparknlp.base.graph_finisher.GraphFinisher"]], "setcleanannotations() (graphfinisher method)": [[133, "sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[133, "sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[133, "sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[133, "sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "sparknlp.base.graph_finisher": [[133, "module-sparknlp.base.graph_finisher"]], "hasrecursivefit (class in sparknlp.base.has_recursive_fit)": [[134, "sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "sparknlp.base.has_recursive_fit": [[134, "module-sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in sparknlp.base.has_recursive_transform)": [[135, "sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "sparknlp.base.has_recursive_transform": [[135, "module-sparknlp.base.has_recursive_transform"]], "imageassembler (class in sparknlp.base.image_assembler)": [[136, "sparknlp.base.image_assembler.ImageAssembler"]], "getoutputcol() (imageassembler method)": [[136, "sparknlp.base.image_assembler.ImageAssembler.getOutputCol"]], "setinputcol() (imageassembler method)": [[136, "sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[136, "sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "sparknlp.base.image_assembler": [[136, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[137, "module-sparknlp.base"]], "lightpipeline (class in sparknlp.base.light_pipeline)": [[138, "sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[138, "sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[138, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[138, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[138, "sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "setignoreunsupported() (lightpipeline method)": [[138, "sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "sparknlp.base.light_pipeline": [[138, "module-sparknlp.base.light_pipeline"]], "transform() (lightpipeline method)": [[138, "sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in sparknlp.base.multi_document_assembler)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "getoutputcols() (multidocumentassembler method)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.getOutputCols"]], "setcleanupmode() (multidocumentassembler method)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[139, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "sparknlp.base.multi_document_assembler": [[139, "module-sparknlp.base.multi_document_assembler"]], "recursivepipeline (class in sparknlp.base.recursive_pipeline)": [[140, "sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in sparknlp.base.recursive_pipeline)": [[140, "sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "sparknlp.base.recursive_pipeline": [[140, "module-sparknlp.base.recursive_pipeline"]], "tableassembler (class in sparknlp.base.table_assembler)": [[141, "sparknlp.base.table_assembler.TableAssembler"]], "setcsvdelimiter() (tableassembler method)": [[141, "sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[141, "sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[141, "sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "sparknlp.base.table_assembler": [[141, "module-sparknlp.base.table_assembler"]], "token2chunk (class in sparknlp.base.token2_chunk)": [[142, "sparknlp.base.token2_chunk.Token2Chunk"]], "sparknlp.base.token2_chunk": [[142, "module-sparknlp.base.token2_chunk"]], "tokenassembler (class in sparknlp.base.token_assembler)": [[143, "sparknlp.base.token_assembler.TokenAssembler"]], "setpreserveposition() (tokenassembler method)": [[143, "sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "sparknlp.base.token_assembler": [[143, "module-sparknlp.base.token_assembler"]], "annotatorapproach (class in sparknlp.common.annotator_approach)": [[144, "sparknlp.common.annotator_approach.AnnotatorApproach"]], "sparknlp.common.annotator_approach": [[144, "module-sparknlp.common.annotator_approach"]], "annotatormodel (class in sparknlp.common.annotator_model)": [[145, "sparknlp.common.annotator_model.AnnotatorModel"]], "sparknlp.common.annotator_model": [[145, "module-sparknlp.common.annotator_model"]], "annotatorproperties (class in sparknlp.common.annotator_properties)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "setinputcols() (annotatorproperties method)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[146, "sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "sparknlp.common.annotator_properties": [[146, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[147, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[148, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[149, "module-sparknlp.common"]], "hasembeddingsproperties (class in sparknlp.common.properties)": [[150, "sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[150, "sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "setdimension() (hasembeddingsproperties method)": [[150, "sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "sparknlp.common.properties": [[150, "module-sparknlp.common.properties"]], "readas (class in sparknlp.common.read_as)": [[151, "sparknlp.common.read_as.ReadAs"]], "sparknlp.common.read_as": [[151, "module-sparknlp.common.read_as"]], "recursiveannotatorapproach (class in sparknlp.common.recursive_annotator_approach)": [[152, "sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "sparknlp.common.recursive_annotator_approach": [[152, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[153, "module-sparknlp.common.storage"]], "externalresource() (in module sparknlp.common.utils)": [[154, "sparknlp.common.utils.ExternalResource"]], "sparknlp.common.utils": [[154, "module-sparknlp.common.utils"]], "explode_annotations_col() (in module sparknlp.functions)": [[155, "sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module sparknlp.functions)": [[155, "sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module sparknlp.functions)": [[155, "sparknlp.functions.map_annotations"]], "map_annotations_array() (in module sparknlp.functions)": [[155, "sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module sparknlp.functions)": [[155, "sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module sparknlp.functions)": [[155, "sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module sparknlp.functions)": [[155, "sparknlp.functions.map_annotations_strict"]], "sparknlp.functions": [[155, "module-sparknlp.functions"]], "sparknlp": [[156, "module-sparknlp"]], "start() (in module sparknlp)": [[156, "sparknlp.start"]], "version() (in module sparknlp)": [[156, "sparknlp.version"]], "annotatorjavamlreadable (class in sparknlp.internal.annotator_java_ml)": [[157, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in sparknlp.internal.annotator_java_ml)": [[157, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "read() (annotatorjavamlreadable class method)": [[157, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "sparknlp.internal.annotator_java_ml": [[157, "module-sparknlp.internal.annotator_java_ml"]], "annotatortransformer (class in sparknlp.internal.annotator_transformer)": [[158, "sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "sparknlp.internal.annotator_transformer": [[158, "module-sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in sparknlp.internal.extended_java_wrapper)": [[159, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[159, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "sparknlp.internal.extended_java_wrapper": [[159, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[160, "module-sparknlp.internal"]], "paramsgetterssetters (class in sparknlp.internal.params_getters_setters)": [[161, "sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[161, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "setparamvalue() (paramsgetterssetters method)": [[161, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "sparknlp.internal.params_getters_setters": [[161, "module-sparknlp.internal.params_getters_setters"]], "recursiveestimator (class in sparknlp.internal.recursive)": [[162, "sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in sparknlp.internal.recursive)": [[162, "sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[162, "sparknlp.internal.recursive.RecursiveEstimator.fit"]], "sparknlp.internal.recursive": [[162, "module-sparknlp.internal.recursive"]], "cometlogger (class in sparknlp.logging.comet)": [[163, "sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[163, "sparknlp.logging.comet.CometLogger.monitor"]], "sparknlp.logging.comet": [[163, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[164, "module-sparknlp.logging"]], "sparknlp.pretrained": [[165, "module-sparknlp.pretrained"]], "pretrainedpipeline (class in sparknlp.pretrained.pretrained_pipeline)": [[166, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[166, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[166, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "fullannotateimage() (pretrainedpipeline method)": [[166, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotateImage"]], "sparknlp.pretrained.pretrained_pipeline": [[166, "module-sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[166, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "resourcedownloader (class in sparknlp.pretrained.resource_downloader)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader"]], "clearcache() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.clearCache"]], "downloadmodel() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModel"]], "downloadmodeldirectly() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModelDirectly"]], "downloadpipeline() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadPipeline"]], "showavailableannotators() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showAvailableAnnotators"]], "showpublicmodels() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicModels"]], "showpublicpipelines() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicPipelines"]], "showuncategorizedresources() (resourcedownloader static method)": [[167, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showUnCategorizedResources"]], "sparknlp.pretrained.resource_downloader": [[167, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[168, "module-sparknlp.pretrained.utils"]], "conll (class in sparknlp.training.conll)": [[169, "sparknlp.training.conll.CoNLL"]], "readdataset() (conll method)": [[169, "sparknlp.training.conll.CoNLL.readDataset"]], "sparknlp.training.conll": [[169, "module-sparknlp.training.conll"]], "conllu (class in sparknlp.training.conllu)": [[170, "sparknlp.training.conllu.CoNLLU"]], "readdataset() (conllu method)": [[170, "sparknlp.training.conllu.CoNLLU.readDataset"]], "sparknlp.training.conllu": [[170, "module-sparknlp.training.conllu"]], "sparknlp.training": [[171, "module-sparknlp.training"]], "pos (class in sparknlp.training.pos)": [[172, "sparknlp.training.pos.POS"]], "readdataset() (pos method)": [[172, "sparknlp.training.pos.POS.readDataset"]], "sparknlp.training.pos": [[172, "module-sparknlp.training.pos"]], "pubtator (class in sparknlp.training.pub_tator)": [[173, "sparknlp.training.pub_tator.PubTator"]], "readdataset() (pubtator method)": [[173, "sparknlp.training.pub_tator.PubTator.readDataset"]], "sparknlp.training.pub_tator": [[173, "module-sparknlp.training.pub_tator"]], "spacytoannotation (class in sparknlp.training.spacy_to_annotation)": [[174, "sparknlp.training.spacy_to_annotation.SpacyToAnnotation"]], "sparknlp.training.spacy_to_annotation": [[174, "module-sparknlp.training.spacy_to_annotation"]], "sparknlp.training.tfgraphs": [[175, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[176, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[177, "module-sparknlp.util"]]}})