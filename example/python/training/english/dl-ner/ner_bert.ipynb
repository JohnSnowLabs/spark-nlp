{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MI3at4LA4TO4"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_bert.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14853,
     "status": "ok",
     "timestamp": 1589704571189,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "CQkc9O5V6vJ5",
    "outputId": "b3698e71-5966-42e8-82bd-c433dfaa666f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnbkiY634TO7"
   },
   "source": [
    "## Deep Learning NER\n",
    "\n",
    "In the following example, we walk-through a LSTM NER model training and prediction. This annotator is implemented on top of TensorFlow.\n",
    "\n",
    "This annotator will take a series of word embedding vectors, training CoNLL dataset, plus a validation dataset. We include our own predefined Tensorflow Graphs, but it will train all layers during fit() stage.\n",
    "\n",
    "DL NER will compute several layers of BI-LSTM in order to auto generate entity extraction, and it will leverage batch-based distributed calls to native TensorFlow libraries during prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5NoZwVw4TO8"
   },
   "source": [
    "#### 1. Call necessary imports and set the resource folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVMuFdHz4TO-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "import time\n",
    "import zipfile\n",
    "#Setting location of resource Directory\n",
    "resource_path= \"../../../src/test/resources/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dnkqe7Db4TPG"
   },
   "source": [
    "#### 2. Download CoNLL 2003 data if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtNyZXDc4TPH"
   },
   "outputs": [],
   "source": [
    "# Download CoNLL 2003 Dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/\"\n",
    "file_train=\"eng.train\"\n",
    "file_testa= \"eng.testa\"\n",
    "file_testb= \"eng.testb\"\n",
    "# https://github.com/patverga/torch-ner-nlp-from-scratch/tree/master/data/conll2003\n",
    "if not Path(file_train).is_file():   \n",
    "    print(\"Downloading \"+file_train)\n",
    "    urllib.request.urlretrieve(url+file_train, file_train)\n",
    "if not Path(file_testa).is_file():\n",
    "    print(\"Downloading \"+file_testa)\n",
    "    urllib.request.urlretrieve(url+file_testa, file_testa)\n",
    "\n",
    "if not Path(file_testb).is_file():\n",
    "    print(\"Downloading \"+file_testb)\n",
    "    urllib.request.urlretrieve(url+file_testb, file_testb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vmA0JH44TPP"
   },
   "source": [
    "#### 3. Create the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22643,
     "status": "ok",
     "timestamp": 1589704579011,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "O3wvVq-14TPQ",
    "outputId": "a3282669-5d17-41e7-dd4b-edf0ad9c27b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.5.0\n",
      "Apache Spark version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxv7jokO4TPY"
   },
   "source": [
    "#### 4. Load dataset and cache into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39584,
     "status": "ok",
     "timestamp": 1589704595967,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "xeuwKgWB4TPZ",
    "outputId": "816df8b8-f98c-4d1d-d4f6-33946e405bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
      "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
      "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
      "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
      "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
      "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
      "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
      "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BO6oz8i4TPh"
   },
   "source": [
    "#### 5. Create annotator components with appropriate params and in the right order. The finisher will output only NER. Put everything in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56765,
     "status": "ok",
     "timestamp": 1589704613167,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "nxArxJq_4TPj",
    "outputId": "2e716ef5-c8c9-48cb-9e02-47b959fe7a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "bert = BertEmbeddings.pretrained() \\\n",
    " .setInputCols([\"sentence\", \"token\"])\\\n",
    " .setOutputCol(\"bert\")\\\n",
    " .setCaseSensitive(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57266,
     "status": "ok",
     "timestamp": 1589704613688,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "NMEx77d3bVpp",
    "outputId": "170fb930-7b88-4c51-fafd-1d892ab02508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
      "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
      "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
      "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
      "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
      "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
      "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
      "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64843,
     "status": "ok",
     "timestamp": 1589704621280,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "cP9nXTCl4TPq",
    "outputId": "80f3bdff-b46e-445c-adca-2602ce68c27c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n",
      "+--------------------+--------------------+\n",
      "|               token|                bert|\n",
      "+--------------------+--------------------+\n",
      "|[[token, 0, 1, EU...|[[word_embeddings...|\n",
      "|[[token, 0, 4, Pe...|[[word_embeddings...|\n",
      "|[[token, 0, 7, BR...|[[word_embeddings...|\n",
      "|[[token, 0, 2, Th...|[[word_embeddings...|\n",
      "|[[token, 0, 6, Ge...|[[word_embeddings...|\n",
      "|[[token, 0, 0, \",...|[[word_embeddings...|\n",
      "|[[token, 0, 1, He...|[[word_embeddings...|\n",
      "|[[token, 0, 1, He...|[[word_embeddings...|\n",
      "|[[token, 0, 7, Fi...|[[word_embeddings...|\n",
      "|[[token, 0, 2, Bu...|[[word_embeddings...|\n",
      "|[[token, 0, 6, Sp...|[[word_embeddings...|\n",
      "|[[token, 0, 0, .,...|[[word_embeddings...|\n",
      "|[[token, 0, 3, On...|[[word_embeddings...|\n",
      "|[[token, 0, 2, Th...|[[word_embeddings...|\n",
      "|[[token, 0, 4, Sh...|[[word_embeddings...|\n",
      "|[[token, 0, 6, Br...|[[word_embeddings...|\n",
      "|[[token, 0, 0, \",...|[[word_embeddings...|\n",
      "|[[token, 0, 3, Bo...|[[word_embeddings...|\n",
      "|[[token, 0, 6, Ge...|[[word_embeddings...|\n",
      "|[[token, 0, 1, It...|[[word_embeddings...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 11.6 ms, sys: 1.54 ms, total: 13.1 ms\n",
      "Wall time: 7.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# WARNING: Setting benchmark to true is  slow and might crash your system and is not recommended on standardCollab notebooks-- High end hardware and/or GPU required\n",
    "## dataframe.cache() does not solve this. Results must be serialized to disk for maximum efficiency\n",
    "### You might need to restart your driver after this step finishes\n",
    "benchmark = False \n",
    "\n",
    "\n",
    "with_bert_path = \"./with_bert.parquet\"\n",
    "if benchmark == True :\n",
    "  if not Path(with_bert_path).is_dir(): \n",
    "    bert.transform(training_data).write.parquet(\"./with_bert.parquet\")\n",
    "    training_with_bert = spark.read.parquet(\"./with_bert.parquet\").cache()\n",
    "else : training_with_bert = bert.transform(training_data)\n",
    "\n",
    "\n",
    "print(training_with_bert.count())\n",
    "training_with_bert.select(\"token\", \"bert\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewZNMRkX4TPz"
   },
   "outputs": [],
   "source": [
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(1)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(0)\n",
    "\n",
    "converter = NerConverter()\\\n",
    "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
    "  .setOutputCol(\"ner_span\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "    nerTagger,\n",
    "    converter\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jmrxa0zb4TP5"
   },
   "source": [
    "#### 6. Train the pipeline. (This will take some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72071,
     "status": "ok",
     "timestamp": 1589704628541,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "M1EsnzJD4TP6",
    "outputId": "9f39ed1e-f436-4f3a-abf3-96449e68ebb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting\n",
      "Fitting is ended\n",
      "7.180534839630127\n",
      "CPU times: user 21.5 ms, sys: 6.81 ms, total: 28.3 ms\n",
      "Wall time: 7.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "print(\"Start fitting\")\n",
    "#We have to limit the rows in Collab, otherwise we will encounter exceptions because of RAM limitations\n",
    "model = pipeline.fit(training_with_bert.limit(25))  \n",
    "print(\"Fitting is ended\")\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N13yqmUu4TQA"
   },
   "source": [
    "#### 7. Lets predict with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc9NJ1EV4TQB"
   },
   "outputs": [],
   "source": [
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "token = Tokenizer()\\\n",
    "    .setInputCols(['sentence'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "prediction_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        sentence,\n",
    "        token,\n",
    "        bert,\n",
    "        model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73124,
     "status": "ok",
     "timestamp": 1589704629618,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "07EWw0mG4TQR",
    "outputId": "d87f8139-8958-4a9e-ce95-e5dc44a629d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Germany is a nice...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_data = spark.createDataFrame([[\"Germany is a nice place\"]]).toDF(\"text\")\n",
    "prediction_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50yCGM6F4TQZ"
   },
   "outputs": [],
   "source": [
    "prediction_model = prediction_pipeline.fit(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74477,
     "status": "ok",
     "timestamp": 1589704630997,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "iHk2VbE_4TQf",
    "outputId": "f13adccb-1770-4ca6-c789-fd175133b274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('International', 'O')\n",
      "('Business', 'O')\n",
      "('Machines', 'O')\n",
      "('Corporation', 'O')\n",
      "('(', 'O')\n",
      "('IBM', 'O')\n",
      "(')', 'O')\n",
      "('is', 'O')\n",
      "('an', 'O')\n",
      "('American', 'O')\n",
      "('multinational', 'O')\n",
      "('information', 'O')\n",
      "('technology', 'O')\n",
      "('company', 'O')\n",
      "('headquartered', 'O')\n",
      "('in', 'O')\n",
      "('Armonk', 'O')\n",
      "('.', 'O')\n",
      "CPU times: user 56.3 ms, sys: 7.62 ms, total: 63.9 ms\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lp = LightPipeline(prediction_model)\n",
    "result = lp.annotate(\"International Business Machines Corporation (IBM) is an American multinational information technology company headquartered in Armonk.\")\n",
    "for e in list(zip(result['token'], result['ner'])):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75321,
     "status": "ok",
     "timestamp": 1589704631851,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "XwNEGQts4TQl",
    "outputId": "69632669-e907-4555-cda5-c046565bb61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+\n",
      "|                text|            document|            sentence|               token|                bert|                 ner|ner_span|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+\n",
      "|Germany is a nice...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 6, Ge...|[[word_embeddings...|[[named_entity, 0...|      []|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------+\n",
      "\n",
      "CPU times: user 27.2 ms, sys: 6.09 ms, total: 33.3 ms\n",
      "Wall time: 883 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This might take 8 minutes. Timing is not lineal\n",
    "\n",
    "prediction_model.transform(prediction_data).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxYs7v3F4TQq"
   },
   "source": [
    "#### 8. Save both pipeline and single model once trained, on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDk4xWbT4TQr"
   },
   "outputs": [],
   "source": [
    "prediction_model.write().overwrite().save(\"./ner_dl_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzvHfHBr4TQx"
   },
   "source": [
    "#### 9. Load both again, deserialize from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARYxI8594TQz"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "\n",
    "loaded_prediction_model = PipelineModel.read().load(\"./ner_dl_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 254641,
     "status": "ok",
     "timestamp": 1589704811204,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "xfVgn3ZI4TQ4",
    "outputId": "0848f1aa-10e6-4caa-c3e7-d7527d23da94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Peter', 'O')\n",
      "('is', 'O')\n",
      "('a', 'O')\n",
      "('good', 'O')\n",
      "('person', 'O')\n",
      "('.', 'O')\n",
      "CPU times: user 55.9 ms, sys: 12.4 ms, total: 68.3 ms\n",
      "Wall time: 723 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lp = LightPipeline(loaded_prediction_model)\n",
    "result = lp.annotate(\"Peter is a good person.\")\n",
    "for e in list(zip(result['token'], result['ner']))[:10]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 254630,
     "status": "ok",
     "timestamp": 1589704811206,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "UpDPutD_4TQ-",
    "outputId": "f4c423cf-8534-4506-c5ea-9ac1df2f46d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocumentAssembler_7a6bc03a0a25\n",
      "SentenceDetector_8130627c0d5f\n",
      "REGEX_TOKENIZER_cf7c9407b892\n",
      "BERT_EMBEDDINGS_abf30dcdf344\n",
      "PipelineModel_e7f7bc4a5dcc\n",
      "[NerDLModel_ba63241e33e5, NerConverter_422eed39d1e4]\n"
     ]
    }
   ],
   "source": [
    "for stage in loaded_prediction_model.stages:\n",
    "    print(stage)\n",
    "print(loaded_prediction_model.stages[-1].stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aH191rNe4TRC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "ner_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
