{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d86L_FUK4U0O"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_dl.ipynb)\n",
        "\n",
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz7v8B5i6uu5",
        "outputId": "9bfe3e4a-0e8a-458f-e2ec-c8b70386ace5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-23 11:33:31--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-12-23 11:33:31--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-12-23 11:33:32--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-23 11:33:32 (48.9 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
            "\u001b[K     |████████████████████████████████| 281.5 MB 45 kB/s \n",
            "\u001b[K     |████████████████████████████████| 453 kB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 47.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTcQcU74U0Q"
      },
      "source": [
        "## Deep Learning NER\n",
        "\n",
        "In the following example, we walk-through a LSTM NER model training and prediction. This annotator is implemented on top of TensorFlow.\n",
        "\n",
        "This annotator will take a series of word embedding vectors, training CoNLL dataset, plus a validation dataset. We include our own predefined Tensorflow Graphs, but it will train all layers during fit() stage.\n",
        "\n",
        "DL NER will compute several layers of BI-LSTM in order to auto generate entity extraction, and it will leverage batch-based distributed calls to native TensorFlow libraries during prediction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKf4cQ0s4U0R"
      },
      "source": [
        "#### 1. Call necessary imports and set the resource folder path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wejw_DrU4U0S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "import time\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcH7A7yG4U0X"
      },
      "source": [
        "#### 2. Download CoNLL 2003 data if not present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwJXvsuR4U0Y",
        "outputId": "cc558594-73f9-46f3-831d-74ac900ffbe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading eng.train\n"
          ]
        }
      ],
      "source": [
        "# Download CoNLL 2003 Dataset\n",
        "import os\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/\"\n",
        "file_train=\"eng.train\"\n",
        "file_testa= \"eng.testa\"\n",
        "file_testb= \"eng.testb\"\n",
        "# https://github.com/patverga/torch-ner-nlp-from-scratch/tree/master/data/conll2003\n",
        "if not Path(file_train).is_file():   \n",
        "    print(\"Downloading \"+file_train)\n",
        "    urllib.request.urlretrieve(url+file_train, file_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Voa04Sj4U0d"
      },
      "source": [
        "#### 4. Create the spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdIbj0Mo4U0e",
        "outputId": "33ae3dc9-9c82-4f6d-8f16-69ed04fba897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  4.2.6\n",
            "Apache Spark version:  3.2.3\n"
          ]
        }
      ],
      "source": [
        "import sparknlp \n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhRg5VSh4U0j"
      },
      "source": [
        "#### 6. Load parquet dataset and cache into memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaxPfBBJ4U0k",
        "outputId": "ab2560ab-3ea5-477a-af1b-8366594ddc2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|          embeddings|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|[{word_embeddings...|\n",
            "|     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|[{word_embeddings...|\n",
            "| BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|[{word_embeddings...|\n",
            "|The European Comm...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|[{word_embeddings...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "conll = CoNLL(\n",
        "    documentCol=\"document\",\n",
        "    sentenceCol=\"sentence\",\n",
        "    tokenCol=\"token\",\n",
        "    posCol=\"pos\"\n",
        ")\n",
        "\n",
        "training_data = conll.readDataset(spark, './eng.train')\n",
        "\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained()\\\n",
        ".setOutputCol('embeddings')\n",
        "\n",
        "ready_data = embeddings.transform(training_data)\n",
        "\n",
        "ready_data.show(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYnYyImW4U0p"
      },
      "source": [
        "#### 5. Create annotator components with appropriate params and in the right order. The finisher will output only NER. Put everything in Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3638abOy4U0p"
      },
      "outputs": [],
      "source": [
        "nerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(1)\\\n",
        "  .setRandomSeed(0)\\\n",
        "  .setVerbose(0)\\\n",
        "  .setIncludeConfidence(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHrjgNUq4U0t"
      },
      "source": [
        "#### 7. Train the NerDLModel. (This will take some time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gwIpiU74U0u",
        "outputId": "0b16ebc6-59ac-495f-e49e-b34ae9b26df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start fitting\n",
            "Fitting is ended\n",
            "349.63567996025085\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "print(\"Start fitting\")\n",
        "ner_model = nerTagger.fit(ready_data)\n",
        "print(\"Fitting is ended\")\n",
        "print (time.time() - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S86y-YiZ4U0z"
      },
      "source": [
        "#### 8. Lets predict with the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywx7fsIj4U0z",
        "outputId": "5b4c2b58-f080-4162-d92c-63888f54622a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained()\\\n",
        ".setOutputCol('embeddings')\n",
        "\n",
        "prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        embeddings,\n",
        "        ner_model\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZgAI4wF4U04",
        "outputId": "85ca3cec-f3ce-4196-e2b4-d9ae79c3e6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Maria is a nice p...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_data = spark.createDataFrame([[\"Maria is a nice place.\"]]).toDF(\"text\")\n",
        "prediction_data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw_r0Ris4U08",
        "outputId": "6ce29e7b-a108-41de-9adc-8bd4efb18064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|          embeddings|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Maria is a nice p...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 4, Ma...|[{word_embeddings...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction_model = prediction_pipeline.fit(prediction_data)\n",
        "prediction_model.transform(prediction_data).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZRKCjrt4U0_",
        "outputId": "2d7f568b-67f5-4eb1-d27a-e5103b92c5e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('International', 'I-ORG'),\n",
              " ('Business', 'I-ORG'),\n",
              " ('Machines', 'I-ORG'),\n",
              " ('Corporation', 'I-ORG'),\n",
              " ('(', 'O'),\n",
              " ('IBM', 'I-ORG'),\n",
              " (')', 'O'),\n",
              " ('is', 'O'),\n",
              " ('an', 'O'),\n",
              " ('American', 'I-MISC'),\n",
              " ('multinational', 'O'),\n",
              " ('information', 'O'),\n",
              " ('technology', 'O'),\n",
              " ('company', 'O'),\n",
              " ('headquartered', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Armonk', 'I-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# We can be fast!\n",
        "\n",
        "lp = LightPipeline(prediction_model)\n",
        "result = lp.annotate(\"International Business Machines Corporation (IBM) is an American multinational information technology company headquartered in Armonk.\")\n",
        "list(zip(result['token'], result['ner']))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "ner_dl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}