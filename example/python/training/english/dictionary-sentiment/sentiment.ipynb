{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4BBN50oyiwG"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dictionary-sentiment/sentiment.ipynb)\n",
        "\n",
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTH23Yu1yqfD",
        "outputId": "775f3049-be2a-4845-f487-66917347a3bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-23 11:26:26--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-12-23 11:26:26--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-12-23 11:26:26--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-23 11:26:26 (60.4 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
            "\u001b[K     |████████████████████████████████| 281.5 MB 53 kB/s \n",
            "\u001b[K     |████████████████████████████████| 453 kB 65.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 54.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ow6rjyOyiwN"
      },
      "source": [
        "## Rule-based Sentiment Analysis\n",
        "\n",
        "In the following example, we walk-through a simple use case for our straight forward SentimentDetector annotator.\n",
        "\n",
        "This annotator will work on top of a list of labeled sentences which can have any of the following features\n",
        "    \n",
        "    positive\n",
        "    negative\n",
        "    revert\n",
        "    increment\n",
        "    decrement\n",
        "\n",
        "Each of these sentences will be used for giving a score to text "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_1aCdWNyiwQ"
      },
      "source": [
        "#### 1. Call necessary imports and set the resource path to read local data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jIH8pFdPyiwS"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import sys\n",
        "sys.path.append('../../')\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import array_contains\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import RegexRule\n",
        "from sparknlp.base import DocumentAssembler, Finisher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58CQiS99yiwh"
      },
      "source": [
        "#### 2. Load SparkSession if not already there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub7u0Z2yyiwj",
        "outputId": "34b4f4db-defc-4e52-e17e-2ad17af97e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version:  4.2.6\n",
            "Apache Spark version:  3.2.3\n"
          ]
        }
      ],
      "source": [
        "import sparknlp \n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version: \", spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYXJ8Lrhyiwz",
        "outputId": "e2fdbc33-f558-401f-91f9-bb5dd904e40e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/tmp/sentiment.parquet.zip': No such file or directory\n",
            "--2022-12-23 11:28:03--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.198, 52.216.112.141, 52.217.137.208, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76127532 (73M) [application/zip]\n",
            "Saving to: ‘/tmp/sentiment.parquet.zip’\n",
            "\n",
            "sentiment.parquet.z 100%[===================>]  72.60M  57.7MB/s    in 1.3s    \n",
            "\n",
            "2022-12-23 11:28:05 (57.7 MB/s) - ‘/tmp/sentiment.parquet.zip’ saved [76127532/76127532]\n",
            "\n",
            "--2022-12-23 11:28:05--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/lemma-corpus-small/lemmas_small.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.198, 52.216.112.141, 52.217.137.208, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 189437 (185K) [text/plain]\n",
            "Saving to: ‘/tmp/lemmas_small.txt’\n",
            "\n",
            "lemmas_small.txt    100%[===================>] 185.00K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-12-23 11:28:05 (2.08 MB/s) - ‘/tmp/lemmas_small.txt’ saved [189437/189437]\n",
            "\n",
            "--2022-12-23 11:28:05--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/default-sentiment-dict.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.136.198, 52.216.112.141, 52.217.137.208, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.136.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 289 [text/plain]\n",
            "Saving to: ‘/tmp/default-sentiment-dict.txt’\n",
            "\n",
            "default-sentiment-d 100%[===================>]     289  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-12-23 11:28:06 (334 KB/s) - ‘/tmp/default-sentiment-dict.txt’ saved [289/289]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! rm /tmp/sentiment.parquet.zip\n",
        "! rm -rf /tmp/sentiment.parquet\n",
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip -P /tmp\n",
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/lemma-corpus-small/lemmas_small.txt -P /tmp\n",
        "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/default-sentiment-dict.txt -P /tmp    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu_lzjvXyiw6",
        "outputId": "fcf13542-c6b8-4349-ec81-5c44df492ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /tmp/sentiment.parquet.zip\n",
            "   creating: /tmp/sentiment.parquet/\n",
            "  inflating: /tmp/sentiment.parquet/.part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
            "  inflating: /tmp/sentiment.parquet/part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
            "  inflating: /tmp/sentiment.parquet/part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
            "  inflating: /tmp/sentiment.parquet/.part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
            "  inflating: /tmp/sentiment.parquet/part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
            " extracting: /tmp/sentiment.parquet/_SUCCESS  \n",
            "  inflating: /tmp/sentiment.parquet/.part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
            "  inflating: /tmp/sentiment.parquet/part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
            "  inflating: /tmp/sentiment.parquet/.part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n"
          ]
        }
      ],
      "source": [
        "! unzip /tmp/sentiment.parquet.zip -d /tmp/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ycCJ0Vyyiw_",
        "outputId": "f424406a-7eb1-42e4-b0f1-d7701654fe72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+--------------------+\n",
            "|itemid|sentiment|                text|\n",
            "+------+---------+--------------------+\n",
            "|     1|        0|                 ...|\n",
            "|     2|        0|                 ...|\n",
            "|     3|        1|              omg...|\n",
            "|     4|        0|          .. Omga...|\n",
            "|     5|        0|         i think ...|\n",
            "|     6|        0|         or i jus...|\n",
            "|     7|        1|       Juuuuuuuuu...|\n",
            "|     8|        0|       Sunny Agai...|\n",
            "|     9|        1|      handed in m...|\n",
            "|    10|        1|      hmmmm.... i...|\n",
            "|    11|        0|      I must thin...|\n",
            "|    12|        1|      thanks to a...|\n",
            "|    13|        0|      this weeken...|\n",
            "|    14|        0|     jb isnt show...|\n",
            "|    15|        0|     ok thats it ...|\n",
            "|    16|        0|    &lt;-------- ...|\n",
            "|    17|        0|    awhhe man.......|\n",
            "|    18|        1|    Feeling stran...|\n",
            "|    19|        0|    HUGE roll of ...|\n",
            "|    20|        0|    I just cut my...|\n",
            "+------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = spark. \\\n",
        "        read. \\\n",
        "        parquet(\"/tmp/sentiment.parquet\"). \\\n",
        "        limit(10000).cache()\n",
        "\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPH7HLK8yixE"
      },
      "source": [
        "#### 3. Create appropriate annotators. We are using Sentence Detection, Tokenizing the sentences, and find the lemmas of those tokens. The Finisher will only output the Sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rPDSRAXtyixG"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"/tmp/lemmas_small.txt\", key_delimiter=\"->\", value_delimiter=\"\\t\")\n",
        "        \n",
        "sentiment_detector = SentimentDetector() \\\n",
        "    .setInputCols([\"lemma\", \"sentence\"]) \\\n",
        "    .setOutputCol(\"sentiment_score\") \\\n",
        "    .setDictionary(\"/tmp/default-sentiment-dict.txt\", \",\")\n",
        "    \n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"sentiment_score\"]) \\\n",
        "    .setOutputCols([\"sentiment\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tYe_QijyixO"
      },
      "source": [
        "#### 4. Train the pipeline, which is only being trained from external resources, not from the dataset we pass on. The prediction runs on the target dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "o53EAomsyixQ"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, lemmatizer, sentiment_detector, finisher])\n",
        "model = pipeline.fit(data)\n",
        "result = model.transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvlQ7TiyixV"
      },
      "source": [
        "#### 5. filter the finisher output, to find the positive sentiment lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD8jYLEsyixW",
        "outputId": "a84b1597-ac5e-48aa-ff07-fe270c996345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|itemid|sentiment |text                                                                                                                                |\n",
            "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1     |[positive]|                     is so sad for my APL friend.............                                                                       |\n",
            "|2     |[positive]|                   I missed the New Moon trailer...                                                                                 |\n",
            "|3     |[positive]|              omg its already 7:30 :O                                                                                               |\n",
            "|4     |[positive]|          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...|\n",
            "|5     |[positive]|         i think mi bf is cheating on me!!!       T_T                                                                               |\n",
            "|6     |[positive]|         or i just worry too much?                                                                                                  |\n",
            "|7     |[positive]|       Juuuuuuuuuuuuuuuuussssst Chillin!!                                                                                           |\n",
            "|8     |[positive]|       Sunny Again        Work Tomorrow  :-|       TV Tonight                                                                       |\n",
            "|9     |[positive]|      handed in my uniform today . i miss you already                                                                               |\n",
            "|10    |[positive]|      hmmmm.... i wonder how she my number @-)                                                                                      |\n",
            "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.where(array_contains(result.sentiment, \"positive\")).show(10,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j8pjkB7Zyixd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}