/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.johnsnowlabs.nlp.annotators.parser.dl

import com.johnsnowlabs.ml.tensorflow.{TensorMathResources, TensorResources, TensorflowEmbeddingLookup, TensorflowWrapper}
import com.johnsnowlabs.nlp.AnnotatorType.{LABELED_DEPENDENCY, TOKEN}
import com.johnsnowlabs.nlp.serialization.MapFeature
import com.johnsnowlabs.nlp.util.io.ResourceHelper
import com.johnsnowlabs.nlp.{Annotation, AnnotatorModel, AnnotatorType, HasSimpleAnnotate}
import org.apache.spark.ml.util.Identifiable
import org.tensorflow.op.Scope
import org.tensorflow.op.core.{Constant, Zeros}
import org.tensorflow.op.math.Tanh
import org.tensorflow.op.nn.BlockLSTM
import org.tensorflow.types.{TFloat32, TInt64, TString}
import org.tensorflow._

import java.nio.file.{Files, Paths}
import java.util


class DependencyParserDLModel(override val uid: String) extends AnnotatorModel[DependencyParserDLModel]
  with HasSimpleAnnotate[DependencyParserDLModel] {

  def this() = this(Identifiable.randomUID("DEPENDENCY_PARSER_DL"))

  protected val vocabulary: MapFeature[String, Int] = new MapFeature[String, Int](this, "vocabulary to lookup embeddings based on word id")

  def setVocabulary(value: Map[String, Int]): this.type = set(vocabulary, value)

  private lazy val vocabularySize = $$(vocabulary).size + 1

  private lazy val scope = {
    val session = EagerSession.create
    new Scope(session)
  }

  private val firstLstmVariables =  List(("w_first_lstm", "weightMatrix"), ("wig_first_lstm", "weightInputGate"),
    ("wfg_first_lstm", "weightForgetGate"), ("wog_first_lstm", "weightOutputGate"))
  private val nextLstmVariables =  List(("w_next_lstm", "weightMatrix"), ("wig_next_lstm", "weightInputGate"),
    ("wfg_next_lstm", "weightForgetGate"), ("wog_next_lstm", "weightOutputGate"))
  private val headsVariables = List("hidLayerFOH", "hidLayerFOM", "hidBias", "outLayer", "outBias")
  private val relationsVariables = List("rhidLayerFOH", "rhidLayerFOM", "rhidBias", "routLayer", "routBias")

  private lazy val weightsFirstLstm = restoreLstmWeights(firstLstmVariables)
  private lazy val weightsNextLstm = restoreLstmWeights(nextLstmVariables)
  private lazy val weightsHeads = restoreDependencyWeights(headsVariables, "heads")
  private lazy val weightsRelations = restoreDependencyWeights(relationsVariables, "relations")
  private lazy val relationsVocabulary = restoreRelationsVocabulary()

  private val EMBEDDINGS_SIZE = 100
  private val SAMPLE_SIZE = 1
  private var timeSteps: Int = 0

  /**
    * takes a document and annotations and produces new annotations of this annotator's annotation type
    *
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
    */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {
    //TODO: Confirm whether pretrained feature will be added
    val embeddings = new TensorflowEmbeddingLookup(EMBEDDINGS_SIZE, vocabularySize, scope)
    val embeddingsTable = embeddings.initializeTable()

    val tokens = annotations
      .filter(_.annotatorType == AnnotatorType.TOKEN)
      .toArray

    val tokensWithRoot = Array(Annotation(AnnotatorType.TOKEN, -1, -1, "*root*", Map())) ++ tokens

    val sentenceEmbeddings: List[Operand[TFloat32]] = tokensWithRoot.map{ token =>
      val wordId: Int = $$(vocabulary).getOrElse(token.result, 0)
      Constant.create(scope, embeddings.lookup(embeddingsTable, Array(wordId)))
    }.toList

    timeSteps = sentenceEmbeddings.length
    val biLstmInputs = getBiLstmInput(sentenceEmbeddings)
    val biLstmOutputs = computeBiLstmOutput(biLstmInputs)
    val resForward = biLstmOutputs(0)
    val resBackward = biLstmOutputs(1)

    val dependencyFeatures: Array[DependencyFeatures] = (0 until timeSteps).map{ index =>
      val size = Array(1, -1)
      val lstmForward = TensorResources.sliceTensor(scope, resForward, begin = Array(index, 0), size)
      val lstmBackward = TensorResources.sliceTensor(scope, resBackward, begin = Array(timeSteps - index - 1, 0), size)
      val concatLstm = TensorResources.concatTensors(scope, List(lstmForward, lstmBackward), 1)
      val hidLayerFoh: Operand[TFloat32] = Constant.create(scope, weightsHeads("hidLayerFOH"))
      val hidLayerFom: Operand[TFloat32] = Constant.create(scope, weightsHeads("hidLayerFOM"))
      val headFov = TensorResources.matmulTensors(scope, concatLstm, hidLayerFoh)
      val modFov = TensorResources.matmulTensors(scope, concatLstm, hidLayerFom)
      DependencyFeatures(Array(headFov, modFov), concatLstm)
    }.toArray

    val predictedScores: Operand[TFloat32] = computeScores(dependencyFeatures)
    val predictedScoreMatrix = TensorResources.extractTwoDimFloats(scope, predictedScores)
    val predictedHeads = ProjectiveDependencyTree.parse(predictedScoreMatrix)
    val predictedRelations = predictRelations(predictedHeads, dependencyFeatures)
    val predictedDependencies = predictedHeads.tail zip predictedRelations

    predictedDependencies.zipWithIndex.map{ case (predictedDependency, index) =>
      val tokenAnnotation = tokens(index)
      val head = predictedDependency._1
      val headAnnotation = tokensWithRoot(head)
      val headBegin = headAnnotation.begin.toString
      val headEnd = headAnnotation.end.toString
      var dependencyRelation = predictedDependency._2
      if (head == 0 && dependencyRelation != "root") {
        dependencyRelation = "root"
      }
      val begin = if (head != 0) tokenAnnotation.begin else -1
      val end = if (head != 0) tokenAnnotation.end else -1

      Annotation(LABELED_DEPENDENCY, begin, end, dependencyRelation, Map("head" -> head.toString,
        "word" -> tokenAnnotation.result, "head_word" -> headAnnotation.result,
        "head_begin" -> headBegin, "head_end" -> headEnd))
    }

  }

  def getBiLstmInput(sentenceEmbeddings: List[Operand[TFloat32]]): List[Operand[TFloat32]] = {
    val reverseSentenceEmbeddings = sentenceEmbeddings.reverse
    val concatSentenceEmbeddings = TensorResources.concatTensors(scope, sentenceEmbeddings, 0)
    val concatReverseSentenceEmbeddings = TensorResources.concatTensors(scope, reverseSentenceEmbeddings, 0)

    val shape = Array(timeSteps, SAMPLE_SIZE, EMBEDDINGS_SIZE)

    val forwardVector = TensorResources.reshapeTensor(scope, concatSentenceEmbeddings, shape)
    val backwardVector = TensorResources.reshapeTensor(scope, concatReverseSentenceEmbeddings, shape)
    List(forwardVector, backwardVector)
  }

  private def computeBiLstmOutput(biLstmInputs: List[Operand[TFloat32]]): Array[Operand[TFloat32]] = {
    val (blockLSTMForward, lstmDims) = getLstmOutputFromSavedModel(biLstmInputs.head, weightsFirstLstm)
    val (blockLSTMBackward, _) = getLstmOutputFromSavedModel(biLstmInputs(1), weightsFirstLstm)

    val nextLstmInputs = computeNextLstmInput(Array(blockLSTMForward, blockLSTMBackward), lstmDims)

    val (blockNextLSTMForward, _) = getLstmOutputFromSavedModel(nextLstmInputs(0), weightsNextLstm)
    val (blockNextLSTMBackward, _) = getLstmOutputFromSavedModel(nextLstmInputs(1), weightsNextLstm)

    Array(TensorResources.reshapeTensor(scope, blockNextLSTMForward, Array(timeSteps, lstmDims)),
      TensorResources.reshapeTensor(scope, blockNextLSTMBackward, Array(timeSteps, lstmDims)))
  }

  private def computeNextLstmInput(lstmOutputs: Array[Operand[TFloat32]], lstmDims: Int): Array[Operand[TFloat32]] = {
    val blockLSTMForward = lstmOutputs(0)
    val blockLSTMBackward = lstmOutputs(1)
    val resShape = Array(SAMPLE_SIZE, timeSteps, lstmDims)
    val resForward = TensorResources.reshapeTensor(scope, blockLSTMForward, resShape)
    val resBackward = TensorResources.reshapeTensor(scope, blockLSTMBackward, resShape)

    val vecShape = Array(timeSteps, SAMPLE_SIZE, -1)
    val resTensors = List(resForward, TensorResources.reverseTensor(scope, resBackward, 1))
    val vecForward = TensorResources.reshapeTensor(scope,
      TensorResources.concatTensors(scope, resTensors, 2), vecShape)
    val vecBackward = TensorResources.reverseTensor(scope, vecForward, 0)

    Array(vecForward, vecBackward)
  }

  private def restoreLstmWeights(weightsVariables: List[(String, String)]): Map[String, Tensor[TFloat32]] = {
    //TODO: Use WriteTensorflowModel.readTensorflowHub to load final model
    val modelPath: String = "src/main/resources/dependency-parser-dl/bi-lstm/"
    val model: SavedModelBundle = TensorflowWrapper.withSafeSavedModelBundleLoader(Array(), savedModelDir = modelPath)

    weightsVariables.map{ weightVariable =>
      var blockName = "FirstBlockLSTMModule"
      if (weightVariable._1.contains("next")) {
        blockName = "NextBlockLSTM"
      }
      val variableName = s"bi_lstm_model/$blockName/${weightVariable._1}/Read/ReadVariableOp"
      val tensor = TensorflowWrapper.restoreVariable(model, modelPath, variableName)
      (weightVariable._2, tensor.expect(TFloat32.DTYPE))
    }.toMap

  }

  private def restoreDependencyWeights(weightsVariables: List[String], module: String): Map[String, Tensor[TFloat32]] = {
    //TODO: Use WriteTensorflowModel.readTensorflowHub to load final model
    val modelPath = s"src/main/resources/dependency-parser-dl/$module/"
    val model: SavedModelBundle = TensorflowWrapper.withSafeSavedModelBundleLoader(Array(), savedModelDir = modelPath)

    weightsVariables.map{ weightVariable =>
      val variableName = s"$weightVariable/Read/ReadVariableOp"
      val tensor = TensorflowWrapper.restoreVariable(model, modelPath, variableName)
      (weightVariable, tensor.expect(TFloat32.DTYPE))
    }.toMap

  }

  private def restoreRelationsVocabulary(): Map[Int, String] = {
    //TODO: Use WriteTensorflowModel.readTensorflowHub to load final model
    val modelPath: String = "src/main/resources/dependency-parser-dl/relations/"
    val model: SavedModelBundle = TensorflowWrapper.withSafeSavedModelBundleLoader(Array(), savedModelDir = modelPath)
    val variableName = "rVocabulary/Read/ReadVariableOp"
    val tensor = TensorflowWrapper.restoreVariable(model, modelPath, variableName).expect(TString.DTYPE)

    val relationsVocabulary = TensorResources.extractStrings(scope, tensor)

    relationsVocabulary.zipWithIndex.map( relation => (relation._2, relation._1)).toMap
  }

  private def getLstmOutput(inputSequence: Operand[TFloat32], weights: Map[String, Tensor[TFloat32]]):
  (Operand[TFloat32], Int) = {

    val weightMatrix: Operand[TFloat32] = Constant.create(scope, weights("weightMatrix"))
    val weightInputGate: Operand[TFloat32] = Constant.create(scope, weights("weightInputGate"))
    val weightForgetGate: Operand[TFloat32] = Constant.create(scope, weights("weightForgetGate"))
    val weightOutputGate: Operand[TFloat32] = Constant.create(scope, weights("weightOutputGate"))
    val seqLenMax: Operand[TInt64] = Constant.vectorOf(scope, Array(timeSteps))
    val lstmDims = weightInputGate.asTensor().shape().size().toInt

    val shape = Array(SAMPLE_SIZE, lstmDims)
    val biasShape = Array(lstmDims * 4)
    val initialCellState: Operand[TFloat32] = Zeros.create(scope, Constant.vectorOf(scope, shape), TFloat32.DTYPE)
    val initialHiddenState: Operand[TFloat32] = Zeros.create(scope, Constant.vectorOf(scope, shape), TFloat32.DTYPE)
    val bias: Operand[TFloat32] = Zeros.create(scope, Constant.vectorOf(scope, biasShape), TFloat32.DTYPE)

    val blockLSTM = BlockLSTM.create(scope, seqLenMax, inputSequence,
      initialCellState, initialHiddenState, weightMatrix, weightInputGate,
      weightForgetGate, weightOutputGate, bias)

    (blockLSTM.h(), lstmDims)

  }

  private def getLstmOutputFromSavedModel(inputSequence: Operand[TFloat32], weights: Map[String, Tensor[TFloat32]]):
  (Operand[TFloat32], Int) = {

    val weightMatrix: Operand[TFloat32] = Constant.create(scope, weights("weightMatrix"))
    val weightInputGate: Operand[TFloat32] = Constant.create(scope, weights("weightInputGate"))
    val weightForgetGate: Operand[TFloat32] = Constant.create(scope, weights("weightForgetGate"))
    val weightOutputGate: Operand[TFloat32] = Constant.create(scope, weights("weightOutputGate"))
    val seqLenMax: Operand[TInt64] = Constant.vectorOf(scope, Array(timeSteps))
    val lstmDims = weightInputGate.asTensor().shape().size().toInt

    val shape = Array(SAMPLE_SIZE, lstmDims)
    val biasShape = Array(lstmDims * 4)
    val initialCellState: Operand[TFloat32] = Zeros.create(scope, Constant.vectorOf(scope, shape), TFloat32.DTYPE)
    val initialHiddenState: Operand[TFloat32] = Zeros.create(scope, Constant.vectorOf(scope, shape), TFloat32.DTYPE)
    val bias: Operand[TFloat32] = Zeros.create(scope, Constant.vectorOf(scope, biasShape), TFloat32.DTYPE)

    val tags: Array[String] = Array(SavedModelBundle.DEFAULT_TAG)
    //TODO: Use WriteTensorflowModel.readTensorflowHub to load model
    val modelPath = "src/main/resources/dependency-parser-dl/utils"
    val model: SavedModelBundle = TensorflowWrapper.withSafeSavedModelBundleLoader(tags = tags, savedModelDir = modelPath)
    val blockLSTM: ConcreteFunction = model.function("lstm_output")

    val args: util.Map[String, Tensor[_]] = new util.HashMap()
    args.put("time_steps", seqLenMax.asTensor())
    args.put("input_sequence", inputSequence.asTensor())
    args.put("ini_cell_state", initialCellState.asTensor())
    args.put("ini_hidden_state", initialHiddenState.asTensor())
    args.put("weight_matrix", weightMatrix.asTensor())
    args.put("weight_input_gate", weightInputGate.asTensor())
    args.put("weight_forget_gate", weightForgetGate.asTensor())
    args.put("weight_output_gate", weightOutputGate.asTensor())
    args.put("bias", bias.asTensor())
    val output = blockLSTM.call(args)

    val hiddenOutput = output.get("output_0").expect(TFloat32.DTYPE)

    (Constant.create(scope, hiddenOutput), lstmDims)

  }

  private def computeScores(dependencyFeatures: Array[DependencyFeatures]): Operand[TFloat32] = {

    val indexes = (0 until timeSteps).toList

    val expressions: List[Operand[TFloat32]] = indexes.map{ i =>
      val result = (0 until timeSteps).toList.map{ j =>
        val headFov = dependencyFeatures(i).headsFeatures(0)
        val modFov = dependencyFeatures(j).headsFeatures(1)
        val hidBias = Constant.create(scope, weightsHeads("hidBias"))
        val activation = Tanh.create(scope, TensorMathResources.sumTensors(scope, Array(headFov, modFov, hidBias)))
        val outLayer = Constant.create(scope, weightsHeads("outLayer"))
        val outBias = Constant.create(scope, weightsHeads("outBias"))
        val matmulResult = TensorResources.matmulTensors(scope, activation, outLayer)
        TensorMathResources.sumTensors(scope, Array(matmulResult, outBias))
      }
      TensorResources.stackTensors(scope, result)
    }

    val scores = TensorResources.reshapeTensor(scope, TensorResources.stackTensors(scope, expressions),
      Array(timeSteps, timeSteps))

    scores
  }

  private def predictRelations(predictedHeads: List[Int], dependencyFeatures: Array[DependencyFeatures]): List[String] = {

    val predictedRelationScores: List[Operand[TFloat32]] = predictedHeads.tail.zipWithIndex.map{ case (predictedHead, modifier) =>
      val concatLstmHead =  dependencyFeatures(predictedHead).concatLstm
      val concatLstmModifier = dependencyFeatures(modifier + 1).concatLstm
      val hidLayerFoh: Operand[TFloat32] = Constant.create(scope, weightsRelations("rhidLayerFOH"))
      val hidLayerFom: Operand[TFloat32] = Constant.create(scope, weightsRelations("rhidLayerFOM"))
      val relationHeadFov = TensorResources.matmulTensors(scope, concatLstmHead, hidLayerFoh)
      val relationModFov = TensorResources.matmulTensors(scope, concatLstmModifier, hidLayerFom)
      val relationHidBias: Operand[TFloat32] = Constant.create(scope, weightsRelations("rhidBias"))
      val sumRelations = TensorMathResources.sumTensors(scope, Array(relationHeadFov, relationModFov, relationHidBias))
      val activation = Tanh.create(scope, sumRelations)
      val relationOutLayer = Constant.create(scope, weightsRelations("routLayer"))
      val relationOutBias = Constant.create(scope, weightsRelations("routBias"))
      TensorMathResources.sumTensors(scope, Array(TensorResources.matmulTensors(scope, activation, relationOutLayer),
        relationOutBias)
      )
    }

    val predictedRelations = predictedRelationScores.map{predictedRelationScore =>
      val scores = TensorResources.extractFloats(predictedRelationScore.asTensor())
      val indexRelation = scores.zipWithIndex.maxBy(_._1)._2
      relationsVocabulary.getOrElse(indexRelation, "*unknown*")
    }

    predictedRelations
  }

  case class DependencyFeatures(headsFeatures: Array[Operand[TFloat32]], concatLstm: Operand[TFloat32])

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  override val inputAnnotatorTypes: Array[String] = Array[String](TOKEN)
  override val outputAnnotatorType: AnnotatorType = LABELED_DEPENDENCY

}
