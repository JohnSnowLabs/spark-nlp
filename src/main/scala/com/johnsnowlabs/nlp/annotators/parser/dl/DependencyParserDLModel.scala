package com.johnsnowlabs.nlp.annotators.parser.dl

import com.johnsnowlabs.ml.tensorflow.{TensorflowEmbeddingLookup, TensorflowWrapper}
import com.johnsnowlabs.nlp.AnnotatorType.{DEPENDENCY, DOCUMENT, TOKEN}
import com.johnsnowlabs.nlp.serialization.MapFeature
import com.johnsnowlabs.nlp.{Annotation, AnnotatorModel, AnnotatorType, HasSimpleAnnotate}
import org.apache.spark.ml.param.{IntParam, StringArrayParam}
import org.apache.spark.ml.util.Identifiable
import org.tensorflow.op.core.Reverse
import org.tensorflow.types.TFloat32
import org.tensorflow.{SavedModelBundle, Tensor}

class DependencyParserDLModel(override val uid: String) extends AnnotatorModel[DependencyParserDLModel]
  with HasSimpleAnnotate[DependencyParserDLModel] {

  def this() = this(Identifiable.randomUID(DEPENDENCY))

  protected val vocabulary: MapFeature[String, Int] = new MapFeature[String, Int](this, "vocabulary to lookup embeddings based on word id")

  def setVocabulary(value: Map[String, Int]): this.type = set(vocabulary, value)

  private lazy val vocabularySize = $$(vocabulary).size

  /**
    * takes a document and annotations and produces new annotations of this annotator's annotation type
    *
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
    */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {
    println("Implement Annotate")
    val embeddings = new TensorflowEmbeddingLookup(100, vocabularySize)
    val embeddingsTable = embeddings.initializeTable()

    val tokens = annotations
      .filter(_.annotatorType == AnnotatorType.TOKEN)
      .toArray

    val sentenceEmbeddings = tokens.map{ token =>
      val wordId: Int = $$(vocabulary).getOrElse(token.result, 0)
      embeddings.lookup(embeddingsTable, Array(wordId))
    }
    //TODO: Add infer logic
//    sentenceEmbeddings.foreach{ embeddings =>
//      val reverse = new Reverse[TFloat32]
//    }

    Seq()
  }

  def restoreLstmWeights(): Map[String, Tensor[TFloat32]] = {
    val tags: Array[String] = Array(SavedModelBundle.DEFAULT_TAG)
    val modelPath: String = "src/test/resources/tensorflow/models/dependency-parser/bi-lstm/"
    val model: SavedModelBundle = TensorflowWrapper.withSafeSavedModelBundleLoader(tags = tags, savedModelDir = modelPath)
    val weightsVariables = List("w_first_lstm", "wig_first_lstm", "wfg_first_lstm", "wog_first_lstm")

    val firstLstmWeights: Map[String, Tensor[TFloat32]] = weightsVariables.map{ weightVariable =>
      val variableName = "bi_lstm_model/FirstBlockLSTMModule/" + weightVariable + "/Read/ReadVariableOp"
      val tensor = TensorflowWrapper.restoreVariable(model, modelPath, variableName)
      (weightVariable, tensor.expect(TFloat32.DTYPE))
    }.toMap

    firstLstmWeights

  }

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  override val inputAnnotatorTypes: Array[String] = Array[String](DOCUMENT, TOKEN)
  override val outputAnnotatorType: AnnotatorType = DEPENDENCY

}
