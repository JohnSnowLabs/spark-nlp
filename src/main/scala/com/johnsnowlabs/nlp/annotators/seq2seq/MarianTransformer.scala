/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements.  See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License.  You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.johnsnowlabs.nlp.annotators.seq2seq

import com.johnsnowlabs.ml.tensorflow._
import com.johnsnowlabs.ml.tensorflow.sentencepiece._
import com.johnsnowlabs.nlp._
import com.johnsnowlabs.nlp.serialization.MapFeature
import com.johnsnowlabs.nlp.util.io.{ExternalResource, ReadAs, ResourceHelper}
import org.apache.spark.broadcast.Broadcast
import org.apache.spark.ml.param.{IntArrayParam, IntParam, Param, StringArrayParam}
import org.apache.spark.ml.util.Identifiable
import org.apache.spark.sql.SparkSession

import java.io.File

/** MarianTransformer: Fast Neural Machine Translation
 *
 * MarianTransformer uses models trained by MarianNMT.
 *
 * Marian is an efficient, free Neural Machine Translation framework written in pure C++ with minimal dependencies.
 * It is mainly being developed by the Microsoft Translator team. Many academic (most notably the University of Edinburgh and in the past the Adam Mickiewicz University in Pozna≈Ñ) and commercial contributors help with its development.
 *
 * It is currently the engine behind the Microsoft Translator Neural Machine Translation services and being deployed by many companies, organizations and research projects (see below for an incomplete list).
 *
 * '''Sources''' :
 * MarianNMT [[https://marian-nmt.github.io/]]
 * Marian: Fast Neural Machine Translation in C++ [[https://www.aclweb.org/anthology/P18-4020/]]
 *
 * '''Note''' :
 * Note that this is a very computationally expensive module especially on larger sequence.
 * The use of an accelerator such as GPU is recommended.
 *
 * @param uid required internal uid for saving annotator
 * @groupname anno Annotator types
 * @groupdesc anno Required input and expected output annotator types
 * @groupname Ungrouped Members
 * @groupname param Parameters
 * @groupname setParam Parameter setters
 * @groupname getParam Parameter getters
 * @groupname Ungrouped Members
 * @groupprio param  1
 * @groupprio anno  2
 * @groupprio Ungrouped 3
 * @groupprio setParam  4
 * @groupprio getParam  5
 * @groupdesc Parameters A list of (hyper-)parameter keys this annotator can take. Users can set and get the parameter values through setters and getters, respectively.
 */
class MarianTransformer(override val uid: String) extends
  AnnotatorModel[MarianTransformer]
  with HasSimpleAnnotate[MarianTransformer]
  with WriteTensorflowModel
  with WriteSentencePieceModel {

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  def this() = this(Identifiable.randomUID("MARIAN_TRANSFORMER"))

  /** Input Annotator Type : TOKEN DOCUMENT
   *
   * @group anno
   * */
  override val inputAnnotatorTypes: Array[String] = Array(AnnotatorType.DOCUMENT)

  /**
   * Output Annotator Type : DOCUMENT
   *
   * @group anno
   * */
  override val outputAnnotatorType: AnnotatorType = AnnotatorType.DOCUMENT

  /**
   * Vocabulary used to encode and decode piece tokens generated by SentencePiece
   * This will be set once the model is created and cannot be changed afterwards
   *
   * @group param
   * */
  val vocabulary = new StringArrayParam(this, "vocabulary", "Vocabulary used to encode and decode piece words generated by SentencePiece")

  /** @group setParam */
  def setVocabulary(value: Array[String]): this.type = {
    if (get(vocabulary).isEmpty)
      set(vocabulary, value)
    this
  }

  /**
   * Controls the maximum length for encoder inputs (source language texts)
   * Default: 40
   *
   * @group param
   * */
  val maxInputLength = new IntParam(this, "maxInputLength", "Controls the maximum length for encoder inputs (source language texts)")

  /** @group setParam * */
  def setMaxInputLength(value: Int): this.type = {
    require(value <= 512, "MarianTransformer model does not support sequences longer than 512.")
    set(maxInputLength, value)
    this
  }

  /** @group getParam * */
  def getMaxInputLength: Int = $(maxInputLength)

  /**
   * Controls the maximum length for decoder outputs (target language texts)
   * Default: 40
   *
   * @group param
   * */
  val maxOutputLength = new IntParam(this, "maxOutputLength", "Controls the maximum length for decoder outputs (target language texts)")

  /** @group setParam * */
  def setMaxOutputLength(value: Int): this.type = {
    set(maxOutputLength, value)
  }

  /** @group getParam * */
  def getMaxOutputLength: Int = $(maxOutputLength)

  /**
   * A string representing the target language in the form of >>id<< (id = valid target language ID)
   *
   * langId is only needed if the model generates multi-lingual target language texts.
   * For instance, for a 'en-fr' model this param is not required to be set.
   *
   * @group param
   * */
  var langId = new Param[String](this, "langId", "A string representing the target language in the form of >>id<< (id = valid target language ID)")

  /** @group setParam * */
  def setLangId(lang: String): MarianTransformer.this.type = {
    set(langId, lang)
  }

  /** @group * */
  def getLangId: String = $(langId)

  /**
   * ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()
   *
   * @group param
   * */
  val configProtoBytes = new IntArrayParam(this, "configProtoBytes", "ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()")

  /** @group getSaram * */
  def setConfigProtoBytes(bytes: Array[Int]): MarianTransformer.this.type = set(this.configProtoBytes, bytes)

  /** @group setGaram * */
  def getConfigProtoBytes: Option[Array[Byte]] = get(this.configProtoBytes).map(_.map(_.toByte))

  /**
   * It contains TF model signatures for the laded saved model
   *
   * @group param
   * */
  val signatures = new MapFeature[String, String](model = this, name = "signatures")

  /** @group setParam */
  def setSignatures(value: Map[String, String]): this.type = {
    if (get(signatures).isEmpty)
      set(signatures, value)
    this
  }

  /** @group getParam */
  def getSignatures: Option[Map[String, String]] = get(this.signatures)

  /**
   * The Tensorflow Marian Model
   *
   * @group param
   * */
  private var _model: Option[Broadcast[TensorflowMarian]] = None

  /** @group setParam * */
  def setModelIfNotSet(spark: SparkSession, tensorflow: TensorflowWrapper, sppSrc: SentencePieceWrapper, sppTrg: SentencePieceWrapper): this.type = {
    if (_model.isEmpty) {
      _model = Some(
        spark.sparkContext.broadcast(
          new TensorflowMarian(
            tensorflow,
            sppSrc,
            sppTrg,
            configProtoBytes = getConfigProtoBytes,
            signatures = getSignatures
          )
        )
      )
    }
    this
  }

  /** @group setParam * */
  def getModelIfNotSet: TensorflowMarian = _model.get.value

  setDefault(
    maxInputLength -> 40,
    maxOutputLength -> 40,
    langId -> ""
  )

  /**
   * takes a document and annotations and produces new annotations of this annotator's annotation type
   *
   * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
   * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
   */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {
    val nonEmptySentences = annotations.filter(_.result.nonEmpty)

    if (nonEmptySentences.nonEmpty) {
      this.getModelIfNotSet.generateSeq2Seq(
        sentences = nonEmptySentences,
        maxInputLength = $(maxInputLength),
        maxOutputLength = $(maxOutputLength),
        vocabs = $(vocabulary),
        langId = $(langId)
      )
    } else {
      Seq.empty[Annotation]
    }

  }

  override def onWrite(path: String, spark: SparkSession): Unit = {
    super.onWrite(path, spark)
    writeTensorflowModelV2(path, spark, getModelIfNotSet.tensorflow, "_marian", MarianTransformer.tfFile, configProtoBytes = getConfigProtoBytes, savedSignatures = getSignatures)
    writeSentencePieceModel(path, spark, getModelIfNotSet.sppSrc, "_src_marian", MarianTransformer.sppFile + "_src")
    writeSentencePieceModel(path, spark, getModelIfNotSet.sppTrg, "_trg_marian", MarianTransformer.sppFile + "_trg")

  }

}

trait ReadablePretrainedMarianMTModel extends ParamsAndFeaturesReadable[MarianTransformer] with HasPretrained[MarianTransformer] {
  override val defaultModelName: Some[String] = Some("opus_mt_en_fr")
  override val defaultLang: String = "xx"

  /** Java compliant-overrides */
  override def pretrained(): MarianTransformer = super.pretrained()

  override def pretrained(name: String): MarianTransformer = super.pretrained(name)

  override def pretrained(name: String, lang: String): MarianTransformer = super.pretrained(name, lang)

  override def pretrained(name: String, lang: String, remoteLoc: String): MarianTransformer = super.pretrained(name, lang, remoteLoc)
}

trait ReadMarianMTTensorflowModel extends ReadTensorflowModel with ReadSentencePieceModel {
  this: ParamsAndFeaturesReadable[MarianTransformer] =>

  override val tfFile: String = "marian_tensorflow"
  override val sppFile: String = "marian_spp"

  def readTensorflow(instance: MarianTransformer, path: String, spark: SparkSession): Unit = {
    val tf = readTensorflowModel(path, spark, "_marian_tf", savedSignatures = instance.getSignatures)
    val sppSrc = readSentencePieceModel(path, spark, "_src_marian", sppFile + "_src")
    val sppTrg = readSentencePieceModel(path, spark, "_trg_marian", sppFile + "_trg")
    instance.setModelIfNotSet(spark, tf, sppSrc, sppTrg)
  }

  addReader(readTensorflow)

  def loadSavedModel(folder: String, spark: SparkSession): MarianTransformer = {

    val f = new File(folder)
    val assetsPath = folder + "/assets"
    val savedModel = new File(folder, "saved_model.pb")
    val sppSrcModel = new File(assetsPath, "source.spm")
    val sppTrgModel = new File(assetsPath, "target.spm")
    val sppVocab = new File(assetsPath, "vocabs.txt")

    require(f.exists, s"Folder $folder not found")
    require(f.isDirectory, s"File $folder is not folder")
    require(
      savedModel.exists(),
      s"savedModel file saved_model.pb not found in folder $folder"
    )
    require(sppSrcModel.exists(), s"SentencePiece model source.spm not found in folder $assetsPath")
    require(sppTrgModel.exists(), s"SentencePiece model target.spm not found in folder $assetsPath")
    require(sppVocab.exists(), s"SentencePiece model source.model not found in folder $assetsPath")

    val vocabResource = new ExternalResource(sppVocab.getAbsolutePath, ReadAs.TEXT, Map("format" -> "text"))
    val words = ResourceHelper.parseLines(vocabResource)
      .zipWithIndex.toMap.toSeq.sortBy(_._2).map(x => x._1.mkString).toArray

    val (wrapper, signatures) = TensorflowWrapper.read(folder, zipped = false, useBundle = true, tags = Array("serve"))
    val sppSrc = SentencePieceWrapper.read(sppSrcModel.toString)
    val sppTrg = SentencePieceWrapper.read(sppTrgModel.toString)

    val _signatures = signatures match {
      case Some(s) => s
      case None => throw new Exception("Cannot load signature definitions from model!")
    }

    /** the order of setSignatures is important is we use getSignatures inside setModelIfNotSet */
    val marianMT = new MarianTransformer()
      .setVocabulary(words)
      .setSignatures(_signatures)
      .setModelIfNotSet(spark, wrapper, sppSrc, sppTrg)

    marianMT
  }
}

object MarianTransformer extends ReadablePretrainedMarianMTModel with ReadMarianMTTensorflowModel with ReadSentencePieceModel
