{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/util/Spark_NLP_Structured_Streaming.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Streaming with Spark NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbQ9JCLtHCPO"
   },
   "source": [
    "This notebook demonstrates the integration of Spark NLP with Spark Structured Streaming. We'll illustrate a straightforward example that performs real-time entity duplication counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_DFTLK4HLhF"
   },
   "source": [
    "First, we create a directory where the files for streaming will reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5DeGx0cax5V8"
   },
   "outputs": [],
   "source": [
    "!mkdir ner-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bFNk7PaA2gxh",
    "outputId": "62a3dce1-bd74-4fa0-8ccb-167ed842790c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences written to ner-resources/ner-example.txt\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Apple Inc. is planning to open a new store in Paris next year.\",\n",
    "    \"Dr. Smith will attend the conference on artificial intelligence in San Francisco on January 15, 2023.\",\n",
    "    \"The Eiffel Tower, located in the heart of Paris, is a popular tourist attraction.\",\n",
    "    \"Google, headquartered in Mountain View, California, announced a breakthrough in machine learning.\",\n",
    "    \"Mary Johnson, the CEO of XYZ Corporation, will deliver the keynote speech at the event.\",\n",
    "    \"The Great Barrier Reef, the world's largest coral reef system, is located in Australia.\",\n",
    "    \"On July 4th, 1776, the United States declared its independence from British rule.\",\n",
    "    \"NASA's Perseverance rover successfully landed on Mars in February 2021.\",\n",
    "    \"The Louvre Museum in France houses thousands of works of art, including the Mona Lisa.\",\n",
    "    \"Amazon, founded by Jeff Bezos, is one of the largest e-commerce and cloud computing companies.\",\n",
    "    \"Tokyo, the capital of Japan, will host the Summer Olympics in 2024.\",\n",
    "    \"Albert Einstein, the famous physicist, developed the theory of relativity.\",\n",
    "    \"The Nile River is the longest river in Africa, flowing through multiple countries.\",\n",
    "    \"The World Health Organization (WHO) plays a crucial role in global health initiatives.\",\n",
    "    \"Queen Elizabeth II has been the reigning monarch of the United Kingdom since 1952.\"\n",
    "]\n",
    "\n",
    "file_path = \"ner-resources/ner-example.txt\"\n",
    "\n",
    "# Write the sentences to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    for sentence in sentences:\n",
    "        file.write(sentence + \"\\n\")\n",
    "\n",
    "print(f\"Sentences written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6GaeClp21Wm",
    "outputId": "1028dc35-8f20-4fcf-8305-a2b1d66ab50e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PySpark 3.2.3 and Spark NLP 5.1.4\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 5.1.4\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.7/540.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xf6yRDo924ZB"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tDXFBhNjxys8"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame representing the stream of input lines\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"text\") \\\n",
    "    .option(\"maxFilesPerTrigger\", 1) \\\n",
    "    .load(\"ner-resources/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i0265q0vyPmE"
   },
   "outputs": [],
   "source": [
    "# Split the lines into sentences\n",
    "text_df = lines.select(lines.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SRvOvc9nxjM3"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxtFXbAlyUar",
    "outputId": "fa862177-96ed-4eb4-dc95-97bc4ad282fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Create Spark NLP pipeline\n",
    "document_assembler = DocumentAssembler().setInputCol(\"value\").setOutputCol(\"document\")\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
    "word_embeddings = WordEmbeddingsModel().pretrained().setInputCols([\"document\", \"token\"]).setOutputCol(\"embeddings\")\n",
    "ner_tagger = NerDLModel().pretrained().setInputCols([\"document\", \"token\", \"embeddings\"]).setOutputCol(\"ner\")\n",
    "ner_converter = NerConverter().setInputCols(\"document\", \"token\", \"ner\").setOutputCol(\"entities\")\n",
    "\n",
    "# Assemble the pipeline\n",
    "pipeline = Pipeline(stages=[document_assembler, tokenizer, word_embeddings, ner_tagger, ner_converter])\n",
    "\n",
    "# Fit the pipeline on the data\n",
    "model = pipeline.fit(text_df)\n",
    "\n",
    "# Transform the data\n",
    "ner_df = model.transform(text_df).selectExpr(\"explode(entities)\").withColumnRenamed(\"col\", \"entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vf0B3c2eyWZP"
   },
   "outputs": [],
   "source": [
    "# Extract the relavant information (entities and NER tags)\n",
    "entities_df = ner_df.select(\n",
    "    col(\"entities.result\").alias(\"entity\"),\n",
    "    col(\"entities.metadata\").getItem(\"entity\").alias(\"tag\")\n",
    ")\n",
    "\n",
    "# Group by 'entity' and 'tag', and count the occurrences\n",
    "entity_counts_df = entities_df.groupBy(\"entity\", \"tag\").count() \\\n",
    "        .writeStream \\\n",
    "        .queryName(\"entity_counts_table\") \\\n",
    "        .outputMode(\"complete\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGOB5m8EA0tJ",
    "outputId": "66e604ff-e7ed-4951-cb99-3dce91b30b07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "threading.Event().wait(45)  # Pauses the execution for 45 seconds to allow refreshing streaming to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huYthxVQ-J_Y",
    "outputId": "9511cd36-ac92-4ce6-de3b-bc3a8c10b734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-----+\n",
      "|             entity| tag|count|\n",
      "+-------------------+----+-----+\n",
      "|            British|MISC|    1|\n",
      "|       Mary Johnson| PER|    1|\n",
      "|       Elizabeth II| PER|    1|\n",
      "|              Paris| LOC|    2|\n",
      "|     United Kingdom| LOC|    1|\n",
      "|      San Francisco| LOC|    1|\n",
      "|NASA's Perseverance| ORG|    1|\n",
      "|          Australia| LOC|    1|\n",
      "|              Tokyo| LOC|    1|\n",
      "|      United States| LOC|    1|\n",
      "|       Eiffel Tower| LOC|    1|\n",
      "|             Google| ORG|    1|\n",
      "|    XYZ Corporation| ORG|    1|\n",
      "|              Japan| LOC|    1|\n",
      "|          Mona Lisa| PER|    1|\n",
      "|         California| LOC|    1|\n",
      "|          Apple Inc| ORG|    1|\n",
      "|         Nile River| LOC|    1|\n",
      "|    Summer Olympics|MISC|    1|\n",
      "|      Mountain View| LOC|    1|\n",
      "+-------------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from entity_counts_table\").show()   # interactively query in-memory table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il5jo4knJVn7"
   },
   "source": [
    "Adding a file for the streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7PFPfSB-LnH",
    "outputId": "b13fbb72-8c74-4a65-d002-7d2045ee99e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences written to ner-resources/ner_example2.txt\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Apple Inc. recently unveiled its latest innovation, a revolutionary product that will change the way we interact with technology.\",\n",
    "    \"Dr. Smith, a leading expert in the field of robotics, will conduct a workshop on advanced machine learning techniques next month.\",\n",
    "    \"The Eiffel Tower, standing tall against the Parisian skyline, offers breathtaking views of the city and is a must-visit landmark.\",\n",
    "    \"Google's research team, based in Silicon Valley, is making strides in developing sustainable technologies for the future.\",\n",
    "    \"Mary Johnson, a renowned artist, will showcase her latest collection at the art gallery downtown this weekend.\",\n",
    "    \"The Great Barrier Reef, teeming with vibrant marine life, attracts snorkelers and divers from around the world.\",\n",
    "    \"On July 4th, 1776, the Founding Fathers signed the Declaration of Independence, marking a pivotal moment in American history.\",\n",
    "    \"NASA's Perseverance rover, equipped with state-of-the-art instruments, is exploring the Martian surface for signs of past life.\",\n",
    "    \"The Louvre Museum, home to priceless masterpieces, continues to be a cultural treasure trove for art enthusiasts.\",\n",
    "    \"Amazon's cloud computing division, led by Jeff Bezos, is at the forefront of shaping the digital landscape.\",\n",
    "    \"Tokyo, a bustling metropolis that seamlessly blends tradition and modernity, is gearing up to host the Olympics in 2024.\",\n",
    "    \"Albert Einstein's groundbreaking theories, including the theory of relativity, revolutionized our understanding of the universe.\",\n",
    "    \"The Nile River, winding through ancient landscapes, has been a source of life and inspiration for countless civilizations.\",\n",
    "    \"The World Health Organization (WHO) collaborates with global partners to address public health challenges and promote well-being.\",\n",
    "    \"Queen Elizabeth II, the longest-reigning monarch, has witnessed significant historical events during her reign.\"\n",
    "]\n",
    "\n",
    "# Write the sentences to a file\n",
    "file_path = \"ner-resources/ner_example2.txt\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    for sentence in sentences:\n",
    "        file.write(sentence + \"\\n\")\n",
    "\n",
    "print(f\"Sentences written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XdbJgOF-xAY",
    "outputId": "68565095-9981-49b8-8f98-78339f7efef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-----+\n",
      "|entity|tag|count|\n",
      "+------+---+-----+\n",
      "| Paris|LOC|    2|\n",
      "+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRXhhuDsDLmK",
    "outputId": "cc1f5c78-bf4a-4dec-94ad-a400c1b40d1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8dib3gtBqAL",
    "outputId": "c078473a-3a2b-4ab5-d399-82ea304982f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+-----+\n",
      "|              entity|tag|count|\n",
      "+--------------------+---+-----+\n",
      "|        Mary Johnson|PER|    2|\n",
      "|        Elizabeth II|PER|    2|\n",
      "|               Paris|LOC|    2|\n",
      "| NASA's Perseverance|ORG|    2|\n",
      "|               Tokyo|LOC|    2|\n",
      "|           Apple Inc|ORG|    2|\n",
      "|          Nile River|LOC|    2|\n",
      "|World Health Orga...|ORG|    2|\n",
      "|               Smith|PER|    2|\n",
      "|          Jeff Bezos|PER|    2|\n",
      "|  Great Barrier Reef|LOC|    2|\n",
      "+--------------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You maye need to refresh the query cells to visualize the result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
