{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "HE7n3PRlQaYA",
    "outputId": "5b622949-97be-460f-9deb-21a4a39c1667"
   },
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/util/Training_Helpers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1uGjSssSNo_"
   },
   "source": [
    "In this notebook, we will explore the file system supported by `CoNLL`, `CoNLLU` and `POS` traning classes in Spark NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eKSuiU-X0jVM"
   },
   "outputs": [],
   "source": [
    "!mkdir datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIip0kwwlEju",
    "outputId": "fe8a3d92-f208-4994-854e-451b384984cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-15 00:27:56--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conllu/en.test.conllu\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1864 (1.8K) [text/plain]\n",
      "Saving to: ‘en.test.conllu’\n",
      "\n",
      "en.test.conllu      100%[===================>]   1.82K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-03-15 00:27:56 (17.0 MB/s) - ‘en.test.conllu’ saved [1864/1864]\n",
      "\n",
      "--2023-03-15 00:27:56--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll/test_conll_docid.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 696 [text/plain]\n",
      "Saving to: ‘test_conll_docid.txt’\n",
      "\n",
      "test_conll_docid.tx 100%[===================>]     696  --.-KB/s    in 0s      \n",
      "\n",
      "2023-03-15 00:27:57 (56.2 MB/s) - ‘test_conll_docid.txt’ saved [696/696]\n",
      "\n",
      "--2023-03-15 00:27:57--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/anc-pos-corpus-small/test-training.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 142 [text/plain]\n",
      "Saving to: ‘test-training.txt’\n",
      "\n",
      "test-training.txt   100%[===================>]     142  --.-KB/s    in 0s      \n",
      "\n",
      "2023-03-15 00:27:57 (8.50 MB/s) - ‘test-training.txt’ saved [142/142]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conllu/en.test.conllu\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll/test_conll_docid.txt\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/anc-pos-corpus-small/test-training.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ko6o75kslKO8"
   },
   "outputs": [],
   "source": [
    "!mv en.test.conllu ./datasets\n",
    "!mv test_conll_docid.txt ./datasets\n",
    "!mv test-training.txt ./datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLZ2Z-1dSbGA"
   },
   "source": [
    "Spark NLP support the file systems below:\n",
    "\n",
    "\n",
    "* Local file system: `file://` or `/my/path/`\n",
    "\n",
    "* Distributed file system: `hdfs://` or `dbfs://`\n",
    "\n",
    "* Cloud buckets: `s3a://` or `s3://`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn3axMFZTaxV"
   },
   "source": [
    "Starting at spark-nlp 4.4.1, you can also set an S3 URI. To configure this,  it is necessary to set up the Spark session with the appropriate settings for both Spark NLP and Spark ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vA7z0u8VOus"
   },
   "source": [
    "### Spark NLP Settings for S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckvJf_2QVWa8"
   },
   "source": [
    "Spark NLP requires the following configuration:\n",
    "1. **S3 Region**: We need the region to upload a file on your S3 bucket. This is defined in the config `spark.jsl.settings.aws.region`\n",
    "2. **Spark NLP JAR**: Since some custom configurations are needed to use S3 URI. It is also required to include spark-nlp JAR either as a dependency for our application or during spark session creation. Since we are using a notebook, we will add these packages while creating a spark session in the following config:\n",
    "\n",
    "- `spark.jars.packages` for Maven coordinates or `spark.jar` for FAT JAR\n",
    "3. **KryoSerializer**: We recommend also adding the parameters described in creating manually a spark session in requirements section on [Spark NLP documentation](https://github.com/JohnSnowLabs/spark-nlp#requirements).\n",
    "4. **Authenticating with S3**: This is needed to interact with external S3 buckets, and it will require an access key, a secret key, and a session token. Define the values in these configs:\n",
    "\n",
    "- `spark.jsl.settings.aws.credentials.access_key_id`\n",
    "- `spark.jsl.settings.aws.credentials.secret_access_key`\n",
    "- `spark.jsl.settings.aws.credentials.session_token`\n",
    "\n",
    "This configuration will depend on your S3 bucket and AWS configuration. In this notebook a connection through **Temporary Security Credentials** is showcased. **Please contact your administrator to choose the right setup, as well as, the required keys/tokens.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a6o4nxOWO3n"
   },
   "source": [
    "### Spark ML Settings for S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-icNADIWTQq"
   },
   "source": [
    "1. **AWS packages**: S3A depends upon two JARs, alongside `hadoop-common` and its dependencies, which are `hadoop-aws` and `aws-java-sdk` packages. So, you will need to either add these dependencies in your application or to your spark session. Since we are using a notebook, we will add these packages while creating the spark session in the following config:\n",
    "\n",
    "- `spark.jars.packages`\n",
    "2. **AWS File System**: Defining S3AFileSystem it's also required for interacting S3 with AWS SDK. Define the value in this config:\n",
    "\n",
    "- `spark.hadoop.fs.s3a.impl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3VcutEGXgta"
   },
   "source": [
    "Now, let's take a look at the spark session creation below to see how to define each of the configurations with its values for **Temporary Security Credentials**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter your AWS Access Key:\")\n",
    "MY_ACCESS_KEY = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter your AWS Secret Key:\")\n",
    "MY_SECRET_KEY = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter your AWS Session Key:\")\n",
    "MY_SESSION_KEY = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SGy4Zd5sGoVg"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkNLP\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12G\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars\", \"./sparknlp.jar\") \\\n",
    "    .config(\"spark.jsl.settings.aws.credentials.access_key_id\", MY_ACCESS_KEY) \\\n",
    "    .config(\"spark.jsl.settings.aws.credentials.secret_access_key\", MY_SECRET_KEY) \\\n",
    "    .config(\"spark.jsl.settings.aws.credentials.session_token\", MY_SESSION_KEY) \\\n",
    "    .config(\"spark.jsl.settings.aws.region\", \"us-east-1\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.4.1,org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk:1.11.901\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FHMllLof4VeB"
   },
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import ResourceDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB19S6xOVqxV"
   },
   "source": [
    "## CoNLLU Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lObPRuO7G6gU"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import CoNLLU\n",
    "\n",
    "conllu_df = CoNLLU().readDataset(spark, \"./datasets/en.test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALkqyxFKH5se",
    "outputId": "3705688e-3687-4f1f-efc7-f11c7d1ee705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|                form|                upos|                xpos|               lemma|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|What if Google Mo...|[{document, 0, 36...|[{document, 0, 36...|[{token, 0, 3, Wh...|[{pos, 0, 3, PRON...|[{pos, 0, 3, WP, ...|[{token, 0, 3, wh...|\n",
      "|Google is a nice ...|[{document, 0, 30...|[{document, 0, 30...|[{token, 0, 5, Go...|[{pos, 0, 5, PROP...|[{pos, 0, 5, NNP,...|[{token, 0, 5, Go...|\n",
      "|Does anybody use ...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 3, Do...|[{pos, 0, 3, AUX,...|[{pos, 0, 3, VBZ,...|[{token, 0, 3, do...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conllu_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Svnznf0zIdmQ"
   },
   "outputs": [],
   "source": [
    "conllu_df2 = CoNLLU().readDataset(spark, \"file:///content/datasets/en.test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ApLTmYsIhn7",
    "outputId": "f41799ba-af3e-4ebc-9529-27f609305911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|                form|                upos|                xpos|               lemma|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|What if Google Mo...|[{document, 0, 36...|[{document, 0, 36...|[{token, 0, 3, Wh...|[{pos, 0, 3, PRON...|[{pos, 0, 3, WP, ...|[{token, 0, 3, wh...|\n",
      "|Google is a nice ...|[{document, 0, 30...|[{document, 0, 30...|[{token, 0, 5, Go...|[{pos, 0, 5, PROP...|[{pos, 0, 5, NNP,...|[{token, 0, 5, Go...|\n",
      "|Does anybody use ...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 3, Do...|[{pos, 0, 3, AUX,...|[{pos, 0, 3, VBZ,...|[{token, 0, 3, do...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conllu_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DWFNPVn_RNnu"
   },
   "outputs": [],
   "source": [
    "conllu_df3 = CoNLLU().readDataset(spark, \"s3://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/en.test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XrIHlVMqRT73",
    "outputId": "15d417ea-fa5b-4c4d-85a6-d0d5ba667fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|                form|                upos|                xpos|               lemma|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|What if Google Mo...|[{document, 0, 36...|[{document, 0, 36...|[{token, 0, 3, Wh...|[{pos, 0, 3, PRON...|[{pos, 0, 3, WP, ...|[{token, 0, 3, wh...|\n",
      "|Google is a nice ...|[{document, 0, 30...|[{document, 0, 30...|[{token, 0, 5, Go...|[{pos, 0, 5, PROP...|[{pos, 0, 5, NNP,...|[{token, 0, 5, Go...|\n",
      "|Does anybody use ...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 3, Do...|[{pos, 0, 3, AUX,...|[{pos, 0, 3, VBZ,...|[{token, 0, 3, do...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conllu_df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NSCrBkwKD5sg"
   },
   "outputs": [],
   "source": [
    "conllu_df4 = CoNLLU().readDataset(spark, \"s3a://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/en.test.conllu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_d36_wsD8dH",
    "outputId": "9cdd8b10-c444-4d95-d4ee-2197d449c6cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|                form|                upos|                xpos|               lemma|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|What if Google Mo...|[{document, 0, 36...|[{document, 0, 36...|[{token, 0, 3, Wh...|[{pos, 0, 3, PRON...|[{pos, 0, 3, WP, ...|[{token, 0, 3, wh...|\n",
      "|Google is a nice ...|[{document, 0, 30...|[{document, 0, 30...|[{token, 0, 5, Go...|[{pos, 0, 5, PROP...|[{pos, 0, 5, NNP,...|[{token, 0, 5, Go...|\n",
      "|Does anybody use ...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 3, Do...|[{pos, 0, 3, AUX,...|[{pos, 0, 3, VBZ,...|[{token, 0, 3, do...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conllu_df4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rAHW4e-VvG1"
   },
   "source": [
    "### CoNLL Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "4aXMOlR-VyO8"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "conll_df = CoNLL().readDataset(spark, \"./datasets/test_conll_docid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--vGlewfWMhp",
    "outputId": "e50d289c-61a7-41a0-d117-8d6105f4517c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KsTTXbt0WQUI"
   },
   "outputs": [],
   "source": [
    "conll_df2 = CoNLL().readDataset(spark, \"file:///content/datasets/test_conll_docid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HAIDDR0WTDD",
    "outputId": "8d544411-3c88-4af0-e6c7-926aae09ed9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "iGnDuBpRDplH"
   },
   "outputs": [],
   "source": [
    "conll_df22 = CoNLL().readDataset(spark, \"/content/datasets/test_conll_docid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpFdm1o5FWdS",
    "outputId": "64d78a47-8ae2-4edc-ced9-2b956ebb332e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df22.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dcoGWYOUWWn0"
   },
   "outputs": [],
   "source": [
    "conll_df3 = CoNLL().readDataset(spark, \"s3://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/test_conll_docid.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBUoMXoiWZIp",
    "outputId": "15dee30c-8797-423b-a9e9-c1175f8e08a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "q_CA2MDaXbzL"
   },
   "outputs": [],
   "source": [
    "conll_df4 = CoNLL().readDataset(spark, \"s3a://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvaZSO-KXhbX",
    "outputId": "99ddad29-35c1-408a-d314-7499f0c5c73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             # # # #|[{document, 0, 6,...|[{document, 0, 6,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|               # # #|[{document, 0, 4,...|[{document, 0, 4,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|                 # #|[{document, 0, 2,...|[{document, 0, 2,...|[{token, 0, 0, #,...|[{pos, 0, 0, sent...|[{named_entity, 0...|\n",
      "|I Today Muiriel T...|[{document, 0, 55...|[{document, 0, 55...|[{token, 0, 0, I,...|[{pos, 0, 0, have...|[{named_entity, 0...|\n",
      "|I Why But I I It ...|[{document, 0, 44...|[{document, 0, 44...|[{token, 0, 0, I,...|[{pos, 0, 0, don'...|[{named_entity, 0...|\n",
      "|The Sail Nobody H...|[{document, 0, 88...|[{document, 0, 88...|[{token, 0, 2, Th...|[{pos, 0, 2, coas...|[{named_entity, 0...|\n",
      "|The The I In We W...|[{document, 0, 86...|[{document, 0, 86...|[{token, 0, 2, Th...|[{pos, 0, 2, spee...|[{named_entity, 0...|\n",
      "|If Do He Walk You...|[{document, 0, 11...|[{document, 0, 11...|[{token, 0, 1, If...|[{pos, 0, 1, it's...|[{named_entity, 0...|\n",
      "|Do Do I If I If I...|[{document, 0, 38...|[{document, 0, 38...|[{token, 0, 1, Do...|[{pos, 0, 1, you,...|[{named_entity, 0...|\n",
      "|Of Of Of As Of I ...|[{document, 0, 34...|[{document, 0, 34...|[{token, 0, 1, Of...|[{pos, 0, 1, cour...|[{named_entity, 0...|\n",
      "|Do I I It's It's ...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 1, Do...|[{pos, 0, 1, you,...|[{named_entity, 0...|\n",
      "|How How What What...|[{document, 0, 12...|[{document, 0, 12...|[{token, 0, 2, Ho...|[{pos, 0, 2, pers...|[{named_entity, 0...|\n",
      "|Because Because B...|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 6, Be...|[{pos, 0, 6, he, ...|[{named_entity, 0...|\n",
      "|Excuse Will Can K...|[{document, 0, 51...|[{document, 0, 51...|[{token, 0, 5, Ex...|[{pos, 0, 5, me,,...|[{named_entity, 0...|\n",
      "|It I'd In The The...|[{document, 0, 41...|[{document, 0, 41...|[{token, 0, 1, It...|[{pos, 0, 1, isn'...|[{named_entity, 0...|\n",
      "|                God,|[{document, 0, 3,...|[{document, 0, 3,...|[{token, 0, 3, Go...|[{pos, 0, 3, this...|[{named_entity, 0...|\n",
      "|The The Dr. We'll...|[{document, 0, 52...|[{document, 0, 52...|[{token, 0, 2, Th...|[{pos, 0, 2, scor...|[{named_entity, 0...|\n",
      "|You're It's We'll...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 5, Yo...|[{pos, 0, 5, out,...|[{named_entity, 0...|\n",
      "|What He I It's Th...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Wh...|[{pos, 0, 3, on, ...|[{named_entity, 0...|\n",
      "|The The We The Th...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 2, Th...|[{pos, 0, 2, caus...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "NvqHtYrsb-5L"
   },
   "outputs": [],
   "source": [
    "conll_df5 = CoNLL().readDataset(spark, \"s3://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnaRIT8fcBj2",
    "outputId": "157bedff-26ef-4124-9730-e13093c42e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             # # # #|[{document, 0, 6,...|[{document, 0, 6,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|               # # #|[{document, 0, 4,...|[{document, 0, 4,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|                 # #|[{document, 0, 2,...|[{document, 0, 2,...|[{token, 0, 0, #,...|[{pos, 0, 0, sent...|[{named_entity, 0...|\n",
      "|I Today Muiriel T...|[{document, 0, 55...|[{document, 0, 55...|[{token, 0, 0, I,...|[{pos, 0, 0, have...|[{named_entity, 0...|\n",
      "|I Why But I I It ...|[{document, 0, 44...|[{document, 0, 44...|[{token, 0, 0, I,...|[{pos, 0, 0, don'...|[{named_entity, 0...|\n",
      "|The Sail Nobody H...|[{document, 0, 88...|[{document, 0, 88...|[{token, 0, 2, Th...|[{pos, 0, 2, coas...|[{named_entity, 0...|\n",
      "|The The I In We W...|[{document, 0, 86...|[{document, 0, 86...|[{token, 0, 2, Th...|[{pos, 0, 2, spee...|[{named_entity, 0...|\n",
      "|If Do He Walk You...|[{document, 0, 11...|[{document, 0, 11...|[{token, 0, 1, If...|[{pos, 0, 1, it's...|[{named_entity, 0...|\n",
      "|Do Do I If I If I...|[{document, 0, 38...|[{document, 0, 38...|[{token, 0, 1, Do...|[{pos, 0, 1, you,...|[{named_entity, 0...|\n",
      "|Of Of Of As Of I ...|[{document, 0, 34...|[{document, 0, 34...|[{token, 0, 1, Of...|[{pos, 0, 1, cour...|[{named_entity, 0...|\n",
      "|Do I I It's It's ...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 1, Do...|[{pos, 0, 1, you,...|[{named_entity, 0...|\n",
      "|How How What What...|[{document, 0, 12...|[{document, 0, 12...|[{token, 0, 2, Ho...|[{pos, 0, 2, pers...|[{named_entity, 0...|\n",
      "|Because Because B...|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 6, Be...|[{pos, 0, 6, he, ...|[{named_entity, 0...|\n",
      "|Excuse Will Can K...|[{document, 0, 51...|[{document, 0, 51...|[{token, 0, 5, Ex...|[{pos, 0, 5, me,,...|[{named_entity, 0...|\n",
      "|It I'd In The The...|[{document, 0, 41...|[{document, 0, 41...|[{token, 0, 1, It...|[{pos, 0, 1, isn'...|[{named_entity, 0...|\n",
      "|                God,|[{document, 0, 3,...|[{document, 0, 3,...|[{token, 0, 3, Go...|[{pos, 0, 3, this...|[{named_entity, 0...|\n",
      "|The The Dr. We'll...|[{document, 0, 52...|[{document, 0, 52...|[{token, 0, 2, Th...|[{pos, 0, 2, scor...|[{named_entity, 0...|\n",
      "|You're It's We'll...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 5, Yo...|[{pos, 0, 5, out,...|[{named_entity, 0...|\n",
      "|What He I It's Th...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Wh...|[{pos, 0, 3, on, ...|[{named_entity, 0...|\n",
      "|The The We The Th...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 2, Th...|[{pos, 0, 2, caus...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HpIl4InWXuar"
   },
   "outputs": [],
   "source": [
    "conll_df6 = CoNLL().readDataset(spark, \"./datasets/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4JAX7vcX1BR",
    "outputId": "2383e9cc-d95d-45ae-80c3-fd11a1677e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             # # # #|[{document, 0, 6,...|[{document, 0, 6,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|               # # #|[{document, 0, 4,...|[{document, 0, 4,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|                 # #|[{document, 0, 2,...|[{document, 0, 2,...|[{token, 0, 0, #,...|[{pos, 0, 0, sent...|[{named_entity, 0...|\n",
      "|          Pierre|NNP|[{document, 0, 9,...|[{document, 0, 9,...|[{token, 0, 9, Pi...|[{pos, 0, 9, Vink...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HudQ8haEYCeN"
   },
   "outputs": [],
   "source": [
    "conll_df7 = CoNLL().readDataset(spark, \"file:///content/datasets/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AcduACzYLB8",
    "outputId": "ee8d6d6c-88e8-42d7-a96d-77c8b163a39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|             # # # #|[{document, 0, 6,...|[{document, 0, 6,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|               # # #|[{document, 0, 4,...|[{document, 0, 4,...|[{token, 0, 0, #,...|[{pos, 0, 0, newd...|[{named_entity, 0...|\n",
      "|                 # #|[{document, 0, 2,...|[{document, 0, 2,...|[{token, 0, 0, #,...|[{pos, 0, 0, sent...|[{named_entity, 0...|\n",
      "|          Pierre|NNP|[{document, 0, 9,...|[{document, 0, 9,...|[{token, 0, 9, Pi...|[{pos, 0, 9, Vink...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|John Smith works ...|[{document, 0, 35...|[{document, 0, 35...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conll_df7.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtrboxtGSuS0"
   },
   "source": [
    "## POS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_oMaT4R7Sq_k"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "X_GQ0U51VK3N"
   },
   "outputs": [],
   "source": [
    "pos = POS()\n",
    "posDf = pos.readDataset(spark, \"./datasets/test-training.txt\", \"|\", \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y0NC8dbVVcV",
    "outputId": "e5336742-eb35-4864-d15e-7f6758936452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|tags                                         |\n",
      "+---------------------------------------------+\n",
      "|{pos, 0, 5, NNP, {word -> Pierre}, []}       |\n",
      "|{pos, 7, 12, NNP, {word -> Vinken}, []}      |\n",
      "|{pos, 14, 14, ,, {word -> ,}, []}            |\n",
      "|{pos, 16, 17, CD, {word -> 61}, []}          |\n",
      "|{pos, 19, 23, NNS, {word -> years}, []}      |\n",
      "|{pos, 25, 27, JJ, {word -> old}, []}         |\n",
      "|{pos, 29, 29, ,, {word -> ,}, []}            |\n",
      "|{pos, 31, 34, MD, {word -> will}, []}        |\n",
      "|{pos, 36, 39, VB, {word -> join}, []}        |\n",
      "|{pos, 41, 43, DT, {word -> the}, []}         |\n",
      "|{pos, 45, 49, NN, {word -> board}, []}       |\n",
      "|{pos, 51, 52, IN, {word -> as}, []}          |\n",
      "|{pos, 47, 47, DT, {word -> a}, []}           |\n",
      "|{pos, 56, 67, JJ, {word -> nonexecutive}, []}|\n",
      "|{pos, 69, 76, NN, {word -> director}, []}    |\n",
      "|{pos, 78, 81, NNP, {word -> Nov.}, []}       |\n",
      "|{pos, 83, 84, CD, {word -> 29}, []}          |\n",
      "|{pos, 81, 81, ., {word -> .}, []}            |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posDf.selectExpr(\"explode(tags) as tags\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Fu58e7l2VvhX"
   },
   "outputs": [],
   "source": [
    "posDf2 = pos.readDataset(spark, \"file:///content/datasets/test-training.txt\", \"|\", \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkG3becIV1vD",
    "outputId": "af765da2-b659-41c0-edea-2f5a04359f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|tags                                         |\n",
      "+---------------------------------------------+\n",
      "|{pos, 0, 5, NNP, {word -> Pierre}, []}       |\n",
      "|{pos, 7, 12, NNP, {word -> Vinken}, []}      |\n",
      "|{pos, 14, 14, ,, {word -> ,}, []}            |\n",
      "|{pos, 16, 17, CD, {word -> 61}, []}          |\n",
      "|{pos, 19, 23, NNS, {word -> years}, []}      |\n",
      "|{pos, 25, 27, JJ, {word -> old}, []}         |\n",
      "|{pos, 29, 29, ,, {word -> ,}, []}            |\n",
      "|{pos, 31, 34, MD, {word -> will}, []}        |\n",
      "|{pos, 36, 39, VB, {word -> join}, []}        |\n",
      "|{pos, 41, 43, DT, {word -> the}, []}         |\n",
      "|{pos, 45, 49, NN, {word -> board}, []}       |\n",
      "|{pos, 51, 52, IN, {word -> as}, []}          |\n",
      "|{pos, 47, 47, DT, {word -> a}, []}           |\n",
      "|{pos, 56, 67, JJ, {word -> nonexecutive}, []}|\n",
      "|{pos, 69, 76, NN, {word -> director}, []}    |\n",
      "|{pos, 78, 81, NNP, {word -> Nov.}, []}       |\n",
      "|{pos, 83, 84, CD, {word -> 29}, []}          |\n",
      "|{pos, 81, 81, ., {word -> .}, []}            |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posDf2.selectExpr(\"explode(tags) as tags\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "05CGn1myV4Yl"
   },
   "outputs": [],
   "source": [
    "posDf3 = pos.readDataset(spark, \"file:///content/datasets/test-training.txt\", \"|\", \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "xnTFGRfMWuRC"
   },
   "outputs": [],
   "source": [
    "posDf3 = pos.readDataset(spark, \"s3://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/test-training.txt\", \"|\", \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRgIEJIfny6N",
    "outputId": "27bbf5df-c58f-4681-dde8-18645e5adf3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|tags                                         |\n",
      "+---------------------------------------------+\n",
      "|{pos, 0, 5, NNP, {word -> Pierre}, []}       |\n",
      "|{pos, 7, 12, NNP, {word -> Vinken}, []}      |\n",
      "|{pos, 14, 14, ,, {word -> ,}, []}            |\n",
      "|{pos, 16, 17, CD, {word -> 61}, []}          |\n",
      "|{pos, 19, 23, NNS, {word -> years}, []}      |\n",
      "|{pos, 25, 27, JJ, {word -> old}, []}         |\n",
      "|{pos, 29, 29, ,, {word -> ,}, []}            |\n",
      "|{pos, 31, 34, MD, {word -> will}, []}        |\n",
      "|{pos, 36, 39, VB, {word -> join}, []}        |\n",
      "|{pos, 41, 43, DT, {word -> the}, []}         |\n",
      "|{pos, 45, 49, NN, {word -> board}, []}       |\n",
      "|{pos, 51, 52, IN, {word -> as}, []}          |\n",
      "|{pos, 47, 47, DT, {word -> a}, []}           |\n",
      "|{pos, 56, 67, JJ, {word -> nonexecutive}, []}|\n",
      "|{pos, 69, 76, NN, {word -> director}, []}    |\n",
      "|{pos, 78, 81, NNP, {word -> Nov.}, []}       |\n",
      "|{pos, 83, 84, CD, {word -> 29}, []}          |\n",
      "|{pos, 81, 81, ., {word -> .}, []}            |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posDf3.selectExpr(\"explode(tags) as tags\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "EHh-nrpzV9Q1"
   },
   "outputs": [],
   "source": [
    "posDf4 = pos.readDataset(spark, \"s3a://auxdata.johnsnowlabs.com/public/tmp/danilo/datasets/test-training.txt\", \"|\", \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxYShTBEW2Lx",
    "outputId": "81a0b894-e37f-4f50-d7eb-b28c512494a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|tags                                         |\n",
      "+---------------------------------------------+\n",
      "|{pos, 0, 5, NNP, {word -> Pierre}, []}       |\n",
      "|{pos, 7, 12, NNP, {word -> Vinken}, []}      |\n",
      "|{pos, 14, 14, ,, {word -> ,}, []}            |\n",
      "|{pos, 16, 17, CD, {word -> 61}, []}          |\n",
      "|{pos, 19, 23, NNS, {word -> years}, []}      |\n",
      "|{pos, 25, 27, JJ, {word -> old}, []}         |\n",
      "|{pos, 29, 29, ,, {word -> ,}, []}            |\n",
      "|{pos, 31, 34, MD, {word -> will}, []}        |\n",
      "|{pos, 36, 39, VB, {word -> join}, []}        |\n",
      "|{pos, 41, 43, DT, {word -> the}, []}         |\n",
      "|{pos, 45, 49, NN, {word -> board}, []}       |\n",
      "|{pos, 51, 52, IN, {word -> as}, []}          |\n",
      "|{pos, 47, 47, DT, {word -> a}, []}           |\n",
      "|{pos, 56, 67, JJ, {word -> nonexecutive}, []}|\n",
      "|{pos, 69, 76, NN, {word -> director}, []}    |\n",
      "|{pos, 78, 81, NNP, {word -> Nov.}, []}       |\n",
      "|{pos, 83, 84, CD, {word -> 29}, []}          |\n",
      "|{pos, 81, 81, ., {word -> .}, []}            |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posDf4.selectExpr(\"explode(tags) as tags\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "RrOhwoGzjXck"
   },
   "outputs": [],
   "source": [
    "posDf5 = pos.readDataset(spark, \"file://content/datasets/test-training.txt\", \"|\", \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSuHNDtWtkVg",
    "outputId": "5a8a4a30-d0c0-4e24-b28d-6833e4aef9eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|tags                                         |\n",
      "+---------------------------------------------+\n",
      "|{pos, 0, 5, NNP, {word -> Pierre}, []}       |\n",
      "|{pos, 7, 12, NNP, {word -> Vinken}, []}      |\n",
      "|{pos, 14, 14, ,, {word -> ,}, []}            |\n",
      "|{pos, 16, 17, CD, {word -> 61}, []}          |\n",
      "|{pos, 19, 23, NNS, {word -> years}, []}      |\n",
      "|{pos, 25, 27, JJ, {word -> old}, []}         |\n",
      "|{pos, 29, 29, ,, {word -> ,}, []}            |\n",
      "|{pos, 31, 34, MD, {word -> will}, []}        |\n",
      "|{pos, 36, 39, VB, {word -> join}, []}        |\n",
      "|{pos, 41, 43, DT, {word -> the}, []}         |\n",
      "|{pos, 45, 49, NN, {word -> board}, []}       |\n",
      "|{pos, 51, 52, IN, {word -> as}, []}          |\n",
      "|{pos, 47, 47, DT, {word -> a}, []}           |\n",
      "|{pos, 56, 67, JJ, {word -> nonexecutive}, []}|\n",
      "|{pos, 69, 76, NN, {word -> director}, []}    |\n",
      "|{pos, 78, 81, NNP, {word -> Nov.}, []}       |\n",
      "|{pos, 83, 84, CD, {word -> 29}, []}          |\n",
      "|{pos, 81, 81, ., {word -> .}, []}            |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "posDf5.selectExpr(\"explode(tags) as tags\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
