{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI2vj-VJyzM-"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfXHpaBVy8PY",
    "outputId": "a66383aa-fffc-4f50-c2b4-2c6311985c86"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 11:57:17--  http://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
      "--2022-12-23 11:57:17--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-23 11:57:17--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 11:57:17 (34.3 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "\u001B[K     |████████████████████████████████| 281.5 MB 44 kB/s \n",
      "\u001B[K     |████████████████████████████████| 453 kB 49.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 199 kB 50.6 MB/s \n",
      "\u001B[?25h  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3lJrZweyzNA"
   },
   "source": [
    "## Vivekn Sentiment Analysis\n",
    "\n",
    "In the following example, we walk-through Sentiment Analysis training and prediction using Spark NLP Annotators.\n",
    "\n",
    "The ViveknSentimentApproach annotator will compute [Vivek Narayanan algorithm](https://arxiv.org/pdf/1305.6143.pdf) with either a column in training dataset with rows labelled 'positive' or 'negative' or a folder full of positive text and a folder with negative text. Using n-grams and negation of sequences, this statistical model can achieve high accuracy if trained properly.\n",
    "\n",
    "Spark can be leveraged in training by utilizing ReadAs.Dataset setting. Spark will be used during prediction by default.\n",
    "\n",
    "We also include in this pipeline a spell checker which shall correct our sentences for better Sentiment Analysis accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWmdcLPGyzNB"
   },
   "source": [
    "#### 1. Call necessary imports and set the resource path to read local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1KcgP4dWyzNC"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import array_contains,when\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvGfY8_jyzNI"
   },
   "source": [
    "#### 2. Load SparkSession if not already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oycji8wiyzNJ",
    "outputId": "3604d242-a35f-4faa-8c5c-f29d603d807e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spark NLP version:  4.2.6\n",
      "Apache Spark version:  3.2.3\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4gVI6pwyzNP",
    "outputId": "751df905-954c-4707-88cf-8dc7f6fb941a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 11:59:02--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.166.48, 52.217.203.104, 3.5.20.150, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.166.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4862966 (4.6M) [text/plain]\n",
      "Saving to: ‘/tmp/words.txt’\n",
      "\n",
      "words.txt           100%[===================>]   4.64M  30.9MB/s    in 0.2s    \n",
      "\n",
      "2022-12-23 11:59:03 (30.9 MB/s) - ‘/tmp/words.txt’ saved [4862966/4862966]\n",
      "\n",
      "--2022-12-23 11:59:03--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.166.48, 52.217.203.104, 3.5.20.150, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.166.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76127532 (73M) [application/zip]\n",
      "Saving to: ‘/tmp/sentiment.parquet.zip’\n",
      "\n",
      "sentiment.parquet.z 100%[===================>]  72.60M  55.2MB/s    in 1.3s    \n",
      "\n",
      "2022-12-23 11:59:05 (55.2 MB/s) - ‘/tmp/sentiment.parquet.zip’ saved [76127532/76127532]\n",
      "\n",
      "Archive:  /tmp/sentiment.parquet.zip\n",
      "   creating: /tmp/sentiment.parquet/\n",
      "  inflating: /tmp/sentiment.parquet/.part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      " extracting: /tmp/sentiment.parquet/_SUCCESS  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n"
     ]
    }
   ],
   "source": [
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt -P /tmp\n",
    "!rm -rf /tmp/sentiment.parquet\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip -P /tmp\n",
    "! unzip /tmp/sentiment.parquet.zip -d /tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-8QQ6YMyzNZ"
   },
   "source": [
    " #### 3. Load a spark dataset and put it in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6iVXyeX5yzNa",
    "outputId": "233cdf4f-be44-4e38-d115-bd5e56653a29"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------+--------------------+---------------+\n",
      "|itemid|sentiment|                text|sentiment_label|\n",
      "+------+---------+--------------------+---------------+\n",
      "|     1|        0|                 ...|       negative|\n",
      "|     2|        0|                 ...|       negative|\n",
      "|     3|        1|              omg...|       positive|\n",
      "|     4|        0|          .. Omga...|       negative|\n",
      "|     5|        0|         i think ...|       negative|\n",
      "|     6|        0|         or i jus...|       negative|\n",
      "|     7|        1|       Juuuuuuuuu...|       positive|\n",
      "|     8|        0|       Sunny Agai...|       negative|\n",
      "|     9|        1|      handed in m...|       positive|\n",
      "|    10|        1|      hmmmm.... i...|       positive|\n",
      "|    11|        0|      I must thin...|       negative|\n",
      "|    12|        1|      thanks to a...|       positive|\n",
      "|    13|        0|      this weeken...|       negative|\n",
      "|    14|        0|     jb isnt show...|       negative|\n",
      "|    15|        0|     ok thats it ...|       negative|\n",
      "|    16|        0|    &lt;-------- ...|       negative|\n",
      "|    17|        0|    awhhe man.......|       negative|\n",
      "|    18|        1|    Feeling stran...|       positive|\n",
      "|    19|        0|    HUGE roll of ...|       negative|\n",
      "|    20|        0|    I just cut my...|       negative|\n",
      "+------+---------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the input data to be annotated\n",
    "#We change 0 and 1 with negative and positive\n",
    "data = spark. \\\n",
    "        read. \\\n",
    "        parquet(\"/tmp/sentiment.parquet\"). \\\n",
    "        withColumn(\"sentiment_label\", when(col(\"sentiment\") == 0, \"negative\").otherwise(\"positive\")). \\\n",
    "        limit(1000).cache()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTiRUnXHyzNi"
   },
   "source": [
    "#### 4. Create the document assembler, which will put target text column into Annotation form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I7kDWrFZyzNj"
   },
   "outputs": [],
   "source": [
    "### Define the dataframe\n",
    "document_assembler = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\")\\\n",
    "            .setOutputCol(\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Vi5ImpwyzNq",
    "outputId": "71448be7-be60-4689-95ad-6ec6c21ecaac"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------+--------------------+---------------+--------------------+\n",
      "|itemid|sentiment|                text|sentiment_label|            document|\n",
      "+------+---------+--------------------+---------------+--------------------+\n",
      "|     1|        0|                 ...|       negative|[{document, 0, 60...|\n",
      "|     2|        0|                 ...|       negative|[{document, 0, 50...|\n",
      "|     3|        1|              omg...|       positive|[{document, 0, 36...|\n",
      "|     4|        0|          .. Omga...|       negative|[{document, 0, 13...|\n",
      "|     5|        0|         i think ...|       negative|[{document, 0, 52...|\n",
      "+------+---------+--------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example: Checkout the output of document assembler\n",
    "assembled = document_assembler.transform(data)\n",
    "assembled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqFWhtGZyzN0"
   },
   "source": [
    "#### 5. Create Sentence detector to parse sub sentences in every document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HK4qRt2tyzN1"
   },
   "outputs": [],
   "source": [
    "### Sentence detector\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pkcAyQnyzN8",
    "outputId": "aabb86f1-1515-403b-deb8-f22bc0d130a8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------+--------------------+---------------+--------------------+--------------------+\n",
      "|itemid|sentiment|                text|sentiment_label|            document|            sentence|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+\n",
      "|     1|        0|                 ...|       negative|[{document, 0, 60...|[{document, 21, 4...|\n",
      "|     2|        0|                 ...|       negative|[{document, 0, 50...|[{document, 19, 4...|\n",
      "|     3|        1|              omg...|       positive|[{document, 0, 36...|[{document, 14, 3...|\n",
      "|     4|        0|          .. Omga...|       negative|[{document, 0, 13...|[{document, 10, 1...|\n",
      "|     5|        0|         i think ...|       negative|[{document, 0, 52...|[{document, 9, 42...|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example: Checkout the output of sentence detector\n",
    "sentence_data = sentence_detector.transform(assembled)\n",
    "sentence_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaVLnDbxyzOA"
   },
   "source": [
    "#### 6. The tokenizer will match standard tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vwBEG3y6yzOB"
   },
   "outputs": [],
   "source": [
    "### Tokenizer\n",
    "tokenizer = Tokenizer() \\\n",
    "            .setInputCols([\"sentence\"]) \\\n",
    "            .setOutputCol(\"token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40PP804uyzOE",
    "outputId": "84e55609-a666-4f65-c91f-f5cc648f58b0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|itemid|sentiment|                text|sentiment_label|            document|            sentence|               token|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|     1|        0|                 ...|       negative|[{document, 0, 60...|[{document, 21, 4...|[{token, 21, 22, ...|\n",
      "|     2|        0|                 ...|       negative|[{document, 0, 50...|[{document, 19, 4...|[{token, 19, 19, ...|\n",
      "|     3|        1|              omg...|       positive|[{document, 0, 36...|[{document, 14, 3...|[{token, 14, 16, ...|\n",
      "|     4|        0|          .. Omga...|       negative|[{document, 0, 13...|[{document, 10, 1...|[{token, 10, 10, ...|\n",
      "|     5|        0|         i think ...|       negative|[{document, 0, 52...|[{document, 9, 42...|[{token, 9, 9, i,...|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example: Checkout the outout of tokenizer\n",
    "tokenized = tokenizer.fit(sentence_data).transform(sentence_data)\n",
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LhoPH8fyzOJ"
   },
   "source": [
    "#### 7. Normalizer will clean out the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cDOtkZF7yzOK"
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvMB0iMGyzOP"
   },
   "source": [
    "#### 8. The spell checker will correct normalized tokens, this trains with a dictionary of english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_EziC6v0yzOP"
   },
   "outputs": [],
   "source": [
    "### Spell Checker\n",
    "spell_checker = NorvigSweetingApproach() \\\n",
    "            .setInputCols([\"normal\"]) \\\n",
    "            .setOutputCol(\"spell\") \\\n",
    "            .setDictionary(\"/tmp/words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0zDsQloyzOT"
   },
   "source": [
    "#### 9. Create the ViveknSentimentApproach and set resources to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jgGbnXcryzOU"
   },
   "outputs": [],
   "source": [
    "sentiment_detector = ViveknSentimentApproach() \\\n",
    "    .setInputCols([\"spell\", \"sentence\"])\\\n",
    "    .setOutputCol(\"sentiment\")\\\n",
    "    .setSentimentCol(\"sentiment_label\")\\\n",
    "    .setPruneCorpus(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A1uXXmxyzOd"
   },
   "source": [
    "#### 10. The finisher will utilize sentiment analysis output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EcJeVOzVyzOe"
   },
   "outputs": [],
   "source": [
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"sentiment\"]) \\\n",
    "    .setIncludeMetadata(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccQhdcDXyzOk"
   },
   "source": [
    "##### 11. Fit and predict over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btpI76ViyzOl",
    "outputId": "9b8b6718-6268-4f27-ec79-9e7444658d27"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time elapsed pipeline process: 22.8889741897583\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    normalizer,\n",
    "    spell_checker,\n",
    "    sentiment_detector,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "sentiment_data = pipeline.fit(data).transform(data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed pipeline process: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcYkKyN-yzOq"
   },
   "source": [
    "##### 13. Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdOIFzD7yzOr",
    "outputId": "e068d899-37aa-407d-89ff-ae64c3711de8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+------------------------------------------------------------------------------------------------------------------------------------+---------------+----------------------------------------+\n",
      "|itemid|text                                                                                                                                |sentiment_label|finished_sentiment                      |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------+---------------+----------------------------------------+\n",
      "|1     |                     is so sad for my APL friend.............                                                                       |negative       |[negative]                              |\n",
      "|2     |                   I missed the New Moon trailer...                                                                                 |negative       |[negative]                              |\n",
      "|3     |              omg its already 7:30 :O                                                                                               |positive       |[positive]                              |\n",
      "|4     |          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...|negative       |[negative, negative, negative, negative]|\n",
      "|5     |         i think mi bf is cheating on me!!!       T_T                                                                               |negative       |[negative, na]                          |\n",
      "+------+------------------------------------------------------------------------------------------------------------------------------------+---------------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_data.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPvfyTPdyzOw",
    "outputId": "72cfc7fd-a27a-45e2-f1bc-512648c4874d"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "type(sentiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0vCTEo5yzO2",
    "outputId": "86a45c72-ff86-4489-9704-601363130a58"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is so sad for my APL friend............. -> ['negative']\n",
      "I missed the New Moon trailer... -> ['negative']\n",
      ".. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)... -> ['negative', 'negative', 'negative', 'negative']\n",
      "i think mi bf is cheating on me!!!       T_T -> ['negative', 'na']\n",
      "or i just worry too much? -> ['negative']\n"
     ]
    }
   ],
   "source": [
    "# Negative Sentiments\n",
    "for r in sentiment_data.where(array_contains(sentiment_data.finished_sentiment, \"negative\")).take(5):\n",
    "    print(r['text'].strip(),\"->\",r['finished_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MM47a2PHyzPC",
    "outputId": "df713d0a-7d7b-45ab-8e22-ed13242a2bfe"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "omg its already 7:30 :O -> ['positive']\n",
      "Juuuuuuuuuuuuuuuuussssst Chillin!! -> ['positive']\n",
      "handed in my uniform today . i miss you already -> ['positive', 'negative']\n",
      "hmmmm.... i wonder how she my number @-) -> ['na', 'positive']\n",
      "thanks to all the haters up in my face all day! 112-102 -> ['positive']\n"
     ]
    }
   ],
   "source": [
    "# Positive Sentiments\n",
    "for r in sentiment_data.where(array_contains(sentiment_data.finished_sentiment, \"positive\")).take(5):\n",
    "    print(r['text'].strip(),\"->\",r['finished_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9QagrcsKyzPK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "VivekNarayanSentimentApproach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
