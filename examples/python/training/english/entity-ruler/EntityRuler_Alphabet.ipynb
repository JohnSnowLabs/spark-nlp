{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/entity-ruler/EntityRuler_Alphabet.ipynb)\n",
    "\n",
    "# Defining EntityRuler with an Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this Cell when you are using Spark NLP on Google Colab\n",
    "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Spark NLP version 4.3.1, we reduce significantly the latency of Entity Ruler by implementing Aho-Corasick algorithm. This requires defining an alphabet for some cases. For English documents, you won't need to define it because under the hood Entity Ruler annotator uses an English alphabet by default. However, for special use cases we will need to proceed like the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|text                           |\n",
      "+-------------------------------+\n",
      "|Elendil used to live in Númenor|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([[\"Elendil used to live in Númenor\"]]).toDF(\"text\")\n",
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text above has an special character, an accent in vowel u (ú)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "locations = [\n",
    "              {\n",
    "                \"id\": \"locations\",\n",
    "                \"label\": \"LOCATION\",\n",
    "                \"patterns\": [\"Númenor\", \"Middle-earth\"]\n",
    "              }\n",
    "            ]\n",
    "\n",
    "with open('./locations.json', 'w') as jsonlfile:\n",
    "  json.dump(locations, jsonlfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a pattern in `locations.json` file has also hyphen punctuation mark (-).\n",
    "So, we need to define our custom alphabet to use Entity Ruler for Tolkien's books. Here, we will define just the 2 special characters for our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "with open('./custom_alphabet.txt', 'w') as alphabet_file:\n",
    "    alphabet_file.write(alphabet + \"\\n\")\n",
    "    alphabet_file.write(alphabet.upper() + \"\\n\")\n",
    "    alphabet_file.write(\"ú\")\n",
    "    alphabet_file.write(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n",
      "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "ú-"
     ]
    }
   ],
   "source": [
    "!cat custom_alphabet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sentence_detector = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
    "\n",
    "entity_ruler = EntityRulerApproach() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"entity\") \\\n",
    "    .setPatternsResource(\"./locations.json\") \\\n",
    "    .setAlphabetResource(\"./custom_alphabet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, entity_ruler])\n",
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+\n",
      "|entity                                                                              |\n",
      "+------------------------------------------------------------------------------------+\n",
      "|[{chunk, 24, 30, Númenor, {entity -> LOCATION, sentence -> 0, id -> locations}, []}]|\n",
      "+------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(data).select(\"entity\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't define the required alphabet, you will get this error: \n",
    "\n",
    "```\n",
    "Py4JJavaError: An error occurred while calling o69.fit.\n",
    ": java.lang.UnsupportedOperationException: Char ú not found on alphabet. Please check alphabet\n",
    "```\n",
    "So, the alphabet must have **all the characters** that can be found in your document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-English Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EntityRuler has some predefined alphabets for the most common languages: English, Spanish, French, and German. So, if you have documents in Spanish, you just need to set an alphabet like the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|text                          |\n",
      "+------------------------------+\n",
      "|Elendil solía vivir en Númenor|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([[\"Elendil solía vivir en Númenor\"]]).toDF(\"text\")\n",
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ruler = EntityRulerApproach() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"entity\") \\\n",
    "    .setPatternsResource(\"./locations.json\") \\\n",
    "    .setAlphabetResource(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, entity_ruler])\n",
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+\n",
      "|entity                                                                              |\n",
      "+------------------------------------------------------------------------------------+\n",
      "|[{chunk, 23, 29, Númenor, {entity -> LOCATION, sentence -> 0, id -> locations}, []}]|\n",
      "+------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(data).select(\"entity\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your language is not a predefined alphabet, you will need to define all the characters of your alphabet, as shown in the first example. \n",
    "Keep in mind that an alphabet may require not only letters but also numbers, punctuation marks, and symbol characters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOn3VALFVB6JhjiE7SBwc48",
   "name": "EntityRuler Alphabet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
