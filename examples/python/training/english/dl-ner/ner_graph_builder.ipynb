{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotator to build a Graph for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDHwES6rTGHd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from sparknlp.training import CoNLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites for TFNerDLGraphBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This annotator only works in Python since we need to build a tensorflow graph, `TFNerDLGraphBuilder` requires this packages:\n",
    "1. Tensorflow 2.xx or 1.15\n",
    "2. Tensorflow addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tfv686d8XXF4",
    "outputId": "1d6fff57-c0c3-4d39-eddf-3be620ad7a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.17.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we need to set `GraphFolder` parameter with the location to store our graph. We have 3 options to do this:\n",
    "- Local File System: `/home/my_user/ner_graphs/`\n",
    "- Distributed File System: `hdfs://my_cluster/my_path/ner_graphs` or `dbfs:/my_databricks_path/ner_graphs`\n",
    "- S3: `s3://my_bucket/my_path/ner_graphs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When storing on S3, we need to define AWS credentials and region when starting a spark session as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkLNhaUOXthX",
    "outputId": "caa03c8c-443f-470c-e4a4-e61aedf8ab88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.2.0\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkNLP\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12G\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.1.0\") \\\n",
    "    .config(\"spark.jsl.settings.aws.credentials.access_key_id\", \"MY_ACCESS_KEY_ID\") \\\n",
    "    .config(\"spark.jsl.settings.aws.credentials.secret_access_key\", \"MY_SECRET_ACCESS_KEY\") \\\n",
    "    .config(\"spark:spark.jsl.settings.aws.credentials.session_token\", \"MY_SESSION_TOKEN\") \\\n",
    "    .config(\"spark.jsl.settings.aws.region\", \"MY_AWS_REGION\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Apache Spark version: {}\".format(spark.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check how to start a spark session with spark-nlp based on your environment [here]( https://github.com/JohnSnowLabs/spark-nlp#usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iernkDqnS-pE"
   },
   "source": [
    "We use a variable to define the location that we will set to generate the graph. This example uses S3, but we can define a local, HDFS or DBFS path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqlL6Q5QS7ov"
   },
   "outputs": [],
   "source": [
    "graph_folder = \"s3://my_bucket/my_path/ner_graphs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfxK9do4THUg"
   },
   "source": [
    "### Prepare NER test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UmKEfSLTJZK",
    "outputId": "e16b9eaf-896e-45b1-87c5-36ef0ea7502f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "conll = CoNLL()\n",
    "\n",
    "train_data = conll.readDataset(spark=spark, path=\"./eng.testa\").limit(1000)\n",
    "test_data = conll.readDataset(spark=spark, path=\"./eng.testa\").limit(1000)\n",
    "\n",
    "embeddings = WordEmbeddingsModel \\\n",
    "    .pretrained() \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "test_data_parquet_path = \"./tmp/test_data_parquet\"\n",
    "\n",
    "embeddings.transform(test_data).write.mode(\"overwrite\").parquet(test_data_parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with TFNerDLGraphBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdKW3pzCURcW"
   },
   "source": [
    "We define `TFNerDLGraphBuilder` to generate the graph and store it in the selected folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AE0AU1-dUTFD"
   },
   "outputs": [],
   "source": [
    "graph_builder = TFNerDLGraphBuilder()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setGraphFile(\"auto\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setHiddenUnitsNumber(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzlNfjseUVId"
   },
   "source": [
    "Then, we use `NerApproach`and let it use the graph generated by the builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCdKfBnAUUTT"
   },
   "outputs": [],
   "source": [
    "ner_dl = NerDLApproach() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\") \\\n",
    "    .setOutputCol(\"ner\") \\\n",
    "    .setMaxEpochs(5) \\\n",
    "    .setLr(0.003) \\\n",
    "    .setBatchSize(8) \\\n",
    "    .setRandomSeed(0) \\\n",
    "    .setVerbose(1) \\\n",
    "    .setEvaluationLogExtended(False) \\\n",
    "    .setEnableOutputLogs(False) \\\n",
    "    .setIncludeConfidence(True) \\\n",
    "    .setTestDataset(test_data_parquet_path) \\\n",
    "    .setGraphFolder(graph_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Juz3SWgtUYF4"
   },
   "source": [
    "Put pipeline together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AUxaelHUZj0"
   },
   "outputs": [],
   "source": [
    "ner_pipeline = sparknlp.base.Pipeline().setStages([\n",
    "    embeddings, \n",
    "    graph_builder, \n",
    "    ner_dl    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGKNDnohUbOK"
   },
   "source": [
    "Fit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipeline.fit(train_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[Dev] TFNerDLGraphBuilder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
