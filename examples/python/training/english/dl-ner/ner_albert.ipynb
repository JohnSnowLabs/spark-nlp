{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZhJcUl06r8w"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_albert.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22mElNLo6rUI",
    "outputId": "4c094532-a49a-4453-a7b7-a901e634020c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 11:33:23--  http://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
      "--2022-12-23 11:33:23--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-23 11:33:24--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 11:33:25 (40.8 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "\u001B[K     |████████████████████████████████| 281.5 MB 49 kB/s \n",
      "\u001B[K     |████████████████████████████████| 453 kB 45.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 199 kB 53.9 MB/s \n",
      "\u001B[?25h  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_QE6hqA4WHh"
   },
   "source": [
    "# How to train a NER classifier with Albert embeddings based on Char CNNs - BiLSTM - CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wybDus1P4WHk"
   },
   "source": [
    "## Download the file into the local File System \n",
    "### It is a standard conll2003 format training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EA0QHrLF4WHl",
    "outputId": "6ff3cd78-94d3-4d7c-c4ad-2c5a0900cc14"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File Not found will downloading it!\n"
     ]
    }
   ],
   "source": [
    "# Download CoNLL 2003 Dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "download_path = \"./eng.train\"\n",
    "\n",
    "\n",
    "if not Path(download_path).is_file():\n",
    "    print(\"File Not found will downloading it!\")\n",
    "    url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
    "    urllib.request.urlretrieve(url, download_path)\n",
    "else:\n",
    "    printalbert(\"File already present.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYZhNUVH4WHs"
   },
   "source": [
    "# Read CoNLL Dataset into Spark dataframe and automagically generate features for futures tasks\n",
    "The readDataset method of the CoNLL class handily adds all the features required in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQExmc684WHu",
    "outputId": "6da2bb18-c211-4a21-c103-642c8c128ffc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|\n",
      "|     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|\n",
      "|The European Comm...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|\n",
      "|Germany 's repres...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|\n",
      "|\" We do n't suppo...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|\n",
      "|He said further s...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|\n",
      "|He said a proposa...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|\n",
      "|Fischler proposed...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, Fi...|[{pos, 0, 7, JJR,...|[{named_entity, 0...|\n",
      "|But Fischler agre...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 2, Bu...|[{pos, 0, 2, CC, ...|[{named_entity, 0...|\n",
      "|Spanish Farm Mini...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 6, Sp...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|\n",
      "|                   .|[{document, 0, 0,...|[{document, 0, 0,...|[{token, 0, 0, .,...|[{pos, 0, 0, ., {...|[{named_entity, 0...|\n",
      "|Only France and B...|[{document, 0, 52...|[{document, 0, 52...|[{token, 0, 3, On...|[{pos, 0, 3, RB, ...|[{named_entity, 0...|\n",
      "|The EU 's scienti...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|\n",
      "|Sheep have long b...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 4, Sh...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|\n",
      "|British farmers d...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Br...|[{pos, 0, 6, JJ, ...|[{named_entity, 0...|\n",
      "|\" What we have to...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|\n",
      "|Bonn has led effo...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 3, Bo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|\n",
      "|Germany imported ...|[{document, 0, 84...|[{document, 0, 84...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|\n",
      "|It brought in 4,2...|[{document, 0, 82...|[{document, 0, 82...|[{token, 0, 1, It...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.training import CoNLL\n",
    "\n",
    "spark = sparknlp.start()\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF9dJWoW4WH6"
   },
   "source": [
    "# Define the NER Pipeline \n",
    "\n",
    "### This pipeline defines a pretrained Albert component and a trainable NerDLApproach which is based on the Char CNN - BiLSTM - CRF\n",
    "\n",
    "Usually you have to add additional pipeline components before the Albert for the document, sentence and token columns. But Spark NLPs CoNLL class took already care of this for us, awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0xFttkH4WH7",
    "outputId": "13ebdfff-4ae4-4334-f684-871bc199d09a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert_base_uncased download started this may take some time.\n",
      "Approximate size to download 42.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Define the pretrained Albert model. \n",
    "albert = AlbertEmbeddings.pretrained().setInputCols(\"sentence\", \"token\")\\\n",
    " .setOutputCol(\"albert\")\\\n",
    "\n",
    "\n",
    "# Define the Char CNN - BiLSTM - CRF model. We will feed it the Albert tokens \n",
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"albert\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(1)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(0)\n",
    "\n",
    "# put everything into the pipe\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "      albert ,\n",
    "      nerTagger\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpcIr8b_4WIB"
   },
   "source": [
    "# Fit the Pipeline and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDKsFDRy4WIC",
    "outputId": "4f98bced-6e5b-4b9e-a30c-a3e28c32d46e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|              albert|                 ner|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|The European Comm...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Germany 's repres...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|\" We do n't suppo...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|He said further s...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|He said a proposa...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Fischler proposed...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, Fi...|[{pos, 0, 7, JJR,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|But Fischler agre...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 2, Bu...|[{pos, 0, 2, CC, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Spanish Farm Mini...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 6, Sp...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|                   .|[{document, 0, 0,...|[{document, 0, 0,...|[{token, 0, 0, .,...|[{pos, 0, 0, ., {...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Only France and B...|[{document, 0, 52...|[{document, 0, 52...|[{token, 0, 3, On...|[{pos, 0, 3, RB, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|The EU 's scienti...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Sheep have long b...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 4, Sh...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|British farmers d...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Br...|[{pos, 0, 6, JJ, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|\" What we have to...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Bonn has led effo...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 3, Bo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Germany imported ...|[{document, 0, 84...|[{document, 0, 84...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|It brought in 4,2...|[{document, 0, 82...|[{document, 0, 82...|[{token, 0, 1, It...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner_df = pipeline.fit(training_data.limit(10)).transform(training_data.limit(50))\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFSKuv-x4WIH"
   },
   "source": [
    "### Checkout only result columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObW2xBPn4WII",
    "outputId": "390e7c45-9138-4098-f49c-49a852c55949"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                            |ner                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|EU rejects German call to boycott British lamb .|[{named_entity, 0, 1, O, {word -> eu, sentence -> 0}, []}, {named_entity, 3, 9, O, {word -> rejects, sentence -> 0}, []}, {named_entity, 11, 16, O, {word -> german, sentence -> 0}, []}, {named_entity, 18, 21, O, {word -> call, sentence -> 0}, []}, {named_entity, 23, 24, O, {word -> to, sentence -> 0}, []}, {named_entity, 26, 32, O, {word -> boycott, sentence -> 0}, []}, {named_entity, 34, 40, O, {word -> british, sentence -> 0}, []}, {named_entity, 42, 45, O, {word -> lamb, sentence -> 0}, []}, {named_entity, 47, 47, O, {word -> ., sentence -> 0}, []}]|\n",
      "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner_df.select(*['text', 'ner']).limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEDXS6R9KtXm"
   },
   "source": [
    "## Alternative Albert models \n",
    "\n",
    "checkout https://github.com/JohnSnowLabs/spark-nlp-models for alternative models, the following are available :\n",
    "  * albert_base_uncased     = https://tfhub.dev/google/albert_base/3    |  768-embed-dim,   12-layer,  12-heads, 12M parameters\n",
    "  * albert_large_uncased    = https://tfhub.dev/google/albert_large/3   |  1024-embed-dim,  24-layer,  16-heads, 18M parameters\n",
    "  * albert_xlarge_uncased   = https://tfhub.dev/google/albert_xlarge/3  |  2048-embed-dim,  24-layer,  32-heads, 60M parameters\n",
    "  * albert_xxlarge_uncased  = https://tfhub.dev/google/albert_xxlarge/3 |  4096-embed-dim,  12-layer,  64-heads, 235M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XsIHHpAKp2-",
    "outputId": "80b92cd5-590f-4e1e-bce9-2d4c6889c586"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "albert_xxlarge_uncased download started this may take some time.\n",
      "Approximate size to download 795 MB\n",
      "[OK!]\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|              albert|                 ner|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|The European Comm...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Germany 's repres...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|\" We do n't suppo...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|He said further s...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|He said a proposa...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 1, He...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Fischler proposed...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, Fi...|[{pos, 0, 7, JJR,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|But Fischler agre...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 2, Bu...|[{pos, 0, 2, CC, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Spanish Farm Mini...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 6, Sp...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|                   .|[{document, 0, 0,...|[{document, 0, 0,...|[{token, 0, 0, .,...|[{pos, 0, 0, ., {...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Only France and B...|[{document, 0, 52...|[{document, 0, 52...|[{token, 0, 3, On...|[{pos, 0, 3, RB, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|The EU 's scienti...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Sheep have long b...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 4, Sh...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|British farmers d...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 6, Br...|[{pos, 0, 6, JJ, ...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|\" What we have to...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 0, \",...|[{pos, 0, 0, \", {...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Bonn has led effo...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 3, Bo...|[{pos, 0, 3, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|Germany imported ...|[{document, 0, 84...|[{document, 0, 84...|[{token, 0, 6, Ge...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|It brought in 4,2...|[{document, 0, 82...|[{document, 0, 82...|[{token, 0, 1, It...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{word_embeddings...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Define the pretrained Albert model. \n",
    "abert_variant = 'albert_xxlarge_uncased'\n",
    "albert = AlbertEmbeddings.pretrained(abert_variant ).setInputCols(\"sentence\", \"token\")\\\n",
    " .setOutputCol(\"albert\")\\\n",
    "\n",
    "\n",
    "# Define the Char CNN - BiLSTM - CRF model. We will feed it the Albert tokens \n",
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"albert\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(1)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(0)\n",
    "\n",
    "# put everything into the pipe\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "      albert ,\n",
    "      nerTagger\n",
    "  ])\n",
    "\n",
    "ner_df = pipeline.fit(training_data.limit(10)).transform(training_data.limit(50))\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9HkYsNFLTHD",
    "outputId": "5ff2a22e-a5aa-4d0b-d4cd-8138ab5e2cee"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                            |ner                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|EU rejects German call to boycott British lamb .|[{named_entity, 0, 1, O, {word -> eu, sentence -> 0}, []}, {named_entity, 3, 9, O, {word -> rejects, sentence -> 0}, []}, {named_entity, 11, 16, O, {word -> german, sentence -> 0}, []}, {named_entity, 18, 21, O, {word -> call, sentence -> 0}, []}, {named_entity, 23, 24, O, {word -> to, sentence -> 0}, []}, {named_entity, 26, 32, O, {word -> boycott, sentence -> 0}, []}, {named_entity, 34, 40, O, {word -> british, sentence -> 0}, []}, {named_entity, 42, 45, O, {word -> lamb, sentence -> 0}, []}, {named_entity, 47, 47, O, {word -> ., sentence -> 0}, []}]|\n",
      "+------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_df.select(*['text', 'ner']).limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TYCBAgL9LjL1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ner_albert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "NER-Tutorial",
  "notebookId": 3359671281044291
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
