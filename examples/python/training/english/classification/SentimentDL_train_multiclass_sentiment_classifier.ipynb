{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/classification/SentimentDL_train_multiclass_sentiment_classifier.ipynb)\n",
    "\n",
    "# Multi-class Sentiment Classification using SentimentDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run this block if you are inside Google Colab otherwise skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.3.1\n",
      "Apache Spark version 3.3.0\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download IMDB movie reviews dataset for training our multi-class sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-20 18:03:45--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_train.csv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.79.54, 52.216.35.184, 52.217.205.136, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.79.54|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33497180 (32M) [text/csv]\n",
      "Saving to: ‘aclimdb_train.csv’\n",
      "\n",
      "aclimdb_train.csv   100%[===================>]  31,95M  13,1MB/s    in 2,4s    \n",
      "\n",
      "2023-02-20 18:03:48 (13,1 MB/s) - ‘aclimdb_train.csv’ saved [33497180/33497180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O aclimdb_train.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-20 18:03:49--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_test.csv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.44.40, 54.231.171.192, 52.217.32.158, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.44.40|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 32715164 (31M) [text/csv]\n",
      "Saving to: ‘aclimdb_test.csv’\n",
      "\n",
      "aclimdb_test.csv    100%[===================>]  31,20M  14,6MB/s    in 2,1s    \n",
      "\n",
      "2023-02-20 18:03:52 (14,6 MB/s) - ‘aclimdb_test.csv’ saved [32715164/32715164]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O aclimdb_test.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text,label\n",
      "\"This is an Excellent little movie! The acting is good and the music is fantastic!! Play it on a 5-1 sound system and enjoy! It will never win any awards but its good clean fun for all!! I recommend this movie to all fans of pretty girls funny and hansom men as well as robot lovers everyone!!1 P.S. It also stars Lisa Rinna! Enjoy!!This is a very hard movie to find, It is out of print. I first saw it on Showtime many years ago but recently found a used VHS copy. Its still a must see for all!!!This is an Excellent little movie! The acting is good and the music is fantastic!! Play it on a 5-1 sound system and enjoy! It will never win any awards but its good clean fun for all!! I recommend this movie to all fans of pretty girls funny and hansom men as well as robot lovers everyone!!1 P.S. It also stars Lisa Rinna! Enjoy!! Dave Engle This is a very hard movie to find, It is out of print. I first saw it on Showtime many years ago but recently found a used VHS copy. Its still a must see for all!!!\",positive\n",
      "\"The Sarah Silverman program is very similar to Sarah's own stand up; It's so over the top with prejudice that you can't possibly take it to heart. The fact is, though, that while most all people will \\\"get it,\\\" it doesn't mean they will all appreciate it. It's a very polarizing and one dimensional show, so if you don't like it after 10 minutes, you may as well give up there. If you do like it after 10 minutes, stay tuned, because every episode thus far has been as good as the last.<br /><br />Like all shows, though, it is not perfect. Personally I love the program, but there are some huge faults with it. Racist songs are funny, but get older a lot faster than Silverman seems to realize--a problem that I had with \\\"Jesus is Magic\\\" as well. It seems as if Silverman gave herself a quota for songs per episode that doesn't need to exist. Not to mention that while the lyrics to the songs she writes are good, the music, well, isn't.<br /><br />Another thing to keep in mind is that while this show will for some reason appeal to fans of Monty Python, Upright Citizens Brigade, etc., it is nothing like those shows. I can watch Monty Python all day, but, as much as I like this show, I can't watch more than the half hour limit at a time. It gets flat very fast. The repeat value for this show is low too--the second time around an episode is fairly funny, and by the third time, in my opinion, it's boring.<br /><br />Still, that first time around is very, very funny. Give it a shot.\",positive\n",
      "\"\\\"Prom Night\\\" is a title-only remake of the 1980 slasher flick that starred Jamie Lee Curtis and Leslie Nielsen. This movie takes place in an Oregon town, where Donna (Brittany Snow) is about to go to her senior prom and let herself have some fun after going through some extremely traumatic events in the past few years. She and her friends arrive at the prom, which is taking place in a grand hotel, and try and enjoy what is supposed to be the most fun night of their lives. Little does anyone know, a man from Donna's past, who has haunted her for years, is also at the prom... and is willing to kill anyone in way of his pursuit of her.<br /><br />I'm a fan of the original \\\"Prom Night\\\", so I tried to maintain a little hope in this movie, but I have to admit I was quite disappointed. \\\"Prom Night\\\" suffers from the worst affliction a horror movie could have, and that is predictability. There are absolutely no surprises here, and I felt I had seen everything in this movie done dozens of times, often better, before. What does this equate to for the audience? Boredom. Unless of course you have never seen any horror movies, or are part of the pre-teen crowd, but the majority of the audience will most likely be able to guess nearly everything that is going to happen. The plot is simplistic, but the entire script is void of any type of surprise, twist, atmosphere, or anything, and this really, really hurts the movie because it never really gives the audience anything to sink their teeth into. It all just seemed very bland.<br /><br />A lot of people seem to complain with the fact that this is a PG-13 slasher movie as well, and I understand what they are saying, but I don't think it's impossible to make a good slasher movie with minimal gore. Take Carpenter's \\\"Halloween\\\" for example - little to no on screen violence, but still an extremely frightening and effective movie. You don't need gore to make a film scary, but even had \\\"Prom Night\\\" been gratuitously violent (which it is not, it is very tame), it still would have added little to the movie because there is not much in the script to build on to begin with. The tension and suspense here is mild at best, and I spent most of the movie predicting the outcome of situations, and was correct about 99% of the time. Our characters aren't well written enough either for the audience to make any connection to them, and their by-the-numbers demises are routine and careless.<br /><br />I will point out a few things I did like about this movie, though, because it wasn't completely useless - the cinematography is really nice, and everything was very well-filmed and fairly stylish. Among the \\\"jump\\\" scares (that are for the most part very predictable), there were a few that were kind of clever. The sets for the movie are nice too and the hotel is a neat place for the plot to unfold, however predictable the unfolding may be. As for the acting, it's mediocre at best. Brittany Snow plays the lead decently, but really the rest of the cast doesn't show off much talent. Johnathan Schaech plays the villain, and is probably the most experienced performer here, but even he isn't that impressive. However, I did like the character he played, which was a nice change from the typical 'masked-stalker' type killer we see a lot. As far as the ending goes, the last fifteen minutes of the film had me bored to my wit's end and it was very anti-climactic.<br /><br />Overall, \\\"Prom Night\\\" was a disappointment. Everything was very by-the-numbers, routine, and predictable, which is somewhat upsetting considering this had the potential to be a decent slasher movie. There were a few neat moments, but the movie lacked any suspense or atmosphere, and had little plot development, nor believable characters. I'd advise seasoned horror fans to save their money and wait till it's out on video, or rent the original instead, because there are absolutely no surprises here. Some may find a little entertainment in it, but it was far too predictable for my tastes. I expected better, and left the theater very disappointed. 3/10.\",negative\n",
      "\"So often a band will get together for a re-union concert only to find that they just can't get it together. Not so here. This concert is just shear brilliance from start to finish. These three musicians obviously got together beforehand and plotted and planned what was needed to ensure this was not just a nostalgic bash to satisfy someone's ego. This is obvious from the start, before they even step on stage. Many faces in the crowd weren't even born when these guys first performed. From the first song they capture that old magic that was Cream, 3 men, 3 instruments, no fuss. Clapton, by his own admission, said he had to stretch himself for this concert because there were no keyboards, synthesizers etc so we get to see him at his best. Ginger Baker demonstrates why so many drummers today, speak of him as some sort of drumming guru. Jack Bruce just great. They really managed to put together a piece of magic that will stand the test of time for many years to come. This one's a 10 for me.\",positive\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 aclimdb_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content is inside `text` column and the sentiment is inside `label` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"aclimdb_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                text|   label|\n",
      "+--------------------+--------+\n",
      "|This is an Excell...|positive|\n",
      "|The Sarah Silverm...|positive|\n",
      "|\"Prom Night\" is a...|negative|\n",
      "|So often a band w...|positive|\n",
      "|\"Pet Sematary\" is...|positive|\n",
      "|I watched the fil...|negative|\n",
      "|Boy this movie ha...|negative|\n",
      "|Checking the spoi...|negative|\n",
      "|Despite its rathe...|positive|\n",
      "|Absolute masterpi...|positive|\n",
      "|The tweedy profes...|positive|\n",
      "|A movie best summ...|negative|\n",
      "|Take young, prett...|negative|\n",
      "|For months I've b...|negative|\n",
      "|\"Batman: The Myst...|positive|\n",
      "|Well, it was funn...|negative|\n",
      "|I have seen the s...|positive|\n",
      "|Brainless film ab...|negative|\n",
      "|Leave it to geniu...|negative|\n",
      "|Seven Pounds star...|positive|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained() \\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "# the classes/labels/categories are in category column\n",
    "sentimentdl = SentimentDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setMaxEpochs(5)\\\n",
    "  .setEnableOutputLogs(True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 288\n",
      "-rw-r--r-- 1 root root 456 20. Feb 17:41 ClassifierDLApproach_0375e3a8df00.log\n",
      "-rw-r--r-- 1 root root 918 20. Feb 17:38 ClassifierDLApproach_6fdb8a569309.log\n",
      "-rw-r--r-- 1 root root 446 20. Feb 15:55 ClassifierDLApproach_97ff5c76d735.log\n",
      "-rw-r--r-- 1 root root 438 20. Feb 17:38 ClassifierMetrics_09bd6fa2ecf7.log\n",
      "-rw-r--r-- 1 root root 317 20. Feb 18:02 ClassifierMetrics_0b655035ca3d.log\n",
      "-rw-r--r-- 1 root root 317 10. Feb 16:54 ClassifierMetrics_17606bbb7d1f.log\n",
      "-rw-r--r-- 1 root root 571 20. Feb 17:45 ClassifierMetrics_176ce729caa6.log\n",
      "-rw-r--r-- 1 root root 327 20. Feb 18:02 ClassifierMetrics_19e043d5e316.log\n",
      "-rw-r--r-- 1 root root 313 10. Feb 16:54 ClassifierMetrics_1a6c515483ae.log\n",
      "-rw-r--r-- 1 root root 441 20. Feb 17:38 ClassifierMetrics_1e0c8ea78e67.log\n",
      "-rw-r--r-- 1 root root 323 10. Feb 16:54 ClassifierMetrics_2530315112a8.log\n",
      "-rw-r--r-- 1 root root 566 20. Feb 17:45 ClassifierMetrics_26e8744dc78c.log\n",
      "-rw-r--r-- 1 root root 565 20. Feb 17:45 ClassifierMetrics_284f041511fb.log\n",
      "-rw-r--r-- 1 root root 445 20. Feb 17:38 ClassifierMetrics_2b7b458fc84d.log\n",
      "-rw-r--r-- 1 root root 551 20. Feb 17:45 ClassifierMetrics_2fde2811a93c.log\n",
      "-rw-r--r-- 1 root root 323 20. Feb 18:02 ClassifierMetrics_3567e301a9ec.log\n",
      "-rw-r--r-- 1 root root 133 20. Feb 17:52 ClassifierMetrics_387f03f0b7a0.log\n",
      "-rw-r--r-- 1 root root 314 10. Feb 16:54 ClassifierMetrics_3ccf43933a23.log\n",
      "-rw-r--r-- 1 root root 132 20. Feb 17:59 ClassifierMetrics_41db1fc54c4f.log\n",
      "-rw-r--r-- 1 root root 322 20. Feb 18:02 ClassifierMetrics_44e8954b5f5d.log\n",
      "-rw-r--r-- 1 root root 559 20. Feb 17:45 ClassifierMetrics_49fdfe64394f.log\n",
      "-rw-r--r-- 1 root root 449 20. Feb 17:38 ClassifierMetrics_4a2e4a7dac7c.log\n",
      "-rw-r--r-- 1 root root 126 20. Feb 17:59 ClassifierMetrics_4a623cb68ecc.log\n",
      "-rw-r--r-- 1 root root 323 20. Feb 18:02 ClassifierMetrics_536a85621ba7.log\n",
      "-rw-r--r-- 1 root root 325 10. Feb 16:54 ClassifierMetrics_55c7e364bf2b.log\n",
      "-rw-r--r-- 1 root root 128 20. Feb 17:52 ClassifierMetrics_66b22a01b7d3.log\n",
      "-rw-r--r-- 1 root root 316 20. Feb 18:02 ClassifierMetrics_6a4855e04b2f.log\n",
      "-rw-r--r-- 1 root root 129 20. Feb 17:59 ClassifierMetrics_6f4f96da828e.log\n",
      "-rw-r--r-- 1 root root 555 20. Feb 17:45 ClassifierMetrics_71effbac2282.log\n",
      "-rw-r--r-- 1 root root 129 20. Feb 17:59 ClassifierMetrics_73bcd38f71f7.log\n",
      "-rw-r--r-- 1 root root 426 20. Feb 17:38 ClassifierMetrics_73fa92fe4be8.log\n",
      "-rw-r--r-- 1 root root 433 20. Feb 17:38 ClassifierMetrics_7764aa9b23e3.log\n",
      "-rw-r--r-- 1 root root 127 20. Feb 17:52 ClassifierMetrics_7dc198897be3.log\n",
      "-rw-r--r-- 1 root root 570 20. Feb 17:45 ClassifierMetrics_80808e6b12d1.log\n",
      "-rw-r--r-- 1 root root 445 20. Feb 17:38 ClassifierMetrics_890dcfe0db80.log\n",
      "-rw-r--r-- 1 root root 444 20. Feb 17:38 ClassifierMetrics_8ecc3f83e12d.log\n",
      "-rw-r--r-- 1 root root 325 10. Feb 16:54 ClassifierMetrics_9290b613e8d7.log\n",
      "-rw-r--r-- 1 root root 567 20. Feb 17:45 ClassifierMetrics_9ba6210e2c94.log\n",
      "-rw-r--r-- 1 root root 308 20. Feb 18:02 ClassifierMetrics_9e50a6c01b6a.log\n",
      "-rw-r--r-- 1 root root 129 20. Feb 17:52 ClassifierMetrics_a579e188cf6b.log\n",
      "-rw-r--r-- 1 root root 317 10. Feb 16:54 ClassifierMetrics_aa0e2812a3b9.log\n",
      "-rw-r--r-- 1 root root 318 10. Feb 16:54 ClassifierMetrics_ad4cb4a650fa.log\n",
      "-rw-r--r-- 1 root root 129 20. Feb 17:52 ClassifierMetrics_b901376087b3.log\n",
      "-rw-r--r-- 1 root root 564 20. Feb 17:45 ClassifierMetrics_d302c6e17f10.log\n",
      "-rw-r--r-- 1 root root 317 20. Feb 18:02 ClassifierMetrics_e0199b46eaa2.log\n",
      "-rw-r--r-- 1 root root 452 20. Feb 17:38 ClassifierMetrics_e0da6952b2c6.log\n",
      "-rw-r--r-- 1 root root 317 20. Feb 18:02 ClassifierMetrics_e0dd3cc9595e.log\n",
      "-rw-r--r-- 1 root root 567 20. Feb 17:45 ClassifierMetrics_e29d5ee5fe87.log\n",
      "-rw-r--r-- 1 root root 312 20. Feb 18:02 ClassifierMetrics_e2fa7c36f711.log\n",
      "-rw-r--r-- 1 root root 312 10. Feb 16:54 ClassifierMetrics_efc7f6345e79.log\n",
      "-rw-r--r-- 1 root root 319 10. Feb 16:54 ClassifierMetrics_f571876aaa09.log\n",
      "-rw-r--r-- 1 root root 131 20. Feb 17:59 ClassifierMetrics_fbe1c172154f.log\n",
      "-rw-r--r-- 1 root root 436 20. Feb 17:38 ClassifierMetrics_fdc5fa307baf.log\n",
      "-rw-r--r-- 1 root root 922 20. Feb 17:45 MultiClassifierDLApproach_0420b23f4851.log\n",
      "-rw-r--r-- 1 root root 792 20. Feb 17:52 MultiClassifierDLApproach_73f999799c2b.log\n",
      "-rw-r--r-- 1 root root 792 20. Feb 17:59 MultiClassifierDLApproach_e6ae1c4549a9.log\n",
      "-rw-r--r-- 1 root root 320 26. Okt 09:23 NerDL_0f47f69f09e6.log\n",
      "-rw-r--r-- 1 root root 320  2. Aug 2022  NerDL_10e337c8a3ef.log\n",
      "-rw-r--r-- 1 root root 320 12. Jan 17:31 NerDL_18e7b1673dab.log\n",
      "-rw-r--r-- 1 root root 320  2. Aug 2022  NerDL_27f18f749174.log\n",
      "-rw-r--r-- 1 root root 320  2. Aug 2022  NerDL_3ae0321ce66a.log\n",
      "-rw-r--r-- 1 root root 319 26. Okt 09:13 NerDL_568d747656b8.log\n",
      "-rw-r--r-- 1 root root 320 26. Okt 09:03 NerDL_5970e276422f.log\n",
      "-rw-r--r-- 1 root root 320 16. Jan 11:10 NerDL_759a68c3769d.log\n",
      "-rw-r--r-- 1 root root 320  3. Nov 19:22 NerDL_891f9b941985.log\n",
      "-rw-r--r-- 1 root root 320  2. Feb 2022  NerDL_8e8184f259cb.log\n",
      "-rw-r--r-- 1 root root 320 27. Okt 13:02 NerDL_add5b34b2ecb.log\n",
      "-rw-r--r-- 1 root root 320 21. Okt 19:06 NerDL_bc57a96c68c3.log\n",
      "-rw-r--r-- 1 root root 320 12. Jan 16:47 NerDL_ff0a43f20378.log\n",
      "-rw-r--r-- 1 root root 437 20. Feb 18:04 SentimentDLApproach_1955fb8515af.log\n",
      "-rw-r--r-- 1 root root 899 20. Feb 18:02 SentimentDLApproach_1e4403144e6c.log\n",
      "-rw-r--r-- 1 root root 897 10. Feb 16:54 SentimentDLApproach_98dfd2c1fdee.log\n"
     ]
    }
   ],
   "source": [
    "!cd ~/annotator_logs && ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /home/root/annotator_logs/SentimentDLApproach_2ea7dc3149c2.log: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cat ~/annotator_logs/SentimentDLApproach_2ea7dc3149c2.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use already trained SentimentDL pipeline or its model\n",
    "\n",
    "We have two ways of using what we already trained: pipeline or model.\n",
    "\n",
    "Let's see how we can save the entire pipeline, load it, and do some prediction with that pre-trained pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load pre-trained SentimentDL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab is free so it comes with a little memory. \n",
    "# It's not possible to save and load in this notebook. But you can do this locally or in a decent machine!\n",
    "\n",
    "# pipelineModel.save(\"./sentimentdl_pipeline\")\n",
    "# loadedPipeline = PipelineModel.load(\"./sentimentdl_pipeline\")\n",
    "# loadedPipeline.transform(YOUR_DATAFRAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load pre-trained SentimentDL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs:/ if you are saving it on distributed file systems in Hadoop\n",
    "pipelineModel.stages[-1].write().overwrite().save('./tmp_sentimentdl_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our pre-trained SentimentDLModel in a pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In a new pipeline you can load it for prediction\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained() \\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentdl = SentimentDLModel.load(\"./tmp_sentimentdl_model\") \\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load it back so we can have prediction all together with everything in that pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "dfTest = spark.createDataFrame([\n",
    "    \"This movie is a delight for those of all ages. I have seen it several times and each time I am enchanted by the characters and magic. The cast is outstanding, the special effects delightful, everything most believable.\",\n",
    "    \"This film was to put it simply rubbish. The child actors couldn't act, as can be seen by Harry's supposed surprise on learning he's a wizard. I'm a wizard! is said with such indifference you'd think he's not surprised at all.\"\n",
    "], StringType()).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipeline.fit(dfTest).transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    result|\n",
      "+----------+\n",
      "|[positive]|\n",
      "|[negative]|\n",
      "+----------+\n",
      "\n",
      "+------------------------------------------------------------------+\n",
      "|metadata                                                          |\n",
      "+------------------------------------------------------------------+\n",
      "|[{sentence -> 0, positive -> 1.0, negative -> 1.7301151E-10}]     |\n",
      "|[{sentence -> 0, positive -> 7.5793296E-6, negative -> 0.9999924}]|\n",
      "+------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"class.result\").show()\n",
    "\n",
    "prediction.select(\"class.metadata\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "Let's evaluatte our SentimentDL model we trained earlier, saved it, and loaded it into a new pipeline by using a test dataset that model has never seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"aclimdb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipelineModel.transform(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------------+----------+\n",
      "|   label|                                              text|    result|\n",
      "+--------+--------------------------------------------------+----------+\n",
      "|negative|The Second Woman is about the story of a myster...|[negative]|\n",
      "|positive|In my opinion the directing, editing, lighting,...|[positive]|\n",
      "|positive|I am listening to Istanbul, intent, my eyes clo...|[positive]|\n",
      "|negative|Before I speak my piece, I would like to make a...|[positive]|\n",
      "|positive|ManBearPig is a pretty funny episode of South P...|[positive]|\n",
      "|negative|A buddy and I went to see this movie when it ca...|[negative]|\n",
      "|negative|It is incredible that there were two films with...|[negative]|\n",
      "|negative|Dire! Dismal! Awful! Laughable! Disappointing!<...|[negative]|\n",
      "|positive|HLOTS was an outstanding series, its what NYPD ...|[positive]|\n",
      "|negative|This is just one of those films which cannot ju...|[negative]|\n",
      "|negative|This movie had the potential to be a very good ...|[negative]|\n",
      "|positive|The 80s were overrun by all those HALLOWEEN/Fri...|[negative]|\n",
      "|positive|The tunes are the best aspect of this televisio...|[positive]|\n",
      "|positive|Having recently seen Grindhouse, I was browsing...|[negative]|\n",
      "|positive|My favorite film this year. Great characters an...|[positive]|\n",
      "|positive|This movie just might make you cooooo. The film...|[positive]|\n",
      "|negative|This is the worst movie I have ever seen. If I ...|[negative]|\n",
      "|positive|This was a nice film. It had a interesting stor...|[positive]|\n",
      "|negative|I don't know, maybe I just wasn't in the mood f...|[negative]|\n",
      "|negative|After wasting 2 hours of my life watching this ...|[negative]|\n",
      "|negative|For the most part, I considered this movie unwo...|[negative]|\n",
      "|positive|I first saw this one when it was first shown, s...|[positive]|\n",
      "|negative|I will not say much about this film, because th...|[negative]|\n",
      "|negative|I sort of liked this movie, not a good one, but...|[negative]|\n",
      "|positive|At the surface COOLEY HIGH is a snappy ensemble...|[positive]|\n",
      "|negative|It is such a shame that so many people \"love\" F...|[negative]|\n",
      "|positive|As you may know Norway is the most developed co...|[positive]|\n",
      "|negative|I went to this film full of hope. With so many ...|[negative]|\n",
      "|positive|The Ator series is a shining example of what B-...|[negative]|\n",
      "|negative|Ted Nicolaou made a lot of great horror and fan...|[negative]|\n",
      "|positive|This without doubt one of the funniest and most...|[positive]|\n",
      "|positive|This is a absolutely masterful stroke of genius...|[positive]|\n",
      "|negative|This is a film that has garnered any interest o...|[positive]|\n",
      "|positive|It seems that no matter how many films are made...|[positive]|\n",
      "|negative|You'd hardly know that a year later MGM put Nor...|[positive]|\n",
      "|negative|this movie is so bad and Hellraiser part 1 to 3...|[negative]|\n",
      "|positive|This is a classic street punk & rock movie. If ...|[positive]|\n",
      "|negative|Aya! If you are looking for special effects tha...|[negative]|\n",
      "|negative|Found an old VHS version of this film in my par...|[negative]|\n",
      "|positive|This movie is funny and sad enough I think that...|[positive]|\n",
      "|negative|The video box for 'Joyride' says \"starring seco...|[negative]|\n",
      "|negative|I will never get back the three hours of life t...|[negative]|\n",
      "|negative|\"Solomon and Sheba\" was the kind of film that y...|[positive]|\n",
      "|negative|This is far the most worst film I've seen this ...|[negative]|\n",
      "|negative|The only reason I watched this is because of it...|[negative]|\n",
      "|negative|Back in the cold and creepy early 90's,a show c...|[negative]|\n",
      "|negative|If you're in the mood for a really bad porno wi...|[negative]|\n",
      "|negative|The bearings of western-style Feminism on the v...|[positive]|\n",
      "|positive|In the changing world of CG and what-not of car...|[negative]|\n",
      "|positive|I wonder why I haven't heard of this movie befo...|[positive]|\n",
      "+--------+--------------------------------------------------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.select('label','text',\"class.result\").show(50, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = preds.select('label','text',\"class.result\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is an array since in Spark NLP you can have multiple sentences.\n",
    "# This means you can add SentenceDetector in the pipeline and feed it into\n",
    "# UniversalSentenceEncoder and you can have prediction based on each sentence.\n",
    "# Let's explode the array and get the item(s) inside of result column out\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SentimentDL` has the ability to accept a threshold to set a label on any result that is less than that number. \n",
    "\n",
    "For instance, by default the threshold is set on `0.6` and everything below that will be assigned as `neutral`. You can change this label with `setThresholdLabel`.\n",
    "\n",
    "We need to filter `neutral` results since we don't have any in the original test dataset to compare with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = preds_df[preds_df['result'] != 'neutral']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `classification_report` from `sklearn` to evaluate the final scores. (keep in mind due to limited resources on a free Google Colab we only used 5 Epochs :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86     12787\n",
      "    positive       0.84      0.87      0.86     11819\n",
      "\n",
      "    accuracy                           0.86     24606\n",
      "   macro avg       0.86      0.86      0.86     24606\n",
      "weighted avg       0.86      0.86      0.86     24606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(preds_df['result'], preds_df['label']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SentimentDL_train_multiclass_sentiment_classifier.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
