{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/classification/SentimentDL_Train_and_Evaluate.ipynb)\n",
    "\n",
    "# Multi-class Sentiment Classification using SentimentDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run this block if you are inside Google Colab otherwise skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to check the training logs on the fly. Thus, we start a session with `real_time_output=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/20 18:01:18 WARN Utils: Your hostname, duc-manjaro resolves to a loopback address: 127.0.1.1; using 192.168.0.34 instead (on interface enp3s0)\n",
      "23/02/20 18:01:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Spark NLP version:  4.3.1\n",
      "Apache Spark version 3.3.0\n",
      ":: loading settings :: url = jar:file:/home/root/.conda/envs/sparknlp/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "23/02/20 18:01:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start(real_time_output=True)\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version\", spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download IMDB movie reviews dataset for training our multi-class sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-20 18:01:23--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_train.csv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.141.0, 52.216.18.187, 52.217.165.168, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.141.0|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33497180 (32M) [text/csv]\n",
      "Saving to: ‘aclimdb_train.csv’\n",
      "\n",
      "aclimdb_train.csv   100%[===================>]  31,95M  11,0MB/s    in 2,9s    \n",
      "\n",
      "2023-02-20 18:01:27 (11,0 MB/s) - ‘aclimdb_train.csv’ saved [33497180/33497180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O aclimdb_train.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-20 18:01:27--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_test.csv\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.172.80, 52.216.233.189, 52.216.171.29, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.172.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 32715164 (31M) [text/csv]\n",
      "Saving to: ‘aclimdb_test.csv’\n",
      "\n",
      "aclimdb_test.csv    100%[===================>]  31,20M  15,8MB/s    in 2,0s    \n",
      "\n",
      "2023-02-20 18:01:30 (15,8 MB/s) - ‘aclimdb_test.csv’ saved [32715164/32715164]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O aclimdb_test.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text,label\n",
      "\"This is an Excellent little movie! The acting is good and the music is fantastic!! Play it on a 5-1 sound system and enjoy! It will never win any awards but its good clean fun for all!! I recommend this movie to all fans of pretty girls funny and hansom men as well as robot lovers everyone!!1 P.S. It also stars Lisa Rinna! Enjoy!!This is a very hard movie to find, It is out of print. I first saw it on Showtime many years ago but recently found a used VHS copy. Its still a must see for all!!!This is an Excellent little movie! The acting is good and the music is fantastic!! Play it on a 5-1 sound system and enjoy! It will never win any awards but its good clean fun for all!! I recommend this movie to all fans of pretty girls funny and hansom men as well as robot lovers everyone!!1 P.S. It also stars Lisa Rinna! Enjoy!! Dave Engle This is a very hard movie to find, It is out of print. I first saw it on Showtime many years ago but recently found a used VHS copy. Its still a must see for all!!!\",positive\n",
      "\"The Sarah Silverman program is very similar to Sarah's own stand up; It's so over the top with prejudice that you can't possibly take it to heart. The fact is, though, that while most all people will \\\"get it,\\\" it doesn't mean they will all appreciate it. It's a very polarizing and one dimensional show, so if you don't like it after 10 minutes, you may as well give up there. If you do like it after 10 minutes, stay tuned, because every episode thus far has been as good as the last.<br /><br />Like all shows, though, it is not perfect. Personally I love the program, but there are some huge faults with it. Racist songs are funny, but get older a lot faster than Silverman seems to realize--a problem that I had with \\\"Jesus is Magic\\\" as well. It seems as if Silverman gave herself a quota for songs per episode that doesn't need to exist. Not to mention that while the lyrics to the songs she writes are good, the music, well, isn't.<br /><br />Another thing to keep in mind is that while this show will for some reason appeal to fans of Monty Python, Upright Citizens Brigade, etc., it is nothing like those shows. I can watch Monty Python all day, but, as much as I like this show, I can't watch more than the half hour limit at a time. It gets flat very fast. The repeat value for this show is low too--the second time around an episode is fairly funny, and by the third time, in my opinion, it's boring.<br /><br />Still, that first time around is very, very funny. Give it a shot.\",positive\n",
      "\"\\\"Prom Night\\\" is a title-only remake of the 1980 slasher flick that starred Jamie Lee Curtis and Leslie Nielsen. This movie takes place in an Oregon town, where Donna (Brittany Snow) is about to go to her senior prom and let herself have some fun after going through some extremely traumatic events in the past few years. She and her friends arrive at the prom, which is taking place in a grand hotel, and try and enjoy what is supposed to be the most fun night of their lives. Little does anyone know, a man from Donna's past, who has haunted her for years, is also at the prom... and is willing to kill anyone in way of his pursuit of her.<br /><br />I'm a fan of the original \\\"Prom Night\\\", so I tried to maintain a little hope in this movie, but I have to admit I was quite disappointed. \\\"Prom Night\\\" suffers from the worst affliction a horror movie could have, and that is predictability. There are absolutely no surprises here, and I felt I had seen everything in this movie done dozens of times, often better, before. What does this equate to for the audience? Boredom. Unless of course you have never seen any horror movies, or are part of the pre-teen crowd, but the majority of the audience will most likely be able to guess nearly everything that is going to happen. The plot is simplistic, but the entire script is void of any type of surprise, twist, atmosphere, or anything, and this really, really hurts the movie because it never really gives the audience anything to sink their teeth into. It all just seemed very bland.<br /><br />A lot of people seem to complain with the fact that this is a PG-13 slasher movie as well, and I understand what they are saying, but I don't think it's impossible to make a good slasher movie with minimal gore. Take Carpenter's \\\"Halloween\\\" for example - little to no on screen violence, but still an extremely frightening and effective movie. You don't need gore to make a film scary, but even had \\\"Prom Night\\\" been gratuitously violent (which it is not, it is very tame), it still would have added little to the movie because there is not much in the script to build on to begin with. The tension and suspense here is mild at best, and I spent most of the movie predicting the outcome of situations, and was correct about 99% of the time. Our characters aren't well written enough either for the audience to make any connection to them, and their by-the-numbers demises are routine and careless.<br /><br />I will point out a few things I did like about this movie, though, because it wasn't completely useless - the cinematography is really nice, and everything was very well-filmed and fairly stylish. Among the \\\"jump\\\" scares (that are for the most part very predictable), there were a few that were kind of clever. The sets for the movie are nice too and the hotel is a neat place for the plot to unfold, however predictable the unfolding may be. As for the acting, it's mediocre at best. Brittany Snow plays the lead decently, but really the rest of the cast doesn't show off much talent. Johnathan Schaech plays the villain, and is probably the most experienced performer here, but even he isn't that impressive. However, I did like the character he played, which was a nice change from the typical 'masked-stalker' type killer we see a lot. As far as the ending goes, the last fifteen minutes of the film had me bored to my wit's end and it was very anti-climactic.<br /><br />Overall, \\\"Prom Night\\\" was a disappointment. Everything was very by-the-numbers, routine, and predictable, which is somewhat upsetting considering this had the potential to be a decent slasher movie. There were a few neat moments, but the movie lacked any suspense or atmosphere, and had little plot development, nor believable characters. I'd advise seasoned horror fans to save their money and wait till it's out on video, or rent the original instead, because there are absolutely no surprises here. Some may find a little entertainment in it, but it was far too predictable for my tastes. I expected better, and left the theater very disappointed. 3/10.\",negative\n",
      "\"So often a band will get together for a re-union concert only to find that they just can't get it together. Not so here. This concert is just shear brilliance from start to finish. These three musicians obviously got together beforehand and plotted and planned what was needed to ensure this was not just a nostalgic bash to satisfy someone's ego. This is obvious from the start, before they even step on stage. Many faces in the crowd weren't even born when these guys first performed. From the first song they capture that old magic that was Cream, 3 men, 3 instruments, no fuss. Clapton, by his own admission, said he had to stretch himself for this concert because there were no keyboards, synthesizers etc so we get to see him at his best. Ginger Baker demonstrates why so many drummers today, speak of him as some sort of drumming guru. Jack Bruce just great. They really managed to put together a piece of magic that will stand the test of time for many years to come. This one's a 10 for me.\",positive\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 aclimdb_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content is inside `text` column and the sentiment is inside `label` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"aclimdb_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                text|   label|\n",
      "+--------------------+--------+\n",
      "|This is an Excell...|positive|\n",
      "|The Sarah Silverm...|positive|\n",
      "|\"Prom Night\" is a...|negative|\n",
      "|So often a band w...|positive|\n",
      "|\"Pet Sematary\" is...|positive|\n",
      "|I watched the fil...|negative|\n",
      "|Boy this movie ha...|negative|\n",
      "|Checking the spoi...|negative|\n",
      "|Despite its rathe...|positive|\n",
      "|Absolute masterpi...|positive|\n",
      "|The tweedy profes...|positive|\n",
      "|A movie best summ...|negative|\n",
      "|Take young, prett...|negative|\n",
      "|For months I've b...|negative|\n",
      "|\"Batman: The Myst...|positive|\n",
      "|Well, it was funn...|negative|\n",
      "|I have seen the s...|positive|\n",
      "|Brainless film ab...|negative|\n",
      "|Leave it to geniu...|negative|\n",
      "|Seven Pounds star...|positive|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "Let's evaluate our SentimentDL model during training, saved it, and loaded it into a new pipeline by using a test dataset that model has never seen. To do this we first need to prepare a test dataset parquet file as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_test_dataset = spark.read \\\n",
    "      .option(\"header\", True) \\\n",
    "      .csv(\"aclimdb_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ | ]tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ / ]Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained() \\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "pipeline = Pipeline(stages = [document,use])\n",
    "\n",
    "test_dataset = pipeline.fit(imdb_test_dataset).transform(imdb_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+\n",
      "|                text|   label|            document| sentence_embeddings|\n",
      "+--------------------+--------+--------------------+--------------------+\n",
      "|The Second Woman ...|negative|[{document, 0, 11...|[{sentence_embedd...|\n",
      "|In my opinion the...|positive|[{document, 0, 14...|[{sentence_embedd...|\n",
      "+--------------------+--------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that out test dataset has the required embeddings, we save it as parquet and use it while training our SentimentDL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.write.parquet(\"./aclimdb_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it and use a validation and the test dataset above for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classes/labels/categories are in category column\n",
    "sentimentdl = SentimentDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setMaxEpochs(5)\\\n",
    "  .setEnableOutputLogs(True)\\\n",
    "  .setValidationSplit(0.2) \\\n",
    "  .setEvaluationLogExtended(True) \\\n",
    "  .setTestDataset(\"./aclimdb_test.parquet\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.005 - batch_size: 64 - training_examples: 20000\n",
      "Epoch 1/5 - 1.42s - loss: 147.28938 - acc: 0.82757413 - batches: 313\n",
      "Quality on validation dataset (20.0%), validation examples = 5000\n",
      "time to finish evaluation: 0.06s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            1968\t 263\t 519\t 0.88211566\t 0.79131484\t 0.8342518\n",
      "0            2250\t 519\t 263\t 0.8125677\t 0.8953442\t 0.85195\n",
      "tp: 4218 fp: 782 fn: 782 labels: 2\n",
      "Macro-average\t prec: 0.84734166, rec: 0.84332955, f1: 0.8453309\n",
      "Micro-average\t prec: 0.8436, recall: 0.8436, f1: 0.8436\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.24s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            9922\t 1415\t 2578\t 0.87518746\t 0.79376\t 0.83248734\n",
      "0            11085\t 2578\t 1415\t 0.81131524\t 0.8868\t 0.8473799\n",
      "tp: 21007 fp: 3993 fn: 3993 labels: 2\n",
      "Macro-average\t prec: 0.84325135, rec: 0.84028, f1: 0.8417631\n",
      "Micro-average\t prec: 0.84028, recall: 0.84028, f1: 0.84028\n",
      "Epoch 2/5 - 1.38s - loss: 134.46562 - acc: 0.8528145 - batches: 313\n",
      "Quality on validation dataset (20.0%), validation examples = 5000\n",
      "time to finish evaluation: 0.05s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            2084\t 334\t 403\t 0.86186934\t 0.8379574\t 0.84974515\n",
      "0            2179\t 403\t 334\t 0.84391946\t 0.8670911\t 0.8553484\n",
      "tp: 4263 fp: 737 fn: 737 labels: 2\n",
      "Macro-average\t prec: 0.8528944, rec: 0.8525243, f1: 0.8527093\n",
      "Micro-average\t prec: 0.8526, recall: 0.8526, f1: 0.8526\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.22s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            10519\t 1829\t 1981\t 0.8518788\t 0.84152\t 0.8466677\n",
      "0            10671\t 1981\t 1829\t 0.84342396\t 0.85368\t 0.848521\n",
      "tp: 21190 fp: 3810 fn: 3810 labels: 2\n",
      "Macro-average\t prec: 0.84765136, rec: 0.8476, f1: 0.8476257\n",
      "Micro-average\t prec: 0.8476, recall: 0.8476, f1: 0.8476\n",
      "Epoch 3/5 - 1.96s - loss: 131.90747 - acc: 0.86177886 - batches: 313\n",
      "Quality on validation dataset (20.0%), validation examples = 5000\n",
      "time to finish evaluation: 0.07s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            2136\t 377\t 351\t 0.8499801\t 0.8588661\t 0.8544\n",
      "0            2136\t 351\t 377\t 0.8588661\t 0.8499801\t 0.8544\n",
      "tp: 4272 fp: 728 fn: 728 labels: 2\n",
      "Macro-average\t prec: 0.8544231, rec: 0.8544231, f1: 0.8544231\n",
      "Micro-average\t prec: 0.8544, recall: 0.8544, f1: 0.8544\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.33s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            10759\t 2033\t 1741\t 0.84107256\t 0.86072\t 0.85078293\n",
      "0            10467\t 1741\t 2033\t 0.8573886\t 0.83736\t 0.84725595\n",
      "tp: 21226 fp: 3774 fn: 3774 labels: 2\n",
      "Macro-average\t prec: 0.8492306, rec: 0.84904003, f1: 0.84913534\n",
      "Micro-average\t prec: 0.84904, recall: 0.84904, f1: 0.84904\n",
      "Epoch 4/5 - 1.73s - loss: 130.34096 - acc: 0.86708736 - batches: 313\n",
      "Quality on validation dataset (20.0%), validation examples = 5000\n",
      "time to finish evaluation: 0.06s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            2167\t 409\t 320\t 0.8412267\t 0.8713309\t 0.8560142\n",
      "0            2104\t 320\t 409\t 0.8679868\t 0.8372463\t 0.85233945\n",
      "tp: 4271 fp: 729 fn: 729 labels: 2\n",
      "Macro-average\t prec: 0.85460675, rec: 0.8542886, f1: 0.85444766\n",
      "Micro-average\t prec: 0.8542, recall: 0.8542, f1: 0.8542\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.25s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            10896\t 2135\t 1604\t 0.83615994\t 0.87168\t 0.85355055\n",
      "0            10365\t 1604\t 2135\t 0.8659871\t 0.8292\t 0.84719443\n",
      "tp: 21261 fp: 3739 fn: 3739 labels: 2\n",
      "Macro-average\t prec: 0.8510735, rec: 0.85044, f1: 0.85075665\n",
      "Micro-average\t prec: 0.85044, recall: 0.85044, f1: 0.85044\n",
      "Epoch 5/5 - 1.58s - loss: 129.25305 - acc: 0.8711438 - batches: 313\n",
      "Quality on validation dataset (20.0%), validation examples = 5000\n",
      "time to finish evaluation: 0.05s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            2172\t 410\t 315\t 0.84120834\t 0.8733414\t 0.8569737\n",
      "0            2103\t 315\t 410\t 0.8697271\t 0.8368484\t 0.852971\n",
      "tp: 4275 fp: 725 fn: 725 labels: 2\n",
      "Macro-average\t prec: 0.8554677, rec: 0.8550949, f1: 0.85528123\n",
      "Micro-average\t prec: 0.855, recall: 0.855, f1: 0.855\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.31s\n",
      "label        tp\t fp\t fn\t prec\t rec\t f1\n",
      "1            10935\t 2176\t 1565\t 0.8340325\t 0.8748\t 0.85392994\n",
      "0            10324\t 1565\t 2176\t 0.8683657\t 0.82592\t 0.8466112\n",
      "tp: 21259 fp: 3741 fn: 3741 labels: 2\n",
      "Macro-average\t prec: 0.8511991, rec: 0.85036004, f1: 0.8507794\n",
      "Micro-average\t prec: 0.85036, recall: 0.85036, f1: 0.85036\n"
     ]
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(trainDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use already trained SentimentDL pipeline or its model\n",
    "\n",
    "We have two ways of using what we already trained: pipeline or model.\n",
    "\n",
    "Let's see how we can save the entire pipeline, load it, and do some prediction with that pre-trained pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load pre-trained SentimentDL pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab is free so it comes with a little memory. \n",
    "# It's not possible to save and load in this notebook. But you can do this locally or in a decent machine!\n",
    "\n",
    "# pipelineModel.save(\"./sentimentdl_pipeline\")\n",
    "# loadedPipeline = PipelineModel.load(\"./sentimentdl_pipeline\")\n",
    "# loadedPipeline.transform(YOUR_DATAFRAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load pre-trained SentimentDL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs:/ if you are saving it on distributed file systems in Hadoop\n",
    "pipelineModel.stages[-1].write().overwrite().save('./tmp_sentimentdl_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our pre-trained SentimentDLModel in a pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In a new pipeline you can load it for prediction\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained() \\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentdl = SentimentDLModel.load(\"./tmp_sentimentdl_model\") \\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        sentimentdl\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load it back so we can have prediction all together with everything in that pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "dfTest = spark.createDataFrame([\n",
    "    \"This movie is a delight for those of all ages. I have seen it several times and each time I am enchanted by the characters and magic. The cast is outstanding, the special effects delightful, everything most believable.\",\n",
    "    \"This film was to put it simply rubbish. The child actors couldn't act, as can be seen by Harry's supposed surprise on learning he's a wizard. I'm a wizard! is said with such indifference you'd think he's not surprised at all.\"\n",
    "], StringType()).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pipeline.fit(dfTest).transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|    result|\n",
      "+----------+\n",
      "|[positive]|\n",
      "|[negative]|\n",
      "+----------+\n",
      "\n",
      "+-------------------------------------------------------------------+\n",
      "|metadata                                                           |\n",
      "+-------------------------------------------------------------------+\n",
      "|[{sentence -> 0, positive -> 1.0, negative -> 2.8575936E-8}]       |\n",
      "|[{sentence -> 0, positive -> 1.2174318E-5, negative -> 0.99998784}]|\n",
      "+-------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"class.result\").show()\n",
    "\n",
    "prediction.select(\"class.metadata\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
