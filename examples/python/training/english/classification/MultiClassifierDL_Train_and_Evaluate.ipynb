{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/classification/MultiClassifierDL_Train_and_Evaluate.ipynb)\n",
    "\n",
    "# Multi-label Text Classification of Toxic Comments using MultiClassifierDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download our Toxic comments for tarining and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2702k  100 2702k    0     0  1699k      0  0:00:01  0:00:01 --:--:-- 1699k\n"
     ]
    }
   ],
   "source": [
    "!curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_train.snappy.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  289k  100  289k    0     0   249k      0  0:00:01  0:00:01 --:--:--  249k\n"
     ]
    }
   ],
   "source": [
    "!curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_test.snappy.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to check the training logs on the fly. Thus, we start a session with real_time_output=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.3.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/20 17:43:36 WARN Utils: Your hostname, duc-manjaro resolves to a loopback address: 127.0.1.1; using 192.168.0.34 instead (on interface enp3s0)\n",
      "23/02/20 17:43:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start(real_time_output=True)\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read our Toxi comments datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = spark.read.parquet(\"toxic_train.snappy.parquet\").repartition(120)\n",
    "toxic_test_dataset = spark.read.parquet(\"toxic_test.snappy.parquet\").repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-------+\n",
      "|              id|                text| labels|\n",
      "+----------------+--------------------+-------+\n",
      "|e63f1cc4b0b9959f|EAT SHIT HORSE FA...|[toxic]|\n",
      "|ed58abb40640f983|PN News\\nYou mean...|[toxic]|\n",
      "+----------------+--------------------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are lots of new lines in our comments which we can fix them with `DocumentAssembler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14620\n",
      "1605\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.cache().count())\n",
    "print(toxic_test_dataset.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "\n",
    "Let's evaluate our MultiClassifierDL model during training, saved it, and loaded it into a new pipeline by using a test dataset that model has never seen. To do this we first need to prepare a test dataset parquet file as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ | ]tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[ / ]Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Let's use shrink to remove new lines in the comments\n",
    "document = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\\\n",
    "  .setCleanupMode(\"shrink\")\n",
    "\n",
    "# Here we use the state-of-the-art Universal Sentence Encoder model from TF Hub\n",
    "embeddings = UniversalSentenceEncoder.pretrained() \\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "pipeline = Pipeline(stages = [document, embeddings])\n",
    "\n",
    "test_dataset = pipeline.fit(toxic_test_dataset).transform(toxic_test_dataset)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------------+--------------------+--------------------+\n",
      "|              id|                text|          labels|            document| sentence_embeddings|\n",
      "+----------------+--------------------+----------------+--------------------+--------------------+\n",
      "|47d256dea1223d39|Vegan \\n\\nWhat in...|         [toxic]|[{document, 0, 78...|[{sentence_embedd...|\n",
      "|5e0dea75de819976|Fight Club! F**k ...|[toxic, obscene]|[{document, 0, 29...|[{sentence_embedd...|\n",
      "+----------------+--------------------+----------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that out test dataset has the required embeddings, we save it as parquet and use it while training our MultiClassifierDL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.write.parquet(\"./toxic_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it and use a validation and the test dataset above for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use MultiClassifierDL built by using Bidirectional GRU and CNNs inside TensorFlow that supports up to 100 classes\n",
    "# We will use only 5 Epochs but feel free to increase it on your own dataset\n",
    "multiClassifier = MultiClassifierDLApproach()\\\n",
    "  .setInputCols(\"sentence_embeddings\")\\\n",
    "  .setOutputCol(\"category\")\\\n",
    "  .setLabelColumn(\"labels\")\\\n",
    "  .setBatchSize(128)\\\n",
    "  .setMaxEpochs(5)\\\n",
    "  .setLr(1e-3)\\\n",
    "  .setThreshold(0.5)\\\n",
    "  .setShufflePerEpoch(False)\\\n",
    "  .setEnableOutputLogs(True)\\\n",
    "  .setValidationSplit(0.1)\\\n",
    "  .setEvaluationLogExtended(True)\\\n",
    "  .setTestDataset(\"./toxic_test.parquet\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        embeddings,\n",
    "        multiClassifier\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - epochs: 5 - learning_rate: 0.001 - batch_size: 128 - training_examples: 13158 - classes: 6\n",
      "Epoch 1/5 - 4.34s - loss: 0.38046357 - acc: 0.848714 - batches: 103\n",
      "Quality on validation dataset (10.0%), validation examples = 1462 \n",
      "time to finish evaluation: 2.05s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1385\t 77\t 0\t 0.94733244\t 1.0\t 0.97295403\n",
      "threat          0\t 0\t 47\t 0.0\t 0.0\t 0.0\n",
      "obscene         545\t 141\t 216\t 0.79446065\t 0.7161629\t 0.75328267\n",
      "insult          456\t 173\t 244\t 0.72496027\t 0.6514286\t 0.6862303\n",
      "severe_toxic    28\t 21\t 101\t 0.5714286\t 0.21705426\t 0.31460676\n",
      "identity_hate   24\t 7\t 101\t 0.7741935\t 0.192\t 0.30769232\n",
      "tp: 2438 fp: 419 fn: 709 labels: 6\n",
      "Macro-average\t prec: 0.63539594, rec: 0.46277428, f1: 0.5355179\n",
      "Micro-average\t prec: 0.85334265, recall: 0.77470607, f1: 0.81212527\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.08s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1504\t 101\t 0\t 0.9370716\t 1.0\t 0.9675137\n",
      "threat          0\t 1\t 50\t 0.0\t 0.0\t 0.0\n",
      "obscene         563\t 167\t 261\t 0.7712329\t 0.68325245\t 0.7245817\n",
      "insult          483\t 183\t 278\t 0.7252252\t 0.6346912\t 0.6769446\n",
      "severe_toxic    32\t 28\t 115\t 0.53333336\t 0.21768707\t 0.30917874\n",
      "identity_hate   30\t 18\t 97\t 0.625\t 0.23622048\t 0.34285715\n",
      "tp: 2612 fp: 498 fn: 801 labels: 6\n",
      "Macro-average\t prec: 0.59864384, rec: 0.4619752, f1: 0.52150416\n",
      "Micro-average\t prec: 0.8398714, recall: 0.7653091, f1: 0.8008585\n",
      "Epoch 2/5 - 1.16s - loss: 0.30138606 - acc: 0.87715614 - batches: 103\n",
      "Quality on validation dataset (10.0%), validation examples = 1462 \n",
      "time to finish evaluation: 0.11s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1385\t 77\t 0\t 0.94733244\t 1.0\t 0.97295403\n",
      "threat          4\t 0\t 43\t 1.0\t 0.08510638\t 0.15686274\n",
      "obscene         554\t 134\t 207\t 0.8052326\t 0.7279895\t 0.76466525\n",
      "insult          468\t 163\t 232\t 0.74167985\t 0.6685714\t 0.7032306\n",
      "severe_toxic    25\t 22\t 104\t 0.5319149\t 0.19379845\t 0.2840909\n",
      "identity_hate   49\t 38\t 76\t 0.5632184\t 0.392\t 0.46226412\n",
      "tp: 2485 fp: 434 fn: 662 labels: 6\n",
      "Macro-average\t prec: 0.7648964, rec: 0.5112443, f1: 0.61286175\n",
      "Micro-average\t prec: 0.85131896, recall: 0.7896409, f1: 0.8193208\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.08s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1504\t 101\t 0\t 0.9370716\t 1.0\t 0.9675137\n",
      "threat          4\t 2\t 46\t 0.6666667\t 0.08\t 0.14285715\n",
      "obscene         568\t 162\t 256\t 0.7780822\t 0.6893204\t 0.73101676\n",
      "insult          494\t 176\t 267\t 0.73731345\t 0.64914584\t 0.69042623\n",
      "severe_toxic    26\t 27\t 121\t 0.49056605\t 0.17687075\t 0.26000002\n",
      "identity_hate   48\t 34\t 79\t 0.58536583\t 0.37795275\t 0.45933014\n",
      "tp: 2644 fp: 502 fn: 769 labels: 6\n",
      "Macro-average\t prec: 0.6991777, rec: 0.49554834, f1: 0.5800097\n",
      "Micro-average\t prec: 0.8404323, recall: 0.774685, f1: 0.8062205\n",
      "Epoch 3/5 - 1.08s - loss: 0.29324576 - acc: 0.87968993 - batches: 103\n",
      "Quality on validation dataset (10.0%), validation examples = 1462 \n",
      "time to finish evaluation: 0.08s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1385\t 77\t 0\t 0.94733244\t 1.0\t 0.97295403\n",
      "threat          9\t 0\t 38\t 1.0\t 0.19148937\t 0.3214286\n",
      "obscene         555\t 133\t 206\t 0.80668604\t 0.72930354\t 0.7660456\n",
      "insult          475\t 166\t 225\t 0.7410296\t 0.6785714\t 0.7084266\n",
      "severe_toxic    26\t 20\t 103\t 0.5652174\t 0.2015504\t 0.2971429\n",
      "identity_hate   53\t 38\t 72\t 0.5824176\t 0.424\t 0.49074075\n",
      "tp: 2503 fp: 434 fn: 644 labels: 6\n",
      "Macro-average\t prec: 0.7737805, rec: 0.5374858, f1: 0.6343426\n",
      "Micro-average\t prec: 0.8522302, recall: 0.7953607, f1: 0.822814\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.08s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1504\t 101\t 0\t 0.9370716\t 1.0\t 0.9675137\n",
      "threat          14\t 4\t 36\t 0.7777778\t 0.28\t 0.41176474\n",
      "obscene         569\t 164\t 255\t 0.7762619\t 0.690534\t 0.7308927\n",
      "insult          494\t 185\t 267\t 0.7275405\t 0.64914584\t 0.6861111\n",
      "severe_toxic    26\t 31\t 121\t 0.45614034\t 0.17687075\t 0.25490195\n",
      "identity_hate   50\t 38\t 77\t 0.5681818\t 0.39370078\t 0.46511626\n",
      "tp: 2657 fp: 523 fn: 756 labels: 6\n",
      "Macro-average\t prec: 0.7071623, rec: 0.5317086, f1: 0.60701126\n",
      "Micro-average\t prec: 0.8355346, recall: 0.778494, f1: 0.8060064\n",
      "Epoch 4/5 - 1.09s - loss: 0.28977352 - acc: 0.88131446 - batches: 103\n",
      "Quality on validation dataset (10.0%), validation examples = 1462 \n",
      "time to finish evaluation: 0.07s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1385\t 77\t 0\t 0.94733244\t 1.0\t 0.97295403\n",
      "threat          11\t 0\t 36\t 1.0\t 0.23404256\t 0.37931037\n",
      "obscene         557\t 131\t 204\t 0.809593\t 0.7319317\t 0.7688061\n",
      "insult          472\t 161\t 228\t 0.7456556\t 0.6742857\t 0.70817703\n",
      "severe_toxic    24\t 20\t 105\t 0.54545456\t 0.18604651\t 0.27745664\n",
      "identity_hate   54\t 32\t 71\t 0.627907\t 0.432\t 0.5118484\n",
      "tp: 2503 fp: 421 fn: 644 labels: 6\n",
      "Macro-average\t prec: 0.77932376, rec: 0.54305106, f1: 0.6400796\n",
      "Micro-average\t prec: 0.85601914, recall: 0.7953607, f1: 0.82457584\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.08s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1504\t 101\t 0\t 0.9370716\t 1.0\t 0.9675137\n",
      "threat          17\t 5\t 33\t 0.77272725\t 0.34\t 0.4722222\n",
      "obscene         572\t 161\t 252\t 0.7803547\t 0.69417477\t 0.7347462\n",
      "insult          496\t 186\t 265\t 0.72727275\t 0.651774\t 0.6874567\n",
      "severe_toxic    25\t 26\t 122\t 0.49019608\t 0.17006803\t 0.25252524\n",
      "identity_hate   50\t 38\t 77\t 0.5681818\t 0.39370078\t 0.46511626\n",
      "tp: 2664 fp: 517 fn: 749 labels: 6\n",
      "Macro-average\t prec: 0.712634, rec: 0.5416196, f1: 0.6154681\n",
      "Micro-average\t prec: 0.8374725, recall: 0.780545, f1: 0.80800736\n",
      "Epoch 5/5 - 1.11s - loss: 0.2876302 - acc: 0.88208383 - batches: 103\n",
      "Quality on validation dataset (10.0%), validation examples = 1462 \n",
      "time to finish evaluation: 0.07s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1385\t 77\t 0\t 0.94733244\t 1.0\t 0.97295403\n",
      "threat          11\t 0\t 36\t 1.0\t 0.23404256\t 0.37931037\n",
      "obscene         558\t 129\t 203\t 0.8122271\t 0.73324573\t 0.7707182\n",
      "insult          472\t 161\t 228\t 0.7456556\t 0.6742857\t 0.70817703\n",
      "severe_toxic    24\t 22\t 105\t 0.5217391\t 0.18604651\t 0.27428573\n",
      "identity_hate   54\t 30\t 71\t 0.64285713\t 0.432\t 0.5167464\n",
      "tp: 2504 fp: 419 fn: 643 labels: 6\n",
      "Macro-average\t prec: 0.7783019, rec: 0.54327005, f1: 0.6398866\n",
      "Micro-average\t prec: 0.8566541, recall: 0.79567844, f1: 0.8250412\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.09s\n",
      "label           tp\t fp\t fn\t prec\t rec\t f1\n",
      "toxic           1504\t 101\t 0\t 0.9370716\t 1.0\t 0.9675137\n",
      "threat          17\t 5\t 33\t 0.77272725\t 0.34\t 0.4722222\n",
      "obscene         564\t 157\t 260\t 0.7822469\t 0.684466\t 0.7300971\n",
      "insult          489\t 183\t 272\t 0.7276786\t 0.64257556\t 0.6824843\n",
      "severe_toxic    25\t 26\t 122\t 0.49019608\t 0.17006803\t 0.25252524\n",
      "identity_hate   49\t 39\t 78\t 0.5568182\t 0.38582677\t 0.45581394\n",
      "tp: 2648 fp: 511 fn: 765 labels: 6\n",
      "Macro-average\t prec: 0.71112305, rec: 0.53715605, f1: 0.6120171\n",
      "Micro-average\t prec: 0.83823997, recall: 0.77585703, f1: 0.805843\n"
     ]
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our trained multi-label classifier model to be loaded in our prediction pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel.stages[-1].write().overwrite().save('tmp_multi_classifierDL_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Saved Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained() \\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "multiClassifier = MultiClassifierDLModel.load(\"tmp_multi_classifierDL_model\") \\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"category\")\\\n",
    "  .setThreshold(0.5)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        multiClassifier\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "name": "MultiClassifierDL_Train_multi_label_toxic_classifier",
  "notebookId": 1952370652427552,
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
