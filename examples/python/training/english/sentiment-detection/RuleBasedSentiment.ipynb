{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/sentiment-detection/RuleBasedSentiment.ipynb)\n",
    "\n",
    "# Rule-based Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we walk-through a simple use case for our straight forward SentimentDetector annotator.\n",
    "\n",
    "This annotator will work on top of a list of labeled sentences which can have any of the following features\n",
    "\n",
    "    positive\n",
    "    negative\n",
    "    revert\n",
    "    increment\n",
    "    decrement\n",
    "\n",
    "Each of these sentences will be used for giving a score to text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Call necessary imports and set the resource path to read local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import array_contains\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load SparkSession if not already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.3.1\n",
      "Apache Spark version:  3.3.0\n"
     ]
    }
   ],
   "source": [
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-20 17:34:18--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.77.126, 52.216.88.173, 54.231.136.0, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.77.126|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 76127532 (73M) [application/zip]\n",
      "Saving to: ‘/tmp/sentiment.parquet.zip’\n",
      "\n",
      "sentiment.parquet.z 100%[===================>]  72,60M  22,5MB/s    in 4,0s    \n",
      "\n",
      "2023-02-20 17:34:22 (18,3 MB/s) - ‘/tmp/sentiment.parquet.zip’ saved [76127532/76127532]\n",
      "\n",
      "--2023-02-20 17:34:23--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/lemma-corpus-small/lemmas_small.txt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.135.240, 54.231.224.176, 52.217.196.88, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.135.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 189437 (185K) [text/plain]\n",
      "Saving to: ‘/tmp/lemmas_small.txt’\n",
      "\n",
      "lemmas_small.txt    100%[===================>] 185,00K   541KB/s    in 0,3s    \n",
      "\n",
      "2023-02-20 17:34:23 (541 KB/s) - ‘/tmp/lemmas_small.txt’ saved [189437/189437]\n",
      "\n",
      "--2023-02-20 17:34:24--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/default-sentiment-dict.txt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 54.231.138.160, 52.216.107.206, 52.217.172.96, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|54.231.138.160|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 289 [text/plain]\n",
      "Saving to: ‘/tmp/default-sentiment-dict.txt’\n",
      "\n",
      "default-sentiment-d 100%[===================>]     289  --.-KB/s    in 0s      \n",
      "\n",
      "2023-02-20 17:34:24 (1,84 MB/s) - ‘/tmp/default-sentiment-dict.txt’ saved [289/289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! rm /tmp/sentiment.parquet.zip\n",
    "! rm -rf /tmp/sentiment.parquet\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip -P /tmp\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/lemma-corpus-small/lemmas_small.txt -P /tmp\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/default-sentiment-dict.txt -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /tmp/sentiment.parquet.zip\n",
      "   creating: /tmp/sentiment.parquet/\n",
      "  inflating: /tmp/sentiment.parquet/.part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      " extracting: /tmp/sentiment.parquet/_SUCCESS  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n"
     ]
    }
   ],
   "source": [
    "! unzip /tmp/sentiment.parquet.zip -d /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+\n",
      "|itemid|sentiment|                text|\n",
      "+------+---------+--------------------+\n",
      "|     1|        0|                 ...|\n",
      "|     2|        0|                 ...|\n",
      "|     3|        1|              omg...|\n",
      "|     4|        0|          .. Omga...|\n",
      "|     5|        0|         i think ...|\n",
      "|     6|        0|         or i jus...|\n",
      "|     7|        1|       Juuuuuuuuu...|\n",
      "|     8|        0|       Sunny Agai...|\n",
      "|     9|        1|      handed in m...|\n",
      "|    10|        1|      hmmmm.... i...|\n",
      "|    11|        0|      I must thin...|\n",
      "|    12|        1|      thanks to a...|\n",
      "|    13|        0|      this weeken...|\n",
      "|    14|        0|     jb isnt show...|\n",
      "|    15|        0|     ok thats it ...|\n",
      "|    16|        0|    &lt;-------- ...|\n",
      "|    17|        0|    awhhe man.......|\n",
      "|    18|        1|    Feeling stran...|\n",
      "|    19|        0|    HUGE roll of ...|\n",
      "|    20|        0|    I just cut my...|\n",
      "+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark. \\\n",
    "        read. \\\n",
    "        parquet(\"/tmp/sentiment.parquet\"). \\\n",
    "        limit(10000).cache()\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create appropriate annotators. We are using Sentence Detection, Tokenizing the sentences, and find the lemmas of those tokens. The Finisher will only output the Sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "lemmatizer = Lemmatizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"lemma\") \\\n",
    "    .setDictionary(\"/tmp/lemmas_small.txt\", key_delimiter=\"->\", value_delimiter=\"\\t\")\n",
    "\n",
    "sentiment_detector = SentimentDetector() \\\n",
    "    .setInputCols([\"lemma\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment_score\") \\\n",
    "    .setDictionary(\"/tmp/default-sentiment-dict.txt\", \",\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"sentiment_score\"]) \\\n",
    "    .setOutputCols([\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the pipeline, which is only being trained from external resources, not from the dataset we pass on. The prediction runs on the target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, lemmatizer, sentiment_detector, finisher])\n",
    "model = pipeline.fit(data)\n",
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. filter the finisher output, to find the positive sentiment lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|itemid|sentiment |text                                                                                                                                |\n",
      "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1     |[positive]|                     is so sad for my APL friend.............                                                                       |\n",
      "|2     |[positive]|                   I missed the New Moon trailer...                                                                                 |\n",
      "|3     |[positive]|              omg its already 7:30 :O                                                                                               |\n",
      "|4     |[positive]|          .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get a crown put on (30mins)...|\n",
      "|5     |[positive]|         i think mi bf is cheating on me!!!       T_T                                                                               |\n",
      "|6     |[positive]|         or i just worry too much?                                                                                                  |\n",
      "|7     |[positive]|       Juuuuuuuuuuuuuuuuussssst Chillin!!                                                                                           |\n",
      "|8     |[positive]|       Sunny Again        Work Tomorrow  :-|       TV Tonight                                                                       |\n",
      "|9     |[positive]|      handed in my uniform today . i miss you already                                                                               |\n",
      "|10    |[positive]|      hmmmm.... i wonder how she my number @-)                                                                                      |\n",
      "+------+----------+------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.where(array_contains(result.sentiment, \"positive\")).show(10,False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
