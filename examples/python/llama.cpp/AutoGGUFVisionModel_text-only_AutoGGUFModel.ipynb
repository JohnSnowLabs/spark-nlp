{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/llama.cpp/AutoGGUFVisionModel_text-only_AutoGGUFModel.ipynb)\n",
    "\n",
    "# Running AutoGGUFVisionModel as text-only AutoGGUFModel\n",
    "\n",
    "This notebook will show you how you can easily load a vision language model (VLM) for text only inference. This way you can run your favorite VLM for your text tasks!\n",
    "\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "- Cross-compatibility between `AutoGGUFModel` and `AutoGGUFVisionModel` support was introduced in `Spark NLP 6.1.1`. Please make sure you have upgraded to the latest Spark NLP release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Save AutoGGUF models in Spark NLP\n",
    "\n",
    "- Let's install and setup Spark NLP (if running it Google Colab)\n",
    "- This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute this if you are on Google Colab\n",
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start Spark with Spark NLP included via our simple `start()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "6.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/05 10:52:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "# let's start Spark with Spark NLP with GPU enabled. If you don't have GPUs available remove this parameter.\n",
    "spark = sparknlp.start(gpu=True)\n",
    "print(sparknlp.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we want to use Qwen2.5 VL 3B Q4 from the pretrained `AutoGGUFVisionModel` but only the text model part. \n",
    "\n",
    "Doing this is easy: we just have to define the correct pretrained model name and load it into `AutoGGUFModel`. The name of this model is `Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf`. You can find the model in the [Models Hub](https://nlp.johnsnowlabs.com/models).\n",
    "You will see that the parameters of the model will be set to default values. This is expected, as some vision specific parameters will not be used in this case. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf download started this may take some time.\n",
      "Approximate size to download 2.5 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf download started this may take some time.\n",
      "Approximate size to download 2.5 GB\n",
      "[ \\ ]Download done! Loading the resource.\n",
      "[ | ]Failed to load all parameters from file:/home/ducha/cache_pretrained/Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf_en_6.1.1_3.0_1754318104734, attempting fallback loader. Parameters will be set to default values.\n",
      "Extracted 'libjllama.so' to '/tmp/libjllama.so'\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "\n",
    "autoGGUFModel = (\n",
    "    AutoGGUFModel.pretrained(\"Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf\")\n",
    "    .setInputCols(\"document\")\n",
    "    .setOutputCol(\"completions\")\n",
    "    .setBatchSize(4)\n",
    "    .setNPredict(20)\n",
    "    .setNGpuLayers(99)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can use it as usual in a Spark NLP pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------+\n",
      "|completions                                                                                   |\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 51, The Moon is approximately 384,400 kilometers (238,85, {sentence -> 0}, []}]|\n",
      "+----------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline().setStages([document_assembler, autoGGUFModel])\n",
    "\n",
    "data = spark.createDataFrame([[\"The moon is \"]]).toDF(\"text\")\n",
    "\n",
    "result = pipeline.fit(data).transform(data)\n",
    "result.select(\"completions\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can now go wild and use hundreds of GGUF models from HuggingFace ðŸ¤— in Spark NLP ðŸš€\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spark-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
