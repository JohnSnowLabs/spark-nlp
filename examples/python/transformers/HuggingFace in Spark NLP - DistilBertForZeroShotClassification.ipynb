{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8IXf_Q668WRo"
   },
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForZeroShotClassification.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fDfihUkE8WRr"
   },
   "source": [
    "## Import DistilBertForZeroShotClassification models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n",
    "\n",
    "Let's keep in mind a few things before we start ðŸ˜Š \n",
    "\n",
    "- This feature is only in `Spark NLP 4.4.1` and after. So please make sure you have upgraded to the latest Spark NLP release\n",
    "- You can import DistilBERT models trained/fine-tuned for sequence classification via `DistilBertForSequenceClassification` or `TFDistilBertForSequenceClassification`. We can use these models for zero-shot classification.\n",
    "  - These models are usually under `Sequence Classification` category and have `distilbert` in their labels\n",
    "  - For zero-shot classification, We will usually use models trained on the nli data sets for best performance.\n",
    "- Reference: [TFDistilBertForSequenceClassification](https://huggingface.co/transformers/model_doc/distilbert.html#tfdistilbertforsequenceclassification)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vMg3NbLo8WRs"
   },
   "source": [
    "## Export and Save HuggingFace model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykej1XKH8WRu"
   },
   "source": [
    "- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n",
    "- We lock TensorFlow on `2.11.0` version and Transformers on `4.25.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yn28bSQi8WRu",
    "outputId": "54c3b582-f829-4052-ce29-791454c17e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.25.1 tensorflow==2.11.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ehfCmKt98WRw"
   },
   "source": [
    "- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n",
    "- We'll use [distilbert-base-uncased-mnli](https://huggingface.co/typeform/distilbert-base-uncased-mnli) model from HuggingFace as an example\n",
    "  - For zero-shot classification, We will usually use models trained on the (m)nli data set for best performance.\n",
    "- In addition to `TFDistilBertForSequenceClassification` we also need to save the `DistilBertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475,
     "referenced_widgets": [
      "f8a1ac89cf5e4a26ad6d30c03a2b8e4d",
      "a2a5e6ebdac742f7b1d4d33123c1c744",
      "b10a1e979e3344ee857b1dfdf88ca748",
      "851a51a9db664e2ca38b6d195384f47a",
      "83fbc4e3720b4791aedc53b77ed3cb19",
      "9d2fa61ddebc49d88c0e9e44d83cf36e",
      "66238454a296491e8bd5ef008d450e38",
      "695c064280044e169f15d9347ab23281",
      "726d4e34581145479154f456c696c278",
      "6df0bcc1a5f144b1bc7fe6f3cfa6a05f",
      "0706c29c1d3c41c2a964f61b2fb72e20",
      "9535415ff7c24a38b8d2e50e3774af01",
      "660ab89806b94f72986d05f86785a4ad",
      "13c72780c3bc4b3987fb5f78bb2a4904",
      "f9436cd1fbbe4d75917b1a4171fed17a",
      "ace0263340a34ac9b8579d5b4666faa7",
      "b23d9d2b72d0488caf2b5dcca31b6314",
      "ce75b803b79a43969269fdf6a890e16e",
      "c9926babdab441b8a0f2a4c4f59ef92b",
      "5399e1fe768345a490175e21a1ece578",
      "3abdf0fcd9e54331b70c8a5008f0c1b5",
      "58dc8096add9432180fd5c8b6eb101c4",
      "c73aaf2bcb674518bb751f508f09292a",
      "09818de216094490870001aca113adba",
      "856bda93ec8941be917ab99623ca4851",
      "ed5990ff8df04548bd259ae01b6e134a",
      "8de2583fc33d48fd8e71b70c9919ea24",
      "522d095cdad54bd48a22260924ecb9c2",
      "f872b7001bcc436985d5cc2e72f7482c",
      "cd2d0543ae6242d2a5d9571d5d4d0726",
      "262a30c072604c048c828db2cd210176",
      "40e34c26038146de9224f61d7bbda5b4",
      "66698d2afeab47458a94bb4aa089184f",
      "16d73d0610d04e52a0a93a45fe09854c",
      "9a1344b59691413480a60f4e3d8cb741",
      "d7af4f84b0ee43f7a26bb4ea7d72f048",
      "7eb50fb21bf74d0f928741211108ea94",
      "b7599ef85f9943e8874a30d5ca071825",
      "d0993edddf534814be5e9e9c726e6011",
      "01c0067c52b44de59fe07165babc8594",
      "abd7567a0bd0495c9a721843786a276d",
      "3d71b8d6a7bd4e26a0e8f6577dbc6d93",
      "c954347f47894d1daa8fb2802e6ebb92",
      "38ee16f0a5d84d92a0be6b3bef817dfe",
      "68a558a48ab144a28137110ffc0dcf3b",
      "341116f0e5074e3f8ce48b1cb0709b00",
      "cc903d6ee439487ab10b881d10167ccf",
      "9a094b07268445b0a7de94bb21e92707",
      "afaa696d4c2c40df8fcc27ce79f634f1",
      "4db458113c9b414d8044cfb8adb7bbba",
      "38b3aa539af04122a723bb79bee08485",
      "57c1248bde6549f4aa5be8aa9b5a353f",
      "830a592bd3594d2cae4fe35c0620b94e",
      "4b5a8de4b92d412eb59306984ac327b1",
      "5cf0e182cba142e7a7e14bac01e39e04"
     ]
    },
    "id": "oCOSyDn88WRx",
    "outputId": "a2b5b435-eb43-4f62-93ad-1c9275c3a21e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a1ac89cf5e4a26ad6d30c03a2b8e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9535415ff7c24a38b8d2e50e3774af01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73aaf2bcb674518bb751f508f09292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/258 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d73d0610d04e52a0a93a45fe09854c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a558a48ab144a28137110ffc0dcf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at typeform/distilbert-base-uncased-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f884580c7c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f884580f400>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8845d72080>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8845d7cd00>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8845d7f940>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8845d8e5c0>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertTokenizer \n",
    "import tensorflow as tf\n",
    "\n",
    "MODEL_NAME = 'typeform/distilbert-base-uncased-mnli'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n",
    "\n",
    "try:\n",
    "  model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "except:\n",
    "  model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME, from_pt=True)\n",
    "    \n",
    "# Define TF Signature\n",
    "@tf.function(\n",
    "  input_signature=[\n",
    "      {\n",
    "          \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n",
    "          \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\")       \n",
    "      }\n",
    "  ]\n",
    ")\n",
    "def serving_fn(input):\n",
    "    return model(input)\n",
    "\n",
    "model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True, signatures={\"serving_default\": serving_fn})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eDjo0QGq8WRy"
   },
   "source": [
    "Let's have a look inside these two directories and see what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daGPGUdz8WRz",
    "outputId": "d84e4167-28a1-47f0-f7e5-d28722ffe63a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261688\n",
      "-rw-r--r-- 1 root root       753 Jun  3 15:53 config.json\n",
      "drwxr-xr-x 3 root root      4096 Jun  3 15:53 saved_model\n",
      "-rw-r--r-- 1 root root 267954880 Jun  3 15:53 tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwQH0R7h8WR1",
    "outputId": "8abc85a8-3f94-4b61-9ed4-f52dcf969092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5008\n",
      "drwxr-xr-x 2 root root    4096 Jun  3 15:53 assets\n",
      "-rw-r--r-- 1 root root      56 Jun  3 15:53 fingerprint.pb\n",
      "-rw-r--r-- 1 root root   80289 Jun  3 15:53 keras_metadata.pb\n",
      "-rw-r--r-- 1 root root 5032374 Jun  3 15:53 saved_model.pb\n",
      "drwxr-xr-x 2 root root    4096 Jun  3 15:53 variables\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}/saved_model/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPztfyM38WR2",
    "outputId": "11fad132-29d2-4057-da33-da8b87bcb38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 236\n",
      "-rw-r--r-- 1 root root    125 Jun  3 15:52 special_tokens_map.json\n",
      "-rw-r--r-- 1 root root    574 Jun  3 15:52 tokenizer_config.json\n",
      "-rw-r--r-- 1 root root 231508 Jun  3 15:52 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}_tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gjrYDipS8WR2"
   },
   "source": [
    "- As you can see, we need the SavedModel from `saved_model/1/` path\n",
    "- We also be needing `vocab.txt` from the tokenizer\n",
    "- All we need is to just copy the `vocab.txt` to `saved_model/1/assets` which Spark NLP will look for\n",
    "- In addition to vocabs, we also need `labels` and their `ids` which is saved inside the model's config. We will save this inside `labels.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnQ0jke38WR3"
   },
   "outputs": [],
   "source": [
    "asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n",
    "\n",
    "!cp {MODEL_NAME}_tokenizer/vocab.txt {asset_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPvOXbeZ8WR4"
   },
   "outputs": [],
   "source": [
    "# get label2id dictionary \n",
    "labels = model.config.label2id\n",
    "# sort the dictionary based on the id\n",
    "labels = sorted(labels, key=labels.get)\n",
    "\n",
    "with open(asset_path+'/labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UzQ650AZ8WR4"
   },
   "source": [
    "Voila! We have our `vocab.txt` and `labels.txt` inside assets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcBOfJ918WR4",
    "outputId": "10112997-f328-4747-fb7f-0d37072e29e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 232\n",
      "-rw-r--r-- 1 root root     32 Jun  3 15:53 labels.txt\n",
      "-rw-r--r-- 1 root root 231508 Jun  3 15:53 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}/saved_model/1/assets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zk28iNof8WR5"
   },
   "source": [
    "## Import and Save DistilBertForZeroShotClassification in Spark NLP\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "J__aVVu48WR5"
   },
   "source": [
    "- Let's install and setup Spark NLP in Google Colab\n",
    "- This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udnbTHNj8WR6",
    "outputId": "e0b6b426-2e0d-4be8-d831-bcea5d64f288"
   },
   "outputs": [],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5u9B2ldj8WR6"
   },
   "source": [
    "Let's start Spark with Spark NLP included via our simple `start()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twQ6BHyo8WR6"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rOEy0EXR8WR7"
   },
   "source": [
    "- Let's use `loadSavedModel` functon in `DistilBertForZeroShotClassification` which allows us to load TensorFlow model in SavedModel format\n",
    "- Most params can be set later when you are loading this model in `DistilBertForZeroShotClassification` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n",
    "- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n",
    "- NOTE: `loadSavedModel` accepts local paths in addition to distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. This feature was introduced in Spark NLP 4.2.2 release. Keep in mind the best and recommended way to move/share/reuse Spark NLP models is to use `write.save` so you can use `.load()` from any file systems natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcqReFJO8WR7"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "zero_shot_classifier = DistilBertForZeroShotClassification.loadSavedModel(\n",
    "    '{}/saved_model/1'.format(MODEL_NAME),\n",
    "    spark\n",
    "    )\\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"class\") \\\n",
    "    .setCandidateLabels([\"urgent\", \"mobile\", \"travel\", \"movie\", \"music\", \"sport\", \"weather\", \"technology\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VmHVmBCo8WR9"
   },
   "source": [
    "- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RBvw6p58WR9"
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DgUg2p0v8WR9"
   },
   "source": [
    "Let's clean up stuff we don't need anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdBziZhw8WR-"
   },
   "outputs": [],
   "source": [
    "!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_iwYIQ6U8WR-"
   },
   "source": [
    "Awesome ðŸ˜Ž  !\n",
    "\n",
    "This is your DistilBertForSequenceClassification model from HuggingFace ðŸ¤—  loaded and saved by Spark NLP ðŸš€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JAkr3438WR-",
    "outputId": "2ec0cc08-2122-4301-e7dc-84fb91eabf5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 266440\n",
      "-rw-r--r-- 1 root root 272826157 Jun  3 15:58 distilbert_classification_tensorflow\n",
      "drwxr-xr-x 5 root root      4096 Jun  3 15:58 fields\n",
      "drwxr-xr-x 2 root root      4096 Jun  3 15:58 metadata\n"
     ]
    }
   ],
   "source": [
    "! ls -l {MODEL_NAME}_spark_nlp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D5c2xWtt8WR-"
   },
   "source": [
    "Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny BertForSequenceClassification model ðŸ˜Š "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjxWoPhW8WR_"
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier_loaded = DistilBertForZeroShotClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
    "  .setInputCols([\"document\",'token'])\\\n",
    "  .setOutputCol(\"class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rAITDhUg8WSA"
   },
   "source": [
    "This is how you can use your loaded classifier model in Spark NLP ðŸš€ pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4svOlV88WSA",
    "outputId": "da5aefa6-efb2-43f4-9cf4-537cac5afe3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|      result|\n",
      "+------------+\n",
      "|    [mobile]|\n",
      "|[technology]|\n",
      "|    [mobile]|\n",
      "|    [travel]|\n",
      "|   [weather]|\n",
      "|     [sport]|\n",
      "|    [urgent]|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols(\"document\").setOutputCol(\"token\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    zero_shot_classifier_loaded\n",
    "])\n",
    "\n",
    "text = [[\"I have a problem with my iphone that needs to be resolved asap!!\"],\n",
    "        [\"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"],\n",
    "        [\"I have a phone and I love it!\"],\n",
    "        [\"I really want to visit Germany and I am planning to go there next year.\"],\n",
    "        [\"Let's watch some movies tonight! I am in the mood for a horror movie.\"],\n",
    "        [\"Have you watched the match yesterday? It was a great game!\"],\n",
    "        [\"We need to harry up and get to the airport. We are going to miss our flight!\"]]\n",
    "\n",
    "# create a DataFrame in PySpark\n",
    "inputDataset = spark.createDataFrame(text, [\"text\"])\n",
    "model = pipeline.fit(inputDataset)\n",
    "model.transform(inputDataset).select(\"class.result\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "26gEdXR28WSB"
   },
   "source": [
    "That's it! You can now go wild and use hundreds of \n",
    "`DistilBertForSequenceClassification` models as zero-shot classifiers from HuggingFace ðŸ¤— in Spark NLP ðŸš€"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:nlpdev]",
   "language": "python",
   "name": "conda-env-nlpdev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
