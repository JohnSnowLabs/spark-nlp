{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBERT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DistilBERT models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n",
    "\n",
    "Let's keep in mind a few things before we start ðŸ˜Š \n",
    "\n",
    "- This feature is only in `Spark NLP 3.1.x` and after. So please make sure you have upgraded to the latest Spark NLP release\n",
    "- You can import models for DistilBERT from HuggingFace but they have to be compatible with `TensorFlow` and they have to be in `Fill Mask` category. Meaning, you cannot use DistilBERT models trained/fine-tuned on a specific task such as token/sequence classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Save HuggingFace model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n",
    "- We lock TensorFlow on `2.11.0` version and Transformers on `4.25.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers==4.25.1 tensorflow==2.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n",
    "- We'll use [distilbert-base-uncased](https://huggingface.co/distilbert-base-uncased) model from HuggingFace as an example\n",
    "- In addition to `TFDistilBertModel` we also need to save the `DistilBertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME).save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n",
    "\n",
    "# just in case if there is no TF/Keras file provided in the model\n",
    "# we can just use `from_pt` and convert PyTorch to TensorFlow\n",
    "try:\n",
    "  print('try downloading TF weights')\n",
    "  model = TFDistilBertModel.from_pretrained(MODEL_NAME)\n",
    "except:\n",
    "  print('try downloading PyTorch weights')\n",
    "  model = TFDistilBertModel.from_pretrained(MODEL_NAME, from_pt=True)\n",
    "\n",
    "# Define TF Signature\n",
    "@tf.function(\n",
    "  input_signature=[\n",
    "      {\n",
    "          \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n",
    "          \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\")       \n",
    "      }\n",
    "  ]\n",
    ")\n",
    "def serving_fn(input):\n",
    "    return model(input)\n",
    "\n",
    "model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True, signatures={\"serving_default\": serving_fn})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look inside these two directories and see what we are dealing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 518704\n",
      "-rw-r--r--  1 maziyar  staff        518 Dec 15 14:46 config.json\n",
      "drwxr-xr-x  3 maziyar  staff         96 Dec 15 14:46 \u001b[34msaved_model\u001b[m\u001b[m\n",
      "-rw-r--r--  1 maziyar  staff  265571968 Dec 15 14:46 tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9472\n",
      "drwxr-xr-x  2 maziyar  staff       64 Dec 15 14:46 \u001b[34massets\u001b[m\u001b[m\n",
      "-rw-r--r--  1 maziyar  staff       55 Dec 15 14:46 fingerprint.pb\n",
      "-rw-r--r--  1 maziyar  staff    77329 Dec 15 14:46 keras_metadata.pb\n",
      "-rw-r--r--  1 maziyar  staff  4764278 Dec 15 14:46 saved_model.pb\n",
      "drwxr-xr-x  4 maziyar  staff      128 Dec 15 14:46 \u001b[34mvariables\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}/saved_model/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 472\n",
      "-rw-r--r--  1 maziyar  staff     125 Dec 15 14:46 special_tokens_map.json\n",
      "-rw-r--r--  1 maziyar  staff     412 Dec 15 14:46 tokenizer_config.json\n",
      "-rw-r--r--  1 maziyar  staff  231508 Dec 15 14:46 vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -l {MODEL_NAME}_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- as you can see, we need the SavedModel from `saved_model/1/` path\n",
    "- we also be needing `vocab.txt` from the tokenizer\n",
    "- all we need is to just copy the `vocab.txt` to `saved_model/1/assets` which Spark NLP will look for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {MODEL_NAME}_tokenizer/vocab.txt {MODEL_NAME}/saved_model/1/assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Save DistilBERT in Spark NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's install and setup Spark NLP in Google Colab\n",
    "- This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing PySpark 3.2.1 and Spark NLP 4.2.4\n",
      "setup Colab for PySpark 3.2.1 and Spark NLP 4.2.4\n"
     ]
    }
   ],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start Spark with Spark NLP included via our simple `start()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's use `loadSavedModel` functon in `DistilBertEmbeddings` which allows us to load TensorFlow model in SavedModel format\n",
    "- Most params can be set later when you are loading this model in `DistilBertEmbeddings` in runtime, so don't worry what you are setting them now\n",
    "- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n",
    "- `setStorageRef` is very important. When you are training a task like NER or any Text Classification, we use this reference to bound the trained model to this specific embeddings so you won't load a different embeddings by mistake and see terrible results ðŸ˜Š\n",
    "- It's up to you what you put in `setStorageRef` but it cannot be changed later on. We usually use the name of the model to be clear, but you can get creative if you want! \n",
    "- The `dimension` param is is purely cosmetic and won't change anything. It's mostly for you to know later via `.getDimension` what is the dimension of your model. So set this accordingly.\n",
    "- NOTE: `loadSavedModel` accepts local paths in addition to distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. This feature was introduced in Spark NLP 4.2.2 release. Keep in mind the best and recommended way to move/share/reuse Spark NLP models is to use `write.save` so you can use `.load()` from any file systems natively..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "\n",
    "distil_bert = DistilBertEmbeddings.loadSavedModel(\n",
    "     '{}/saved_model/1'.format(MODEL_NAME),\n",
    "     spark\n",
    " )\\\n",
    " .setInputCols([\"sentence\",'token'])\\\n",
    " .setOutputCol(\"embeddings\")\\\n",
    " .setCaseSensitive(False)\\\n",
    " .setDimension(768)\\\n",
    " .setStorageRef('distilbert_base_uncased') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_bert.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up stuff we don't need anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome ðŸ˜Ž  !\n",
    "\n",
    "This is your DistilERT model from HuggingFace ðŸ¤— loaded and saved by Spark NLP ðŸš€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 527720\n",
      "-rw-r--r--  1 maziyar  staff  270191794 Dec 15 14:53 distilbert_tensorflow\n",
      "drwxr-xr-x  4 maziyar  staff        128 Dec 15 14:53 \u001b[34mfields\u001b[m\u001b[m\n",
      "drwxr-xr-x  6 maziyar  staff        192 Dec 15 14:53 \u001b[34mmetadata\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls -l {MODEL_NAME}_spark_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny DistilBERT model ðŸ˜Š "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_loaded = DistilBertEmbeddings.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n",
    "  .setInputCols([\"sentence\",'token'])\\\n",
    "  .setOutputCol(\"embeddings\")\\\n",
    "  .setCaseSensitive(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert_base_uncased'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_loaded.getStorageRef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can now go wild and use hundreds of DistilBERT models from HuggingFace ðŸ¤— in Spark NLP ðŸš€ \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HuggingFace in Spark NLP - DistilBERT.ipynb",
   "provenance": [
    {
     "file_id": "1wPsMf2tqrA0uR_qfBT4HY_CozriMZUBF",
     "timestamp": 1622473868648
    }
   ]
  },
  "kernelspec": {
   "display_name": "sparknlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
