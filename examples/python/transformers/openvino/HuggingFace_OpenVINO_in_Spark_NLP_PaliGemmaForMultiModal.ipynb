{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/openvino/HuggingFace_OpenVINO_in_Spark_NLP_PaliGemmaForMultiModal.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import OpenVINO PaliGemma models from HuggingFace ðŸ¤— into Spark NLP ðŸš€\n",
    "\n",
    "This notebook provides a detailed walkthrough on optimizing and importing PaliGemma models from HuggingFace for use in Spark NLP, with [Intel OpenVINO toolkit](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html). The focus is on converting the model to the OpenVINO format and applying precision optimizations (INT8 and INT4), to enhance the performance and efficiency on CPU platforms using [Optimum Intel](https://huggingface.co/docs/optimum/main/en/intel/inference).\n",
    "\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "- OpenVINO support was introduced in `Spark NLP 5.4.0`, enabling high performance CPU inference for models. So please make sure you have upgraded to the latest Spark NLP release.\n",
    "- Model quantization is a computationally expensive process, so it is recommended to use a runtime with more than 32GB memory for exporting the quantized model from HuggingFace.\n",
    "- You can import PaliGemma models via `PaliGemma`. These models are usually under the `Text Generation` category and have `PaliGemma` in their labels.\n",
    "- Reference: [PaliGemma](https://huggingface.co/docs/transformers/model_doc/llama#transformers.PaliGemma)\n",
    "- Some [example models](https://huggingface.co/models?search=PaliGemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Installation](#setup-and-installation)\n",
    "2. [Model Configuration](#model-configuration)\n",
    "3. [Model Loading and Preparation](#model-loading-and-preparation)\n",
    "4. [Model Conversion to OpenVINO](#model-conversion-to-openvino)\n",
    "5. [Model Quantization](#model-quantization)\n",
    "6. [Model Merger Implementation](#model-merger-implementation)\n",
    "7. [Testing OpenVINO Model](#7-testing-openvino-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install all the required dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenVINO and NNCF for model optimization\n",
    "%pip install -qU \"openvino>=2024.4.0\" \"nncf>=2.13.0\"\n",
    "\n",
    "# Install NLP and tokenization libraries\n",
    "%pip install -q  \"sentencepiece\" \"tokenizers>=0.12.1\" \"transformers>=4.46.0\" \"gradio>=4.36\"\n",
    "\n",
    "# Install OpenVINO nightly builds for latest features\n",
    "%pip install -q -U --pre --extra-index-url https://storage.openvinotoolkit.org/simple/wheels/nightly openvino-tokenizers openvino openvino-genai\n",
    "\n",
    "# Install HuggingFace Hub and PyTorch\n",
    "%pip install -q --upgrade huggingface_hub\n",
    "%pip install -q --upgrade torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "Configure the environment to disable tokenizer parallelism for better compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable tokenizer parallelism to avoid potential issues\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/openvino/runtime/__init__.py:10: DeprecationWarning: The `openvino.runtime` module is deprecated and will be removed in the 2026.0 release. Please replace `openvino.runtime` with `openvino`.\n",
      "  warnings.warn(\n",
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import types\n",
    "from typing import Optional, List\n",
    "import gc\n",
    "import openvino as ov\n",
    "from openvino.runtime import opset13\n",
    "import nncf\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoConfig, PaliGemmaForConditionalGeneration\n",
    "from openvino.frontend.pytorch.patch_model import __make_16bit_traceable\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Set up the model ID and quantization parameters for the conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/paligemma-3b-mix-224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_method = \"int4\"\n",
    "output_dir = Path(f\"models/{model_id}/{quantization_method}\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Loading and Preparation\n",
    "\n",
    "Load the model processor, configuration, and prepare the model for conversion to OpenVINO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True, )\n",
    "\n",
    "# load the config\n",
    "config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "# Change the model to use SDPA attention\n",
    "# This is a workaround for the model to be compatible with OpenVINO\n",
    "config.text_config._attn_implementation = \"sdpa\"\n",
    "\n",
    "\n",
    "# export the processor and config to output_dir/assets\n",
    "processor.save_pretrained(output_dir/\"assets\")\n",
    "config.save_pretrained(output_dir/\"assets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, trust_remote_code=True, config=config)\n",
    "model.eval()\n",
    "__make_16bit_traceable(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Conversion to OpenVINO\n",
    "\n",
    "Define paths for the converted model components and implement conversion utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "image_encoder_path = output_dir / \"image_encoder.xml\"\n",
    "language_model_path = output_dir / \"language_model.xml\"\n",
    "model_merger_path = output_dir / \"model_merger.xml\"\n",
    "text_embeddings_path = output_dir / \"text_embeddings.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_torchscript_cache():\n",
    "    \"\"\"\n",
    "    Helper function for removing cached model representation to prevent memory leaks\n",
    "    during model conversion.\n",
    "    \"\"\"\n",
    "    torch._C._jit_clear_class_registry()\n",
    "    torch.jit._recursive.concrete_type_store = torch.jit._recursive.ConcreteTypeStore()\n",
    "    torch.jit._state._clear_class_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Text Embeddings Component\n",
    "\n",
    "Convert the text embeddings component of the model to OpenVINO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:nncf:NNCF provides best results with torch==2.5.*, while current torch version is 2.6.0+cu124. If you encounter issues, consider switching to torch==2.5.*\n"
     ]
    }
   ],
   "source": [
    "# save text embeddings\n",
    "with torch.no_grad():\n",
    "    ov_model = ov.convert_model(\n",
    "        model.language_model.model.embed_tokens,\n",
    "        example_input=torch.ones([2, 2], dtype=torch.int64),\n",
    "    )\n",
    "    ov.save_model(ov_model, text_embeddings_path)\n",
    "    del ov_model\n",
    "    cleanup_torchscript_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Vision Model Components\n",
    "\n",
    "Convert the vision model components to OpenVINO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionEncoder(nn.Module):\n",
    "  def __init__(self, paligemma_model):\n",
    "    super().__init__()\n",
    "    self.config = paligemma_model.config\n",
    "    self.vision_tower = paligemma_model.vision_tower\n",
    "    self.multi_modal_projector = paligemma_model.multi_modal_projector\n",
    "\n",
    "  def forward(self, pixel_values: torch.FloatTensor):\n",
    "      \"\"\"\n",
    "      Obtains image last hidden states from the vision tower and apply multimodal projection.\n",
    "\n",
    "      Args:\n",
    "          pixel_values (`torch.FloatTensor]` of shape `(batch_size, channels, height, width)`)\n",
    "              The tensors corresponding to the input images.\n",
    "      Returns:\n",
    "          image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).\n",
    "      \"\"\"\n",
    "      image_outputs = self.vision_tower(pixel_values)\n",
    "      selected_image_feature = image_outputs.last_hidden_state\n",
    "      image_features = self.multi_modal_projector(selected_image_feature)\n",
    "      image_features = image_features / (self.config.text_config.hidden_size**0.5)\n",
    "      return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "vision_model = VisionEncoder(model)\n",
    "with torch.no_grad():\n",
    "    ov_model = ov.convert_model(\n",
    "        vision_model,\n",
    "        example_input=torch.ones([2, 3, config.vision_config.image_size, config.vision_config.image_size], dtype=torch.float32),\n",
    "    )\n",
    "    ov.save_model(ov_model, image_encoder_path)\n",
    "    del ov_model\n",
    "    cleanup_torchscript_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Quantization\n",
    "\n",
    "Implement functions for model state management and quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_has_state(ov_model: ov.Model):\n",
    "    return len(ov_model.get_sinks()) > 0\n",
    "\n",
    "\n",
    "def model_has_input_output_name(ov_model: ov.Model, name: str):\n",
    "    \"\"\"\n",
    "    Helper function for checking that model has specified input or output name\n",
    "\n",
    "    Parameters:\n",
    "      ov_model (ov.Model):\n",
    "      name (str):\n",
    "          name of input or output\n",
    "\n",
    "    Returns:\n",
    "      True if input or output with requested name exists else False\n",
    "    \"\"\"\n",
    "    return name in sum([list(t.get_names()) for t in ov_model.inputs + ov_model.outputs], [])\n",
    "\n",
    "\n",
    "def fuse_cache_reorder(\n",
    "    ov_model: ov.Model,\n",
    "    not_kv_inputs: List[str],\n",
    "    key_value_input_names: List[str],\n",
    "    gather_dim: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fuses reored_cache during generate cycle into ov.Model. Used with stateful models, because we can not modify model state directly.\n",
    "\n",
    "    Adds a new beam_idx parameter and Gather op per each kv-cache input in a given model.\n",
    "    Should be run before make_stateful. Implements optimumum's _reorder_cache\n",
    "    inside the model in the beginning of each iteration.\n",
    "    Gather works along given gather_dim dimension that may vary from model to model.\n",
    "    KV-cache inputs are identified based on names in key_value_input_names.\n",
    "    Append the new beam_idx parameter to not_kv_inputs.\n",
    "\n",
    "    Parameters:\n",
    "      ov_model (`ov.Model`):\n",
    "          openvino model for processing\n",
    "      not_kv_inputs (`List[str]`):\n",
    "          list of input nodes in model that not related to past key values\n",
    "      key_value_input_names (`List[str]`):\n",
    "          list of names for key value input layers\n",
    "      gather_dim (int):\n",
    "          dimension for gathering cache during reorder pass\n",
    "    \"\"\"\n",
    "\n",
    "    if model_has_input_output_name(ov_model, \"beam_idx\"):\n",
    "        raise ValueError(\"Model already has fused cache\")\n",
    "    input_batch = ov_model.input(\"inputs_embeds\").get_partial_shape()[0]\n",
    "    beam_idx = opset13.parameter(name=\"beam_idx\", dtype=ov.Type.i32, shape=ov.PartialShape([input_batch]))\n",
    "    beam_idx.output(0).get_tensor().add_names({\"beam_idx\"})  # why list is not accepted?\n",
    "    ov_model.add_parameters([beam_idx])\n",
    "    not_kv_inputs.append(ov_model.inputs[-1])\n",
    "    # Go over all cache parameters and fuse _reorder_cache with indices provided by the new parameter beam_idx\n",
    "    for input_name in key_value_input_names:\n",
    "        parameter_output_port = ov_model.input(input_name)\n",
    "        consumers = parameter_output_port.get_target_inputs()\n",
    "        gather = opset13.gather(parameter_output_port, beam_idx, opset13.constant(gather_dim))\n",
    "        for consumer in consumers:\n",
    "            consumer.replace_source_output(gather.output(0))\n",
    "    ov_model.validate_nodes_and_infer_types()\n",
    "\n",
    "\n",
    "def build_state_initializer(ov_model: ov.Model, batch_dim: int):\n",
    "    \"\"\"\n",
    "    Build initialization ShapeOf Expression for all ReadValue ops\n",
    "\n",
    "    Parameters:\n",
    "      ov_model (ov.Model):\n",
    "          openvino model\n",
    "      batch_dim (int):\n",
    "          index of dimension corresponding to batch size\n",
    "    \"\"\"\n",
    "    input_ids = ov_model.input(\"inputs_embeds\")\n",
    "    batch = opset13.gather(\n",
    "        opset13.shape_of(input_ids, output_type=\"i64\"),\n",
    "        opset13.constant([0]),\n",
    "        opset13.constant(0),\n",
    "    )\n",
    "    for op in ov_model.get_ops():\n",
    "        if op.get_type_name() == \"ReadValue\":\n",
    "            dims = [dim.min_length for dim in list(op.get_output_partial_shape(0))]\n",
    "            dims[batch_dim] = batch\n",
    "            dims = [(opset13.constant(np.array([dim], dtype=np.int64)) if isinstance(dim, int) else dim) for dim in dims]\n",
    "            shape = opset13.concat(dims, axis=0)\n",
    "            broadcast = opset13.broadcast(opset13.constant(0.0, dtype=op.get_output_element_type(0)), shape)\n",
    "            op.set_arguments([broadcast])\n",
    "    ov_model.validate_nodes_and_infer_types()\n",
    "\n",
    "\n",
    "def make_stateful(\n",
    "    ov_model: ov.Model,\n",
    "    not_kv_inputs: List[str],\n",
    "    key_value_input_names: List[str],\n",
    "    key_value_output_names: List[str],\n",
    "    batch_dim: int,\n",
    "    num_attention_heads: int,\n",
    "    num_beams_and_batch: int = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hides kv-cache inputs and outputs inside the model as variables.\n",
    "\n",
    "    Parameters:\n",
    "        ov_model (ov.Model):\n",
    "            openvino model\n",
    "        not_kv_inputs (`List[str]`):\n",
    "            list of input nodes in model that not related to past key values\n",
    "        key_value_input_names (`List[str]`):\n",
    "            list of names for key value input layers\n",
    "        key_value_output_names (`List[str]`):\n",
    "            list of names for key value input layers\n",
    "        batch_dim (int):\n",
    "            index of batch dimension in key value layers\n",
    "        num_attention_heads (int):\n",
    "            number of attention heads for batch dimension initialization\n",
    "        num_beams_an_batch (int):\n",
    "            precalculated number of beams and batch for shapes initialization\n",
    "    \"\"\"\n",
    "    from openvino._offline_transformations import apply_make_stateful_transformation\n",
    "\n",
    "    input_output_map = {}\n",
    "\n",
    "    if num_beams_and_batch is not None:\n",
    "        # Set batch size for input_ids and attention mask to avoid dynamic dimension got propagated from the end of the model back to ReadValue\n",
    "        for input in not_kv_inputs:\n",
    "            shape = input.get_partial_shape()\n",
    "            if shape.rank.get_length() <= 2:  # == 1 for beam_index\n",
    "                shape[0] = num_beams_and_batch\n",
    "                input.get_node().set_partial_shape(shape)\n",
    "    for kv_name_pair in zip(key_value_input_names, key_value_output_names):\n",
    "        input_output_map[kv_name_pair[0]] = kv_name_pair[1]\n",
    "        if num_beams_and_batch is not None:\n",
    "            input = ov_model.input(kv_name_pair[0])\n",
    "            shape = input.get_partial_shape()\n",
    "            shape[batch_dim] = num_beams_and_batch * num_attention_heads\n",
    "            input.get_node().set_partial_shape(shape)\n",
    "\n",
    "    if num_beams_and_batch is not None:\n",
    "        # Re-validation model if shapes are altered above\n",
    "        ov_model.validate_nodes_and_infer_types()\n",
    "\n",
    "    apply_make_stateful_transformation(ov_model, input_output_map)\n",
    "    if num_beams_and_batch is None:\n",
    "        build_state_initializer(ov_model, batch_dim)\n",
    "\n",
    "\n",
    "def patch_stateful(ov_model):\n",
    "    key_value_input_names = [key.get_any_name() for key in ov_model.inputs[2:-1]]\n",
    "    key_value_output_names = [key.get_any_name() for key in ov_model.outputs[1:]]\n",
    "    not_kv_inputs = [input for input in ov_model.inputs if not any(name in key_value_input_names for name in input.get_names())]\n",
    "    if not key_value_input_names or not key_value_output_names:\n",
    "        return\n",
    "    batch_dim = 0\n",
    "    num_attention_heads = 1\n",
    "\n",
    "    fuse_cache_reorder(ov_model, not_kv_inputs, key_value_input_names, batch_dim)\n",
    "    make_stateful(\n",
    "        ov_model,\n",
    "        not_kv_inputs,\n",
    "        key_value_input_names,\n",
    "        key_value_output_names,\n",
    "        batch_dim,\n",
    "        num_attention_heads,\n",
    "        None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Quantization Process\n",
    "\n",
    "The quantization process reduces the precision of the model weights from floating-point to integer format, which can significantly reduce model size and improve inference speed. We're using INT4 quantization in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/transformers/cache_utils.py:460: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  or len(self.key_cache[layer_idx]) == 0  # the layer has no cache\n",
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/transformers/models/gemma/modeling_gemma.py:731: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if sequence_length != 1:\n",
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/nncf/torch/dynamic_graph/wrappers.py:85: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  op1 = operator(*args, **kwargs)\n",
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/transformers/cache_utils.py:444: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  len(self.key_cache[layer_idx]) == 0\n",
      "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/torch/jit/_trace.py:165: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if a.grad is not None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Language model successfully converted\n",
      "âŒ› Weights compression with int4_asym mode started\n",
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¯â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”‘\n",
      "â”‚ Weight compression mode   â”‚ % all parameters (layers)   â”‚ % ratio-defining parameters (layers)   â”‚\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¿â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¿â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”¥\n",
      "â”‚ int8_asym                 â”‚ 21% (1 / 127)               â”‚ 0% (0 / 126)                           â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ int4_asym                 â”‚ 79% (126 / 127)             â”‚ 100% (126 / 126)                       â”‚\n",
      "â”•â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”·â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”™\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\"\n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/prabod/anaconda3/envs/smolvlm/lib/python3.9/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\"\n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Weights compression finished\n"
     ]
    }
   ],
   "source": [
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "quantization_config = {\n",
    "    \"mode\": nncf.CompressWeightsMode.INT4_ASYM,\n",
    "    \"group_size\": 128,\n",
    "    \"ratio\": 1.0,\n",
    "}\n",
    "lang_model = model.language_model\n",
    "def forward_wrap(\n",
    "        self,\n",
    "        attention_mask,\n",
    "        position_ids=None,\n",
    "        past_key_values=None,\n",
    "        inputs_embeds=None,\n",
    "    ):\n",
    "        if past_key_values is not None:\n",
    "            new_past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n",
    "        else:\n",
    "            new_past_key_values = None\n",
    "        result = self._orig_forward(\n",
    "            input_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=new_past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "        if past_key_values is not None:\n",
    "            result[\"past_key_values\"] = result[\"past_key_values\"].to_legacy_cache()\n",
    "        return tuple(result.values())\n",
    "\n",
    "lang_model._orig_forward = lang_model.forward\n",
    "lang_model.forward = types.MethodType(forward_wrap, lang_model)\n",
    "hidden_size = lang_model.config.hidden_size\n",
    "llm_input = torch.zeros([2, 2, hidden_size])\n",
    "pkv = lang_model._orig_forward(\n",
    "        inputs_embeds=llm_input,\n",
    "        attention_mask=torch.ones((2, 2), dtype=torch.int64),\n",
    "        past_key_values= DynamicCache()\n",
    "    )[1]\n",
    "try:\n",
    "    pkv = pkv.to_legacy_cache()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    legacy_cache = ()\n",
    "    for layer_idx in range(lang_model.config.num_hidden_layers):\n",
    "        legacy_cache += ((pkv.key_cache[layer_idx], pkv.value_cache[layer_idx]))\n",
    "    pkv = legacy_cache\n",
    "model_inputs = [\"attention_mask\", \"position_ids\"]\n",
    "model_outputs = [\"logits\"]\n",
    "for idx in range(len(pkv)):\n",
    "    model_inputs.extend([f\"past_key_values.{idx}.key\", f\"past_key_values.{idx}.value\"])\n",
    "    model_outputs.extend([f\"present.{idx}.key\", f\"present.{idx}.value\"])\n",
    "model_inputs.append(\"inputs_embeds\")\n",
    "position_ids = torch.tensor([[2, 3], [2, 3]])\n",
    "with torch.no_grad():\n",
    "    ov_model = ov.convert_model(\n",
    "        lang_model,\n",
    "        example_input={\n",
    "            \"inputs_embeds\": llm_input,\n",
    "            \"attention_mask\": torch.ones([2, 4], dtype=torch.int64),\n",
    "            \"past_key_values\": pkv,\n",
    "            \"position_ids\": position_ids,\n",
    "        },\n",
    "    )\n",
    "for input, input_name in zip(ov_model.inputs, model_inputs):\n",
    "            input.get_tensor().set_names({input_name})\n",
    "\n",
    "for output, output_name in zip(ov_model.outputs, model_outputs):\n",
    "    output.get_tensor().set_names({output_name})\n",
    "patch_stateful(ov_model)\n",
    "print(\"âœ… Language model successfully converted\")\n",
    "fp_lang_model_path = language_model_path if quantization_config is None else language_model_path.parent / (\"fp_\" + language_model_path.name)\n",
    "ov.save_model(ov_model, fp_lang_model_path)\n",
    "del ov_model\n",
    "cleanup_torchscript_cache()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "ov_model = core.read_model(fp_lang_model_path)\n",
    "print(f\"âŒ› Weights compression with {quantization_config['mode']} mode started\")\n",
    "c_ov_model = nncf.compress_weights(ov_model, **quantization_config)\n",
    "print(\"âœ… Weights compression finished\")\n",
    "ov.save_model(c_ov_model, language_model_path)\n",
    "del c_ov_model\n",
    "del ov_model\n",
    "gc.collect()\n",
    "\n",
    "# delete fp_lang_model_path\n",
    "fp_lang_model_path.unlink(missing_ok=True)\n",
    "fp_lang_model_path.with_suffix(\".bin\").unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Merger Implementation\n",
    "\n",
    "Implement the model merger to combine text and image components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class MergeMultiModalInputs(torch.nn.Module):\n",
    "    def __init__(self,image_token_index=257152):\n",
    "        super().__init__()\n",
    "        self.image_token_index = image_token_index\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        vision_embeds,\n",
    "        inputs_embeds,\n",
    "        input_ids,\n",
    "    ):\n",
    "        image_features = vision_embeds\n",
    "        inputs_embeds = inputs_embeds\n",
    "        special_image_mask = (input_ids == self.image_token_index).unsqueeze(-1).expand_as(inputs_embeds)\n",
    "        # image_features = image_features.to(inputs_embeds.dtype)\n",
    "        final_embedding = inputs_embeds.masked_scatter(special_image_mask, image_features)\n",
    "\n",
    "        return {\n",
    "            \"final_embedding\": final_embedding\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_merger = MergeMultiModalInputs(config.image_token_index)\n",
    "with torch.no_grad():\n",
    "    ov_model = ov.convert_model(\n",
    "        multimodal_merger,\n",
    "        example_input= {\n",
    "            \"input_ids\": torch.ones([2, 1198], dtype=torch.int64),\n",
    "            \"inputs_embeds\": torch.ones([2, 1198, config.hidden_size], dtype=torch.float32),\n",
    "            \"vision_embeds\": torch.ones([2, config.vision_config.num_image_tokens, config.hidden_size], dtype=torch.float32),\n",
    "        }\n",
    "    )\n",
    "    ov.save_model(ov_model, model_merger_path)\n",
    "    del ov_model\n",
    "    cleanup_torchscript_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Testing OpenVINO Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "device = \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for the exported models\n",
    "image_encoder_path = output_dir / \"image_encoder.xml\"\n",
    "language_model_path = output_dir / \"language_model.xml\"\n",
    "model_merger_path = output_dir / \"model_merger.xml\"\n",
    "text_embeddings_path = output_dir / \"text_embeddings.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the models\n",
    "language_model = core.read_model(language_model_path)\n",
    "compiled_language_model = core.compile_model(language_model, \"AUTO\")\n",
    "\n",
    "image_encoder = core.compile_model(image_encoder_path, device)\n",
    "model_merger = core.compile_model(model_merger_path, device)\n",
    "text_embeddings = core.compile_model(text_embeddings_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this image we can see the statue of liberty on the water. In the background we can see the buildings and the sky.\n"
     ]
    }
   ],
   "source": [
    "from transformers.image_utils import load_image\n",
    "from transformers import AutoProcessor, TextStreamer\n",
    "from transformers import AutoProcessor, AutoConfig\n",
    "\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "image1 = load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Instruct the model to create a caption in english\n",
    "prompt = \"caption en\"\n",
    "inputs_new = processor(text=prompt, images=image1, return_tensors=\"pt\")\n",
    "\n",
    "request = compiled_language_model.create_infer_request()\n",
    "merge_model_request = model_merger.create_infer_request()\n",
    "# Set the input names\n",
    "input_names = {key.get_any_name(): idx for idx, key in enumerate(language_model.inputs)}\n",
    "inputs = {}\n",
    "# Set the initial input_ids\n",
    "current_input_ids = inputs_new[\"input_ids\"]\n",
    "attention_mask = inputs_new[\"attention_mask\"]\n",
    "position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "position_ids.masked_fill_(attention_mask == 0, 1)\n",
    "pixel_values = inputs_new[\"pixel_values\"]\n",
    "\n",
    "\n",
    "generation_args = {\"max_new_tokens\": 200, \"do_sample\": False, \"streamer\": TextStreamer(processor.tokenizer, skip_prompt=True, skip_special_tokens=True)}\n",
    "generated_tokens = []\n",
    "\n",
    "for i in range(generation_args[\"max_new_tokens\"]):\n",
    "    # Generate input embeds each time\n",
    "    text_embeds = torch.from_numpy(\n",
    "            text_embeddings(current_input_ids\n",
    "            )[0]\n",
    "        )\n",
    "    if current_input_ids.shape[-1] > 1:\n",
    "        vision_embeds = torch.from_numpy(\n",
    "            image_encoder(\n",
    "                {\n",
    "                    \"pixel_values\": pixel_values,\n",
    "                }\n",
    "            )[0]\n",
    "        )\n",
    "        merge_model_request.start_async({\n",
    "            \"vision_embeds\": vision_embeds,\n",
    "            \"inputs_embeds\": text_embeds,\n",
    "            \"input_ids\": current_input_ids,\n",
    "        }, share_inputs=True)\n",
    "        merge_model_request.wait()\n",
    "        final_embedding = torch.from_numpy(merge_model_request.get_tensor(\"final_embedding\").data)\n",
    "    else:\n",
    "        final_embedding = text_embeds\n",
    "\n",
    "    \n",
    "    if i>0:\n",
    "        inputs = {}\n",
    "    # Prepare inputs for the model\n",
    "    inputs[\"inputs_embeds\"] = final_embedding\n",
    "    inputs[\"attention_mask\"] = attention_mask\n",
    "    inputs[\"position_ids\"] = position_ids\n",
    "    if \"beam_idx\" in input_names:\n",
    "        inputs[\"beam_idx\"] = np.arange(attention_mask.shape[0], dtype=int)\n",
    "    \n",
    "    # Start inference\n",
    "    request.start_async(inputs, share_inputs=True)\n",
    "    request.wait()\n",
    "    \n",
    "    # Get the logits and find the next token\n",
    "    logits = torch.from_numpy(request.get_tensor(\"logits\").data)\n",
    "    next_token = logits.argmax(-1)[0][-1]\n",
    "    \n",
    "    # Append the generated token\n",
    "    generated_tokens.append(next_token)\n",
    "    \n",
    "    # Update input_ids with the new token\n",
    "    current_input_ids = torch.cat([next_token.unsqueeze(0).unsqueeze(0)], dim=-1)\n",
    "    \n",
    "    # update the attention mask\n",
    "    attention_mask = torch.cat([attention_mask, torch.ones_like(attention_mask[:, :1])], dim=-1)\n",
    "\n",
    "    # Update inputs for the next iteration\n",
    "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
    "    position_ids = position_ids[:, -current_input_ids.shape[1] :]\n",
    "    inputs[\"position_ids\"] = position_ids\n",
    "\n",
    "generated_text = processor.decode(generated_tokens, skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Import and Save in Spark NLP\n",
    "- Let's install and setup Spark NLP in Google Colab\n",
    "- This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start Spark with Spark NLP included via our simple `start()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/14 10:47:16 WARN NativeLibrary: Failed to load library null: java.lang.UnsatisfiedLinkError: Can't load library: /tmp/openvino-native1828305829993043212/libtbb.so.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/prabod/spark/jars/spark-core_2.12-3.3.2.jar) to field java.util.regex.Pattern.pattern\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "imageClassifier = PaliGemmaForMultiModal \\\n",
    "            .loadSavedModel(str(output_dir),spark) \\\n",
    "            .setInputCols(\"image_assembler\") \\\n",
    "            .setOutputCol(\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "imageClassifier.write().overwrite().save(f\"file:///tmp/{model_id}_spark_nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml import Pipeline\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# download two images to test into ./images folder\n",
    "\n",
    "url1 = \"https://github.com/openvinotoolkit/openvino_notebooks/assets/29454499/d5fbbd1a-d484-415c-88cb-9986625b7b11\"\n",
    "url2 = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "\n",
    "Path(\"images\").mkdir(exist_ok=True)\n",
    "\n",
    "!wget -q -O images/image1.jpg {url1}\n",
    "!wget -q -O images/image2.jpg {url2}\n",
    "\n",
    "\n",
    "\n",
    "images_path = \"file://\" + os.getcwd() + \"/images/\"\n",
    "image_df = spark.read.format(\"image\").load(\n",
    "    path=images_path\n",
    ")\n",
    "\n",
    "test_df = image_df.withColumn(\"text\", lit(\"<image><bos>caption en\\n\"))\n",
    "\n",
    "image_assembler = ImageAssembler().setInputCol(\"image\").setOutputCol(\"image_assembler\")\n",
    "\n",
    "imageClassifier = PaliGemmaForMultiModal.load(f\"file:///tmp/{model_id}_spark_nlp\")\\\n",
    "            .setMaxOutputLength(50) \\\n",
    "            .setInputCols(\"image_assembler\") \\\n",
    "            .setOutputCol(\"answer\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "            stages=[\n",
    "                image_assembler,\n",
    "                imageClassifier,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "model = pipeline.fit(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path: /mnt/research/Projects/ModelZoo/PaliGemma/images/image1.jpg\n",
      "[Annotation(document, 0, 34, A cat is laying in a cardboard box., Map(), [])]\n"
     ]
    }
   ],
   "source": [
    "light_pipeline = LightPipeline(model)\n",
    "image_path = os.getcwd() + \"/images/\" + \"image1.jpg\"\n",
    "print(\"image_path: \" + image_path)\n",
    "annotations_result = light_pipeline.fullAnnotateImage(\n",
    "    image_path,\n",
    "    \"<image><bos>caption en\\n\"\n",
    ")\n",
    "\n",
    "for result in annotations_result:\n",
    "    print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model_merger.xml (deflated 86%)\n",
      "  adding: .model_merger.xml.crc (stored 0%)\n",
      "  adding: .image_encoder.xml.crc (deflated 0%)\n",
      "  adding: .language_model.xml.crc (deflated 0%)\n",
      "  adding: fields/ (stored 0%)\n",
      "  adding: fields/merges/ (stored 0%)\n",
      "  adding: fields/merges/.part-00017.crc (stored 0%)\n",
      "  adding: fields/merges/part-00022 (deflated 76%)\n",
      "  adding: fields/merges/part-00005 (deflated 76%)\n",
      "  adding: fields/merges/.part-00054.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00037.crc (stored 0%)\n",
      "  adding: fields/merges/part-00037 (deflated 76%)\n",
      "  adding: fields/merges/part-00017 (deflated 76%)\n",
      "  adding: fields/merges/part-00009 (deflated 76%)\n",
      "  adding: fields/merges/part-00010 (deflated 76%)\n",
      "  adding: fields/merges/.part-00039.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00012.crc (stored 0%)\n",
      "  adding: fields/merges/part-00040 (deflated 76%)\n",
      "  adding: fields/merges/.part-00005.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00019.crc (stored 0%)\n",
      "  adding: fields/merges/part-00021 (deflated 76%)\n",
      "  adding: fields/merges/part-00004 (deflated 76%)\n",
      "  adding: fields/merges/.part-00035.crc (stored 0%)\n",
      "  adding: fields/merges/part-00018 (deflated 76%)\n",
      "  adding: fields/merges/part-00003 (deflated 76%)\n",
      "  adding: fields/merges/part-00053 (deflated 76%)\n",
      "  adding: fields/merges/part-00000 (deflated 76%)\n",
      "  adding: fields/merges/.part-00042.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00029.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00038.crc (stored 0%)\n",
      "  adding: fields/merges/part-00044 (deflated 76%)\n",
      "  adding: fields/merges/part-00050 (deflated 76%)\n",
      "  adding: fields/merges/part-00039 (deflated 76%)\n",
      "  adding: fields/merges/.part-00001.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00004.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00010.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00041.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00044.crc (stored 0%)\n",
      "  adding: fields/merges/part-00013 (deflated 76%)\n",
      "  adding: fields/merges/part-00015 (deflated 76%)\n",
      "  adding: fields/merges/part-00025 (deflated 76%)\n",
      "  adding: fields/merges/part-00024 (deflated 76%)\n",
      "  adding: fields/merges/part-00002 (deflated 76%)\n",
      "  adding: fields/merges/part-00028 (deflated 76%)\n",
      "  adding: fields/merges/part-00008 (deflated 76%)\n",
      "  adding: fields/merges/.part-00031.crc (stored 0%)\n",
      "  adding: fields/merges/part-00036 (deflated 76%)\n",
      "  adding: fields/merges/.part-00030.crc (stored 0%)\n",
      "  adding: fields/merges/part-00014 (deflated 76%)\n",
      "  adding: fields/merges/.part-00025.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00034.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00052.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00002.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00032.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00033.crc (stored 0%)\n",
      "  adding: fields/merges/part-00016 (deflated 76%)\n",
      "  adding: fields/merges/part-00052 (deflated 76%)\n",
      "  adding: fields/merges/.part-00048.crc (stored 0%)\n",
      "  adding: fields/merges/part-00023 (deflated 76%)\n",
      "  adding: fields/merges/part-00034 (deflated 76%)\n",
      "  adding: fields/merges/part-00007 (deflated 76%)\n",
      "  adding: fields/merges/part-00049 (deflated 76%)\n",
      "  adding: fields/merges/.part-00016.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00050.crc (stored 0%)\n",
      "  adding: fields/merges/part-00041 (deflated 76%)\n",
      "  adding: fields/merges/.part-00024.crc (stored 0%)\n",
      "  adding: fields/merges/part-00046 (deflated 76%)\n",
      "  adding: fields/merges/part-00011 (deflated 76%)\n",
      "  adding: fields/merges/part-00047 (deflated 76%)\n",
      "  adding: fields/merges/.part-00040.crc (stored 0%)\n",
      "  adding: fields/merges/part-00043 (deflated 76%)\n",
      "  adding: fields/merges/part-00012 (deflated 76%)\n",
      "  adding: fields/merges/.part-00051.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00020.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00000.crc (stored 0%)\n",
      "  adding: fields/merges/part-00042 (deflated 76%)\n",
      "  adding: fields/merges/.part-00008.crc (stored 0%)\n",
      "  adding: fields/merges/part-00006 (deflated 76%)\n",
      "  adding: fields/merges/.part-00018.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00013.crc (stored 0%)\n",
      "  adding: fields/merges/part-00055 (deflated 76%)\n",
      "  adding: fields/merges/.part-00047.crc (stored 0%)\n",
      "  adding: fields/merges/part-00001 (deflated 76%)\n",
      "  adding: fields/merges/part-00019 (deflated 76%)\n",
      "  adding: fields/merges/part-00032 (deflated 76%)\n",
      "  adding: fields/merges/.part-00055.crc (stored 0%)\n",
      "  adding: fields/merges/part-00051 (deflated 76%)\n",
      "  adding: fields/merges/.part-00009.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00015.crc (stored 0%)\n",
      "  adding: fields/merges/part-00020 (deflated 76%)\n",
      "  adding: fields/merges/part-00038 (deflated 76%)\n",
      "  adding: fields/merges/part-00027 (deflated 76%)\n",
      "  adding: fields/merges/.part-00045.crc (stored 0%)\n",
      "  adding: fields/merges/part-00031 (deflated 76%)\n",
      "  adding: fields/merges/.part-00049.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00021.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00053.crc (stored 0%)\n",
      "  adding: fields/merges/part-00035 (deflated 76%)\n",
      "  adding: fields/merges/.part-00026.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00043.crc (stored 0%)\n",
      "  adding: fields/merges/._SUCCESS.crc (stored 0%)\n",
      "  adding: fields/merges/part-00029 (deflated 76%)\n",
      "  adding: fields/merges/.part-00023.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00011.crc (stored 0%)\n",
      "  adding: fields/merges/part-00054 (deflated 76%)\n",
      "  adding: fields/merges/.part-00028.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00014.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00003.crc (stored 0%)\n",
      "  adding: fields/merges/.part-00046.crc (stored 0%)\n",
      "  adding: fields/merges/part-00033 (deflated 76%)\n",
      "  adding: fields/merges/.part-00007.crc (stored 0%)\n",
      "  adding: fields/merges/part-00026 (deflated 76%)\n",
      "  adding: fields/merges/.part-00006.crc (stored 0%)\n",
      "  adding: fields/merges/part-00048 (deflated 76%)\n",
      "  adding: fields/merges/.part-00036.crc (stored 0%)\n",
      "  adding: fields/merges/_SUCCESS (stored 0%)\n",
      "  adding: fields/merges/.part-00027.crc (stored 0%)\n",
      "  adding: fields/merges/part-00030 (deflated 76%)\n",
      "  adding: fields/merges/.part-00022.crc (stored 0%)\n",
      "  adding: fields/merges/part-00045 (deflated 76%)\n",
      "  adding: fields/generationConfig/ (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00017.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00022 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00005 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00054.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00037.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00037 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00017 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00009 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00010 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00039.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00012.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00040 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00005.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00019.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00021 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00004 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00035.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00018 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00003 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00053 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00000 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00042.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00029.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00038.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00044 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00050 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00039 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00001.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00004.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00010.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00041.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00044.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00013 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00015 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00025 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00024 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00002 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00028 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00008 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00031.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00036 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00030.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00014 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00025.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00034.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00052.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00002.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00032.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00033.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00016 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00052 (deflated 26%)\n",
      "  adding: fields/generationConfig/.part-00048.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00023 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00034 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00007 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00049 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00016.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00050.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00041 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00024.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00046 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00011 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00047 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00040.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00043 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00012 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00051.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00020.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00000.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00042 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00008.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00006 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00018.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00013.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00055 (deflated 32%)\n",
      "  adding: fields/generationConfig/.part-00047.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00001 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00019 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00032 (deflated 26%)\n",
      "  adding: fields/generationConfig/.part-00055.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00051 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00009.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00015.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00020 (deflated 26%)\n",
      "  adding: fields/generationConfig/part-00038 (deflated 27%)\n",
      "  adding: fields/generationConfig/part-00027 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00045.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00031 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00049.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00021.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00053.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00035 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00026.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00043.crc (stored 0%)\n",
      "  adding: fields/generationConfig/._SUCCESS.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00029 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00023.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00011.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00054 (deflated 26%)\n",
      "  adding: fields/generationConfig/.part-00028.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00014.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00003.crc (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00046.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00033 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00007.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00026 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00006.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00048 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00036.crc (stored 0%)\n",
      "  adding: fields/generationConfig/_SUCCESS (stored 0%)\n",
      "  adding: fields/generationConfig/.part-00027.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00030 (deflated 27%)\n",
      "  adding: fields/generationConfig/.part-00022.crc (stored 0%)\n",
      "  adding: fields/generationConfig/part-00045 (deflated 27%)\n",
      "  adding: fields/vocabulary/ (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00017.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00022 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00005 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00054.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00037.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00037 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00017 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00009 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00010 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00039.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00012.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00040 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00005.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00019.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00021 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00004 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00035.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00018 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00003 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00053 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00000 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00042.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00029.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00038.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00044 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00050 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00039 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00001.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00004.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00010.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00041.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00044.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00013 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00015 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00025 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00024 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00002 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00028 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00008 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00031.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00036 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00030.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00014 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00025.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00034.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00052.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00002.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00032.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00033.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00016 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00052 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00048.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00023 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00034 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00007 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00049 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00016.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00050.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00041 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00024.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00046 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00011 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00047 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00040.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00043 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00012 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00051.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00020.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00000.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00042 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00008.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00006 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00018.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00013.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00055 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00047.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00001 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00019 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00032 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00055.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00051 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00009.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00015.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00020 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00038 (deflated 74%)\n",
      "  adding: fields/vocabulary/part-00027 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00045.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00031 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00049.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00021.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00053.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00035 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00026.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00043.crc (stored 0%)\n",
      "  adding: fields/vocabulary/._SUCCESS.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00029 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00023.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00011.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00054 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00028.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00014.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00003.crc (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00046.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00033 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00007.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00026 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00006.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00048 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00036.crc (stored 0%)\n",
      "  adding: fields/vocabulary/_SUCCESS (stored 0%)\n",
      "  adding: fields/vocabulary/.part-00027.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00030 (deflated 74%)\n",
      "  adding: fields/vocabulary/.part-00022.crc (stored 0%)\n",
      "  adding: fields/vocabulary/part-00045 (deflated 74%)\n",
      "  adding: fields/addedTokens/ (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00017.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00022 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00005 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00054.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00037.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00037 (deflated 63%)\n",
      "  adding: fields/addedTokens/part-00017 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00009 (deflated 63%)\n",
      "  adding: fields/addedTokens/part-00010 (deflated 63%)\n",
      "  adding: fields/addedTokens/.part-00039.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00012.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00040 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00005.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00019.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00021 (deflated 66%)\n",
      "  adding: fields/addedTokens/part-00004 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00035.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00018 (deflated 63%)\n",
      "  adding: fields/addedTokens/part-00003 (deflated 63%)\n",
      "  adding: fields/addedTokens/part-00053 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00000 (deflated 66%)\n",
      "  adding: fields/addedTokens/.part-00042.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00029.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00038.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00044 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00050 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00039 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00001.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00004.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00010.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00041.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00044.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00013 (deflated 62%)\n",
      "  adding: fields/addedTokens/part-00015 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00025 (deflated 66%)\n",
      "  adding: fields/addedTokens/part-00024 (deflated 65%)\n",
      "  adding: fields/addedTokens/part-00002 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00028 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00008 (deflated 63%)\n",
      "  adding: fields/addedTokens/.part-00031.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00036 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00030.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00014 (deflated 66%)\n",
      "  adding: fields/addedTokens/.part-00025.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00034.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00052.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00002.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00032.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00033.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00016 (deflated 65%)\n",
      "  adding: fields/addedTokens/part-00052 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00048.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00023 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00034 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00007 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00049 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00016.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00050.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00041 (deflated 68%)\n",
      "  adding: fields/addedTokens/.part-00024.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00046 (deflated 65%)\n",
      "  adding: fields/addedTokens/part-00011 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00047 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00040.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00043 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00012 (deflated 63%)\n",
      "  adding: fields/addedTokens/.part-00051.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00020.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00000.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00042 (deflated 62%)\n",
      "  adding: fields/addedTokens/.part-00008.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00006 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00018.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00013.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00055 (deflated 63%)\n",
      "  adding: fields/addedTokens/.part-00047.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00001 (deflated 63%)\n",
      "  adding: fields/addedTokens/part-00019 (deflated 65%)\n",
      "  adding: fields/addedTokens/part-00032 (deflated 66%)\n",
      "  adding: fields/addedTokens/.part-00055.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00051 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00009.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00015.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00020 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00038 (deflated 64%)\n",
      "  adding: fields/addedTokens/part-00027 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00045.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00031 (deflated 63%)\n",
      "  adding: fields/addedTokens/.part-00049.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00021.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00053.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00035 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00026.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00043.crc (stored 0%)\n",
      "  adding: fields/addedTokens/._SUCCESS.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00029 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00023.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00011.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00054 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00028.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00014.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00003.crc (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00046.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00033 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00007.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00026 (deflated 66%)\n",
      "  adding: fields/addedTokens/.part-00006.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00048 (deflated 64%)\n",
      "  adding: fields/addedTokens/.part-00036.crc (stored 0%)\n",
      "  adding: fields/addedTokens/_SUCCESS (stored 0%)\n",
      "  adding: fields/addedTokens/.part-00027.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00030 (deflated 65%)\n",
      "  adding: fields/addedTokens/.part-00022.crc (stored 0%)\n",
      "  adding: fields/addedTokens/part-00045 (deflated 65%)\n",
      "  adding: language_model.xml (deflated 13%)\n",
      "  adding: metadata/ (stored 0%)\n",
      "  adding: metadata/part-00000 (deflated 48%)\n",
      "  adding: metadata/.part-00000.crc (stored 0%)\n",
      "  adding: metadata/._SUCCESS.crc (stored 0%)\n",
      "  adding: metadata/_SUCCESS (stored 0%)\n",
      "  adding: text_embeddings.xml (deflated 7%)\n",
      "  adding: image_encoder.xml (deflated 8%)\n",
      "  adding: .text_embeddings.xml.crc (deflated 0%)\n"
     ]
    }
   ],
   "source": [
    "ZIP_NAME = f\"{model_id.split('/')[-1].replace(' ','_').lower()}_int4_sn\"\n",
    "!cd /tmp/{model_id}_spark_nlp && zip -r {ZIP_NAME}.zip ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smolvlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
