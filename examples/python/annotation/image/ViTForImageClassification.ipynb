{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/image/ViTForImageClassification.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash /dev/stdin -p 3.2.1 -s 4.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViTForImageClassification Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebok we are going to classify images using spark-nlp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.unpack_archive(\"images.zip\", \"images\", \"zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.read.format(\"image\").option(\"dropInvalid\", value = True).load(path=\"images/images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_classifier_vit_base_patch16_224 download started this may take some time.\n",
      "Approximate size to download 309.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "image_assembler = ImageAssembler() \\\n",
    "            .setInputCol(\"image\") \\\n",
    "            .setOutputCol(\"image_assembler\")\n",
    "\n",
    "image_classifier = ViTForImageClassification \\\n",
    "    .pretrained() \\\n",
    "    .setInputCols(\"image_assembler\") \\\n",
    "    .setOutputCol(\"class\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    image_assembler,\n",
    "    image_classifier,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               image|     image_assembler|               class|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 5,...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 11...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 55...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 2,...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 24...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 14...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 7,...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 8,...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 6,...|\n",
      "|{file:///content/...|[{image, file:///...|[{category, 0, 1,...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df = model.transform(data_df)\n",
    "image_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use light pipeline in ViT transformer, we need to use the new method `fullAnnotateImage`, which can receive 3 kind of inputs:\n",
    "1. A path to a single image\n",
    "2. A path to a list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_assembler', 'class'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_pipeline = LightPipeline(model)\n",
    "annotations_result = light_pipeline.fullAnnotateImage(\"images/images/hippopotamus.JPEG\")\n",
    "annotations_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in annotations_result:\n",
    "  image_assembler = result['image_assembler'][0]\n",
    "  print(f\"annotator_type: {image_assembler.annotator_type}\")\n",
    "  print(f\"origin: {image_assembler.origin}\")\n",
    "  print(f\"height: {image_assembler.height}\")\n",
    "  print(f\"width: {image_assembler.width}\")\n",
    "  print(f\"nChannels: {image_assembler.nChannels}\")\n",
    "  print(f\"mode: {image_assembler.mode}\")\n",
    "  print(f\"result size: {str(len(image_assembler.result))}\")\n",
    "  print(f\"metadata: {image_assembler.metadata}\")\n",
    "  print(result['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To send a list of images, we just difine a set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_assembler', 'class'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [\"images/images/bluetick.jpg\", \"images/images/palace.JPEG\", \"images/images/hen.JPEG\"]\n",
    "annotations_result = light_pipeline.fullAnnotateImage(images)\n",
    "annotations_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Annotation(category, 0, 7, bluetick, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 1.3846728E-6, Some(beer glass) -> 1.1807944E-6, image -> 0, Some(damselfly) -> 3.6875622E-7, Some(turnstile) -> 2.023695E-6, Some(cockroach, roach) -> 6.2982855E-7, height -> 500, Some(bulbul) -> 5.417509E-7, Some(sea snake) -> 5.7421556E-7, origin -> images/images/bluetick.jpg, Some(mixing bowl) -> 5.4001305E-7, mode -> 16, None -> 4.5454306E-7, Some(whippet) -> 1.2101438E-6, width -> 333, Some(buckle) -> 1.1306514E-6))]\n",
      "[Annotation(category, 0, 5, palace, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 6.3918545E-5, Some(beer glass) -> 8.879939E-6, image -> 0, Some(damselfly) -> 9.565577E-6, Some(turnstile) -> 6.315168E-5, Some(cockroach, roach) -> 1.125408E-5, height -> 334, Some(bulbul) -> 3.321073E-5, Some(sea snake) -> 1.0886038E-5, origin -> images/images/palace.JPEG, Some(mixing bowl) -> 2.6202975E-5, mode -> 16, None -> 2.6134943E-5, Some(whippet) -> 1.3805137E-5, width -> 500, Some(buckle) -> 3.121459E-5))]\n",
      "[Annotation(category, 0, 2, hen, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 2.1663836E-5, Some(beer glass) -> 3.062036E-6, image -> 0, Some(damselfly) -> 5.8477954E-6, Some(turnstile) -> 1.8546416E-6, Some(cockroach, roach) -> 2.5356887E-6, height -> 375, Some(bulbul) -> 3.2049334E-6, Some(sea snake) -> 2.8824059E-6, origin -> images/images/hen.JPEG, Some(mixing bowl) -> 6.9148127E-6, mode -> 16, None -> 2.824775E-6, Some(whippet) -> 4.5998115E-7, width -> 500, Some(buckle) -> 1.6334545E-5))]\n"
     ]
    }
   ],
   "source": [
    "for result in annotations_result:\n",
    "  print(result['class'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ViTForImageClassification-LightPipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
