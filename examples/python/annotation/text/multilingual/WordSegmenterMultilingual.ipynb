{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUB_oKDe7tv-",
    "outputId": "74d0dd7c-e235-4a34-f4de-ef0f70ae60ee"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/multilingual/WordSegmenterMultilingual.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I9zHmXu37_AU",
    "outputId": "64655014-7c3c-42bb-bdbf-353d711581ec",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 12:24:06--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-23 12:24:06--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 12:24:07 (36.0 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "\u001B[K     |████████████████████████████████| 281.5 MB 42 kB/s \n",
      "\u001B[K     |████████████████████████████████| 453 kB 66.8 MB/s \n",
      "\u001B[K     |████████████████████████████████| 199 kB 71.2 MB/s \n",
      "\u001B[?25h  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V7j7Io_n8Anv"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YdDln5dO8CNX"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8YrqB8XS5Z8"
   },
   "source": [
    "## Multilingual Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EK-KvdocS9Bx"
   },
   "source": [
    "When dealing with multilingual text, we have two options in WordSegmenter:\n",
    "1. Use `setEnableRegexTokenizer` parameter. This is useful for current pretrained models.\n",
    "2. Train a model with multilingual text. This can be useful in case a current model (with `setEnableRegexTokenizer=True`) does not yield good results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_N6T1WtpH3d"
   },
   "source": [
    "Setting `setEnableRegexTokenizer=True` parameter will make WordSegmenter to tokenize latin words based on spaces and apply word segmenter inference **only in non-latin words**. As show in the example below.\n",
    "\n",
    "**Note:** There are 3 parameters to play around for tokenization of latin words. You can check those in our [official documentation](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rO4nw34a04Vq"
   },
   "source": [
    "This example has a text with Thai and English words. So, we use a WordSegmenter model of Thai language. You can check additional WordSegmenter models in our [official model's page](https://nlp.johnsnowlabs.com/models?q=Word+Segmenter).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "40VRukPNBd92"
   },
   "outputs": [],
   "source": [
    "multilingual_text = \"สำหรับฐานลำโพง apple homepod อุปกรณ์เครื่องเสียงยึดขาตั้งไม้แข็งตั้งพื้น speaker stands null\"\n",
    "multilingual_df = spark.createDataFrame([[multilingual_text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qM36eUWBA7ND",
    "outputId": "08e96c37-b7a0-4991-dd90-d03d23aa9b0e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wordseg_best download started this may take some time.\n",
      "Approximate size to download 79.2 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "word_segmenter = WordSegmenterModel().pretrained(\"wordseg_best\", \"th\") \\\n",
    "      .setInputCols([\"document\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .setEnableRegexTokenizer(True)\n",
    "\n",
    "pipeline = Pipeline(stages=[document_assembler, word_segmenter])\n",
    "result_df = pipeline.fit(multilingual_df).transform(multilingual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CpzTFTABugA",
    "outputId": "ef1062f5-cb51-4a0f-f884-e9e1c44ad8a6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            document|               token|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|สำหรับฐานลำโพง ap...|[{document, 0, 91...|[{token, 0, 8, สำ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97AO5D57Sz7j",
    "outputId": "f92401d2-1e24-4517-a5fd-9165c5df23c5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|token                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{token, 0, 8, สำหรับฐาน, {sentence -> 0}, []}, {token, 9, 9, ล, {sentence -> 0}, []}, {token, 10, 10, ำ, {sentence -> 0}, []}, {token, 11, 13, โพง, {sentence -> 0}, []}, {token, 15, 19, apple, {sentence -> 0}, []}, {token, 21, 27, homepod, {sentence -> 0}, []}, {token, 29, 35, อุปกรณ์, {sentence -> 0}, []}, {token, 36, 42, เครื่อง, {sentence -> 0}, []}, {token, 43, 47, เสียง, {sentence -> 0}, []}, {token, 48, 50, ยึด, {sentence -> 0}, []}, {token, 51, 52, ขา, {sentence -> 0}, []}, {token, 53, 56, ตั้ง, {sentence -> 0}, []}, {token, 57, 59, ไม้, {sentence -> 0}, []}, {token, 60, 63, แข็ง, {sentence -> 0}, []}, {token, 64, 67, ตั้ง, {sentence -> 0}, []}, {token, 68, 71, พื้น, {sentence -> 0}, []}, {token, 73, 79, speaker, {sentence -> 0}, []}, {token, 81, 86, stands, {sentence -> 0}, []}, {token, 88, 91, null, {sentence -> 0}, []}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.select(\"token\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv4MabwbtCfR"
   },
   "source": [
    "##Training a Multilingual Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjSA2lqi1hSQ"
   },
   "source": [
    "We can also train our own multilingual model, which will require to build a training file with the required format, as in this example to label each character for English and Thai alike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYYxvyKa10Oe"
   },
   "source": [
    "The tags legend for the training dataset is the following:\n",
    "- LL: Left Boundary of a word\n",
    "- RR: Right Boundary of a word\n",
    "- MM: Middle character of a word\n",
    "- LR: A single character that can be seen as a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DRbfBpBfr2-_"
   },
   "outputs": [],
   "source": [
    "thai_word1 = \"สำ|LL ห|MM รั|MM บ|RR ฐ|LL า|MM น|RR ลำ|LL โ|MM พ|MM ง|RR \"\n",
    "english_words = \"a|LL p|MM p|MM l|MM e|RR h|LL o|MM m|MM e|MM p|MM o|MM d|RR \"\n",
    "thai_word2 = \"อุ|LL ป|MM ก|MM ร|MM ณ์|RR เ|LL ค|MM รื่|MM อ|MM ง|RR เ|LL สี|MM ย|MM ง|RR ยึ|LL ด|RR ข|LLา|RR ตั้|LL ง|RR พื้|LL น|RR \"\n",
    "english_words2 = \"s|LL p|MM e|MM a|MM k|MM e|MM r|RR s|LL t|MM a|MM n|MM d|MM s|RR n|LL u|MM l|MM l|RR\"\n",
    "thai_english_sentence = thai_word1 + english_words + thai_word2 + english_words2\n",
    "\n",
    "with open('./thai_english.txt', 'w') as alphabet_file:\n",
    "    alphabet_file.write(thai_english_sentence + \"\\n\")\n",
    "    alphabet_file.write(thai_english_sentence + \"\\n\")\n",
    "    alphabet_file.write(thai_english_sentence + \"\\n\")\n",
    "    alphabet_file.write(thai_english_sentence + \"\\n\")\n",
    "    alphabet_file.write(thai_english_sentence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjbtYRUCs9_t",
    "outputId": "8264b70c-575c-40e1-ae8c-579f17aefebc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "สำ|LL ห|MM รั|MM บ|RR ฐ|LL า|MM น|RR ลำ|LL โ|MM พ|MM ง|RR a|LL p|MM p|MM l|MM e|RR h|LL o|MM m|MM e|MM p|MM o|MM d|RR อุ|LL ป|MM ก|MM ร|MM ณ์|RR เ|LL ค|MM รื่|MM อ|MM ง|RR เ|LL สี|MM ย|MM ง|RR ยึ|LL ด|RR ข|LLา|RR ตั้|LL ง|RR พื้|LL น|RR s|LL p|MM e|MM a|MM k|MM e|MM r|RR s|LL t|MM a|MM n|MM d|MM s|RR n|LL u|MM l|MM l|RR\n",
      "สำ|LL ห|MM รั|MM บ|RR ฐ|LL า|MM น|RR ลำ|LL โ|MM พ|MM ง|RR a|LL p|MM p|MM l|MM e|RR h|LL o|MM m|MM e|MM p|MM o|MM d|RR อุ|LL ป|MM ก|MM ร|MM ณ์|RR เ|LL ค|MM รื่|MM อ|MM ง|RR เ|LL สี|MM ย|MM ง|RR ยึ|LL ด|RR ข|LLา|RR ตั้|LL ง|RR พื้|LL น|RR s|LL p|MM e|MM a|MM k|MM e|MM r|RR s|LL t|MM a|MM n|MM d|MM s|RR n|LL u|MM l|MM l|RR\n",
      "สำ|LL ห|MM รั|MM บ|RR ฐ|LL า|MM น|RR ลำ|LL โ|MM พ|MM ง|RR a|LL p|MM p|MM l|MM e|RR h|LL o|MM m|MM e|MM p|MM o|MM d|RR อุ|LL ป|MM ก|MM ร|MM ณ์|RR เ|LL ค|MM รื่|MM อ|MM ง|RR เ|LL สี|MM ย|MM ง|RR ยึ|LL ด|RR ข|LLา|RR ตั้|LL ง|RR พื้|LL น|RR s|LL p|MM e|MM a|MM k|MM e|MM r|RR s|LL t|MM a|MM n|MM d|MM s|RR n|LL u|MM l|MM l|RR\n",
      "สำ|LL ห|MM รั|MM บ|RR ฐ|LL า|MM น|RR ลำ|LL โ|MM พ|MM ง|RR a|LL p|MM p|MM l|MM e|RR h|LL o|MM m|MM e|MM p|MM o|MM d|RR อุ|LL ป|MM ก|MM ร|MM ณ์|RR เ|LL ค|MM รื่|MM อ|MM ง|RR เ|LL สี|MM ย|MM ง|RR ยึ|LL ด|RR ข|LLา|RR ตั้|LL ง|RR พื้|LL น|RR s|LL p|MM e|MM a|MM k|MM e|MM r|RR s|LL t|MM a|MM n|MM d|MM s|RR n|LL u|MM l|MM l|RR\n",
      "สำ|LL ห|MM รั|MM บ|RR ฐ|LL า|MM น|RR ลำ|LL โ|MM พ|MM ง|RR a|LL p|MM p|MM l|MM e|RR h|LL o|MM m|MM e|MM p|MM o|MM d|RR อุ|LL ป|MM ก|MM ร|MM ณ์|RR เ|LL ค|MM รื่|MM อ|MM ง|RR เ|LL สี|MM ย|MM ง|RR ยึ|LL ด|RR ข|LLา|RR ตั้|LL ง|RR พื้|LL น|RR s|LL p|MM e|MM a|MM k|MM e|MM r|RR s|LL t|MM a|MM n|MM d|MM s|RR n|LL u|MM l|MM l|RR\n"
     ]
    }
   ],
   "source": [
    "! cat ./thai_english.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9QNHM_uxIVL",
    "outputId": "138c71bc-eff8-4085-d95c-d63a4d540858"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            document|                tags|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|สำ ห รั บ ฐ า น ล...|[{document, 0, 13...|[{pos, 0, 1, LL, ...|\n",
      "|สำ ห รั บ ฐ า น ล...|[{document, 0, 13...|[{pos, 0, 1, LL, ...|\n",
      "|สำ ห รั บ ฐ า น ล...|[{document, 0, 13...|[{pos, 0, 1, LL, ...|\n",
      "|สำ ห รั บ ฐ า น ล...|[{document, 0, 13...|[{pos, 0, 1, LL, ...|\n",
      "|สำ ห รั บ ฐ า น ล...|[{document, 0, 13...|[{pos, 0, 1, LL, ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.training import POS\n",
    "\n",
    "train_df = POS().readDataset(spark, \"./thai_english.txt\")\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEPIUB17tq4u",
    "outputId": "d718ddf4-d863-46e8-d91e-168594dc0d10"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                text|            document|               token|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|สำหรับฐานลำโพง ap...|[{document, 0, 91...|[{token, 0, 8, สำ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\") \\\n",
    "            .setOutputCol(\"document\")\n",
    "\n",
    "word_segmenter = WordSegmenterApproach() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"token\") \\\n",
    "    .setPosColumn(\"tags\") \\\n",
    "    .setNIterations(5)\n",
    "\n",
    "pipeline = Pipeline(stages=[document_assembler, word_segmenter])\n",
    "\n",
    "result = pipeline.fit(train_df).transform(multilingual_df)\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoKPY_qRt8fv",
    "outputId": "811dbd1e-f950-479b-8414-a4d8f70bcf8e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|token                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{token, 0, 8, สำหรับฐาน, {sentence -> 0}, []}, {token, 9, 9, ล, {sentence -> 0}, []}, {token, 10, 10, ำ, {sentence -> 0}, []}, {token, 11, 13, โพง, {sentence -> 0}, []}, {token, 15, 19, apple, {sentence -> 0}, []}, {token, 21, 27, homepod, {sentence -> 0}, []}, {token, 29, 35, อุปกรณ์, {sentence -> 0}, []}, {token, 36, 42, เครื่อง, {sentence -> 0}, []}, {token, 43, 47, เสียง, {sentence -> 0}, []}, {token, 48, 50, ยึด, {sentence -> 0}, []}, {token, 51, 52, ขา, {sentence -> 0}, []}, {token, 53, 56, ตั้ง, {sentence -> 0}, []}, {token, 57, 59, ไม้, {sentence -> 0}, []}, {token, 60, 63, แข็ง, {sentence -> 0}, []}, {token, 64, 67, ตั้ง, {sentence -> 0}, []}, {token, 68, 71, พื้น, {sentence -> 0}, []}, {token, 73, 79, speaker, {sentence -> 0}, []}, {token, 81, 86, stands, {sentence -> 0}, []}, {token, 88, 91, null, {sentence -> 0}, []}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.select(\"token\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
