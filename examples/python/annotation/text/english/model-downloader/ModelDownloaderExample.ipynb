{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9ps18GDtt5j"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/model-downloader/Running_Pretrained_pipelines.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gm0tZvJdtvgx",
    "outputId": "442ebfa3-d968-4d74-b63d-2df16ee7de85"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 14:20:06--  http://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
      "--2022-12-23 14:20:06--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-23 14:20:07--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 14:20:07 (26.6 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "\u001B[K     |████████████████████████████████| 281.5 MB 54 kB/s \n",
      "\u001B[K     |████████████████████████████████| 453 kB 68.6 MB/s \n",
      "\u001B[K     |████████████████████████████████| 199 kB 57.0 MB/s \n",
      "\u001B[?25h  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyumVtb_tt5k"
   },
   "source": [
    "## Runing Pretrained models\n",
    "\n",
    "In the following example, we walk-through different use cases of some of our Pretrained models and pipelines which could be used off the shelf.\n",
    "\n",
    "There is BasicPipeline which will return tokens, normalized tokens, lemmas and part of speech tags. The AdvancedPipeline will return same as the BasicPipeline plus Stems, Spell Checked tokens and NER entities using the CRF model. All the pipelines and pre trained models are downloaded from internet at run time hence would require internet access. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Emh6GE1Ctt5l"
   },
   "source": [
    "#### 1. Call necessary imports and create the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYPs5MTqtt5m",
    "outputId": "138fe46c-38dd-41a6-e975-ac5cba579676"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.8.16 (default, Dec  7 2022, 01:12:13) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfoLeCq9tt5r",
    "outputId": "d2d6a8e3-4e42-46cb-df7c-a213840e4358"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spark NLP version:  4.2.6\n",
      "Apache Spark version:  3.2.3\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr6G_81ftt5v"
   },
   "source": [
    "#### 2. Create a dummy spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ur8mKlQTtt5v"
   },
   "outputs": [],
   "source": [
    "\n",
    "l = [\n",
    "  (1,'To be or not to be'),\n",
    "  (2,'This is it!')\n",
    "]\n",
    "\n",
    "data = spark.createDataFrame(l, ['docID','text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TiWAq7-tt5z"
   },
   "source": [
    "#### 3. We use predefined BasicPipeline in order to annotate a dataframe with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtpSOtKStt50",
    "outputId": "857a4655-6aab-4e91-de62-7a2ec6eecdfd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "explain_document_ml download started this may take some time.\n",
      "Approx size to download 9.2 MB\n",
      "[OK!]\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|docID|              text|            document|            sentence|               token|               spell|              lemmas|               stems|                 pos|\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    1|To be or not to be|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 1, To...|[{token, 0, 1, To...|[{token, 0, 1, To...|[{token, 0, 1, to...|[{pos, 0, 1, TO, ...|\n",
      "|    2|       This is it!|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 3, Th...|[{token, 0, 3, Th...|[{token, 0, 3, Th...|[{token, 0, 3, th...|[{pos, 0, 3, DT, ...|\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download predefined - pipelines\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "explain_document_ml = PretrainedPipeline(\"explain_document_ml\")\n",
    "basic_data = explain_document_ml.transform(data) \n",
    "basic_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dT-FqWFOtt54"
   },
   "source": [
    "#### We can also annotate a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQ76lDOTtt55",
    "outputId": "29846ace-8e69-4bd8-a0f1-cd73324a1e37"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'document': ['This world is made up of good and bad things'],\n",
       " 'spell': ['This',\n",
       "  'world',\n",
       "  'is',\n",
       "  'made',\n",
       "  'up',\n",
       "  'of',\n",
       "  'good',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'things'],\n",
       " 'pos': ['DT', 'NN', 'VBZ', 'VBN', 'RP', 'IN', 'JJ', 'CC', 'JJ', 'NNS'],\n",
       " 'lemmas': ['This',\n",
       "  'world',\n",
       "  'be',\n",
       "  'make',\n",
       "  'up',\n",
       "  'of',\n",
       "  'good',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'thing'],\n",
       " 'token': ['This',\n",
       "  'world',\n",
       "  'is',\n",
       "  'made',\n",
       "  'up',\n",
       "  'of',\n",
       "  'good',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'things'],\n",
       " 'stems': ['thi',\n",
       "  'world',\n",
       "  'i',\n",
       "  'made',\n",
       "  'up',\n",
       "  'of',\n",
       "  'good',\n",
       "  'and',\n",
       "  'bad',\n",
       "  'thing'],\n",
       " 'sentence': ['This world is made up of good and bad things']}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# annotat quickly from string\n",
    "explain_document_ml.annotate(\"This world is made up of good and bad things\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TG2d8N3tt5_"
   },
   "source": [
    "#### 4. Now we intend to use one of the fast pretrained models such as Preceptron model which is a POS model trained with ANC American Corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSGo6qZbtt6A",
    "outputId": "bd301220-3155-49d1-98e5-e5612c546687"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[OK!]\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|docID|              text|            document|            sentence|               token|                 pos|     word_embeddings|\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    1|To be or not to be|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 1, To...|[{pos, 0, 1, TO, ...|[{word_embeddings...|\n",
      "|    2|       This is it!|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 3, Th...|[{pos, 0, 3, DT, ...|[{word_embeddings...|\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "wordEmbeddings = WordEmbeddingsModel.pretrained().setOutputCol(\"word_embeddings\")    \n",
    "\n",
    "# download directly - models\n",
    "pos = PerceptronModel.pretrained() \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"pos\")\n",
    "    \n",
    "advancedPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, pos, wordEmbeddings])\n",
    "\n",
    "output = advancedPipeline.fit(data).transform(data)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPPaP1sxtt6G"
   },
   "source": [
    "#### 5. Now we proceed to download a Fast CRF Named Entity Recognitionl which is trained with Glove embeddings. Then, we retrieve the `advancedPipeline` and combine these models to use them appropriately meeting their requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MXo_zTNatt6H",
    "outputId": "9109da40-024c-40f9-c776-7d3fb70a4d18"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ner_crf download started this may take some time.\n",
      "Approximate size to download 10.2 MB\n",
      "[OK!]\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|docID|              text|            document|            sentence|               token|                 pos|     word_embeddings|                 ner|\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    1|To be or not to be|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 1, To...|[{pos, 0, 1, TO, ...|[{word_embeddings...|[{named_entity, 0...|\n",
      "|    2|       This is it!|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 3, Th...|[{pos, 0, 3, DT, ...|[{word_embeddings...|[{named_entity, 0...|\n",
      "+-----+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner = NerCrfModel.pretrained()\n",
    "ner.setInputCols([\"pos\", \"token\", \"document\", \"word_embeddings\"]).setOutputCol(\"ner\")\n",
    "\n",
    "annotation_data = advancedPipeline.fit(data).transform(data)\n",
    "\n",
    "pos_tagged = pos.transform(annotation_data)\n",
    "ner_tagged = ner.transform(pos_tagged)\n",
    "ner_tagged.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nuR8cxytt6L"
   },
   "source": [
    "#### 6. Finally, lets try a pre trained sentiment analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnjUFYqctt6L",
    "outputId": "24e51559-8a3c-4a6a-a354-f4a42697bc12"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "analyze_sentiment download started this may take some time.\n",
      "Approx size to download 4.9 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'checked': ['This', 'is', 'a', 'good', 'movie', '!!!'],\n",
       " 'document': ['This is a good movie!!!'],\n",
       " 'sentiment': ['positive'],\n",
       " 'token': ['This', 'is', 'a', 'good', 'movie', '!!!'],\n",
       " 'sentence': ['This is a good movie!!!']}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "PretrainedPipeline(\"analyze_sentiment\").annotate(\"This is a good movie!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "H0sOfKV9tt6P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ModelDownloaderExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
