{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/token-assembler/Assembling_Tokens_to_Documents.ipynb)\n",
    "\n",
    "\n",
    "# **Assembling Tokens to Documents**\n",
    "In this example we will take a look how to use the TokenAssembler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyspark==3.3.0  spark-nlp==4.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Spark NLP version:  4.3.1\n",
      "Apache Spark version:  3.3.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.34:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f80a0e71af0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Spark Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+\n",
      "|text                                                                         |\n",
      "+-----------------------------------------------------------------------------+\n",
      "|Peter is a very good person.                                                 |\n",
      "|My life in Russia is very interesting.                                       |\n",
      "|John and Peter are brothers. However they don't support each other that much.|\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.text('../spark-nlp-basics/sample-sentences-en.txt').toDF('text')\n",
    "\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|           sentences|               token|          normalized|         cleanTokens|          clean_text|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Peter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|[{document, 0, 16...|\n",
      "|My life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, My...|[{token, 3, 6, li...|[{document, 0, 22...|\n",
      "|John and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|[{document, 0, 18...|\n",
      "|Lucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|[{document, 0, 34...|\n",
      "|Europe is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|[{document, 0, 18...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentences')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentences\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")\\\n",
    "    .setLowercase(False)\\\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "    .setInputCols(\"normalized\")\\\n",
    "    .setOutputCol(\"cleanTokens\")\\\n",
    "    .setCaseSensitive(False)\\\n",
    "\n",
    "tokenassembler = TokenAssembler()\\\n",
    "    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"clean_text\")\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
    "                               sentenceDetector,\n",
    "                               tokenizer,\n",
    "                               normalizer,\n",
    "                               stopwords_cleaner,\n",
    "                               tokenassembler])\n",
    "\n",
    "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(clean_text=[Row(annotatorType='document', begin=0, end=16, result='Peter good person', metadata={'sentence': '0'}, embeddings=[])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we use TokenAssembler().setPreservePosition(True), the original borders will be preserved (dropped & unwanted chars will be replaced by spaces)\n",
    "result.select('clean_text').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+-----------------------------------+\n",
      "|text                                                                         |clean_text                         |\n",
      "+-----------------------------------------------------------------------------+-----------------------------------+\n",
      "|Peter is a very good person.                                                 |Peter good person                  |\n",
      "|My life in Russia is very interesting.                                       |life Russia interesting            |\n",
      "|John and Peter are brothers. However they don't support each other that much.|John Peter brothers                |\n",
      "|John and Peter are brothers. However they don't support each other that much.|However dont support much          |\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker longer happy|\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |good car though                    |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |Europe culture rich                |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |huge churches                      |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |big houses                         |\n",
      "+-----------------------------------------------------------------------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('text', F.explode(result.clean_text.result).alias('clean_text')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter is a very good person.</td>\n",
       "      <td>Peter good person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My life in Russia is very interesting.</td>\n",
       "      <td>life Russia interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John and Peter are brothers. However they don'...</td>\n",
       "      <td>John Peter brothers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John and Peter are brothers. However they don'...</td>\n",
       "      <td>However dont support much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n",
       "      <td>Lucas Nogal Dunbercker longer happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n",
       "      <td>good car though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Europe is very culture rich. There are huge ch...</td>\n",
       "      <td>Europe culture rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Europe is very culture rich. There are huge ch...</td>\n",
       "      <td>huge churches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Europe is very culture rich. There are huge ch...</td>\n",
       "      <td>big houses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                       Peter is a very good person.   \n",
       "1             My life in Russia is very interesting.   \n",
       "2  John and Peter are brothers. However they don'...   \n",
       "3  John and Peter are brothers. However they don'...   \n",
       "4  Lucas Nogal Dunbercker is no longer happy. He ...   \n",
       "5  Lucas Nogal Dunbercker is no longer happy. He ...   \n",
       "6  Europe is very culture rich. There are huge ch...   \n",
       "7  Europe is very culture rich. There are huge ch...   \n",
       "8  Europe is very culture rich. There are huge ch...   \n",
       "\n",
       "                            clean_text  \n",
       "0                    Peter good person  \n",
       "1              life Russia interesting  \n",
       "2                  John Peter brothers  \n",
       "3            However dont support much  \n",
       "4  Lucas Nogal Dunbercker longer happy  \n",
       "5                      good car though  \n",
       "6                  Europe culture rich  \n",
       "7                        huge churches  \n",
       "8                           big houses  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('text', F.explode(result.clean_text.result).alias('clean_text')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----------------------------------+--------+\n",
      "|begin|end|result                             |sentence|\n",
      "+-----+---+-----------------------------------+--------+\n",
      "|0    |16 |Peter good person                  |0       |\n",
      "|0    |22 |life Russia interesting            |0       |\n",
      "|0    |18 |John Peter brothers                |0       |\n",
      "|29   |53 |However dont support much          |1       |\n",
      "|0    |34 |Lucas Nogal Dunbercker longer happy|0       |\n",
      "|43   |57 |good car though                    |1       |\n",
      "|0    |18 |Europe culture rich                |0       |\n",
      "|29   |41 |huge churches                      |1       |\n",
      "|54   |63 |big houses                         |2       |\n",
      "+-----+---+-----------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.withColumn(\n",
    "    \"tmp\",\n",
    "    F.explode(\"clean_text\")) \\\n",
    "    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+-----------------------------------------------------+\n",
      "|text                                                                         |result                                               |\n",
      "+-----------------------------------------------------------------------------+-----------------------------------------------------+\n",
      "|Peter is a very good person.                                                 |[Peter good person]                                  |\n",
      "|My life in Russia is very interesting.                                       |[life Russia interesting]                            |\n",
      "|John and Peter are brothers. However they don't support each other that much.|[John Peter brothers However dont support much]      |\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |[Lucas Nogal Dunbercker longer happy good car though]|\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |[Europe culture rich huge churches big houses]       |\n",
      "+-----------------------------------------------------------------------------+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if we hadn't used Sentence Detector, this would be what we got. (tokenizer gets document instead of sentences column)\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "tokenassembler = TokenAssembler()\\\n",
    "    .setInputCols([\"document\", \"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"clean_text\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
    "                               tokenizer,\n",
    "                               normalizer,\n",
    "                               stopwords_cleaner,\n",
    "                               tokenassembler])\n",
    "\n",
    "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
    "result.select('text', 'clean_text.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------------------------------------------------+--------+\n",
      "|begin|end|result                                             |sentence|\n",
      "+-----+---+---------------------------------------------------+--------+\n",
      "|0    |16 |Peter good person                                  |0       |\n",
      "|0    |22 |life Russia interesting                            |0       |\n",
      "|0    |44 |John Peter brothers However dont support much      |0       |\n",
      "|0    |50 |Lucas Nogal Dunbercker longer happy good car though|0       |\n",
      "|0    |43 |Europe culture rich huge churches big houses       |0       |\n",
      "+-----+---+---------------------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.withColumn(\n",
    "    \"tmp\",\n",
    "    F.explode(\"clean_text\")) \\\n",
    "    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:**\n",
    "\n",
    "If you have some other steps & annotators in your pipeline that will need to use the tokens from cleaned text (assembled tokens), you will need to tokenize the processed text again as the original text is probably changed completely."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
