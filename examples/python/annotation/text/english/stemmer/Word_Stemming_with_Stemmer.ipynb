{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/stemmer/Word_Stemming_with_Stemmer.ipynb)\n",
    "\n",
    "\n",
    "# **Word Stemming with Stemmer**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these examples we to stem words with Stemmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Colab Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run this block if you are inside Google Colab to set up Spark NLP otherwise\n",
    "skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.3.1\n",
      "Apache Spark version:  3.3.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.34:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7bdb8f14c0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Spark Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+\n",
      "|text                                                                         |\n",
      "+-----------------------------------------------------------------------------+\n",
      "|Peter is a very good person.                                                 |\n",
      "|My life in Russia is very interesting.                                       |\n",
      "|John and Peter are brothers. However they don't support each other that much.|\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.text('../spark-nlp-basics/sample-sentences-en.txt').toDF('text')\n",
    "\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns hard-stems out of words with the objective of retrieving the meaningful part of the word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"stem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|                                    text|                                document|                                   token|                                    stem|\n",
      "+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "|            Peter is a very good person.|[{document, 0, 27, Peter is a very go...|[{token, 0, 4, Peter, {sentence -> 0}...|[{token, 0, 4, peter, {sentence -> 0}...|\n",
      "|  My life in Russia is very interesting.|[{document, 0, 37, My life in Russia ...|[{token, 0, 1, My, {sentence -> 0}, [...|[{token, 0, 1, my, {sentence -> 0}, [...|\n",
      "|John and Peter are brothers. However ...|[{document, 0, 76, John and Peter are...|[{token, 0, 3, John, {sentence -> 0},...|[{token, 0, 3, john, {sentence -> 0},...|\n",
      "|Lucas Nogal Dunbercker is no longer h...|[{document, 0, 67, Lucas Nogal Dunber...|[{token, 0, 4, Lucas, {sentence -> 0}...|[{token, 0, 4, luca, {sentence -> 0},...|\n",
      "|Europe is very culture rich. There ar...|[{document, 0, 68, Europe is very cul...|[{token, 0, 5, Europe, {sentence -> 0...|[{token, 0, 5, europ, {sentence -> 0}...|\n",
      "+----------------------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
    "                               tokenizer,\n",
    "                               stemmer])\n",
    "\n",
    "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
    "\n",
    "result.show(truncate=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------+\n",
      "|result                                                                                     |\n",
      "+-------------------------------------------------------------------------------------------+\n",
      "|[peter, i, a, veri, good, person, .]                                                       |\n",
      "|[my, life, in, russia, i, veri, interest, .]                                               |\n",
      "|[john, and, peter, ar, brother, ., howev, thei, don't, support, each, other, that, much, .]|\n",
      "|[luca, nogal, dunberck, i, no, longer, happi, ., he, ha, a, good, car, though, .]          |\n",
      "|[europ, i, veri, cultur, rich, ., there, ar, huge, church, !, and, big, hous, !]           |\n",
      "+-------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('stem.result').show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using PySpark 3.1.2 or below, You should use this format.\n",
    "\n",
    "```python\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "result_df = result.select(F.explode(F.arrays_zip(\"token.result\", \"stem.result\")).alias(\"cols\")) \\\n",
    "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                          F.expr(\"cols['1']\").alias(\"stem\")).toPandas()\n",
    "\n",
    "result_df.head(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter</td>\n",
       "      <td>peter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very</td>\n",
       "      <td>veri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>person</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>My</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>life</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token    stem\n",
       "0   Peter   peter\n",
       "1      is       i\n",
       "2       a       a\n",
       "3    very    veri\n",
       "4    good    good\n",
       "5  person  person\n",
       "6       .       .\n",
       "7      My      my\n",
       "8    life    life\n",
       "9      in      in"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result_df = result.select(F.explode(F.arrays_zip(result.token.result,\n",
    "                                                 result.stem.result)).alias(\"cols\")) \\\n",
    "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                          F.expr(\"cols['1']\").alias(\"stem\")).toPandas()\n",
    "\n",
    "result_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
