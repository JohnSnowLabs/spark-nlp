{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/text-similarity/Spark_NLP_Spark_ML_Text_Similarity.ipynb)\n",
    "\n",
    "# Calculating Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.3.1\n",
      "Apache Spark version:  3.3.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.functions import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.functions import *\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primaryCorpus = spark.read.option(\"header\",\"true\").csv(\"file1.csv\")\n",
    "secondaryCorpus = spark.read.option(\"header\",\"true\").csv(\"file2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"sentence\")\\\n",
    "    .setExplodeSentences(False)\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "bertEmbeddings = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
    "    .setInputCols([\"sentence\",'token'])\\\n",
    "    .setOutputCol(\"bert\")\\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"sentence\", \"bert\"]) \\\n",
    "    .setOutputCol(\"sentence_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "embeddingsFinisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"sentence_embeddings\",\"bert\"]) \\\n",
    "    .setOutputCols(\"sentence_embeddings_vectors\", \"bert_vectors\") \\\n",
    "    .setOutputAsVector(True)\\\n",
    "    .setCleanAnnotations(False)\n",
    "\n",
    "\n",
    "explodeVectors = SQLTransformer() \\\n",
    "    .setStatement(\"SELECT EXPLODE(sentence_embeddings_vectors) AS features, * FROM __THIS__\")\n",
    "\n",
    "vectorNormalizer = Normalizer() \\\n",
    "    .setInputCol(\"features\") \\\n",
    "    .setOutputCol(\"normFeatures\") \\\n",
    "    .setP(1.0)\n",
    "\n",
    "similarityChecker = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength=6.0,numHashTables=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([\n",
    "    documentAssembler,\n",
    "    sentence,\n",
    "    tokenizer,\n",
    "    bertEmbeddings,\n",
    "    embeddingsSentence,\n",
    "    embeddingsFinisher,\n",
    "    explodeVectors,\n",
    "    vectorNormalizer,\n",
    "    similarityChecker\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(primaryCorpus)\n",
    "primaryDF = pipelineModel.transform(primaryCorpus)\n",
    "secondaryDF = pipelineModel.transform(secondaryCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|                text|            features|        normFeatures|           lookupKey| id|\n",
      "+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|Wall Decals Lamp ...|[0.04242564737796...|[2.48993627607806...|bbc5a89d7cf3354ea...|  0|\n",
      "|iphone charger ph...|[0.37093448638916...|[0.00200630526885...|37c2b6ab956f9ebd6...|  1|\n",
      "+--------------------+--------------------+--------------------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfA = primaryDF.select(\"text\",\"features\",\"normFeatures\").withColumn(\"lookupKey\", md5(\"text\")).withColumn(\"id\",monotonically_increasing_id())\n",
    "dfA.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+\n",
      "|                text|            features|        normFeatures| id|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "|Curtains & Valanc...|[0.30033871531486...|[0.00192763000744...|  0|\n",
      "|iphone case Apple...|[0.44015255570411...|[0.00236218518925...|  1|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfB = secondaryDF.select(\"text\",\"features\",\"normFeatures\").withColumn(\"id\",monotonically_increasing_id())\n",
    "dfB.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|                 idA|                 idB|          distance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|Wall Decals Lamp ...|Curtains & Valanc...|3.7816639073044893|\n",
      "|iphone charger ph...|iphone case Apple...| 5.666233511624179|\n",
      "+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(\"Approximately joining dfA and dfB :\")\n",
    "pipelineModel.stages[8].approxSimilarityJoin(dfA, dfB, 100, distCol=\"distance\")\\\n",
    "     .where(col(\"datasetA.id\") == col(\"datasetB.id\")) \\\n",
    "     .select(col(\"datasetA.text\").alias(\"idA\"), \\\n",
    "            col(\"datasetB.text\").alias(\"idB\"), \\\n",
    "            col(\"distance\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         primaryText|     primaryFeatures|           lookupKey|       secondaryText|   secondaryFeatures|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Wall Decals Lamp ...|[0.04242564737796...|bbc5a89d7cf3354ea...|Curtains & Valanc...|[0.30033871531486...|\n",
      "|iphone charger ph...|[0.37093448638916...|37c2b6ab956f9ebd6...|iphone case Apple...|[0.44015255570411...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import PandasUDFType, pandas_udf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "dfA = dfA.withColumnRenamed('text','primaryText').withColumnRenamed('features', 'primaryFeatures')\n",
    "\n",
    "dfB = dfB.withColumnRenamed('text','secondaryText').withColumnRenamed('features', 'secondaryFeatures')\n",
    "\n",
    "joinedDF = dfA.join(dfB, \"id\", \"inner\").drop(\"id\",\"normFeatures\")\n",
    "\n",
    "joinedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primaryText</th>\n",
       "      <th>primaryFeatures</th>\n",
       "      <th>lookupKey</th>\n",
       "      <th>secondaryText</th>\n",
       "      <th>secondaryFeatures</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall Decals Lamp Shades Armchairs Bed Sheets N...</td>\n",
       "      <td>[0.042425647377967834, -0.226881206035614, -0....</td>\n",
       "      <td>bbc5a89d7cf3354ea4887c3690404ad8</td>\n",
       "      <td>Curtains &amp; Valances Wall Decals &amp; Stickers Bed...</td>\n",
       "      <td>[0.3003387153148651, -0.022465573623776436, -0...</td>\n",
       "      <td>0.942328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone charger phone Gift case iPhone holder s...</td>\n",
       "      <td>[0.37093448638916016, 0.07500777393579483, -0....</td>\n",
       "      <td>37c2b6ab956f9ebd6dccebd7623bf8c1</td>\n",
       "      <td>iphone case Apple ipod</td>\n",
       "      <td>[0.4401525557041168, -0.09592525660991669, 0.0...</td>\n",
       "      <td>0.885493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         primaryText  \\\n",
       "0  Wall Decals Lamp Shades Armchairs Bed Sheets N...   \n",
       "1  iphone charger phone Gift case iPhone holder s...   \n",
       "\n",
       "                                     primaryFeatures  \\\n",
       "0  [0.042425647377967834, -0.226881206035614, -0....   \n",
       "1  [0.37093448638916016, 0.07500777393579483, -0....   \n",
       "\n",
       "                          lookupKey  \\\n",
       "0  bbc5a89d7cf3354ea4887c3690404ad8   \n",
       "1  37c2b6ab956f9ebd6dccebd7623bf8c1   \n",
       "\n",
       "                                       secondaryText  \\\n",
       "0  Curtains & Valances Wall Decals & Stickers Bed...   \n",
       "1                             iphone case Apple ipod   \n",
       "\n",
       "                                   secondaryFeatures    cosine  \n",
       "0  [0.3003387153148651, -0.022465573623776436, -0...  0.942328  \n",
       "1  [0.4401525557041168, -0.09592525660991669, 0.0...  0.885493  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "finalDF = joinedDF.toPandas()\n",
    "\n",
    "finalDF['cosine'] = finalDF.apply(lambda row: 1-cosine(row['primaryFeatures'], row['secondaryFeatures']), axis=1)\n",
    "finalDF"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "name": "tf2-2-2-cpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-cpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
