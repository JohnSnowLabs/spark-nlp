{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5vxzYTW-cTv8",
    "outputId": "9a870958-d998-4d8d-f641-30aeced7e784",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 14:55:47--  http://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
      "--2022-12-23 14:55:48--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-23 14:55:48--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 14:55:48 (45.3 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "\u001B[K     |████████████████████████████████| 281.5 MB 46 kB/s \n",
      "\u001B[K     |████████████████████████████████| 453 kB 57.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 199 kB 63.2 MB/s \n",
      "\u001B[?25h  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9FfkFoYHcTv-",
    "outputId": "30bb3d43-163b-4a22-af32-a72ad517f706",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "openjdk version \"11.0.17\" 2022-10-18\n",
      "OpenJDK Runtime Environment (build 11.0.17+8-post-Ubuntu-1ubuntu218.04)\n",
      "OpenJDK 64-Bit Server VM (build 11.0.17+8-post-Ubuntu-1ubuntu218.04, mixed mode, sharing)\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:             12           0           6           0           5          11\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!java -version\n",
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/text-similarity/file1.csv\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/text-similarity/file2.csv\n"
   ],
   "metadata": {
    "id": "y70C2BPeesRK",
    "outputId": "fe18cfbc-6e2f-4cc5-c1ff-aa24f3bc6e9a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 14:56:43--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/text-similarity/file1.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 297 [text/plain]\n",
      "Saving to: ‘file1.csv’\n",
      "\n",
      "\rfile1.csv             0%[                    ]       0  --.-KB/s               \rfile1.csv           100%[===================>]     297  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 14:56:43 (9.62 MB/s) - ‘file1.csv’ saved [297/297]\n",
      "\n",
      "--2022-12-23 14:56:43--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/text-similarity/file2.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 262 [text/plain]\n",
      "Saving to: ‘file2.csv’\n",
      "\n",
      "file2.csv           100%[===================>]     262  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 14:56:43 (9.84 MB/s) - ‘file2.csv’ saved [262/262]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Lja137H2cTv-"
   },
   "outputs": [],
   "source": [
    "#!pip install --ignore-installed -q pyspark==2.4.5\n",
    "#!gsutil cp gs://hadoop-lib/gcs/gcs-connector-hadoop2-latest.jar /opt/conda/lib/python3.7/site-packages/pyspark/jars/\n",
    "    \n",
    "#!pip install --ignore-installed spark-nlp==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "meJjUs07cTv_",
    "outputId": "d4292729-d1c6-46c6-ab87-78fa8e5d02ef",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root         587     241  0 14:56 ?        00:00:00 /bin/bash -c ps -ef | grep spark\n",
      "root         589     587  0 14:56 ?        00:00:00 grep spark\n"
     ]
    }
   ],
   "source": [
    "!ps -ef | grep spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Niauzii1cTv_"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import explode, col\n",
    "from pyspark.sql.functions import from_unixtime, to_date, asc, year, udf, explode, split, col, desc, length, rank, dense_rank, avg, sum\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.clustering import BisectingKMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.functions import col, to_timestamp,date_format\n",
    "from pyspark import StorageLevel\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from collections import Counter\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml.feature import Normalizer, SQLTransformer\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j47WpVxCcTv_",
    "outputId": "2900b78b-b4a7-469c-b94c-d80d22987217",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root         604     241 91 14:56 ?        00:00:46 /usr/lib/jvm/java-11-openjdk-amd64/bin/java -cp /usr/local/lib/python3.8/dist-packages/pyspark/conf:/usr/local/lib/python3.8/dist-packages/pyspark/jars/* -Xmx16G org.apache.spark.deploy.SparkSubmit --conf spark.master=local[*] --conf spark.driver.memory=16G --conf spark.kryoserializer.buffer.max=2000M --conf spark.driver.maxResultSize=0 --conf spark.jars.packages=com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.6 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.app.name=Spark NLP pyspark-shell\n",
      "root        1314     241  0 14:57 ?        00:00:00 /bin/bash -c ps -ef | grep spark\n",
      "root        1316    1314  0 14:57 ?        00:00:00 grep spark\n"
     ]
    }
   ],
   "source": [
    "spark.version\n",
    "!ps -ef | grep spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wlZc3EE3cTwA"
   },
   "outputs": [],
   "source": [
    "primaryCorpus = spark.read.option(\"header\",\"true\").csv(\"file1.csv\")\n",
    "secondaryCorpus = spark.read.option(\"header\",\"true\").csv(\"file2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BiazE3F3cTwA",
    "outputId": "93e6a4d2-15cb-4a2e-832a-115b6d2c7b39",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector()\\\n",
    "      .setInputCols(\"document\")\\\n",
    "      .setOutputCol(\"sentence\")\\\n",
    "      .setExplodeSentences(False)\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "bertEmbeddings = BertEmbeddings\\\n",
    " .pretrained('bert_base_cased', 'en') \\\n",
    " .setInputCols([\"sentence\",'token'])\\\n",
    " .setOutputCol(\"bert\")\\\n",
    " .setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "      .setInputCols([\"sentence\", \"bert\"]) \\\n",
    "      .setOutputCol(\"sentence_embeddings\") \\\n",
    "      .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "embeddingsFinisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"sentence_embeddings\",\"bert\"]) \\\n",
    "    .setOutputCols(\"sentence_embeddings_vectors\", \"bert_vectors\") \\\n",
    "    .setOutputAsVector(True)\\\n",
    "    .setCleanAnnotations(False)\n",
    "\n",
    "\n",
    "explodeVectors = SQLTransformer() \\\n",
    ".setStatement(\"SELECT EXPLODE(sentence_embeddings_vectors) AS features, * FROM __THIS__\")\n",
    "\n",
    "vectorNormalizer = Normalizer() \\\n",
    "    .setInputCol(\"features\") \\\n",
    "    .setOutputCol(\"normFeatures\") \\\n",
    "    .setP(1.0)\n",
    "\n",
    "similartyChecker = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength=6.0,numHashTables=6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zgOBgMt_cTwA"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "      .setStages([documentAssembler,\n",
    "        sentence,\n",
    "        tokenizer,\n",
    "        bertEmbeddings,\n",
    "        embeddingsSentence,\n",
    "        embeddingsFinisher,\n",
    "        explodeVectors,\n",
    "        vectorNormalizer,\n",
    "        similartyChecker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "I-b3JkN7cTwB"
   },
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(primaryCorpus)\n",
    "primaryDF = pipelineModel.transform(primaryCorpus)\n",
    "secondaryDF = pipelineModel.transform(secondaryCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GBvI8DT6cTwB",
    "outputId": "13e2900c-7c81-45b5-935b-88c02f1ae233",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|                text|            features|        normFeatures|           lookupKey| id|\n",
      "+--------------------+--------------------+--------------------+--------------------+---+\n",
      "|Wall Decals Lamp ...|[0.04242564737796...|[2.48993627607806...|bbc5a89d7cf3354ea...|  0|\n",
      "|iphone charger ph...|[0.37093448638916...|[0.00200630526885...|37c2b6ab956f9ebd6...|  1|\n",
      "+--------------------+--------------------+--------------------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfA = primaryDF.select(\"text\",\"features\",\"normFeatures\").withColumn(\"lookupKey\", md5(\"text\")).withColumn(\"id\",monotonically_increasing_id())\n",
    "dfA.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oCtCzkSIcTwB",
    "outputId": "7a1850c7-ec92-4d97-aa2d-a23130d8fd7e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+---+\n",
      "|                text|            features|        normFeatures| id|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "|Curtains & Valanc...|[0.30033871531486...|[0.00192763000744...|  0|\n",
      "|iphone case Apple...|[0.44015255570411...|[0.00236218518925...|  1|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfB = secondaryDF.select(\"text\",\"features\",\"normFeatures\").withColumn(\"id\",monotonically_increasing_id())\n",
    "dfB.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VwpGN_dwcTwB",
    "outputId": "d51c037b-cc40-4dc6-90a3-420bc8de87b7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|                 idA|                 idB|          distance|\n",
      "+--------------------+--------------------+------------------+\n",
      "|iphone charger ph...|iphone case Apple...| 5.666233511624179|\n",
      "|Wall Decals Lamp ...|Curtains & Valanc...|3.7816639073044893|\n",
      "+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(\"Approximately joining dfA and dfB :\")\n",
    "pipelineModel.stages[8].approxSimilarityJoin(dfA, dfB, 100, distCol=\"distance\")\\\n",
    "     .where(col(\"datasetA.id\") == col(\"datasetB.id\")) \\\n",
    "     .select(col(\"datasetA.text\").alias(\"idA\"), \\\n",
    "            col(\"datasetB.text\").alias(\"idB\"), \\\n",
    "            col(\"distance\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8dpMJrpcTwB"
   },
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lS08MF9ucTwC",
    "outputId": "71ba245a-d088-4291-ac1b-1e4f71390f54",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         primaryText|     primaryFeatures|           lookupKey|       secondaryText|   secondaryFeatures|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Wall Decals Lamp ...|[0.04242564737796...|bbc5a89d7cf3354ea...|Curtains & Valanc...|[0.30033871531486...|\n",
      "|iphone charger ph...|[0.37093448638916...|37c2b6ab956f9ebd6...|iphone case Apple...|[0.44015255570411...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import PandasUDFType, pandas_udf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "dfA = dfA.withColumnRenamed('text','primaryText').withColumnRenamed('features', 'primaryFeatures')\n",
    "\n",
    "dfB = dfB.withColumnRenamed('text','secondaryText').withColumnRenamed('features', 'secondaryFeatures')\n",
    "\n",
    "joinedDF = dfA.join(dfB, \"id\", \"inner\").drop(\"id\",\"normFeatures\")\n",
    "\n",
    "joinedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IuAh7w2fcTwC",
    "outputId": "3cd51280-724d-47c4-ee19-b418fdf7db64",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         primaryText  \\\n",
       "0  Wall Decals Lamp Shades Armchairs Bed Sheets N...   \n",
       "1  iphone charger phone Gift case iPhone holder s...   \n",
       "\n",
       "                                     primaryFeatures  \\\n",
       "0  [0.042425647377967834, -0.226881206035614, -0....   \n",
       "1  [0.37093448638916016, 0.07500777393579483, -0....   \n",
       "\n",
       "                          lookupKey  \\\n",
       "0  bbc5a89d7cf3354ea4887c3690404ad8   \n",
       "1  37c2b6ab956f9ebd6dccebd7623bf8c1   \n",
       "\n",
       "                                       secondaryText  \\\n",
       "0  Curtains & Valances Wall Decals & Stickers Bed...   \n",
       "1                             iphone case Apple ipod   \n",
       "\n",
       "                                   secondaryFeatures    cosine  \n",
       "0  [0.3003387153148651, -0.022465573623776436, -0...  0.942328  \n",
       "1  [0.4401525557041168, -0.09592525660991669, 0.0...  0.885493  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-dce31df2-da41-4e16-abcc-f5e66617c604\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primaryText</th>\n",
       "      <th>primaryFeatures</th>\n",
       "      <th>lookupKey</th>\n",
       "      <th>secondaryText</th>\n",
       "      <th>secondaryFeatures</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall Decals Lamp Shades Armchairs Bed Sheets N...</td>\n",
       "      <td>[0.042425647377967834, -0.226881206035614, -0....</td>\n",
       "      <td>bbc5a89d7cf3354ea4887c3690404ad8</td>\n",
       "      <td>Curtains &amp; Valances Wall Decals &amp; Stickers Bed...</td>\n",
       "      <td>[0.3003387153148651, -0.022465573623776436, -0...</td>\n",
       "      <td>0.942328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone charger phone Gift case iPhone holder s...</td>\n",
       "      <td>[0.37093448638916016, 0.07500777393579483, -0....</td>\n",
       "      <td>37c2b6ab956f9ebd6dccebd7623bf8c1</td>\n",
       "      <td>iphone case Apple ipod</td>\n",
       "      <td>[0.4401525557041168, -0.09592525660991669, 0.0...</td>\n",
       "      <td>0.885493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dce31df2-da41-4e16-abcc-f5e66617c604')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dce31df2-da41-4e16-abcc-f5e66617c604 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dce31df2-da41-4e16-abcc-f5e66617c604');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "finalDF = joinedDF.toPandas()\n",
    "\n",
    "finalDF['cosine'] = finalDF.apply(lambda row: 1-cosine(row['primaryFeatures'], row['secondaryFeatures']), axis=1)\n",
    "finalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2uzNr89ocTwC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qyOkhPvEcTwC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-cpu.2-2.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-cpu.2-2:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
