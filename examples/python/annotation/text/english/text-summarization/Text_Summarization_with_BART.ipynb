{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXatvRX899i0"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44B_JtXmyOuF"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/text-summarization/Text_Summarization_with_BART.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl6fW8Fkf3vN"
   },
   "source": [
    "# Document Summarization with [BART](https://arxiv.org/pdf/1910.13461.pdf)\n",
    "\n",
    "The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation.\n",
    "   \n",
    "BART is unique in that it is both bidirectional and auto-regressive, meaning that it can generate text both from left-to-right and from right-to-left. This allows it to capture contextual information from both past and future tokens in a sentence,resulting in more accurate and natural language generation.\n",
    "   \n",
    "The model was trained on a large corpus of text data using a combination of unsupervised and supervised learning techniques. It incorporates pretraining and fine-tuning phases, where the model is first trained on a large unlabeled corpus of text, and then fine-tuned on specific downstream tasks.\n",
    "   \n",
    "BART has achieved state-of-the-art performance on a wide range of NLP tasks, including summarization, question-answering, and language translation. Its ability to handle multiple tasks and its high performance on each of these tasks make it a versatile and valuable tool for natural language processing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06DMedvcgjKa"
   },
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Mc2rld9f7YW"
   },
   "outputs": [],
   "source": [
    "!pip install -q pyspark==3.3.2 spark-nlp==4.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjcBNzFVgoky"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Comment out this line  and uncomment the next one to enable GPU mode and High RAM\n",
    "# \n",
    "spark = sparknlp.start()\n",
    "\n",
    "# spark = sparknlp.start(gpu=True)\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZyycKyzQcwQ"
   },
   "source": [
    "# Download BART Model and Create Spark NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "gXdynTiFHKLK",
    "outputId": "bebd77ef-ac8c-49ab-bc06-dbf8f7f03a32",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbart_xsum_12_6 download started this may take some time.\n",
      "Approximate size to download 814.9 MB\n",
      "[ / ]distilbart_xsum_12_6 download started this may take some time.\n",
      "Approximate size to download 814.9 MB\n",
      "Download done! Loading the resource.\n",
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ — ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 08:52:08.552206: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\") \n",
    "\n",
    "# Can take in document or sentence columns\n",
    "bart = BartTransformer.pretrained(name=\"distilbart_xsum_12_6\",lang='en') \\\n",
    "    .setInputCols('document')\\\n",
    "    .setOutputCol(\"Bart\")\\\n",
    "    .setMaxOutputLength(100)\n",
    "\n",
    "# Build pipeline with BART\n",
    "pipe_components = [documentAssembler, bart]\n",
    "pipeline = Pipeline().setStages( pipe_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUfqQBdtNTS6"
   },
   "source": [
    "# Summarize documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X1-x-TLL5iJK",
    "outputId": "e5409d11-8ee2-4f94-d78b-697a53fa584f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTRANSFORMER_117e3797a285"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the task for questions on T5\n",
    "bart.setTask('summarize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzKvMHteNUTB",
    "outputId": "f5a3227d-c481-461d-c032-f1ceb9d1571c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                     |\n",
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|[The world's biggest credit- card company is joining the growing trend of accepting cryptocurrencies as a form of payment.]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# https://www.reuters.com/article/instant-article/idCAKBN2AA2WF\n",
    "\n",
    "text = \"\"\"(Reuters) - Mastercard Inc said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year, joining a string of big-ticket firms that have pledged similar support.\n",
    "\n",
    "The credit-card giant’s announcement comes days after Elon Musk’s Tesla Inc revealed it had purchased $1.5 billion of bitcoin and would soon accept it as a form of payment.\n",
    "\n",
    "Asset manager BlackRock Inc and payments companies Square and PayPal have also recently backed cryptocurrencies.\n",
    "\n",
    "Mastercard already offers customers cards that allow people to transact using their cryptocurrencies, although without going through its network.\n",
    "\n",
    "\"Doing this work will create a lot more possibilities for shoppers and merchants, allowing them to transact in an entirely new form of payment. This change may open merchants up to new customers who are already flocking to digital assets,\" Mastercard said. (mstr.cd/3tLaPZM)\n",
    "\n",
    "Mastercard specified that not all cryptocurrencies will be supported on its network, adding that many of the hundreds of digital assets in circulation still need to tighten their compliance measures.\n",
    "\n",
    "Many cryptocurrencies have struggled to win the trust of mainstream investors and the general public due to their speculative nature and potential for money laundering.\n",
    "\"\"\"\n",
    "data = [[text]]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "#Predict on text data with BART\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['bart.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdII1LrdNq3p",
    "outputId": "5bc00a17-7de1-49e3-d2ca-03ec07d89b73",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length 1284   Summarized Length : 121 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "v = annotated_df.take(1)\n",
    "print(f\"Original Length {len(v[0].text)}   Summarized Length : {len(v[0].Bart[0].result)} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "do_7s8baOCej",
    "outputId": "7425b0b5-b6b5-45b3-a07c-3db2c2fd35c4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The world's biggest credit- card company is joining the growing trend of accepting cryptocurrencies as a form of payment.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full summarized text\n",
    "v[0].Bart[0].result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XcVWsrDtW6X"
   },
   "source": [
    "# Explore BART Parameters and Play with Params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yxj99xiOtRwX"
   },
   "source": [
    "### Sampling Methods\n",
    "\n",
    "\n",
    "Sampling means we **randomly** draw from a distribution of words. \n",
    "The probability distribution is conditioned on all previous tokens in a text to generate the next token. \n",
    "\n",
    "By default the distribution contains all words in the vocabulary of BART, where many candidates are incorrect to generate.\n",
    "\n",
    "There are two methods of reshaping and drawing from those distributions : \n",
    "\n",
    "1. **Top-K Sampling** Take the k most likely words from the original distribution. Redistribute probability mass among those k words and draw according to the new probabilities.\n",
    "\n",
    "2. **Top-P Nucleus sampling**  Take smallest possible set of N words, which  together have a probability of p. Redistribute probability mass among those N words and draw according to the new probabilities.\n",
    "\n",
    "\n",
    "\n",
    "Additionally, both methods can be tweaked ith the following parameters : \n",
    "\n",
    "- **temperature** : Parameter of the softmax function which affect the distrubtion computed by the model. The closer we are to 0, the more deterministic the probability will become, distribution tails will become slimmer and outlier word probabilites are more close to 0. Temperature values closer values to 1 make tails of probability fatter which makes outliers more probable and generic results less probable. \n",
    "\n",
    "\n",
    "These parameters are shared by all method : \n",
    "- **beamSize**: Number of beams in the beam search\n",
    "- **ignoreTokenIds**: A list of token ids which are ignored in the decoder's output (default: [])\n",
    "- **noRepeatNgramSize**: If set to int > 0, all ngrams of that size can only occur once \n",
    "- **repetitionPenalty**: The parameter for repetition penalty. 1.0 means no penalty.  https://arxiv.org/pdf/1909.05858.pdf> \n",
    "- **task**:  Transformer's task, e.g. 'is it true that'> (default: , current: generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtj0kZV5tvBm"
   },
   "source": [
    "### Play with temperature \n",
    "Set Temperature higher to make GPT more random/creative and text less coherent\n",
    "Temperature > 0  and Temperature <=1\n",
    "You must set `bart.setDoSample(True)` to have non-deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Gmf32IdwgNlO",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTRANSFORMER_117e3797a285"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.setTemperature(0.7)\n",
    "bart.setDoSample(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "chCkax_jtF4R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                                  |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[The bitcoin virtual currency is set to get a major boost from the US credit card giant Mastercard its support for some of the virtual currency's cash.]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = [[text]]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "#Predict on text data with BART\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['bart.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nfbE1r7gSEb"
   },
   "source": [
    "### Play with beamSize\n",
    "\n",
    "When `beamSize = 1` the decoding process produce the greedy search, and when beamSize > 1 it produce the decoded output with beam search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Qn4_6A6lhcGX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTRANSFORMER_117e3797a285"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart.setBeamSize(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qkoBNgpuhi-f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[The cryptocurrency bitcoin is expected to reach a new level of use this year, after Mastercard said it would accept some of the digital assets.]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = [[text]]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "#Predict on text data with BART\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['bart.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GRDbFRWDhkte"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartTRANSFORMER_117e3797a285"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set beam size to 4\n",
    "bart.setBeamSize(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yrtCol7WhnSF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[South a row has escalidated over the the value of cryptocurrencies, with Mastercard now pledging to support some of the digital assets.]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "CPU times: user 48.6 ms, sys: 10.9 ms, total: 59.5 ms\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = [[text]]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "#Predict on text data with BART\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['bart.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
