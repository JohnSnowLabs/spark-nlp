{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/language-detection/Language_Detection_and_Indentification.ipynb)\n",
    "\n",
    "# Language Detection and Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.3.1\n",
      "Apache Spark version: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "\n",
    "print(\"Apache Spark version:\", spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanguageDetectorDL Pre-trained Models & Pipelines\n",
    "\n",
    "* Available pre-trained pipelines: https://sparknlp.org/models?tag=language_detection\n",
    "\n",
    "\n",
    "| Model                        | Name               | Build            | Lang \n",
    "|:-----------------------------|:-------------------|:-----------------|:------\n",
    "| LanguageDetectorDL    | `detect_language_21`        | 2.7.0 |      `xx`         | \n",
    "| LanguageDetectorDL    | `detect_language_43`        | 2.7.0 |      `xx`         | \n",
    "| LanguageDetectorDL    | `detect_language_95`        | 2.7.0 |      `xx`         | \n",
    "| LanguageDetectorDL    | `detect_language_99`        | 2.7.0 |      `xx`         | \n",
    "| LanguageDetectorDL    | `detect_language_220`        | 2.7.0 |      `xx`         | \n",
    "| LanguageDetectorDL    | `detect_language_231`        | 2.7.0 |      `xx`         | \n",
    "| LanguageDetectorDL    | `detect_language_375`        | 2.7.0 |      `xx`         | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LanguageDetectorDL\n",
    "## Pre-trained Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect_language_21 download started this may take some time.\n",
      "Approx size to download 7.7 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document': ['«Нападение на 13-й участок»'],\n",
       " 'sentence': ['«Нападение на 13-й участок»'],\n",
       " 'language': ['bg']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download a pre-trained pipeline by name and language\n",
    "language_detector_pipeline = PretrainedPipeline('detect_language_21', lang='xx')\n",
    "\n",
    "# Depending on the language (how similar the characters are), the LanguageDetectorDL works\n",
    "# best with text longer than 140 characters\n",
    "language_detector_pipeline.annotate(\"«Нападение на 13-й участок»\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LanguageDetectorDL\n",
    "## Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld_wiki_tatoeba_cnn_21 download started this may take some time.\n",
      "Approximate size to download 7.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    ".setInputCol(\"text\")\\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "language_detector = LanguageDetectorDL.pretrained(\"ld_wiki_tatoeba_cnn_21\")\\\n",
    ".setInputCols([\"document\"])\\\n",
    ".setOutputCol(\"lang\")\\\n",
    ".setThreshold(0.8)\\\n",
    ".setCoalesceSentences(True)\n",
    "\n",
    "languagePipeline = Pipeline(stages=[\n",
    " documentAssembler,\n",
    " language_detector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.createDataFrame([\n",
    "  ['Spark NLP is an open-source text processing library for advanced natural language processing for the Python, Java and Scala programming languages.'], \n",
    "  ['Spark NLP est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python, Java et Scala.']]\n",
    ").toDF(\"text\")\n",
    "\n",
    "results = languagePipeline.fit(test_df).transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|result|\n",
      "+------+\n",
      "|  [en]|\n",
      "|  [fr]|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(\"lang.result\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|metadata                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{fr -> 1.5861486E-20, lv -> 0.0, pt -> 1.3417289E-18, cs -> 1.867664E-20, el -> 1.0063604E-37, it -> 5.571735E-19, nl -> 4.5068417E-14, bg -> 0.0, et -> 1.1714855E-21, de -> 1.9250226E-15, sv -> 7.832558E-14, da -> 9.4325055E-11, en -> 1.0, sk -> 4.056913E-20, es -> 2.1614585E-21, fi -> 9.727943E-28, ro -> 4.9038655E-21, lt -> 5.9740204E-19, sl -> 3.4076286E-12, sentence -> 0, hu -> 1.5670225E-14, pl -> 1.0098784E-16}]|\n",
      "|[{fr -> 1.0, lv -> 0.0, pt -> 1.3446722E-30, cs -> 0.0, el -> 0.0, it -> 1.7137674E-27, nl -> 4.1279706E-37, bg -> 0.0, et -> 0.0, de -> 0.0, sv -> 0.0, da -> 0.0, en -> 0.0, sk -> 0.0, es -> 8.6860005E-30, fi -> 0.0, ro -> 9.285776E-25, lt -> 0.0, sl -> 7.775083E-34, sentence -> 0, hu -> 1.5921176E-30, pl -> 0.0}]                                                                                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# probabilities for other languages\n",
    "results.select(\"lang.metadata\").show(2, False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Language Detection and Indentification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
