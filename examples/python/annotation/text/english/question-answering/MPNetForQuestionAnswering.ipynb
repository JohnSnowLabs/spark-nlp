{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97EiXueJA9cY"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmxL_blSA9ce"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/question-answering/MPNetForQuestionAnswering.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI7yhCibA9cf"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WQLLrIUA9cg",
        "outputId": "d5760193-3cd6-45df-d354-def6d62b3c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing PySpark 3.2.3 and Spark NLP 5.3.1\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.8/564.8 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-XJDfUA9ci"
      },
      "source": [
        "# Download MPNetForQuestionAnswering Model and Create Spark NLP Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4uPbdrSA9ci"
      },
      "source": [
        "Lets create a Spark NLP pipeline with the following stages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzMHa0HdA9ch",
        "outputId": "4c19dc18-abdc-4c87-f5e3-2924c5dae7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP version 5.3.1\n",
            "Apache Spark version: 3.2.3\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# for GPU training >> sparknlp.start(gpu = True)\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "DVHludGFMSCk",
        "outputId": "fa69c6f0-d320-436a-b3e5-2021d73538bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sparknlp.annotator.classifier_dl.mpnet_for_question_answering.MPNetForQuestionAnswering</b><br/>def __init__(classname=&#x27;com.johnsnowlabs.nlp.annotators.classifier.dl.MPNetForQuestionAnswering&#x27;, java_model=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sparknlp/annotator/classifier_dl/mpnet_for_question_answering.py</a>MPNetForQuestionAnswering can load MPNet Models with a span classification head on top for extractive\n",
              "question-answering tasks like SQuAD (a linear layer on top of the hidden-states output to compute span start\n",
              "logits and span end logits).\n",
              "\n",
              "Pretrained models can be loaded with :meth:`.pretrained` of the companion\n",
              "object:\n",
              "\n",
              "&gt;&gt;&gt; spanClassifier = MPNetForQuestionAnswering.pretrained() \\\n",
              "...     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) \\\n",
              "...     .setOutputCol(&quot;answer&quot;)\n",
              "\n",
              "The default model is ``&quot;mpnet_base_question_answering_squad2&quot;``, if no name is\n",
              "provided.\n",
              "\n",
              "For available pretrained models please see the `Models Hub\n",
              "&lt;https://sparknlp.org/models?task=Question+Answering&gt;`__.\n",
              "\n",
              "To see which models are compatible and how to import them see\n",
              "`Import Transformers into Spark NLP 🚀\n",
              "&lt;https://github.com/JohnSnowLabs/spark-nlp/discussions/5669&gt;`_.\n",
              "\n",
              "====================== ======================\n",
              "Input Annotation types Output Annotation type\n",
              "====================== ======================\n",
              "``DOCUMENT, DOCUMENT``    ``CHUNK``\n",
              "====================== ======================\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "batchSize\n",
              "    Batch size. Large values allows faster processing but requires more\n",
              "    memory, by default 8\n",
              "caseSensitive\n",
              "    Whether to ignore case in tokens for embeddings matching, by default\n",
              "    False\n",
              "maxSentenceLength\n",
              "    Max sentence length to process, by default 128\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; import sparknlp\n",
              "&gt;&gt;&gt; from sparknlp.base import *\n",
              "&gt;&gt;&gt; from sparknlp.annotator import *\n",
              "&gt;&gt;&gt; from pyspark.ml import Pipeline\n",
              "&gt;&gt;&gt; documentAssembler = MultiDocumentAssembler() \\\n",
              "...     .setInputCols([&quot;question&quot;, &quot;context&quot;]) \\\n",
              "...     .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])\n",
              "&gt;&gt;&gt; spanClassifier = MPNetForQuestionAnswering.pretrained() \\\n",
              "...     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;]) \\\n",
              "...     .setOutputCol(&quot;answer&quot;) \\\n",
              "...     .setCaseSensitive(False)\n",
              "&gt;&gt;&gt; pipeline = Pipeline().setStages([\n",
              "...     documentAssembler,\n",
              "...     spanClassifier\n",
              "... ])\n",
              "&gt;&gt;&gt; data = spark.createDataFrame([[&quot;What&#x27;s my name?&quot;, &quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)\n",
              "&gt;&gt;&gt; result = pipeline.fit(data).transform(data)\n",
              "&gt;&gt;&gt; result.select(&quot;answer.result&quot;).show(truncate=False)\n",
              "+--------------------+\n",
              "|result              |\n",
              "+--------------------+\n",
              "|[Clara]             |\n",
              "+--------------------+</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 18);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "sparknlp.annotator.classifier_dl.mpnet_for_question_answering.MPNetForQuestionAnswering"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MPNetForQuestionAnswering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASQ5Ot2NA9ci",
        "outputId": "10133550-be84-42f4-fb48-2c7eb959dad2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mpnet_base_question_answering_squad2 download started this may take some time.\n",
            "Approximate size to download 384.9 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = MultiDocumentAssembler() \\\n",
        "    .setInputCols([\"question\", \"context\"]) \\\n",
        "    .setOutputCols([\"document_question\", \"document_context\"])\n",
        "\n",
        "spanClassifier = MPNetForQuestionAnswering.pretrained() \\\n",
        "    .setInputCols([\"document_question\", \"document_context\"]) \\\n",
        "    .setOutputCol(\"answer\") \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "     document_assembler,\n",
        "     spanClassifier\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENiJegX4A9cj"
      },
      "source": [
        "Lets create a dataframe with some queries and passages to be used as input for the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mEvtvP6CArla"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    [\"Do you know where I'm from?\", \"I'm from Tokyo and love sushi.\"],\n",
        "    [\"Can you guess my favorite color?\", \"My favorite color is blue and I love the ocean.\"],\n",
        "    [\"What do you think I do for a living?\", \"I'm a teacher in New York and enjoy reading.\"],\n",
        "    [\"Are you aware of my hobby?\", \"I enjoy painting and often visit art galleries.\"],\n",
        "    [\"Do you know my pet's name?\", \"My dog's name is Max and he loves long walks.\"]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "QuzAVrSE7ell"
      },
      "outputs": [],
      "source": [
        "data = spark.createDataFrame(examples).toDF(\"question\", \"context\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ3DGJ6CA9cj"
      },
      "source": [
        "Run the pipeline and get the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8oxp02ZA9cj",
        "outputId": "e7611d89-0a1a-4c3f-8327-9c7b24258272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------+-----------------------------------------------+----------+\n",
            "|question                            |context                                        |result    |\n",
            "+------------------------------------+-----------------------------------------------+----------+\n",
            "|Do you know where I'm from?         |I'm from Tokyo and love sushi.                 |[Tokyo]   |\n",
            "|Can you guess my favorite color?    |My favorite color is blue and I love the ocean.|[blue]    |\n",
            "|What do you think I do for a living?|I'm a teacher in New York and enjoy reading.   |[teacher] |\n",
            "|Are you aware of my hobby?          |I enjoy painting and often visit art galleries.|[painting]|\n",
            "|Do you know my pet's name?          |My dog's name is Max and he loves long walks.  |[Max]     |\n",
            "+------------------------------------+-----------------------------------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = pipeline.fit(data).transform(data)\n",
        "result.select(\"question\", \"context\", \"answer.result\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:tempspark]",
      "language": "python",
      "name": "conda-env-tempspark-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
