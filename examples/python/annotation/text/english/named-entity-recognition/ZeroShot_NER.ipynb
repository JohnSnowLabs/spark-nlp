{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21e9eafb",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/named-entity-recognition/ZeroShot_NER.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "212325cc-182f-4565-abed-9b46864d6d69",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with ZeroShotNer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216EshxBJ9ra",
   "metadata": {},
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyspark==3.3.0  spark-nlp==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.2.8\n",
      "Apache Spark version:  3.3.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.34:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc22f6d58e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32aee6",
   "metadata": {},
   "source": [
    "# Zero-shot Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43420eee-1c29-4148-b1c8-fa7884eff9b3",
   "metadata": {},
   "source": [
    "`Zero-shot` is a new inference paradigm which allows us to use a model for prediction without any previous training step.\n",
    "\n",
    "For doing that, several examples (_hypotheses_) are provided and sent to the Language model, which will use `NLI (Natural Language Inference)` to check if the any information found in the text matches the examples (confirm the hypotheses).\n",
    "\n",
    "NLI usually works by trying to _confirm or reject an hypotheses_. The _hypotheses_ are the `prompts` or examples we are going to provide. If any piece of information confirm the constructed hypotheses (answer the examples we are given), then the hypotheses is confirmed and the Zero-shot is triggered.\n",
    "\n",
    "Let's see it  in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948d346-d522-43b9-9cd7-99430882621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finner_roberta_zeroshot download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "sen = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "sparktokenizer = Tokenizer()\\\n",
    "  .setInputCols(\"sentence\")\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "zero_shot_ner = ZeroShotNerModel.pretrained(\"finner_roberta_zeroshot\", \"en\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"zero_shot_ner\")\\\n",
    "    .setEntityDefinitions(\n",
    "        {\n",
    "            \"DATE\": ['When was the company acquisition?', 'When was the company purchase agreement?'],\n",
    "            \"ORG\": [\"Which company was acquired?\"],\n",
    "            \"PRODUCT\": [\"Which product?\"],\n",
    "            \"PROFIT_INCREASE\": [\"How much has the gross profit increased?\"],\n",
    "            \"REVENUES_DECLINED\": [\"How much has the revenues declined?\"],\n",
    "            \"OPERATING_LOSS_2020\": [\"Which was the operating loss in 2020\"],\n",
    "            \"OPERATING_LOSS_2019\": [\"Which was the operating loss in 2019\"]\n",
    "        })\n",
    "\n",
    "nerconverter = NerConverter()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"zero_shot_ner\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline =  Pipeline(stages=[\n",
    "  documentAssembler,\n",
    "  sen,\n",
    "  sparktokenizer,\n",
    "  zero_shot_ner,\n",
    "  nerconverter\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005b29f-f0c0-44dd-baac-590166d6bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "sample_text = [\"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.\",\n",
    "              \"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.\",\n",
    "              \"While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019.\",\n",
    "              \"We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019.\"]\n",
    "\n",
    "p_model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))\n",
    "\n",
    "res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183fb2db-1cee-4f78-a486-dd6c9f6abd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+\n",
      "|chunk             |ner_label          |\n",
      "+------------------+-------------------+\n",
      "|March 2012        |DATE               |\n",
      "|Vertro            |ORG                |\n",
      "|ALOT              |PRODUCT            |\n",
      "|February 2017     |DATE               |\n",
      "|NetSeer           |ORG                |\n",
      "|81.4%             |PROFIT_INCREASE    |\n",
      "|27%               |REVENUES_DECLINED  |\n",
      "|$8,048,581 million|OPERATING_LOSS_2020|\n",
      "|$7,738,193        |OPERATING_LOSS_2019|\n",
      "|2019              |DATE               |\n",
      "+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "   .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "           F.expr(\"cols['3']['entity']\").alias(\"ner_label\"))\\\n",
    "   .filter(\"ner_label!='O'\")\\\n",
    "   .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nlpdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf73c0c97d90b2660ff29b0c9bed4b851524d3484a00df4555e25832aa5cf188"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
