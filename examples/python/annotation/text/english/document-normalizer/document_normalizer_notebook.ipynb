{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/document-normalizer/document_normalizer_notebook.ipynb)\n",
    "\n",
    "\n",
    "# Document Normalizer annotator notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://ckl-it.de/wp-content/uploads/2022/12/docs.zip\n",
    "!unzip -f docs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Spark NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Normalizer annotator overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DocumentNormalizer is an annotator that can be used after the DocumentAssembler to\n",
    "normalizes documents once that they have been processed and indexed.\n",
    "\n",
    "It takes in input annotated documents of type `Array[AnnotatorType]` (DOCUMENT) and gives\n",
    "as output annotated document of type AnnotatorType.DOCUMENT .\n",
    "\n",
    "Parameters are:\n",
    "- inputCol: input column name string which targets a column of type\n",
    "  Array(AnnotatorType.DOCUMENT).\n",
    "- outputCol: output column name string which targets a column of type\n",
    "  AnnotatorType.DOCUMENT.\n",
    "- action: action string to perform applying regex patterns, i.e. (clean | extract).\n",
    "  Default is \"clean\".\n",
    "- cleanupPatterns: normalization regex patterns which match will be removed from\n",
    "  document. Default is \"<[^>]*>\" (e.g., it removes all HTML tags).\n",
    "- replacement: replacement string to apply when regexes match. Default is \" \".\n",
    "- lowercase: whether to convert strings to lowercase. Default is False.\n",
    "- removalPolicy: removalPolicy to remove patterns from text with a given policy. Valid\n",
    "  policy values are: \"all\", \"pretty_all\", \"first\", \"pretty_first\". Defaults is\n",
    "  \"pretty_all\".\n",
    "- encoding: file encoding to apply on normalized documents. Supported encodings are:\n",
    "  UTF_8, UTF_16, US_ASCII, ISO-8859-1, UTF-16BE, UTF-16LE. Default is \"UTF-8\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "inpuColName = \"document\"\n",
    "outputColName = \"normalizedDocument\"\n",
    "\n",
    "action = \"clean\"\n",
    "cleanUpPatterns = [\"<[^>]*>\"]\n",
    "replacement = \" \"\n",
    "removalPolicy = \"pretty_all\"\n",
    "encoding = \"UTF-8\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(inpuColName) \\\n",
    "    .setOutputCol(outputColName) \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(removalPolicy) \\\n",
    "    .setLowercase(True) \\\n",
    "    .setEncoding(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|<!DOCTYPE html>\\n...|\n",
      "|<div class='w3-co...|\n",
      "|<span style=\"font...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"html-docs\"\n",
    "\n",
    "data = spark.sparkContext.wholeTextFiles(\"html-docs\")\n",
    "df = data.toDF(schema=[\"filename\", \"text\"]).select(\"text\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: remove all the tags from HTML text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  normalizedDocument|\n",
      "+--------------------+\n",
      "|[{document, 0, 17...|\n",
      "|[{document, 0, 67...|\n",
      "|[{document, 0, 31...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Once data is loaded we can process the textual document applying a pipeline that normalizes the document right after the DocumentAssembler.\n",
    "# For instance, let's imagine we are loading some HTML pages in our DataFrame and we want to remove all the tags in it:\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "cleanUpPatterns = [\"<[^>]*>\"]\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(\"clean\") \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(\" \") \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: obfuscate PII such as emails in HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 476, ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***w3schools***obfuscated pii***.com***obfuscated pii******obfuscated pii*** ***obfuscated pii***this is a heading***obfuscated pii*** ***obfuscated pii***this is a paragraph containing some pii like jonhdoe@myemail.com ! john is now 42 years old.***obfuscated pii*** ***obfuscated pii***48% of cardiologists treated patients aged 65+.***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{document, 0, 1040, ***obfuscated pii*** ***obfuscated pii***w3schools***obfuscated pii***.com***obfuscated pii******obfuscated pii*** ***obfuscated pii*** ***obfuscated pii******obfuscated pii*** ***obfuscated pii***log in***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** the world's largest web developer site ***obfuscated pii***the world's largest web developer site***obfuscated pii*** ***obfuscated pii***lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***, {sentence -> 0}, []}]|\n",
      "|[{document, 0, 217, ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***the output y(s) of the fig. is: ***obfuscated pii******obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"clean\"\n",
    "patterns = [\"([^.@\\\\s]+)(\\\\.[^.@\\\\s]+)*@([^.@\\\\s]+\\\\.)+([^.@\\\\s]+)\"]\n",
    "replacement = \"***OBFUSCATED PII***\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(\"clean\") \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: obfuscate PII such as ages in HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 440, <!doctype html> <html> <body> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <h1 style=\"font-size:300%;\">this is a heading</h1> <p style=\"font-size:160%;\">this is a paragraph containing some pii like jonhdoe@myemail.com ! john is now ***obfuscated pii*** years old.</p> <p style=\"font-size:160%;\">48% of cardiologists treated patients ***obfuscated pii***+.</p> </body> </html>, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{document, 0, 1212, <div class='w3-container top'> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <div id=\"loginactioncontainer\" class='w3-right'> <div id=\"mypagediv\"></div> <a id=\"w3loginbtn\" style=\"display:none;\" class=\"login w3-right\" href='javascript:void(0);' onclick='w3_open_nav(\"login\")'>log in</a> </div> <div id=\"theworldsgreatest\" class='w3-right w3-hide-small w3-wide toptext' style=\"font-family:'segoe ui',arial,sans-serif\"> the world's largest web developer site <h1 style=\"font-size:300%;\">the world's largest web developer site</h1> <p style=\"font-size:160%;\">lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..</p> </div> </div>, {sentence -> 0}, []}]|\n",
      "|[{document, 0, 241, <span style=\"font-weight: bold; font-size: 8pt\"> <pre style=\"font-family: verdana\"> <b>the output y(s) of the fig. is: <br /><br /> <img src=\"http://192.168.5.151/uadp4.0/itemauthoring/questionbank/resources/94954.jpeg\" /> </b> </pre> </span>, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"clean\"\n",
    "patterns = [\"\\\\d+(?=[\\\\s]?year)\", \"(aged)[\\\\s]?\\\\d+\"]\n",
    "replacement = \"***OBFUSCATED PII***\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: extract XML name tag contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|<?xml version=\"1....|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "data = spark.sparkContext.wholeTextFiles(\"xml-docs\")\n",
    "df = data.toDF(schema=[\"filename\", \"text\"]).select(\"text\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 638,  isabella isa jones ralph jones community health and hospitals henry seven henry seven henry seven frank jones community health and hospitals henry seven community health and hospitals henry seven henry seven mrs. martha jones health ls - immuno inc.health ls - immuno inc.health ls - immuno inc.health ls - immuno inc.medication factory inc.community health and hospitalsaerosolmedication factory inc. dr. henry seven medication factory inc. dr. henry seven community health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitals, {sentence -> 0}, []}]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"extract\"\n",
    "\n",
    "tag = \"name\"\n",
    "patterns = [tag]\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(\"\") \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5 : apply lookaround patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "            (1, \"10.2\",),\n",
    "            (2, \"9,53\",),\n",
    "            (3, \"11.01 mg\",),\n",
    "            (4, \"mg 11.01\",),\n",
    "            (5, \"14,220\",),\n",
    "            (6, \"Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.\",)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+---+---------------------------------------------------------+\n",
      "|id |text                                                     |\n",
      "+---+---------------------------------------------------------+\n",
      "|1  |10.2                                                     |\n",
      "|2  |9,53                                                     |\n",
      "|3  |11.01 mg                                                 |\n",
      "|4  |mg 11.01                                                 |\n",
      "|5  |14,220                                                   |\n",
      "|6  |Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|\n",
      "+---+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles_cols = [\"id\", \"text\"]\n",
    "df = spark.createDataFrame(data=articles, schema=articles_cols)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate replacing . to , using positive lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11,01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11.01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# Targetting text 11.01 mg annotating to 11,01 mg\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*\\d+(\\.)\\d+(?= mg).*\"]\n",
    "replacement = \",\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate replacing . to , using positive lookbehind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11.01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11,01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Targetting text mg 11.01 annotating to mg 11,01\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*(?<=mg )\\d+(\\.)\\d+.*\"]\n",
    "replacement = \",\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate replacing , to . using iterative positive lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11.01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11.01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4.5 mg for $10.35; Ibuprofen 5.5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Targetting text Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.\n",
    "# annotating to \n",
    "# Amoxiciline 4.5 mg for $10.35; Ibuprofen 5.5mg for $9.00\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*\\d+(\\,)\\d+(?=\\s?mg).*\"]\n",
    "replacement = \".\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "DocumentNormalizer_notebook_doc",
   "notebookOrigID": 3142402907558969,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
