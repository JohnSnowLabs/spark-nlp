{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gilhjL-xtel5"
   },
   "source": [
    "# Document Normalizer annotator notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7c65f64-07d6-4355-97a0-0a371d83116c",
     "showTitle": false,
     "title": ""
    },
    "id": "a9z0Sk-wtel7"
   },
   "source": [
    "# Set up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XJd1FYZEtel7",
    "outputId": "76c387aa-a5f2-48a0-edda-1a4b2cc26f60",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-24 15:21:32--  http://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
      "--2022-12-24 15:21:33--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-24 15:21:34--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-24 15:21:34 (61.0 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "\u001B[K     |████████████████████████████████| 281.5 MB 49 kB/s \n",
      "\u001B[K     |████████████████████████████████| 453 kB 59.8 MB/s \n",
      "\u001B[K     |████████████████████████████████| 199 kB 46.0 MB/s \n",
      "\u001B[?25h  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!wget http://ckl-it.de/wp-content/uploads/2022/12/docs.zip\n",
    "!unzip docs.zip"
   ],
   "metadata": {
    "id": "fQGr5EBmuUbh",
    "outputId": "177b45fc-2934-402f-f465-ec526791d2f2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-24 15:22:28--  http://ckl-it.de/wp-content/uploads/2022/12/docs.zip\n",
      "Resolving ckl-it.de (ckl-it.de)... 217.160.0.108, 2001:8d8:100f:f000::209\n",
      "Connecting to ckl-it.de (ckl-it.de)|217.160.0.108|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16670 (16K) [application/zip]\n",
      "Saving to: ‘docs.zip’\n",
      "\n",
      "docs.zip            100%[===================>]  16.28K  65.6KB/s    in 0.2s    \n",
      "\n",
      "2022-12-24 15:22:29 (65.6 KB/s) - ‘docs.zip’ saved [16670/16670]\n",
      "\n",
      "Archive:  docs.zip\n",
      "  inflating: html-docs/sample0.html  \n",
      "  inflating: html-docs/sample1.html  \n",
      "  inflating: html-docs/sample2.html  \n",
      "  inflating: json-docs/sample0.json  \n",
      "  inflating: xml-docs/C-CDAsample.xml  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5sJmpLPtel8"
   },
   "source": [
    "# Start Spark NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nKadS7-5tel8"
   },
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "import sparknlp \n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y460nHLitel8"
   },
   "source": [
    "# Document Normalizer annotator overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b4efb61f-6011-4ba1-a0ad-6c229f69e3d9",
     "showTitle": true,
     "title": "DocumentNormalizer overview and parameters"
    },
    "id": "gicU4xN_tel9"
   },
   "outputs": [],
   "source": [
    "# The DocumentNormalizer is an annotator that can be used after the DocumentAssembler to narmalize documents once that they have been processed and indexed .\n",
    "# It takes in input annotated documents of type Array[AnnotatorType](DOCUMENT) and gives as output annotated document of type AnnotatorType.DOCUMENT .\n",
    "#\n",
    "# Parameters are:\n",
    "# - inputCol: input column name string which targets a column of type Array(AnnotatorType.DOCUMENT).\n",
    "# - outputCol: output column name string which targets a column of type AnnotatorType.DOCUMENT.\n",
    "# - action: action string to perform applying regex patterns, i.e. (clean | extract). Default is \"clean\".\n",
    "# - cleanupPatterns: normalization regex patterns which match will be removed from document. Default is \"<[^>]*>\" (e.g., it removes all HTML tags).\n",
    "# - replacement: replacement string to apply when regexes match. Default is \" \".\n",
    "# - lowercase: whether to convert strings to lowercase. Default is False.\n",
    "# - removalPolicy: removalPolicy to remove patterns from text with a given policy. Valid policy values are: \"all\", \"pretty_all\", \"first\", \"pretty_first\". Defaults is \"pretty_all\".\n",
    "# - encoding: file encoding to apply on normalized documents. Supported encodings are: UTF_8, UTF_16, US_ASCII, ISO-8859-1, UTF-16BE, UTF-16LE. Default is \"UTF-8\".\n",
    "\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "inpuColName = \"document\"\n",
    "outputColName = \"normalizedDocument\"\n",
    "\n",
    "action = \"clean\"\n",
    "cleanUpPatterns = [\"<[^>]*>\"]\n",
    "replacement = \" \"\n",
    "removalPolicy = \"pretty_all\"\n",
    "encoding = \"UTF-8\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(inpuColName) \\\n",
    "    .setOutputCol(outputColName) \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(removalPolicy) \\\n",
    "    .setLowercase(True) \\\n",
    "    .setEncoding(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7QB7zgrtel9"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "58874c76-fc17-4d9e-9b4d-4e3db38cca95",
     "showTitle": false,
     "title": ""
    },
    "id": "zBtpXZWZtel9",
    "outputId": "92d3554b-2976-4f8d-a7e2-e2387067ade6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|<!DOCTYPE html>\\r...|\n",
      "|<div class='w3-co...|\n",
      "|<span style=\"font...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"html-docs\"\n",
    "\n",
    "data = spark.sparkContext.wholeTextFiles(\"html-docs\")\n",
    "df = data.toDF(schema=[\"filename\", \"text\"]).select(\"text\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNPN2S2Ytel-"
   },
   "source": [
    "# Example 1: remove all the tags from HTML text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f15441c7-5d2c-46f6-b102-fe9bc50c1b5e",
     "showTitle": true,
     "title": "Use case #1: HTML documents normalization using clean up and extract action"
    },
    "id": "ZjCsiX7stel-",
    "outputId": "eb07acef-acdb-48d0-def8-8670a90205e1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|  normalizedDocument|\n",
      "+--------------------+\n",
      "|[{document, 0, 17...|\n",
      "|[{document, 0, 67...|\n",
      "|[{document, 0, 31...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Once data is loaded we can process the textual document applying a pipeline that normalizes the document right after the DocumentAssembler.\n",
    "# For instance, let's imagine we are loading some HTML pages in our DataFrame and we want to remove all the tags in it:\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "cleanUpPatterns = [\"<[^>]*>\"]\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(\"clean\") \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(\" \") \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJM1jGN-tel_"
   },
   "source": [
    "# Example 2: obfuscate PII such as emails in HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zH03Yecztel_",
    "outputId": "c01aca3a-882e-4104-fe85-7c1ff6cadcd6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 476, ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***w3schools***obfuscated pii***.com***obfuscated pii******obfuscated pii*** ***obfuscated pii***this is a heading***obfuscated pii*** ***obfuscated pii***this is a paragraph containing some pii like jonhdoe@myemail.com ! john is now 42 years old.***obfuscated pii*** ***obfuscated pii***48% of cardiologists treated patients aged 65+.***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{document, 0, 1040, ***obfuscated pii*** ***obfuscated pii***w3schools***obfuscated pii***.com***obfuscated pii******obfuscated pii*** ***obfuscated pii*** ***obfuscated pii******obfuscated pii*** ***obfuscated pii***log in***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** the world's largest web developer site ***obfuscated pii***the world's largest web developer site***obfuscated pii*** ***obfuscated pii***lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***, {sentence -> 0}, []}]|\n",
      "|[{document, 0, 217, ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***the output y(s) of the fig. is: ***obfuscated pii******obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii*** ***obfuscated pii***, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"clean\"\n",
    "patterns = [\"([^.@\\\\s]+)(\\\\.[^.@\\\\s]+)*@([^.@\\\\s]+\\\\.)+([^.@\\\\s]+)\"]\n",
    "replacement = \"***OBFUSCATED PII***\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(\"clean\") \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dLQUngYtel_"
   },
   "source": [
    "# Example 3: obfuscate PII such as ages in HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ee2421ea-6f99-4161-ba15-2dffa44f91a8",
     "showTitle": true,
     "title": "Remove PII emails (\"this is a paragraph containing some pii like jonhdoe@myemail.com\")"
    },
    "id": "0w2Nj1B4tel_",
    "outputId": "de0d5bc6-d2e1-45ae-d480-f123540f9db3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 440, <!doctype html> <html> <body> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <h1 style=\"font-size:300%;\">this is a heading</h1> <p style=\"font-size:160%;\">this is a paragraph containing some pii like jonhdoe@myemail.com ! john is now ***obfuscated pii*** years old.</p> <p style=\"font-size:160%;\">48% of cardiologists treated patients ***obfuscated pii***+.</p> </body> </html>, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{document, 0, 1212, <div class='w3-container top'> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <div id=\"loginactioncontainer\" class='w3-right'> <div id=\"mypagediv\"></div> <a id=\"w3loginbtn\" style=\"display:none;\" class=\"login w3-right\" href='javascript:void(0);' onclick='w3_open_nav(\"login\")'>log in</a> </div> <div id=\"theworldsgreatest\" class='w3-right w3-hide-small w3-wide toptext' style=\"font-family:'segoe ui',arial,sans-serif\"> the world's largest web developer site <h1 style=\"font-size:300%;\">the world's largest web developer site</h1> <p style=\"font-size:160%;\">lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..</p> </div> </div>, {sentence -> 0}, []}]|\n",
      "|[{document, 0, 241, <span style=\"font-weight: bold; font-size: 8pt\"> <pre style=\"font-family: verdana\"> <b>the output y(s) of the fig. is: <br /><br /> <img src=\"http://192.168.5.151/uadp4.0/itemauthoring/questionbank/resources/94954.jpeg\" /> </b> </pre> </span>, {sentence -> 0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"clean\"\n",
    "patterns = [\"\\\\d+(?=[\\\\s]?year)\", \"(aged)[\\\\s]?\\\\d+\"]\n",
    "replacement = \"***OBFUSCATED PII***\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz1ztryatel_"
   },
   "source": [
    "# Example 4: extract XML name tag contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a7b7c94-f738-464e-b48f-4cc33807b0af",
     "showTitle": true,
     "title": "Use case #2: XML documents normalization using extract action on assigned person tag"
    },
    "id": "RLOcwYghtel_",
    "outputId": "89e7acdc-a22c-4066-f22e-2954e8a32b1e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|<?xml version=\"1....|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "data = spark.sparkContext.wholeTextFiles(\"xml-docs\")\n",
    "df = data.toDF(schema=[\"filename\", \"text\"]).select(\"text\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c75d10d8-d31f-40f6-a3cd-69b324c08325",
     "showTitle": false,
     "title": ""
    },
    "id": "cHrO1z7Etel_",
    "outputId": "9424d246-45f0-47b5-d7f4-5e07d6ea5190",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 638,  isabella isa jones ralph jones community health and hospitals henry seven henry seven henry seven frank jones community health and hospitals henry seven community health and hospitals henry seven henry seven mrs. martha jones health ls - immuno inc.health ls - immuno inc.health ls - immuno inc.health ls - immuno inc.medication factory inc.community health and hospitalsaerosolmedication factory inc. dr. henry seven medication factory inc. dr. henry seven community health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitals, {sentence -> 0}, []}]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"extract\"\n",
    "\n",
    "tag = \"name\"\n",
    "patterns = [tag]\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(\"\") \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1f9a9bd-20c7-4375-a1e9-6f75d83be23f",
     "showTitle": false,
     "title": ""
    },
    "id": "zZ5H5yA3temA"
   },
   "source": [
    "# Example 5 : apply lookaround patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qN9W6q46temA"
   },
   "outputs": [],
   "source": [
    "articles = [\n",
    "            (1, \"10.2\",),\n",
    "            (2, \"9,53\",),\n",
    "            (3, \"11.01 mg\",),\n",
    "            (4, \"mg 11.01\",),\n",
    "            (5, \"14,220\",),\n",
    "            (6, \"Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.\",)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rDF2RtTvtemA",
    "outputId": "958caf3c-4464-4cfb-a98e-87ebd4ed22e7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+---+---------------------------------------------------------+\n",
      "|id |text                                                     |\n",
      "+---+---------------------------------------------------------+\n",
      "|1  |10.2                                                     |\n",
      "|2  |9,53                                                     |\n",
      "|3  |11.01 mg                                                 |\n",
      "|4  |mg 11.01                                                 |\n",
      "|5  |14,220                                                   |\n",
      "|6  |Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|\n",
      "+---+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles_cols = [\"id\", \"text\"]\n",
    "df = spark.createDataFrame(data=articles, schema=articles_cols)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIdBYa6JtemA"
   },
   "source": [
    "## Annotate replacing . to , using positive lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "o690JNHLtemA",
    "outputId": "5d6cd76f-216b-4242-ff65-e79dba144b57",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11,01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11.01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# Targetting text 11.01 mg annotating to 11,01 mg\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*\\d+(\\.)\\d+(?= mg).*\"]\n",
    "replacement = \",\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97mpJ2RltemA"
   },
   "source": [
    "## Annotate replacing . to , using positive lookbehind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ubi4ky1GtemA",
    "outputId": "87e1125c-8e1d-4865-ad11-c36601a266ee",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11.01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11,01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Targetting text mg 11.01 annotating to mg 11,01\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*(?<=mg )\\d+(\\.)\\d+.*\"]\n",
    "replacement = \",\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcJ3A_jTtemA"
   },
   "source": [
    "## Annotate replacing , to . using iterative positive lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "U2H5QcOQtemB",
    "outputId": "418bafc8-d606-4d52-e5e6-10a76e5653aa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11.01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11.01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4.5 mg for $10.35; Ibuprofen 5.5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Targetting text Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.\n",
    "# annotating to \n",
    "# Amoxiciline 4.5 mg for $10.35; Ibuprofen 5.5mg for $9.00\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*\\d+(\\,)\\d+(?=\\s?mg).*\"]\n",
    "replacement = \".\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iDQEQkiztemB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "DocumentNormalizer_notebook_doc",
   "notebookOrigID": 3142402907558969,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
