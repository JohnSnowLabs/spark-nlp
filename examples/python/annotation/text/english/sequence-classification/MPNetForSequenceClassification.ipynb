{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97EiXueJA9cY"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmxL_blSA9ce"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/sequence-classification/MPNetForSequenceClassification.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI7yhCibA9cf"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4WQLLrIUA9cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45c18bb4-7045-4a55-b0de-c0f3d2a26fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PySpark 3.2.3 and Spark NLP 5.3.1\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 5.3.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.8/564.8 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-XJDfUA9ci"
      },
      "source": [
        "# Download MPNetForQuestionAnswering Model and Create Spark NLP Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4uPbdrSA9ci"
      },
      "source": [
        "Lets create a Spark NLP pipeline with the following stages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KzMHa0HdA9ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811e0b82-e037-47e8-ebf4-940eb584e848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 5.3.1\n",
            "Apache Spark version: 3.2.3\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# for GPU training >> sparknlp.start(gpu = True)\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MPNetForSequenceClassification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "DVHludGFMSCk",
        "outputId": "efc6d8ac-b92f-4d38-b248-1dd787161dd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sparknlp.annotator.classifier_dl.mpnet_for_sequence_classification.MPNetForSequenceClassification"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>sparknlp.annotator.classifier_dl.mpnet_for_sequence_classification.MPNetForSequenceClassification</b><br/>def __init__(classname=&#x27;com.johnsnowlabs.nlp.annotators.classifier.dl.MPNetForSequenceClassification&#x27;, java_model=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/sparknlp/annotator/classifier_dl/mpnet_for_sequence_classification.py</a>MPNetForSequenceClassification can load MPNet Models with sequence classification/regression head on\n",
              "top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.\n",
              "\n",
              "Pretrained models can be loaded with :meth:`.pretrained` of the companion\n",
              "object:\n",
              "\n",
              "&gt;&gt;&gt; sequenceClassifier = MPNetForSequenceClassification.pretrained() \\\n",
              "...     .setInputCols([&quot;token&quot;, &quot;document&quot;]) \\\n",
              "...     .setOutputCol(&quot;label&quot;)\n",
              "\n",
              "The default model is ``&quot;mpnet_sequence_classifier_ukr_message&quot;``, if no name is\n",
              "provided.\n",
              "\n",
              "For available pretrained models please see the `Models Hub\n",
              "&lt;https://sparknlp.org/models?task=Text+Classification&gt;`__.\n",
              "\n",
              "To see which models are compatible and how to import them see\n",
              "`Import Transformers into Spark NLP 🚀\n",
              "&lt;https://github.com/JohnSnowLabs/spark-nlp/discussions/5669&gt;`_.\n",
              "\n",
              "====================== ======================\n",
              "Input Annotation types Output Annotation type\n",
              "====================== ======================\n",
              "``DOCUMENT, TOKEN``    ``CATEGORY``\n",
              "====================== ======================\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "batchSize\n",
              "    Batch size. Large values allows faster processing but requires more\n",
              "    memory, by default 8\n",
              "caseSensitive\n",
              "    Whether to ignore case in tokens for embeddings matching, by default\n",
              "    True\n",
              "maxSentenceLength\n",
              "    Max sentence length to process, by default 128\n",
              "coalesceSentences\n",
              "    Instead of 1 class per sentence (if inputCols is `sentence`) output\n",
              "    1 class per document by averaging probabilities in all sentences, by\n",
              "    default False.\n",
              "activation\n",
              "    Whether to calculate logits via Softmax or Sigmoid, by default\n",
              "    `&quot;softmax&quot;`.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; import sparknlp\n",
              "&gt;&gt;&gt; from sparknlp.base import *\n",
              "&gt;&gt;&gt; from sparknlp.annotator import *\n",
              "&gt;&gt;&gt; from pyspark.ml import Pipeline\n",
              "&gt;&gt;&gt; document = DocumentAssembler() \\\n",
              "...     .setInputCol(&quot;text&quot;) \\\n",
              "...     .setOutputCol(&quot;document&quot;)\n",
              "&gt;&gt;&gt; tokenizer = Tokenizer() \\\n",
              "...     .setInputCols([&quot;document&quot;]) \\\n",
              "...     .setOutputCol(&quot;token&quot;)\n",
              "&gt;&gt;&gt; sequenceClassifier = MPNetForSequenceClassification \\\n",
              "...     .pretrained() \\\n",
              "...     .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\\n",
              "...     .setOutputCol(&quot;label&quot;)\n",
              "&gt;&gt;&gt; data = spark.createDataFrame([\n",
              "...     [&quot;I love driving my car.&quot;],\n",
              "...     [&quot;The next bus will arrive in 20 minutes.&quot;],\n",
              "...     [&quot;pineapple on pizza is the worst 🤮&quot;],\n",
              "... ]).toDF(&quot;text&quot;)\n",
              "&gt;&gt;&gt; pipeline = Pipeline().setStages([document, tokenizer, sequenceClassifier])\n",
              "&gt;&gt;&gt; pipelineModel = pipeline.fit(data)\n",
              "&gt;&gt;&gt; results = pipelineModel.transform(data)\n",
              "&gt;&gt;&gt; results.select(&quot;label.result&quot;).show()\n",
              "+--------------------+\n",
              "|              result|\n",
              "+--------------------+\n",
              "|     [TRANSPORT/CAR]|\n",
              "|[TRANSPORT/MOVEMENT]|\n",
              "|              [FOOD]|\n",
              "+--------------------+</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 19);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ASQ5Ot2NA9ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18dead41-dd5b-4a31-d712-0628762a5fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpnet_sequence_classifier_ukr_message download started this may take some time.\n",
            "Approximate size to download 384.5 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document = DocumentAssembler() \\\n",
        "     .setInputCol(\"text\") \\\n",
        "     .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "     .setInputCols([\"document\"]) \\\n",
        "     .setOutputCol(\"token\")\n",
        "\n",
        "sequenceClassifier = MPNetForSequenceClassification.pretrained() \\\n",
        "     .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setOutputCol(\"label\")\n",
        "\n",
        "pipeline = Pipeline().setStages([document, tokenizer, sequenceClassifier])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENiJegX4A9cj"
      },
      "source": [
        "Lets create a dataframe with some queries to be used as input for the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.createDataFrame([\n",
        "     [\"I love driving my car.\"],\n",
        "     [\"The next bus will arrive in 20 minutes.\"],\n",
        "     [\"pineapple on pizza is the worst 🤮\"]]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = pipeline.fit(data)\n",
        "results = pipelineModel.transform(data)"
      ],
      "metadata": {
        "id": "5OdRmdpQCZ14"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZ3DGJ6CA9cj"
      },
      "source": [
        "display the results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.select(\"text\", \"label.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-rN0D7ZCWkZ",
        "outputId": "31cb6800-195a-40d9-90b2-a1c6f622478d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------+--------------------+\n",
            "|text                                   |result              |\n",
            "+---------------------------------------+--------------------+\n",
            "|I love driving my car.                 |[TRANSPORT/CAR]     |\n",
            "|The next bus will arrive in 20 minutes.|[TRANSPORT/MOVEMENT]|\n",
            "|pineapple on pizza is the worst 🤮     |[FOOD]              |\n",
            "+---------------------------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tempspark]",
      "language": "python",
      "name": "conda-env-tempspark-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}