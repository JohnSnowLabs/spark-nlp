{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/document-assembler/Loading_Documents_With_DocumentAssembler.ipynb)\n",
    "\n",
    "\n",
    "# **Loading Documents with DocumentAssembler**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these examples we look at ways to use the DocumentAssembler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0. Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyspark==3.3.0  spark-nlp==4.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  4.2.8\n",
      "Apache Spark version:  3.3.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.34:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc22f6d58e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create Spark Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+\n",
      "|text                                                                         |\n",
      "+-----------------------------------------------------------------------------+\n",
      "|Peter is a very good person.                                                 |\n",
      "|My life in Russia is very interesting.                                       |\n",
      "|John and Peter are brothers. However they don't support each other that much.|\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.read.text('../spark-nlp-basics/sample-sentences-en.txt').toDF('text')\n",
    "\n",
    "spark_df.show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DocumentAssembler() creates the first annotation of type Document which may be used by annotators down the road.\n",
    "\n",
    "DocumentAssembler() comes from sparknlp.base class and has the following settable parameters. See the full list here and the source code here.\n",
    "\n",
    "\n",
    "| Parametre  | Value | Description |\n",
    "| - | - | - |\n",
    "|**setInputCol()**       |String |The name of the column that will be converted. We can specify only one column here. It can read either a String column or an Array.|\n",
    "|**setOutputCol()** |optional|The name of the column in Document type that is generated. We can specify only one column here. Default is '**document**'.|\n",
    "|**setIdCol()**  |optional|String type column with id information|\n",
    "|**setMetadataCol()** |optional|Map type column with metadata information.|\n",
    "|**setCleanupMode()** |optional| Cleaning up options|\n",
    "\n",
    "\n",
    "possible values for setCleanupMode :\n",
    "  ```\n",
    "  disabled: Source kept as original. This is a default.\n",
    "  inplace: removes new lines and tabs.\n",
    "  inplace_full: removes new lines and tabs but also those which were converted to strings (i.e. \\n)\n",
    "  shrink: removes new lines and tabs, plus merging multiple spaces and blank lines to a single space.\n",
    "  shrink_full: remove new lines and tabs, including stringified values, plus shrinking spaces and blank lines.\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                         |document                                                                                                               |\n",
      "+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|Peter is a very good person.                                                 |[{document, 0, 27, Peter is a very good person., {sentence -> 0}, []}]                                                 |\n",
      "|My life in Russia is very interesting.                                       |[{document, 0, 37, My life in Russia is very interesting., {sentence -> 0}, []}]                                       |\n",
      "|John and Peter are brothers. However they don't support each other that much.|[{document, 0, 76, John and Peter are brothers. However they don't support each other that much., {sentence -> 0}, []}]|\n",
      "|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |[{document, 0, 67, Lucas Nogal Dunbercker is no longer happy. He has a good car though., {sentence -> 0}, []}]         |\n",
      "|Europe is very culture rich. There are huge churches! and big houses!        |[{document, 0, 68, Europe is very culture rich. There are huge churches! and big houses!, {sentence -> 0}, []}]        |\n",
      "+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.base import *\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\\\n",
    "    .setCleanupMode(\"shrink\")\n",
    "\n",
    "doc_df = documentAssembler.transform(spark_df)\n",
    "\n",
    "doc_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we define DocumentAssembler with desired parameters and then transform the data frame with it. The most important point to pay attention to here is that you need to use a String or String[Array] type column in .setInputCol(). So it doesn’t have to be named as text. You just use the column name as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+-----+----+\n",
      "|result                                                                         |begin|end |\n",
      "+-------------------------------------------------------------------------------+-----+----+\n",
      "|[Peter is a very good person.]                                                 |[0]  |[27]|\n",
      "|[My life in Russia is very interesting.]                                       |[0]  |[37]|\n",
      "|[John and Peter are brothers. However they don't support each other that much.]|[0]  |[76]|\n",
      "|[Lucas Nogal Dunbercker is no longer happy. He has a good car though.]         |[0]  |[67]|\n",
      "|[Europe is very culture rich. There are huge churches! and big houses!]        |[0]  |[68]|\n",
      "+-------------------------------------------------------------------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_df.select('document.result','document.begin','document.end').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new column is in an array of struct type and has the parameters shown above. The annotators and transformers all come with universal metadata that would be filled down the road depending on the annotators being used. Unless you want to append other Spark NLP annotators to DocumentAssembler(), you don’t need to know what all these parameters mean for now. So we will talk about them in the following articles. You can access all these parameters with {column name}.{parameter name}.\n",
    "\n",
    "Let’s print out the first item’s result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(result=['Peter is a very good person.'])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df.select(\"document.result\").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would like to flatten the document column, we can do as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n",
      "|annotatorType|begin|end|result                                                                       |metadata       |embeddings|\n",
      "+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n",
      "|document     |0    |27 |Peter is a very good person.                                                 |{sentence -> 0}|[]        |\n",
      "|document     |0    |37 |My life in Russia is very interesting.                                       |{sentence -> 0}|[]        |\n",
      "|document     |0    |76 |John and Peter are brothers. However they don't support each other that much.|{sentence -> 0}|[]        |\n",
      "|document     |0    |67 |Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |{sentence -> 0}|[]        |\n",
      "|document     |0    |68 |Europe is very culture rich. There are huge churches! and big houses!        |{sentence -> 0}|[]        |\n",
      "+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "doc_df.withColumn(\n",
    "    \"tmp\",\n",
    "    F.explode(\"document\"))\\\n",
    "    .select(\"tmp.*\")\\\n",
    "    .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
