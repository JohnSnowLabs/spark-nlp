{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zAYzZXMyCYQx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3edc9bee-abcc-471a-946b-882d4bebd967"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-12-23 14:10:34--  http://setup.johnsnowlabs.com/colab.sh\n",
      "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
      "--2022-12-23 14:10:34--  https://setup.johnsnowlabs.com/colab.sh\n",
      "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
      "--2022-12-23 14:10:34--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1191 (1.2K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 14:10:34 (14.6 MB/s) - written to stdout [1191/1191]\n",
      "\n",
      "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
      "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n"
     ]
    }
   ],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxJniPtV_gqj",
    "outputId": "5c769310-69bc-4f5a-9740-676d875de5dc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spark NLP version 4.3.0\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession\n",
    "spark = sparknlp.start()\n",
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luNlbsk1AJqP",
    "outputId": "830269b6-ee71-4a98-cfbc-2c26a7752ed7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------------------------+\n",
      "|text                                            |\n",
      "+------------------------------------------------+\n",
      "|Peter Parker is a nice lad and lives in New York|\n",
      "+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "text = ['Peter Parker is a nice lad and lives in New York']\n",
    "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "data_set.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSvNig972xXC"
   },
   "source": [
    "# Graph Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkW7uQ4_cqAQ"
   },
   "source": [
    "Graph Extraction will use pretrained POS, Dependency Parser and Typed Dependency Parser annotators when the pipeline does not have those defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVFs6NDBlWsN",
    "outputId": "002a3d63-90c1-4a63-bf03-8bf9395921c4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_tagger = NerDLModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEJRu8qXg3SI"
   },
   "source": [
    "To consider Peter Parker a single token, we will need to set `MergeEntities` parameter to True. This parameter will merge neighbor tagging entities into one before sending it to Dependency Parsers annotators. To make this possible, Graph Extraction under the hood automatically uses pretrained POS, Dependency, and Typed Dependency Parser annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0qUXI5cBQFS"
   },
   "source": [
    "In this sentence, we can extract paths for the following pair of tokens-ENTITIES:\n",
    "* lad-PER, will output the path between *lad* and Peter Parker\n",
    "* lad-LOC, will output the path between *lad* and New York\n",
    "\n",
    "Any other pair of token,ENTITY will output an empty path since there is no path between them. You can visualize the dependency tree for this sentence using [sparknlp display package](https://github.com/JohnSnowLabs/spark-nlp-display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XxqysCFDg1aP"
   },
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "            .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "            .setOutputCol(\"graph\") \\\n",
    "            .setRelationshipTypes([\"lad-PER\", \"lad-LOC\"]) \\\n",
    "            .setMergeEntities(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEpjj9shlKMP"
   },
   "source": [
    "Under the hood it uses default pretrained annotators, but we can set any pretrained model with the parameters *setPosModel*, *setDependencyParserModel* or *setTypedDependencyParserModel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Dms9keFa7K0"
   },
   "source": [
    "Unlike [this notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/feature/graph-extraction-tutorial/jupyter/annotation/english/graph-extraction/graph_extraction.ipynb), the pipeline below just has graph extraction + NER + tokenizer annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LRpKY22pAqlL"
   },
   "outputs": [],
   "source": [
    "           \n",
    "graph_pipeline = Pipeline().setStages([document_assembler, tokenizer,\n",
    "                                       word_embeddings, ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJV6x-Nqw442"
   },
   "source": [
    "The result dataset has a *graph* column with the paths between lad,PER and lad-LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kh78KBe-63Dn",
    "outputId": "5b07b845-ce9b-4a85-918b-99a3ec1d6666"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|graph                                                                                                                                                               |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{node, 23, 25, lad, {relationship -> lad,PER, path1 -> lad,flat,Peter Parker}, []}, {node, 23, 25, lad, {relationship -> lad,LOC, path1 -> lad,flat,New York}, []}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cT7ArZJFCup8"
   },
   "execution_count": 7,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Graph Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
