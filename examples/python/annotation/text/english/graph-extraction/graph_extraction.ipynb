{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/graph-extraction/graph_extraction.ipynb)\n",
    "\n",
    "# Graph Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.3.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession\n",
    "spark = sparknlp.start()\n",
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+\n",
      "|text                                            |\n",
      "+------------------------------------------------+\n",
      "|Peter Parker is a nice lad and lives in New York|\n",
      "+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "text = ['Peter Parker is a nice lad and lives in New York']\n",
    "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "data_set.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Extraction will use pretrained POS, Dependency Parser and Typed Dependency Parser annotators when the pipeline does not have those defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_tagger = NerDLModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To consider Peter Parker a single token, we will need to set `MergeEntities` parameter to True. This parameter will merge neighbor tagging entities into one before sending it to Dependency Parsers annotators. To make this possible, Graph Extraction under the hood automatically uses pretrained POS, Dependency, and Typed Dependency Parser annotators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sentence, we can extract paths for the following pair of tokens-ENTITIES:\n",
    "* lad-PER, will output the path between *lad* and Peter Parker\n",
    "* lad-LOC, will output the path between *lad* and New York\n",
    "\n",
    "Any other pair of token,ENTITY will output an empty path since there is no path between them. You can visualize the dependency tree for this sentence using [sparknlp display package](https://github.com/JohnSnowLabs/spark-nlp-display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "            .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "            .setOutputCol(\"graph\") \\\n",
    "            .setRelationshipTypes([\"lad-PER\", \"lad-LOC\"]) \\\n",
    "            .setMergeEntities(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood it uses default pretrained annotators, but we can set any pretrained model with the parameters *setPosModel*, *setDependencyParserModel* or *setTypedDependencyParserModel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike [this notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/feature/graph-extraction-tutorial/jupyter/annotation/english/graph-extraction/graph_extraction.ipynb), the pipeline below just has graph extraction + NER + tokenizer annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "graph_pipeline = Pipeline().setStages([document_assembler, tokenizer,\n",
    "                                       word_embeddings, ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result dataset has a *graph* column with the paths between lad,PER and lad-LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|graph                                                                                                                |\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "|[[node, 23, 25, lad, [entities -> PER,LOC, left_path -> lad,flat,Peter Parker, right_path -> lad,flat,New York], []]]|\n",
      "+---------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Graph Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
