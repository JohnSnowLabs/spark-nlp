{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/prediction/english/graph_extraction_roots_paths.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 281.3 MB 39 kB/s \n",
      "\u001b[K     |████████████████████████████████| 198 kB 59.2 MB/s \n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing ./spark_nlp-4.2.7-py2.py3-none-any.whl\n",
      "Installing collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-4.2.7\n"
     ]
    }
   ],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.2.7\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.2.7\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "spark = sparknlp.start(real_time_output=True)\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|text                                             |\n",
      "+-------------------------------------------------+\n",
      "|Peter was born in Mexico and very successful man.|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "text = ['Peter was born in Mexico and very successful man.']\n",
    "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "data_set.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Extraction requires POS, DependencyParsers and NER to extract information from a Dependency Tree. Check this [introductory notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/graph-extraction/graph_extraction_intro.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[ / ]glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[ — ]Download done! Loading the resource.\n",
      "[OK!]\n",
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[ / ]ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_tagger = NerDLModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Extraction Default Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Extraction by default will merge and explode entities. Which means:\n",
    "\n",
    "*   **explodeEntities**: This parameter finds paths between all pair of entities labeled by NER\n",
    "*   **mergeEntities**: This parameter merges same neighboring entities as a single token e.g. `New York` will be consider a single token, instead of `New` as one token and `York` as another one.\n",
    "\n",
    "**mergeEntities** will also configure Graph Extraction to use default pretrained POS, Dependency Parser and Typed Dependency Parser models under the hood. If we set this parameter to `false`, we will need to define those in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "            .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "            .setOutputCol(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_pipeline = Pipeline().setStages([document_assembler, tokenizer,\n",
    "                                       word_embeddings, ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "Download done! Loading the resource.\n",
      "dependency_conllu download started this may take some time.\n",
      "Approximate size to download 16.7 MB\n",
      "Download done! Loading the resource.\n",
      "dependency_typed_conllu download started this may take some time.\n",
      "Approximate size to download 2.4 MB\n",
      "Download done! Loading the resource.\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|graph                                                                                                                    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{node, 10, 13, born, {entities -> PER,LOC, left_path -> born,flat,Peter, right_path -> born,nsubj,man,flat,Mexico}, []}]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**entitTypes** parameter allow us to find paths between a pair of entities. The pair of entities must be separated by hyphen. So, we must use this format:\n",
    "\n",
    "`[ \"ENTITY_1-ENTITY_2\", \"ENTITY_3-ENTITY_4\", \"ENTITY_N-ENTITY_M\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"graph\") \\\n",
    "    .setEntityTypes(['LOC-PER'])\n",
    "\n",
    "\n",
    "graph_pipeline = Pipeline().setStages([document_assembler, \n",
    "                                       tokenizer,\n",
    "                                       word_embeddings, \n",
    "                                       ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|graph                                                                                                                    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{node, 10, 13, born, {entities -> LOC,PER, left_path -> born,nsubj,man,flat,Mexico, right_path -> born,flat,Peter}, []}]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Root Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set a different root. For that we need to check which words can be defined as root. Visualizing the first level of the dependency tree in [this notebook](https://colab.research.google.com/drive/1BbLeRBjHxqIvcz8812ckwk5gNc2es383?usp=sharing), besides `born` those could be: `Peter`, `was`, `.` and `man`. However, some of those won't return a relationship.\n",
    "\n",
    "To define a root that will return meaningful relationships, a token has to fulfill the following requirements:\n",
    "1. It has to have an ancestor node\n",
    "2. It has to have descendants\n",
    "3. It has to have at least one descendant node labeled as entity by NER\n",
    "\n",
    "Let's check `Peter` token:\n",
    "1. It has an ancestor node: `born` (OK)\n",
    "2. It does not have any descendant. \n",
    "\n",
    "*Peter* does not comply to requirement 2. So, it won't output any relationship. The same will hold for tokens `was` and `.` \n",
    "\n",
    "Now. let's check `man` token:\n",
    "1. It has an ancestor node: `born` (OK)\n",
    "2. It has descendants: `Mexico` and `successful` (OK)\n",
    "3. It has to have at least one descendant node labeled as an entity by NER: `Mexico` as `LOC` (as we can see in [this visualization for NER](https://colab.research.google.com/drive/1BbLeRBjHxqIvcz8812ckwk5gNc2es383?usp=sharing)) (OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we let things by default. It won't output anything as we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"graph\") \\\n",
    "    .setRootTokens(['man'])\n",
    "\n",
    "\n",
    "graph_pipeline = Pipeline().setStages([document_assembler, \n",
    "                                       tokenizer,\n",
    "                                       word_embeddings, \n",
    "                                       ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Not found paths between given roots: [man] and entities pairs: (PER,LOC).\n",
      "This could mean there are no more labeled tokens below the given roots or NER didn't label any token.\n",
      "You can try using relationshipTypes parameter, check this notebook: https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english//graph-extraction/graph_extraction_roots_paths.ipynb \n",
      "You can also use spark-nlp-display to visualize Dependency Parser and NER output to help identify the kind of relations you can extract, check this notebook: https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english//graph-extraction/graph_extraction_helper_display.ipynb\n",
      "+-----+\n",
      "|graph|\n",
      "+-----+\n",
      "|[]   |\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is empty, because under `man` we only have `Mexico` as an entity. NER does not identify any other entity. So, `Mexico` does not have another pair to show a path. But, we can use `relationshipTypes` parameter to find a path between and unlabeled token and a labeled token, as we can see in the example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**relationshipTypes** allows us to find a path between an unlabeled token and a labeled token. To use this parameter, we need to set **explodEntities** parameter to `false`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"graph\") \\\n",
    "    .setExplodeEntities(False) \\\n",
    "    .setRootTokens(['man']) \\\n",
    "    .setRelationshipTypes([\"man-LOC\"])\n",
    "\n",
    "graph_pipeline = Pipeline().setStages([document_assembler, \n",
    "                                       tokenizer,\n",
    "                                       word_embeddings, \n",
    "                                       ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+\n",
      "|graph                                                                         |\n",
      "+------------------------------------------------------------------------------+\n",
      "|[{node, 45, 47, man, {relationship -> man,LOC, path1 -> man,flat,Mexico}, []}]|\n",
      "+------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, it searchs deep which means it will find relationships from the defined root to its labeled descendants. This means that if for example we set a relationship like `setRelationshipTypes([\"successful-LOC\"])` it won't output a path. \n",
    "\n",
    "So, a requirement to use `setRelationshipTypes` is that the unlabeled token in the relationship has to be an ancestor node. Remember to use hyphen to separate the pair `[\"unlabeled_token-labeled_token\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Entities more Relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the example above, we can set a root token and let other parameters as default to get an output. However, we need a different sentence that produces a deeper dependency tree with descendants that have labeled tokens. If we tweak the sentence as shown below, we can make it work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|text                                                   |\n",
      "+-------------------------------------------------------+\n",
      "|Peter was born in Mexico and very successful in Queens.|\n",
      "+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ['Peter was born in Mexico and very successful in Queens.']\n",
    "data_set = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
    "data_set.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in this [visualization notebook ](https://colab.research.google.com/drive/1BbLeRBjHxqIvcz8812ckwk5gNc2es383?usp=sharing), now we have a labeled token (`Queens`) at a deeper level. So, we can use it safely to get a path from another root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_extraction = GraphExtraction() \\\n",
    "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"graph\") \\\n",
    "    .setRootTokens(['Mexico'])\n",
    "\n",
    "\n",
    "graph_pipeline = Pipeline().setStages([document_assembler, \n",
    "                                       tokenizer,\n",
    "                                       word_embeddings, \n",
    "                                       ner_tagger,\n",
    "                                       graph_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|graph                                                                                                                      |\n",
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{node, 18, 23, Mexico, {entities -> LOC,LOC, left_path -> Mexico, right_path -> Mexico,amod,successful,nsubj,Queens}, []}]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_data_set = graph_pipeline.fit(data_set).transform(data_set)\n",
    "graph_data_set.select(\"graph\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
