{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/spark-nlp-basics/playground-dataFrames.ipynb)\n",
    "\n",
    "## Playground - DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when you are using Spark NLP on Google Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYSPARK_PYTHON=/home/ducha/.conda/envs/sparknlp/bin/python\n",
      "env: PYSPARK_DRIVER_PYTHON=/home/ducha/.conda/envs/sparknlp/bin/python\n"
     ]
    }
   ],
   "source": [
    "%env PYSPARK_PYTHON=/home/ducha/.conda/envs/sparknlp/bin/python\n",
    "%env PYSPARK_DRIVER_PYTHON=/home/ducha/.conda/envs/sparknlp/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 3.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler().setInputCol('text').setOutputCol('document')\n",
    "tokenizer = Tokenizer().setInputCols('document').setOutputCol('token')\n",
    "pos = PerceptronModel.pretrained().setInputCols('document', 'token').setOutputCol('pos')\n",
    "\n",
    "pipeline = Pipeline().setStages([document, tokenizer, pos])\n",
    "\n",
    "data = spark.read.text('./sample-sentences-en.txt').toDF('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Peter is a very g...|\n",
      "|My life in Russia...|\n",
      "|John and Peter ar...|\n",
      "|Lucas Nogal Dunbe...|\n",
      "|Europe is very cu...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|               token|                 pos|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|\n",
      "|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{pos, 0, 1, PRP$...|\n",
      "|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{pos, 0, 3, NNP,...|\n",
      "|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{pos, 0, 4, NNP,...|\n",
      "|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{pos, 0, 5, NNP,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = result\\\n",
    "  .select('text', 'pos.begin', 'pos.end', 'pos.result', 'pos.metadata')\\\n",
    "  .toDF('text', 'pos_begin', 'pos_end', 'pos_result', 'pos_meta')\\\n",
    "  .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- pos_begin: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- pos_end: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- pos_result: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- pos_meta: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|           pos_begin|             pos_end|          pos_result|            pos_meta|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Peter is a very g...|[0, 6, 9, 11, 16,...|[4, 7, 9, 14, 19,...|[NNP, VBZ, DT, RB...|[{word -> Peter, ...|\n",
      "|My life in Russia...|[0, 3, 8, 11, 18,...|[1, 6, 9, 16, 19,...|[PRP$, NN, IN, NN...|[{word -> My, sen...|\n",
      "|John and Peter ar...|[0, 5, 9, 15, 19,...|[3, 7, 13, 17, 26...|[NNP, CC, NNP, VB...|[{word -> John, s...|\n",
      "|Lucas Nogal Dunbe...|[0, 6, 12, 23, 26...|[4, 10, 21, 24, 2...|[NNP, NNP, NNP, V...|[{word -> Lucas, ...|\n",
      "|Europe is very cu...|[0, 7, 10, 15, 23...|[5, 8, 13, 21, 26...|[NNP, VBZ, RB, RB...|[{word -> Europe,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## Spark SQL Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-------+----------+--------+\n",
      "|text|pos_begin|pos_end|pos_result|pos_meta|\n",
      "+----+---------+-------+----------+--------+\n",
      "+----+---------+-------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.filter(array_contains('pos_result', 'VBD')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          pos_result|token_count|\n",
      "+--------------------+-----------+\n",
      "|[NNP, VBZ, DT, RB...|          7|\n",
      "|[PRP$, NN, IN, NN...|          8|\n",
      "|[NNP, CC, NNP, VB...|         15|\n",
      "|[NNP, NNP, NNP, V...|         15|\n",
      "|[NNP, VBZ, RB, RB...|         15|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.withColumn('token_count', size('pos_result')).select('pos_result', 'token_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                text|array_max(pos_end)|\n",
      "+--------------------+------------------+\n",
      "|Peter is a very g...|                27|\n",
      "|My life in Russia...|                37|\n",
      "|John and Peter ar...|                76|\n",
      "|Lucas Nogal Dunbe...|                67|\n",
      "|Europe is very cu...|                68|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.select('text', array_max('pos_end')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          pos_result|          unique_pos|\n",
      "+--------------------+--------------------+\n",
      "|[NNP, VBZ, DT, RB...|[NNP, VBZ, DT, RB...|\n",
      "|[PRP$, NN, IN, NN...|[PRP$, NN, IN, NN...|\n",
      "|[NNP, CC, NNP, VB...|[NNP, CC, VBP, NN...|\n",
      "|[NNP, NNP, NNP, V...|[NNP, VBZ, DT, RB...|\n",
      "|[NNP, VBZ, RB, RB...|[NNP, VBZ, RB, JJ...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.withColumn('unique_pos', array_distinct('pos_result')).select('pos_result', 'unique_pos').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|array_sort(array_distinct(pos_result), lambdafunction((IF(((left IS NULL) AND (right IS NULL)), 0, (IF((left IS NULL), 1, (IF((right IS NULL), -1, (IF((left < right), -1, (IF((left > right), 1, 0)))))))))), left, right))|count|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|                                                                                                                                                                                                        [., CC, EX, JJ, N...|    1|\n",
      "|                                                                                                                                                                                                        [., IN, JJ, NN, N...|    1|\n",
      "|                                                                                                                                                                                                        [., CC, DT, IN, J...|    1|\n",
      "|                                                                                                                                                                                                        [., DT, IN, JJ, N...|    1|\n",
      "|                                                                                                                                                                                                        [., DT, JJ, NN, N...|    1|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.groupBy(array_sort(array_distinct('pos_result'))).count().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "### SQL Functions with `col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|pos_meta[0][word]|\n",
      "+-----------------+\n",
      "|            Peter|\n",
      "|               My|\n",
      "|             John|\n",
      "|            Lucas|\n",
      "|           Europe|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.select(col('pos_meta').getItem(0).getItem('word')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Spark NLP Annotation UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|pos                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{pos, 0, 4, NNP, {word -> Peter, sentence -> 0}, []}, {pos, 6, 7, VBZ, {word -> is, sentence -> 0}, []}, {pos, 9, 9, DT, {word -> a, sentence -> 0}, []}, {pos, 11, 14, RB, {word -> very, sentence -> 0}, []}, {pos, 16, 19, JJ, {word -> good, sentence -> 0}, []}, {pos, 21, 26, NN, {word -> person, sentence -> 0}, []}, {pos, 27, 27, ., {word -> ., sentence -> 0}, []}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('pos').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.functions import *\n",
    "from pyspark.sql.types import ArrayType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------+\n",
      "|nn_tokens                                               |\n",
      "+--------------------------------------------------------+\n",
      "|[{pos, 21, 26, NN, {sentence -> 0, word -> person}, []}]|\n",
      "|[{pos, 3, 6, NN, {sentence -> 0, word -> life}, []}]    |\n",
      "|[]                                                      |\n",
      "|[{pos, 57, 59, NN, {sentence -> 0, word -> car}, []}]   |\n",
      "|[]                                                      |\n",
      "+--------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def nn_tokens(annotations):\n",
    "    nn_annotations = list(\n",
    "        filter(lambda annotation: annotation.result == 'NN', annotations)\n",
    "    )\n",
    "    return nn_annotations\n",
    "\n",
    "result.select(map_annotations(nn_tokens, Annotation.arrayType())('pos').alias('nn_tokens')).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "playground-dataFrames.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
