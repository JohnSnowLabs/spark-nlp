{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIKUgFUO6Ks7"
      },
      "source": [
        "# DateMatcher multi-language\n",
        "\n",
        "#### This annotator allows you to specify a source language that will be used to identify temporal keywords and extract dates."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "metadata": {
        "id": "wEzGFRu06LRA",
        "outputId": "16f76462-9b3f-4810-8c62-0526a05dace2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-23 12:15:39--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-12-23 12:15:39--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-12-23 12:15:39--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-23 12:15:39 (35.7 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 4.2.6\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 4.2.6\n",
            "\u001b[K     |████████████████████████████████| 281.5 MB 57 kB/s \n",
            "\u001b[K     |████████████████████████████████| 453 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 83.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "943a272c-0686-4e02-a8d9-b2849721c829",
          "showTitle": false,
          "title": ""
        },
        "id": "snWEWQPW6Ks9"
      },
      "outputs": [],
      "source": [
        "# Import Spark NLP\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "import sparknlp\n",
        "\n",
        "# Start Spark Session with Spark NLP\n",
        "# start() functions has two parameters: gpu and spark23\n",
        "# sparknlp.start(gpu=True) will start the session with GPU support\n",
        "# sparknlp.start(spark23=True) is when you have Apache Spark 2.3.x installed\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "b200e2aa-6280-4f51-9eb4-e30f660e2ba4",
          "showTitle": false,
          "title": ""
        },
        "id": "xDQ3AELm6Ks-",
        "outputId": "547e834b-8ccb-45c9-8653-178beb988bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f39ed47fe80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e0d19818193f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "c0b759a0-346f-4d9f-9f01-383124c0aa05",
          "showTitle": false,
          "title": ""
        },
        "id": "cYA0Xhws6Ks_",
        "outputId": "4d0bcc8c-6cc1-4236-ecee-f183668c306d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.2.6'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sparknlp.version()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM91YCJJ6Ks_"
      },
      "source": [
        "# French examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_mlITBN6Ks_"
      },
      "source": [
        "### Let's import some articoles sentences from the news where relative dates are present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "a91c2626-5ef8-4e01-9563-120daf4f63f3",
          "showTitle": false,
          "title": ""
        },
        "id": "gedTbW8-6Ks_"
      },
      "outputs": [],
      "source": [
        "fr_articles = [\n",
        "  (\"Le dimanche 11 juillet 2021, Chiellini a utilisé le mot Kiricocho lorsque Saka s'est approché du ballon pour le penalty.\",),\n",
        "  (\"La prochaine Coupe du monde aura lieu en novembre 2022.\",),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LR9O-Ck6KtA"
      },
      "source": [
        "### Let's  fill a DataFrame with the text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "cfe3f9e0-4a96-44bb-b056-0b4a5407c6dc",
          "showTitle": false,
          "title": ""
        },
        "id": "9Aaa1EMg6KtA",
        "outputId": "94220058-9895-4391-930f-d4e83cbe2e69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            "\n",
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Le dimanche 11 ju...|\n",
            "|La prochaine Coup...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "articles_cols = [\"text\"]\n",
        "\n",
        "df = spark.createDataFrame(data=fr_articles, schema=articles_cols)\n",
        "\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CouoUbh6KtB"
      },
      "source": [
        "### Now, let's create a simple pipeline to apply the DateMatcher, specifying the source language"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "f4baf2a1-3e75-479e-9e9b-2b071624ee3d",
          "showTitle": false,
          "title": ""
        },
        "id": "p0g2aabO6KtB"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "            .setInputCol(\"text\") \\\n",
        "            .setOutputCol(\"document\")\n",
        "\n",
        "date_matcher = DateMatcher() \\\n",
        "            .setInputCols(['document']) \\\n",
        "            .setOutputCol(\"date\") \\\n",
        "            .setOutputFormat(\"MM/dd/yyyy\") \\\n",
        "            .setSourceLanguage(\"fr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5zcbvoMJ6KtB"
      },
      "outputs": [],
      "source": [
        "### Let's transform the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "inputWidgets": {},
          "nuid": "10380fbb-43c1-42c3-b6d0-f02e55d75a24",
          "showTitle": false,
          "title": ""
        },
        "id": "bxLOMmBn6KtC",
        "outputId": "027b1e63-e724-4831-a160-4adae85fb8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------+\n",
            "|date                                             |\n",
            "+-------------------------------------------------+\n",
            "|[{date, 10, 21, 07/11/2021, {sentence -> 0}, []}]|\n",
            "|[{date, 41, 53, 11/01/2022, {sentence -> 0}, []}]|\n",
            "+-------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "assembled = document_assembler.transform(df)\n",
        "date_matcher.transform(assembled).select('date').show(10, False)"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "DateMatcherMultiLanguage_tests",
      "notebookOrigID": 2439167545177012,
      "widgets": {}
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}