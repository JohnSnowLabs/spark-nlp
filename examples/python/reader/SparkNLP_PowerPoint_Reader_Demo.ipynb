{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_ssGnSHQytt"
   },
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/reader/SparkNLP_PowerPoint_Reader_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcU5p2gdak9"
   },
   "source": [
    "# Introducing PowerPoint reader in SparkNLP\n",
    "This notebook showcases the newly added  `sparknlp.read().ppt()` method in Spark NLP that parses Excel content from both local files and both local and distributed file systems into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFOFhaEedalB"
   },
   "source": [
    "## Setup and Initialization\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "Support for reading html files was introduced in Spark NLP 6.0.0. Please make sure you have upgraded to the latest Spark NLP release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYkjwyv7Qyt2"
   },
   "source": [
    "- Let's install and setup Spark NLP in Google Colab\n",
    "- This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oRvzXqEFQyt3"
   },
   "outputs": [],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YoyZLVYQyt4"
   },
   "source": [
    "For local files example we will download a couple of HTML files from Spark NLP Github repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ya8qZe00dalC",
    "outputId": "8c76ad45-1102-4f7e-d18e-35df54b51265"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--2025-03-06 17:00:19--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1103-Adding-support-to-read-PowerPoint-files/src/test/resources/reader/ppt/fake-power-point.pptx',\n",
       " 'Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...',\n",
       " 'Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.',\n",
       " 'HTTP request sent, awaiting response... 200 OK',\n",
       " 'Length: 38412 (38K) [application/octet-stream]',\n",
       " 'Saving to: â€˜power-point-files/fake-power-point.pptxâ€™',\n",
       " '',\n",
       " '',\n",
       " 'fake-power-point.pp   0%[                    ]       0  --.-KB/s               ',\n",
       " 'fake-power-point.pp 100%[===================>]  37.51K  --.-KB/s    in 0.004s  ',\n",
       " '',\n",
       " '2025-03-06 17:00:19 (9.90 MB/s) - â€˜power-point-files/fake-power-point.pptxâ€™ saved [38412/38412]',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir power-point-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/ppt/fake-power-point.pptx -P power-point-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoFI66NAdalE"
   },
   "source": [
    "## Parsing PowerPoint slides from Local Files\n",
    "Use the `ppt()` method to parse Excel content from local directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAkMjJ1vdalE",
    "outputId": "d8391d2f-17b8-495d-bbba-03ef73db3bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "+--------------------+--------------------+\n",
      "|                path|                 ppt|\n",
      "+--------------------+--------------------+\n",
      "|file:/content/pow...|[{Title, Adding a...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "ppt_df = sparknlp.read().ppt(\"./power-point-files\")\n",
    "ppt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWbUgoVQrO8m",
    "outputId": "faf985ce-92a3-4c4f-9827-70ce51081082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- ppt: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- elementType: string (nullable = true)\n",
      " |    |    |-- content: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ppt_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB2FEfegGuxl"
   },
   "source": [
    "You can also use DFS file systems like:\n",
    "- Databricks: `dbfs://`\n",
    "- HDFS: `hdfs://`\n",
    "- Microsoft Fabric OneLake: `abfss://`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9KEkKxERI_U"
   },
   "source": [
    "### Configuration Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLbJsw20ROAO"
   },
   "source": [
    "- `storeContent`: By default, this is set to `false`. When enabled, the output will include the byte content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ARg336ZROUc",
    "outputId": "c26761ad-c3f2-41dd-d334-25c7f73a0726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                path|                 ppt|             content|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|file:/content/pow...|[{Title, Adding a...|[50 4B 03 04 14 0...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\"storeContent\": \"true\"}\n",
    "ppt_df = sparknlp.read(params).ppt(\"./power-point-files\")\n",
    "ppt_df.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
