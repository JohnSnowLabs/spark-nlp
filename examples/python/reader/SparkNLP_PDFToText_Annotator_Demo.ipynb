{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/reader/SparkNLP_PDFToText_Annotator_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcU5p2gdak9"
   },
   "source": [
    "# Introducing PDFToText annotator in SparkNLP\n",
    "This notebook showcases the newly added  `PDFToText` method in Spark NLP that parses PDF content from both local files and distributed file systems into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFOFhaEedalB"
   },
   "source": [
    "## Setup and Initialization\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "Support for reading pdf files was introduced in Spark NLP 6.0.0 Please make sure you have upgraded to the latest Spark NLP release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install and setup Spark NLP in Google Colab. This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For local files example we will download a couple of PDF files from Spark NLP Github repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ya8qZe00dalC",
    "outputId": "a54d8f71-be37-43eb-b7e7-bc4c05848358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-24 21:31:17--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1098-Adding-a-PDF-Reader-to-Spark-NLP/src/test/resources/reader/pdf/pdf-title.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25803 (25K) [application/octet-stream]\n",
      "Saving to: â€˜pdf-files/pdf-title.pdfâ€™\n",
      "\n",
      "pdf-title.pdf       100%[===================>]  25.20K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-02-24 21:31:18 (31.4 MB/s) - â€˜pdf-files/pdf-title.pdfâ€™ saved [25803/25803]\n",
      "\n",
      "--2025-02-24 21:31:18--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1098-Adding-a-PDF-Reader-to-Spark-NLP/src/test/resources/reader/pdf/text_3_pages.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9487 (9.3K) [application/octet-stream]\n",
      "Saving to: â€˜pdf-files/text_3_pages.pdfâ€™\n",
      "\n",
      "text_3_pages.pdf    100%[===================>]   9.26K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-02-24 21:31:18 (45.7 MB/s) - â€˜pdf-files/text_3_pages.pdfâ€™ saved [9487/9487]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir pdf-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/pdf/pdf-title.pdf -P pdf-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/pdf/text_3_pages.pdf -P pdf-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoFI66NAdalE"
   },
   "source": [
    "## Parsing PDFs from Local Files\n",
    "Use the `PdfToText()` annotator to parse Excel content from local directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAkMjJ1vdalE",
    "outputId": "aabe0859-ec33-4830-e052-d3bc3a58f7e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.5.4\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acetAKBOHbif"
   },
   "source": [
    "We need to set the configuraiton below. This setting is primarily included for backward compatibility with older versions of Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6SSkLxHp4Ayq"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.allowUntypedScalaUDF\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HHxmco4D17RB"
   },
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.reader.pdf_to_text import *\n",
    "\n",
    "pdf_to_text = PdfToText().setStoreSplittedPdf(True)\n",
    "test_df = spark.read.format(\"binaryFile\").load(\"./pdf-examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M3peSmKx2Rt-",
    "outputId": "2b6ae1d8-485e-4ed1-a2c0-728b423d46c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+------------------------------+----------------+---------------+--------------------+---------+-------+\n",
      "|                path|    modificationTime|length|PdfToText_d08a2552221b__output|height_dimension|width_dimension|             content|exception|pagenum|\n",
      "+--------------------+--------------------+------+------------------------------+----------------+---------------+--------------------+---------+-------+\n",
      "|file:/content/pdf...|2025-02-24 21:26:...| 25803|          This is a Title \\...|             842|            596|[25 50 44 46 2D 3...|     NULL|      0|\n",
      "|file:/content/pdf...|2025-02-24 21:26:...|  9487|             This is a page.\\n|             841|            595|[25 50 44 46 2D 3...|     NULL|      0|\n",
      "|file:/content/pdf...|2025-02-24 21:26:...|  9487|          This is another p...|             841|            595|[25 50 44 46 2D 3...|     NULL|      1|\n",
      "|file:/content/pdf...|2025-02-24 21:26:...|  9487|           Yet another page.\\n|             841|            595|[25 50 44 46 2D 3...|     NULL|      2|\n",
      "+--------------------+--------------------+------+------------------------------+----------------+---------------+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[pdf_to_text])\n",
    "pipeline_model = pipeline.fit(test_df)\n",
    "pdf_df = pipeline_model.transform(test_df)\n",
    "pdf_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWbUgoVQrO8m",
    "outputId": "e89dc2fd-3051-40ee-d4af-8cddccb60a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- PdfToText_d08a2552221b__output: string (nullable = true)\n",
      " |-- height_dimension: integer (nullable = true)\n",
      " |-- width_dimension: integer (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- exception: string (nullable = true)\n",
      " |-- pagenum: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BB2FEfegGuxl"
   },
   "source": [
    "You can also use DFS file systems like:\n",
    "- Databricks: `dbfs://`\n",
    "- HDFS: `hdfs://`\n",
    "- Microsoft Fabric OneLake: `abfss://`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
