{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/reader/SparkNLP_Extractor_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4a5cfc-53fe-4996-a290-4dedb2ffdbf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tzcU5p2gdak9"
   },
   "source": [
    "# Introducing Extractor in SparkNLP\n",
    "This notebook showcases the newly added  `Extractor()` annotator in Spark NLP enabling seamless extraction of key information (e.g., dates, emails, IP addresses) from various data sources such as `.eml` files. This simplifies data parsing workflows by isolating relevant details automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53dbab4c-5f20-4dc0-aaeb-5a6f7289768e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DczWop6QeE8F",
    "outputId": "3634f091-1da2-4013-bbe8-4abdcef6d0c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Apache Spark version: 3.4.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()\n",
    "print(\"Apache Spark version: {}\".format(spark.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "593ff948-8109-4ea8-a21a-d1ee153150bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RFOFhaEedalB"
   },
   "source": [
    "## Setup and Initialization\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "Support for reading html files was introduced in Spark NLP 6.0.0. Please make sure you have upgraded to the latest Spark NLP release.\n",
    "We simple need to import the cleaners components to use `Extractor` annotator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d27fe1e-e91e-4388-be7d-c6fc7229e8c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "stirVdLP-ASE"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator.cleaners import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ca7bde-fb68-4ea0-855f-6931400b096f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EoFI66NAdalE"
   },
   "source": [
    "## Extracting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49b2c5d2-991b-4e01-a639-7de15f5f1148",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "BjAsd5Gs8drv"
   },
   "source": [
    "Extracting information from eml data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "911c7225-8760-4e98-9878-7782ecf9d972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bAkMjJ1vdalE"
   },
   "outputs": [],
   "source": [
    "eml_data = \"\"\"from ABC.DEF.local ([ba23::58b5:2236:45g2:88h2]) by\n",
    "  \\n ABC.DEF.local2 ([ba23::58b5:2236:45g2:88h2%25]) with mapi id\\\n",
    "  n 32.88.5467.123; Fri, 26 Mar 2021 11:04:09 +1200\"\"\"\n",
    "\n",
    "data_set = spark.createDataFrame([[eml_data]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eef12f80-6a1d-46aa-80d4-1e7c83308af6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DZ3tHeJM_wnD"
   },
   "source": [
    "Extracting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56f1f7b-1aa4-431a-924b-fc2c94a0066c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnxOTj_Uf3a0",
    "outputId": "bfb8bcaa-b9ca-43c7-d8bf-ca1a80808b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|date                                                        |\n",
      "+------------------------------------------------------------+\n",
      "|[{chunk, 136, 166, Fri, 26 Mar 2021 11:04:09 +1200, {}, []}]|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "\n",
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"date\") \\\n",
    "    .setExtractorMode(\"email_date\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(data_set)\n",
    "result = model.transform(data_set)\n",
    "result.select(\"date\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59beb7a2-243f-4888-a610-c785358ab739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dpohooB0_yOa"
   },
   "source": [
    "Extracting email addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c1ac427-2fe9-417b-a811-ee939c6f1c9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "OC_PElzuAKZw"
   },
   "outputs": [],
   "source": [
    "eml_data = [\n",
    "    \"Me me@email.com and You <You@email.com>\\n  ([ba23::58b5:2236:45g2:88h2]) (10.0.2.01)\",\n",
    "    \"Im Rabn <Im.Rabn@npf.gov.nr>\"\n",
    "]\n",
    "\n",
    "data_set = spark.createDataFrame(eml_data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a96a56b-3b96-41a9-a090-278ab22fb2ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ESl4yUL_2WR",
    "outputId": "e40cf1f5-df1b-45b3-c663-ce5fc5d789a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+\n",
      "|email                                                                         |\n",
      "+------------------------------------------------------------------------------+\n",
      "|[{chunk, 3, 14, me@email.com, {}, []}, {chunk, 25, 37, You@email.com, {}, []}]|\n",
      "|[{chunk, 9, 26, Im.Rabn@npf.gov.nr, {}, []}]                                  |\n",
      "+------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"email\") \\\n",
    "    .setExtractorMode(\"email_address\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(data_set)\n",
    "result = model.transform(data_set)\n",
    "result.select(\"email\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74edbb08-3fe5-47d8-9884-c22b1bd1dec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Hqm_ttjEAUaH"
   },
   "source": [
    "Extracting IPv4 and IPv6 addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33d7eaf-d87d-47f9-832d-4ff6aa967210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WB0bI47xAlIr"
   },
   "outputs": [],
   "source": [
    "eml_data = [\n",
    "    \"\"\"from ABC.DEF.local ([ba23::58b5:2236:45g2:88h2]) by\n",
    "    ABC.DEF.local ([68.183.71.12]) with mapi id\n",
    "    32.88.5467.123; Fri, 26 Mar 2021 11:04:09 +1200\"\"\"\n",
    "]\n",
    "\n",
    "data_set = spark.createDataFrame(eml_data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36cf18e8-7395-41be-a08e-d37495842685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YykeYZltAXQX",
    "outputId": "f250f242-098c-4766-e2d7-dfb6bfff08de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------+\n",
      "|ip_address                                                                                 |\n",
      "+-------------------------------------------------------------------------------------------+\n",
      "|[{chunk, 21, 45, ba23::58b5:2236:45g2:88h2, {}, []}, {chunk, 72, 83, 68.183.71.12, {}, []}]|\n",
      "+-------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"ip_address\") \\\n",
    "    .setExtractorMode(\"ip_address\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(data_set)\n",
    "result = model.transform(data_set)\n",
    "result.select(\"ip_address\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dae9271c-5d0f-45da-a2b9-35c7b60db5e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YPeqQL-UA17w"
   },
   "source": [
    "Extracting MAPI IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8463ec7-46d4-4e2d-8cbd-7ff9ba3bb207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "10_a1O9cA4Tk"
   },
   "outputs": [],
   "source": [
    "eml_data = \"\"\"from ABC.DEF.local ([ba23::58b5:2236:45g2:88h2]) by\n",
    "  \\n ABC.DEF.local2 ([ba23::58b5:2236:45g2:88h2%25]) with mapi id\\\n",
    "  n 32.88.5467.123; Fri, 26 Mar 2021 11:04:09 +1200\"\"\"\n",
    "\n",
    "data_set = spark.createDataFrame([[eml_data]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f34e1e39-b8ac-45fe-931a-71de97e6c178",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbOmybPLA_nV",
    "outputId": "bf150f95-88d5-42db-8038-b4a44920cfd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|mapi_id                                    |\n",
      "+-------------------------------------------+\n",
      "|[{chunk, 120, 133, 32.88.5467.123, {}, []}]|\n",
      "+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"mapi_id\") \\\n",
    "    .setExtractorMode(\"mapi_id\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(data_set)\n",
    "result = model.transform(data_set)\n",
    "result.select(\"mapi_id\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c492045-9883-48a9-a452-cf646b55d4bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EV4Wpr_qBFm1"
   },
   "source": [
    "Extracting US phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42356372-2e35-455b-8f88-a7c6f9320584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "UQxqmsFgBTw7"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"215-867-5309\",\n",
    "    \"Phone Number: +1 215.867.5309\",\n",
    "    \"Phone Number: Just Kidding\"\n",
    "]\n",
    "\n",
    "test_df = spark.createDataFrame(data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4570b13f-7195-4720-8f22-e1da4de3e140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AK_kwa4SBHZL",
    "outputId": "ae506a88-6010-40d0-b580-2d73d171e498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|us_phones                                 |\n",
      "+------------------------------------------+\n",
      "|[{chunk, 0, 11, 215-867-5309, {}, []}]    |\n",
      "|[{chunk, 14, 28, +1 215.867.5309, {}, []}]|\n",
      "|[]                                        |\n",
      "+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"us_phones\") \\\n",
    "    .setExtractorMode(\"us_phone_numbers\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"us_phones\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bc9dcf3-70b3-4054-999b-37aea18af833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "w9bBC9ebBgvi"
   },
   "source": [
    "Extracting bullets from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fcdcbe1-bec5-49db-b94a-168ef0f9107b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nDfwOWkEBjv4"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"1. Introduction:\",\n",
    "    \"a. Introduction:\",\n",
    "    \"5.3.1 Convolutional Networks\",\n",
    "    \"D.b.C Recurrent Neural Networks\",\n",
    "    \"2.b.1 Recurrent Neural Networks\",\n",
    "    \"bb.c Feed Forward Neural Networks\",\n",
    "    \"Fig. 2: The relationship\"\n",
    "]\n",
    "\n",
    "test_df = spark.createDataFrame(data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf27f07-e422-4f1d-8c3f-579271096a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaVxWBT-C9eS",
    "outputId": "86c71467-9b54-4acd-985b-af90e6cc075d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------+\n",
      "|bullets                                                                             |\n",
      "+------------------------------------------------------------------------------------+\n",
      "|[{chunk, 0, 2, (1,None,None), {section -> 1}, []}]                                  |\n",
      "|[{chunk, 0, 2, (a,None,None), {section -> a}, []}]                                  |\n",
      "|[{chunk, 0, 5, (5,3,1), {section -> 5, sub_section -> 3, sub_sub_section -> 1}, []}]|\n",
      "|[{chunk, 0, 5, (D,b,C), {section -> D, sub_section -> b, sub_sub_section -> C}, []}]|\n",
      "|[{chunk, 0, 5, (2,b,1), {section -> 2, sub_section -> b, sub_sub_section -> 1}, []}]|\n",
      "|[{chunk, 0, 4, (bb,c,None), {section -> bb, sub_section -> c}, []}]                 |\n",
      "|[{chunk, 0, 0, (None,None,None), {}, []}]                                           |\n",
      "+------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"bullets\") \\\n",
    "    .setExtractorMode(\"bullets\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"bullets\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db36280f-40f6-4d4b-808d-545d2d88f6a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ZJBz2_ZTGL82"
   },
   "source": [
    "Extract image from URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76860b07-7b87-4396-b886-12e0ce4d646e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iGZEspw1GR6Q"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"https://my-image.png with some text\",\n",
    "    \"some text https://my-image.jpg with another http://my-image.bmp\",\n",
    "    \"http://my-path/my%20image.JPG\",\n",
    "    \"\"\"<img src=\"https://example.com/images/photo1.jpg\" />\n",
    "    <img src=\"https://example.org/assets/icon.png\" />\n",
    "    <link href=\"https://example.net/style.css\" />\"\"\"\n",
    "]\n",
    "\n",
    "test_df = spark.createDataFrame(data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48bc7615-869b-4e65-81a3-e5d7efd58371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mm0FrFtBGqBQ",
    "outputId": "4e206112-afe6-4bc1-fd4f-538b3373fb90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|image_urls                                                                                                                     |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{chunk, 0, 19, https://my-image.png, {}, []}]                                                                                 |\n",
      "|[{chunk, 10, 29, https://my-image.jpg, {}, []}, {chunk, 44, 62, http://my-image.bmp, {}, []}]                                  |\n",
      "|[{chunk, 0, 28, http://my-path/my%20image.JPG, {}, []}]                                                                        |\n",
      "|[{chunk, 10, 46, https://example.com/images/photo1.jpg, {}, []}, {chunk, 66, 100, https://example.org/assets/icon.png, {}, []}]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"image_urls\") \\\n",
    "    .setExtractorMode(\"image_urls\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"image_urls\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57717be0-06be-451c-bdde-ca67cad1fab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "UGMZ5puuKzcP"
   },
   "source": [
    "Extract text after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3de7cf0f-0897-4aae-812f-3808a585b2c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "7GuykSrsK04V"
   },
   "outputs": [],
   "source": [
    "data = [\"SPEAKER 1: Look at me, I'm flying!\"]\n",
    "\n",
    "test_df = spark.createDataFrame(data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3fcf79f-c9e1-429c-8f63-60b2d0553dcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yX1no37ALAPO",
    "outputId": "4b6e9f5f-1b0d-4eac-ac07-b794db799565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|text_after                                                  |\n",
      "+------------------------------------------------------------+\n",
      "|[{chunk, 10, 34, Look at me, I'm flying!, {index -> 0}, []}]|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"text_after\") \\\n",
    "    .setExtractorMode(\"text_after\") \\\n",
    "    .setTextPattern(\"SPEAKER \\\\d{1}:\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"text_after\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0045ce9-8a27-4f50-95eb-054f5579ed91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ogDxF5DlLJvT"
   },
   "source": [
    "Extract text before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cc76379-f6a2-4c07-b2ec-86a551395d0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "zPiLiuh1LLC8"
   },
   "outputs": [],
   "source": [
    "data = [\"Here I am! STOP Look at me! STOP I'm flying! STOP\"]\n",
    "\n",
    "test_df = spark.createDataFrame(data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d989d7c7-1891-420d-9b96-f34541b5f50e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBBRy0hZLPz2",
    "outputId": "cef60d80-3985-427a-c4b3-ebb7e54eb9bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|text_before                                   |\n",
      "+----------------------------------------------+\n",
      "|[{chunk, 0, 11, Here I am!, {index -> 0}, []}]|\n",
      "+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"text_before\") \\\n",
    "    .setExtractorMode(\"text_before\") \\\n",
    "    .setTextPattern(\"STOP\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"text_before\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "764fa826-06c1-4309-a5b1-e279d6a5e0a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "SNzyE7rmLgL4"
   },
   "source": [
    "## Custom Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d15170a-3cba-48c2-9728-f03ea388ec60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "OxSYMMORLrsz"
   },
   "source": [
    "As you can see in the output of the example above. We have by default patterns to extract most common data. However, you can also set custom regex patterns to address your specific extraction needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faecf90c-552f-42c8-b1aa-3e50da7e7b6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Be0VrtdjLmAa"
   },
   "outputs": [],
   "source": [
    "eml_data = [\n",
    "    \"\"\"from ABC.DEF.local ([ba23::58b5:2236:45g2:88h2]) by\n",
    "    ABC.DEF.local ([68.183.71.12]) with mapi id\n",
    "    32.88.5467.123; Fri, 26 Mar 2021 11:04:09 +1200\"\"\"\n",
    "]\n",
    "\n",
    "data_set = spark.createDataFrame(eml_data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aa79ac9-c404-4901-a792-b5cb5ff33659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_6Gi_PuvMU5x",
    "outputId": "0318a824-cde1-4404-d2bf-d9859a6a4eb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|ipv4_address                           |\n",
      "+---------------------------------------+\n",
      "|[{chunk, 72, 83, 68.183.71.12, {}, []}]|\n",
      "+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_ipv4_regex = \"(?:25[0-5]|2[0-4]\\\\d|1\\\\d{2}|[1-9]?\\\\d)(?:\\\\.(?:25[0-5]|2[0-4]\\\\d|1\\\\d{2}|[1-9]?\\\\d)){3}\"\n",
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"ipv4_address\") \\\n",
    "    .setExtractorMode(\"ip_address\") \\\n",
    "    .setIpAddressPattern(my_ipv4_regex)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(data_set)\n",
    "result = model.transform(data_set)\n",
    "result.select(\"ipv4_address\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada7ab5b-5773-49cf-bac4-c86668e62343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H05hbWuQOuTA"
   },
   "source": [
    "Index in After and Before text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f83245f5-4070-4a67-8aaf-11571c1e7ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ihzYu3qhfrQ9"
   },
   "source": [
    "The `index` parameter tells the `Extractor` which occurrence of the specified `text pattern` should be used as the reference point for extracting text. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bacb0658-0658-49b6-9811-96d593af27e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "815xRlXsOwfP"
   },
   "outputs": [],
   "source": [
    "data = [\"Teacher: BLAH BLAH BLAH; Student: BLAH BLAH BLAH!\"]\n",
    "\n",
    "test_df = spark.createDataFrame(data, \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fb680b-5ff6-47cb-a0fa-dd0a473e10b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rd0_m1D8O_BY",
    "outputId": "d6295c30-6e96-4c8c-cd5e-1df5d53238a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|text_before                                      |\n",
      "+-------------------------------------------------+\n",
      "|[{chunk, 0, 14, Teacher: BLAH, {index -> 1}, []}]|\n",
      "+-------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"text_before\") \\\n",
    "    .setExtractorMode(\"text_before\") \\\n",
    "    .setTextPattern(\"BLAH\") \\\n",
    "    .setIndex(1)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"text_before\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c489beb3-caaf-44f4-8f66-736ae50fb95e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIwNAetLYUYN",
    "outputId": "6eb8da1e-c0b8-4966-d621-34570d7949b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+\n",
      "|text_before                                |\n",
      "+-------------------------------------------+\n",
      "|[{chunk, 0, 9, Teacher:, {index -> 0}, []}]|\n",
      "+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = Extractor() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"text_before\") \\\n",
    "    .setExtractorMode(\"text_before\") \\\n",
    "    .setTextPattern(\"BLAH\") \\\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    extractor\n",
    "])\n",
    "\n",
    "model = pipeline.fit(test_df)\n",
    "result = model.transform(test_df)\n",
    "result.select(\"text_before\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SparkNLP_Extractor_Demo",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
