{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/SparkNLP_Reader2Image_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quSlGrh2X0Ar"
   },
   "source": [
    "# Introducing Reader2Image in SparkNLP\n",
    "\n",
    "This notebook showcases the newly added `Reader2Image` annotator in Spark NLP. It provides a streamlined and user-friendly interface for reading image files and integrating them with VLM annotators in Spark NLP. The annotator is useful for preprocessing data in NLP pipelines that rely on information contained within images. Currently, it supports HTML and Markdown files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Initialization\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "Support for **Reader2Image** files was introduced in Spark NLP 6.1.3. Please make sure you have upgraded to the latest Spark NLP release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's install and setup Spark NLP in Google Colab. This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvycj4qAObCw",
    "outputId": "1b5e5472-5ed3-45c5-e1df-54e1f3b1c583"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()\n",
    "print(sparknlp.version())\n",
    "\n",
    "print(\"Apache Spark version: {}\".format(spark.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXtXmyJFYfGG"
   },
   "source": [
    "To illustrate the use of this reader, letâ€™s define an HTML document containing image data and display a preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "6ZUkBA7rZ1lp",
    "outputId": "75d845e9-bcc6-4409-e55c-1ef3877a272e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <title>Image Parsing Test</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Test Images</h1>\n",
       "\n",
       "<!-- Base64 inline PNG -->\n",
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUA\n",
       "  AAAFCAYAAACNbyblAAAAHElEQVQI12P4\n",
       "  //8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==\"\n",
       "     alt=\"Base64 Red Dot\" width=\"5\" height=\"5\">\n",
       "\n",
       "<!-- External image -->\n",
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/React-icon.svg/1024px-React-icon.svg.png\"\n",
       "     alt=\"React Logo\" width=\"50\" height=\"50\">\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "html_code = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Image Parsing Test</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>Test Images</h1>\n",
    "\n",
    "<!-- Base64 inline PNG -->\n",
    "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUA\n",
    "  AAAFCAYAAACNbyblAAAAHElEQVQI12P4\n",
    "  //8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==\"\n",
    "     alt=\"Base64 Red Dot\" width=\"5\" height=\"5\">\n",
    "\n",
    "<!-- External image -->\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/React-icon.svg/1024px-React-icon.svg.png\"\n",
    "     alt=\"React Logo\" width=\"50\" height=\"50\">\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KhznNBIYx0m"
   },
   "source": [
    "As you can see in the image above, we have two files: a small red dot and an atom. We expect a VLM model to generate descriptions of these images for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MTnevAlxaXB5"
   },
   "outputs": [],
   "source": [
    "with open(\"example-images.html\", \"w\") as f:\n",
    "    f.write(html_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4JOsiklDVTgd"
   },
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZwclDzKVVX_",
    "outputId": "cbbdabb9-c1bc-472a-b478-41ab8516cda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|                path|             content|           partition|           fileName|               image|\n",
      "+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "|file:/content/exa...|\\n<!DOCTYPE html>...|[{Title, Test Ima...|example-images.html|[{image, example-...|\n",
      "|file:/content/exa...|\\n<!DOCTYPE html>...|[{Title, Test Ima...|example-images.html|[{image, example-...|\n",
      "+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.reader.reader2image import Reader2Image\n",
    "\n",
    "reader2image = Reader2Image() \\\n",
    "    .setContentType(\"text/html\") \\\n",
    "    .setContentPath(\"./example-images.html\") \\\n",
    "    .setOutputCol(\"image\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2image])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "image_df = model.transform(empty_df)\n",
    "image_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDRjLx9gZLVK"
   },
   "source": [
    "For this example, we will use the `Qwen2VLTransformer`. Letâ€™s add a text prompt column for VQA (Vision Question Answering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4tGr69PYVpwS"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "prompt_df = image_df.withColumn(\n",
    "    \"text\",\n",
    "    lit(\n",
    "        \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\"\n",
    "        \"<|im_start|>user\\n<|vision_start|><|image_pad|><|vision_end|>\"\n",
    "        \"Describe this image.<|im_end|>\\n\"\n",
    "        \"<|im_start|>assistant\\n\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7vMR6AHVt_w",
    "outputId": "fb88f19b-2e22-416e-b6de-91e30a351a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|                path|             content|           partition|           fileName|               image|                text|\n",
      "+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|file:/content/exa...|\\n<!DOCTYPE html>...|[{Title, Test Ima...|example-images.html|[{image, example-...|<|im_start|>syste...|\n",
      "|file:/content/exa...|\\n<!DOCTYPE html>...|[{Title, Test Ima...|example-images.html|[{image, example-...|<|im_start|>syste...|\n",
      "+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufF265kuV0-7",
    "outputId": "916d69fb-fcd3-42a5-b23c-ed940df4819f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen2_vl_2b_instruct_int4 download started this may take some time.\n",
      "Approximate size to download 1.4 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import Qwen2VLTransformer\n",
    "\n",
    "visualQAClassifier = (\n",
    "    Qwen2VLTransformer.pretrained()\n",
    "    .setInputCols(\"image\")\n",
    "    .setOutputCol(\"answer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jiAReBePWJtq"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([visualQAClassifier])\n",
    "result_df = pipeline.fit(prompt_df).transform(prompt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XiAw_vbVWqlN",
    "outputId": "c1c84963-90b7-4252-efb4-1d0f61218e26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|origin               |result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[example-images.html]|[The image is a simple, solid-colored background with a gradient effect. The background is composed of of two primary colors: a bright yellow and a slightly darker yellow. The yellow on the left side of the image is brighter and more vivid, while the yellow on the right side is slightly muted and less intense. The gradient effect creates a smooth transition from one color to the other, giving the impression of a gradient background.]                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|[example-images.html]|[The image depicts a stylized representation of an atom. The atom is composed of three main parts: the nucleus, the electron shell, and the atomic nucleus. The nucleus is represented by a central, circular shape, which is the core of the atom. The electron shell is depicted as a series of concentric circles, each representing a different energy level or shell of electrons. The outermost shell is the highest energy level, and the innermost shell is the lowest energy level. The electron shell is typically divided into two subshells, with one subshell containing one electron and the other containing two electrons. which are held together by a single bond.\\n\\nThe background of the image is a solid red color, which contrasts with the pink outline of the atom. The overall design is minimalistic and focuses on the essential components of an atom.]|\n",
      "+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.select(\"image.origin\", \"answer.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnsyx37VZlUm"
   },
   "source": [
    "VoilÃ ! As you can see above, we have accurate descriptions of the images generated by Qwen2VLTransformer."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
