{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzcU5p2gdak9"
   },
   "source": [
    "# Introducing Reader2Doc in SparkNLP\n",
    "This notebook showcases the newly added `Reader2Doc` annotator in Spark NLP\n",
    "providing a streamlined and user-friendly interface for reading files. Useful for preprocessing data for NLP pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DczWop6QeE8F",
    "outputId": "63c45993-626d-4b75-b4d4-57efe43b8a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.5.1\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "# let's start Spark with Spark NLP\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Apache Spark version: {}\".format(spark.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFOFhaEedalB"
   },
   "source": [
    "## Setup and Initialization\n",
    "Let's keep in mind a few things before we start ðŸ˜Š\n",
    "\n",
    "Support for **Reader2Doc** annotator was introduced in Spark NLP 6.1.0. Please make sure you have upgraded to the latest Spark NLP release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vLFuCnVnVd8"
   },
   "source": [
    "- Let's install and setup Spark NLP in Google Colab. This part is pretty easy via our simple script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JVUu3mJXnXmm"
   },
   "outputs": [],
   "source": [
    "! wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QXcOttbnmsI"
   },
   "source": [
    "The output of Reader2Doc uses the same Annotation schema as other Spark NLP annotators. This means you can seamlessly integrate it into any Spark NLP pipeline or process that expects annotated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0WIcptZ7nhp5"
   },
   "outputs": [],
   "source": [
    "from sparknlp.reader.reader2doc import Reader2Doc\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ah8RigOanazZ"
   },
   "source": [
    "For local files example we will download different files from Spark NLP Github repo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3bCFJZn8TS0"
   },
   "source": [
    "## Reading PDF Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZP7vz-gn6Rl"
   },
   "source": [
    "**Downloading PDF files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ya8qZe00dalC",
    "outputId": "7b0ed5d2-aa8a-493f-fe32-ce9b1cf9c581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:50:48--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/pdf/image_3_pages.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15629 (15K) [application/octet-stream]\n",
      "Saving to: â€˜pdf-files/image_3_pages.pdfâ€™\n",
      "\n",
      "image_3_pages.pdf   100%[===================>]  15.26K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-07-20 23:50:49 (13.4 MB/s) - â€˜pdf-files/image_3_pages.pdfâ€™ saved [15629/15629]\n",
      "\n",
      "--2025-07-20 23:50:49--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/pdf/pdf-title.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25803 (25K) [application/octet-stream]\n",
      "Saving to: â€˜pdf-files/pdf-title.pdfâ€™\n",
      "\n",
      "pdf-title.pdf       100%[===================>]  25.20K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2025-07-20 23:50:49 (16.0 MB/s) - â€˜pdf-files/pdf-title.pdfâ€™ saved [25803/25803]\n",
      "\n",
      "--2025-07-20 23:50:49--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/pdf/text_3_pages.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9487 (9.3K) [application/octet-stream]\n",
      "Saving to: â€˜pdf-files/text_3_pages.pdfâ€™\n",
      "\n",
      "text_3_pages.pdf    100%[===================>]   9.26K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:50:49 (60.9 MB/s) - â€˜pdf-files/text_3_pages.pdfâ€™ saved [9487/9487]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir pdf-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/pdf/image_3_pages.pdf -P pdf-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/pdf/pdf-title.pdf -P pdf-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/pdf/text_3_pages.pdf -P pdf-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vz48AHQHyON",
    "outputId": "cf838fd4-fdf7-47c8-c641-2dbbf2e021e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 14...|\n",
      "|[{document, 15, 3...|\n",
      "|[{document, 36, 5...|\n",
      "|[{document, 0, 14...|\n",
      "|[{document, 15, 3...|\n",
      "|[{document, 39, 6...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"application/pdf\") \\\n",
    "    .setContentPath(\"./pdf-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02qrQWIWP89R"
   },
   "source": [
    "## Reading HTML Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joUGu23jq4m4"
   },
   "source": [
    "**Downloading HTML files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bo7s-jZVrE7W",
    "outputId": "01cd6445-85e7-4632-fddc-0276de3d2ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:04--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/html/example-10k.html\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2456707 (2.3M) [text/plain]\n",
      "Saving to: â€˜html-files/example-10k.htmlâ€™\n",
      "\n",
      "\r",
      "example-10k.html      0%[                    ]       0  --.-KB/s               \r",
      "example-10k.html    100%[===================>]   2.34M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-07-20 23:51:04 (43.6 MB/s) - â€˜html-files/example-10k.htmlâ€™ saved [2456707/2456707]\n",
      "\n",
      "--2025-07-20 23:51:04--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/html/fake-html.html\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 665 [text/plain]\n",
      "Saving to: â€˜html-files/fake-html.htmlâ€™\n",
      "\n",
      "fake-html.html      100%[===================>]     665  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:04 (28.5 MB/s) - â€˜html-files/fake-html.htmlâ€™ saved [665/665]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir html-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/html/example-10k.html -P html-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/html/fake-html.html -P html-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg13MEz2NDzE",
    "outputId": "1097dfc0-dd7b-4ac6-e172-c883e10f7bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 12...|\n",
      "|[{document, 13, 4...|\n",
      "|[{document, 47, 6...|\n",
      "|[{document, 69, 7...|\n",
      "|[{document, 78, 1...|\n",
      "|[{document, 164, ...|\n",
      "|[{document, 207, ...|\n",
      "|[{document, 297, ...|\n",
      "|[{document, 330, ...|\n",
      "|[{document, 363, ...|\n",
      "|[{document, 382, ...|\n",
      "|[{document, 447, ...|\n",
      "|[{document, 702, ...|\n",
      "|[{document, 755, ...|\n",
      "|[{document, 862, ...|\n",
      "|[{document, 992, ...|\n",
      "|[{document, 1127,...|\n",
      "|[{document, 1481,...|\n",
      "|[{document, 1796,...|\n",
      "|[{document, 2143,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"text/html\") \\\n",
    "    .setContentPath(\"./html-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMyqJX-K7dss"
   },
   "source": [
    "## Reading MS Office Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpYvufV2qgbB"
   },
   "source": [
    "### Reading Word Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-uW6gV8pUYM"
   },
   "source": [
    "**Downloading Word files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLLEUl3KpYZ6",
    "outputId": "b22f1af6-6bea-4c59-df27-53c829439928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:07--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/doc/contains-pictures.docx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 95087 (93K) [application/octet-stream]\n",
      "Saving to: â€˜word-files/contains-pictures.docxâ€™\n",
      "\n",
      "contains-pictures.d 100%[===================>]  92.86K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2025-07-20 23:51:07 (4.77 MB/s) - â€˜word-files/contains-pictures.docxâ€™ saved [95087/95087]\n",
      "\n",
      "--2025-07-20 23:51:07--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/doc/fake_table.docx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12392 (12K) [application/octet-stream]\n",
      "Saving to: â€˜word-files/fake_table.docxâ€™\n",
      "\n",
      "fake_table.docx     100%[===================>]  12.10K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-07-20 23:51:07 (21.8 MB/s) - â€˜word-files/fake_table.docxâ€™ saved [12392/12392]\n",
      "\n",
      "--2025-07-20 23:51:07--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/doc/page-breaks.docx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14584 (14K) [application/octet-stream]\n",
      "Saving to: â€˜word-files/page-breaks.docxâ€™\n",
      "\n",
      "page-breaks.docx    100%[===================>]  14.24K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-07-20 23:51:08 (14.8 MB/s) - â€˜word-files/page-breaks.docxâ€™ saved [14584/14584]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir word-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/doc/contains-pictures.docx -P word-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/doc/fake_table.docx -P word-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/doc/page-breaks.docx -P word-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YId4UG1rOVQq",
    "outputId": "868114c4-6605-423f-864e-dbf00875225c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 31...|\n",
      "|[{document, 32, 4...|\n",
      "|[{document, 430, ...|\n",
      "|[{document, 504, ...|\n",
      "|[{document, 586, ...|\n",
      "|[{document, 0, 11...|\n",
      "|[{document, 114, ...|\n",
      "|[{document, 263, ...|\n",
      "|[{document, 294, ...|\n",
      "|[{document, 325, ...|\n",
      "|[{document, 354, ...|\n",
      "|[{document, 411, ...|\n",
      "|[{document, 0, 11...|\n",
      "|[{document, 12, 2...|\n",
      "|[{document, 24, 3...|\n",
      "|[{document, 35, 4...|\n",
      "|[{document, 49, 6...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"application/msword\") \\\n",
    "    .setContentPath(\"./word-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8ockED4NxLi"
   },
   "source": [
    "### Reading PowerPoint Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3lF0_7qqlZB"
   },
   "source": [
    "**Downloading PowerPoint files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jDRFmcHqpxn",
    "outputId": "5cd0ee8d-417f-42c5-fff6-e70dcd281468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:11--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/ppt/fake-power-point.pptx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 38412 (38K) [application/octet-stream]\n",
      "Saving to: â€˜ppt-files/fake-power-point.pptxâ€™\n",
      "\n",
      "\r",
      "fake-power-point.pp   0%[                    ]       0  --.-KB/s               \r",
      "fake-power-point.pp 100%[===================>]  37.51K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2025-07-20 23:51:11 (4.88 MB/s) - â€˜ppt-files/fake-power-point.pptxâ€™ saved [38412/38412]\n",
      "\n",
      "--2025-07-20 23:51:11--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/ppt/fake-power-point-table.pptx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39894 (39K) [application/octet-stream]\n",
      "Saving to: â€˜ppt-files/fake-power-point-table.pptxâ€™\n",
      "\n",
      "fake-power-point-ta 100%[===================>]  38.96K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2025-07-20 23:51:11 (4.60 MB/s) - â€˜ppt-files/fake-power-point-table.pptxâ€™ saved [39894/39894]\n",
      "\n",
      "--2025-07-20 23:51:11--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/ppt/speaker-notes.pptx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39414 (38K) [application/octet-stream]\n",
      "Saving to: â€˜ppt-files/speaker-notes.pptxâ€™\n",
      "\n",
      "speaker-notes.pptx  100%[===================>]  38.49K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-07-20 23:51:11 (5.49 MB/s) - â€˜ppt-files/speaker-notes.pptxâ€™ saved [39414/39414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir ppt-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/ppt/fake-power-point.pptx -P ppt-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/ppt/fake-power-point-table.pptx -P ppt-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1259-Implement-Reader2Doc-Annotator/src/test/resources/reader/ppt/speaker-notes.pptx -P ppt-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fPCpk7RTGRjo",
    "outputId": "daeb374c-44c6-42cd-adbf-a42610456a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 20...|\n",
      "|[{document, 21, 5...|\n",
      "|[{document, 51, 8...|\n",
      "|[{document, 89, 1...|\n",
      "|[{document, 144, ...|\n",
      "|[{document, 166, ...|\n",
      "|[{document, 0, 20...|\n",
      "|[{document, 21, 5...|\n",
      "|[{document, 51, 8...|\n",
      "|[{document, 89, 1...|\n",
      "|[{document, 144, ...|\n",
      "|[{document, 166, ...|\n",
      "|[{document, 0, 19...|\n",
      "|[{document, 20, 2...|\n",
      "|[{document, 28, 3...|\n",
      "|[{document, 36, 4...|\n",
      "|[{document, 44, 4...|\n",
      "|[{document, 47, 5...|\n",
      "|[{document, 52, 5...|\n",
      "|[{document, 56, 6...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"application/vnd.ms-powerpoint\") \\\n",
    "    .setContentPath(\"./ppt-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHsnpNNmrWtR"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40ts9-MmqNHp"
   },
   "source": [
    "**Downloading Excel files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3-BCYP6qQ4x",
    "outputId": "11775571-4dd6-47f2-f1f2-b075f13a608c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:15--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/vodafone.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12541 (12K) [application/octet-stream]\n",
      "Saving to: â€˜excel-files/vodafone.xlsxâ€™\n",
      "\n",
      "\r",
      "vodafone.xlsx         0%[                    ]       0  --.-KB/s               \r",
      "vodafone.xlsx       100%[===================>]  12.25K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-07-20 23:51:15 (18.2 MB/s) - â€˜excel-files/vodafone.xlsxâ€™ saved [12541/12541]\n",
      "\n",
      "--2025-07-20 23:51:15--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/2023-half-year-analyses-by-segment.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 38442 (38K) [application/octet-stream]\n",
      "Saving to: â€˜excel-files/2023-half-year-analyses-by-segment.xlsxâ€™\n",
      "\n",
      "2023-half-year-anal 100%[===================>]  37.54K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2025-07-20 23:51:15 (5.15 MB/s) - â€˜excel-files/2023-half-year-analyses-by-segment.xlsxâ€™ saved [38442/38442]\n",
      "\n",
      "--2025-07-20 23:51:15--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/page-break-example.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10676 (10K) [application/octet-stream]\n",
      "Saving to: â€˜excel-files/page-break-example.xlsxâ€™\n",
      "\n",
      "page-break-example. 100%[===================>]  10.43K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:16 (42.5 MB/s) - â€˜excel-files/page-break-example.xlsxâ€™ saved [10676/10676]\n",
      "\n",
      "--2025-07-20 23:51:16--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/xlsx-subtable-cases.xlsx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9210 (9.0K) [application/octet-stream]\n",
      "Saving to: â€˜excel-files/xlsx-subtable-cases.xlsxâ€™\n",
      "\n",
      "xlsx-subtable-cases 100%[===================>]   8.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:16 (73.0 MB/s) - â€˜excel-files/xlsx-subtable-cases.xlsxâ€™ saved [9210/9210]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir excel-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/vodafone.xlsx -P excel-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/2023-half-year-analyses-by-segment.xlsx -P excel-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/page-break-example.xlsx -P excel-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xls/xlsx-subtable-cases.xlsx -P excel-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQ4MpGw6xCko",
    "outputId": "84664ce1-20ff-4237-8f2d-10b75c6b4c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 21...|\n",
      "|[{document, 22, 4...|\n",
      "|[{document, 44, 6...|\n",
      "|[{document, 63, 1...|\n",
      "|[{document, 107, ...|\n",
      "|[{document, 339, ...|\n",
      "|[{document, 395, ...|\n",
      "|[{document, 452, ...|\n",
      "|[{document, 508, ...|\n",
      "|[{document, 566, ...|\n",
      "|[{document, 615, ...|\n",
      "|[{document, 682, ...|\n",
      "|[{document, 734, ...|\n",
      "|[{document, 793, ...|\n",
      "|[{document, 858, ...|\n",
      "|[{document, 949, ...|\n",
      "|[{document, 993, ...|\n",
      "|[{document, 1225,...|\n",
      "|[{document, 1282,...|\n",
      "|[{document, 1339,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"application/vnd.ms-excel\") \\\n",
    "    .setContentPath(\"./excel-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GyL6D4N75i-"
   },
   "source": [
    "## Reading Text Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATDLz3Gws5ob"
   },
   "source": [
    "**Downloading Text files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AV-krG6Ps8pq",
    "outputId": "3d6080b7-ad02-4c2d-930a-1ce36743de74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:19--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/txt/simple-text.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 300 [text/plain]\n",
      "Saving to: â€˜txt-files/simple-text.txtâ€™\n",
      "\n",
      "\r",
      "simple-text.txt       0%[                    ]       0  --.-KB/s               \r",
      "simple-text.txt     100%[===================>]     300  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:19 (11.3 MB/s) - â€˜txt-files/simple-text.txtâ€™ saved [300/300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir txt-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/txt/simple-text.txt -P txt-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mutwZUFj720X",
    "outputId": "0063e1e5-f7d9-481a-a26a-ade5633ad172"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 17...|\n",
      "|[{document, 18, 1...|\n",
      "|[{document, 145, ...|\n",
      "|[{document, 161, ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"text/plain\") \\\n",
    "    .setContentPath(\"./txt-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epCp5DnQ8E7o"
   },
   "source": [
    "## Reading XML Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVq5C0Uqs4wU"
   },
   "source": [
    "**Downloading XML files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gip5P7Ess63U",
    "outputId": "c47de770-fc8d-4e74-bc80-fe4bc4c86b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:20--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xml/multi-level.xml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 538 [text/plain]\n",
      "Saving to: â€˜xml-files/multi-level.xmlâ€™\n",
      "\n",
      "\r",
      "multi-level.xml       0%[                    ]       0  --.-KB/s               \r",
      "multi-level.xml     100%[===================>]     538  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:20 (26.1 MB/s) - â€˜xml-files/multi-level.xmlâ€™ saved [538/538]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir xml-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/xml/multi-level.xml -P xml-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AViMSzKQtP-o",
    "outputId": "b1723d38-dfd8-4090-e135-726ca1cfef4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 12...|\n",
      "|[{document, 13, 2...|\n",
      "|[{document, 25, 2...|\n",
      "|[{document, 29, 5...|\n",
      "|[{document, 52, 6...|\n",
      "|[{document, 67, 7...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"application/xml\") \\\n",
    "    .setContentPath(\"./xml-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qB4uXOFiqO0"
   },
   "source": [
    "## Reading Mardown Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4OpCThUiriY",
    "outputId": "0f2c06cf-2d8f-42eb-97d5-2aafde97899b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:21--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1213-Adding-MarkdownReader/src/test/resources/reader/md/simple.md\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 184 [text/plain]\n",
      "Saving to: â€˜md-files/simple.mdâ€™\n",
      "\n",
      "\r",
      "simple.md             0%[                    ]       0  --.-KB/s               \r",
      "simple.md           100%[===================>]     184  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:21 (2.67 MB/s) - â€˜md-files/simple.mdâ€™ saved [184/184]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir md-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/feature/SPARKNLP-1213-Adding-MarkdownReader/src/test/resources/reader/md/simple.md -P md-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjpuIEatz5yt",
    "outputId": "9e401ac0-0f71-489b-a69d-8a1a66d28458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 11...|\n",
      "|[{document, 12, 7...|\n",
      "|[{document, 80, 8...|\n",
      "|[{document, 88, 1...|\n",
      "|[{document, 102, ...|\n",
      "|[{document, 115, ...|\n",
      "|[{document, 129, ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"text/markdown\") \\\n",
    "    .setContentPath(\"./md-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CuYYlw8tGQO"
   },
   "source": [
    "## Reading Email Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3Fyab6wret-"
   },
   "source": [
    "**Downloading Email files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yYMVpVQurk7G",
    "outputId": "ea24ce84-276d-4085-bc38-0381d5bd470e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-20 23:51:22--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/email/email-text-attachments.eml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3175 (3.1K) [text/plain]\n",
      "Saving to: â€˜email-files/email-text-attachments.emlâ€™\n",
      "\n",
      "\r",
      "          email-tex   0%[                    ]       0  --.-KB/s               \r",
      "email-text-attachme 100%[===================>]   3.10K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-07-20 23:51:22 (35.7 MB/s) - â€˜email-files/email-text-attachments.emlâ€™ saved [3175/3175]\n",
      "\n",
      "--2025-07-20 23:51:22--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/email/test-several-attachments.eml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1324361 (1.3M) [text/plain]\n",
      "Saving to: â€˜email-files/test-several-attachments.emlâ€™\n",
      "\n",
      "test-several-attach 100%[===================>]   1.26M  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-07-20 23:51:23 (27.1 MB/s) - â€˜email-files/test-several-attachments.emlâ€™ saved [1324361/1324361]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir email-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/email/email-text-attachments.eml -P email-files\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/reader/email/test-several-attachments.eml -P email-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gK-Te-BWtIxQ",
    "outputId": "8001ce16-d240-4c8c-e2b2-5bca89348f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 23...|\n",
      "|[{document, 24, 1...|\n",
      "|[{document, 162, ...|\n",
      "|[{document, 1419,...|\n",
      "|[{document, 1431,...|\n",
      "|[{document, 1456,...|\n",
      "|[{document, 0, 21...|\n",
      "|[{document, 22, 7...|\n",
      "|[{document, 74, 1...|\n",
      "|[{document, 1045,...|\n",
      "|[{document, 1057,...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"message/rfc822\") \\\n",
    "    .setContentPath(\"./email-files\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMxLm81mLv_c"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4YGo70IMA9q"
   },
   "source": [
    "We can output one document per row by setting `explodeDocs` to `false`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFdH0OV2L96F",
    "outputId": "32afaed2-dd27-418e-b78f-a11014e0bc6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 23...|\n",
      "|[{document, 0, 21...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"message/rfc822\") \\\n",
    "    .setContentPath(\"./email-files\") \\\n",
    "    .setOutputCol(\"document\") \\\n",
    "    .setExplodeDocs(False)\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDF87g1eM2L0"
   },
   "source": [
    "We can output plain text with minimal metadata by setting `flattentOutput` to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACuEwYIuM74C",
    "outputId": "c4da0a00-9e1a-47f0-e2a9-55ad0df7b57e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            document|\n",
      "+--------------------+\n",
      "|[{document, 0, 12...|\n",
      "|[{document, 13, 4...|\n",
      "|[{document, 47, 6...|\n",
      "|[{document, 69, 7...|\n",
      "|[{document, 78, 1...|\n",
      "|[{document, 164, ...|\n",
      "|[{document, 207, ...|\n",
      "|[{document, 297, ...|\n",
      "|[{document, 330, ...|\n",
      "|[{document, 363, ...|\n",
      "|[{document, 382, ...|\n",
      "|[{document, 447, ...|\n",
      "|[{document, 702, ...|\n",
      "|[{document, 755, ...|\n",
      "|[{document, 862, ...|\n",
      "|[{document, 992, ...|\n",
      "|[{document, 1127,...|\n",
      "|[{document, 1481,...|\n",
      "|[{document, 1796,...|\n",
      "|[{document, 2143,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader2doc = Reader2Doc() \\\n",
    "    .setContentType(\"text/html\") \\\n",
    "    .setContentPath(\"./html-files\") \\\n",
    "    .setOutputCol(\"document\") \\\n",
    "    .setFlattenOutput(True)\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aucJ6Aa9Ne4k"
   },
   "source": [
    "## Pipeline Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NlyM21qNir5"
   },
   "source": [
    "We can integrate with pipelines. For example, with a simple `Tokenizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KXkLK7WWNgS4"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n",
    "\n",
    "regex_tok = RegexTokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"regex_token\")\n",
    "\n",
    "pipeline = Pipeline(stages=[reader2doc, regex_tok])\n",
    "model = pipeline.fit(empty_df)\n",
    "\n",
    "result_df = model.transform(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mc3RPhLROAg8",
    "outputId": "e8d28875-769c-4a6b-cfdc-8820f81d7a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            document|         regex_token|\n",
      "+--------------------+--------------------+\n",
      "|[{document, 0, 12...|[{token, 0, 5, UN...|\n",
      "|[{document, 13, 4...|[{token, 13, 22, ...|\n",
      "|[{document, 47, 6...|[{token, 47, 57, ...|\n",
      "|[{document, 69, 7...|[{token, 69, 72, ...|\n",
      "|[{document, 78, 1...|[{token, 78, 78, ...|\n",
      "|[{document, 164, ...|[{token, 164, 166...|\n",
      "|[{document, 207, ...|[{token, 207, 207...|\n",
      "|[{document, 297, ...|[{token, 297, 299...|\n",
      "|[{document, 330, ...|[{token, 330, 339...|\n",
      "|[{document, 363, ...|[{token, 363, 368...|\n",
      "|[{document, 382, ...|[{token, 382, 387...|\n",
      "|[{document, 447, ...|[{token, 447, 452...|\n",
      "|[{document, 702, ...|[{token, 702, 711...|\n",
      "|[{document, 755, ...|[{token, 755, 759...|\n",
      "|[{document, 862, ...|[{token, 862, 869...|\n",
      "|[{document, 992, ...|[{token, 992, 999...|\n",
      "|[{document, 1127,...|[{token, 1127, 11...|\n",
      "|[{document, 1481,...|[{token, 1481, 14...|\n",
      "|[{document, 1796,...|[{token, 1796, 18...|\n",
      "|[{document, 2143,...|[{token, 2143, 21...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
