<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-03-14T19:57:02+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">English asr_Malaya_speech_fine_tune_realcase_27_Jun TFWav2Vec2ForCTC from RuiqianLi</title><link href="/2023/03/14/asr_Malaya_speech_fine_tune_realcase_27_Jun_en.html" rel="alternate" type="text/html" title="English asr_Malaya_speech_fine_tune_realcase_27_Jun TFWav2Vec2ForCTC from RuiqianLi" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Malaya_speech_fine_tune_realcase_27_Jun_en</id><content type="html" xml:base="/2023/03/14/asr_Malaya_speech_fine_tune_realcase_27_Jun_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Malaya_speech_fine_tune_realcase_27_Jun` is a English model originally trained by RuiqianLi.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Malaya_speech_fine_tune_realcase_27_Jun_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Malaya_speech_fine_tune_realcase_27_Jun_en_4.4.0_3.0_1678793941796.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Malaya_speech_fine_tune_realcase_27_Jun_en_4.4.0_3.0_1678793941796.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_27_Jun&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_27_Jun&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Malaya_speech_fine_tune_realcase_27_Jun|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Malaya_speech_fine_tune_realcase_27_Jun is a English model originally trained by RuiqianLi. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Malaya_speech_fine_tune_realcase_27_Jun_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_27_Jun&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_27_Jun&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Malaya_speech_fine_tune_realcase_27_Jun Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">English asr_Malaya_speech_fine_tune_realcase_30_Jun_lm TFWav2Vec2ForCTC from RuiqianLi</title><link href="/2023/03/14/asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_en.html" rel="alternate" type="text/html" title="English asr_Malaya_speech_fine_tune_realcase_30_Jun_lm TFWav2Vec2ForCTC from RuiqianLi" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_en</id><content type="html" xml:base="/2023/03/14/asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Malaya_speech_fine_tune_realcase_30_Jun_lm` is a English model originally trained by RuiqianLi.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_en_4.4.0_3.0_1678799134721.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_en_4.4.0_3.0_1678799134721.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_30_Jun_lm&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_30_Jun_lm&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Malaya_speech_fine_tune_realcase_30_Jun_lm|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Malaya_speech_fine_tune_realcase_30_Jun_lm is a English model originally trained by RuiqianLi. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Malaya_speech_fine_tune_realcase_30_Jun_lm_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_30_Jun_lm&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Malaya_speech_fine_tune_realcase_30_Jun_lm&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Malaya_speech_fine_tune_realcase_30_Jun_lm Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">English asr_Mandarin_char TFWav2Vec2ForCTC from GleamEyeBeast</title><link href="/2023/03/14/asr_Mandarin_char_en.html" rel="alternate" type="text/html" title="English asr_Mandarin_char TFWav2Vec2ForCTC from GleamEyeBeast" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Mandarin_char_en</id><content type="html" xml:base="/2023/03/14/asr_Mandarin_char_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Mandarin_char` is a English model originally trained by GleamEyeBeast.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Mandarin_char_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Mandarin_char_en_4.4.0_3.0_1678814822299.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Mandarin_char_en_4.4.0_3.0_1678814822299.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Mandarin_char&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Mandarin_char&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Mandarin_char|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Mandarin_char is a English model originally trained by GleamEyeBeast. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Mandarin_char_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Mandarin_char&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Mandarin_char&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Mandarin_char Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">English asr_Mandarin_naive TFWav2Vec2ForCTC from GleamEyeBeast</title><link href="/2023/03/14/asr_Mandarin_naive_en.html" rel="alternate" type="text/html" title="English asr_Mandarin_naive TFWav2Vec2ForCTC from GleamEyeBeast" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Mandarin_naive_en</id><content type="html" xml:base="/2023/03/14/asr_Mandarin_naive_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Mandarin_naive` is a English model originally trained by GleamEyeBeast.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Mandarin_naive_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Mandarin_naive_en_4.4.0_3.0_1678816937348.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Mandarin_naive_en_4.4.0_3.0_1678816937348.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Mandarin_naive&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Mandarin_naive&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Mandarin_naive|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Mandarin_naive is a English model originally trained by GleamEyeBeast. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Mandarin_naive_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Mandarin_naive&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Mandarin_naive&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Mandarin_naive Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">English asr_Wav2Vec2_XLSR_Bengali_1b TFWav2Vec2ForCTC from LegolasTheElf</title><link href="/2023/03/14/asr_Wav2Vec2_XLSR_Bengali_1b_en.html" rel="alternate" type="text/html" title="English asr_Wav2Vec2_XLSR_Bengali_1b TFWav2Vec2ForCTC from LegolasTheElf" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Wav2Vec2_XLSR_Bengali_1b_en</id><content type="html" xml:base="/2023/03/14/asr_Wav2Vec2_XLSR_Bengali_1b_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Wav2Vec2_XLSR_Bengali_1b` is a English model originally trained by LegolasTheElf.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Wav2Vec2_XLSR_Bengali_1b_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Wav2Vec2_XLSR_Bengali_1b_en_4.4.0_3.0_1678787741774.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Wav2Vec2_XLSR_Bengali_1b_en_4.4.0_3.0_1678787741774.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_1b&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_1b&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Wav2Vec2_XLSR_Bengali_1b|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|3.6 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Wav2Vec2_XLSR_Bengali_1b is a English model originally trained by LegolasTheElf. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Wav2Vec2_XLSR_Bengali_1b_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_1b&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_1b&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Wav2Vec2_XLSR_Bengali_1b Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 3.6 GB</summary></entry><entry><title type="html">English asr_Wav2Vec2_XLSR_Bengali_V3 TFWav2Vec2ForCTC from LegolasTheElf</title><link href="/2023/03/14/asr_Wav2Vec2_XLSR_Bengali_V3_en.html" rel="alternate" type="text/html" title="English asr_Wav2Vec2_XLSR_Bengali_V3 TFWav2Vec2ForCTC from LegolasTheElf" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Wav2Vec2_XLSR_Bengali_V3_en</id><content type="html" xml:base="/2023/03/14/asr_Wav2Vec2_XLSR_Bengali_V3_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Wav2Vec2_XLSR_Bengali_V3` is a English model originally trained by LegolasTheElf.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Wav2Vec2_XLSR_Bengali_V3_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Wav2Vec2_XLSR_Bengali_V3_en_4.4.0_3.0_1678820951571.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Wav2Vec2_XLSR_Bengali_V3_en_4.4.0_3.0_1678820951571.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_V3&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_V3&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Wav2Vec2_XLSR_Bengali_V3|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Wav2Vec2_XLSR_Bengali_V3 is a English model originally trained by LegolasTheElf. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Wav2Vec2_XLSR_Bengali_V3_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_V3&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Wav2Vec2_XLSR_Bengali_V3&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Wav2Vec2_XLSR_Bengali_V3 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">Hindi asr_Wav2Vec2_large_xlsr_hindi TFWav2Vec2ForCTC from theainerd</title><link href="/2023/03/14/asr_Wav2Vec2_large_xlsr_hindi_hi.html" rel="alternate" type="text/html" title="Hindi asr_Wav2Vec2_large_xlsr_hindi TFWav2Vec2ForCTC from theainerd" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_Wav2Vec2_large_xlsr_hindi_hi</id><content type="html" xml:base="/2023/03/14/asr_Wav2Vec2_large_xlsr_hindi_hi.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_Wav2Vec2_large_xlsr_hindi` is a Hindi model originally trained by theainerd.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Wav2Vec2_large_xlsr_hindi_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_Wav2Vec2_large_xlsr_hindi_hi_4.4.0_3.0_1678822131874.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_Wav2Vec2_large_xlsr_hindi_hi_4.4.0_3.0_1678822131874.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_Wav2Vec2_large_xlsr_hindi&quot;, &quot;hi&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_Wav2Vec2_large_xlsr_hindi&quot;, &quot;hi&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_Wav2Vec2_large_xlsr_hindi|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|hi|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="hi" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_Wav2Vec2_large_xlsr_hindi is a Hindi model originally trained by theainerd. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_Wav2Vec2_large_xlsr_hindi_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_Wav2Vec2_large_xlsr_hindi&quot;, &quot;hi&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_Wav2Vec2_large_xlsr_hindi&quot;, &quot;hi&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_Wav2Vec2_large_xlsr_hindi Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: hi Size: 1.2 GB</summary></entry><entry><title type="html">English asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1 TFWav2Vec2ForCTC from gary109</title><link href="/2023/03/14/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_en.html" rel="alternate" type="text/html" title="English asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1 TFWav2Vec2ForCTC from gary109" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_en</id><content type="html" xml:base="/2023/03/14/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1` is a English model originally trained by gary109.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_en_4.4.0_3.0_1678796697997.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_en_4.4.0_3.0_1678796697997.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1 is a English model originally trained by gary109. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_5gram_v4_1 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">English asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2 TFWav2Vec2ForCTC from gary109</title><link href="/2023/03/14/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_en.html" rel="alternate" type="text/html" title="English asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2 TFWav2Vec2ForCTC from gary109" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_en</id><content type="html" xml:base="/2023/03/14/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_en.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2` is a English model originally trained by gary109.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_en_4.4.0_3.0_1678795495611.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_en_4.4.0_3.0_1678795495611.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2&quot;, &quot;en&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="en" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2 is a English model originally trained by gary109. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_ai_light_dance_singing2_wav2vec2_large_xlsr_53_v2 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">Castilian, Spanish asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211 TFWav2Vec2ForCTC from jonatasgrosman</title><link href="/2023/03/14/asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_es.html" rel="alternate" type="text/html" title="Castilian, Spanish asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211 TFWav2Vec2ForCTC from jonatasgrosman" /><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>/2023/03/14/asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_es</id><content type="html" xml:base="/2023/03/14/asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_es.html">## Description

Pretrained Wav2vec2  model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211` is a Castilian, Spanish model originally trained by jonatasgrosman.

NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_gpu

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_es_4.4.0_3.0_1678819788313.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_es_4.4.0_3.0_1678819788313.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

audio_assembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = Wav2Vec2ForCTC \
    .pretrained(&quot;asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211&quot;, &quot;es&quot;)\
    .setInputCols(&quot;audio_assembler&quot;) \
    .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = Wav2Vec2ForCTC
    .pretrained(&quot;asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211&quot;, &quot;es&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|es|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="wav2vec2" /><category term="es" /><category term="audio" /><category term="open_source" /><category term="asr" /><category term="tensorflow" /><summary type="html">Description Pretrained Wav2vec2 model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211 is a Castilian, Spanish model originally trained by jonatasgrosman. NOTE: This model only works on a CPU, if you need to use this model on a GPU device please use asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211_gpu Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = Wav2Vec2ForCTC \ .pretrained(&quot;asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211&quot;, &quot;es&quot;)\ .setInputCols(&quot;audio_assembler&quot;) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = Wav2Vec2ForCTC .pretrained(&quot;asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211&quot;, &quot;es&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_exp_w2v2r_vp_100k_accent_surpeninsular_0_nortepeninsular_10_s211 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: es Size: 1.2 GB</summary></entry></feed>