<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-03-19T09:07:16+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">English distil_asr_whisper_large_v2 WhisperForCTC from distil-whisper</title><link href="/2024/02/26/distil_asr_whisper_large_v2_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_large_v2 WhisperForCTC from distil-whisper" /><published>2024-02-26T00:00:00+00:00</published><updated>2024-02-26T00:00:00+00:00</updated><id>/2024/02/26/distil_asr_whisper_large_v2_en</id><content type="html" xml:base="/2024/02/26/distil_asr_whisper_large_v2_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_large_v2 is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_large_v2_en_5.2.4_3.4_1708969018025.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_large_v2_en_5.2.4_3.4_1708969018025.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)


speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)
val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_large_v2|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|2.4 GB|

## References

https://huggingface.co/distil-whisper/distil-large-v2</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_large_v2 is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_large_v2 Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 2.4 GB References https://huggingface.co/distil-whisper/distil-large-v2</summary></entry><entry><title type="html">English distil_asr_whisper_mediumWhisperForCTC from distil-whisper</title><link href="/2024/02/25/distil_asr_whisper_medium_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_mediumWhisperForCTC from distil-whisper" /><published>2024-02-25T00:00:00+00:00</published><updated>2024-02-25T00:00:00+00:00</updated><id>/2024/02/25/distil_asr_whisper_medium_en</id><content type="html" xml:base="/2024/02/25/distil_asr_whisper_medium_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_medium is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_medium_en_5.2.4_3.4_1708901703317.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_medium_en_5.2.4_3.4_1708901703317.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)


speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)
val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_medium|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.4 GB|

## References

https://huggingface.co/distil-whisper/distil-medium.en</content><author><name>John Snow Labs</name></author><category term="whisper" /><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_medium is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_medium Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.4 GB References https://huggingface.co/distil-whisper/distil-medium.en</summary></entry><entry><title type="html">English distil_asr_whisper_small WhisperForCTC from distil-whisper</title><link href="/2024/02/16/distil_asr_whisper_small_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_small WhisperForCTC from distil-whisper" /><published>2024-02-16T00:00:00+00:00</published><updated>2024-02-16T00:00:00+00:00</updated><id>/2024/02/16/distil_asr_whisper_small_en</id><content type="html" xml:base="/2024/02/16/distil_asr_whisper_small_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_small is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_small_en_5.2.4_3.0_1708118638184.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_small_en_5.2.4_3.0_1708118638184.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)
    
    
speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_small|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|748.5 MB|

## References

https://huggingface.co/distil-whisper/distil-small.en</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_small is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_small Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 748.5 MB References https://huggingface.co/distil-whisper/distil-small.en</summary></entry><entry><title type="html">Multilingual bge_m3 XlmRoBertaSentenceEmbeddings from BAII</title><link href="/2024/02/11/bge_m3_xx.html" rel="alternate" type="text/html" title="Multilingual bge_m3 XlmRoBertaSentenceEmbeddings from BAII" /><published>2024-02-11T00:00:00+00:00</published><updated>2024-02-11T00:00:00+00:00</updated><id>/2024/02/11/bge_m3_xx</id><content type="html" xml:base="/2024/02/11/bge_m3_xx.html">## Description

Pretrained XlmRoBertaSentenceEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bge_m3 is a Multilingual model originally trained by BAII.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bge_m3_xx_5.2.3_3.4_1707668886363.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bge_m3_xx_5.2.3_3.4_1707668886363.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;documents&quot;)
    
sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ 
    .setInputCols([&quot;document&quot;])\ 
    .setOutputCol(&quot;sentence&quot;)
    
embeddings =XlmRoBertaSentenceEmbeddings.pretrained(&quot;bge_m3 &quot;,&quot;xx&quot;) \
            .setInputCols([&quot;sentence&quot;]) \
            .setOutputCol(&quot;embeddings&quot;)

pipeline = Pipeline().setStages([document_assembler, sentencerDL, embeddings])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;documents&quot;)
    
val sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)
    .setInputCols([&quot;document&quot;])
    .setOutputCol(&quot;sentence&quot;)
    
val embeddings = XlmRoBertaSentenceEmbeddings 
    .pretrained(&quot;bge_m3 &quot;, &quot;xx&quot;)
    .setInputCols(Array(&quot;sentence&quot;)) 
    .setOutputCol(&quot;embeddings&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, sentencerDL, embeddings))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bge_m3|
|Compatibility:|Spark NLP 5.2.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence]|
|Output Labels:|[sentence_embeddings]|
|Language:|xx|
|Size:|410.8 MB|
|Max sentence length:|32|

## References

https://huggingface.co/BAAI/bge-m3</content><author><name>John Snow Labs</name></author><category term="xx" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained XlmRoBertaSentenceEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bge_m3 is a Multilingual model originally trained by BAII. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;documents&quot;) sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) embeddings =XlmRoBertaSentenceEmbeddings.pretrained(&quot;bge_m3 &quot;,&quot;xx&quot;) \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;embeddings&quot;) pipeline = Pipeline().setStages([document_assembler, sentencerDL, embeddings]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val embeddings = XlmRoBertaSentenceEmbeddings .pretrained(&quot;bge_m3 &quot;, &quot;xx&quot;) .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentencerDL, embeddings)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bge_m3 Compatibility: Spark NLP 5.2.3+ License: Open Source Edition: Official Input Labels: [sentence] Output Labels: [sentence_embeddings] Language: xx Size: 410.8 MB Max sentence length: 32 References https://huggingface.co/BAAI/bge-m3</summary></entry><entry><title type="html">BERT Zero-Shot Classification Base - MNLI (bert_zero_shot_classifier_mnli)</title><link href="/2024/02/01/bert_zero_shot_classifier_mnli_xx.html" rel="alternate" type="text/html" title="BERT Zero-Shot Classification Base - MNLI (bert_zero_shot_classifier_mnli)" /><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-01T00:00:00+00:00</updated><id>/2024/02/01/bert_zero_shot_classifier_mnli_xx</id><content type="html" xml:base="/2024/02/01/bert_zero_shot_classifier_mnli_xx.html">## Description

This model is intended to be used for zero-shot text classification. It is fine-tuned on MNLI.

BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models donâ€™t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means itâ€™s slower but it is much more flexible.

We used TFBertForSequenceClassification to train this model and used BertForZeroShotClassification annotator in Spark NLP ðŸš€ for prediction at scale!

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_zero_shot_classifier_mnli_xx_5.2.4_3.4_1706784558791.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_zero_shot_classifier_mnli_xx_5.2.4_3.4_1706784558791.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler() \
.setInputCol('text') \
.setOutputCol('document')

tokenizer = Tokenizer() \
.setInputCols(['document']) \
.setOutputCol('token')

zeroShotClassifier = BertForZeroShotClassification \
.pretrained('bert_zero_shot_classifier_mnli', 'xx') \
.setInputCols(['token', 'document']) \
.setOutputCol('class') \
.setCaseSensitive(True) \
.setMaxSentenceLength(512) \
.setCandidateLabels([&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;])

pipeline = Pipeline(stages=[
document_assembler,
tokenizer,
zeroShotClassifier
])

example = spark.createDataFrame([['I have a problem with my iphone that needs to be resolved asap!!']]).toDF(&quot;text&quot;)
result = pipeline.fit(example).transform(example)
```
```scala
val document_assembler = DocumentAssembler()
.setInputCol(&quot;text&quot;)
.setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer()
.setInputCols(&quot;document&quot;)
.setOutputCol(&quot;token&quot;)

val zeroShotClassifier = BertForSequenceClassification.pretrained(&quot;bert_zero_shot_classifier_mnli&quot;, &quot;xx&quot;)
.setInputCols(&quot;document&quot;, &quot;token&quot;)
.setOutputCol(&quot;class&quot;)
.setCaseSensitive(true)
.setMaxSentenceLength(512)
.setCandidateLabels(Array(&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;))

val pipeline = new Pipeline().setStages(Array(document_assembler, tokenizer, zeroShotClassifier))

val example = Seq(&quot;I have a problem with my iphone that needs to be resolved asap!!&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(example).transform(example)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_zero_shot_classifier_mnli|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[token, document]|
|Output Labels:|[label]|
|Language:|xx|
|Size:|409.1 MB|
|Case sensitive:|true|</content><author><name>John Snow Labs</name></author><category term="xx" /><category term="open_source" /><category term="onnx" /><summary type="html">Description This model is intended to be used for zero-shot text classification. It is fine-tuned on MNLI. BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models donâ€™t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means itâ€™s slower but it is much more flexible. We used TFBertForSequenceClassification to train this model and used BertForZeroShotClassification annotator in Spark NLP ðŸš€ for prediction at scale! Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') zeroShotClassifier = BertForZeroShotClassification \ .pretrained('bert_zero_shot_classifier_mnli', 'xx') \ .setInputCols(['token', 'document']) \ .setOutputCol('class') \ .setCaseSensitive(True) \ .setMaxSentenceLength(512) \ .setCandidateLabels([&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;]) pipeline = Pipeline(stages=[ document_assembler, tokenizer, zeroShotClassifier ]) example = spark.createDataFrame([['I have a problem with my iphone that needs to be resolved asap!!']]).toDF(&quot;text&quot;) result = pipeline.fit(example).transform(example) val document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val zeroShotClassifier = BertForSequenceClassification.pretrained(&quot;bert_zero_shot_classifier_mnli&quot;, &quot;xx&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;class&quot;) .setCaseSensitive(true) .setMaxSentenceLength(512) .setCandidateLabels(Array(&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;)) val pipeline = new Pipeline().setStages(Array(document_assembler, tokenizer, zeroShotClassifier)) val example = Seq(&quot;I have a problem with my iphone that needs to be resolved asap!!&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(example).transform(example) Model Information Model Name: bert_zero_shot_classifier_mnli Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [token, document] Output Labels: [label] Language: xx Size: 409.1 MB Case sensitive: true</summary></entry><entry><title type="html">English 10_epochs_camembert_jb CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/10_epochs_camembert_jb_en.html" rel="alternate" type="text/html" title="English 10_epochs_camembert_jb CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/10_epochs_camembert_jb_en</id><content type="html" xml:base="/2024/01/21/10_epochs_camembert_jb_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`10_epochs_camembert_jb` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/10_epochs_camembert_jb_en_5.2.4_3.0_1705836801086.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/10_epochs_camembert_jb_en_5.2.4_3.0_1705836801086.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;10_epochs_camembert_jb&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;10_epochs_camembert_jb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|10_epochs_camembert_jb|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|412.1 MB|

## References

https://huggingface.co/bjubert/10_epochs_camembert_jb</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.10_epochs_camembert_jb is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;10_epochs_camembert_jb&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;10_epochs_camembert_jb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 10_epochs_camembert_jb Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 412.1 MB References https://huggingface.co/bjubert/10_epochs_camembert_jb</summary></entry><entry><title type="html">English 6_epochs_camembert CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/6_epochs_camembert_en.html" rel="alternate" type="text/html" title="English 6_epochs_camembert CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/6_epochs_camembert_en</id><content type="html" xml:base="/2024/01/21/6_epochs_camembert_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`6_epochs_camembert` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_en_5.2.4_3.0_1705836837867.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_en_5.2.4_3.0_1705836837867.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;6_epochs_camembert&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|6_epochs_camembert|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|412.2 MB|

## References

https://huggingface.co/bjubert/6_epochs_camembert</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.6_epochs_camembert is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;6_epochs_camembert&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 6_epochs_camembert Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 412.2 MB References https://huggingface.co/bjubert/6_epochs_camembert</summary></entry><entry><title type="html">English 6_epochs_camembert_jb CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/6_epochs_camembert_jb_en.html" rel="alternate" type="text/html" title="English 6_epochs_camembert_jb CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/6_epochs_camembert_jb_en</id><content type="html" xml:base="/2024/01/21/6_epochs_camembert_jb_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`6_epochs_camembert_jb` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_jb_en_5.2.4_3.0_1705838100373.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_jb_en_5.2.4_3.0_1705838100373.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert_jb&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;6_epochs_camembert_jb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|6_epochs_camembert_jb|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|411.9 MB|

## References

https://huggingface.co/bjubert/6_epochs_camembert_jb</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.6_epochs_camembert_jb is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert_jb&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;6_epochs_camembert_jb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 6_epochs_camembert_jb Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 411.9 MB References https://huggingface.co/bjubert/6_epochs_camembert_jb</summary></entry><entry><title type="html">French 8bit_distilcamembert_base_ner CamemBertForTokenClassification from konverner</title><link href="/2024/01/21/8bit_distilcamembert_base_ner_fr.html" rel="alternate" type="text/html" title="French 8bit_distilcamembert_base_ner CamemBertForTokenClassification from konverner" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/8bit_distilcamembert_base_ner_fr</id><content type="html" xml:base="/2024/01/21/8bit_distilcamembert_base_ner_fr.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`8bit_distilcamembert_base_ner` is a French model originally trained by konverner.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/8bit_distilcamembert_base_ner_fr_5.2.4_3.0_1705834120473.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/8bit_distilcamembert_base_ner_fr_5.2.4_3.0_1705834120473.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;8bit_distilcamembert_base_ner&quot;,&quot;fr&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;8bit_distilcamembert_base_ner&quot;, &quot;fr&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|8bit_distilcamembert_base_ner|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|fr|
|Size:|252.5 MB|

## References

https://huggingface.co/konverner/8bit-distilcamembert-base-ner</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="fr" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.8bit_distilcamembert_base_ner is a French model originally trained by konverner. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;8bit_distilcamembert_base_ner&quot;,&quot;fr&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;8bit_distilcamembert_base_ner&quot;, &quot;fr&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 8bit_distilcamembert_base_ner Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: fr Size: 252.5 MB References https://huggingface.co/konverner/8bit-distilcamembert-base-ner</summary></entry><entry><title type="html">English argument_wangchanberta2 CamemBertForTokenClassification from pitiwat</title><link href="/2024/01/21/argument_wangchanberta2_en.html" rel="alternate" type="text/html" title="English argument_wangchanberta2 CamemBertForTokenClassification from pitiwat" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/argument_wangchanberta2_en</id><content type="html" xml:base="/2024/01/21/argument_wangchanberta2_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`argument_wangchanberta2` is a English model originally trained by pitiwat.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/argument_wangchanberta2_en_5.2.4_3.0_1705835802208.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/argument_wangchanberta2_en_5.2.4_3.0_1705835802208.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;argument_wangchanberta2&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;argument_wangchanberta2&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|argument_wangchanberta2|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|392.1 MB|

## References

https://huggingface.co/pitiwat/argument_wangchanberta2</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.argument_wangchanberta2 is a English model originally trained by pitiwat. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;argument_wangchanberta2&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;argument_wangchanberta2&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: argument_wangchanberta2 Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 392.1 MB References https://huggingface.co/pitiwat/argument_wangchanberta2</summary></entry></feed>