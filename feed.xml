<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-05-24T08:30:05+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">UAE-Large-V1 for Sentence Embeddings</title><link href="/2024/04/05/uae_large_v1_en.html" rel="alternate" type="text/html" title="UAE-Large-V1 for Sentence Embeddings" /><published>2024-04-05T00:00:00+00:00</published><updated>2024-04-05T00:00:00+00:00</updated><id>/2024/04/05/uae_large_v1_en</id><content type="html" xml:base="/2024/04/05/uae_large_v1_en.html">## Description

UAE is a novel angle-optimized text embedding model, designed to improve semantic textual
similarity tasks, which are crucial for Large Language Model (LLM) applications. By
introducing angle optimization in a complex space, AnglE effectively mitigates saturation of
the cosine similarity function.

This model is based on UAE-Large-V1 and was orignally exported from https://huggingface.co/WhereIsAI/UAE-Large-V1. Several embedding pooling strategies can be set. Please refer to the class for more information.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/uae_large_v1_en_5.3.3_3.0_1712335736995.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/uae_large_v1_en_5.3.3_3.0_1712335736995.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline
documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
embeddings = UAEEmbeddings.pretrained() \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)
embeddingsFinisher = EmbeddingsFinisher() \
    .setInputCols(&quot;embeddings&quot;) \
    .setOutputCols(&quot;finished_embeddings&quot;) \
    .setOutputAsVector(True)
pipeline = Pipeline().setStages([
    documentAssembler,
    embeddings,
    embeddingsFinisher
])
data = spark.createDataFrame([[&quot;hello world&quot;, &quot;hello moon&quot;]]).toDF(&quot;text&quot;)
result = pipeline.fit(data).transform(data)
result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)
```
```scala
import spark.implicits._
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.annotators.Tokenizer
import com.johnsnowlabs.nlp.embeddings.UAEEmbeddings
import com.johnsnowlabs.nlp.EmbeddingsFinisher
import org.apache.spark.ml.Pipeline
val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)
val embeddings = UAEEmbeddings.pretrained()
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;UAE_embeddings&quot;)
val embeddingsFinisher = new EmbeddingsFinisher()
  .setInputCols(&quot;UAE_embeddings&quot;)
  .setOutputCols(&quot;finished_embeddings&quot;)
  .setOutputAsVector(true)
val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  embeddings,
  embeddingsFinisher
))
val data = Seq(&quot;hello world&quot;, &quot;hello moon&quot;).toDF(&quot;text&quot;)
val result = pipeline.fit(data).transform(data)
result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)
```
&lt;/div&gt;

## Results

```bash
+--------------------------------------------------------------------------------+
|                                                                          result|
+--------------------------------------------------------------------------------+
|[0.50387806, 0.5861606, 0.35129607, -0.76046336, -0.32446072, -0.117674336, 0...|
|[0.6660665, 0.961762, 0.24854276, -0.1018044, -0.6569202, 0.027635604, 0.1915...|
+--------------------------------------------------------------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|uae_large_v1|
|Compatibility:|Spark NLP 5.3.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[embeddings]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="uae" /><category term="en" /><category term="sentence" /><category term="embeddings" /><category term="open_source" /><category term="onnx" /><summary type="html">Description UAE is a novel angle-optimized text embedding model, designed to improve semantic textual similarity tasks, which are crucial for Large Language Model (LLM) applications. By introducing angle optimization in a complex space, AnglE effectively mitigates saturation of the cosine similarity function. This model is based on UAE-Large-V1 and was orignally exported from https://huggingface.co/WhereIsAI/UAE-Large-V1. Several embedding pooling strategies can be set. Please refer to the class for more information. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) embeddings = UAEEmbeddings.pretrained() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;embeddings&quot;) embeddingsFinisher = EmbeddingsFinisher() \ .setInputCols(&quot;embeddings&quot;) \ .setOutputCols(&quot;finished_embeddings&quot;) \ .setOutputAsVector(True) pipeline = Pipeline().setStages([ documentAssembler, embeddings, embeddingsFinisher ]) data = spark.createDataFrame([[&quot;hello world&quot;, &quot;hello moon&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80) import spark.implicits._ import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.Tokenizer import com.johnsnowlabs.nlp.embeddings.UAEEmbeddings import com.johnsnowlabs.nlp.EmbeddingsFinisher import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val embeddings = UAEEmbeddings.pretrained() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;UAE_embeddings&quot;) val embeddingsFinisher = new EmbeddingsFinisher() .setInputCols(&quot;UAE_embeddings&quot;) .setOutputCols(&quot;finished_embeddings&quot;) .setOutputAsVector(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, embeddings, embeddingsFinisher )) val data = Seq(&quot;hello world&quot;, &quot;hello moon&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80) Results +--------------------------------------------------------------------------------+ | result| +--------------------------------------------------------------------------------+ |[0.50387806, 0.5861606, 0.35129607, -0.76046336, -0.32446072, -0.117674336, 0...| |[0.6660665, 0.961762, 0.24854276, -0.1018044, -0.6569202, 0.027635604, 0.1915...| +--------------------------------------------------------------------------------+ Model Information Model Name: uae_large_v1 Compatibility: Spark NLP 5.3.3+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [embeddings] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">English BioLORD-2023-C MPNetEmbeddings from FremyCompany</title><link href="/2024/04/04/mpnet_embeddings_biolord_2023_c_en.html" rel="alternate" type="text/html" title="English BioLORD-2023-C MPNetEmbeddings from FremyCompany" /><published>2024-04-04T00:00:00+00:00</published><updated>2024-04-04T00:00:00+00:00</updated><id>/2024/04/04/mpnet_embeddings_biolord_2023_c_en</id><content type="html" xml:base="/2024/04/04/mpnet_embeddings_biolord_2023_c_en.html">## Description

Pretrained MPNetEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP `mpnet_embeddings_biolord_2023_c` is a English model originally trained by `FremyCompany`.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/mpnet_embeddings_biolord_2023_c_en_5.3.1_3.0_1712265672474.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/mpnet_embeddings_biolord_2023_c_en_5.3.1_3.0_1712265672474.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;documents&quot;)
    
embeddings =MPNetEmbeddings.pretrained(&quot;mpnet_embeddings_biolord_2023_c&quot;,&quot;en&quot;)\
    .setInputCols([&quot;documents&quot;])\
    .setOutputCol(&quot;mpnet_embeddings&quot;)

pipeline = Pipeline().setStages([document_assembler, embeddings])

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;documents&quot;)
    
val embeddings = MPNetEmbeddings 
    .pretrained(&quot;mpnet_embeddings_biolord_2023_c&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;)) 
    .setOutputCol(&quot;mpnet_embeddings&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, embeddings))

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|mpnet_embeddings_biolord_2023_c|
|Compatibility:|Spark NLP 5.3.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[MPNet]|
|Language:|en|
|Size:|406.9 MB|

## References

https://huggingface.co/FremyCompany/BioLORD-2023-C</content><author><name>John Snow Labs</name></author><category term="en" /><category term="mpnet" /><category term="embeddings" /><category term="biolord" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained MPNetEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP mpnet_embeddings_biolord_2023_c is a English model originally trained by FremyCompany. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;documents&quot;) embeddings =MPNetEmbeddings.pretrained(&quot;mpnet_embeddings_biolord_2023_c&quot;,&quot;en&quot;)\ .setInputCols([&quot;documents&quot;])\ .setOutputCol(&quot;mpnet_embeddings&quot;) pipeline = Pipeline().setStages([document_assembler, embeddings]) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val embeddings = MPNetEmbeddings .pretrained(&quot;mpnet_embeddings_biolord_2023_c&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;)) .setOutputCol(&quot;mpnet_embeddings&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, embeddings)) val result = pipeline.fit(data).transform(data) Model Information Model Name: mpnet_embeddings_biolord_2023_c Compatibility: Spark NLP 5.3.1+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [MPNet] Language: en Size: 406.9 MB References https://huggingface.co/FremyCompany/BioLORD-2023-C</summary></entry><entry><title type="html">English distil_asr_whisper_large_v2 WhisperForCTC from distil-whisper</title><link href="/2024/02/26/distil_asr_whisper_large_v2_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_large_v2 WhisperForCTC from distil-whisper" /><published>2024-02-26T00:00:00+00:00</published><updated>2024-02-26T00:00:00+00:00</updated><id>/2024/02/26/distil_asr_whisper_large_v2_en</id><content type="html" xml:base="/2024/02/26/distil_asr_whisper_large_v2_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_large_v2 is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_large_v2_en_5.2.4_3.4_1708969018025.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_large_v2_en_5.2.4_3.4_1708969018025.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)


speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)
val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_large_v2|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|2.4 GB|

## References

https://huggingface.co/distil-whisper/distil-large-v2</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_large_v2 is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_large_v2 Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 2.4 GB References https://huggingface.co/distil-whisper/distil-large-v2</summary></entry><entry><title type="html">English distil_asr_whisper_mediumWhisperForCTC from distil-whisper</title><link href="/2024/02/25/distil_asr_whisper_medium_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_mediumWhisperForCTC from distil-whisper" /><published>2024-02-25T00:00:00+00:00</published><updated>2024-02-25T00:00:00+00:00</updated><id>/2024/02/25/distil_asr_whisper_medium_en</id><content type="html" xml:base="/2024/02/25/distil_asr_whisper_medium_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_medium is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_medium_en_5.2.4_3.4_1708901703317.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_medium_en_5.2.4_3.4_1708901703317.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)


speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)
val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_medium|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.4 GB|

## References

https://huggingface.co/distil-whisper/distil-medium.en</content><author><name>John Snow Labs</name></author><category term="whisper" /><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_medium is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_medium Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.4 GB References https://huggingface.co/distil-whisper/distil-medium.en</summary></entry><entry><title type="html">English distil_asr_whisper_small WhisperForCTC from distil-whisper</title><link href="/2024/02/16/distil_asr_whisper_small_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_small WhisperForCTC from distil-whisper" /><published>2024-02-16T00:00:00+00:00</published><updated>2024-02-16T00:00:00+00:00</updated><id>/2024/02/16/distil_asr_whisper_small_en</id><content type="html" xml:base="/2024/02/16/distil_asr_whisper_small_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_small is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_small_en_5.2.4_3.0_1708118638184.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_small_en_5.2.4_3.0_1708118638184.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)
    
    
speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_small|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|748.5 MB|

## References

https://huggingface.co/distil-whisper/distil-small.en</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_small is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_small Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 748.5 MB References https://huggingface.co/distil-whisper/distil-small.en</summary></entry><entry><title type="html">Multilingual bge_m3 XlmRoBertaSentenceEmbeddings from BAII</title><link href="/2024/02/11/bge_m3_xx.html" rel="alternate" type="text/html" title="Multilingual bge_m3 XlmRoBertaSentenceEmbeddings from BAII" /><published>2024-02-11T00:00:00+00:00</published><updated>2024-02-11T00:00:00+00:00</updated><id>/2024/02/11/bge_m3_xx</id><content type="html" xml:base="/2024/02/11/bge_m3_xx.html">## Description

Pretrained XlmRoBertaSentenceEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bge_m3 is a Multilingual model originally trained by BAII.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bge_m3_xx_5.2.3_3.4_1707668886363.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bge_m3_xx_5.2.3_3.4_1707668886363.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;documents&quot;)
    
sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ 
    .setInputCols([&quot;document&quot;])\ 
    .setOutputCol(&quot;sentence&quot;)
    
embeddings =XlmRoBertaSentenceEmbeddings.pretrained(&quot;bge_m3&quot;,&quot;xx&quot;) \
            .setInputCols([&quot;sentence&quot;]) \
            .setOutputCol(&quot;embeddings&quot;)

pipeline = Pipeline().setStages([document_assembler, sentencerDL, embeddings])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;documents&quot;)
    
val sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)
    .setInputCols([&quot;document&quot;])
    .setOutputCol(&quot;sentence&quot;)
    
val embeddings = XlmRoBertaSentenceEmbeddings 
    .pretrained(&quot;bge_m3&quot;, &quot;xx&quot;)
    .setInputCols(Array(&quot;sentence&quot;)) 
    .setOutputCol(&quot;embeddings&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, sentencerDL, embeddings))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bge_m3|
|Compatibility:|Spark NLP 5.2.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence]|
|Output Labels:|[sentence_embeddings]|
|Language:|xx|
|Size:|410.8 MB|
|Max sentence length:|32|

## References

https://huggingface.co/BAAI/bge-m3</content><author><name>John Snow Labs</name></author><category term="xx" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained XlmRoBertaSentenceEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bge_m3 is a Multilingual model originally trained by BAII. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;documents&quot;) sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) embeddings =XlmRoBertaSentenceEmbeddings.pretrained(&quot;bge_m3&quot;,&quot;xx&quot;) \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;embeddings&quot;) pipeline = Pipeline().setStages([document_assembler, sentencerDL, embeddings]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val embeddings = XlmRoBertaSentenceEmbeddings .pretrained(&quot;bge_m3&quot;, &quot;xx&quot;) .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentencerDL, embeddings)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bge_m3 Compatibility: Spark NLP 5.2.3+ License: Open Source Edition: Official Input Labels: [sentence] Output Labels: [sentence_embeddings] Language: xx Size: 410.8 MB Max sentence length: 32 References https://huggingface.co/BAAI/bge-m3</summary></entry><entry><title type="html">BERT Zero-Shot Classification Base - MNLI (bert_zero_shot_classifier_mnli)</title><link href="/2024/02/01/bert_zero_shot_classifier_mnli_xx.html" rel="alternate" type="text/html" title="BERT Zero-Shot Classification Base - MNLI (bert_zero_shot_classifier_mnli)" /><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-01T00:00:00+00:00</updated><id>/2024/02/01/bert_zero_shot_classifier_mnli_xx</id><content type="html" xml:base="/2024/02/01/bert_zero_shot_classifier_mnli_xx.html">## Description

This model is intended to be used for zero-shot text classification. It is fine-tuned on MNLI.

BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models donâ€™t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means itâ€™s slower but it is much more flexible.

We used TFBertForSequenceClassification to train this model and used BertForZeroShotClassification annotator in Spark NLP ðŸš€ for prediction at scale!

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_zero_shot_classifier_mnli_xx_5.2.4_3.4_1706784558791.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_zero_shot_classifier_mnli_xx_5.2.4_3.4_1706784558791.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler() \
.setInputCol('text') \
.setOutputCol('document')

tokenizer = Tokenizer() \
.setInputCols(['document']) \
.setOutputCol('token')

zeroShotClassifier = BertForZeroShotClassification \
.pretrained('bert_zero_shot_classifier_mnli', 'xx') \
.setInputCols(['token', 'document']) \
.setOutputCol('class') \
.setCaseSensitive(True) \
.setMaxSentenceLength(512) \
.setCandidateLabels([&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;])

pipeline = Pipeline(stages=[
document_assembler,
tokenizer,
zeroShotClassifier
])

example = spark.createDataFrame([['I have a problem with my iphone that needs to be resolved asap!!']]).toDF(&quot;text&quot;)
result = pipeline.fit(example).transform(example)
```
```scala
val document_assembler = DocumentAssembler()
.setInputCol(&quot;text&quot;)
.setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer()
.setInputCols(&quot;document&quot;)
.setOutputCol(&quot;token&quot;)

val zeroShotClassifier = BertForSequenceClassification.pretrained(&quot;bert_zero_shot_classifier_mnli&quot;, &quot;xx&quot;)
.setInputCols(&quot;document&quot;, &quot;token&quot;)
.setOutputCol(&quot;class&quot;)
.setCaseSensitive(true)
.setMaxSentenceLength(512)
.setCandidateLabels(Array(&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;))

val pipeline = new Pipeline().setStages(Array(document_assembler, tokenizer, zeroShotClassifier))

val example = Seq(&quot;I have a problem with my iphone that needs to be resolved asap!!&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(example).transform(example)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_zero_shot_classifier_mnli|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[token, document]|
|Output Labels:|[label]|
|Language:|xx|
|Size:|409.1 MB|
|Case sensitive:|true|</content><author><name>John Snow Labs</name></author><category term="xx" /><category term="open_source" /><category term="onnx" /><summary type="html">Description This model is intended to be used for zero-shot text classification. It is fine-tuned on MNLI. BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models donâ€™t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means itâ€™s slower but it is much more flexible. We used TFBertForSequenceClassification to train this model and used BertForZeroShotClassification annotator in Spark NLP ðŸš€ for prediction at scale! Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') zeroShotClassifier = BertForZeroShotClassification \ .pretrained('bert_zero_shot_classifier_mnli', 'xx') \ .setInputCols(['token', 'document']) \ .setOutputCol('class') \ .setCaseSensitive(True) \ .setMaxSentenceLength(512) \ .setCandidateLabels([&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;]) pipeline = Pipeline(stages=[ document_assembler, tokenizer, zeroShotClassifier ]) example = spark.createDataFrame([['I have a problem with my iphone that needs to be resolved asap!!']]).toDF(&quot;text&quot;) result = pipeline.fit(example).transform(example) val document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val zeroShotClassifier = BertForSequenceClassification.pretrained(&quot;bert_zero_shot_classifier_mnli&quot;, &quot;xx&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;class&quot;) .setCaseSensitive(true) .setMaxSentenceLength(512) .setCandidateLabels(Array(&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;)) val pipeline = new Pipeline().setStages(Array(document_assembler, tokenizer, zeroShotClassifier)) val example = Seq(&quot;I have a problem with my iphone that needs to be resolved asap!!&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(example).transform(example) Model Information Model Name: bert_zero_shot_classifier_mnli Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [token, document] Output Labels: [label] Language: xx Size: 409.1 MB Case sensitive: true</summary></entry><entry><title type="html">English 10_epochs_camembert_jb CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/10_epochs_camembert_jb_en.html" rel="alternate" type="text/html" title="English 10_epochs_camembert_jb CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/10_epochs_camembert_jb_en</id><content type="html" xml:base="/2024/01/21/10_epochs_camembert_jb_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`10_epochs_camembert_jb` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/10_epochs_camembert_jb_en_5.2.4_3.0_1705836801086.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/10_epochs_camembert_jb_en_5.2.4_3.0_1705836801086.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;10_epochs_camembert_jb&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;10_epochs_camembert_jb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|10_epochs_camembert_jb|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|412.1 MB|

## References

https://huggingface.co/bjubert/10_epochs_camembert_jb</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.10_epochs_camembert_jb is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;10_epochs_camembert_jb&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;10_epochs_camembert_jb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 10_epochs_camembert_jb Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 412.1 MB References https://huggingface.co/bjubert/10_epochs_camembert_jb</summary></entry><entry><title type="html">English 6_epochs_camembert CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/6_epochs_camembert_en.html" rel="alternate" type="text/html" title="English 6_epochs_camembert CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/6_epochs_camembert_en</id><content type="html" xml:base="/2024/01/21/6_epochs_camembert_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`6_epochs_camembert` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_en_5.2.4_3.0_1705836837867.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_en_5.2.4_3.0_1705836837867.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;6_epochs_camembert&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|6_epochs_camembert|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|412.2 MB|

## References

https://huggingface.co/bjubert/6_epochs_camembert</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.6_epochs_camembert is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;6_epochs_camembert&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 6_epochs_camembert Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 412.2 MB References https://huggingface.co/bjubert/6_epochs_camembert</summary></entry><entry><title type="html">English 6_epochs_camembert_jb CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/6_epochs_camembert_jb_en.html" rel="alternate" type="text/html" title="English 6_epochs_camembert_jb CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/6_epochs_camembert_jb_en</id><content type="html" xml:base="/2024/01/21/6_epochs_camembert_jb_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`6_epochs_camembert_jb` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_jb_en_5.2.4_3.0_1705838100373.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_jb_en_5.2.4_3.0_1705838100373.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert_jb&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;6_epochs_camembert_jb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|6_epochs_camembert_jb|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|411.9 MB|

## References

https://huggingface.co/bjubert/6_epochs_camembert_jb</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.6_epochs_camembert_jb is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert_jb&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;6_epochs_camembert_jb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 6_epochs_camembert_jb Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 411.9 MB References https://huggingface.co/bjubert/6_epochs_camembert_jb</summary></entry></feed>