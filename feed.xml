<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-12-08T22:40:45+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Image Zero Shot Classification with CLIP</title><link href="/2023/12/02/zero_shot_classifier_clip_vit_base_patch32_en.html" rel="alternate" type="text/html" title="Image Zero Shot Classification with CLIP" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/zero_shot_classifier_clip_vit_base_patch32_en</id><content type="html" xml:base="/2023/12/02/zero_shot_classifier_clip_vit_base_patch32_en.html">## Description

CLIP (Contrastive Language-Image Pre-Training) is a neural network that was trained on image
and text pairs. It has the ability to predict images without training on any hard-coded
labels. This makes it very flexible, as labels can be provided during inference. This is
similar to the zero-shot capabilities of the GPT-2 and 3 models.

This model was imported from huggingface transformers:
https://huggingface.co/openai/clip-vit-base-patch32

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/zero_shot_classifier_clip_vit_base_patch32_en_5.2.0_3.0_1701541274927.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/zero_shot_classifier_clip_vit_base_patch32_en_5.2.0_3.0_1701541274927.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline

imageDF = spark.read \
    .format(&quot;image&quot;) \
    .option(&quot;dropInvalid&quot;, value = True) \
    .load(&quot;src/test/resources/image/&quot;)

imageAssembler: ImageAssembler = ImageAssembler() \
    .setInputCol(&quot;image&quot;) \
    .setOutputCol(&quot;image_assembler&quot;)

candidateLabels = [
    &quot;a photo of a bird&quot;,
    &quot;a photo of a cat&quot;,
    &quot;a photo of a dog&quot;,
    &quot;a photo of a hen&quot;,
    &quot;a photo of a hippo&quot;,
    &quot;a photo of a room&quot;,
    &quot;a photo of a tractor&quot;,
    &quot;a photo of an ostrich&quot;,
    &quot;a photo of an ox&quot;]

imageClassifier = CLIPForZeroShotClassification \
    .pretrained() \
    .setInputCols([&quot;image_assembler&quot;]) \
    .setOutputCol(&quot;label&quot;) \
    .setCandidateLabels(candidateLabels)

pipeline = Pipeline().setStages([imageAssembler, imageClassifier])
pipelineDF = pipeline.fit(imageDF).transform(imageDF)
pipelineDF \
  .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;label.result&quot;) \
  .show(truncate=False)
```
```scala
import com.johnsnowlabs.nlp.ImageAssembler
import com.johnsnowlabs.nlp.annotator._
import org.apache.spark.ml.Pipeline
val imageDF = ResourceHelper.spark.read
  .format(&quot;image&quot;)
  .option(&quot;dropInvalid&quot;, value = true)
  .load(&quot;src/test/resources/image/&quot;)
val imageAssembler: ImageAssembler = new ImageAssembler()
  .setInputCol(&quot;image&quot;)
  .setOutputCol(&quot;image_assembler&quot;)
val candidateLabels = Array(
  &quot;a photo of a bird&quot;,
  &quot;a photo of a cat&quot;,
  &quot;a photo of a dog&quot;,
  &quot;a photo of a hen&quot;,
  &quot;a photo of a hippo&quot;,
  &quot;a photo of a room&quot;,
  &quot;a photo of a tractor&quot;,
  &quot;a photo of an ostrich&quot;,
  &quot;a photo of an ox&quot;)
val imageClassifier = CLIPForZeroShotClassification
  .pretrained()
  .setInputCols(&quot;image_assembler&quot;)
  .setOutputCol(&quot;label&quot;)
  .setCandidateLabels(candidateLabels)
val pipeline =
  new Pipeline().setStages(Array(imageAssembler, imageClassifier)).fit(imageDF).transform(imageDF)
pipeline
  .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;label.result&quot;)
  .show(truncate = false)
```
&lt;/div&gt;

## Results

```bash
+-----------------+-----------------------+
|image_name       |result                 |
+-----------------+-----------------------+
|palace.JPEG      |[a photo of a room]    |
|egyptian_cat.jpeg|[a photo of a cat]     |
|hippopotamus.JPEG|[a photo of a hippo]   |
|hen.JPEG         |[a photo of a hen]     |
|ostrich.JPEG     |[a photo of an ostrich]|
|junco.JPEG       |[a photo of a bird]    |
|bluetick.jpg     |[a photo of a dog]     |
|chihuahua.jpg    |[a photo of a dog]     |
|tractor.JPEG     |[a photo of a tractor] |
|ox.JPEG          |[a photo of an ox]     |
+-----------------+-----------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|zero_shot_classifier_clip_vit_base_patch32|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[image_assembler]|
|Output Labels:|[classification]|
|Language:|en|
|Size:|392.8 MB|</content><author><name>John Snow Labs</name></author><category term="classification" /><category term="image" /><category term="en" /><category term="zero_shot" /><category term="open_source" /><category term="onnx" /><summary type="html">Description CLIP (Contrastive Language-Image Pre-Training) is a neural network that was trained on image and text pairs. It has the ability to predict images without training on any hard-coded labels. This makes it very flexible, as labels can be provided during inference. This is similar to the zero-shot capabilities of the GPT-2 and 3 models. This model was imported from huggingface transformers: https://huggingface.co/openai/clip-vit-base-patch32 Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline imageDF = spark.read \ .format(&quot;image&quot;) \ .option(&quot;dropInvalid&quot;, value = True) \ .load(&quot;src/test/resources/image/&quot;) imageAssembler: ImageAssembler = ImageAssembler() \ .setInputCol(&quot;image&quot;) \ .setOutputCol(&quot;image_assembler&quot;) candidateLabels = [ &quot;a photo of a bird&quot;, &quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;, &quot;a photo of a hen&quot;, &quot;a photo of a hippo&quot;, &quot;a photo of a room&quot;, &quot;a photo of a tractor&quot;, &quot;a photo of an ostrich&quot;, &quot;a photo of an ox&quot;] imageClassifier = CLIPForZeroShotClassification \ .pretrained() \ .setInputCols([&quot;image_assembler&quot;]) \ .setOutputCol(&quot;label&quot;) \ .setCandidateLabels(candidateLabels) pipeline = Pipeline().setStages([imageAssembler, imageClassifier]) pipelineDF = pipeline.fit(imageDF).transform(imageDF) pipelineDF \ .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;label.result&quot;) \ .show(truncate=False) import com.johnsnowlabs.nlp.ImageAssembler import com.johnsnowlabs.nlp.annotator._ import org.apache.spark.ml.Pipeline val imageDF = ResourceHelper.spark.read .format(&quot;image&quot;) .option(&quot;dropInvalid&quot;, value = true) .load(&quot;src/test/resources/image/&quot;) val imageAssembler: ImageAssembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val candidateLabels = Array( &quot;a photo of a bird&quot;, &quot;a photo of a cat&quot;, &quot;a photo of a dog&quot;, &quot;a photo of a hen&quot;, &quot;a photo of a hippo&quot;, &quot;a photo of a room&quot;, &quot;a photo of a tractor&quot;, &quot;a photo of an ostrich&quot;, &quot;a photo of an ox&quot;) val imageClassifier = CLIPForZeroShotClassification .pretrained() .setInputCols(&quot;image_assembler&quot;) .setOutputCol(&quot;label&quot;) .setCandidateLabels(candidateLabels) val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier)).fit(imageDF).transform(imageDF) pipeline .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;label.result&quot;) .show(truncate = false) Results +-----------------+-----------------------+ |image_name |result | +-----------------+-----------------------+ |palace.JPEG |[a photo of a room] | |egyptian_cat.jpeg|[a photo of a cat] | |hippopotamus.JPEG|[a photo of a hippo] | |hen.JPEG |[a photo of a hen] | |ostrich.JPEG |[a photo of an ostrich]| |junco.JPEG |[a photo of a bird] | |bluetick.jpg |[a photo of a dog] | |chihuahua.jpg |[a photo of a dog] | |tractor.JPEG |[a photo of a tractor] | |ox.JPEG |[a photo of an ox] | +-----------------+-----------------------+ Model Information Model Name: zero_shot_classifier_clip_vit_base_patch32 Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [image_assembler] Output Labels: [classification] Language: en Size: 392.8 MB</summary></entry><entry><title type="html">English 3rh RoBertaForSequenceClassification from aloxatel</title><link href="/2023/12/02/3rh_en.html" rel="alternate" type="text/html" title="English 3rh RoBertaForSequenceClassification from aloxatel" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/3rh_en</id><content type="html" xml:base="/2023/12/02/3rh_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`3rh` is a English model originally trained by aloxatel.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/3rh_en_5.2.0_3.0_1701538107263.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/3rh_en_5.2.0_3.0_1701538107263.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;3rh&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;3rh&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|3rh|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/aloxatel/3RH</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.3rh is a English model originally trained by aloxatel. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;3rh&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;3rh&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: 3rh Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/aloxatel/3RH</summary></entry><entry><title type="html">English 4_way_detection_prop_16 RoBertaForSequenceClassification from ultra-coder54732</title><link href="/2023/12/02/4_way_detection_prop_16_en.html" rel="alternate" type="text/html" title="English 4_way_detection_prop_16 RoBertaForSequenceClassification from ultra-coder54732" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/4_way_detection_prop_16_en</id><content type="html" xml:base="/2023/12/02/4_way_detection_prop_16_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`4_way_detection_prop_16` is a English model originally trained by ultra-coder54732.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/4_way_detection_prop_16_en_5.2.0_3.0_1701498030547.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/4_way_detection_prop_16_en_5.2.0_3.0_1701498030547.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;4_way_detection_prop_16&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;4_way_detection_prop_16&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|4_way_detection_prop_16|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|437.7 MB|

## References

https://huggingface.co/ultra-coder54732/4-way-detection-prop-16</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.4_way_detection_prop_16 is a English model originally trained by ultra-coder54732. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;4_way_detection_prop_16&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;4_way_detection_prop_16&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: 4_way_detection_prop_16 Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 437.7 MB References https://huggingface.co/ultra-coder54732/4-way-detection-prop-16</summary></entry><entry><title type="html">English a2 RoBertaForSequenceClassification from ethanrom</title><link href="/2023/12/02/a2_en.html" rel="alternate" type="text/html" title="English a2 RoBertaForSequenceClassification from ethanrom" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/a2_en</id><content type="html" xml:base="/2023/12/02/a2_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`a2` is a English model originally trained by ethanrom.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/a2_en_5.2.0_3.0_1701481751360.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/a2_en_5.2.0_3.0_1701481751360.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;a2&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;a2&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|a2|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/ethanrom/a2</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.a2 is a English model originally trained by ethanrom. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;a2&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;a2&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: a2 Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/ethanrom/a2</summary></entry><entry><title type="html">English adequacymodel RoBertaForSequenceClassification from ashwinpokee</title><link href="/2023/12/02/adequacymodel_en.html" rel="alternate" type="text/html" title="English adequacymodel RoBertaForSequenceClassification from ashwinpokee" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/adequacymodel_en</id><content type="html" xml:base="/2023/12/02/adequacymodel_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`adequacymodel` is a English model originally trained by ashwinpokee.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/adequacymodel_en_5.2.0_3.0_1701517975373.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/adequacymodel_en_5.2.0_3.0_1701517975373.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;adequacymodel&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;adequacymodel&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|adequacymodel|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/ashwinpokee/adequacymodel</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.adequacymodel is a English model originally trained by ashwinpokee. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;adequacymodel&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;adequacymodel&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: adequacymodel Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/ashwinpokee/adequacymodel</summary></entry><entry><title type="html">English all_roberta_large_v1_banking_2_16_5 RoBertaForSequenceClassification from fathyshalab</title><link href="/2023/12/02/all_roberta_large_v1_banking_2_16_5_en.html" rel="alternate" type="text/html" title="English all_roberta_large_v1_banking_2_16_5 RoBertaForSequenceClassification from fathyshalab" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/all_roberta_large_v1_banking_2_16_5_en</id><content type="html" xml:base="/2023/12/02/all_roberta_large_v1_banking_2_16_5_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_roberta_large_v1_banking_2_16_5` is a English model originally trained by fathyshalab.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_banking_2_16_5_en_5.2.0_3.0_1701512590514.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_banking_2_16_5_en_5.2.0_3.0_1701512590514.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_2_16_5&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_2_16_5&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_roberta_large_v1_banking_2_16_5|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/fathyshalab/all-roberta-large-v1-banking-2-16-5</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_roberta_large_v1_banking_2_16_5 is a English model originally trained by fathyshalab. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_2_16_5&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_2_16_5&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: all_roberta_large_v1_banking_2_16_5 Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/fathyshalab/all-roberta-large-v1-banking-2-16-5</summary></entry><entry><title type="html">English all_roberta_large_v1_banking_7_16_5 RoBertaForSequenceClassification from fathyshalab</title><link href="/2023/12/02/all_roberta_large_v1_banking_7_16_5_en.html" rel="alternate" type="text/html" title="English all_roberta_large_v1_banking_7_16_5 RoBertaForSequenceClassification from fathyshalab" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/all_roberta_large_v1_banking_7_16_5_en</id><content type="html" xml:base="/2023/12/02/all_roberta_large_v1_banking_7_16_5_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_roberta_large_v1_banking_7_16_5` is a English model originally trained by fathyshalab.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_banking_7_16_5_en_5.2.0_3.0_1701524580211.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_banking_7_16_5_en_5.2.0_3.0_1701524580211.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_7_16_5&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_7_16_5&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_roberta_large_v1_banking_7_16_5|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/fathyshalab/all-roberta-large-v1-banking-7-16-5</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_roberta_large_v1_banking_7_16_5 is a English model originally trained by fathyshalab. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_7_16_5&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_banking_7_16_5&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: all_roberta_large_v1_banking_7_16_5 Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/fathyshalab/all-roberta-large-v1-banking-7-16-5</summary></entry><entry><title type="html">English all_roberta_large_v1_credit_cards_1000_16_5_oos RoBertaForSequenceClassification from fathyshalab</title><link href="/2023/12/02/all_roberta_large_v1_credit_cards_1000_16_5_oos_en.html" rel="alternate" type="text/html" title="English all_roberta_large_v1_credit_cards_1000_16_5_oos RoBertaForSequenceClassification from fathyshalab" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/all_roberta_large_v1_credit_cards_1000_16_5_oos_en</id><content type="html" xml:base="/2023/12/02/all_roberta_large_v1_credit_cards_1000_16_5_oos_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_roberta_large_v1_credit_cards_1000_16_5_oos` is a English model originally trained by fathyshalab.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_credit_cards_1000_16_5_oos_en_5.2.0_3.0_1701534826697.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_credit_cards_1000_16_5_oos_en_5.2.0_3.0_1701534826697.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_credit_cards_1000_16_5_oos&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_credit_cards_1000_16_5_oos&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_roberta_large_v1_credit_cards_1000_16_5_oos|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/fathyshalab/all-roberta-large-v1-credit_cards-1000-16-5-oos</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_roberta_large_v1_credit_cards_1000_16_5_oos is a English model originally trained by fathyshalab. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_credit_cards_1000_16_5_oos&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_credit_cards_1000_16_5_oos&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: all_roberta_large_v1_credit_cards_1000_16_5_oos Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/fathyshalab/all-roberta-large-v1-credit_cards-1000-16-5-oos</summary></entry><entry><title type="html">English all_roberta_large_v1_home_2_16_5_oos RoBertaForSequenceClassification from fathyshalab</title><link href="/2023/12/02/all_roberta_large_v1_home_2_16_5_oos_en.html" rel="alternate" type="text/html" title="English all_roberta_large_v1_home_2_16_5_oos RoBertaForSequenceClassification from fathyshalab" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/all_roberta_large_v1_home_2_16_5_oos_en</id><content type="html" xml:base="/2023/12/02/all_roberta_large_v1_home_2_16_5_oos_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_roberta_large_v1_home_2_16_5_oos` is a English model originally trained by fathyshalab.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_home_2_16_5_oos_en_5.2.0_3.0_1701542287112.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_home_2_16_5_oos_en_5.2.0_3.0_1701542287112.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_2_16_5_oos&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_2_16_5_oos&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_roberta_large_v1_home_2_16_5_oos|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/fathyshalab/all-roberta-large-v1-home-2-16-5-oos</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_roberta_large_v1_home_2_16_5_oos is a English model originally trained by fathyshalab. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_2_16_5_oos&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_2_16_5_oos&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: all_roberta_large_v1_home_2_16_5_oos Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/fathyshalab/all-roberta-large-v1-home-2-16-5-oos</summary></entry><entry><title type="html">English all_roberta_large_v1_home_7_16_5 RoBertaForSequenceClassification from fathyshalab</title><link href="/2023/12/02/all_roberta_large_v1_home_7_16_5_en.html" rel="alternate" type="text/html" title="English all_roberta_large_v1_home_7_16_5 RoBertaForSequenceClassification from fathyshalab" /><published>2023-12-02T00:00:00+00:00</published><updated>2023-12-02T00:00:00+00:00</updated><id>/2023/12/02/all_roberta_large_v1_home_7_16_5_en</id><content type="html" xml:base="/2023/12/02/all_roberta_large_v1_home_7_16_5_en.html">## Description

Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_roberta_large_v1_home_7_16_5` is a English model originally trained by fathyshalab.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_home_7_16_5_en_5.2.0_3.0_1701509825003.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_roberta_large_v1_home_7_16_5_en_5.2.0_3.0_1701509825003.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)  
    
sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_7_16_5&quot;,&quot;en&quot;)\
            .setInputCols([&quot;document&quot;,&quot;token&quot;])\
            .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier])

data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;) 
    .setOutputCol(&quot;token&quot;)  
    
val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_7_16_5&quot;,&quot;en&quot;)
            .setInputCols(Array(&quot;document&quot;,&quot;token&quot;))
            .setOutputCol(&quot;class&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))

val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_roberta_large_v1_home_7_16_5|
|Compatibility:|Spark NLP 5.2.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.3 GB|

## References

https://huggingface.co/fathyshalab/all-roberta-large-v1-home-7-16-5</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="sequence_classification" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_roberta_large_v1_home_7_16_5 is a English model originally trained by fathyshalab. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_7_16_5&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;,&quot;token&quot;])\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([document_assembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;PUT YOUR STRING HERE&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val sequenceClassifier = RoBertaForSequenceClassification.pretrained(&quot;all_roberta_large_v1_home_7_16_5&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;PUT YOUR STRING HERE&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: all_roberta_large_v1_home_7_16_5 Compatibility: Spark NLP 5.2.0+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [class] Language: en Size: 1.3 GB References https://huggingface.co/fathyshalab/all-roberta-large-v1-home-7-16-5</summary></entry></feed>