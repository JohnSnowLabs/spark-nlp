<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-03-19T09:07:16+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">English distil_asr_whisper_large_v2 WhisperForCTC from distil-whisper</title><link href="/2024/02/26/distil_asr_whisper_large_v2_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_large_v2 WhisperForCTC from distil-whisper" /><published>2024-02-26T00:00:00+00:00</published><updated>2024-02-26T00:00:00+00:00</updated><id>/2024/02/26/distil_asr_whisper_large_v2_en</id><content type="html" xml:base="/2024/02/26/distil_asr_whisper_large_v2_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_large_v2 is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_large_v2_en_5.2.4_3.4_1708969018025.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_large_v2_en_5.2.4_3.4_1708969018025.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)


speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)
val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_large_v2|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|2.4 GB|

## References

https://huggingface.co/distil-whisper/distil-large-v2</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_large_v2 is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_large_v2&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_large_v2 Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 2.4 GB References https://huggingface.co/distil-whisper/distil-large-v2</summary></entry><entry><title type="html">English distil_asr_whisper_mediumWhisperForCTC from distil-whisper</title><link href="/2024/02/25/distil_asr_whisper_medium_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_mediumWhisperForCTC from distil-whisper" /><published>2024-02-25T00:00:00+00:00</published><updated>2024-02-25T00:00:00+00:00</updated><id>/2024/02/25/distil_asr_whisper_medium_en</id><content type="html" xml:base="/2024/02/25/distil_asr_whisper_medium_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_medium is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_medium_en_5.2.4_3.4_1708901703317.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_medium_en_5.2.4_3.4_1708901703317.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)


speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)
val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_medium|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.4 GB|

## References

https://huggingface.co/distil-whisper/distil-medium.en</content><author><name>John Snow Labs</name></author><category term="whisper" /><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_medium is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_medium&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_medium Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.4 GB References https://huggingface.co/distil-whisper/distil-medium.en</summary></entry><entry><title type="html">English distil_asr_whisper_small WhisperForCTC from distil-whisper</title><link href="/2024/02/16/distil_asr_whisper_small_en.html" rel="alternate" type="text/html" title="English distil_asr_whisper_small WhisperForCTC from distil-whisper" /><published>2024-02-16T00:00:00+00:00</published><updated>2024-02-16T00:00:00+00:00</updated><id>/2024/02/16/distil_asr_whisper_small_en</id><content type="html" xml:base="/2024/02/16/distil_asr_whisper_small_en.html">## Description

Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_small is a English model originally trained by distil-whisper.

This model is only compatible with PySpark 3.4 and above

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_small_en_5.2.4_3.0_1708118638184.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distil_asr_whisper_small_en_5.2.4_3.0_1708118638184.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
audioAssembler = AudioAssembler() \
    .setInputCol(&quot;audio_content&quot;) \
    .setOutputCol(&quot;audio_assembler&quot;)
    
    
speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) \
            .setInputCols([&quot;audio_assembler&quot;]) \
            .setOutputCol(&quot;text&quot;)

pipeline = Pipeline().setStages([audioAssembler, speechToText])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)
```
```scala
val audioAssembler = new AudioAssembler() 
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)
    
val speechToText  = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) 
            .setInputCols(Array(&quot;audio_assembler&quot;)) 
            .setOutputCol(&quot;text&quot;)

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distil_asr_whisper_small|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|748.5 MB|

## References

https://huggingface.co/distil-whisper/distil-small.en</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained WhisperForCTC model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.distil_asr_whisper_small is a English model originally trained by distil-whisper. This model is only compatible with PySpark 3.4 and above Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audioAssembler = AudioAssembler() \ .setInputCol(&quot;audio_content&quot;) \ .setOutputCol(&quot;audio_assembler&quot;) speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) \ .setInputCols([&quot;audio_assembler&quot;]) \ .setOutputCol(&quot;text&quot;) pipeline = Pipeline().setStages([audioAssembler, speechToText]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = WhisperForCTC.pretrained(&quot;distil_asr_whisper_small&quot;,&quot;en&quot;) .setInputCols(Array(&quot;audio_assembler&quot;)) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: distil_asr_whisper_small Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 748.5 MB References https://huggingface.co/distil-whisper/distil-small.en</summary></entry><entry><title type="html">Multilingual bge_m3 XlmRoBertaSentenceEmbeddings from BAII</title><link href="/2024/02/11/bge_m3_xx.html" rel="alternate" type="text/html" title="Multilingual bge_m3 XlmRoBertaSentenceEmbeddings from BAII" /><published>2024-02-11T00:00:00+00:00</published><updated>2024-02-11T00:00:00+00:00</updated><id>/2024/02/11/bge_m3_xx</id><content type="html" xml:base="/2024/02/11/bge_m3_xx.html">## Description

Pretrained XlmRoBertaSentenceEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bge_m3 is a Multilingual model originally trained by BAII.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bge_m3_xx_5.2.3_3.4_1707668886363.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bge_m3_xx_5.2.3_3.4_1707668886363.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;documents&quot;)
    
sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ 
    .setInputCols([&quot;document&quot;])\ 
    .setOutputCol(&quot;sentence&quot;)
    
embeddings =XlmRoBertaSentenceEmbeddings.pretrained(&quot;bge_m3 &quot;,&quot;xx&quot;) \
            .setInputCols([&quot;sentence&quot;]) \
            .setOutputCol(&quot;embeddings&quot;)

pipeline = Pipeline().setStages([document_assembler, sentencerDL, embeddings])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala

val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;documents&quot;)
    
val sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)
    .setInputCols([&quot;document&quot;])
    .setOutputCol(&quot;sentence&quot;)
    
val embeddings = XlmRoBertaSentenceEmbeddings 
    .pretrained(&quot;bge_m3 &quot;, &quot;xx&quot;)
    .setInputCols(Array(&quot;sentence&quot;)) 
    .setOutputCol(&quot;embeddings&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, sentencerDL, embeddings))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bge_m3|
|Compatibility:|Spark NLP 5.2.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence]|
|Output Labels:|[sentence_embeddings]|
|Language:|xx|
|Size:|410.8 MB|
|Max sentence length:|32|

## References

https://huggingface.co/BAAI/bge-m3</content><author><name>John Snow Labs</name></author><category term="xx" /><category term="open_source" /><category term="onnx" /><summary type="html">Description Pretrained XlmRoBertaSentenceEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bge_m3 is a Multilingual model originally trained by BAII. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;documents&quot;) sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) embeddings =XlmRoBertaSentenceEmbeddings.pretrained(&quot;bge_m3 &quot;,&quot;xx&quot;) \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;embeddings&quot;) pipeline = Pipeline().setStages([document_assembler, sentencerDL, embeddings]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val sentencerDL = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) .setInputCols([&quot;document&quot;]) .setOutputCol(&quot;sentence&quot;) val embeddings = XlmRoBertaSentenceEmbeddings .pretrained(&quot;bge_m3 &quot;, &quot;xx&quot;) .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, sentencerDL, embeddings)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bge_m3 Compatibility: Spark NLP 5.2.3+ License: Open Source Edition: Official Input Labels: [sentence] Output Labels: [sentence_embeddings] Language: xx Size: 410.8 MB Max sentence length: 32 References https://huggingface.co/BAAI/bge-m3</summary></entry><entry><title type="html">BERT Zero-Shot Classification Base - MNLI (bert_zero_shot_classifier_mnli)</title><link href="/2024/02/01/bert_zero_shot_classifier_mnli_xx.html" rel="alternate" type="text/html" title="BERT Zero-Shot Classification Base - MNLI (bert_zero_shot_classifier_mnli)" /><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-01T00:00:00+00:00</updated><id>/2024/02/01/bert_zero_shot_classifier_mnli_xx</id><content type="html" xml:base="/2024/02/01/bert_zero_shot_classifier_mnli_xx.html">## Description

This model is intended to be used for zero-shot text classification. It is fine-tuned on MNLI.

BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models don’t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means it’s slower but it is much more flexible.

We used TFBertForSequenceClassification to train this model and used BertForZeroShotClassification annotator in Spark NLP 🚀 for prediction at scale!

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_zero_shot_classifier_mnli_xx_5.2.4_3.4_1706784558791.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_zero_shot_classifier_mnli_xx_5.2.4_3.4_1706784558791.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler() \
.setInputCol('text') \
.setOutputCol('document')

tokenizer = Tokenizer() \
.setInputCols(['document']) \
.setOutputCol('token')

zeroShotClassifier = BertForZeroShotClassification \
.pretrained('bert_zero_shot_classifier_mnli', 'xx') \
.setInputCols(['token', 'document']) \
.setOutputCol('class') \
.setCaseSensitive(True) \
.setMaxSentenceLength(512) \
.setCandidateLabels([&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;])

pipeline = Pipeline(stages=[
document_assembler,
tokenizer,
zeroShotClassifier
])

example = spark.createDataFrame([['I have a problem with my iphone that needs to be resolved asap!!']]).toDF(&quot;text&quot;)
result = pipeline.fit(example).transform(example)
```
```scala
val document_assembler = DocumentAssembler()
.setInputCol(&quot;text&quot;)
.setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer()
.setInputCols(&quot;document&quot;)
.setOutputCol(&quot;token&quot;)

val zeroShotClassifier = BertForSequenceClassification.pretrained(&quot;bert_zero_shot_classifier_mnli&quot;, &quot;xx&quot;)
.setInputCols(&quot;document&quot;, &quot;token&quot;)
.setOutputCol(&quot;class&quot;)
.setCaseSensitive(true)
.setMaxSentenceLength(512)
.setCandidateLabels(Array(&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;))

val pipeline = new Pipeline().setStages(Array(document_assembler, tokenizer, zeroShotClassifier))

val example = Seq(&quot;I have a problem with my iphone that needs to be resolved asap!!&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(example).transform(example)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_zero_shot_classifier_mnli|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[token, document]|
|Output Labels:|[label]|
|Language:|xx|
|Size:|409.1 MB|
|Case sensitive:|true|</content><author><name>John Snow Labs</name></author><category term="xx" /><category term="open_source" /><category term="onnx" /><summary type="html">Description This model is intended to be used for zero-shot text classification. It is fine-tuned on MNLI. BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models don’t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means it’s slower but it is much more flexible. We used TFBertForSequenceClassification to train this model and used BertForZeroShotClassification annotator in Spark NLP 🚀 for prediction at scale! Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') zeroShotClassifier = BertForZeroShotClassification \ .pretrained('bert_zero_shot_classifier_mnli', 'xx') \ .setInputCols(['token', 'document']) \ .setOutputCol('class') \ .setCaseSensitive(True) \ .setMaxSentenceLength(512) \ .setCandidateLabels([&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;]) pipeline = Pipeline(stages=[ document_assembler, tokenizer, zeroShotClassifier ]) example = spark.createDataFrame([['I have a problem with my iphone that needs to be resolved asap!!']]).toDF(&quot;text&quot;) result = pipeline.fit(example).transform(example) val document_assembler = DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val zeroShotClassifier = BertForSequenceClassification.pretrained(&quot;bert_zero_shot_classifier_mnli&quot;, &quot;xx&quot;) .setInputCols(&quot;document&quot;, &quot;token&quot;) .setOutputCol(&quot;class&quot;) .setCaseSensitive(true) .setMaxSentenceLength(512) .setCandidateLabels(Array(&quot;urgent&quot;, &quot;mobile&quot;, &quot;travel&quot;, &quot;movie&quot;, &quot;music&quot;, &quot;sport&quot;, &quot;weather&quot;, &quot;technology&quot;)) val pipeline = new Pipeline().setStages(Array(document_assembler, tokenizer, zeroShotClassifier)) val example = Seq(&quot;I have a problem with my iphone that needs to be resolved asap!!&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(example).transform(example) Model Information Model Name: bert_zero_shot_classifier_mnli Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [token, document] Output Labels: [label] Language: xx Size: 409.1 MB Case sensitive: true</summary></entry><entry><title type="html">English 10_epochs_camembert_jb CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/10_epochs_camembert_jb_en.html" rel="alternate" type="text/html" title="English 10_epochs_camembert_jb CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/10_epochs_camembert_jb_en</id><content type="html" xml:base="/2024/01/21/10_epochs_camembert_jb_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`10_epochs_camembert_jb` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/10_epochs_camembert_jb_en_5.2.4_3.0_1705836801086.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/10_epochs_camembert_jb_en_5.2.4_3.0_1705836801086.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;10_epochs_camembert_jb&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;10_epochs_camembert_jb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|10_epochs_camembert_jb|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|412.1 MB|

## References

https://huggingface.co/bjubert/10_epochs_camembert_jb</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.10_epochs_camembert_jb is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;10_epochs_camembert_jb&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;10_epochs_camembert_jb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 10_epochs_camembert_jb Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 412.1 MB References https://huggingface.co/bjubert/10_epochs_camembert_jb</summary></entry><entry><title type="html">English 6_epochs_camembert CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/6_epochs_camembert_en.html" rel="alternate" type="text/html" title="English 6_epochs_camembert CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/6_epochs_camembert_en</id><content type="html" xml:base="/2024/01/21/6_epochs_camembert_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`6_epochs_camembert` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_en_5.2.4_3.0_1705836837867.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_en_5.2.4_3.0_1705836837867.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;6_epochs_camembert&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|6_epochs_camembert|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|412.2 MB|

## References

https://huggingface.co/bjubert/6_epochs_camembert</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.6_epochs_camembert is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;6_epochs_camembert&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 6_epochs_camembert Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 412.2 MB References https://huggingface.co/bjubert/6_epochs_camembert</summary></entry><entry><title type="html">English 6_epochs_camembert_jb CamemBertForTokenClassification from bjubert</title><link href="/2024/01/21/6_epochs_camembert_jb_en.html" rel="alternate" type="text/html" title="English 6_epochs_camembert_jb CamemBertForTokenClassification from bjubert" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/6_epochs_camembert_jb_en</id><content type="html" xml:base="/2024/01/21/6_epochs_camembert_jb_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`6_epochs_camembert_jb` is a English model originally trained by bjubert.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_jb_en_5.2.4_3.0_1705838100373.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/6_epochs_camembert_jb_en_5.2.4_3.0_1705838100373.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert_jb&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;6_epochs_camembert_jb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|6_epochs_camembert_jb|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|411.9 MB|

## References

https://huggingface.co/bjubert/6_epochs_camembert_jb</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.6_epochs_camembert_jb is a English model originally trained by bjubert. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;6_epochs_camembert_jb&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;6_epochs_camembert_jb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 6_epochs_camembert_jb Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 411.9 MB References https://huggingface.co/bjubert/6_epochs_camembert_jb</summary></entry><entry><title type="html">French 8bit_distilcamembert_base_ner CamemBertForTokenClassification from konverner</title><link href="/2024/01/21/8bit_distilcamembert_base_ner_fr.html" rel="alternate" type="text/html" title="French 8bit_distilcamembert_base_ner CamemBertForTokenClassification from konverner" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/8bit_distilcamembert_base_ner_fr</id><content type="html" xml:base="/2024/01/21/8bit_distilcamembert_base_ner_fr.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`8bit_distilcamembert_base_ner` is a French model originally trained by konverner.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/8bit_distilcamembert_base_ner_fr_5.2.4_3.0_1705834120473.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/8bit_distilcamembert_base_ner_fr_5.2.4_3.0_1705834120473.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;8bit_distilcamembert_base_ner&quot;,&quot;fr&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;8bit_distilcamembert_base_ner&quot;, &quot;fr&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|8bit_distilcamembert_base_ner|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|fr|
|Size:|252.5 MB|

## References

https://huggingface.co/konverner/8bit-distilcamembert-base-ner</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="fr" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.8bit_distilcamembert_base_ner is a French model originally trained by konverner. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;8bit_distilcamembert_base_ner&quot;,&quot;fr&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;8bit_distilcamembert_base_ner&quot;, &quot;fr&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: 8bit_distilcamembert_base_ner Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: fr Size: 252.5 MB References https://huggingface.co/konverner/8bit-distilcamembert-base-ner</summary></entry><entry><title type="html">English argument_wangchanberta2 CamemBertForTokenClassification from pitiwat</title><link href="/2024/01/21/argument_wangchanberta2_en.html" rel="alternate" type="text/html" title="English argument_wangchanberta2 CamemBertForTokenClassification from pitiwat" /><published>2024-01-21T00:00:00+00:00</published><updated>2024-01-21T00:00:00+00:00</updated><id>/2024/01/21/argument_wangchanberta2_en</id><content type="html" xml:base="/2024/01/21/argument_wangchanberta2_en.html">## Description

Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`argument_wangchanberta2` is a English model originally trained by pitiwat.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/argument_wangchanberta2_en_5.2.4_3.0_1705835802208.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/argument_wangchanberta2_en_5.2.4_3.0_1705835802208.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
    
tokenizer = Tokenizer() \
        .setInputCols([&quot;document&quot;]) \
        .setOutputCol(&quot;token&quot;)
        
    
tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;argument_wangchanberta2&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
            .setOutputCol(&quot;ner&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val tokenizer = Tokenizer() \
        .setInputCols(Array(&quot;document&quot;)) \
        .setOutputCol(&quot;token&quot;)

val tokenClassifier = CamemBertForTokenClassification  
    .pretrained(&quot;argument_wangchanberta2&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;ner&quot;) 

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|argument_wangchanberta2|
|Compatibility:|Spark NLP 5.2.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|392.1 MB|

## References

https://huggingface.co/pitiwat/argument_wangchanberta2</content><author><name>John Snow Labs</name></author><category term="camembert" /><category term="en" /><category term="open_source" /><category term="token_classification" /><category term="onnx" /><summary type="html">Description Pretrained CamemBertForTokenClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.argument_wangchanberta2 is a English model originally trained by pitiwat. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;token&quot;) tokenClassifier = CamemBertForTokenClassification.pretrained(&quot;argument_wangchanberta2&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;ner&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, tokenClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = Tokenizer() \ .setInputCols(Array(&quot;document&quot;)) \ .setOutputCol(&quot;token&quot;) val tokenClassifier = CamemBertForTokenClassification .pretrained(&quot;argument_wangchanberta2&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document&quot;,&quot;token&quot;)) .setOutputCol(&quot;ner&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, tokenClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: argument_wangchanberta2 Compatibility: Spark NLP 5.2.4+ License: Open Source Edition: Official Input Labels: [documents, token] Output Labels: [ner] Language: en Size: 392.1 MB References https://huggingface.co/pitiwat/argument_wangchanberta2</summary></entry></feed>