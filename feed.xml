<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-02-08T14:00:53+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Chinese Financial NER (sm, bert_embeddings_mengzi_bert_base_fin)</title><link href="/2023/02/04/finner_finance_chinese_sm_zh.html" rel="alternate" type="text/html" title="Chinese Financial NER (sm, bert_embeddings_mengzi_bert_base_fin)" /><published>2023-02-04T00:00:00+00:00</published><updated>2023-02-04T00:00:00+00:00</updated><id>/2023/02/04/finner_finance_chinese_sm_zh</id><content type="html" xml:base="/2023/02/04/finner_finance_chinese_sm_zh.html">## Description

This is the small version of the NER model for Financial Chinese texts, trained in a subset of **ChFinAnn** (see &quot;Datasets used for training&quot;). 

To use this model, use the `BertEmbeddings` model named `bert_embeddings_mengzi_bert_base_fin&quot;` as:

```python
bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_mengzi_bert_base_fin&quot;,&quot;zh&quot;) \
    .setInputCols(&quot;sentence&quot;, &quot;token&quot;) \
    .setOutputCol(&quot;embeddings&quot;)
```

Also, please note that the Chinese texts are not separated by white space. The embedding model we use is based on character-level embeddings, so you need to split the text on every character (for example, by setting `.setSplitPattern(&quot;&quot;)` in the `Tokenizer` annotator).

## Predicted Entities

`AveragePrice`, `ClosingDate`, `CompanyName`, `EndDate`, `EquityHolder`, `FrozeShares`, `HighestTradingPrice`, `LaterHoldingShares`, `LegalInstitution`, `LowestTradingPrice`, `OtherType`, `PledgedShares`, `Pledgee`, `ReleasedDate`, `RepurchaseAmount`, `RepurchasedShares`, `StartDate`, `StockAbbr`, `StockCode`, `TotalHoldingRatio`, `TotalHoldingShares`, `TotalPledgedShares`, `TradedShares`, `UnfrozeDate`

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/finance/FINNER_FINANCE_CHINESE){:.button.button-orange}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_finance_chinese_sm_zh_1.0.0_3.0_1675554138686.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_finance_chinese_sm_zh_1.0.0_3.0_1675554138686.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)
        
tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;token&quot;)\
        .setSplitPattern(&quot;&quot;) # Split on char level

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_mengzi_bert_base_fin&quot;,&quot;en&quot;) \
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \
        .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained(&quot;finner_finance_chinese_sm&quot;, &quot;zh&quot;, &quot;finance/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = Pipeline(stages=[
        documentAssembler,
        sentenceDetector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;近日，渤海水业股份有限公司（以下简称“公司”）收到公司持股5%以上股东李华青女士的《告知函》，获悉李华青女士将其所持有的部分公司股票进行补充质押，具体事项如下：&quot;&quot;&quot;]

res = model. Transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
res.select(F.explode(F.arrays_zip(res.ner_chunk.result, res.ner_chunk.metadata)).alias(&quot;cols&quot;)) \
      .select(F.expr(&quot;cols['0']&quot;).alias(&quot;chunk&quot;),
              F.expr(&quot;cols['1']['entity']&quot;).alias(&quot;ner_label&quot;),
              F.expr(&quot;cols['1']['confidence']&quot;).alias(&quot;confidence&quot;)).show(truncate=False)

```

&lt;/div&gt;

## Results

```bash
+------------------------------------+------------+----------+
|chunk                               |ner_label   |confidence|
+------------------------------------+------------+----------+
|业股份有限公司（以下简称“公司”）收到|CompanyName |0.7933    |
|质押，具体                          |EquityHolder|0.9378667 |
+------------------------------------+------------+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_finance_chinese_sm|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|zh|
|Size:|16.8 MB|

## References

The dataset used for training was a subset of the **chFinAnn** dataset, consisting of financial statements of Chinese listed companies from 2008 to 2018. 

Reference:

- [Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction](https://aclanthology.org/D19-1032) (Zheng et al., EMNLP-IJCNLP 2019)

## Sample text from the training dataset

近日，渤海水业股份有限公司（以下简称“公司”）收到公司持股5%以上股东李华青女士的《告知函》，获悉李华青女士将其所持有的部分公司股票进行补充质押，具体事项如下：

## Benchmarking

```bash
 entity                 precision    recall        f1    support 
 AveragePrice            78.0731   85.1449   81.4558         301 
 ClosingDate             76.0148   57.7031   65.6051         271 
 CompanyName             94.0767   95.9251   94.9919        5605 
 EndDate                 75.487    44.5402   56.0241         616 
 EquityHolder            83.8303   91.319    87.4146        7780 
 FrozeShares             47.4227   31.7241   38.0165          97 
 HighestTradingPrice     74.4186   70.5085   72.4108         559 
 LaterHoldingShares      31.4961   11.9048   17.2786         127 
 LegalInstitution        92.3767   87.6596   89.9563         223 
 LowestTradingPrice      78.5047   52.1739   62.6866         107 
 OtherType               78.2961   36.7619   50.0324         493 
 PledgedShares           78.0776   65.5189   71.249         1779 
 Pledgee                 90.1003   88.656    89.3723        1596 
 ReleasedDate            54.5016   46.1853   50              622 
 RepurchaseAmount        68.323    72.8477   70.5128         322 
 RepurchasedShares       79.5918   70.4819   74.7604         588 
 StartDate               65.4217   77.5493   70.9711        4150 
 StockAbbr               83.7656   82.0521   82.9           2969 
 StockCode               99.8355   99.5626   99.6989        1824 
 TotalHoldingRatio       74.2574   85.1628   79.3371        1515 
 TotalHoldingShares      67.0582   88.7306   76.387         2043 
 TotalPledgedShares      74.5989   86.0226   79.9045        1122 
 TradedShares            76.9231   68.6948   72.5765         910 
 UnfrozeDate              5.88235   5.55556   5.71429         17
```</content><author><name>John Snow Labs</name></author><category term="zh" /><category term="cn" /><category term="finance" /><category term="ner" /><category term="licensed" /><summary type="html">Description This is the small version of the NER model for Financial Chinese texts, trained in a subset of ChFinAnn (see “Datasets used for training”). To use this model, use the BertEmbeddings model named bert_embeddings_mengzi_bert_base_fin&quot; as: bert_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_mengzi_bert_base_fin&quot;,&quot;zh&quot;) \ .setInputCols(&quot;sentence&quot;, &quot;token&quot;) \ .setOutputCol(&quot;embeddings&quot;) Also, please note that the Chinese texts are not separated by white space. The embedding model we use is based on character-level embeddings, so you need to split the text on every character (for example, by setting .setSplitPattern(&quot;&quot;) in the Tokenizer annotator). Predicted Entities AveragePrice, ClosingDate, CompanyName, EndDate, EquityHolder, FrozeShares, HighestTradingPrice, LaterHoldingShares, LegalInstitution, LowestTradingPrice, OtherType, PledgedShares, Pledgee, ReleasedDate, RepurchaseAmount, RepurchasedShares, StartDate, StockAbbr, StockCode, TotalHoldingRatio, TotalHoldingShares, TotalPledgedShares, TradedShares, UnfrozeDate Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;)\ .setSplitPattern(&quot;&quot;) # Split on char level embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_mengzi_bert_base_fin&quot;,&quot;en&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_finance_chinese_sm&quot;, &quot;zh&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;近日，渤海水业股份有限公司（以下简称“公司”）收到公司持股5%以上股东李华青女士的《告知函》，获悉李华青女士将其所持有的部分公司股票进行补充质押，具体事项如下：&quot;&quot;&quot;] res = model. Transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) res.select(F.explode(F.arrays_zip(res.ner_chunk.result, res.ner_chunk.metadata)).alias(&quot;cols&quot;)) \ .select(F.expr(&quot;cols['0']&quot;).alias(&quot;chunk&quot;), F.expr(&quot;cols['1']['entity']&quot;).alias(&quot;ner_label&quot;), F.expr(&quot;cols['1']['confidence']&quot;).alias(&quot;confidence&quot;)).show(truncate=False) Results +------------------------------------+------------+----------+ |chunk |ner_label |confidence| +------------------------------------+------------+----------+ |业股份有限公司（以下简称“公司”）收到|CompanyName |0.7933 | |质押，具体 |EquityHolder|0.9378667 | +------------------------------------+------------+----------+ Model Information Model Name: finner_finance_chinese_sm Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: zh Size: 16.8 MB References The dataset used for training was a subset of the chFinAnn dataset, consisting of financial statements of Chinese listed companies from 2008 to 2018. Reference: Doc2EDAG: An End-to-End Document-level Framework for Chinese Financial Event Extraction (Zheng et al., EMNLP-IJCNLP 2019) Sample text from the training dataset 近日，渤海水业股份有限公司（以下简称“公司”）收到公司持股5%以上股东李华青女士的《告知函》，获悉李华青女士将其所持有的部分公司股票进行补充质押，具体事项如下： Benchmarking entity precision recall f1 support AveragePrice 78.0731 85.1449 81.4558 301 ClosingDate 76.0148 57.7031 65.6051 271 CompanyName 94.0767 95.9251 94.9919 5605 EndDate 75.487 44.5402 56.0241 616 EquityHolder 83.8303 91.319 87.4146 7780 FrozeShares 47.4227 31.7241 38.0165 97 HighestTradingPrice 74.4186 70.5085 72.4108 559 LaterHoldingShares 31.4961 11.9048 17.2786 127 LegalInstitution 92.3767 87.6596 89.9563 223 LowestTradingPrice 78.5047 52.1739 62.6866 107 OtherType 78.2961 36.7619 50.0324 493 PledgedShares 78.0776 65.5189 71.249 1779 Pledgee 90.1003 88.656 89.3723 1596 ReleasedDate 54.5016 46.1853 50 622 RepurchaseAmount 68.323 72.8477 70.5128 322 RepurchasedShares 79.5918 70.4819 74.7604 588 StartDate 65.4217 77.5493 70.9711 4150 StockAbbr 83.7656 82.0521 82.9 2969 StockCode 99.8355 99.5626 99.6989 1824 TotalHoldingRatio 74.2574 85.1628 79.3371 1515 TotalHoldingShares 67.0582 88.7306 76.387 2043 TotalPledgedShares 74.5989 86.0226 79.9045 1122 TradedShares 76.9231 68.6948 72.5765 910 UnfrozeDate 5.88235 5.55556 5.71429 17</summary></entry><entry><title type="html">Categorize Chat Messages from Customer Service</title><link href="/2023/02/03/finclf_customer_service_category_en.html" rel="alternate" type="text/html" title="Categorize Chat Messages from Customer Service" /><published>2023-02-03T00:00:00+00:00</published><updated>2023-02-03T00:00:00+00:00</updated><id>/2023/02/03/finclf_customer_service_category_en</id><content type="html" xml:base="/2023/02/03/finclf_customer_service_category_en.html">## Description

This is a Text Classification model that can help you classify a chat message from customer service.

## Predicted Entities

`ACCOUNT`, `CANCELLATION_FEE`, `CONTACT`, `DELIVERY`, `FEEDBACK`, `INVOICE`, `NEWSLETTER`, `ORDER`, `PAYMENT`, `REFUND`, `SHIPPING_ADDRESS`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_customer_service_category_en_1.0.0_3.0_1675417487415.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_customer_service_category_en_1.0.0_3.0_1675417487415.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;sentence_embeddings&quot;)

docClassifier = finance.ClassifierDLModel.pretrained(&quot;finclf_customer_service_category&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols(&quot;sentence_embeddings&quot;) \
    .setOutputCol(&quot;class&quot;)

pipeline = nlp.Pipeline().setStages(
      [
        document_assembler,
        embeddings,
        docClassifier
      ]
    )

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = pipeline.fit(empty_data)
light_model = nlp.LightPipeline(model)

result = light_model.annotate(&quot;&quot;&quot;can I place an order from Finland?&quot;&quot;&quot;)

result[&quot;class&quot;]
```

&lt;/div&gt;

## Results

```bash
['DELIVERY']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_customer_service_category|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.7 MB|

## References

https://github.com/bitext/customer-support-intent-detection-evaluation-dataset

## Benchmarking

```bash
label             precision  recall  f1-score  support 
ACCOUNT           0.99       0.99    0.99      180     
CANCELLATION_FEE  1.00       1.00    1.00      30      
CONTACT           0.98       1.00    0.99      60      
DELIVERY          1.00       1.00    1.00      60      
FEEDBACK          0.97       0.95    0.96      60      
INVOICE           1.00       1.00    1.00      60      
NEWSLETTER        0.94       1.00    0.97      30      
ORDER             1.00       0.99    1.00      120     
OTHER             1.00       0.97    0.98      63      
PAYMENT           0.95       1.00    0.98      60      
REFUND            0.99       0.98    0.98      90      
SHIPPING_ADDRESS  1.00       0.98    0.99      60      
accuracy          -          -       0.99      973     
macro-avg         0.99       0.99    0.99      873     
weighted-avg      0.99       0.99    0.99      873  
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="finance" /><category term="customer" /><category term="classification" /><category term="tensorflow" /><summary type="html">Description This is a Text Classification model that can help you classify a chat message from customer service. Predicted Entities ACCOUNT, CANCELLATION_FEE, CONTACT, DELIVERY, FEEDBACK, INVOICE, NEWSLETTER, ORDER, PAYMENT, REFUND, SHIPPING_ADDRESS Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = finance.ClassifierDLModel.pretrained(&quot;finclf_customer_service_category&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols(&quot;sentence_embeddings&quot;) \ .setOutputCol(&quot;class&quot;) pipeline = nlp.Pipeline().setStages( [ document_assembler, embeddings, docClassifier ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) result = light_model.annotate(&quot;&quot;&quot;can I place an order from Finland?&quot;&quot;&quot;) result[&quot;class&quot;] Results ['DELIVERY'] Model Information Model Name: finclf_customer_service_category Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.7 MB References https://github.com/bitext/customer-support-intent-detection-evaluation-dataset Benchmarking label precision recall f1-score support ACCOUNT 0.99 0.99 0.99 180 CANCELLATION_FEE 1.00 1.00 1.00 30 CONTACT 0.98 1.00 0.99 60 DELIVERY 1.00 1.00 1.00 60 FEEDBACK 0.97 0.95 0.96 60 INVOICE 1.00 1.00 1.00 60 NEWSLETTER 0.94 1.00 0.97 30 ORDER 1.00 0.99 1.00 120 OTHER 1.00 0.97 0.98 63 PAYMENT 0.95 1.00 0.98 60 REFUND 0.99 0.98 0.98 90 SHIPPING_ADDRESS 1.00 0.98 0.99 60 accuracy - - 0.99 973 macro-avg 0.99 0.99 0.99 873 weighted-avg 0.99 0.99 0.99 873</summary></entry><entry><title type="html">Extract Intent Type from Customer Service Chat Messages</title><link href="/2023/02/03/finclf_customer_service_intent_type_en.html" rel="alternate" type="text/html" title="Extract Intent Type from Customer Service Chat Messages" /><published>2023-02-03T00:00:00+00:00</published><updated>2023-02-03T00:00:00+00:00</updated><id>/2023/02/03/finclf_customer_service_intent_type_en</id><content type="html" xml:base="/2023/02/03/finclf_customer_service_intent_type_en.html">## Description

This is a Text Classification model that can help you classify a chat message from customer service according to intent type.

## Predicted Entities

`cancel_order`, `change_order`, `change_setup_shipping_address`, `check_cancellation_fee`, `check_payment_methods`, `check_refund_policy`, `complaint`, `contact_customer_service`, `contact_human_agent`, `create_edit_switch_account`, `delete_account`, `delivery_options`, `delivery_period`, `get_check_invoice`, `get_refund`, `newsletter_subscription`, `payment_issue`, `place_order`, `recover_password`, `registration_problems`, `review`, `track_order`, `track_refund`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_customer_service_intent_type_en_1.0.0_3.0_1675427852317.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_customer_service_intent_type_en_1.0.0_3.0_1675427852317.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;sentence_embeddings&quot;)

docClassifier = finance.ClassifierDLModel.pretrained(&quot;finclf_customer_service_intent_type&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols(&quot;sentence_embeddings&quot;) \
    .setOutputCol(&quot;class&quot;)

pipeline = nlp.Pipeline().setStages(
      [
        document_assembler,
        embeddings,
        docClassifier
      ]
    )

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = pipeline.fit(empty_data)
light_model = nlp.LightPipeline(model)

result = light_model.annotate(&quot;&quot;&quot;I have a problem with the deletion of my Premium account.&quot;&quot;&quot;)

result[&quot;class&quot;]
```

&lt;/div&gt;

## Results

```bash
['delete_account']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_customer_service_intent_type|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.8 MB|

## References

https://github.com/bitext/customer-support-intent-detection-evaluation-dataset

## Benchmarking

```bash
label                          precision  recall  f1-score  support 
cancel_order                   0.88       1.00    0.94      30      
change_order                   1.00       0.90    0.95      30      
change_setup_shipping_address  0.97       0.97    0.97      36      
check_cancellation_fee         0.97       0.97    0.97      30      
check_payment_methods          0.97       0.93    0.95      30      
check_refund_policy            0.97       0.97    0.97      30      
complaint                      0.93       0.93    0.93      30      
contact_customer_service       1.00       1.00    1.00      30      
contact_human_agent            0.97       0.97    0.97      30      
create_edit_switch_account     0.90       0.97    0.93      36      
delete_account                 0.96       0.87    0.91      30      
delivery_options               0.91       1.00    0.95      30      
delivery_period                1.00       0.97    0.98      30      
get_check_invoice              0.92       0.97    0.95      36      
get_refund                     1.00       0.87    0.93      30      
newsletter_subscription        1.00       0.93    0.97      30      
other                          1.00       0.92    0.96      38      
payment_issue                  0.97       1.00    0.98      30      
place_order                    0.97       0.93    0.95      30      
recover_password               0.97       1.00    0.98      30      
registration_problems          1.00       0.97    0.98      30      
review                         0.94       1.00    0.97      30      
track_order                    0.93       0.93    0.93      30      
track_refund                   0.91       1.00    0.95      30      
accuracy                       -          -       0.96      746     
macro-avg                      0.96       0.96    0.96      746     
weighted-avg                   0.96       0.96    0.96      746      
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="intent" /><category term="finance" /><category term="customer" /><category term="tensorflow" /><summary type="html">Description This is a Text Classification model that can help you classify a chat message from customer service according to intent type. Predicted Entities cancel_order, change_order, change_setup_shipping_address, check_cancellation_fee, check_payment_methods, check_refund_policy, complaint, contact_customer_service, contact_human_agent, create_edit_switch_account, delete_account, delivery_options, delivery_period, get_check_invoice, get_refund, newsletter_subscription, payment_issue, place_order, recover_password, registration_problems, review, track_order, track_refund, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = finance.ClassifierDLModel.pretrained(&quot;finclf_customer_service_intent_type&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols(&quot;sentence_embeddings&quot;) \ .setOutputCol(&quot;class&quot;) pipeline = nlp.Pipeline().setStages( [ document_assembler, embeddings, docClassifier ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) result = light_model.annotate(&quot;&quot;&quot;I have a problem with the deletion of my Premium account.&quot;&quot;&quot;) result[&quot;class&quot;] Results ['delete_account'] Model Information Model Name: finclf_customer_service_intent_type Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.8 MB References https://github.com/bitext/customer-support-intent-detection-evaluation-dataset Benchmarking label precision recall f1-score support cancel_order 0.88 1.00 0.94 30 change_order 1.00 0.90 0.95 30 change_setup_shipping_address 0.97 0.97 0.97 36 check_cancellation_fee 0.97 0.97 0.97 30 check_payment_methods 0.97 0.93 0.95 30 check_refund_policy 0.97 0.97 0.97 30 complaint 0.93 0.93 0.93 30 contact_customer_service 1.00 1.00 1.00 30 contact_human_agent 0.97 0.97 0.97 30 create_edit_switch_account 0.90 0.97 0.93 36 delete_account 0.96 0.87 0.91 30 delivery_options 0.91 1.00 0.95 30 delivery_period 1.00 0.97 0.98 30 get_check_invoice 0.92 0.97 0.95 36 get_refund 1.00 0.87 0.93 30 newsletter_subscription 1.00 0.93 0.97 30 other 1.00 0.92 0.96 38 payment_issue 0.97 1.00 0.98 30 place_order 0.97 0.93 0.95 30 recover_password 0.97 1.00 0.98 30 registration_problems 1.00 0.97 0.98 30 review 0.94 1.00 0.97 30 track_order 0.93 0.93 0.93 30 track_refund 0.91 1.00 0.95 30 accuracy - - 0.96 746 macro-avg 0.96 0.96 0.96 746 weighted-avg 0.96 0.96 0.96 746</summary></entry><entry><title type="html">Multilabel Classification of Customer Service (Linguistic features)</title><link href="/2023/02/03/finmulticlf_customer_service_lin_features_en.html" rel="alternate" type="text/html" title="Multilabel Classification of Customer Service (Linguistic features)" /><published>2023-02-03T00:00:00+00:00</published><updated>2023-02-03T00:00:00+00:00</updated><id>/2023/02/03/finmulticlf_customer_service_lin_features_en</id><content type="html" xml:base="/2023/02/03/finmulticlf_customer_service_lin_features_en.html">## Description

This is a Multilabel Text Classification model that can help you classify a chat message from customer service according to linguistic features. The classes are the following:
 - Q - Colloquial variation
 - P - Politeness variation
 - W - Offensive language
 - K - Keyword language
 - B - Basic syntactic structure
 - C - Coordinated syntactic structure
 - I - Interrogative structure
 - M - Morphological variation (plurals, tenses…)
 - L - Lexical variation (synonyms)
 - E - Expanded abbreviations (I'm -&gt; I am, I'd -&gt; I would…)
 - N - Negation
 - Z - Noise phenomena like spelling or punctuation errors

## Predicted Entities

`B`, `C`, `E`, `I`, `K`, `L`, `M`, `N`, `P`, `Q`, `W`, `Z`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finmulticlf_customer_service_lin_features_en_1.0.0_3.0_1675430237309.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finmulticlf_customer_service_lin_features_en_1.0.0_3.0_1675430237309.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;sentence_embeddings&quot;)

docClassifier = nlp.MultiClassifierDLModel().load(&quot;finmulticlf_customer_service_lin_features&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols(&quot;sentence_embeddings&quot;) \
    .setOutputCol(&quot;class&quot;)

pipeline = nlp.Pipeline().setStages(
      [
        document_assembler,
        embeddings,
        docClassifier
      ]
    )

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = pipeline.fit(empty_data)
light_model = nlp.LightPipeline(model)

result = light_model.annotate(&quot;&quot;&quot;What do i have to ddo to cancel a Gold account&quot;&quot;&quot;)

result[&quot;class&quot;]
```

&lt;/div&gt;

## Results

```bash
['Q', 'B', 'L', 'Z', 'I']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finmulticlf_customer_service_lin_features|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|13.0 MB|

## References

https://github.com/bitext/customer-support-intent-detection-training-dataset

## Benchmarking

```bash
label         precision  recall  f1-score  support 
B             1.00       1.00    1.00      485     
C             0.79       0.80    0.80      61      
E             0.74       0.89    0.80      44      
I             0.95       0.94    0.94      134     
K             0.96       0.96    0.96      108     
L             0.96       0.97    0.96      402     
M             0.93       0.93    0.93      134     
N             0.90       0.75    0.82      12      
P             0.77       0.90    0.83      30      
Q             0.73       0.68    0.71      212     
W             0.85       0.88    0.87      33      
Z             0.68       0.72    0.70      160     
micro-avg     0.90       0.90    0.90      1815    
macro-avg     0.85       0.87    0.86      1815    
weighted-avg  0.90       0.90    0.90      1815    
samples-avg   0.91       0.92    0.90      1815   
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="finance" /><category term="classification" /><category term="customer" /><category term="linguistic" /><category term="tensorflow" /><summary type="html">Description This is a Multilabel Text Classification model that can help you classify a chat message from customer service according to linguistic features. The classes are the following: Q - Colloquial variation P - Politeness variation W - Offensive language K - Keyword language B - Basic syntactic structure C - Coordinated syntactic structure I - Interrogative structure M - Morphological variation (plurals, tenses…) L - Lexical variation (synonyms) E - Expanded abbreviations (I’m -&amp;gt; I am, I’d -&amp;gt; I would…) N - Negation Z - Noise phenomena like spelling or punctuation errors Predicted Entities B, C, E, I, K, L, M, N, P, Q, W, Z Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = nlp.MultiClassifierDLModel().load(&quot;finmulticlf_customer_service_lin_features&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols(&quot;sentence_embeddings&quot;) \ .setOutputCol(&quot;class&quot;) pipeline = nlp.Pipeline().setStages( [ document_assembler, embeddings, docClassifier ] ) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) light_model = nlp.LightPipeline(model) result = light_model.annotate(&quot;&quot;&quot;What do i have to ddo to cancel a Gold account&quot;&quot;&quot;) result[&quot;class&quot;] Results ['Q', 'B', 'L', 'Z', 'I'] Model Information Model Name: finmulticlf_customer_service_lin_features Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 13.0 MB References https://github.com/bitext/customer-support-intent-detection-training-dataset Benchmarking label precision recall f1-score support B 1.00 1.00 1.00 485 C 0.79 0.80 0.80 61 E 0.74 0.89 0.80 44 I 0.95 0.94 0.94 134 K 0.96 0.96 0.96 108 L 0.96 0.97 0.96 402 M 0.93 0.93 0.93 134 N 0.90 0.75 0.82 12 P 0.77 0.90 0.83 30 Q 0.73 0.68 0.71 212 W 0.85 0.88 0.87 33 Z 0.68 0.72 0.70 160 micro-avg 0.90 0.90 0.90 1815 macro-avg 0.85 0.87 0.86 1815 weighted-avg 0.90 0.90 0.90 1815 samples-avg 0.91 0.92 0.90 1815</summary></entry><entry><title type="html">Legal Acquisition Agreement Document Classifier (Bert Sentence Embeddings)</title><link href="/2023/02/02/legclf_acquisition_agreement_bert_en.html" rel="alternate" type="text/html" title="Legal Acquisition Agreement Document Classifier (Bert Sentence Embeddings)" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>/2023/02/02/legclf_acquisition_agreement_bert_en</id><content type="html" xml:base="/2023/02/02/legclf_acquisition_agreement_bert_en.html">## Description

The `legclf_acquisition_agreement_bert` model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class `acquisition-agreement` (check [Lawinsider](https://www.lawinsider.com/tags) for similar document type classification) or not (Binary Classification).

Unlike the Longformer model, this model is lighter in terms of inference time.

## Predicted Entities

`acquisition-agreement`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_acquisition_agreement_bert_en_1.0.0_3.0_1675360092921.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_acquisition_agreement_bert_en_1.0.0_3.0_1675360092921.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
  
embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence_embeddings&quot;)
    
doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_acquisition_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;category&quot;)
    
nlpPipeline = nlp.Pipeline(stages=[
    document_assembler, 
    embeddings,
    doc_classifier])
 
df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

```

&lt;/div&gt;

## Results

```bash

+-------+
|result|
+-------+
|[acquisition-agreement]|
|[other]|
|[other]|
|[acquisition-agreement]|

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_acquisition_agreement_bert|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.7 MB|

## References

Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization

## Benchmarking

```bash
                label  precision    recall  f1-score   support
acquisition-agreement       0.91      0.91      0.91        33
                other       0.96      0.96      0.96        73
             accuracy          -         -      0.94       106
            macro-avg       0.93      0.93      0.93       106
         weighted-avg       0.94      0.94      0.94       106
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="classification" /><category term="acquisition" /><category term="agreement" /><category term="licensed" /><category term="bert" /><category term="tensorflow" /><summary type="html">Description The legclf_acquisition_agreement_bert model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class acquisition-agreement (check Lawinsider for similar document type classification) or not (Binary Classification). Unlike the Longformer model, this model is lighter in terms of inference time. Predicted Entities acquisition-agreement, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence_embeddings&quot;) doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_acquisition_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, embeddings, doc_classifier]) df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) Results +-------+ |result| +-------+ |[acquisition-agreement]| |[other]| |[other]| |[acquisition-agreement]| Model Information Model Name: legclf_acquisition_agreement_bert Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.7 MB References Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization Benchmarking label precision recall f1-score support acquisition-agreement 0.91 0.91 0.91 33 other 0.96 0.96 0.96 73 accuracy - - 0.94 106 macro-avg 0.93 0.93 0.93 106 weighted-avg 0.94 0.94 0.94 106</summary></entry><entry><title type="html">Legal Forbearance Agreement Document Classifier (Bert Sentence Embeddings)</title><link href="/2023/02/02/legclf_forbearance_agreement_bert_en.html" rel="alternate" type="text/html" title="Legal Forbearance Agreement Document Classifier (Bert Sentence Embeddings)" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>/2023/02/02/legclf_forbearance_agreement_bert_en</id><content type="html" xml:base="/2023/02/02/legclf_forbearance_agreement_bert_en.html">## Description

The `legclf_forbearance_agreement_bert` model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class `forbearance-agreement` (check [Lawinsider](https://www.lawinsider.com/tags) for similar document type classification) or not (Binary Classification).

Unlike the Longformer model, this model is lighter in terms of inference time.

## Predicted Entities

`forbearance-agreement`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_forbearance_agreement_bert_en_1.0.0_3.0_1675359983427.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_forbearance_agreement_bert_en_1.0.0_3.0_1675359983427.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
  
embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence_embeddings&quot;)
    
doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_forbearance_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;category&quot;)
    
nlpPipeline = nlp.Pipeline(stages=[
    document_assembler, 
    embeddings,
    doc_classifier])
 
df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

```

&lt;/div&gt;

## Results

```bash

+-------+
|result|
+-------+
|[forbearance-agreement]|
|[other]|
|[other]|
|[forbearance-agreement]|

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_forbearance_agreement_bert|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.5 MB|

## References

Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization

## Benchmarking

```bash
                label  precision    recall  f1-score   support
forbearance-agreement       0.97      1.00      0.99        37
                other       1.00      0.99      0.99        73
             accuracy          -         -      0.99       110
            macro-avg       0.99      0.99      0.99       110
         weighted-avg       0.99      0.99      0.99       110
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="classification" /><category term="forbearance" /><category term="agreement" /><category term="licensed" /><category term="bert" /><category term="tensorflow" /><summary type="html">Description The legclf_forbearance_agreement_bert model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class forbearance-agreement (check Lawinsider for similar document type classification) or not (Binary Classification). Unlike the Longformer model, this model is lighter in terms of inference time. Predicted Entities forbearance-agreement, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence_embeddings&quot;) doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_forbearance_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, embeddings, doc_classifier]) df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) Results +-------+ |result| +-------+ |[forbearance-agreement]| |[other]| |[other]| |[forbearance-agreement]| Model Information Model Name: legclf_forbearance_agreement_bert Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.5 MB References Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization Benchmarking label precision recall f1-score support forbearance-agreement 0.97 1.00 0.99 37 other 1.00 0.99 0.99 73 accuracy - - 0.99 110 macro-avg 0.99 0.99 0.99 110 weighted-avg 0.99 0.99 0.99 110</summary></entry><entry><title type="html">Legal Limited Liability Company Operating Agreement Document Classifier (Bert Sentence Embeddings)</title><link href="/2023/02/02/legclf_limited_liability_company_operating_agreement_bert_en.html" rel="alternate" type="text/html" title="Legal Limited Liability Company Operating Agreement Document Classifier (Bert Sentence Embeddings)" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>/2023/02/02/legclf_limited_liability_company_operating_agreement_bert_en</id><content type="html" xml:base="/2023/02/02/legclf_limited_liability_company_operating_agreement_bert_en.html">## Description

The `legclf_limited_liability_company_operating_agreement_bert` model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class `limited-liability-company-operating-agreement` (check [Lawinsider](https://www.lawinsider.com/tags) for similar document type classification) or not (Binary Classification).

Unlike the Longformer model, this model is lighter in terms of inference time.

## Predicted Entities

`limited-liability-company-operating-agreement`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_limited_liability_company_operating_agreement_bert_en_1.0.0_3.0_1675360839682.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_limited_liability_company_operating_agreement_bert_en_1.0.0_3.0_1675360839682.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
  
embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence_embeddings&quot;)
    
doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_limited_liability_company_operating_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;category&quot;)
    
nlpPipeline = nlp.Pipeline(stages=[
    document_assembler, 
    embeddings,
    doc_classifier])
 
df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

```

&lt;/div&gt;

## Results

```bash

+-------+
|result|
+-------+
|[limited-liability-company-operating-agreement]|
|[other]|
|[other]|
|[limited-liability-company-operating-agreement]|

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_limited_liability_company_operating_agreement_bert|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.6 MB|

## References

Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization

## Benchmarking

```bash
                                        label  precision    recall  f1-score   support
limited-liability-company-operating-agreement       1.00      0.94      0.97        53
                                        other       0.98      1.00      0.99       122
                                     accuracy          -         -      0.98       175
                                    macro-avg       0.99      0.97      0.98       175
                                 weighted-avg       0.98      0.98      0.98       175
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="classification" /><category term="limited" /><category term="liability" /><category term="company" /><category term="operating" /><category term="agreement" /><category term="licensed" /><category term="bert" /><category term="tensorflow" /><summary type="html">Description The legclf_limited_liability_company_operating_agreement_bert model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class limited-liability-company-operating-agreement (check Lawinsider for similar document type classification) or not (Binary Classification). Unlike the Longformer model, this model is lighter in terms of inference time. Predicted Entities limited-liability-company-operating-agreement, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence_embeddings&quot;) doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_limited_liability_company_operating_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, embeddings, doc_classifier]) df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) Results +-------+ |result| +-------+ |[limited-liability-company-operating-agreement]| |[other]| |[other]| |[limited-liability-company-operating-agreement]| Model Information Model Name: legclf_limited_liability_company_operating_agreement_bert Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.6 MB References Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization Benchmarking label precision recall f1-score support limited-liability-company-operating-agreement 1.00 0.94 0.97 53 other 0.98 1.00 0.99 122 accuracy - - 0.98 175 macro-avg 0.99 0.97 0.98 175 weighted-avg 0.98 0.98 0.98 175</summary></entry><entry><title type="html">Legal Nonstatutory Stock Option Agreement Document Classifier (Bert Sentence Embeddings)</title><link href="/2023/02/02/legclf_nonstatutory_stock_option_agreement_bert_en.html" rel="alternate" type="text/html" title="Legal Nonstatutory Stock Option Agreement Document Classifier (Bert Sentence Embeddings)" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>/2023/02/02/legclf_nonstatutory_stock_option_agreement_bert_en</id><content type="html" xml:base="/2023/02/02/legclf_nonstatutory_stock_option_agreement_bert_en.html">## Description

The `legclf_nonstatutory_stock_option_agreement_bert` model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class `nonstatutory-stock-option-agreement` (check [Lawinsider](https://www.lawinsider.com/tags) for similar document type classification) or not (Binary Classification).

Unlike the Longformer model, this model is lighter in terms of inference time.

## Predicted Entities

`nonstatutory-stock-option-agreement`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_nonstatutory_stock_option_agreement_bert_en_1.0.0_3.0_1675360953793.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_nonstatutory_stock_option_agreement_bert_en_1.0.0_3.0_1675360953793.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
  
embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence_embeddings&quot;)
    
doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_nonstatutory_stock_option_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;category&quot;)
    
nlpPipeline = nlp.Pipeline(stages=[
    document_assembler, 
    embeddings,
    doc_classifier])
 
df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

```

&lt;/div&gt;

## Results

```bash

+-------+
|result|
+-------+
|[nonstatutory-stock-option-agreement]|
|[other]|
|[other]|
|[nonstatutory-stock-option-agreement]|

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_nonstatutory_stock_option_agreement_bert|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.5 MB|

## References

Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization

## Benchmarking

```bash
                              label  precision    recall  f1-score   support
nonstatutory-stock-option-agreement       0.98      0.96      0.97        53
                              other       0.98      0.99      0.99       122
                           accuracy          -         -      0.98       175
                          macro-avg       0.98      0.98      0.98       175
                       weighted-avg       0.98      0.98      0.98       175
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="classification" /><category term="nonstatutory" /><category term="stock" /><category term="option" /><category term="agreement" /><category term="licensed" /><category term="bert" /><category term="tensorflow" /><summary type="html">Description The legclf_nonstatutory_stock_option_agreement_bert model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class nonstatutory-stock-option-agreement (check Lawinsider for similar document type classification) or not (Binary Classification). Unlike the Longformer model, this model is lighter in terms of inference time. Predicted Entities nonstatutory-stock-option-agreement, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence_embeddings&quot;) doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_nonstatutory_stock_option_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, embeddings, doc_classifier]) df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) Results +-------+ |result| +-------+ |[nonstatutory-stock-option-agreement]| |[other]| |[other]| |[nonstatutory-stock-option-agreement]| Model Information Model Name: legclf_nonstatutory_stock_option_agreement_bert Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.5 MB References Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization Benchmarking label precision recall f1-score support nonstatutory-stock-option-agreement 0.98 0.96 0.97 53 other 0.98 0.99 0.99 122 accuracy - - 0.98 175 macro-avg 0.98 0.98 0.98 175 weighted-avg 0.98 0.98 0.98 175</summary></entry><entry><title type="html">Legal Private Placement Warrants Purchase Agreement Document Classifier (Bert Sentence Embeddings)</title><link href="/2023/02/02/legclf_private_placement_warrants_purchase_agreement_bert_en.html" rel="alternate" type="text/html" title="Legal Private Placement Warrants Purchase Agreement Document Classifier (Bert Sentence Embeddings)" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>/2023/02/02/legclf_private_placement_warrants_purchase_agreement_bert_en</id><content type="html" xml:base="/2023/02/02/legclf_private_placement_warrants_purchase_agreement_bert_en.html">## Description

The `legclf_private_placement_warrants_purchase_agreement_bert` model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class `private-placement-warrants-purchase-agreement` (check [Lawinsider](https://www.lawinsider.com/tags) for similar document type classification) or not (Binary Classification).

Unlike the Longformer model, this model is lighter in terms of inference time.

## Predicted Entities

`private-placement-warrants-purchase-agreement`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_private_placement_warrants_purchase_agreement_bert_en_1.0.0_3.0_1675360216586.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_private_placement_warrants_purchase_agreement_bert_en_1.0.0_3.0_1675360216586.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
  
embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence_embeddings&quot;)
    
doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_private_placement_warrants_purchase_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;category&quot;)
    
nlpPipeline = nlp.Pipeline(stages=[
    document_assembler, 
    embeddings,
    doc_classifier])
 
df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

```

&lt;/div&gt;

## Results

```bash

+-------+
|result|
+-------+
|[private-placement-warrants-purchase-agreement]|
|[other]|
|[other]|
|[private-placement-warrants-purchase-agreement]|

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_private_placement_warrants_purchase_agreement_bert|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.1 MB|

## References

Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization

## Benchmarking

```bash
                                        label  precision    recall  f1-score   support
                                        other       1.00      1.00      1.00        99
private-placement-warrants-purchase-agreement       1.00      1.00      1.00        42
                                     accuracy          -         -      1.00       141
                                    macro-avg       1.00      1.00      1.00       141
                                 weighted-avg       1.00      1.00      1.00       141
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="classification" /><category term="private" /><category term="placement" /><category term="warrants" /><category term="purchase" /><category term="agreement" /><category term="licensed" /><category term="bert" /><category term="tensorflow" /><summary type="html">Description The legclf_private_placement_warrants_purchase_agreement_bert model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class private-placement-warrants-purchase-agreement (check Lawinsider for similar document type classification) or not (Binary Classification). Unlike the Longformer model, this model is lighter in terms of inference time. Predicted Entities private-placement-warrants-purchase-agreement, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence_embeddings&quot;) doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_private_placement_warrants_purchase_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, embeddings, doc_classifier]) df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) Results +-------+ |result| +-------+ |[private-placement-warrants-purchase-agreement]| |[other]| |[other]| |[private-placement-warrants-purchase-agreement]| Model Information Model Name: legclf_private_placement_warrants_purchase_agreement_bert Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.1 MB References Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization Benchmarking label precision recall f1-score support other 1.00 1.00 1.00 99 private-placement-warrants-purchase-agreement 1.00 1.00 1.00 42 accuracy - - 1.00 141 macro-avg 1.00 1.00 1.00 141 weighted-avg 1.00 1.00 1.00 141</summary></entry><entry><title type="html">Legal Sales Agreement Document Classifier (Bert Sentence Embeddings)</title><link href="/2023/02/02/legclf_sales_agreement_bert_en.html" rel="alternate" type="text/html" title="Legal Sales Agreement Document Classifier (Bert Sentence Embeddings)" /><published>2023-02-02T00:00:00+00:00</published><updated>2023-02-02T00:00:00+00:00</updated><id>/2023/02/02/legclf_sales_agreement_bert_en</id><content type="html" xml:base="/2023/02/02/legclf_sales_agreement_bert_en.html">## Description

The `legclf_sales_agreement_bert` model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class `sales-agreement` (check [Lawinsider](https://www.lawinsider.com/tags) for similar document type classification) or not (Binary Classification).

Unlike the Longformer model, this model is lighter in terms of inference time.

## Predicted Entities

`sales-agreement`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_sales_agreement_bert_en_1.0.0_3.0_1675359477213.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_sales_agreement_bert_en_1.0.0_3.0_1675359477213.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python

document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)
  
embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence_embeddings&quot;)
    
doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_sales_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;category&quot;)
    
nlpPipeline = nlp.Pipeline(stages=[
    document_assembler, 
    embeddings,
    doc_classifier])
 
df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

```

&lt;/div&gt;

## Results

```bash

+-------+
|result|
+-------+
|[sales-agreement]|
|[other]|
|[other]|
|[sales-agreement]|

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_sales_agreement_bert|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.4 MB|

## References

Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization

## Benchmarking

```bash
          label  precision    recall  f1-score   support
          other       0.88      0.93      0.90       122
sales-agreement       0.84      0.76      0.80        63
       accuracy          -         -      0.87       185
      macro-avg       0.86      0.84      0.85       185
   weighted-avg       0.87      0.87      0.87       185
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="legal" /><category term="classification" /><category term="sales" /><category term="agreement" /><category term="licensed" /><category term="bert" /><category term="tensorflow" /><summary type="html">Description The legclf_sales_agreement_bert model is a Bert Sentence Embeddings Document Classifier used to classify if the document belongs to the class sales-agreement (check Lawinsider for similar document type classification) or not (Binary Classification). Unlike the Longformer model, this model is lighter in terms of inference time. Predicted Entities sales-agreement, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence_embeddings&quot;) doc_classifier = legal.ClassifierDLModel.pretrained(&quot;legclf_sales_agreement_bert&quot;, &quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ document_assembler, embeddings, doc_classifier]) df = spark.createDataFrame([[&quot;YOUR TEXT HERE&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) Results +-------+ |result| +-------+ |[sales-agreement]| |[other]| |[other]| |[sales-agreement]| Model Information Model Name: legclf_sales_agreement_bert Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.4 MB References Legal documents, scrapped from the Internet, and classified in-house + SEC documents + Lawinsider categorization Benchmarking label precision recall f1-score support other 0.88 0.93 0.90 122 sales-agreement 0.84 0.76 0.80 63 accuracy - - 0.87 185 macro-avg 0.86 0.84 0.85 185 weighted-avg 0.87 0.87 0.87 185</summary></entry></feed>