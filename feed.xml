<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-02-13T16:14:23+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Social Determinants of Health</title><link href="/2023/02/11/ner_sdoh_wip_en.html" rel="alternate" type="text/html" title="Social Determinants of Health" /><published>2023-02-11T00:00:00+00:00</published><updated>2023-02-11T00:00:00+00:00</updated><id>/2023/02/11/ner_sdoh_wip_en</id><content type="html" xml:base="/2023/02/11/ner_sdoh_wip_en.html">## Description

This model extracts terminology related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Other_SDoH_Keywords`, `Education`, `Population_Group`, `Quality_Of_Life`, `Housing`, `Substance_Frequency`, `Smoking`, `Eating_Disorder`, `Obesity`, `Healthcare_Institution`, `Financial_Status`, `Age`, `Chidhood_Event`, `Exercise`, `Communicable_Disease`, `Hypertension`, `Other_Disease`, `Violence_Or_Abuse`, `Spiritual_Beliefs`, `Employment`, `Social_Exclusion`, `Access_To_Care`, `Marital_Status`, `Diet`, `Social_Support`, `Disability`, `Mental_Health`, `Alcohol`, `Insurance_Status`, `Substance_Quantity`, `Hyperlipidemia`, `Family_Member`, `Legal_Issues`, `Race_Ethnicity`, `Gender`, `Geographic_Entity`, `Sexual_Orientation`, `Transportation`, `Sexual_Activity`, `Language`, `Substance_Use`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_wip_en_4.2.8_3.0_1676135569606.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_wip_en_4.2.8_3.0_1676135569606.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [[&quot;Smith is a 55 years old, divorced Mexcian American woman with financial problems. She speaks spanish. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave. She has a son student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reprots having her catholic faith as a means of support as well.Â  She has long history of etoh abuse, beginning in her teens. She reports she has been a daily drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI back in April and was due to be in court this week.&quot;]]
             
data = spark.createDataFrame(sample_texts).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;He continues to smoke one pack of cigarettes daily, as he has for the past 28 years.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+------------------+-----+---+-------------------+
|chunk             |begin|end|ner_label          |
+------------------+-----+---+-------------------+
|55 years old      |11   |22 |Age                |
|divorced          |25   |32 |Marital_Status     |
|Mexcian American  |34   |49 |Race_Ethnicity     |
|woman             |51   |55 |Gender             |
|financial problems|62   |79 |Financial_Status   |
|She               |82   |84 |Gender             |
|spanish           |93   |99 |Language           |
|She               |102  |104|Gender             |
|apartment         |118  |126|Housing            |
|She               |129  |131|Gender             |
|diabetes          |158  |165|Other_Disease      |
|cleaning assistant|307  |324|Employment         |
|health insurance  |354  |369|Insurance_Status   |
|She               |391  |393|Gender             |
|son               |401  |403|Family_Member      |
|student           |405  |411|Education          |
|college           |416  |422|Education          |
|depression        |454  |463|Mental_Health      |
|She               |466  |468|Gender             |
|she               |479  |481|Gender             |
|rehab             |489  |493|Access_To_Care     |
|her               |514  |516|Gender             |
|catholic faith    |518  |531|Spiritual_Beliefs  |
|support           |547  |553|Social_Support     |
|She               |565  |567|Gender             |
|etoh abuse        |589  |598|Alcohol            |
|her               |614  |616|Gender             |
|teens             |618  |622|Age                |
|She               |625  |627|Gender             |
|she               |637  |639|Gender             |
|drinker           |658  |664|Alcohol            |
|drinking beer     |694  |706|Alcohol            |
|daily             |708  |712|Substance_Frequency|
|She               |715  |717|Gender             |
|smokes            |719  |724|Smoking            |
|a pack            |726  |731|Substance_Quantity |
|cigarettes        |736  |745|Smoking            |
|a day             |747  |751|Substance_Frequency|
|She               |754  |756|Gender             |
|DUI               |762  |764|Legal_Issues       |
+------------------+-----+---+-------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_wip|
|Compatibility:|Healthcare NLP 4.2.8+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|1.5 MB|

## Benchmarking

```bash
                 label	    tp	   fp	    fn	 total precision	  recall	      f1
   Other_SDoH_Keywords	 317.0	 84.0	 112.0	 429.0	0.790524	0.738928	0.763855
             Education	 116.0	 38.0	  31.0	 147.0	0.753247	0.789116	0.770764
      Population_Group	  27.0	  4.0	  11.0	  38.0	0.870968	0.710526	0.782609
       Quality_Of_Life	 146.0	 37.0	  57.0	 203.0	0.797814	0.719212	0.756477
               Housing	 809.0	 91.0	 118.0	 927.0	0.898889	0.872708	0.885605
   Substance_Frequency	  74.0	 19.0	  44.0	 118.0	0.795699	0.627119	0.701422
               Smoking	 136.0	  4.0	   2.0	 138.0	0.971429	0.985507	0.978417
       Eating_Disorder	  40.0	  2.0	   0.0	  40.0	0.952381	1.000000	0.975610
               Obesity	  16.0	  1.0	   5.0	  21.0	0.941176	0.761905	0.842105
Healthcare_Institution	 117.0	 36.0	  57.0	 174.0	0.764706	0.672414	0.715596
      Financial_Status	 222.0	 47.0	 128.0	 350.0	0.825279	0.634286	0.717286
                   Age	1328.0	109.0	  48.0	1376.0	0.924148	0.965116	0.944188
        Chidhood_Event	  30.0	  0.0	  24.0	  54.0	1.000000	0.555556	0.714286
              Exercise	  52.0	 17.0	  31.0	  83.0	0.753623	0.626506	0.684211
  Communicable_Disease	  61.0	  5.0	  10.0	  71.0	0.924242	0.859155	0.890511
          Hypertension	  45.0	  1.0	  12.0	  57.0	0.978261	0.789474	0.873786
         Other_Disease	1065.0	229.0	 119.0	1184.0	0.823029	0.899493	0.859564
     Violence_Or_Abuse	  98.0	 26.0	  53.0	 151.0	0.790323	0.649007	0.712727
     Spiritual_Beliefs	  94.0	  9.0	  21.0	 115.0	0.912621	0.817391	0.862385
            Employment	3797.0	272.0	 288.0	4085.0	0.933153	0.929498	0.931322
      Social_Exclusion	  38.0	  6.0	  14.0	  52.0	0.863636	0.730769	0.791667
        Access_To_Care	 810.0	 95.0	 160.0	 970.0	0.895028	0.835052	0.864000
        Marital_Status	 177.0	  4.0	   9.0	 186.0	0.977901	0.951613	0.964578
                  Diet	 110.0	 34.0	  30.0	 140.0	0.763889	0.785714	0.774648
        Social_Support	1243.0	197.0	  99.0	1342.0	0.863194	0.926230	0.893602
            Disability	  94.0	  4.0	   9.0	 103.0	0.959184	0.912621	0.935323
         Mental_Health	 817.0	 99.0	 216.0	1033.0	0.891921	0.790900	0.838379
               Alcohol	 592.0	 32.0	  28.0	 620.0	0.948718	0.954839	0.951768
      Insurance_Status	 145.0	 23.0	  32.0	 177.0	0.863095	0.819209	0.840580
    Substance_Quantity	 107.0	 42.0	  39.0	 146.0	0.718121	0.732877	0.725424
        Hyperlipidemia	  14.0	  1.0	   2.0	  16.0	0.933333	0.875000	0.903226
         Family_Member	4255.0	110.0	  73.0	4328.0	0.974800	0.983133	0.978949
          Legal_Issues	  71.0	 13.0	  20.0	  91.0	0.845238	0.780220	0.811429
        Race_Ethnicity	  81.0	  9.0	   7.0	  88.0	0.900000	0.920455	0.910112
                Gender	9698.0	183.0	 193.0	9891.0	0.981480	0.980487	0.980983
     Geographic_Entity	 189.0	 18.0	  22.0	 211.0	0.913043	0.895735	0.904306
    Sexual_Orientation	  21.0	  0.0	   3.0	  24.0	1.000000	0.875000	0.933333
        Transportation	  27.0	  2.0	  27.0	  54.0	0.931034	0.500000	0.650602
       Sexual_Activity	  56.0	  4.0	  24.0	  80.0	0.933333	0.700000	0.800000
              Language	  35.0	  6.0	   2.0	  37.0	0.853659	0.945946	0.897436
         Substance_Use	 400.0	 40.0	  24.0	 424.0	0.909091	0.943396	0.925926
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="clinical" /><category term="en" /><category term="social_determinants" /><category term="ner" /><category term="public_health" /><category term="sdoh" /><summary type="html">Description This model extracts terminology related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Other_SDoH_Keywords, Education, Population_Group, Quality_Of_Life, Housing, Substance_Frequency, Smoking, Eating_Disorder, Obesity, Healthcare_Institution, Financial_Status, Age, Chidhood_Event, Exercise, Communicable_Disease, Hypertension, Other_Disease, Violence_Or_Abuse, Spiritual_Beliefs, Employment, Social_Exclusion, Access_To_Care, Marital_Status, Diet, Social_Support, Disability, Mental_Health, Alcohol, Insurance_Status, Substance_Quantity, Hyperlipidemia, Family_Member, Legal_Issues, Race_Ethnicity, Gender, Geographic_Entity, Sexual_Orientation, Transportation, Sexual_Activity, Language, Substance_Use Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [[&quot;Smith is a 55 years old, divorced Mexcian American woman with financial problems. She speaks spanish. She lives in an apartment. She has been struggling with diabetes for the past 10 years and has recently been experiencing frequent hospitalizations due to uncontrolled blood sugar levels. Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave. She has a son student at college. Pt with likely long-standing depression. She is aware she needs rehab. Pt reprots having her catholic faith as a means of support as well.Â  She has long history of etoh abuse, beginning in her teens. She reports she has been a daily drinker for 30 years, most recently drinking beer daily. She smokes a pack of cigarettes a day. She had DUI back in April and was due to be in court this week.&quot;]] data = spark.createDataFrame(sample_texts).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;He continues to smoke one pack of cigarettes daily, as he has for the past 28 years.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +------------------+-----+---+-------------------+ |chunk |begin|end|ner_label | +------------------+-----+---+-------------------+ |55 years old |11 |22 |Age | |divorced |25 |32 |Marital_Status | |Mexcian American |34 |49 |Race_Ethnicity | |woman |51 |55 |Gender | |financial problems|62 |79 |Financial_Status | |She |82 |84 |Gender | |spanish |93 |99 |Language | |She |102 |104|Gender | |apartment |118 |126|Housing | |She |129 |131|Gender | |diabetes |158 |165|Other_Disease | |cleaning assistant|307 |324|Employment | |health insurance |354 |369|Insurance_Status | |She |391 |393|Gender | |son |401 |403|Family_Member | |student |405 |411|Education | |college |416 |422|Education | |depression |454 |463|Mental_Health | |She |466 |468|Gender | |she |479 |481|Gender | |rehab |489 |493|Access_To_Care | |her |514 |516|Gender | |catholic faith |518 |531|Spiritual_Beliefs | |support |547 |553|Social_Support | |She |565 |567|Gender | |etoh abuse |589 |598|Alcohol | |her |614 |616|Gender | |teens |618 |622|Age | |She |625 |627|Gender | |she |637 |639|Gender | |drinker |658 |664|Alcohol | |drinking beer |694 |706|Alcohol | |daily |708 |712|Substance_Frequency| |She |715 |717|Gender | |smokes |719 |724|Smoking | |a pack |726 |731|Substance_Quantity | |cigarettes |736 |745|Smoking | |a day |747 |751|Substance_Frequency| |She |754 |756|Gender | |DUI |762 |764|Legal_Issues | +------------------+-----+---+-------------------+ Model Information Model Name: ner_sdoh_wip Compatibility: Healthcare NLP 4.2.8+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 1.5 MB Benchmarking label tp fp fn total precision recall f1 Other_SDoH_Keywords 317.0 84.0 112.0 429.0 0.790524 0.738928 0.763855 Education 116.0 38.0 31.0 147.0 0.753247 0.789116 0.770764 Population_Group 27.0 4.0 11.0 38.0 0.870968 0.710526 0.782609 Quality_Of_Life 146.0 37.0 57.0 203.0 0.797814 0.719212 0.756477 Housing 809.0 91.0 118.0 927.0 0.898889 0.872708 0.885605 Substance_Frequency 74.0 19.0 44.0 118.0 0.795699 0.627119 0.701422 Smoking 136.0 4.0 2.0 138.0 0.971429 0.985507 0.978417 Eating_Disorder 40.0 2.0 0.0 40.0 0.952381 1.000000 0.975610 Obesity 16.0 1.0 5.0 21.0 0.941176 0.761905 0.842105 Healthcare_Institution 117.0 36.0 57.0 174.0 0.764706 0.672414 0.715596 Financial_Status 222.0 47.0 128.0 350.0 0.825279 0.634286 0.717286 Age 1328.0 109.0 48.0 1376.0 0.924148 0.965116 0.944188 Chidhood_Event 30.0 0.0 24.0 54.0 1.000000 0.555556 0.714286 Exercise 52.0 17.0 31.0 83.0 0.753623 0.626506 0.684211 Communicable_Disease 61.0 5.0 10.0 71.0 0.924242 0.859155 0.890511 Hypertension 45.0 1.0 12.0 57.0 0.978261 0.789474 0.873786 Other_Disease 1065.0 229.0 119.0 1184.0 0.823029 0.899493 0.859564 Violence_Or_Abuse 98.0 26.0 53.0 151.0 0.790323 0.649007 0.712727 Spiritual_Beliefs 94.0 9.0 21.0 115.0 0.912621 0.817391 0.862385 Employment 3797.0 272.0 288.0 4085.0 0.933153 0.929498 0.931322 Social_Exclusion 38.0 6.0 14.0 52.0 0.863636 0.730769 0.791667 Access_To_Care 810.0 95.0 160.0 970.0 0.895028 0.835052 0.864000 Marital_Status 177.0 4.0 9.0 186.0 0.977901 0.951613 0.964578 Diet 110.0 34.0 30.0 140.0 0.763889 0.785714 0.774648 Social_Support 1243.0 197.0 99.0 1342.0 0.863194 0.926230 0.893602 Disability 94.0 4.0 9.0 103.0 0.959184 0.912621 0.935323 Mental_Health 817.0 99.0 216.0 1033.0 0.891921 0.790900 0.838379 Alcohol 592.0 32.0 28.0 620.0 0.948718 0.954839 0.951768 Insurance_Status 145.0 23.0 32.0 177.0 0.863095 0.819209 0.840580 Substance_Quantity 107.0 42.0 39.0 146.0 0.718121 0.732877 0.725424 Hyperlipidemia 14.0 1.0 2.0 16.0 0.933333 0.875000 0.903226 Family_Member 4255.0 110.0 73.0 4328.0 0.974800 0.983133 0.978949 Legal_Issues 71.0 13.0 20.0 91.0 0.845238 0.780220 0.811429 Race_Ethnicity 81.0 9.0 7.0 88.0 0.900000 0.920455 0.910112 Gender 9698.0 183.0 193.0 9891.0 0.981480 0.980487 0.980983 Geographic_Entity 189.0 18.0 22.0 211.0 0.913043 0.895735 0.904306 Sexual_Orientation 21.0 0.0 3.0 24.0 1.000000 0.875000 0.933333 Transportation 27.0 2.0 27.0 54.0 0.931034 0.500000 0.650602 Sexual_Activity 56.0 4.0 24.0 80.0 0.933333 0.700000 0.800000 Language 35.0 6.0 2.0 37.0 0.853659 0.945946 0.897436 Substance_Use 400.0 40.0 24.0 424.0 0.909091 0.943396 0.925926</summary></entry><entry><title type="html">Extract Demographic Entities from Social Determinants of Health Texts</title><link href="/2023/02/10/ner_sdoh_demographics_wip_en.html" rel="alternate" type="text/html" title="Extract Demographic Entities from Social Determinants of Health Texts" /><published>2023-02-10T00:00:00+00:00</published><updated>2023-02-10T00:00:00+00:00</updated><id>/2023/02/10/ner_sdoh_demographics_wip_en</id><content type="html" xml:base="/2023/02/10/ner_sdoh_demographics_wip_en.html">## Description

This model extracts demographic information related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Family_Member`, `Age`, `Gender`, `Geographic_Entity`, `Race_Ethnicity`, `Language`, `Spiritual_Beliefs`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_demographics_wip_en_4.2.8_3.0_1675998706136.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_demographics_wip_en_4.2.8_3.0_1675998706136.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_demographics_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;SOCIAL HISTORY: He is a former tailor from Korea.&quot;,
             &quot;He lives alone,single and no children.&quot;,
             &quot;Pt is a 61 years old married, Caucasian, Catholic woman. Pt speaks English reasonably well.&quot;]


data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_demographics_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;Pt is a 61 years old married, Caucasian, Catholic woman. Pt speaks English reasonably well.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-----------------+-----+---+------------+
|ner_label        |begin|end|chunk       |
+-----------------+-----+---+------------+
|Gender           |16   |17 |He          |
|Geographic_Entity|43   |47 |Korea       |
|Gender           |0    |1  |He          |
|Family_Member    |29   |36 |children    |
|Age              |8    |19 |61 years old|
|Race_Ethnicity   |30   |38 |Caucasian   |
|Spiritual_Beliefs|41   |48 |Catholic    |
|Gender           |50   |54 |woman       |
|Language         |67   |73 |English     |
+-----------------+-----+---+------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_demographics_wip|
|Compatibility:|Healthcare NLP 4.2.8+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|858.4 KB|

## Benchmarking

```bash
	    label	     tp	    fp	   fn	   total	precision	   recall	       f1
              Age	 1346.0	  73.0	 74.0	  1420.0	 0.948555	 0.947887	 0.948221
Spiritual_Beliefs	  100.0	  13.0	 16.0	   116.0	 0.884956	 0.862069	 0.873362
    Family_Member	 4468.0	 134.0	 43.0	  4511.0	 0.970882	 0.990468	 0.980577
   Race_Ethnicity	   56.0	   0.0	 13.0	    69.0	 1.000000	 0.811594	 0.896000
           Gender	 9825.0	  67.0	247.0	 10072.0	 0.993227	 0.975477	 0.984272
Geographic_Entity	  225.0	   9.0	 29.0	   254.0	 0.961538	 0.885827	 0.922131
         Language	   51.0	   9.0	  5.0	    56.0	 0.850000	 0.910714	 0.879310
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="clinical" /><category term="social_determinants" /><category term="en" /><category term="ner" /><category term="demographics" /><category term="sdoh" /><category term="public_health" /><summary type="html">Description This model extracts demographic information related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Family_Member, Age, Gender, Geographic_Entity, Race_Ethnicity, Language, Spiritual_Beliefs Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_demographics_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;SOCIAL HISTORY: He is a former tailor from Korea.&quot;, &quot;He lives alone,single and no children.&quot;, &quot;Pt is a 61 years old married, Caucasian, Catholic woman. Pt speaks English reasonably well.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_demographics_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;Pt is a 61 years old married, Caucasian, Catholic woman. Pt speaks English reasonably well.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +-----------------+-----+---+------------+ |ner_label |begin|end|chunk | +-----------------+-----+---+------------+ |Gender |16 |17 |He | |Geographic_Entity|43 |47 |Korea | |Gender |0 |1 |He | |Family_Member |29 |36 |children | |Age |8 |19 |61 years old| |Race_Ethnicity |30 |38 |Caucasian | |Spiritual_Beliefs|41 |48 |Catholic | |Gender |50 |54 |woman | |Language |67 |73 |English | +-----------------+-----+---+------------+ Model Information Model Name: ner_sdoh_demographics_wip Compatibility: Healthcare NLP 4.2.8+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 858.4 KB Benchmarking label tp fp fn total precision recall f1 Age 1346.0 73.0 74.0 1420.0 0.948555 0.947887 0.948221 Spiritual_Beliefs 100.0 13.0 16.0 116.0 0.884956 0.862069 0.873362 Family_Member 4468.0 134.0 43.0 4511.0 0.970882 0.990468 0.980577 Race_Ethnicity 56.0 0.0 13.0 69.0 1.000000 0.811594 0.896000 Gender 9825.0 67.0 247.0 10072.0 0.993227 0.975477 0.984272 Geographic_Entity 225.0 9.0 29.0 254.0 0.961538 0.885827 0.922131 Language 51.0 9.0 5.0 56.0 0.850000 0.910714 0.879310</summary></entry><entry><title type="html">Extract Income and Social Status Entities from Social Determinants of Health Texts</title><link href="/2023/02/10/ner_sdoh_income_social_status_wip_en.html" rel="alternate" type="text/html" title="Extract Income and Social Status Entities from Social Determinants of Health Texts" /><published>2023-02-10T00:00:00+00:00</published><updated>2023-02-10T00:00:00+00:00</updated><id>/2023/02/10/ner_sdoh_income_social_status_wip_en</id><content type="html" xml:base="/2023/02/10/ner_sdoh_income_social_status_wip_en.html">## Description

This model extracts income and social status information related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Education`, `Marital_Status`, `Financial_Status`, `Population_Group`, `Employment`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_income_social_status_wip_en_4.2.8_3.0_1675999206708.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_income_social_status_wip_en_4.2.8_3.0_1675999206708.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_income_social_status_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;Pt is described as divorced and pleasant when approached but keeps to himself. Pt is working as a plumber, but he gets financial diffuculties. He has a son student at college. His family is imigrant for 2 years.&quot;]

data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_income_social_status_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;Pt is described as divorced and pleasant when approached but keeps to himself. Pt is working as a plumber, but he gets financial diffuculties. He has a son student at college. His family is imigrant for 2 years.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-----------+----------------+-----+---+----------------------+
|sentence_id|ner_label       |begin|end|chunk                 |
+-----------+----------------+-----+---+----------------------+
|0          |Marital_Status  |19   |26 |divorced              |
|1          |Employment      |98   |104|plumber               |
|1          |Financial_Status|119  |140|financial diffuculties|
|2          |Education       |156  |162|student               |
|2          |Education       |167  |173|college               |
|3          |Population_Group|190  |197|imigrant              |
+-----------+----------------+-----+---+----------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_income_social_status_wip|
|Compatibility:|Healthcare NLP 4.2.8+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|856.8 KB|

## Benchmarking

```bash
           label	    tp	   fp	    fn	 total	precision	   recall	       f1
       Education	  95.0	 20.0	  18.0	 113.0	 0.826087	 0.840708	 0.833333
Population_Group	  41.0	  0.0	   5.0	  46.0	 1.000000	 0.891304	 0.942529
Financial_Status	 286.0	 52.0	  82.0	 368.0	 0.846154	 0.777174	 0.810198
      Employment	3968.0	142.0	 215.0	4183.0	 0.965450	 0.948601	 0.956952
  Marital_Status	 167.0	  1.0	   7.0	 174.0	 0.994048	 0.959770	 0.976608
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="clinical" /><category term="social_determinants" /><category term="en" /><category term="ner" /><category term="income" /><category term="social_status" /><category term="sdoh" /><category term="public_health" /><summary type="html">Description This model extracts income and social status information related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Education, Marital_Status, Financial_Status, Population_Group, Employment Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_income_social_status_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;Pt is described as divorced and pleasant when approached but keeps to himself. Pt is working as a plumber, but he gets financial diffuculties. He has a son student at college. His family is imigrant for 2 years.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_income_social_status_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;Pt is described as divorced and pleasant when approached but keeps to himself. Pt is working as a plumber, but he gets financial diffuculties. He has a son student at college. His family is imigrant for 2 years.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +-----------+----------------+-----+---+----------------------+ |sentence_id|ner_label |begin|end|chunk | +-----------+----------------+-----+---+----------------------+ |0 |Marital_Status |19 |26 |divorced | |1 |Employment |98 |104|plumber | |1 |Financial_Status|119 |140|financial diffuculties| |2 |Education |156 |162|student | |2 |Education |167 |173|college | |3 |Population_Group|190 |197|imigrant | +-----------+----------------+-----+---+----------------------+ Model Information Model Name: ner_sdoh_income_social_status_wip Compatibility: Healthcare NLP 4.2.8+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 856.8 KB Benchmarking label tp fp fn total precision recall f1 Education 95.0 20.0 18.0 113.0 0.826087 0.840708 0.833333 Population_Group 41.0 0.0 5.0 46.0 1.000000 0.891304 0.942529 Financial_Status 286.0 52.0 82.0 368.0 0.846154 0.777174 0.810198 Employment 3968.0 142.0 215.0 4183.0 0.965450 0.948601 0.956952 Marital_Status 167.0 1.0 7.0 174.0 0.994048 0.959770 0.976608</summary></entry><entry><title type="html">Detect SDOH of Social Environment</title><link href="/2023/02/10/ner_sdoh_social_environment_wip_en.html" rel="alternate" type="text/html" title="Detect SDOH of Social Environment" /><published>2023-02-10T00:00:00+00:00</published><updated>2023-02-10T00:00:00+00:00</updated><id>/2023/02/10/ner_sdoh_social_environment_wip_en</id><content type="html" xml:base="/2023/02/10/ner_sdoh_social_environment_wip_en.html">## Description

This model extracts social environment terminologies related to Social Determinants of Health from various kinds of documents.

## Predicted Entities

`Social_Support`, `Chidhood_Event`, `Social_Exclusion`, `Violence_Abuse_Legal`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_social_environment_wip_en_4.2.8_3.0_1675998295035.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_social_environment_wip_en_4.2.8_3.0_1675998295035.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_social_environment_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;He is the primary caregiver.&quot;,
             &quot;There is some evidence of abuse.&quot;,
             &quot;She stated that she was in a safe environment in prison, but that her siblings lived in an unsafe neighborhood, she was very afraid for them and witnessed their ostracism by other people.&quot;,
             &quot;Medical history: Jane was born in a low - income household and experienced significant trauma during her childhood, including physical and emotional abuse.&quot;]

data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_social_environment_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;Medical history: Jane was born in a low - income household and experienced significant trauma during her childhood, including physical and emotional abuse.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)

```
&lt;/div&gt;

## Results

```bash
+--------------------+-----+---+---------------------------+
|ner_label           |begin|end|chunk                      |
+--------------------+-----+---+---------------------------+
|Social_Support      |10   |26 |primary caregiver          |
|Violence_Abuse_Legal|26   |30 |abuse                      |
|Violence_Abuse_Legal|49   |54 |prison                     |
|Social_Exclusion    |161  |169|ostracism                  |
|Chidhood_Event      |87   |113|trauma during her childhood|
|Violence_Abuse_Legal|139  |153|emotional abuse            |
+--------------------+-----+---+---------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_social_environment_wip|
|Compatibility:|Healthcare NLP 4.2.8+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|858.7 KB|

## Benchmarking

```bash
	       label	    tp	  fp	   fn	  total	 precision	  recall	      f1
      Chidhood_Event	  34.0	 6.0	  5.0	   39.0	  0.850000	0.871795	0.860759
    Social_Exclusion	  45.0	 6.0	 12.0  	 57.0	  0.882353	0.789474	0.833333
      Social_Support	1139.0	57.0	103.0	 1242.0	  0.952341	0.917069	0.934372
Violence_Abuse_Legal	 235.0	38.0	 44.0	  279.0	  0.860806	0.842294	0.851449
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="clinical" /><category term="social_determinants" /><category term="en" /><category term="ner" /><category term="social" /><category term="environment" /><category term="sdoh" /><category term="public_health" /><summary type="html">Description This model extracts social environment terminologies related to Social Determinants of Health from various kinds of documents. Predicted Entities Social_Support, Chidhood_Event, Social_Exclusion, Violence_Abuse_Legal Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_social_environment_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;He is the primary caregiver.&quot;, &quot;There is some evidence of abuse.&quot;, &quot;She stated that she was in a safe environment in prison, but that her siblings lived in an unsafe neighborhood, she was very afraid for them and witnessed their ostracism by other people.&quot;, &quot;Medical history: Jane was born in a low - income household and experienced significant trauma during her childhood, including physical and emotional abuse.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_social_environment_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;Medical history: Jane was born in a low - income household and experienced significant trauma during her childhood, including physical and emotional abuse.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +--------------------+-----+---+---------------------------+ |ner_label |begin|end|chunk | +--------------------+-----+---+---------------------------+ |Social_Support |10 |26 |primary caregiver | |Violence_Abuse_Legal|26 |30 |abuse | |Violence_Abuse_Legal|49 |54 |prison | |Social_Exclusion |161 |169|ostracism | |Chidhood_Event |87 |113|trauma during her childhood| |Violence_Abuse_Legal|139 |153|emotional abuse | +--------------------+-----+---+---------------------------+ Model Information Model Name: ner_sdoh_social_environment_wip Compatibility: Healthcare NLP 4.2.8+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 858.7 KB Benchmarking label tp fp fn total precision recall f1 Chidhood_Event 34.0 6.0 5.0 39.0 0.850000 0.871795 0.860759 Social_Exclusion 45.0 6.0 12.0 57.0 0.882353 0.789474 0.833333 Social_Support 1139.0 57.0 103.0 1242.0 0.952341 0.917069 0.934372 Violence_Abuse_Legal 235.0 38.0 44.0 279.0 0.860806 0.842294 0.851449</summary></entry><entry><title type="html">Mapping RxNorm and RxNorm Extension Codes with Corresponding Drug Brand Names</title><link href="/2023/02/09/rxnorm_drug_brandname_mapper_en.html" rel="alternate" type="text/html" title="Mapping RxNorm and RxNorm Extension Codes with Corresponding Drug Brand Names" /><published>2023-02-09T00:00:00+00:00</published><updated>2023-02-09T00:00:00+00:00</updated><id>/2023/02/09/rxnorm_drug_brandname_mapper_en</id><content type="html" xml:base="/2023/02/09/rxnorm_drug_brandname_mapper_en.html">## Description

This pretrained model maps RxNorm and RxNorm Extension codes with their corresponding drug brand names. It returns 2 types of brand names for the corresponding RxNorm or RxNorm Extension code.

## Predicted Entities

`rxnorm_brandname`, `rxnorm_extension_brandname`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/rxnorm_drug_brandname_mapper_en_4.3.0_3.0_1675966478332.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/rxnorm_drug_brandname_mapper_en_4.3.0_3.0_1675966478332.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler()\
      .setInputCol(&quot;text&quot;)\
      .setOutputCol(&quot;chunk&quot;)

sbert_embedder = BertSentenceEmbeddings\
      .pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;,&quot;clinical/models&quot;)\
      .setInputCols([&quot;chunk&quot;])\
      .setOutputCol(&quot;sbert_embeddings&quot;)
    
rxnorm_resolver = SentenceEntityResolverModel\
      .pretrained(&quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
      .setInputCols([&quot;chunk&quot;, &quot;sbert_embeddings&quot;])\
      .setOutputCol(&quot;rxnorm_code&quot;)\
      .setDistanceFunction(&quot;EUCLIDEAN&quot;)

resolver2chunk = Resolution2Chunk()\
    .setInputCols([&quot;rxnorm_code&quot;]) \
    .setOutputCol(&quot;rxnorm_chunk&quot;)\

chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
      .setInputCols([&quot;rxnorm_chunk&quot;])\
      .setOutputCol(&quot;mappings&quot;)\
      .setRels([&quot;rxnorm_brandname&quot;, &quot;rxnorm_extension_brandname&quot;])


pipeline = Pipeline(
    stages = [
        documentAssembler,
        sbert_embedder,
        rxnorm_resolver,
        resolver2chunk,
        chunkerMapper
        ])

model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) 

pipeline = LightPipeline(model)

result = pipeline.fullAnnotate(['metformin', 'advil'])

```
```scala
val documentAssembler = new DocumentAssembler()\
      .setInputCol(&quot;text&quot;)\
      .setOutputCol(&quot;chunk&quot;)

val sbert_embedder = BertSentenceEmbeddings\
      .pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;,&quot;clinical/models&quot;)\
      .setInputCols([&quot;chunk&quot;])\
      .setOutputCol(&quot;sbert_embeddings&quot;)
    
val rxnorm_resolver = SentenceEntityResolverModel\
      .pretrained(&quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
      .setInputCols([&quot;chunk&quot;, &quot;sbert_embeddings&quot;])\
      .setOutputCol(&quot;rxnorm_code&quot;)\
      .setDistanceFunction(&quot;EUCLIDEAN&quot;)

val resolver2chunk = new Resolution2Chunk()\
    .setInputCols([&quot;rxnorm_code&quot;]) \
    .setOutputCol(&quot;rxnorm_chunk&quot;)\

val chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
      .setInputCols([&quot;rxnorm_chunk&quot;])\
      .setOutputCol(&quot;mappings&quot;)\
      .setRels([&quot;rxnorm_brandname&quot;, &quot;rxnorm_extension_brandname&quot;])



val pipeline = new Pipeline(stages = Array(
documentAssembler,
sbert_embedder,
rxnorm_resolver,
resolver2chunk
chunkerMapper
))

val data = Seq(Array(&quot;metformin&quot;, &quot;advil&quot;)).toDS.toDF(&quot;text&quot;)

val result= pipeline.fit(data).transform(data)

```
&lt;/div&gt;

## Results

```bash
+--------------+-------------+--------------------------------------------------+--------------------------+
|     drug_name|rxnorm_result|                                    mapping_result|                 relation |
+--------------+-------------+--------------------------------------------------+--------------------------+
|     metformin|         6809|Actoplus Met (metformin):::Avandamet (metformin...|          rxnorm_brandname|
|     metformin|         6809|A FORMIN (metformin):::ABERIN MAX (metformin)::...|rxnorm_extension_brandname|
|         advil|       153010|                                     Advil (Advil)|          rxnorm_brandname|
|         advil|       153010|                                              NONE|rxnorm_extension_brandname|
+--------------+-------------+--------------------------------------------------+--------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|rxnorm_drug_brandname_mapper|
|Compatibility:|Healthcare NLP 4.3.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[rxnorm_chunk]|
|Output Labels:|[mappings]|
|Language:|en|
|Size:|4.0 MB|</content><author><name>John Snow Labs</name></author><category term="chunk_mappig" /><category term="rxnorm" /><category term="drug_brand_name" /><category term="rxnorm_extension" /><category term="en" /><category term="clinical" /><category term="licensed" /><summary type="html">Description This pretrained model maps RxNorm and RxNorm Extension codes with their corresponding drug brand names. It returns 2 types of brand names for the corresponding RxNorm or RxNorm Extension code. Predicted Entities rxnorm_brandname, rxnorm_extension_brandname Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;chunk&quot;) sbert_embedder = BertSentenceEmbeddings\ .pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;chunk&quot;])\ .setOutputCol(&quot;sbert_embeddings&quot;) rxnorm_resolver = SentenceEntityResolverModel\ .pretrained(&quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;chunk&quot;, &quot;sbert_embeddings&quot;])\ .setOutputCol(&quot;rxnorm_code&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) resolver2chunk = Resolution2Chunk()\ .setInputCols([&quot;rxnorm_code&quot;]) \ .setOutputCol(&quot;rxnorm_chunk&quot;)\ chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;rxnorm_chunk&quot;])\ .setOutputCol(&quot;mappings&quot;)\ .setRels([&quot;rxnorm_brandname&quot;, &quot;rxnorm_extension_brandname&quot;]) pipeline = Pipeline( stages = [ documentAssembler, sbert_embedder, rxnorm_resolver, resolver2chunk, chunkerMapper ]) model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) pipeline = LightPipeline(model) result = pipeline.fullAnnotate(['metformin', 'advil']) val documentAssembler = new DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;chunk&quot;) val sbert_embedder = BertSentenceEmbeddings\ .pretrained(&quot;sbiobert_base_cased_mli&quot;, &quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;chunk&quot;])\ .setOutputCol(&quot;sbert_embeddings&quot;) val rxnorm_resolver = SentenceEntityResolverModel\ .pretrained(&quot;sbiobertresolve_rxnorm_augmented&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;chunk&quot;, &quot;sbert_embeddings&quot;])\ .setOutputCol(&quot;rxnorm_code&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) val resolver2chunk = new Resolution2Chunk()\ .setInputCols([&quot;rxnorm_code&quot;]) \ .setOutputCol(&quot;rxnorm_chunk&quot;)\ val chunkerMapper = ChunkMapperModel.pretrained(&quot;rxnorm_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;rxnorm_chunk&quot;])\ .setOutputCol(&quot;mappings&quot;)\ .setRels([&quot;rxnorm_brandname&quot;, &quot;rxnorm_extension_brandname&quot;]) val pipeline = new Pipeline(stages = Array( documentAssembler, sbert_embedder, rxnorm_resolver, resolver2chunk chunkerMapper )) val data = Seq(Array(&quot;metformin&quot;, &quot;advil&quot;)).toDS.toDF(&quot;text&quot;) val result= pipeline.fit(data).transform(data) Results +--------------+-------------+--------------------------------------------------+--------------------------+ | drug_name|rxnorm_result| mapping_result| relation | +--------------+-------------+--------------------------------------------------+--------------------------+ | metformin| 6809|Actoplus Met (metformin):::Avandamet (metformin...| rxnorm_brandname| | metformin| 6809|A FORMIN (metformin):::ABERIN MAX (metformin)::...|rxnorm_extension_brandname| | advil| 153010| Advil (Advil)| rxnorm_brandname| | advil| 153010| NONE|rxnorm_extension_brandname| +--------------+-------------+--------------------------------------------------+--------------------------+ Model Information Model Name: rxnorm_drug_brandname_mapper Compatibility: Healthcare NLP 4.3.0+ License: Licensed Edition: Official Input Labels: [rxnorm_chunk] Output Labels: [mappings] Language: en Size: 4.0 MB</summary></entry><entry><title type="html">French CamemBertForQuestionAnswering Base squadFR (camembert_base_qa_fquad)</title><link href="/2023/02/08/camembert_base_qa_fquad_fr.html" rel="alternate" type="text/html" title="French CamemBertForQuestionAnswering Base squadFR (camembert_base_qa_fquad)" /><published>2023-02-08T00:00:00+00:00</published><updated>2023-02-08T00:00:00+00:00</updated><id>/2023/02/08/camembert_base_qa_fquad_fr</id><content type="html" xml:base="/2023/02/08/camembert_base_qa_fquad_fr.html">## Description

Pretrained CamemBertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `camembert_base_qa_fquad ` is a French model originally fine-tuned on a combo of three French Q&amp;A datasets:

- PIAFv1.1
- FQuADv1.0
- SQuAD-FR (SQuAD automatically translated to French)

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/camembert_base_qa_fquad_fr_4.3.0_3.2_1675865521345.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/camembert_base_qa_fquad_fr_4.3.0_3.2_1675865521345.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = CamemBertForQuestionAnswering(&quot;camembert_base_qa_fquad&quot;,&quot;fr&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;OÃ¹ est-ce que je vis?&quot;,&quot;Mon nom est Wolfgang et je vis Ã  Berlin.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = CamemBertForQuestionAnswering(&quot;camembert_base_qa_fquad&quot;,&quot;fr&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(True)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;OÃ¹ est-ce que je vis?&quot;,&quot;Mon nom est Wolfgang et je vis Ã  Berlin.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|camembert_base_qa_fquad|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|fr|
|Size:|411.9 MB|

## References

https://huggingface.co/etalab-ia/camembert-base-squadFR-fquad-piaf

## Benchmarking

```bash
{&quot;f1&quot;: 80.61, &quot;exact_match&quot;: 59.54}
```</content><author><name>John Snow Labs</name></author><category term="fr" /><category term="french" /><category term="question_answering" /><category term="camembert" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description Pretrained CamemBertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. camembert_base_qa_fquad is a French model originally fine-tuned on a combo of three French Q&amp;amp;A datasets: PIAFv1.1 FQuADv1.0 SQuAD-FR (SQuAD automatically translated to French) Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = CamemBertForQuestionAnswering(&quot;camembert_base_qa_fquad&quot;,&quot;fr&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;OÃ¹ est-ce que je vis?&quot;,&quot;Mon nom est Wolfgang et je vis Ã  Berlin.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = CamemBertForQuestionAnswering(&quot;camembert_base_qa_fquad&quot;,&quot;fr&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;OÃ¹ est-ce que je vis?&quot;,&quot;Mon nom est Wolfgang et je vis Ã  Berlin.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: camembert_base_qa_fquad Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: fr Size: 411.9 MB References https://huggingface.co/etalab-ia/camembert-base-squadFR-fquad-piaf Benchmarking {&quot;f1&quot;: 80.61, &quot;exact_match&quot;: 59.54}</summary></entry><entry><title type="html">Zero-Shot Named Entity Recognition (Generic sample)</title><link href="/2023/02/08/zero_shot_ner_roberta_en.html" rel="alternate" type="text/html" title="Zero-Shot Named Entity Recognition (Generic sample)" /><published>2023-02-08T00:00:00+00:00</published><updated>2023-02-08T00:00:00+00:00</updated><id>/2023/02/08/zero_shot_ner_roberta_en</id><content type="html" xml:base="/2023/02/08/zero_shot_ner_roberta_en.html">## Description

This model is trained with Zero-Shot Named Entity Recognition (NER) approach and it can detect any kind of defined entities with no training dataset, just pretrained RoBERTa embeddings (included in the model).

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/zero_shot_ner_roberta_en_4.3.0_3.2_1675890474068.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/zero_shot_ner_roberta_en_4.3.0_3.2_1675890474068.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentenceDetector = SentenceDetector() \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer() \
    .setInputCols([&quot;sentence&quot;]) \
    .setOutputCol(&quot;token&quot;)
    
zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;zero_shot_ner&quot;)\
    .setEntityDefinitions(
        {
            &quot;NAME&quot;: [&quot;What is his name?&quot;, &quot;What is my name?&quot;, &quot;What is her name?&quot;],
            &quot;CITY&quot;: [&quot;Which city?&quot;, &quot;Which is the city?&quot;]
        })

ner_converter = NerConverter()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)\

pipeline = Pipeline(stages = [
    documentAssembler, 
    sentenceDetector, 
    tokenizer, 
    zero_shot_ner, 
    ner_converter])

data = spark.createDataFrame([&quot;Hellen works in London, Paris and Berlin. My name is Clara, I live in New York and Hellen lives in Paris.&quot;,
                              &quot;John is a man who works in London, London and London.&quot;], StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentenceDetector = new SentenceDetector() 
    .setInputCols(Array(&quot;document&quot;)) 
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer() 
    .setInputCols(Array(&quot;sentence&quot;)) 
    .setOutputCol(&quot;token&quot;)
    
val zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;zero_shot_ner&quot;)
    .setEntityDefinitions(Map(
            &quot;NAME&quot;-&gt; Array(&quot;What is his name?&quot;, &quot;What is my name?&quot;, &quot;What is her name?&quot;),
            &quot;CITY&quot;-&gt; Array(&quot;Which city?&quot;, &quot;Which is the city?&quot;)
    ))

val ner_converter = new NerConverter()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new .setStages(Array(
    documentAssembler, 
    sentenceDetector, 
    tokenizer, 
    zero_shot_ner, 
    ner_converter))

val data = Seq(Array(&quot;Hellen works in London, Paris and Berlin. My name is Clara, I live in New York and Hellen lives in Paris.&quot;,
                                     &quot;John is a man who works in London, London and London.&quot;)toDS().toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+------+---------+--------+-----+---+----------+
| token|ner_label|sentence|begin|end|confidence|
+------+---------+--------+-----+---+----------+
|Hellen|   B-NAME|       0|    0|  5|0.13306311|
| works|        O|       0|    7| 11|      null|
|    in|        O|       0|   13| 14|      null|
|London|   B-CITY|       0|   16| 21| 0.4064213|
|     ,|        O|       0|   22| 22|      null|
| Paris|   B-CITY|       0|   24| 28|0.04597357|
|   and|        O|       0|   30| 32|      null|
|Berlin|   B-CITY|       0|   34| 39|0.16265489|
|     .|        O|       0|   40| 40|      null|
|    My|        O|       1|   42| 43|      null|
|  name|        O|       1|   45| 48|      null|
|    is|        O|       1|   50| 51|      null|
| Clara|   B-NAME|       1|   53| 57| 0.9274031|
|     ,|        O|       1|   58| 58|      null|
|     I|        O|       1|   60| 60|      null|
|  live|        O|       1|   62| 65|      null|
|    in|        O|       1|   67| 68|      null|
|   New|   B-CITY|       1|   70| 72|0.82799006|
|  York|   I-CITY|       1|   74| 77|0.82799006|
|   and|        O|       1|   79| 81|      null|
|Hellen|   B-NAME|       1|   83| 88|0.40429682|
| lives|        O|       1|   90| 94|      null|
|    in|        O|       1|   96| 97|      null|
| Paris|   B-CITY|       1|   99|103|0.49216735|
|     .|        O|       1|  104|104|      null|
|  John|   B-NAME|       0|    0|  3|0.14063153|
|    is|        O|       0|    5|  6|      null|
|     a|        O|       0|    8|  8|      null|
|   man|        O|       0|   10| 12|      null|
|   who|        O|       0|   14| 16|      null|
| works|        O|       0|   18| 22|      null|
|    in|        O|       0|   24| 25|      null|
|London|   B-CITY|       0|   27| 32|0.15521188|
|     ,|        O|       0|   33| 33|      null|
|London|   B-CITY|       0|   35| 40|0.12151082|
|   and|        O|       0|   42| 44|      null|
|London|   B-CITY|       0|   46| 51| 0.2650951|
|     .|        O|       0|   52| 52|      null|
+------+---------+--------+-----+---+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|zero_shot_ner_roberta|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|463.8 MB|
|Case sensitive:|true|
|Max sentence length:|512|</content><author><name>John Snow Labs</name></author><category term="ner" /><category term="zero_shot" /><category term="roberta" /><category term="qa" /><category term="en" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description This model is trained with Zero-Shot Named Entity Recognition (NER) approach and it can detect any kind of defined entities with no training dataset, just pretrained RoBERTa embeddings (included in the model). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentenceDetector = SentenceDetector() \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer() \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;token&quot;) zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;zero_shot_ner&quot;)\ .setEntityDefinitions( { &quot;NAME&quot;: [&quot;What is his name?&quot;, &quot;What is my name?&quot;, &quot;What is her name?&quot;], &quot;CITY&quot;: [&quot;Which city?&quot;, &quot;Which is the city?&quot;] }) ner_converter = NerConverter()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;)\ pipeline = Pipeline(stages = [ documentAssembler, sentenceDetector, tokenizer, zero_shot_ner, ner_converter]) data = spark.createDataFrame([&quot;Hellen works in London, Paris and Berlin. My name is Clara, I live in New York and Hellen lives in Paris.&quot;, &quot;John is a man who works in London, London and London.&quot;], StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentenceDetector = new SentenceDetector() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;sentence&quot;)) .setOutputCol(&quot;token&quot;) val zero_shot_ner = ZeroShotNerModel.pretrained(&quot;zero_shot_ner_roberta&quot;, &quot;en&quot;, &quot;clincial/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;zero_shot_ner&quot;) .setEntityDefinitions(Map( &quot;NAME&quot;-&amp;gt; Array(&quot;What is his name?&quot;, &quot;What is my name?&quot;, &quot;What is her name?&quot;), &quot;CITY&quot;-&amp;gt; Array(&quot;Which city?&quot;, &quot;Which is the city?&quot;) )) val ner_converter = new NerConverter() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;zero_shot_ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new .setStages(Array( documentAssembler, sentenceDetector, tokenizer, zero_shot_ner, ner_converter)) val data = Seq(Array(&quot;Hellen works in London, Paris and Berlin. My name is Clara, I live in New York and Hellen lives in Paris.&quot;, &quot;John is a man who works in London, London and London.&quot;)toDS().toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +------+---------+--------+-----+---+----------+ | token|ner_label|sentence|begin|end|confidence| +------+---------+--------+-----+---+----------+ |Hellen| B-NAME| 0| 0| 5|0.13306311| | works| O| 0| 7| 11| null| | in| O| 0| 13| 14| null| |London| B-CITY| 0| 16| 21| 0.4064213| | ,| O| 0| 22| 22| null| | Paris| B-CITY| 0| 24| 28|0.04597357| | and| O| 0| 30| 32| null| |Berlin| B-CITY| 0| 34| 39|0.16265489| | .| O| 0| 40| 40| null| | My| O| 1| 42| 43| null| | name| O| 1| 45| 48| null| | is| O| 1| 50| 51| null| | Clara| B-NAME| 1| 53| 57| 0.9274031| | ,| O| 1| 58| 58| null| | I| O| 1| 60| 60| null| | live| O| 1| 62| 65| null| | in| O| 1| 67| 68| null| | New| B-CITY| 1| 70| 72|0.82799006| | York| I-CITY| 1| 74| 77|0.82799006| | and| O| 1| 79| 81| null| |Hellen| B-NAME| 1| 83| 88|0.40429682| | lives| O| 1| 90| 94| null| | in| O| 1| 96| 97| null| | Paris| B-CITY| 1| 99|103|0.49216735| | .| O| 1| 104|104| null| | John| B-NAME| 0| 0| 3|0.14063153| | is| O| 0| 5| 6| null| | a| O| 0| 8| 8| null| | man| O| 0| 10| 12| null| | who| O| 0| 14| 16| null| | works| O| 0| 18| 22| null| | in| O| 0| 24| 25| null| |London| B-CITY| 0| 27| 32|0.15521188| | ,| O| 0| 33| 33| null| |London| B-CITY| 0| 35| 40|0.12151082| | and| O| 0| 42| 44| null| |London| B-CITY| 0| 46| 51| 0.2650951| | .| O| 0| 52| 52| null| +------+---------+--------+-----+---+----------+ Model Information Model Name: zero_shot_ner_roberta Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 463.8 MB Case sensitive: true Max sentence length: 512</summary></entry><entry><title type="html">ASR HubertForCTC - asr_hubert_large_ls960</title><link href="/2023/02/07/asr_hubert_large_ls960_en.html" rel="alternate" type="text/html" title="ASR HubertForCTC - asr_hubert_large_ls960" /><published>2023-02-07T00:00:00+00:00</published><updated>2023-02-07T00:00:00+00:00</updated><id>/2023/02/07/asr_hubert_large_ls960_en</id><content type="html" xml:base="/2023/02/07/asr_hubert_large_ls960_en.html">## Description

Hubert Model with a language modeling head on top for Connectionist Temporal Classification (CTC). 
Hubert was proposed in HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.

The large model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/asr_hubert_large_ls960_en_4.3.0_3.0_1675767067233.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/asr_hubert_large_ls960_en_4.3.0_3.0_1675767067233.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
                
audio_assembler = AudioAssembler()\
  .setInputCol(&quot;audio_content&quot;)\
  .setOutputCol(&quot;audio_assembler&quot;)

speech_to_text = HubertForCTC.pretrained(&quot;asr_hubert_large_ls960&quot;, &quot;en&quot;)\
  .setInputCols(&quot;audio_assembler&quot;)\
  .setOutputCol(&quot;text&quot;)

pipeline = Pipeline(stages=[
  audio_assembler,
  speech_to_text,
])

pipelineModel = pipeline.fit(audioDf)

pipelineDF = pipelineModel.transform(audioDf)
```
```scala

val audioAssembler = new AudioAssembler()
    .setInputCol(&quot;audio_content&quot;) 
    .setOutputCol(&quot;audio_assembler&quot;)

val speechToText = HubertForCTC
    .pretrained(&quot;asr_hubert_large_ls960&quot;, &quot;en&quot;)
    .setInputCols(&quot;audio_assembler&quot;) 
    .setOutputCol(&quot;text&quot;) 

val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText))

val pipelineModel = pipeline.fit(audioDf)

val pipelineDF = pipelineModel.transform(audioDf)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|asr_hubert_large_ls960|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[audio_assembler]|
|Output Labels:|[text]|
|Language:|en|
|Size:|1.5 GB|

## References

[https://huggingface.co/facebook/hubert-large-ls960-ft](https://huggingface.co/facebook/hubert-large-ls960-ft)</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="hubert" /><category term="audio" /><category term="en" /><category term="english" /><category term="asr" /><category term="speech" /><category term="librispeech_asr" /><category term="tensorflow" /><summary type="html">Description Hubert Model with a language modeling head on top for Connectionist Temporal Classification (CTC). Hubert was proposed in HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed. The large model fine-tuned on 960h of Librispeech on 16kHz sampled speech audio. When using the model make sure that your speech input is also sampled at 16Khz. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU audio_assembler = AudioAssembler()\ .setInputCol(&quot;audio_content&quot;)\ .setOutputCol(&quot;audio_assembler&quot;) speech_to_text = HubertForCTC.pretrained(&quot;asr_hubert_large_ls960&quot;, &quot;en&quot;)\ .setInputCols(&quot;audio_assembler&quot;)\ .setOutputCol(&quot;text&quot;) pipeline = Pipeline(stages=[ audio_assembler, speech_to_text, ]) pipelineModel = pipeline.fit(audioDf) pipelineDF = pipelineModel.transform(audioDf) val audioAssembler = new AudioAssembler() .setInputCol(&quot;audio_content&quot;) .setOutputCol(&quot;audio_assembler&quot;) val speechToText = HubertForCTC .pretrained(&quot;asr_hubert_large_ls960&quot;, &quot;en&quot;) .setInputCols(&quot;audio_assembler&quot;) .setOutputCol(&quot;text&quot;) val pipeline = new Pipeline().setStages(Array(audioAssembler, speechToText)) val pipelineModel = pipeline.fit(audioDf) val pipelineDF = pipelineModel.transform(audioDf) Model Information Model Name: asr_hubert_large_ls960 Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [audio_assembler] Output Labels: [text] Language: en Size: 1.5 GB References https://huggingface.co/facebook/hubert-large-ls960-ft</summary></entry><entry><title type="html">SwinForImageClassification - image_classifier_swin_base_patch4_window12_384_in22k</title><link href="/2023/02/07/image_classifier_swin_base_patch4_window12_384_in22k_en.html" rel="alternate" type="text/html" title="SwinForImageClassification - image_classifier_swin_base_patch4_window12_384_in22k" /><published>2023-02-07T00:00:00+00:00</published><updated>2023-02-07T00:00:00+00:00</updated><id>/2023/02/07/image_classifier_swin_base_patch4_window12_384_in22k_en</id><content type="html" xml:base="/2023/02/07/image_classifier_swin_base_patch4_window12_384_in22k_en.html">## Description

Pretrained Swin model for Image Classification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.

Swin Transformer was introduced in the paper [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) by Liu et al.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/image_classifier_swin_base_patch4_window12_384_in22k_en_4.3.0_3.0_1675783085913.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/image_classifier_swin_base_patch4_window12_384_in22k_en_4.3.0_3.0_1675783085913.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
                
image_assembler = ImageAssembler()\
  .setInputCol(&quot;image&quot;)
  .setOutputCol(&quot;image_assembler&quot;)

imageClassifier = SwinForImageClassification.pretrained(&quot;image_classifier_swin_base_patch4_window12_384_in22k&quot;, &quot;en&quot;)\
  .setInputCols(&quot;image_assembler&quot;)\
  .setOutputCol(&quot;class&quot;)

pipeline = Pipeline(stages=[
  image_assembler,
  imageClassifier,
])

pipelineModel = pipeline.fit(imageDF)

pipelineDF = pipelineModel.transform(imageDF)
```
```scala

val imageAssembler = new ImageAssembler()
    .setInputCol(&quot;image&quot;)
    .setOutputCol(&quot;image_assembler&quot;)

val imageClassifier = SwinForImageClassification
    .pretrained(&quot;image_classifier_swin_base_patch4_window12_384_in22k&quot;, &quot;en&quot;)
    .setInputCols(&quot;image_assembler&quot;) 
    .setOutputCol(&quot;class&quot;) 

val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier))

val pipelineModel = pipeline.fit(imageDF)

val pipelineDF = pipelineModel.transform(imageDF)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|image_classifier_swin_base_patch4_window12_384_in22k|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[image_assembler]|
|Output Labels:|[class]|
|Language:|en|
|Size:|826.8 MB|

## References

[https://huggingface.co/microsoft/swin_base_patch4_window12_384_in22k](https://huggingface.co/microsoft/swin_base_patch4_window12_384_in22k)</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="swin" /><category term="image" /><category term="en" /><category term="english" /><category term="image_classification" /><category term="imagenet" /><category term="tensorflow" /><summary type="html">Description Pretrained Swin model for Image Classification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. Swin Transformer was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU image_assembler = ImageAssembler()\ .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) imageClassifier = SwinForImageClassification.pretrained(&quot;image_classifier_swin_base_patch4_window12_384_in22k&quot;, &quot;en&quot;)\ .setInputCols(&quot;image_assembler&quot;)\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline(stages=[ image_assembler, imageClassifier, ]) pipelineModel = pipeline.fit(imageDF) pipelineDF = pipelineModel.transform(imageDF) val imageAssembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val imageClassifier = SwinForImageClassification .pretrained(&quot;image_classifier_swin_base_patch4_window12_384_in22k&quot;, &quot;en&quot;) .setInputCols(&quot;image_assembler&quot;) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier)) val pipelineModel = pipeline.fit(imageDF) val pipelineDF = pipelineModel.transform(imageDF) Model Information Model Name: image_classifier_swin_base_patch4_window12_384_in22k Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [image_assembler] Output Labels: [class] Language: en Size: 826.8 MB References https://huggingface.co/microsoft/swin_base_patch4_window12_384_in22k</summary></entry><entry><title type="html">SwinForImageClassification - image_classifier_swin_base_patch4_window7_224</title><link href="/2023/02/07/image_classifier_swin_base_patch4_window7_224_en.html" rel="alternate" type="text/html" title="SwinForImageClassification - image_classifier_swin_base_patch4_window7_224" /><published>2023-02-07T00:00:00+00:00</published><updated>2023-02-07T00:00:00+00:00</updated><id>/2023/02/07/image_classifier_swin_base_patch4_window7_224_en</id><content type="html" xml:base="/2023/02/07/image_classifier_swin_base_patch4_window7_224_en.html">## Description

Pretrained Swin model for Image Classification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.

Swin Transformer was introduced in the paper [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) by Liu et al.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/image_classifier_swin_base_patch4_window7_224_en_4.3.0_3.0_1675783112124.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/image_classifier_swin_base_patch4_window7_224_en_4.3.0_3.0_1675783112124.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
                
image_assembler = ImageAssembler()\
  .setInputCol(&quot;image&quot;)\
  .setOutputCol(&quot;image_assembler&quot;)

imageClassifier = SwinForImageClassification.pretrained(&quot;image_classifier_swin_base_patch4_window7_224&quot;, &quot;en&quot;)\
  .setInputCols(&quot;image_assembler&quot;)\
  .setOutputCol(&quot;class&quot;)

pipeline = Pipeline(stages=[
  image_assembler,
  imageClassifier,
])

pipelineModel = pipeline.fit(imageDF)

pipelineDF = pipelineModel.transform(imageDF)
```
```scala

val imageAssembler = new ImageAssembler()
    .setInputCol(&quot;image&quot;)
    .setOutputCol(&quot;image_assembler&quot;)

val imageClassifier = SwinForImageClassification
    .pretrained(&quot;image_classifier_swin_base_patch4_window7_224&quot;, &quot;en&quot;)
    .setInputCols(&quot;image_assembler&quot;) 
    .setOutputCol(&quot;class&quot;) 

val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier))

val pipelineModel = pipeline.fit(imageDF)

val pipelineDF = pipelineModel.transform(imageDF)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|image_classifier_swin_base_patch4_window7_224|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[image_assembler]|
|Output Labels:|[class]|
|Language:|en|
|Size:|665.2 MB|

## References

[https://huggingface.co/microsoft/swin_base_patch4_window7_224](https://huggingface.co/microsoft/swin_base_patch4_window7_224)</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="swin" /><category term="image" /><category term="en" /><category term="english" /><category term="image_classification" /><category term="imagenet" /><category term="tensorflow" /><summary type="html">Description Pretrained Swin model for Image Classification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. Swin Transformer was introduced in the paper Swin Transformer: Hierarchical Vision Transformer using Shifted Windows by Liu et al. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU image_assembler = ImageAssembler()\ .setInputCol(&quot;image&quot;)\ .setOutputCol(&quot;image_assembler&quot;) imageClassifier = SwinForImageClassification.pretrained(&quot;image_classifier_swin_base_patch4_window7_224&quot;, &quot;en&quot;)\ .setInputCols(&quot;image_assembler&quot;)\ .setOutputCol(&quot;class&quot;) pipeline = Pipeline(stages=[ image_assembler, imageClassifier, ]) pipelineModel = pipeline.fit(imageDF) pipelineDF = pipelineModel.transform(imageDF) val imageAssembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val imageClassifier = SwinForImageClassification .pretrained(&quot;image_classifier_swin_base_patch4_window7_224&quot;, &quot;en&quot;) .setInputCols(&quot;image_assembler&quot;) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier)) val pipelineModel = pipeline.fit(imageDF) val pipelineDF = pipelineModel.transform(imageDF) Model Information Model Name: image_classifier_swin_base_patch4_window7_224 Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [image_assembler] Output Labels: [class] Language: en Size: 665.2 MB References https://huggingface.co/microsoft/swin_base_patch4_window7_224</summary></entry></feed>