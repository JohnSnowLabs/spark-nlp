<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-02-26T19:35:31+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Chinese Deberta Embeddings Cased model (from IDEA-CCNL)</title><link href="/2023/02/23/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh.html" rel="alternate" type="text/html" title="Chinese Deberta Embeddings Cased model (from IDEA-CCNL)" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>/2023/02/23/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh</id><content type="html" xml:base="/2023/02/23/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh.html">## Description

Pretrained DebertaV2ForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece` is a Chinese model originally trained by `IDEA-CCNL`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh_4.3.0_3.0_1677192535880.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh_4.3.0_3.0_1677192535880.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark-NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark-NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|deberta_embeddings_erlangshen_v2_chinese_sentencepiece|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[embeddings]|
|Language:|zh|
|Size:|445.8 MB|
|Case sensitive:|false|

## References

https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="deberta" /><category term="deberta_embeddings" /><category term="debertav2formaskedlm" /><category term="zh" /><category term="tensorflow" /><summary type="html">Description Pretrained DebertaV2ForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece is a Chinese model originally trained by IDEA-CCNL. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark-NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark-NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: deberta_embeddings_erlangshen_v2_chinese_sentencepiece Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [embeddings] Language: zh Size: 445.8 MB Case sensitive: false References https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece</summary></entry><entry><title type="html">Multilingual DistilBertForMaskedLM Cased model (from hf-maintainers)</title><link href="/2023/02/23/distilbert_embeddings_base_multilingual_cased_xx.html" rel="alternate" type="text/html" title="Multilingual DistilBertForMaskedLM Cased model (from hf-maintainers)" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>/2023/02/23/distilbert_embeddings_base_multilingual_cased_xx</id><content type="html" xml:base="/2023/02/23/distilbert_embeddings_base_multilingual_cased_xx.html">## Description

Pretrained DistilBertForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `distilbert-base-multilingual-cased` is a Multilingual model originally trained by `hf-maintainers`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distilbert_embeddings_base_multilingual_cased_xx_4.3.0_3.0_1677190875798.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distilbert_embeddings_base_multilingual_cased_xx_4.3.0_3.0_1677190875798.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distilbert_embeddings_base_multilingual_cased|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[embeddings]|
|Language:|xx|
|Size:|505.8 MB|
|Case sensitive:|false|

## References

https://huggingface.co/distilbert-base-multilingual-cased</content><author><name>John Snow Labs</name></author><category term="distilbert" /><category term="open_source" /><category term="distilbert_embeddings" /><category term="distilbertformaskedlm" /><category term="xx" /><category term="tensorflow" /><summary type="html">Description Pretrained DistilBertForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. distilbert-base-multilingual-cased is a Multilingual model originally trained by hf-maintainers. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: distilbert_embeddings_base_multilingual_cased Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [embeddings] Language: xx Size: 505.8 MB Case sensitive: false References https://huggingface.co/distilbert-base-multilingual-cased</summary></entry><entry><title type="html">English Bert Embeddings Cased model (from aditeyabaral)</title><link href="/2023/02/22/bert_embeddings_carlbert_webex_mlm_spatial_en.html" rel="alternate" type="text/html" title="English Bert Embeddings Cased model (from aditeyabaral)" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>/2023/02/22/bert_embeddings_carlbert_webex_mlm_spatial_en</id><content type="html" xml:base="/2023/02/22/bert_embeddings_carlbert_webex_mlm_spatial_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `carlbert-webex-mlm-spatial` is a English model originally trained by `aditeyabaral`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_carlbert_webex_mlm_spatial_en_4.3.0_3.0_1677087512961.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_carlbert_webex_mlm_spatial_en_4.3.0_3.0_1677087512961.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_carlbert_webex_mlm_spatial&quot;,&quot;de&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;Ich liebe Spark-NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_carlbert_webex_mlm_spatial&quot;,&quot;de&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;Ich liebe Spark-NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_carlbert_webex_mlm_spatial|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|406.6 MB|
|Case sensitive:|true|

## References

https://huggingface.co/aditeyabaral/carlbert-webex-mlm-spatial</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="bert" /><category term="bert_embeddings" /><category term="bertformaskedlm" /><category term="en" /><category term="tensorflow" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. carlbert-webex-mlm-spatial is a English model originally trained by aditeyabaral. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_carlbert_webex_mlm_spatial&quot;,&quot;de&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;Ich liebe Spark-NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_carlbert_webex_mlm_spatial&quot;,&quot;de&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;Ich liebe Spark-NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_carlbert_webex_mlm_spatial Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 406.6 MB Case sensitive: true References https://huggingface.co/aditeyabaral/carlbert-webex-mlm-spatial</summary></entry><entry><title type="html">English Bert Embeddings Cased model (from nlpie)</title><link href="/2023/02/22/bert_embeddings_distil_clinical_en.html" rel="alternate" type="text/html" title="English Bert Embeddings Cased model (from nlpie)" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>/2023/02/22/bert_embeddings_distil_clinical_en</id><content type="html" xml:base="/2023/02/22/bert_embeddings_distil_clinical_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `distil-clinicalbert` is a English model originally trained by `nlpie`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_distil_clinical_en_4.3.0_3.0_1677088459443.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_distil_clinical_en_4.3.0_3.0_1677088459443.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_distil_clinical&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark-NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_distil_clinical&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark-NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_distil_clinical|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|247.1 MB|
|Case sensitive:|true|

## References

https://huggingface.co/nlpie/distil-clinicalbert</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="bert" /><category term="bert_embeddings" /><category term="bertformaskedlm" /><category term="en" /><category term="tensorflow" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. distil-clinicalbert is a English model originally trained by nlpie. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_distil_clinical&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark-NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_distil_clinical&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark-NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_distil_clinical Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 247.1 MB Case sensitive: true References https://huggingface.co/nlpie/distil-clinicalbert</summary></entry><entry><title type="html">English Bert Embeddings Cased model (from Shafin)</title><link href="/2023/02/21/bert_embeddings_chemical_uncased_finetuned_cust_c1_cust_en.html" rel="alternate" type="text/html" title="English Bert Embeddings Cased model (from Shafin)" /><published>2023-02-21T00:00:00+00:00</published><updated>2023-02-21T00:00:00+00:00</updated><id>/2023/02/21/bert_embeddings_chemical_uncased_finetuned_cust_c1_cust_en</id><content type="html" xml:base="/2023/02/21/bert_embeddings_chemical_uncased_finetuned_cust_c1_cust_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `chemical-bert-uncased-finetuned-cust-c1-cust` is a English model originally trained by `Shafin`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_chemical_uncased_finetuned_cust_c1_cust_en_4.3.0_3.0_1677001598364.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_chemical_uncased_finetuned_cust_c1_cust_en_4.3.0_3.0_1677001598364.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c1_cust&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c1_cust&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_chemical_uncased_finetuned_cust_c1_cust|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|412.1 MB|
|Case sensitive:|true|

## References

https://huggingface.co/shafin/chemical-bert-uncased-finetuned-cust-c1-cust</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="bert" /><category term="bert_embeddings" /><category term="bertformaskedlm" /><category term="en" /><category term="tensorflow" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. chemical-bert-uncased-finetuned-cust-c1-cust is a English model originally trained by Shafin. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c1_cust&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c1_cust&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_chemical_uncased_finetuned_cust_c1_cust Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 412.1 MB Case sensitive: true References https://huggingface.co/shafin/chemical-bert-uncased-finetuned-cust-c1-cust</summary></entry><entry><title type="html">English Bert Embeddings Cased model (from Shafin)</title><link href="/2023/02/21/bert_embeddings_chemical_uncased_finetuned_cust_c2_en.html" rel="alternate" type="text/html" title="English Bert Embeddings Cased model (from Shafin)" /><published>2023-02-21T00:00:00+00:00</published><updated>2023-02-21T00:00:00+00:00</updated><id>/2023/02/21/bert_embeddings_chemical_uncased_finetuned_cust_c2_en</id><content type="html" xml:base="/2023/02/21/bert_embeddings_chemical_uncased_finetuned_cust_c2_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `chemical-bert-uncased-finetuned-cust-c2` is a English model originally trained by `shafin`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_chemical_uncased_finetuned_cust_c2_en_4.3.0_3.0_1676998811176.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_chemical_uncased_finetuned_cust_c2_en_4.3.0_3.0_1676998811176.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c2&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c2&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_chemical_uncased_finetuned_cust_c2|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|412.1 MB|
|Case sensitive:|true|

## References

https://huggingface.co/shafin/chemical-bert-uncased-finetuned-cust-c2</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="bert" /><category term="bert_embeddings" /><category term="bertformaskedlm" /><category term="en" /><category term="tensorflow" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. chemical-bert-uncased-finetuned-cust-c2 is a English model originally trained by shafin. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c2&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_chemical_uncased_finetuned_cust_c2&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_chemical_uncased_finetuned_cust_c2 Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 412.1 MB Case sensitive: true References https://huggingface.co/shafin/chemical-bert-uncased-finetuned-cust-c2</summary></entry><entry><title type="html">English Bert Embeddings Cased model (from Tristan)</title><link href="/2023/02/21/bert_embeddings_olm_base_uncased_oct_2022_en.html" rel="alternate" type="text/html" title="English Bert Embeddings Cased model (from Tristan)" /><published>2023-02-21T00:00:00+00:00</published><updated>2023-02-21T00:00:00+00:00</updated><id>/2023/02/21/bert_embeddings_olm_base_uncased_oct_2022_en</id><content type="html" xml:base="/2023/02/21/bert_embeddings_olm_base_uncased_oct_2022_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `olm-bert-base-uncased-oct-2022` is a English model originally trained by `Tristan`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_olm_base_uncased_oct_2022_en_4.3.0_3.0_1676999449577.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_olm_base_uncased_oct_2022_en_4.3.0_3.0_1676999449577.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_olm_base_uncased_oct_2022&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_olm_base_uncased_oct_2022&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_olm_base_uncased_oct_2022|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|467.5 MB|
|Case sensitive:|true|

## References

https://huggingface.co/Tristan/olm-bert-base-uncased-oct-2022</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="bert" /><category term="bert_embeddings" /><category term="bertformaskedlm" /><category term="en" /><category term="tensorflow" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. olm-bert-base-uncased-oct-2022 is a English model originally trained by Tristan. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_olm_base_uncased_oct_2022&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_olm_base_uncased_oct_2022&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_olm_base_uncased_oct_2022 Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 467.5 MB Case sensitive: true References https://huggingface.co/Tristan/olm-bert-base-uncased-oct-2022</summary></entry><entry><title type="html">bert base cased ieee test</title><link href="/2023/02/21/ieeeBERT_en.html" rel="alternate" type="text/html" title="bert base cased ieee test" /><published>2023-02-21T00:00:00+00:00</published><updated>2023-02-21T00:00:00+00:00</updated><id>/2023/02/21/ieeeBERT_en</id><content type="html" xml:base="/2023/02/21/ieeeBERT_en.html">## Description

bert base cased ieee test

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/community.johnsnowlabs.com/Zhengyi-Xiao/ieeeBERT_en_4.3.0_3.2_1677009476381.zip){:.button.button-orange}
[Copy S3 URI](s3://community.johnsnowlabs.com/Zhengyi-Xiao/ieeeBERT_en_4.3.0_3.2_1677009476381.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
bert base cased ieee test
```

&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ieeeBERT|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Community|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|406.7 MB|
|Case sensitive:|true|</content><author><name>Zhengyi-Xiao</name></author><category term="en" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description bert base cased ieee test Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU bert base cased ieee test Model Information Model Name: ieeeBERT Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Community Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 406.7 MB Case sensitive: true</summary></entry><entry><title type="html">English BERT Embeddings (from hatemestinbejaia)</title><link href="/2023/02/21/bert_embeddings_legalbert_adept_en.html" rel="alternate" type="text/html" title="English BERT Embeddings (from hatemestinbejaia)" /><published>2023-02-21T00:00:00+00:00</published><updated>2023-02-21T00:00:00+00:00</updated><id>/2023/02/21/bert_embeddings_legalbert_adept_en</id><content type="html" xml:base="/2023/02/21/bert_embeddings_legalbert_adept_en.html">## Description

Pretrained BERT Embeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `legalbert-adept` is a English model originally trained by `hatemestinbejaia`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_legalbert_adept_en_4.3.0_3.0_1676979162440.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_legalbert_adept_en_4.3.0_3.0_1676979162440.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
 documentAssembler = nlp.DocumentAssembler() \
      .setInputCol(&quot;text&quot;) \
      .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)
  
embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_legalbert_adept&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)
    
pipeline = nlp.Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
      .setInputCol(&quot;text&quot;) 
      .setOutputCol(&quot;document&quot;)
 
val tokenizer = new Tokenizer() 
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_legalbert_adept&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) 
    .setOutputCol(&quot;embeddings&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark NLP&quot;).toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_legalbert_adept|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|410.1 MB|
|Case sensitive:|true|

## References

https://huggingface.co/hatemestinbejaia/legalbert-adept</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="en" /><category term="english" /><category term="embeddings" /><category term="transformer" /><category term="open_source" /><summary type="html">Description Pretrained BERT Embeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. legalbert-adept is a English model originally trained by hatemestinbejaia. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_legalbert_adept&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) pipeline = nlp.Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_legalbert_adept&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark NLP&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_legalbert_adept Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: en Size: 410.1 MB Case sensitive: true References https://huggingface.co/hatemestinbejaia/legalbert-adept</summary></entry><entry><title type="html">English BERT Embeddings (from dlicari)</title><link href="/2023/02/21/bert_embeddings_lsg16k_Italian_Legal_it.html" rel="alternate" type="text/html" title="English BERT Embeddings (from dlicari)" /><published>2023-02-21T00:00:00+00:00</published><updated>2023-02-21T00:00:00+00:00</updated><id>/2023/02/21/bert_embeddings_lsg16k_Italian_Legal_it</id><content type="html" xml:base="/2023/02/21/bert_embeddings_lsg16k_Italian_Legal_it.html">## Description

Pretrained BERT Embeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `lsg16k-Italian-Legal-BERT` is a Italian model originally trained by `dlicari`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_lsg16k_Italian_Legal_it_4.3.0_3.0_1676980225424.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_lsg16k_Italian_Legal_it_4.3.0_3.0_1676980225424.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
 documentAssembler = nlp.DocumentAssembler() \
      .setInputCol(&quot;text&quot;) \
      .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)
  
embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_lsg16k_Italian_Legal&quot;,&quot;it&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)
    
pipeline = nlp.Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;Adoro Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
      .setInputCol(&quot;text&quot;) 
      .setOutputCol(&quot;document&quot;)
 
val tokenizer = new Tokenizer() 
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_lsg16k_Italian_Legal&quot;,&quot;it&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) 
    .setOutputCol(&quot;embeddings&quot;)

val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;Adoro Spark NLP&quot;).toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_lsg16k_Italian_Legal|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[bert]|
|Language:|it|
|Size:|457.4 MB|
|Case sensitive:|true|

## References

https://huggingface.co/dlicari/lsg16k-Italian-Legal-BERT</content><author><name>John Snow Labs</name></author><category term="longformer" /><category term="it" /><category term="italian" /><category term="embeddings" /><category term="transformer" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description Pretrained BERT Embeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. lsg16k-Italian-Legal-BERT is a Italian model originally trained by dlicari. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_lsg16k_Italian_Legal&quot;,&quot;it&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) pipeline = nlp.Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;Adoro Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val embeddings = BertEmbeddings.pretrained(&quot;bert_embeddings_lsg16k_Italian_Legal&quot;,&quot;it&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;Adoro Spark NLP&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_lsg16k_Italian_Legal Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [bert] Language: it Size: 457.4 MB Case sensitive: true References https://huggingface.co/dlicari/lsg16k-Italian-Legal-BERT</summary></entry></feed>