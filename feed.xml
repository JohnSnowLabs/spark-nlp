<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-03-06T08:54:29+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Medical Question Answering (biogpt)</title><link href="/2023/02/26/biogpt_pubmed_qa_en.html" rel="alternate" type="text/html" title="Medical Question Answering (biogpt)" /><published>2023-02-26T00:00:00+00:00</published><updated>2023-02-26T00:00:00+00:00</updated><id>/2023/02/26/biogpt_pubmed_qa_en</id><content type="html" xml:base="/2023/02/26/biogpt_pubmed_qa_en.html">## Description

This model has been trained with medical documents and can generate two types of answers, short and long.
Types of questions are supported: `&quot;short&quot;` (producing yes/no/maybe) answers and `&quot;full&quot;` (long answers).

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/biogpt_pubmed_qa_en_4.3.0_3.0_1677406773484.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/biogpt_pubmed_qa_en_4.3.0_3.0_1677406773484.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = MultiDocumentAssembler()\
    .setInputCols(&quot;question&quot;, &quot;context&quot;)\
    .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;)

med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
    .setMaxNewTokens(100)\
    .setOutputCol(&quot;answer&quot;)\
    .setQuestionType(&quot;short&quot;) #long

pipeline = Pipeline(stages=[document_assembler, med_qa])

paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65-97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus-stimulus and stimulus-response spatial compatibility.&quot;
long_question = &quot;What is the effect of directing attention on memory?&quot;
yes_no_question = &quot;Does directing attention improve memory for items?&quot;

data = spark.createDataFrame(
    [
        [long_question, paper_abstract, &quot;long&quot;],
        [yes_no_question, paper_abstract, &quot;short&quot;],
    ]
).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;)


pipeline.fit(data).transform(data.where(&quot;question_type == 'long'&quot;))\
    .select(&quot;answer.result&quot;)\
    .show(truncate=False)

pipeline.fit(data).transform(data.where(&quot;question_type == 'short'&quot;))\
    .select(&quot;answer.result&quot;)\
    .show(truncate=False)
```
```scala
val document_assembler = new MultiDocumentAssembler()
    .setInputCols(&quot;question&quot;, &quot;context&quot;)
    .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;)

val med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;)
    .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    .setMaxNewTokens(100)
    .setOutputCol(&quot;answer&quot;)
    .setQuestionType(&quot;short&quot;) #long

val pipeline = new Pipeline().setStages(Array(document_assembler, med_qa))

paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65-97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus-stimulus and stimulus-response spatial compatibility.&quot;
long_question = &quot;What is the effect of directing attention on memory?&quot;
yes_no_question = &quot;Does directing attention improve memory for items?&quot;

val data = Seq( 
    (long_question, paper_abstract,&quot;long&quot; ),
    (yes_no_question, paper_abstract, &quot;short&quot;))
    .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
#short result
+------+
|result|
+------+
|[no]  |
+------+

#long result
+------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                |
+------------------------------------------------------------------------------------------------------------------------------------------------------+
|[the results of the two experiments suggest that the visual indexeing theory does not fully explain the effects that spatial attention has on memory.]|
+------------------------------------------------------------------------------------------------------------------------------------------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|biogpt_pubmed_qa|
|Compatibility:|Healthcare NLP 4.3.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|1.1 GB|
|Case sensitive:|true|</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="en" /><category term="clinical" /><category term="biogpt" /><category term="gpt" /><category term="pubmed" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description This model has been trained with medical documents and can generate two types of answers, short and long. Types of questions are supported: &quot;short&quot; (producing yes/no/maybe) answers and &quot;full&quot; (long answers). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler()\ .setInputCols(&quot;question&quot;, &quot;context&quot;)\ .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setMaxNewTokens(100)\ .setOutputCol(&quot;answer&quot;)\ .setQuestionType(&quot;short&quot;) #long pipeline = Pipeline(stages=[document_assembler, med_qa]) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65-97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus-stimulus and stimulus-response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; data = spark.createDataFrame( [ [long_question, paper_abstract, &quot;long&quot;], [yes_no_question, paper_abstract, &quot;short&quot;], ] ).toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) pipeline.fit(data).transform(data.where(&quot;question_type == 'long'&quot;))\ .select(&quot;answer.result&quot;)\ .show(truncate=False) pipeline.fit(data).transform(data.where(&quot;question_type == 'short'&quot;))\ .select(&quot;answer.result&quot;)\ .show(truncate=False) val document_assembler = new MultiDocumentAssembler() .setInputCols(&quot;question&quot;, &quot;context&quot;) .setOutputCols(&quot;document_question&quot;, &quot;document_context&quot;) val med_qa = MedicalQuestionAnswering.pretrained(&quot;medical_qa_biogpt&quot;,&quot;en&quot;,&quot;clinical/models&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setMaxNewTokens(100) .setOutputCol(&quot;answer&quot;) .setQuestionType(&quot;short&quot;) #long val pipeline = new Pipeline().setStages(Array(document_assembler, med_qa)) paper_abstract = &quot;The visual indexing theory proposed by Zenon Pylyshyn (Cognition, 32, 65-97, 1989) predicts that visual attention mechanisms are employed when mental images are projected onto a visual scene. Recent eye-tracking studies have supported this hypothesis by showing that people tend to look at empty places where requested information has been previously presented. However, it has remained unclear to what extent this behavior is related to memory performance. The aim of the present study was to explore whether the manipulation of spatial attention can facilitate memory retrieval. In two experiments, participants were asked first to memorize a set of four objects and then to determine whether a probe word referred to any of the objects. The results of both experiments indicate that memory accuracy is not affected by the current focus of attention and that all the effects of directing attention to specific locations on response times can be explained in terms of stimulus-stimulus and stimulus-response spatial compatibility.&quot; long_question = &quot;What is the effect of directing attention on memory?&quot; yes_no_question = &quot;Does directing attention improve memory for items?&quot; val data = Seq( (long_question, paper_abstract,&quot;long&quot; ), (yes_no_question, paper_abstract, &quot;short&quot;)) .toDS.toDF(&quot;question&quot;, &quot;context&quot;, &quot;question_type&quot;) val result = pipeline.fit(data).transform(data) Results #short result +------+ |result| +------+ |[no] | +------+ #long result +------------------------------------------------------------------------------------------------------------------------------------------------------+ |result | +------------------------------------------------------------------------------------------------------------------------------------------------------+ |[the results of the two experiments suggest that the visual indexeing theory does not fully explain the effects that spatial attention has on memory.]| +------------------------------------------------------------------------------------------------------------------------------------------------------+ Model Information Model Name: biogpt_pubmed_qa Compatibility: Healthcare NLP 4.3.0+ License: Licensed Edition: Official Language: en Size: 1.1 GB Case sensitive: true</summary></entry><entry><title type="html">Voice of the Patients</title><link href="/2023/02/25/ner_vop_slim_wip_en.html" rel="alternate" type="text/html" title="Voice of the Patients" /><published>2023-02-25T00:00:00+00:00</published><updated>2023-02-25T00:00:00+00:00</updated><id>/2023/02/25/ner_vop_slim_wip_en</id><content type="html" xml:base="/2023/02/25/ner_vop_slim_wip_en.html">## Description

This model extracts healthcare-related terms from the documents transferred from the patient's own sentences.

Note: 'wip' suffix indicates that the model development is work-in-progress and will be finalised and the model performance will improved in the upcoming releases.

## Predicted Entities

`AdmissionDischarge`, `Age`, `BodyPart`, `ClinicalDept`, `DateTime`, `Disease`, `Dosage_Strength`, `Drug`, `Duration`, `Employment`, `Form`, `Frequency`, `Gender`, `Laterality`, `Procedure`, `PsychologicalCondition`, `RelationshipStatus`, `Route`, `Symptom`, `Test`, `Vaccine`, `VitalTest`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_vop_slim_wip_en_4.3.1_3.0_1677342424243.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_vop_slim_wip_en_4.3.1_3.0_1677342424243.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_vop_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;Hello,I'm 20 year old girl. I'm diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed,poor digestion, panic attacks, depression, left chest pain, increased heart rate, rapidly weight loss,  from 4 months. Because of this, I stayed in the hospital and just discharged from hospital. I had many other blood tests, brain mri, ultrasound scan, endoscopy because of some dumb doctors bcs they were not able to diagnose actual problem. Finally I got an appointment with a homeopathy doctor finally he find that i was suffering from hyperthyroid and my TSH was 0.15 T3 and T4 is normal . Also i have b12 deficiency and vitamin D deficiency so I'm taking weekly supplement of vitamin D and 1000 mcg b12 daily. I'm taking homeopathy medicine for 40 days and took 2nd test after 30 days. My TSH is 0.5 now. I feel a little bit relief from weakness and depression but I'm facing with 2 new problem from last week that is breathtaking problem and very rapid heartrate. I just want to know if i should start allopathy medicine or homeopathy is okay? Bcs i heard that thyroid take time to start recover. So please let me know if both of medicines take same time. Because some of my friends advising me to start allopathy and never take a chance as i can develop some serious problems.Sorry for my poor english😐Thank you.&quot;]


data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_vop_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;Hello,I'm 20 year old girl. I'm diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed,poor digestion, panic attacks, depression, left chest pain, increased heart rate, rapidly weight loss,  from 4 months. Because of this, I stayed in the hospital and just discharged from hospital. I had many other blood tests, brain mri, ultrasound scan, endoscopy because of some dumb doctors bcs they were not able to diagnose actual problem. Finally I got an appointment with a homeopathy doctor finally he find that i was suffering from hyperthyroid and my TSH was 0.15 T3 and T4 is normal . Also i have b12 deficiency and vitamin D deficiency so I'm taking weekly supplement of vitamin D and 1000 mcg b12 daily. I'm taking homeopathy medicine for 40 days and took 2nd test after 30 days. My TSH is 0.5 now. I feel a little bit relief from weakness and depression but I'm facing with 2 new problem from last week that is breathtaking problem and very rapid heartrate. I just want to know if i should start allopathy medicine or homeopathy is okay? Bcs i heard that thyroid take time to start recover. So please let me know if both of medicines take same time. Because some of my friends advising me to start allopathy and never take a chance as i can develop some serious problems.Sorry for my poor english😐Thank you.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+--------------------+-----+----+----------------------+
|chunk               |begin|end |ner_label             |
+--------------------+-----+----+----------------------+
|20 year old         |10   |20  |Age                   |
|girl                |22   |25  |Gender                |
|hyperthyroid        |47   |58  |Disease               |
|1 month ago         |60   |70  |DateTime              |
|weak                |87   |90  |Symptom               |
|panic attacks       |122  |134 |PsychologicalCondition|
|depression          |137  |146 |PsychologicalCondition|
|left                |149  |152 |Laterality            |
|chest               |154  |158 |BodyPart              |
|pain                |160  |163 |Symptom               |
|heart rate          |176  |185 |VitalTest             |
|weight loss         |196  |206 |Symptom               |
|4 months            |215  |222 |Duration              |
|hospital            |258  |265 |ClinicalDept          |
|discharged          |276  |285 |AdmissionDischarge    |
|hospital            |292  |299 |ClinicalDept          |
|blood tests         |319  |329 |Test                  |
|brain               |332  |336 |BodyPart              |
|mri                 |338  |340 |Test                  |
|ultrasound scan     |343  |357 |Test                  |
|endoscopy           |360  |368 |Procedure             |
|doctors             |391  |397 |Employment            |
|homeopathy doctor   |486  |502 |Employment            |
|he                  |512  |513 |Gender                |
|hyperthyroid        |546  |557 |Disease               |
|TSH                 |566  |568 |Test                  |
|T3                  |579  |580 |Test                  |
|T4                  |586  |587 |Test                  |
|b12 deficiency      |613  |626 |Disease               |
|vitamin D deficiency|632  |651 |Disease               |
|weekly              |667  |672 |Frequency             |
|supplement          |674  |683 |Drug                  |
|vitamin D           |688  |696 |Drug                  |
|1000 mcg            |702  |709 |Dosage_Strength       |
|b12                 |711  |713 |Drug                  |
|daily               |715  |719 |Frequency             |
|homeopathy medicine |733  |751 |Drug                  |
|40 days             |757  |763 |Duration              |
|after 30 days       |783  |795 |DateTime              |
|TSH                 |801  |803 |Test                  |
|now                 |812  |814 |DateTime              |
|weakness            |849  |856 |Symptom               |
|depression          |862  |871 |PsychologicalCondition|
|last week           |912  |920 |DateTime              |
|rapid heartrate     |960  |974 |Symptom               |
|thyroid             |1074 |1080|BodyPart              |
+--------------------+-----+----+----------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_vop_slim_wip|
|Compatibility:|Healthcare NLP 4.3.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|2.4 MB|

## Benchmarking

```bash
               label     tp    fp    fn  total precision recall     f1
               Route   25.0   4.0  15.0   40.0    0.8621  0.625 0.7246
           Procedure  161.0  48.0  70.0  231.0    0.7703  0.697 0.7318
             Vaccine   22.0   7.0   8.0   30.0    0.7586 0.7333 0.7458
  RelationshipStatus    6.0   2.0   2.0    8.0      0.75   0.75   0.75
             Disease  884.0 201.0 285.0 1169.0    0.8147 0.7562 0.7844
           Frequency  342.0  61.0 113.0  455.0    0.8486 0.7516 0.7972
            Duration  720.0 188.0 146.0  866.0     0.793 0.8314 0.8117
                Test  478.0 106.0 103.0  581.0    0.8185 0.8227 0.8206
             Symptom 1569.0 337.0 340.0 1909.0    0.8232 0.8219 0.8225
            DateTime 1558.0 277.0 296.0 1854.0     0.849 0.8403 0.8447
        ClinicalDept  157.0   9.0  48.0  205.0    0.9458 0.7659 0.8464
                Form  110.0  28.0  11.0  121.0    0.7971 0.9091 0.8494
     Dosage_Strength  184.0  25.0  33.0  217.0    0.8804 0.8479 0.8638
                Drug  672.0 109.0 103.0  775.0    0.8604 0.8671 0.8638
           VitalTest   73.0   7.0  16.0   89.0    0.9125 0.8202 0.8639
          Laterality  262.0  43.0  38.0  300.0     0.859 0.8733 0.8661
                 Age  236.0  42.0  14.0  250.0    0.8489  0.944 0.8939
PsychologicalCond...  144.0  20.0  14.0  158.0     0.878 0.9114 0.8944
            BodyPart 1319.0 139.0 160.0 1479.0    0.9047 0.8918 0.8982
          Employment  541.0  25.0  77.0  618.0    0.9558 0.8754 0.9139
  AdmissionDischarge   13.0   0.0   1.0   14.0       1.0 0.9286  0.963
              Gender  548.0  26.0  12.0  560.0    0.9547 0.9786 0.9665
```</content><author><name>John Snow Labs</name></author><category term="ner" /><category term="clinical" /><category term="en" /><category term="licensed" /><category term="vop" /><category term="voice" /><category term="patient" /><summary type="html">Description This model extracts healthcare-related terms from the documents transferred from the patient’s own sentences. Note: ‘wip’ suffix indicates that the model development is work-in-progress and will be finalised and the model performance will improved in the upcoming releases. Predicted Entities AdmissionDischarge, Age, BodyPart, ClinicalDept, DateTime, Disease, Dosage_Strength, Drug, Duration, Employment, Form, Frequency, Gender, Laterality, Procedure, PsychologicalCondition, RelationshipStatus, Route, Symptom, Test, Vaccine, VitalTest Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_vop_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;Hello,I'm 20 year old girl. I'm diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed,poor digestion, panic attacks, depression, left chest pain, increased heart rate, rapidly weight loss, from 4 months. Because of this, I stayed in the hospital and just discharged from hospital. I had many other blood tests, brain mri, ultrasound scan, endoscopy because of some dumb doctors bcs they were not able to diagnose actual problem. Finally I got an appointment with a homeopathy doctor finally he find that i was suffering from hyperthyroid and my TSH was 0.15 T3 and T4 is normal . Also i have b12 deficiency and vitamin D deficiency so I'm taking weekly supplement of vitamin D and 1000 mcg b12 daily. I'm taking homeopathy medicine for 40 days and took 2nd test after 30 days. My TSH is 0.5 now. I feel a little bit relief from weakness and depression but I'm facing with 2 new problem from last week that is breathtaking problem and very rapid heartrate. I just want to know if i should start allopathy medicine or homeopathy is okay? Bcs i heard that thyroid take time to start recover. So please let me know if both of medicines take same time. Because some of my friends advising me to start allopathy and never take a chance as i can develop some serious problems.Sorry for my poor english😐Thank you.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_vop_slim_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;Hello,I'm 20 year old girl. I'm diagnosed with hyperthyroid 1 month ago. I was feeling weak, light headed,poor digestion, panic attacks, depression, left chest pain, increased heart rate, rapidly weight loss, from 4 months. Because of this, I stayed in the hospital and just discharged from hospital. I had many other blood tests, brain mri, ultrasound scan, endoscopy because of some dumb doctors bcs they were not able to diagnose actual problem. Finally I got an appointment with a homeopathy doctor finally he find that i was suffering from hyperthyroid and my TSH was 0.15 T3 and T4 is normal . Also i have b12 deficiency and vitamin D deficiency so I'm taking weekly supplement of vitamin D and 1000 mcg b12 daily. I'm taking homeopathy medicine for 40 days and took 2nd test after 30 days. My TSH is 0.5 now. I feel a little bit relief from weakness and depression but I'm facing with 2 new problem from last week that is breathtaking problem and very rapid heartrate. I just want to know if i should start allopathy medicine or homeopathy is okay? Bcs i heard that thyroid take time to start recover. So please let me know if both of medicines take same time. Because some of my friends advising me to start allopathy and never take a chance as i can develop some serious problems.Sorry for my poor english😐Thank you.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +--------------------+-----+----+----------------------+ |chunk |begin|end |ner_label | +--------------------+-----+----+----------------------+ |20 year old |10 |20 |Age | |girl |22 |25 |Gender | |hyperthyroid |47 |58 |Disease | |1 month ago |60 |70 |DateTime | |weak |87 |90 |Symptom | |panic attacks |122 |134 |PsychologicalCondition| |depression |137 |146 |PsychologicalCondition| |left |149 |152 |Laterality | |chest |154 |158 |BodyPart | |pain |160 |163 |Symptom | |heart rate |176 |185 |VitalTest | |weight loss |196 |206 |Symptom | |4 months |215 |222 |Duration | |hospital |258 |265 |ClinicalDept | |discharged |276 |285 |AdmissionDischarge | |hospital |292 |299 |ClinicalDept | |blood tests |319 |329 |Test | |brain |332 |336 |BodyPart | |mri |338 |340 |Test | |ultrasound scan |343 |357 |Test | |endoscopy |360 |368 |Procedure | |doctors |391 |397 |Employment | |homeopathy doctor |486 |502 |Employment | |he |512 |513 |Gender | |hyperthyroid |546 |557 |Disease | |TSH |566 |568 |Test | |T3 |579 |580 |Test | |T4 |586 |587 |Test | |b12 deficiency |613 |626 |Disease | |vitamin D deficiency|632 |651 |Disease | |weekly |667 |672 |Frequency | |supplement |674 |683 |Drug | |vitamin D |688 |696 |Drug | |1000 mcg |702 |709 |Dosage_Strength | |b12 |711 |713 |Drug | |daily |715 |719 |Frequency | |homeopathy medicine |733 |751 |Drug | |40 days |757 |763 |Duration | |after 30 days |783 |795 |DateTime | |TSH |801 |803 |Test | |now |812 |814 |DateTime | |weakness |849 |856 |Symptom | |depression |862 |871 |PsychologicalCondition| |last week |912 |920 |DateTime | |rapid heartrate |960 |974 |Symptom | |thyroid |1074 |1080|BodyPart | +--------------------+-----+----+----------------------+ Model Information Model Name: ner_vop_slim_wip Compatibility: Healthcare NLP 4.3.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 2.4 MB Benchmarking label tp fp fn total precision recall f1 Route 25.0 4.0 15.0 40.0 0.8621 0.625 0.7246 Procedure 161.0 48.0 70.0 231.0 0.7703 0.697 0.7318 Vaccine 22.0 7.0 8.0 30.0 0.7586 0.7333 0.7458 RelationshipStatus 6.0 2.0 2.0 8.0 0.75 0.75 0.75 Disease 884.0 201.0 285.0 1169.0 0.8147 0.7562 0.7844 Frequency 342.0 61.0 113.0 455.0 0.8486 0.7516 0.7972 Duration 720.0 188.0 146.0 866.0 0.793 0.8314 0.8117 Test 478.0 106.0 103.0 581.0 0.8185 0.8227 0.8206 Symptom 1569.0 337.0 340.0 1909.0 0.8232 0.8219 0.8225 DateTime 1558.0 277.0 296.0 1854.0 0.849 0.8403 0.8447 ClinicalDept 157.0 9.0 48.0 205.0 0.9458 0.7659 0.8464 Form 110.0 28.0 11.0 121.0 0.7971 0.9091 0.8494 Dosage_Strength 184.0 25.0 33.0 217.0 0.8804 0.8479 0.8638 Drug 672.0 109.0 103.0 775.0 0.8604 0.8671 0.8638 VitalTest 73.0 7.0 16.0 89.0 0.9125 0.8202 0.8639 Laterality 262.0 43.0 38.0 300.0 0.859 0.8733 0.8661 Age 236.0 42.0 14.0 250.0 0.8489 0.944 0.8939 PsychologicalCond... 144.0 20.0 14.0 158.0 0.878 0.9114 0.8944 BodyPart 1319.0 139.0 160.0 1479.0 0.9047 0.8918 0.8982 Employment 541.0 25.0 77.0 618.0 0.9558 0.8754 0.9139 AdmissionDischarge 13.0 0.0 1.0 14.0 1.0 0.9286 0.963 Gender 548.0 26.0 12.0 560.0 0.9547 0.9786 0.9665</summary></entry><entry><title type="html">Extract Access to Healthcare Entities from Social Determinants of Health Texts</title><link href="/2023/02/24/ner_sdoh_access_to_healthcare_wip_en.html" rel="alternate" type="text/html" title="Extract Access to Healthcare Entities from Social Determinants of Health Texts" /><published>2023-02-24T00:00:00+00:00</published><updated>2023-02-24T00:00:00+00:00</updated><id>/2023/02/24/ner_sdoh_access_to_healthcare_wip_en</id><content type="html" xml:base="/2023/02/24/ner_sdoh_access_to_healthcare_wip_en.html">## Description

This model extracts access to healthcare information related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Insurance_Status`, `Healthcare_Institution`, `Access_To_Care`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_access_to_healthcare_wip_en_4.3.1_3.0_1677202491556.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_access_to_healthcare_wip_en_4.3.1_3.0_1677202491556.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_access_to_healthcare_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;She has a pension and private health insurance, she reports feeling lonely and isolated.&quot;,
             &quot;He also reported food insecurityduring his childhood and lack of access to adequate healthcare.&quot;,
               &quot;She used to work as a unit clerk at XYZ Medical Center.&quot;]


data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_access_to_healthcare_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;She has a pension and private health insurance, she reports feeling lonely and isolated.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-----------------------------+-----+---+----------------------+
|chunk                        |begin|end|ner_label             |
+-----------------------------+-----+---+----------------------+
|private health insurance     |22   |45 |Insurance_Status      |
|access to adequate healthcare|65   |93 |Access_To_Care        |
|XYZ Medical Center           |36   |53 |Healthcare_Institution|
+-----------------------------+-----+---+----------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_access_to_healthcare_wip|
|Compatibility:|Healthcare NLP 4.3.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|3.0 MB|

## Benchmarking

```bash
                 label	   tp	  fp	  fn	total	precision 	recall	      f1
Healthcare_Institution	 94.0	 8.0	 5.0	 99.0	 0.921569	0.949495	0.935323
        Access_To_Care	561.0	23.0	38.0	599.0	 0.960616	0.936561	0.948436
      Insurance_Status	 60.0	 5.0	 3.0	 63.0	 0.923077	0.952381	0.937500
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="clinical" /><category term="en" /><category term="social_determinants" /><category term="ner" /><category term="sdoh" /><category term="public_health" /><category term="access" /><category term="healthcare" /><category term="access_to_healthcare" /><summary type="html">Description This model extracts access to healthcare information related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Insurance_Status, Healthcare_Institution, Access_To_Care Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_access_to_healthcare_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;She has a pension and private health insurance, she reports feeling lonely and isolated.&quot;, &quot;He also reported food insecurityduring his childhood and lack of access to adequate healthcare.&quot;, &quot;She used to work as a unit clerk at XYZ Medical Center.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_access_to_healthcare_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;She has a pension and private health insurance, she reports feeling lonely and isolated.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +-----------------------------+-----+---+----------------------+ |chunk |begin|end|ner_label | +-----------------------------+-----+---+----------------------+ |private health insurance |22 |45 |Insurance_Status | |access to adequate healthcare|65 |93 |Access_To_Care | |XYZ Medical Center |36 |53 |Healthcare_Institution| +-----------------------------+-----+---+----------------------+ Model Information Model Name: ner_sdoh_access_to_healthcare_wip Compatibility: Healthcare NLP 4.3.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 3.0 MB Benchmarking label tp fp fn total precision recall f1 Healthcare_Institution 94.0 8.0 5.0 99.0 0.921569 0.949495 0.935323 Access_To_Care 561.0 23.0 38.0 599.0 0.960616 0.936561 0.948436 Insurance_Status 60.0 5.0 3.0 63.0 0.923077 0.952381 0.937500</summary></entry><entry><title type="html">Extract Community Condition Entities from Social Determinants of Health Texts</title><link href="/2023/02/24/ner_sdoh_community_condition_wip_en.html" rel="alternate" type="text/html" title="Extract Community Condition Entities from Social Determinants of Health Texts" /><published>2023-02-24T00:00:00+00:00</published><updated>2023-02-24T00:00:00+00:00</updated><id>/2023/02/24/ner_sdoh_community_condition_wip_en</id><content type="html" xml:base="/2023/02/24/ner_sdoh_community_condition_wip_en.html">## Description

This model extracts community condition information related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Transportation`, `Community_Living_Conditions`, `Housing`, `Food_Insecurity`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_community_condition_wip_en_4.3.1_3.0_1677201525944.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_community_condition_wip_en_4.3.1_3.0_1677201525944.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_community_condition_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;He is currently experiencing financial stress due to job insecurity, and he lives in a small apartment in a densely populated area with limited access to green spaces and outdoor recreational activities.&quot;,
             &quot;Patient reports difficulty affording healthy food, and relies oncheaper, processed options.&quot;,
               &quot;She reports her husband and sons provide transportation top medical apptsand do her grocery shopping.&quot;]


data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_community_condition_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;He is currently experiencing financial stress due to job insecurity, and he lives in a small apartment in a densely populated area with limited access to green spaces and outdoor recreational activities.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-------------------------------+-----+---+---------------------------+
|chunk                          |begin|end|ner_label                  |
+-------------------------------+-----+---+---------------------------+
|small apartment                |87   |101|Housing                    |
|green spaces                   |154  |165|Community_Living_Conditions|
|outdoor recreational activities|171  |201|Community_Living_Conditions|
|healthy food                   |37   |48 |Food_Insecurity            |
|transportation                 |41   |54 |Transportation             |
+-------------------------------+-----+---+---------------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_community_condition_wip|
|Compatibility:|Healthcare NLP 4.3.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|3.0 MB|

## Benchmarking

```bash
                      label 	 tp	  fp	  fn	total	precision	  recall	      f1
            Food_Insecurity	 40.0	 0.0	 5.0	 45.0	 1.000000	0.888889	0.941176
                    Housing	376.0	20.0	28.0	404.0	 0.949495	0.930693	0.940000
Community_Living_Conditions	 97.0	 8.0	 8.0	105.0	 0.923810	0.923810	0.923810
             Transportation	 31.0	 2.0	 0.0	 31.0	 0.939394	1.000000	0.968750
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="en" /><category term="clinical" /><category term="sdoh" /><category term="social_determinants" /><category term="ner" /><category term="public_health" /><category term="community" /><category term="condition" /><category term="community_condition" /><summary type="html">Description This model extracts community condition information related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Transportation, Community_Living_Conditions, Housing, Food_Insecurity Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_community_condition_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;He is currently experiencing financial stress due to job insecurity, and he lives in a small apartment in a densely populated area with limited access to green spaces and outdoor recreational activities.&quot;, &quot;Patient reports difficulty affording healthy food, and relies oncheaper, processed options.&quot;, &quot;She reports her husband and sons provide transportation top medical apptsand do her grocery shopping.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_community_condition_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;He is currently experiencing financial stress due to job insecurity, and he lives in a small apartment in a densely populated area with limited access to green spaces and outdoor recreational activities.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +-------------------------------+-----+---+---------------------------+ |chunk |begin|end|ner_label | +-------------------------------+-----+---+---------------------------+ |small apartment |87 |101|Housing | |green spaces |154 |165|Community_Living_Conditions| |outdoor recreational activities|171 |201|Community_Living_Conditions| |healthy food |37 |48 |Food_Insecurity | |transportation |41 |54 |Transportation | +-------------------------------+-----+---+---------------------------+ Model Information Model Name: ner_sdoh_community_condition_wip Compatibility: Healthcare NLP 4.3.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 3.0 MB Benchmarking label tp fp fn total precision recall f1 Food_Insecurity 40.0 0.0 5.0 45.0 1.000000 0.888889 0.941176 Housing 376.0 20.0 28.0 404.0 0.949495 0.930693 0.940000 Community_Living_Conditions 97.0 8.0 8.0 105.0 0.923810 0.923810 0.923810 Transportation 31.0 2.0 0.0 31.0 0.939394 1.000000 0.968750</summary></entry><entry><title type="html">Extract Health and Behaviours Problems Entities from Social Determinants of Health Texts</title><link href="/2023/02/24/ner_sdoh_health_behaviours_problems_wip_en.html" rel="alternate" type="text/html" title="Extract Health and Behaviours Problems Entities from Social Determinants of Health Texts" /><published>2023-02-24T00:00:00+00:00</published><updated>2023-02-24T00:00:00+00:00</updated><id>/2023/02/24/ner_sdoh_health_behaviours_problems_wip_en</id><content type="html" xml:base="/2023/02/24/ner_sdoh_health_behaviours_problems_wip_en.html">## Description

This model extracts health and behaviours problems related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Diet`, `Mental_Health`, `Obesity`, `Eating_Disorder`, `Sexual_Activity`, `Disability`, `Quality_Of_Life`, `Other_Disease`, `Exercise`, `Communicable_Disease`, `Hyperlipidemia`, `Hypertension`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_health_behaviours_problems_wip_en_4.3.1_3.0_1677198610586.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_health_behaviours_problems_wip_en_4.3.1_3.0_1677198610586.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_health_behaviours_problems_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;She has not been getting regular exercise and not followed diet for approximately two years due to chronic sciatic pain.&quot;,
             &quot;Medical History: The patient is a 32-year-old female who presents with a history of anxiety, depression, bulimia nervosa, elevated cholesterol, and substance abuse.&quot;,
               &quot;Pt was intubated atthe scene &amp; currently sedated due to high BP. Also, he is currently on social security disability.&quot;]



data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_health_behaviours_problems_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;She has not been getting regular exercise for approximately two years due to chronic sciatic pain.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+--------------------+-----+---+---------------+
|chunk               |begin|end|ner_label      |
+--------------------+-----+---+---------------+
|regular exercise    |25   |40 |Exercise       |
|diet                |59   |62 |Diet           |
|chronic sciatic pain|99   |118|Other_Disease  |
|anxiety             |84   |90 |Mental_Health  |
|depression          |93   |102|Mental_Health  |
|bulimia nervosa     |105  |119|Eating_Disorder|
|elevated cholesterol|122  |141|Hyperlipidemia |
|high BP             |56   |62 |Hypertension   |
|disability          |106  |115|Disability     |
+--------------------+-----+---+---------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_health_behaviours_problems_wip|
|Compatibility:|Healthcare NLP 4.3.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|3.0 MB|

## Benchmarking

```bash
               label	   tp	   fp	   fn	 total	precision	  recall	      f1
     Quality_Of_Life	127.0	 19.0	  3.0	 130.0	 0.869863	0.976923	0.920290
     Eating_Disorder	 56.0	  5.0	  0.0	  56.0	 0.918033	1.000000	0.957265
             Obesity	 16.0	  2.0	  7.0	  23.0	 0.888889	0.695652	0.780488
            Exercise	103.0	  6.0	  5.0	 108.0	 0.944954	0.953704	0.949309
Communicable_Disease	 61.0	 11.0	  5.0	  66.0	 0.847222	0.924242	0.884058
        Hypertension	 52.0	  0.0	  2.0	  54.0	 1.000000	0.962963	0.981132
       Other_Disease 1068.0	 85.0	 79.0 1147.0	 0.926279	0.931125	0.928696
                Diet	 66.0	 12.0	 15.0	  81.0	 0.846154	0.814815	0.830189
          Disability	 95.0	  1.0	  6.0	 101.0	 0.989583	0.940594	0.964467
       Mental_Health 1020.0	 45.0	134.0	1154.0	 0.957746	0.883882	0.919333
      Hyperlipidemia	 19.0	  1.0	  2.0	  21.0	 0.950000	0.904762	0.926829
     Sexual_Activity	 82.0	 15.0	  6.0	  88.0	 0.845361	0.931818	0.886486
```</content><author><name>John Snow Labs</name></author><category term="clinical" /><category term="licensed" /><category term="en" /><category term="social_determinants" /><category term="ner" /><category term="public_health" /><category term="sdoh" /><category term="health" /><category term="behaviours" /><category term="problems" /><category term="health_behaviours_problems" /><summary type="html">Description This model extracts health and behaviours problems related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Diet, Mental_Health, Obesity, Eating_Disorder, Sexual_Activity, Disability, Quality_Of_Life, Other_Disease, Exercise, Communicable_Disease, Hyperlipidemia, Hypertension Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_health_behaviours_problems_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;She has not been getting regular exercise and not followed diet for approximately two years due to chronic sciatic pain.&quot;, &quot;Medical History: The patient is a 32-year-old female who presents with a history of anxiety, depression, bulimia nervosa, elevated cholesterol, and substance abuse.&quot;, &quot;Pt was intubated atthe scene &amp;amp; currently sedated due to high BP. Also, he is currently on social security disability.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_health_behaviours_problems_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;She has not been getting regular exercise for approximately two years due to chronic sciatic pain.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +--------------------+-----+---+---------------+ |chunk |begin|end|ner_label | +--------------------+-----+---+---------------+ |regular exercise |25 |40 |Exercise | |diet |59 |62 |Diet | |chronic sciatic pain|99 |118|Other_Disease | |anxiety |84 |90 |Mental_Health | |depression |93 |102|Mental_Health | |bulimia nervosa |105 |119|Eating_Disorder| |elevated cholesterol|122 |141|Hyperlipidemia | |high BP |56 |62 |Hypertension | |disability |106 |115|Disability | +--------------------+-----+---+---------------+ Model Information Model Name: ner_sdoh_health_behaviours_problems_wip Compatibility: Healthcare NLP 4.3.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 3.0 MB Benchmarking label tp fp fn total precision recall f1 Quality_Of_Life 127.0 19.0 3.0 130.0 0.869863 0.976923 0.920290 Eating_Disorder 56.0 5.0 0.0 56.0 0.918033 1.000000 0.957265 Obesity 16.0 2.0 7.0 23.0 0.888889 0.695652 0.780488 Exercise 103.0 6.0 5.0 108.0 0.944954 0.953704 0.949309 Communicable_Disease 61.0 11.0 5.0 66.0 0.847222 0.924242 0.884058 Hypertension 52.0 0.0 2.0 54.0 1.000000 0.962963 0.981132 Other_Disease 1068.0 85.0 79.0 1147.0 0.926279 0.931125 0.928696 Diet 66.0 12.0 15.0 81.0 0.846154 0.814815 0.830189 Disability 95.0 1.0 6.0 101.0 0.989583 0.940594 0.964467 Mental_Health 1020.0 45.0 134.0 1154.0 0.957746 0.883882 0.919333 Hyperlipidemia 19.0 1.0 2.0 21.0 0.950000 0.904762 0.926829 Sexual_Activity 82.0 15.0 6.0 88.0 0.845361 0.931818 0.886486</summary></entry><entry><title type="html">Mapping Entities with Corresponding RxNorm Codes According to According to National Institute of Health (NIH) Database</title><link href="/2023/02/23/rxnorm_nih_mapper_en.html" rel="alternate" type="text/html" title="Mapping Entities with Corresponding RxNorm Codes According to According to National Institute of Health (NIH) Database" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>/2023/02/23/rxnorm_nih_mapper_en</id><content type="html" xml:base="/2023/02/23/rxnorm_nih_mapper_en.html">## Description

This pretrained model maps entities with their corresponding RxNorm codes according to the National Institute of Health (NIH) database. It returns Rxnorm codes with their NIH Rxnorm Term Types within a parenthesis.

## Predicted Entities

`rxnorm_code`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/rxnorm_nih_mapper_en_4.3.0_3.2_1677156206111.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/rxnorm_nih_mapper_en_4.3.0_3.2_1677156206111.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
.setInputCol('text')\
.setOutputCol('document')

sentence_detector = SentenceDetector()\
.setInputCols([&quot;document&quot;])\
.setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
.setInputCols(&quot;sentence&quot;)\
.setOutputCol(&quot;token&quot;)

word_embeddings = WordEmbeddingsModel\
.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
.setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
.setOutputCol(&quot;embeddings&quot;)

posology_ner_model = MedicalNerModel\
.pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
.setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
.setOutputCol(&quot;posology_ner&quot;)

posology_ner_converter = NerConverterInternal()\
.setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;posology_ner&quot;)\
.setOutputCol(&quot;ner_chunk&quot;)

chunkerMapper = ChunkMapperModel\
.pretrained(&quot;rxnorm_nih_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
.setInputCols([&quot;ner_chunk&quot;])\
.setOutputCol(&quot;mappings&quot;)\
.setRels([&quot;rxnorm_code&quot;])

mapper_pipeline = Pipeline().setStages([
document_assembler,
sentence_detector,
tokenizer, 
word_embeddings,
posology_ner_model, 
posology_ner_converter, 
chunkerMapper])


test_data = spark.createDataFrame([[&quot;The patient was given Adapin 10 MG Oral Capsule, acetohexamide and Parlodel&quot;]]).toDF(&quot;text&quot;)

mapper_model = mapper_pipeline.fit(test_data)

result= mapper_model.transform(test_data)
```
```scala
val document_assembler = new DocumentAssembler()\
.setInputCol(&quot;text&quot;)\
.setOutputCol(&quot;document&quot;)

val sentence_detector = new SentenceDetector()\
.setInputCols(Array(&quot;document&quot;))\
.setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()\
.setInputCols(&quot;sentence&quot;)\
.setOutputCol(&quot;token&quot;)

val word_embeddings = WordEmbeddingsModel
.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
.setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))\
.setOutputCol(&quot;embeddings&quot;)

val posology_ner_model = MedicalNerModel
.pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
.setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))\
.setOutputCol(&quot;posology_ner&quot;)

val posology_ner_converter = new NerConverterInternal()\
.setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;posology_ner&quot;)\
.setOutputCol(&quot;ner_chunk&quot;)

val chunkerMapper = ChunkMapperModel
.pretrained(&quot;rxnorm_nih_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
.setInputCols(Array(&quot;ner_chunk&quot;))\
.setOutputCol(&quot;mappings&quot;)\
.setRels(Array(&quot;rxnorm_code&quot;)) 

val mapper_pipeline = new Pipeline().setStages(Array(
document_assembler,
sentence_detector,
tokenizer, 
word_embeddings,
posology_ner_model, 
posology_ner_converter, 
chunkerMapper))


val data = Seq(&quot;The patient was given Adapin 10 MG Oral Capsule, acetohexamide and Parlodel&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data) 
```
&lt;/div&gt;

## Results

```bash
+-------------------------+-------------+-----------+
|ner_chunk                |mappings     |relation   |
+-------------------------+-------------+-----------+
|Adapin 10 MG Oral Capsule|1911002 (SY) |rxnorm_code|
|acetohexamide            |12250421 (IN)|rxnorm_code|
|Parlodel                 |829 (BN)     |rxnorm_code|
+-------------------------+-------------+-----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|rxnorm_nih_mapper|
|Compatibility:|Healthcare NLP 4.3.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[chunk]|
|Output Labels:|[mappings]|
|Language:|en|
|Size:|10.3 MB|

## References

Trained on February 2023 with NIH data: 
 https://www.nlm.nih.gov/research/umls/rxnorm/docs/rxnormfiles.html</content><author><name>John Snow Labs</name></author><category term="rxnorm" /><category term="nih" /><category term="chunk_mapping" /><category term="clinical" /><category term="en" /><category term="licensed" /><summary type="html">Description This pretrained model maps entities with their corresponding RxNorm codes according to the National Institute of Health (NIH) database. It returns Rxnorm codes with their NIH Rxnorm Term Types within a parenthesis. Predicted Entities rxnorm_code Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') sentence_detector = SentenceDetector()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols(&quot;sentence&quot;)\ .setOutputCol(&quot;token&quot;) word_embeddings = WordEmbeddingsModel\ .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) posology_ner_model = MedicalNerModel\ .pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;posology_ner&quot;) posology_ner_converter = NerConverterInternal()\ .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;posology_ner&quot;)\ .setOutputCol(&quot;ner_chunk&quot;) chunkerMapper = ChunkMapperModel\ .pretrained(&quot;rxnorm_nih_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;ner_chunk&quot;])\ .setOutputCol(&quot;mappings&quot;)\ .setRels([&quot;rxnorm_code&quot;]) mapper_pipeline = Pipeline().setStages([ document_assembler, sentence_detector, tokenizer, word_embeddings, posology_ner_model, posology_ner_converter, chunkerMapper]) test_data = spark.createDataFrame([[&quot;The patient was given Adapin 10 MG Oral Capsule, acetohexamide and Parlodel&quot;]]).toDF(&quot;text&quot;) mapper_model = mapper_pipeline.fit(test_data) result= mapper_model.transform(test_data) val document_assembler = new DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) val sentence_detector = new SentenceDetector()\ .setInputCols(Array(&quot;document&quot;))\ .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer()\ .setInputCols(&quot;sentence&quot;)\ .setOutputCol(&quot;token&quot;) val word_embeddings = WordEmbeddingsModel .pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))\ .setOutputCol(&quot;embeddings&quot;) val posology_ner_model = MedicalNerModel .pretrained(&quot;ner_posology_greedy&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))\ .setOutputCol(&quot;posology_ner&quot;) val posology_ner_converter = new NerConverterInternal()\ .setInputCols(&quot;sentence&quot;, &quot;token&quot;, &quot;posology_ner&quot;)\ .setOutputCol(&quot;ner_chunk&quot;) val chunkerMapper = ChunkMapperModel .pretrained(&quot;rxnorm_nih_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols(Array(&quot;ner_chunk&quot;))\ .setOutputCol(&quot;mappings&quot;)\ .setRels(Array(&quot;rxnorm_code&quot;)) val mapper_pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, word_embeddings, posology_ner_model, posology_ner_converter, chunkerMapper)) val data = Seq(&quot;The patient was given Adapin 10 MG Oral Capsule, acetohexamide and Parlodel&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +-------------------------+-------------+-----------+ |ner_chunk |mappings |relation | +-------------------------+-------------+-----------+ |Adapin 10 MG Oral Capsule|1911002 (SY) |rxnorm_code| |acetohexamide |12250421 (IN)|rxnorm_code| |Parlodel |829 (BN) |rxnorm_code| +-------------------------+-------------+-----------+ Model Information Model Name: rxnorm_nih_mapper Compatibility: Healthcare NLP 4.3.0+ License: Licensed Edition: Official Input Labels: [chunk] Output Labels: [mappings] Language: en Size: 10.3 MB References Trained on February 2023 with NIH data: https://www.nlm.nih.gov/research/umls/rxnorm/docs/rxnormfiles.html</summary></entry><entry><title type="html">Chinese Deberta Embeddings Cased model (from IDEA-CCNL)</title><link href="/2023/02/23/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh.html" rel="alternate" type="text/html" title="Chinese Deberta Embeddings Cased model (from IDEA-CCNL)" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>/2023/02/23/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh</id><content type="html" xml:base="/2023/02/23/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh.html">## Description

Pretrained DebertaV2ForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece` is a Chinese model originally trained by `IDEA-CCNL`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh_4.3.0_3.0_1677192535880.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/deberta_embeddings_erlangshen_v2_chinese_sentencepiece_zh_4.3.0_3.0_1677192535880.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark-NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark-NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|deberta_embeddings_erlangshen_v2_chinese_sentencepiece|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[embeddings]|
|Language:|zh|
|Size:|445.8 MB|
|Case sensitive:|false|

## References

https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece</content><author><name>John Snow Labs</name></author><category term="open_source" /><category term="deberta" /><category term="deberta_embeddings" /><category term="debertav2formaskedlm" /><category term="zh" /><category term="tensorflow" /><summary type="html">Description Pretrained DebertaV2ForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece is a Chinese model originally trained by IDEA-CCNL. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark-NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = DeBertaEmbeddings.pretrained(&quot;deberta_embeddings_erlangshen_v2_chinese_sentencepiece&quot;,&quot;zh&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark-NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: deberta_embeddings_erlangshen_v2_chinese_sentencepiece Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [embeddings] Language: zh Size: 445.8 MB Case sensitive: false References https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece</summary></entry><entry><title type="html">Multilingual DistilBertForMaskedLM Cased model (from hf-maintainers)</title><link href="/2023/02/23/distilbert_embeddings_base_multilingual_cased_xx.html" rel="alternate" type="text/html" title="Multilingual DistilBertForMaskedLM Cased model (from hf-maintainers)" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>/2023/02/23/distilbert_embeddings_base_multilingual_cased_xx</id><content type="html" xml:base="/2023/02/23/distilbert_embeddings_base_multilingual_cased_xx.html">## Description

Pretrained DistilBertForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `distilbert-base-multilingual-cased` is a Multilingual model originally trained by `hf-maintainers`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distilbert_embeddings_base_multilingual_cased_xx_4.3.0_3.0_1677190875798.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distilbert_embeddings_base_multilingual_cased_xx_4.3.0_3.0_1677190875798.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(True)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distilbert_embeddings_base_multilingual_cased|
|Compatibility:|Spark NLP 4.3.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[embeddings]|
|Language:|xx|
|Size:|505.8 MB|
|Case sensitive:|false|

## References

https://huggingface.co/distilbert-base-multilingual-cased</content><author><name>John Snow Labs</name></author><category term="distilbert" /><category term="open_source" /><category term="distilbert_embeddings" /><category term="distilbertformaskedlm" /><category term="xx" /><category term="tensorflow" /><summary type="html">Description Pretrained DistilBertForMaskedLM model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. distilbert-base-multilingual-cased is a Multilingual model originally trained by hf-maintainers. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, embeddings]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val embeddings = DistilBertEmbeddings.pretrained(&quot;distilbert_embeddings_base_multilingual_cased&quot;,&quot;xx&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(True) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, embeddings)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: distilbert_embeddings_base_multilingual_cased Compatibility: Spark NLP 4.3.0+ License: Open Source Edition: Official Input Labels: [sentence, token] Output Labels: [embeddings] Language: xx Size: 505.8 MB Case sensitive: false References https://huggingface.co/distilbert-base-multilingual-cased</summary></entry><entry><title type="html">Extract Substance Usage Entities from Social Determinants of Health Texts</title><link href="/2023/02/23/ner_sdoh_substance_usage_wip_en.html" rel="alternate" type="text/html" title="Extract Substance Usage Entities from Social Determinants of Health Texts" /><published>2023-02-23T00:00:00+00:00</published><updated>2023-02-23T00:00:00+00:00</updated><id>/2023/02/23/ner_sdoh_substance_usage_wip_en</id><content type="html" xml:base="/2023/02/23/ner_sdoh_substance_usage_wip_en.html">## Description

This model extracts substance usage information related to Social Determinants of Health from various kinds of biomedical documents.

## Predicted Entities

`Smoking`, `Substance_Duration`, `Substance_Use`, `Substance_Quantity`, `Substance_Frequency`, `Alcohol`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_substance_usage_wip_en_4.3.1_3.0_1677186927181.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ner_sdoh_substance_usage_wip_en_4.3.1_3.0_1677186927181.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;token&quot;)

clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_substance_usage_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
    ])

sample_texts = [&quot;He does drink occasional alcohol approximately 5 to 6 alcoholic drinks per month.&quot;,
             &quot;He continues to smoke one pack of cigarettes daily, as he has for the past 28 years.&quot;]


data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val document_assembler = new DocumentAssembler()
    .setInputCol(&quot;text&quot;)
    .setOutputCol(&quot;document&quot;)

val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentence&quot;)
    .setOutputCol(&quot;token&quot;)

val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)

val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_substance_usage_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)

val pipeline = new Pipeline().setStages(Array(
    document_assembler, 
    sentence_detector,
    tokenizer,
    clinical_embeddings,
    ner_model,
    ner_converter   
))

val data = Seq(&quot;He does drink occasional alcohol approximately 5 to 6 alcoholic drinks per month.&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+----------------+-----+---+-------------------+
|chunk           |begin|end|ner_label          |
+----------------+-----+---+-------------------+
|drink           |8    |12 |Alcohol            |
|occasional      |14   |23 |Substance_Frequency|
|alcohol         |25   |31 |Alcohol            |
|5 to 6          |47   |52 |Substance_Quantity |
|alcoholic drinks|54   |69 |Alcohol            |
|per month       |71   |79 |Substance_Frequency|
|smoke           |16   |20 |Smoking            |
|one pack        |22   |29 |Substance_Quantity |
|cigarettes      |34   |43 |Smoking            |
|daily           |45   |49 |Substance_Frequency|
|past 28 years   |70   |82 |Substance_Duration |
+----------------+-----+---+-------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ner_sdoh_substance_usage_wip|
|Compatibility:|Healthcare NLP 4.3.1+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|3.0 MB|

## Benchmarking

```bash
              label	   tp	 fp	  fn	total	 precision	  recall	      f1
Substance_Frequency	 52.0	2.0	12.0	 64.0	  0.962963	0.812500	0.881356
            Smoking	 77.0	4.0	 2.0	 79.0	  0.950617	0.974684	0.962500
            Alcohol	327.0	8.0	15.0	342.0	  0.976119	0.956140	0.966027
 Substance_Quantity	 74.0	7.0	12.0	 86.0	  0.913580	0.860465	0.886228
 Substance_Duration	 27.0	7.0	14.0	 41.0	  0.794118	0.658537	0.720000
      Substance_Use	204.0	8.0	 6.0	210.0	  0.962264	0.971429	0.966825
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="en" /><category term="sdoh" /><category term="ner" /><category term="clinical" /><category term="social_determinants" /><category term="public_health" /><category term="substance_usage" /><summary type="html">Description This model extracts substance usage information related to Social Determinants of Health from various kinds of biomedical documents. Predicted Entities Smoking, Substance_Duration, Substance_Use, Substance_Quantity, Substance_Frequency, Alcohol Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_substance_usage_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter ]) sample_texts = [&quot;He does drink occasional alcohol approximately 5 to 6 alcoholic drinks per month.&quot;, &quot;He continues to smoke one pack of cigarettes daily, as he has for the past 28 years.&quot;] data = spark.createDataFrame(sample_texts, StringType()).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;token&quot;) val clinical_embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) val ner_model = MedicalNerModel.pretrained(&quot;ner_sdoh_substance_usage_wip&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;,&quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) val pipeline = new Pipeline().setStages(Array( document_assembler, sentence_detector, tokenizer, clinical_embeddings, ner_model, ner_converter )) val data = Seq(&quot;He does drink occasional alcohol approximately 5 to 6 alcoholic drinks per month.&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results +----------------+-----+---+-------------------+ |chunk |begin|end|ner_label | +----------------+-----+---+-------------------+ |drink |8 |12 |Alcohol | |occasional |14 |23 |Substance_Frequency| |alcohol |25 |31 |Alcohol | |5 to 6 |47 |52 |Substance_Quantity | |alcoholic drinks|54 |69 |Alcohol | |per month |71 |79 |Substance_Frequency| |smoke |16 |20 |Smoking | |one pack |22 |29 |Substance_Quantity | |cigarettes |34 |43 |Smoking | |daily |45 |49 |Substance_Frequency| |past 28 years |70 |82 |Substance_Duration | +----------------+-----+---+-------------------+ Model Information Model Name: ner_sdoh_substance_usage_wip Compatibility: Healthcare NLP 4.3.1+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 3.0 MB Benchmarking label tp fp fn total precision recall f1 Substance_Frequency 52.0 2.0 12.0 64.0 0.962963 0.812500 0.881356 Smoking 77.0 4.0 2.0 79.0 0.950617 0.974684 0.962500 Alcohol 327.0 8.0 15.0 342.0 0.976119 0.956140 0.966027 Substance_Quantity 74.0 7.0 12.0 86.0 0.913580 0.860465 0.886228 Substance_Duration 27.0 7.0 14.0 41.0 0.794118 0.658537 0.720000 Substance_Use 204.0 8.0 6.0 210.0 0.962264 0.971429 0.966825</summary></entry><entry><title type="html">Mapping National Drug Codes (NDC) Codes with Corresponding Drug Brand Names</title><link href="/2023/02/22/ndc_drug_brandname_mapper_en.html" rel="alternate" type="text/html" title="Mapping National Drug Codes (NDC) Codes with Corresponding Drug Brand Names" /><published>2023-02-22T00:00:00+00:00</published><updated>2023-02-22T00:00:00+00:00</updated><id>/2023/02/22/ndc_drug_brandname_mapper_en</id><content type="html" xml:base="/2023/02/22/ndc_drug_brandname_mapper_en.html">## Description

This pretrained model maps National Drug Codes (NDC) codes with their corresponding drug brand names.

## Predicted Entities

`drug_brand_name`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/ndc_drug_brandname_mapper_en_4.3.0_3.0_1677102197072.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/ndc_drug_brandname_mapper_en_4.3.0_3.0_1677102197072.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

mapper = DocMapperModel.pretrained(&quot;ndc_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;mappings&quot;)\
    .setRels([&quot;drug_brand_name&quot;])\

pipeline = Pipeline(
    stages = [
        documentAssembler,
        mapper
        ])

model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) 

lp = LightPipeline(model)

result = lp.fullAnnotate([&quot;0009-4992&quot;, &quot;57894-150&quot;])
```
```scala
val documentAssembler = new DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

val mapper = DocMapperModel.pretrained(&quot;ndc_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;mappings&quot;)\
    .setRels(Array(&quot;drug_brand_name&quot;)\

val pipeline = new Pipeline(stages = Array(
        documentAssembler,
        mapper
))

val data = Seq(Array(&quot;0009-4992&quot;, &quot;57894-150&quot;)).toDS.toDF(&quot;text&quot;)

val result= pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
|    | ndc_code   | drug_brand_name   |
|---:|:-----------|:------------------|
|  0 | 0009-4992  | ZYVOX             |
|  1 | 57894-150  | ZYTIGA            |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ndc_drug_brandname_mapper|
|Compatibility:|Healthcare NLP 4.3.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[chunk]|
|Output Labels:|[brandname]|
|Language:|en|
|Size:|917.7 KB|</content><author><name>John Snow Labs</name></author><category term="chunk_mapping" /><category term="ndc" /><category term="drug_brand_name" /><category term="clinical" /><category term="en" /><category term="licensed" /><summary type="html">Description This pretrained model maps National Drug Codes (NDC) codes with their corresponding drug brand names. Predicted Entities drug_brand_name Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) mapper = DocMapperModel.pretrained(&quot;ndc_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;mappings&quot;)\ .setRels([&quot;drug_brand_name&quot;])\ pipeline = Pipeline( stages = [ documentAssembler, mapper ]) model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) lp = LightPipeline(model) result = lp.fullAnnotate([&quot;0009-4992&quot;, &quot;57894-150&quot;]) val documentAssembler = new DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) val mapper = DocMapperModel.pretrained(&quot;ndc_drug_brandname_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;mappings&quot;)\ .setRels(Array(&quot;drug_brand_name&quot;)\ val pipeline = new Pipeline(stages = Array( documentAssembler, mapper )) val data = Seq(Array(&quot;0009-4992&quot;, &quot;57894-150&quot;)).toDS.toDF(&quot;text&quot;) val result= pipeline.fit(data).transform(data) Results | | ndc_code | drug_brand_name | |---:|:-----------|:------------------| | 0 | 0009-4992 | ZYVOX | | 1 | 57894-150 | ZYTIGA | Model Information Model Name: ndc_drug_brandname_mapper Compatibility: Healthcare NLP 4.3.0+ License: Licensed Edition: Official Input Labels: [chunk] Output Labels: [brandname] Language: en Size: 917.7 KB</summary></entry></feed>