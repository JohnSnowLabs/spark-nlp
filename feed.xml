<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2025-08-01T09:36:50+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">NuExtract 2.0 2B by NuMind</title><link href="/2025/07/18/nuextract_2.0_2B_en.html" rel="alternate" type="text/html" title="NuExtract 2.0 2B by NuMind" /><published>2025-07-18T00:00:00+00:00</published><updated>2025-07-18T00:00:00+00:00</updated><id>/2025/07/18/nuextract_2.0_2B_en</id><content type="html" xml:base="/2025/07/18/nuextract_2.0_2B_en.html">## Description

NuExtract 2.0 is a family of models trained specifically for structured information extraction tasks. It supports both multimodal inputs and is multilingual.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/nuextract_2.0_2B_en_6.0.0_3.0_1752879851166.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/nuextract_2.0_2B_en_6.0.0_3.0_1752879851166.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import os
from pathlib import Path
from pyspark.sql.functions import lit
from sparknlp.annotator import *
from sparknlp.base import *
from pyspark.ml import Pipeline
from sparknlp.base import LightPipeline

url1 = &quot;https://github.com/openvinotoolkit/openvino_notebooks/assets/29454499/d5fbbd1a-d484-415c-88cb-9986625b7b11&quot;
url2 = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;

Path(&quot;images&quot;).mkdir(exist_ok=True)

!wget -q -O images/image1.jpg {url1}
!wget -q -O images/image2.jpg {url2}

images_path = &quot;file://&quot; + os.getcwd() + &quot;/images/&quot;
image_df = spark.read.format(&quot;image&quot;).load(path=images_path)

prompt = (
    &quot;&lt;|im_start|&gt;system
You are a helpful assistant.&lt;|im_end|&gt;
&quot;
    &quot;&lt;|im_start|&gt;user
&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;&quot;
    &quot;Describe this image.&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
&quot;
)
test_df = image_df.withColumn(&quot;text&quot;, lit(prompt))

image_assembler = ImageAssembler() \
    .setInputCol(&quot;image&quot;) \
    .setOutputCol(&quot;image_assembler&quot;)

imageClassifier = Qwen2VLTransformer.pretrained(&quot;nuextract_2.0_2B&quot;, &quot;en&quot;) \
    .setMaxOutputLength(50) \
    .setInputCols(&quot;image_assembler&quot;) \
    .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline(stages=[
    image_assembler, 
    imageClassifier
])

model = pipeline.fit(test_df)

image_path = os.path.join(os.getcwd(), &quot;images&quot;, &quot;image1.jpg&quot;)

prompt = (
    &quot;&lt;|im_start|&gt;system
You are a helpful assistant.&lt;|im_end|&gt;
&quot;
    &quot;&lt;|im_start|&gt;user
&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;&quot;
    &quot;Describe this image.&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
&quot;
)

light_pipeline = LightPipeline(model)
annotations_result = light_pipeline.fullAnnotateImage(image_path, prompt)

for result in annotations_result:
    print(result[&quot;answer&quot;])

```
```scala
import java.nio.file.{Files, Paths}
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.functions.lit
import com.johnsnowlabs.nlp.base._
import com.johnsnowlabs.nlp.annotator._
import com.johnsnowlabs.nlp.annotators.vision._
import scala.sys.process._

Files.createDirectories(Paths.get(&quot;images&quot;))

s&quot;wget -q -O images/image1.jpg https://github.com/openvinotoolkit/openvino_notebooks/assets/29454499/d5fbbd1a-d484-415c-88cb-9986625b7b11&quot;.!
s&quot;wget -q -O images/image2.jpg http://images.cocodataset.org/val2017/000000039769.jpg&quot;.!

val imagesPath = &quot;file://&quot; + System.getProperty(&quot;user.dir&quot;) + &quot;/images/&quot;
val imageDf = spark.read.format(&quot;image&quot;).load(imagesPath)

val prompt =
  &quot;&lt;|im_start|&gt;system
You are a helpful assistant.&lt;|im_end|&gt;
&quot; +
  &quot;&lt;|im_start|&gt;user
&lt;|vision_start|&gt;&lt;|image_pad|&gt;&lt;|vision_end|&gt;Describe this image.&lt;|im_end|&gt;
&quot; +
  &quot;&lt;|im_start|&gt;assistant
&quot;

val testDf = imageDf.withColumn(&quot;text&quot;, lit(prompt))

val imageAssembler = new ImageAssembler()
  .setInputCol(&quot;image&quot;)
  .setOutputCol(&quot;image_assembler&quot;)

val imageClassifier = Qwen2VLTransformer.pretrained(&quot;nuextract_2.0_2B&quot;, &quot;en&quot;)
  .setInputCols(&quot;image_assembler&quot;)
  .setOutputCol(&quot;answer&quot;)
  .setMaxOutputLength(50)

val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier))
val model = pipeline.fit(testDf)

val lightPipeline = new LightPipeline(model)
val imagePath = Paths.get(&quot;images/image1.jpg&quot;).toAbsolutePath.toString
val results = lightPipeline.fullAnnotateImage(imagePath, prompt)

results.foreach(r =&gt; println(r(&quot;answer&quot;)))

```
&lt;/div&gt;

## Results

```bash
The image shows a cat lying inside a cardboard box. The cat has a relaxed posture, with its paws tucked under its body and its head resting on its front paws. The box is positioned on a light-colored carpet, and the background includes...
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|nuextract_2.0_2B|
|Compatibility:|Spark NLP 6.0.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[image_assembler]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|1.5 GB|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="llm" /><category term="qwen2_vl" /><category term="image_to_text" /><category term="conversational" /><category term="openvino" /><summary type="html">Description NuExtract 2.0 is a family of models trained specifically for structured information extraction tasks. It supports both multimodal inputs and is multilingual. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import os from pathlib import Path from pyspark.sql.functions import lit from sparknlp.annotator import * from sparknlp.base import * from pyspark.ml import Pipeline from sparknlp.base import LightPipeline url1 = &quot;https://github.com/openvinotoolkit/openvino_notebooks/assets/29454499/d5fbbd1a-d484-415c-88cb-9986625b7b11&quot; url2 = &quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot; Path(&quot;images&quot;).mkdir(exist_ok=True) !wget -q -O images/image1.jpg {url1} !wget -q -O images/image2.jpg {url2} images_path = &quot;file://&quot; + os.getcwd() + &quot;/images/&quot; image_df = spark.read.format(&quot;image&quot;).load(path=images_path) prompt = ( &quot;&amp;lt;|im_start|&amp;gt;system You are a helpful assistant.&amp;lt;|im_end|&amp;gt; &quot; &quot;&amp;lt;|im_start|&amp;gt;user &amp;lt;|vision_start|&amp;gt;&amp;lt;|image_pad|&amp;gt;&amp;lt;|vision_end|&amp;gt;&quot; &quot;Describe this image.&amp;lt;|im_end|&amp;gt; &amp;lt;|im_start|&amp;gt;assistant &quot; ) test_df = image_df.withColumn(&quot;text&quot;, lit(prompt)) image_assembler = ImageAssembler() \ .setInputCol(&quot;image&quot;) \ .setOutputCol(&quot;image_assembler&quot;) imageClassifier = Qwen2VLTransformer.pretrained(&quot;nuextract_2.0_2B&quot;, &quot;en&quot;) \ .setMaxOutputLength(50) \ .setInputCols(&quot;image_assembler&quot;) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline(stages=[ image_assembler, imageClassifier ]) model = pipeline.fit(test_df) image_path = os.path.join(os.getcwd(), &quot;images&quot;, &quot;image1.jpg&quot;) prompt = ( &quot;&amp;lt;|im_start|&amp;gt;system You are a helpful assistant.&amp;lt;|im_end|&amp;gt; &quot; &quot;&amp;lt;|im_start|&amp;gt;user &amp;lt;|vision_start|&amp;gt;&amp;lt;|image_pad|&amp;gt;&amp;lt;|vision_end|&amp;gt;&quot; &quot;Describe this image.&amp;lt;|im_end|&amp;gt; &amp;lt;|im_start|&amp;gt;assistant &quot; ) light_pipeline = LightPipeline(model) annotations_result = light_pipeline.fullAnnotateImage(image_path, prompt) for result in annotations_result: print(result[&quot;answer&quot;]) import java.nio.file.{Files, Paths} import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions.lit import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotator._ import com.johnsnowlabs.nlp.annotators.vision._ import scala.sys.process._ Files.createDirectories(Paths.get(&quot;images&quot;)) s&quot;wget -q -O images/image1.jpg https://github.com/openvinotoolkit/openvino_notebooks/assets/29454499/d5fbbd1a-d484-415c-88cb-9986625b7b11&quot;.! s&quot;wget -q -O images/image2.jpg http://images.cocodataset.org/val2017/000000039769.jpg&quot;.! val imagesPath = &quot;file://&quot; + System.getProperty(&quot;user.dir&quot;) + &quot;/images/&quot; val imageDf = spark.read.format(&quot;image&quot;).load(imagesPath) val prompt = &quot;&amp;lt;|im_start|&amp;gt;system You are a helpful assistant.&amp;lt;|im_end|&amp;gt; &quot; + &quot;&amp;lt;|im_start|&amp;gt;user &amp;lt;|vision_start|&amp;gt;&amp;lt;|image_pad|&amp;gt;&amp;lt;|vision_end|&amp;gt;Describe this image.&amp;lt;|im_end|&amp;gt; &quot; + &quot;&amp;lt;|im_start|&amp;gt;assistant &quot; val testDf = imageDf.withColumn(&quot;text&quot;, lit(prompt)) val imageAssembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val imageClassifier = Qwen2VLTransformer.pretrained(&quot;nuextract_2.0_2B&quot;, &quot;en&quot;) .setInputCols(&quot;image_assembler&quot;) .setOutputCol(&quot;answer&quot;) .setMaxOutputLength(50) val pipeline = new Pipeline().setStages(Array(imageAssembler, imageClassifier)) val model = pipeline.fit(testDf) val lightPipeline = new LightPipeline(model) val imagePath = Paths.get(&quot;images/image1.jpg&quot;).toAbsolutePath.toString val results = lightPipeline.fullAnnotateImage(imagePath, prompt) results.foreach(r =&amp;gt; println(r(&quot;answer&quot;))) Results The image shows a cat lying inside a cardboard box. The cat has a relaxed posture, with its paws tucked under its body and its head resting on its front paws. The box is positioned on a light-colored carpet, and the background includes... Model Information Model Name: nuextract_2.0_2B Compatibility: Spark NLP 6.0.0+ License: Open Source Edition: Official Input Labels: [image_assembler] Output Labels: [answer] Language: en Size: 1.5 GB</summary></entry><entry><title type="html">all-mpnet-base-v2 from sentence-transformers OpenVINO</title><link href="/2025/07/15/all_mpnet_base_v2_openvino_en.html" rel="alternate" type="text/html" title="all-mpnet-base-v2 from sentence-transformers OpenVINO" /><published>2025-07-15T00:00:00+00:00</published><updated>2025-07-15T00:00:00+00:00</updated><id>/2025/07/15/all_mpnet_base_v2_openvino_en</id><content type="html" xml:base="/2025/07/15/all_mpnet_base_v2_openvino_en.html">## Description

This is a sentence-transformers model: It maps sentences &amp; paragraphs to a 768-dimensional dense vector space and can be used for tasks like clustering or semantic search.

This model is intended to be used as a sentence and short paragraph encoder. Given an input text, it outputs a vector that captures the semantic information. The sentence vector may be used for information retrieval, clustering, or sentence similarity tasks.

By default, input text longer than 384 word pieces is truncated.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_mpnet_base_v2_openvino_en_6.0.0_3.0_1752610809513.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_mpnet_base_v2_openvino_en_6.0.0_3.0_1752610809513.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import MPNetEmbeddings
from pyspark.ml import Pipeline

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

mpnet_loaded = MPNetEmbeddings.load(&quot;all_mpnet_base_v2_openvino&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;mpnet_embeddings&quot;)\

pipeline = Pipeline(
    stages = [
        document_assembler,
        mpnet_loaded
  ])

data = spark.createDataFrame([
    ['William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.']
]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)

result.selectExpr(&quot;explode(mpnet_embeddings.embeddings) as embeddings&quot;).show()

```
```scala
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.embeddings.MPNetEmbeddings
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.functions.explode
import spark.implicits._

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val mpnetEmbeddings = MPNetEmbeddings.load(&quot;all_mpnet_base_v2_openvino&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;mpnet_embeddings&quot;)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  mpnetEmbeddings
))

val data = Seq(
  &quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.&quot;
).toDF(&quot;text&quot;)

val model = pipeline.fit(data)
val result = model.transform(data)

result.select(explode($&quot;mpnet_embeddings.embeddings&quot;).alias(&quot;embeddings&quot;)).show(false)

```
&lt;/div&gt;

## Results

```bash

+--------------------+
|          embeddings|
+--------------------+
|[-0.020282388, 0....|
+--------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_mpnet_base_v2_openvino|
|Compatibility:|Spark NLP 6.0.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[mpnet_embeddings]|
|Language:|en|
|Size:|406.5 MB|</content><author><name>John Snow Labs</name></author><category term="openvino" /><category term="english" /><category term="embedding" /><category term="open_source" /><category term="mpnet" /><category term="en" /><summary type="html">Description This is a sentence-transformers model: It maps sentences &amp;amp; paragraphs to a 768-dimensional dense vector space and can be used for tasks like clustering or semantic search. This model is intended to be used as a sentence and short paragraph encoder. Given an input text, it outputs a vector that captures the semantic information. The sentence vector may be used for information retrieval, clustering, or sentence similarity tasks. By default, input text longer than 384 word pieces is truncated. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import MPNetEmbeddings from pyspark.ml import Pipeline document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) mpnet_loaded = MPNetEmbeddings.load(&quot;all_mpnet_base_v2_openvino&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;mpnet_embeddings&quot;)\ pipeline = Pipeline( stages = [ document_assembler, mpnet_loaded ]) data = spark.createDataFrame([ ['William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.'] ]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.selectExpr(&quot;explode(mpnet_embeddings.embeddings) as embeddings&quot;).show() import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.embeddings.MPNetEmbeddings import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions.explode import spark.implicits._ val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val mpnetEmbeddings = MPNetEmbeddings.load(&quot;all_mpnet_base_v2_openvino&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;mpnet_embeddings&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, mpnetEmbeddings )) val data = Seq( &quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.&quot; ).toDF(&quot;text&quot;) val model = pipeline.fit(data) val result = model.transform(data) result.select(explode($&quot;mpnet_embeddings.embeddings&quot;).alias(&quot;embeddings&quot;)).show(false) Results +--------------------+ | embeddings| +--------------------+ |[-0.020282388, 0....| +--------------------+ Model Information Model Name: all_mpnet_base_v2_openvino Compatibility: Spark NLP 6.0.0+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [mpnet_embeddings] Language: en Size: 406.5 MB</summary></entry><entry><title type="html">MedEmbed base: Specialized Embedding Model for Medical and Clinical Information Retrieval (OpenVINO)</title><link href="/2025/07/15/bge_medembed_base_v0_1_openvino_en.html" rel="alternate" type="text/html" title="MedEmbed base: Specialized Embedding Model for Medical and Clinical Information Retrieval (OpenVINO)" /><published>2025-07-15T00:00:00+00:00</published><updated>2025-07-15T00:00:00+00:00</updated><id>/2025/07/15/bge_medembed_base_v0_1_openvino_en</id><content type="html" xml:base="/2025/07/15/bge_medembed_base_v0_1_openvino_en.html">## Description

MedEmbed is a family of embedding models fine-tuned specifically for medical and clinical data, designed to enhance performance in healthcare-related natural language processing (NLP) tasks, particularly information retrieval.

GitHub Repo: https://github.com/abhinand5/MedEmbed
Technical Blog Post: https://huggingface.co/blog/abhinand/medembed-finetuned-embedding-models-for-medical-ir

This model is intended for use in medical and clinical contexts to improve information retrieval, question answering, and semantic search tasks. It can be integrated into healthcare systems, research tools, and medical literature databases to enhance search capabilities and information access.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bge_medembed_base_v0_1_openvino_en_6.0.0_3.0_1752605366919.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bge_medembed_base_v0_1_openvino_en_6.0.0_3.0_1752605366919.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import BGEEmbeddings
from pyspark.ml import Pipeline

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

bge_loaded = BGEEmbeddings.load(&quot;bge_medembed_base_v0_1_openvino&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\

pipeline = Pipeline(
    stages = [
        document_assembler,
        bge_loaded
  ])

data = spark.createDataFrame([
    ['William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.']
]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)

result.selectExpr(&quot;explode(embeddings.embeddings) as embeddings&quot;).show()

```
```scala
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.embeddings.BGEEmbeddings
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.functions.explode
import spark.implicits._

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val bgeEmbeddings = BGEEmbeddings.load(&quot;bge_medembed_base_v0_1_openvino&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;bge&quot;)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  bgeEmbeddings
))

val data = Seq(
  &quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.&quot;
).toDF(&quot;text&quot;)

val model = pipeline.fit(data)
val result = model.transform(data)

result.select(explode($&quot;bge.embeddings&quot;).alias(&quot;embeddings&quot;)).show(false)

```
&lt;/div&gt;

## Results

```bash

+--------------------+
|          embeddings|
+--------------------+
|[-0.055220805, 0....|
+--------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bge_medembed_base_v0_1_openvino|
|Compatibility:|Spark NLP 6.0.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[embeddings]|
|Language:|en|
|Size:|389.7 MB|</content><author><name>John Snow Labs</name></author><category term="openvino" /><category term="english" /><category term="medical_embedding" /><category term="clinical_embedding" /><category term="information_retrieval" /><category term="open_source" /><category term="bge" /><category term="en" /><summary type="html">Description MedEmbed is a family of embedding models fine-tuned specifically for medical and clinical data, designed to enhance performance in healthcare-related natural language processing (NLP) tasks, particularly information retrieval. GitHub Repo: https://github.com/abhinand5/MedEmbed Technical Blog Post: https://huggingface.co/blog/abhinand/medembed-finetuned-embedding-models-for-medical-ir This model is intended for use in medical and clinical contexts to improve information retrieval, question answering, and semantic search tasks. It can be integrated into healthcare systems, research tools, and medical literature databases to enhance search capabilities and information access. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import BGEEmbeddings from pyspark.ml import Pipeline document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) bge_loaded = BGEEmbeddings.load(&quot;bge_medembed_base_v0_1_openvino&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ pipeline = Pipeline( stages = [ document_assembler, bge_loaded ]) data = spark.createDataFrame([ ['William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.'] ]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.selectExpr(&quot;explode(embeddings.embeddings) as embeddings&quot;).show() import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.embeddings.BGEEmbeddings import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions.explode import spark.implicits._ val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val bgeEmbeddings = BGEEmbeddings.load(&quot;bge_medembed_base_v0_1_openvino&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;bge&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, bgeEmbeddings )) val data = Seq( &quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.&quot; ).toDF(&quot;text&quot;) val model = pipeline.fit(data) val result = model.transform(data) result.select(explode($&quot;bge.embeddings&quot;).alias(&quot;embeddings&quot;)).show(false) Results +--------------------+ | embeddings| +--------------------+ |[-0.055220805, 0....| +--------------------+ Model Information Model Name: bge_medembed_base_v0_1_openvino Compatibility: Spark NLP 6.0.0+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [embeddings] Language: en Size: 389.7 MB</summary></entry><entry><title type="html">MedEmbed large: Specialized Embedding Model for Medical and Clinical Information Retrieval (OpenVINO)</title><link href="/2025/07/15/bge_medembed_large_v0_1_openvino_en.html" rel="alternate" type="text/html" title="MedEmbed large: Specialized Embedding Model for Medical and Clinical Information Retrieval (OpenVINO)" /><published>2025-07-15T00:00:00+00:00</published><updated>2025-07-15T00:00:00+00:00</updated><id>/2025/07/15/bge_medembed_large_v0_1_openvino_en</id><content type="html" xml:base="/2025/07/15/bge_medembed_large_v0_1_openvino_en.html">## Description

MedEmbed is a family of embedding models fine-tuned specifically for medical and clinical data, designed to enhance performance in healthcare-related natural language processing (NLP) tasks, particularly information retrieval.

GitHub Repo: https://github.com/abhinand5/MedEmbed
Technical Blog Post: https://huggingface.co/blog/abhinand/medembed-finetuned-embedding-models-for-medical-ir

This model is intended for use in medical and clinical contexts to improve information retrieval, question answering, and semantic search tasks. It can be integrated into healthcare systems, research tools, and medical literature databases to enhance search capabilities and information access.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bge_medembed_large_v0_1_openvino_en_6.0.0_3.0_1752608614322.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bge_medembed_large_v0_1_openvino_en_6.0.0_3.0_1752608614322.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import BGEEmbeddings
from pyspark.ml import Pipeline

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

bge_loaded = BGEEmbeddings.load(&quot;bge_medembed_large_v0_1_openvino&quot;)\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\

pipeline = Pipeline(
    stages = [
        document_assembler,
        bge_loaded
  ])

data = spark.createDataFrame([
    ['William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.']
]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)

result.selectExpr(&quot;explode(embeddings.embeddings) as embeddings&quot;).show()

```
```scala
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.embeddings.BGEEmbeddings
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.functions.explode
import spark.implicits._

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val bgeEmbeddings = BGEEmbeddings.load(&quot;bge_medembed_large_v0_1_openvino&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;bge&quot;)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  bgeEmbeddings
))

val data = Seq(
  &quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.&quot;
).toDF(&quot;text&quot;)

val model = pipeline.fit(data)
val result = model.transform(data)

result.select(explode($&quot;bge.embeddings&quot;).alias(&quot;embeddings&quot;)).show(false)

```
&lt;/div&gt;

## Results

```bash

+--------------------+
|          embeddings|
+--------------------+
|[0.0026465012, 3....|
+--------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bge_medembed_large_v0_1_openvino|
|Compatibility:|Spark NLP 6.0.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[embeddings]|
|Language:|en|
|Size:|1.2 GB|</content><author><name>John Snow Labs</name></author><category term="openvino" /><category term="english" /><category term="medical_embedding" /><category term="clinical_embedding" /><category term="information_retrieval" /><category term="open_source" /><category term="bge" /><category term="en" /><summary type="html">Description MedEmbed is a family of embedding models fine-tuned specifically for medical and clinical data, designed to enhance performance in healthcare-related natural language processing (NLP) tasks, particularly information retrieval. GitHub Repo: https://github.com/abhinand5/MedEmbed Technical Blog Post: https://huggingface.co/blog/abhinand/medembed-finetuned-embedding-models-for-medical-ir This model is intended for use in medical and clinical contexts to improve information retrieval, question answering, and semantic search tasks. It can be integrated into healthcare systems, research tools, and medical literature databases to enhance search capabilities and information access. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import BGEEmbeddings from pyspark.ml import Pipeline document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) bge_loaded = BGEEmbeddings.load(&quot;bge_medembed_large_v0_1_openvino&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ pipeline = Pipeline( stages = [ document_assembler, bge_loaded ]) data = spark.createDataFrame([ ['William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.'] ]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.selectExpr(&quot;explode(embeddings.embeddings) as embeddings&quot;).show() import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.embeddings.BGEEmbeddings import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions.explode import spark.implicits._ val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val bgeEmbeddings = BGEEmbeddings.load(&quot;bge_medembed_large_v0_1_openvino&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;bge&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, bgeEmbeddings )) val data = Seq( &quot;William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist.&quot; ).toDF(&quot;text&quot;) val model = pipeline.fit(data) val result = model.transform(data) result.select(explode($&quot;bge.embeddings&quot;).alias(&quot;embeddings&quot;)).show(false) Results +--------------------+ | embeddings| +--------------------+ |[0.0026465012, 3....| +--------------------+ Model Information Model Name: bge_medembed_large_v0_1_openvino Compatibility: Spark NLP 6.0.0+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [embeddings] Language: en Size: 1.2 GB</summary></entry><entry><title type="html">Phi-3.5-mini int4</title><link href="/2025/07/03/phi_3.5_mini_instruct_int4_en.html" rel="alternate" type="text/html" title="Phi-3.5-mini int4" /><published>2025-07-03T00:00:00+00:00</published><updated>2025-07-03T00:00:00+00:00</updated><id>/2025/07/03/phi_3.5_mini_instruct_int4_en</id><content type="html" xml:base="/2025/07/03/phi_3.5_mini_instruct_int4_en.html">## Description

Phi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites - with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family and supports 128K token context length.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/phi_3.5_mini_instruct_int4_en_6.0.4_3.4_1751538746155.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/phi_3.5_mini_instruct_int4_en_6.0.4_3.4_1751538746155.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline

document = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

Phi3 = Phi3Transformer \
    .loadSavedModel(EXPORT_PATH, spark) \
    .setMaxOutputLength(50) \
    .setDoSample(True) \
    .setInputCols([&quot;documents&quot;]) \
    .setOutputCol(&quot;generation&quot;)

pipeline = Pipeline().setStages([document, Phi3])
data = spark.createDataFrame([[&quot;Hello, I am a&quot;]]).toDF(&quot;text&quot;)
result = pipeline.fit(data).transform(data)
result.select(&quot;completions&quot;).show(truncate = False)
```

&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|phi_3.5_mini_instruct_int4|
|Compatibility:|Spark NLP 6.0.4+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents]|
|Output Labels:|[generation]|
|Language:|en|
|Size:|2.2 GB|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="openvino" /><summary type="html">Description Phi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites - with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family and supports 128K token context length. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline document = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) Phi3 = Phi3Transformer \ .loadSavedModel(EXPORT_PATH, spark) \ .setMaxOutputLength(50) \ .setDoSample(True) \ .setInputCols([&quot;documents&quot;]) \ .setOutputCol(&quot;generation&quot;) pipeline = Pipeline().setStages([document, Phi3]) data = spark.createDataFrame([[&quot;Hello, I am a&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;completions&quot;).show(truncate = False) Model Information Model Name: phi_3.5_mini_instruct_int4 Compatibility: Spark NLP 6.0.4+ License: Open Source Edition: Official Input Labels: [documents] Output Labels: [generation] Language: en Size: 2.2 GB</summary></entry><entry><title type="html">English awesome_fb_model BartForZeroShotClassification from ClaudeYang</title><link href="/2025/06/24/awesome_fb_model_en.html" rel="alternate" type="text/html" title="English awesome_fb_model BartForZeroShotClassification from ClaudeYang" /><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>/2025/06/24/awesome_fb_model_en</id><content type="html" xml:base="/2025/06/24/awesome_fb_model_en.html">## Description

Pretrained BartForZeroShotClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`awesome_fb_model` is a English model originally trained by ClaudeYang.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/awesome_fb_model_en_5.5.1_3.0_1750784933380.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/awesome_fb_model_en_5.5.1_3.0_1750784933380.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

zeroShotClassifier  = BartForZeroShotClassification.pretrained(&quot;awesome_fb_model&quot;,&quot;en&quot;) \
     .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, zeroShotClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)

val zeroShotClassifier  = BartForZeroShotClassification.pretrained(&quot;awesome_fb_model&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, zeroShotClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|awesome_fb_model|
|Compatibility:|Spark NLP 5.5.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.5 GB|

## References

https://huggingface.co/ClaudeYang/awesome_fb_model</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="zero_shot" /><category term="bart" /><category term="openvino" /><summary type="html">Description Pretrained BartForZeroShotClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.awesome_fb_model is a English model originally trained by ClaudeYang. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') zeroShotClassifier = BartForZeroShotClassification.pretrained(&quot;awesome_fb_model&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, zeroShotClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val zeroShotClassifier = BartForZeroShotClassification.pretrained(&quot;awesome_fb_model&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, zeroShotClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: awesome_fb_model Compatibility: Spark NLP 5.5.1+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 1.5 GB References https://huggingface.co/ClaudeYang/awesome_fb_model</summary></entry><entry><title type="html">English awesome_fb_model_pipeline pipeline BartForZeroShotClassification from ClaudeYang</title><link href="/2025/06/24/awesome_fb_model_pipeline_en.html" rel="alternate" type="text/html" title="English awesome_fb_model_pipeline pipeline BartForZeroShotClassification from ClaudeYang" /><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>/2025/06/24/awesome_fb_model_pipeline_en</id><content type="html" xml:base="/2025/06/24/awesome_fb_model_pipeline_en.html">## Description

Pretrained BartForZeroShotClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`awesome_fb_model_pipeline` is a English model originally trained by ClaudeYang.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/awesome_fb_model_pipeline_en_5.5.1_3.0_1750785058490.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/awesome_fb_model_pipeline_en_5.5.1_3.0_1750785058490.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

pipeline = PretrainedPipeline(&quot;awesome_fb_model_pipeline&quot;, lang = &quot;en&quot;)
annotations =  pipeline.transform(df)   

```
```scala

val pipeline = new PretrainedPipeline(&quot;awesome_fb_model_pipeline&quot;, lang = &quot;en&quot;)
val annotations = pipeline.transform(df)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|awesome_fb_model_pipeline|
|Type:|pipeline|
|Compatibility:|Spark NLP 5.5.1+|
|License:|Open Source|
|Edition:|Official|
|Language:|en|
|Size:|1.5 GB|

## References

https://huggingface.co/ClaudeYang/awesome_fb_model

## Included Models

- DocumentAssembler
- TokenizerModel
- BartForZeroShotClassification</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="pipeline" /><category term="onnx" /><summary type="html">Description Pretrained BartForZeroShotClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.awesome_fb_model_pipeline is a English model originally trained by ClaudeYang. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU pipeline = PretrainedPipeline(&quot;awesome_fb_model_pipeline&quot;, lang = &quot;en&quot;) annotations = pipeline.transform(df) val pipeline = new PretrainedPipeline(&quot;awesome_fb_model_pipeline&quot;, lang = &quot;en&quot;) val annotations = pipeline.transform(df) Model Information Model Name: awesome_fb_model_pipeline Type: pipeline Compatibility: Spark NLP 5.5.1+ License: Open Source Edition: Official Language: en Size: 1.5 GB References https://huggingface.co/ClaudeYang/awesome_fb_model Included Models DocumentAssembler TokenizerModel BartForZeroShotClassification</summary></entry><entry><title type="html">English bart_large_mnli_yahoo_answers_joeddav BartForZeroShotClassification from joeddav</title><link href="/2025/06/24/bart_large_mnli_yahoo_answers_joeddav_en.html" rel="alternate" type="text/html" title="English bart_large_mnli_yahoo_answers_joeddav BartForZeroShotClassification from joeddav" /><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>/2025/06/24/bart_large_mnli_yahoo_answers_joeddav_en</id><content type="html" xml:base="/2025/06/24/bart_large_mnli_yahoo_answers_joeddav_en.html">## Description

Pretrained BartForZeroShotClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bart_large_mnli_yahoo_answers_joeddav` is a English model originally trained by joeddav.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bart_large_mnli_yahoo_answers_joeddav_en_5.5.1_3.0_1750785248137.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bart_large_mnli_yahoo_answers_joeddav_en_5.5.1_3.0_1750785248137.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

zeroShotClassifier  = BartForZeroShotClassification.pretrained(&quot;bart_large_mnli_yahoo_answers_joeddav&quot;,&quot;en&quot;) \
     .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, zeroShotClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)
```
```scala
val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)

val zeroShotClassifier  = BartForZeroShotClassification.pretrained(&quot;bart_large_mnli_yahoo_answers_joeddav&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, zeroShotClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bart_large_mnli_yahoo_answers_joeddav|
|Compatibility:|Spark NLP 5.5.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.5 GB|

## References

References

https://huggingface.co/joeddav/bart-large-mnli-yahoo-answers</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="zero_shot" /><category term="bart" /><category term="openvino" /><summary type="html">Description Pretrained BartForZeroShotClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bart_large_mnli_yahoo_answers_joeddav is a English model originally trained by joeddav. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') zeroShotClassifier = BartForZeroShotClassification.pretrained(&quot;bart_large_mnli_yahoo_answers_joeddav&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, zeroShotClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val zeroShotClassifier = BartForZeroShotClassification.pretrained(&quot;bart_large_mnli_yahoo_answers_joeddav&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, zeroShotClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bart_large_mnli_yahoo_answers_joeddav Compatibility: Spark NLP 5.5.1+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 1.5 GB References References https://huggingface.co/joeddav/bart-large-mnli-yahoo-answers</summary></entry><entry><title type="html">English bart_large_mnli_yahoo_answers_joeddav_pipeline pipeline BartForZeroShotClassification from joeddav</title><link href="/2025/06/24/bart_large_mnli_yahoo_answers_joeddav_pipeline_en.html" rel="alternate" type="text/html" title="English bart_large_mnli_yahoo_answers_joeddav_pipeline pipeline BartForZeroShotClassification from joeddav" /><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>/2025/06/24/bart_large_mnli_yahoo_answers_joeddav_pipeline_en</id><content type="html" xml:base="/2025/06/24/bart_large_mnli_yahoo_answers_joeddav_pipeline_en.html">## Description

Pretrained BartForZeroShotClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bart_large_mnli_yahoo_answers_joeddav_pipeline` is a English model originally trained by joeddav.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bart_large_mnli_yahoo_answers_joeddav_pipeline_en_5.5.1_3.0_1750785326280.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bart_large_mnli_yahoo_answers_joeddav_pipeline_en_5.5.1_3.0_1750785326280.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
pipeline = PretrainedPipeline(&quot;bart_large_mnli_yahoo_answers_joeddav_pipeline&quot;, lang = &quot;en&quot;)
annotations =  pipeline.transform(df)
```
```scala
val pipeline = new PretrainedPipeline(&quot;bart_large_mnli_yahoo_answers_joeddav_pipeline&quot;, lang = &quot;en&quot;)
val annotations = pipeline.transform(df)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bart_large_mnli_yahoo_answers_joeddav_pipeline|
|Type:|pipeline|
|Compatibility:|Spark NLP 5.5.1+|
|License:|Open Source|
|Edition:|Official|
|Language:|en|
|Size:|1.5 GB|

## References

References

https://huggingface.co/joeddav/bart-large-mnli-yahoo-answers

## Included Models

- DocumentAssembler
- TokenizerModel
- BartForZeroShotClassification</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="pipeline" /><category term="onnx" /><summary type="html">Description Pretrained BartForZeroShotClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bart_large_mnli_yahoo_answers_joeddav_pipeline is a English model originally trained by joeddav. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU pipeline = PretrainedPipeline(&quot;bart_large_mnli_yahoo_answers_joeddav_pipeline&quot;, lang = &quot;en&quot;) annotations = pipeline.transform(df) val pipeline = new PretrainedPipeline(&quot;bart_large_mnli_yahoo_answers_joeddav_pipeline&quot;, lang = &quot;en&quot;) val annotations = pipeline.transform(df) Model Information Model Name: bart_large_mnli_yahoo_answers_joeddav_pipeline Type: pipeline Compatibility: Spark NLP 5.5.1+ License: Open Source Edition: Official Language: en Size: 1.5 GB References References https://huggingface.co/joeddav/bart-large-mnli-yahoo-answers Included Models DocumentAssembler TokenizerModel BartForZeroShotClassification</summary></entry><entry><title type="html">English bart_mnli_cnn_256 BartForZeroShotClassification from AyoubChLin</title><link href="/2025/06/24/bart_mnli_cnn_256_en.html" rel="alternate" type="text/html" title="English bart_mnli_cnn_256 BartForZeroShotClassification from AyoubChLin" /><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>/2025/06/24/bart_mnli_cnn_256_en</id><content type="html" xml:base="/2025/06/24/bart_mnli_cnn_256_en.html">## Description

Pretrained BartForZeroShotClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bart_mnli_cnn_256` is a English model originally trained by AyoubChLin.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bart_mnli_cnn_256_en_5.5.1_3.0_1750785128151.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bart_mnli_cnn_256_en_5.5.1_3.0_1750785128151.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

zeroShotClassifier  = BartForZeroShotClassification.pretrained(&quot;bart_mnli_cnn_256&quot;,&quot;en&quot;) \
     .setInputCols([&quot;document&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, zeroShotClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)
```
```scala
val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)

val zeroShotClassifier  = BartForZeroShotClassification.pretrained(&quot;bart_mnli_cnn_256&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, zeroShotClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bart_mnli_cnn_256|
|Compatibility:|Spark NLP 5.5.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|1.5 GB|

## References

References

https://huggingface.co/AyoubChLin/BART-mnli_cnn_256</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="zero_shot" /><category term="bart" /><category term="openvino" /><summary type="html">Description Pretrained BartForZeroShotClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bart_mnli_cnn_256 is a English model originally trained by AyoubChLin. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') zeroShotClassifier = BartForZeroShotClassification.pretrained(&quot;bart_mnli_cnn_256&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, zeroShotClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val zeroShotClassifier = BartForZeroShotClassification.pretrained(&quot;bart_mnli_cnn_256&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, zeroShotClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bart_mnli_cnn_256 Compatibility: Spark NLP 5.5.1+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 1.5 GB References References https://huggingface.co/AyoubChLin/BART-mnli_cnn_256</summary></entry></feed>