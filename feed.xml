<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-03-29T08:53:55+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Legal Criticality Prediction Classifier (German)</title><link href="/2023/03/27/legclf_critical_prediction_legal_de.html" rel="alternate" type="text/html" title="Legal Criticality Prediction Classifier (German)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/legclf_critical_prediction_legal_de</id><content type="html" xml:base="/2023/03/27/legclf_critical_prediction_legal_de.html">## Description

This is a Binary classification model which identifies two criticality labels(critical, non-critical) in German-based Court Cases.

## Predicted Entities

`critical`, `non-critical`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_legal_de_1.0.0_3.0_1679923757236.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_critical_prediction_legal_de_1.0.0_3.0_1679923757236.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_legal&quot;, &quot;de&quot;, &quot;legal/models&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;class&quot;)

nlpPipeline = nlp.Pipeline(
      stages = [documentAssembler,
                tokenizer,
                classifier])
     
# Example text
example = spark.createDataFrame([[&quot;erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtskosten erhoben. 3. Dieses Urteil wird den Parteien, dem Sozialversicherungsgericht des Kantons Zürich und dem Staatssekretariat für Wirtschaft (SECO) schriftlich mitgeteilt. Luzern, 5. Dezember 2016 Im Namen der I. sozialrechtlichen Abteilung des Schweizerischen Bundesgerichts Der Präsident: Maillard Der Gerichtsschreiber: Grünvogel&quot;]]).toDF(&quot;text&quot;)

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)
model = nlpPipeline.fit(empty_data)

result = model.transform(example)

# result is a DataFrame
result.select(&quot;text&quot;, &quot;class.result&quot;).show()
```

&lt;/div&gt;

## Results

```bash
+----------------------------------------------------------------------------------------------------+--------------+
|                                                                                                text|        result|
+----------------------------------------------------------------------------------------------------+--------------+
|erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtsk...|[non_critical]|
+----------------------------------------------------------------------------------------------------+--------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_critical_prediction_legal|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|de|
|Size:|468.5 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

Train dataset available [here](https://huggingface.co/datasets/rcds/legal_criticality_prediction)

## Benchmarking

```bash
label         precision  recall  f1-score  support 
critical      0.76       0.87    0.81      249     
non_critical  0.87       0.76    0.81      293     
accuracy      -          -       0.81      542     
macro-avg     0.81       0.82    0.81      542     
weighted-avg  0.82       0.81    0.81      542     
```</content><author><name>John Snow Labs</name></author><category term="classification" /><category term="de" /><category term="licensed" /><category term="legal" /><category term="tensorflow" /><summary type="html">Description This is a Binary classification model which identifies two criticality labels(critical, non-critical) in German-based Court Cases. Predicted Entities critical, non-critical Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) classifier = nlp.RoBertaForSequenceClassification.pretrained(&quot;legclf_critical_prediction_legal&quot;, &quot;de&quot;, &quot;legal/models&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) nlpPipeline = nlp.Pipeline( stages = [documentAssembler, tokenizer, classifier]) # Example text example = spark.createDataFrame([[&quot;erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtskosten erhoben. 3. Dieses Urteil wird den Parteien, dem Sozialversicherungsgericht des Kantons Zürich und dem Staatssekretariat für Wirtschaft (SECO) schriftlich mitgeteilt. Luzern, 5. Dezember 2016 Im Namen der I. sozialrechtlichen Abteilung des Schweizerischen Bundesgerichts Der Präsident: Maillard Der Gerichtsschreiber: Grünvogel&quot;]]).toDF(&quot;text&quot;) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) result = model.transform(example) # result is a DataFrame result.select(&quot;text&quot;, &quot;class.result&quot;).show() Results +----------------------------------------------------------------------------------------------------+--------------+ | text| result| +----------------------------------------------------------------------------------------------------+--------------+ |erkennt der Präsident: 1. Auf die Beschwerde wird nicht eingetreten. 2. Es werden keine Gerichtsk...|[non_critical]| +----------------------------------------------------------------------------------------------------+--------------+ Model Information Model Name: legclf_critical_prediction_legal Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: de Size: 468.5 MB Case sensitive: true Max sentence length: 512 References Train dataset available here Benchmarking label precision recall f1-score support critical 0.76 0.87 0.81 249 non_critical 0.87 0.76 0.81 293 accuracy - - 0.81 542 macro-avg 0.81 0.82 0.81 542 weighted-avg 0.82 0.81 0.81 542</summary></entry><entry><title type="html">Financial Company Sentiments (Codalab)</title><link href="/2023/03/27/finclf_bert_company_sentiments_es.html" rel="alternate" type="text/html" title="Financial Company Sentiments (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finclf_bert_company_sentiments_es</id><content type="html" xml:base="/2023/03/27/finclf_bert_company_sentiments_es.html">## Description

This  Spanish Text Classifier will identify from the viewpoint of a company whether a financial statement is `positive`, `neutral` or `negative`. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`positive`, `neutral`, `negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_bert_company_sentiments_es_1.0.0_3.0_1679941143258.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_bert_company_sentiments_es_1.0.0_3.0_1679941143258.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_company_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;class&quot;)\
  .setCaseSensitive(True)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  sequenceClassifier
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-----------------------------------------------------------------------------+---------+
|text                                                                         |result   |
+-----------------------------------------------------------------------------+---------+
|Leopoldo del Nogal abandona el consejo de administraciÃ³n de El Corte InglÃ©s|[neutral]|
+-----------------------------------------------------------------------------+---------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_bert_company_sentiments|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|408.7 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels            precision    recall  f1-score   support
    negative       0.51      0.52      0.52        44
     neutral       0.65      0.74      0.69        77
    positive       0.56      0.38      0.45        37
    accuracy        -         -        0.59       158
   macro avg       0.57      0.55      0.55       158
weighted avg       0.59      0.59      0.59       158

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="classification" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish Text Classifier will identify from the viewpoint of a company whether a financial statement is positive, neutral or negative. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities positive, neutral, negative Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_company_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;class&quot;)\ .setCaseSensitive(True) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, sequenceClassifier ] ) Results +-----------------------------------------------------------------------------+---------+ |text |result | +-----------------------------------------------------------------------------+---------+ |Leopoldo del Nogal abandona el consejo de administraciÃ³n de El Corte InglÃ©s|[neutral]| +-----------------------------------------------------------------------------+---------+ Model Information Model Name: finclf_bert_company_sentiments Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 408.7 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support negative 0.51 0.52 0.52 44 neutral 0.65 0.74 0.69 77 positive 0.56 0.38 0.45 37 accuracy - - 0.59 158 macro avg 0.57 0.55 0.55 158 weighted avg 0.59 0.59 0.59 158</summary></entry><entry><title type="html">Financial Consumer Sentiments (Codalab)</title><link href="/2023/03/27/finclf_bert_consumer_sentiments_es.html" rel="alternate" type="text/html" title="Financial Consumer Sentiments (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finclf_bert_consumer_sentiments_es</id><content type="html" xml:base="/2023/03/27/finclf_bert_consumer_sentiments_es.html">## Description

This  Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is `positive`, `neutral` or `negative`. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`positive`, `neutral`, `negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_bert_consumer_sentiments_es_1.0.0_3.0_1679940812817.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_bert_consumer_sentiments_es_1.0.0_3.0_1679940812817.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_consumer_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;class&quot;)\
  .setCaseSensitive(True)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  sequenceClassifier
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-------------------------------------------------------------------------+----------+
|text                                                                     |result    |
+-------------------------------------------------------------------------+----------+
|Renfe afronta maÃ±ana un nuevo dÃ­a de paros parciales de los maquinistas|[negative]|
+-------------------------------------------------------------------------+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_bert_consumer_sentiments|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|408.7 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels            precision    recall  f1-score   support
    negative       0.59      0.72      0.66        36
     neutral       0.77      0.79      0.80        80
    positive       0.72      0.55      0.64        42
    accuracy        -         -        0.73       158
   macro-avg       0.69      0.69      0.70       158
weighted-avg       0.71      0.71      0.72       158

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="classification" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is positive, neutral or negative. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities positive, neutral, negative Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_consumer_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;class&quot;)\ .setCaseSensitive(True) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, sequenceClassifier ] ) Results +-------------------------------------------------------------------------+----------+ |text |result | +-------------------------------------------------------------------------+----------+ |Renfe afronta maÃ±ana un nuevo dÃ­a de paros parciales de los maquinistas|[negative]| +-------------------------------------------------------------------------+----------+ Model Information Model Name: finclf_bert_consumer_sentiments Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 408.7 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support negative 0.59 0.72 0.66 36 neutral 0.77 0.79 0.80 80 positive 0.72 0.55 0.64 42 accuracy - - 0.73 158 macro-avg 0.69 0.69 0.70 158 weighted-avg 0.71 0.71 0.72 158</summary></entry><entry><title type="html">Financial Target Sentiments (Codalab)</title><link href="/2023/03/27/finclf_bert_target_sentiments_es.html" rel="alternate" type="text/html" title="Financial Target Sentiments (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finclf_bert_target_sentiments_es</id><content type="html" xml:base="/2023/03/27/finclf_bert_target_sentiments_es.html">## Description

This  Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is `positive`, `neutral` or `negative`. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`positive`, `neutral`, `negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finclf_bert_target_sentiments_es_1.0.0_3.0_1679941309907.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finclf_bert_target_sentiments_es_1.0.0_3.0_1679941309907.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_target_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;class&quot;)\
  .setCaseSensitive(True)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  sequenceClassifier
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-------------------------------------------------------------------------------------------+----------+
|text                                                                                       |result    |
+-------------------------------------------------------------------------------------------+----------+
|La deuda de las familias cae en 25.000 millones en 2015 y marca niveles previos a la crisis|[positive]|
+-------------------------------------------------------------------------------------------+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finclf_bert_target_sentiments|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|412.2 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels      precision    recall  f1-score   support
negative        0.81      0.66      0.73        44
neutral         1.00      0.22      0.36         9
positive        0.82      0.93      0.87       105
accuracy          -        -        0.82       158
macro-avg       0.87      0.60      0.65       158
weighted-avg    0.82      0.82      0.80       158

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="classification" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish Text Classifier will identify from the viewpoint of a target whether a financial statement is positive, neutral or negative. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities positive, neutral, negative Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) sequenceClassifier = finance.BertForSequenceClassification.pretrained(&quot;finclf_bert_target_sentiments&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;class&quot;)\ .setCaseSensitive(True) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, sequenceClassifier ] ) Results +-------------------------------------------------------------------------------------------+----------+ |text |result | +-------------------------------------------------------------------------------------------+----------+ |La deuda de las familias cae en 25.000 millones en 2015 y marca niveles previos a la crisis|[positive]| +-------------------------------------------------------------------------------------------+----------+ Model Information Model Name: finclf_bert_target_sentiments Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 412.2 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support negative 0.81 0.66 0.73 44 neutral 1.00 0.22 0.36 9 positive 0.82 0.93 0.87 105 accuracy - - 0.82 158 macro-avg 0.87 0.60 0.65 158 weighted-avg 0.82 0.82 0.80 158</summary></entry><entry><title type="html">Financial Target NER (Codalab)</title><link href="/2023/03/27/finner_bert_target_es.html" rel="alternate" type="text/html" title="Financial Target NER (Codalab)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finner_bert_target_es</id><content type="html" xml:base="/2023/03/27/finner_bert_target_es.html">## Description

This  Spanish NER model will identify the label `TARGET` from a financial statement. This model is trained from the competition - `IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish`. We have used the participation dataset which is a small subset of the main one to train this model.

## Predicted Entities

`TARGET`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_bert_target_es_1.0.0_3.0_1679942128323.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_bert_target_es_1.0.0_3.0_1679942128323.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_bert_target&quot;,&quot;es&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;label&quot;)\
  .setCaseSensitive(True)

converter = finance.NerConverterInternal()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\
    .setOutputCol(&quot;ner&quot;)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  tokenClassifier,
  converter
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-----------+------+
|chunk      |entity|
+-----------+------+
|Presupuesto|TARGET|
|populista  |TARGET|
+-----------+------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_bert_target|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[ner]|
|Language:|es|
|Size:|406.6 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details

## Benchmarking

```bash
 
labels              precision    recall  f1-score   support
    B-TARGET       0.76      0.82      0.79       435
   micro-avg       0.76      0.82      0.79       435
   macro-avg       0.76      0.82      0.79       435
weighted-avg       0.76      0.82      0.79       435

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="ner" /><category term="es" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This Spanish NER model will identify the label TARGET from a financial statement. This model is trained from the competition - IBERLEF 2023 Task - FinancES. Financial Targeted Sentiment Analysis in Spanish. We have used the participation dataset which is a small subset of the main one to train this model. Predicted Entities TARGET Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_bert_target&quot;,&quot;es&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;label&quot;)\ .setCaseSensitive(True) converter = finance.NerConverterInternal()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\ .setOutputCol(&quot;ner&quot;) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, converter ] ) Results +-----------+------+ |chunk |entity| +-----------+------+ |Presupuesto|TARGET| |populista |TARGET| +-----------+------+ Model Information Model Name: finner_bert_target Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [ner] Language: es Size: 406.6 MB Case sensitive: true Max sentence length: 128 References https://codalab.lisn.upsaclay.fr/competitions/10052#learn_the_details Benchmarking labels precision recall f1-score support B-TARGET 0.76 0.82 0.79 435 micro-avg 0.76 0.82 0.79 435 macro-avg 0.76 0.82 0.79 435 weighted-avg 0.76 0.82 0.79 435</summary></entry><entry><title type="html">Broker Reports Financial NER (Specific, sm)</title><link href="/2023/03/27/finner_broker_reports_specific_sm_en.html" rel="alternate" type="text/html" title="Broker Reports Financial NER (Specific, sm)" /><published>2023-03-27T00:00:00+00:00</published><updated>2023-03-27T00:00:00+00:00</updated><id>/2023/03/27/finner_broker_reports_specific_sm_en</id><content type="html" xml:base="/2023/03/27/finner_broker_reports_specific_sm_en.html">## Description

This is a `sm` (small) version of a financial model trained on Broker Reports to detect financial entities (NER model).

## Predicted Entities

`LIABILITY_INCREASE`, `REVENUE_INCREASE`, `ASSET_DECREASE`, `AMOUNT`, `TICKER`, `TARGET_PRICE`, `ORG`, `DATE`, `LIABILITY_DECREASE`, `LIABILITY`, `CFO_INCREASE`, `ASSET_INCREASE`, `LOSS`, `CMP`, `ASSET`, `CF_DECREASE`, `EXPENSE`, `CF`, `PAD`, `CFO`, `FCF`, `PROFIT_INCREASE`, `REVENUE_DECLINE`, `CF_INCREASE`, `PERCENTAGE`, `RATING`, `STOCKHOLDERS_EQUITY`, `PROFIT_DECLINE`, `PROFIT`, `CURRENCY`, `FISCAL_YEAR`, `EXPENSE_INCREASE`, `EXPENSE_DECREASE`, `REVENUE`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_broker_reports_specific_sm_en_1.0.0_3.0_1679939860761.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_broker_reports_specific_sm_en_1.0.0_3.0_1679939860761.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
  .setInputCol(&quot;text&quot;)\
  .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
  .setInputCols(&quot;document&quot;)\
  .setOutputCol(&quot;token&quot;)
  
tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_broker_reports_specific_sm&quot;,&quot;en&quot;,&quot;finance/models&quot;)\
  .setInputCols(&quot;token&quot;, &quot;document&quot;)\
  .setOutputCol(&quot;label&quot;)\
  .setCaseSensitive(True)

converter = finance.NerConverterInternal()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\
    .setOutputCol(&quot;ner_span&quot;)

pipeline =  nlp.Pipeline(
    stages=[
  documentAssembler,
  tokenizer,
  tokenClassifier,
  converter
    ]
)

```

&lt;/div&gt;

## Results

```bash
+-----------------+----------+
|chunk            |entity    |
+-----------------+----------+
|revenue          |REVENUE   |
|$                |CURRENCY  |
|1.7 billion      |AMOUNT    |
|net profit margin|PROFIT    |
|13               |PERCENTAGE|
|net debt         |LIABILITY |
|Rs               |CURRENCY  |
|6.62bn           |AMOUNT    |
+-----------------+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_broker_reports_specific_sm|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|400.9 MB|
|Case sensitive:|true|
|Max sentence length:|128|

## References

In-house annotated dataset

## Benchmarking

```bash
 
labels                     precision    recall  f1-score   support
   B-REVENUE_INCREASE       0.69      0.78      0.73       126
     I-ASSET_DECREASE       0.80      0.87      0.83        23
              B-ASSET       0.84      0.82      0.83        50
    B-REVENUE_DECLINE       0.81      0.79      0.80        28
I-STOCKHOLDERS_EQUITY       1.00      0.96      0.98        56
                 B-CF       0.77      0.94      0.85        18
               I-LOSS       0.92      0.92      0.92        25
            I-REVENUE       0.28      0.26      0.27        19
     I-PROFIT_DECLINE       0.80      0.94      0.86        17
             I-PROFIT       0.91      0.94      0.93       249
   I-EXPENSE_DECREASE       0.77      1.00      0.87        10
   I-REVENUE_INCREASE       0.58      0.68      0.63        56
             B-TICKER       0.65      0.81      0.72        73
            B-EXPENSE       0.76      0.90      0.83        63
        I-CF_DECREASE       0.90      1.00      0.95        38
             B-RATING       0.93      0.99      0.96       536
                B-FCF       1.00      1.00      1.00        18
        B-CF_INCREASE       1.00      1.00      1.00        20
           B-CURRENCY       0.98      1.00      0.99       936
     I-ASSET_INCREASE       0.76      1.00      0.86        16
                B-CFO       0.96      1.00      0.98        22
          I-LIABILITY       0.97      0.82      0.89        38
               B-LOSS       0.85      0.94      0.89        31
 I-LIABILITY_DECREASE       0.44      0.67      0.53        12
    B-PROFIT_INCREASE       0.81      0.77      0.79       173
   B-EXPENSE_DECREASE       0.90      1.00      0.95        26
       B-CFO_INCREASE       0.92      0.96      0.94        25
             B-AMOUNT       0.97      1.00      0.98      1999
       B-TARGET_PRICE       0.97      0.98      0.97       171
             B-PROFIT       0.85      0.92      0.88       437
             I-AMOUNT       0.97      0.97      0.97       464
     B-ASSET_INCREASE       0.69      0.78      0.73        23
   I-EXPENSE_INCREASE       0.88      0.79      0.84        29
 B-LIABILITY_DECREASE       0.85      0.88      0.86        40
     B-PROFIT_DECLINE       0.90      0.85      0.87        53
B-STOCKHOLDERS_EQUITY       1.00      0.93      0.96        27
            I-EXPENSE       0.91      0.87      0.89        61
         B-PERCENTAGE       0.95      0.99      0.97      1133
              I-ASSET       0.97      0.73      0.83        44
         I-PERCENTAGE       0.33      1.00      0.50         2
       I-TARGET_PRICE       0.94      1.00      0.97       119
                B-CMP       0.89      1.00      0.94        33
    I-PROFIT_INCREASE       0.75      0.75      0.75        48
               I-DATE       0.40      0.57      0.47        14
            B-REVENUE       0.78      0.83      0.80       128
     B-ASSET_DECREASE       0.87      0.91      0.89        22
        I-CF_INCREASE       1.00      1.00      1.00        42
        I-FISCAL_YEAR       0.98      0.89      0.93       110
                I-CFO       0.97      1.00      0.99        75
                I-FCF       1.00      1.00      1.00        32
                B-ORG       0.95      0.98      0.96      1310
                I-ORG       0.95      0.98      0.97      1005
   B-EXPENSE_INCREASE       1.00      0.68      0.81        34
    I-REVENUE_DECLINE       0.67      0.38      0.48        21
             I-RATING       0.00      0.00      0.00         1
               B-DATE       0.98      0.99      0.98       358
                I-CMP       0.97      1.00      0.98        29
 B-LIABILITY_INCREASE       1.00      0.93      0.96        41
        B-FISCAL_YEAR       0.96      0.89      0.93        28
           I-CURRENCY       0.96      1.00      0.98        72
       I-CFO_INCREASE       0.89      0.97      0.93        72
        B-CF_DECREASE       0.96      1.00      0.98        23
             I-TICKER       1.00      0.40      0.57         5
 I-LIABILITY_INCREASE       1.00      0.94      0.97        31
          B-LIABILITY       0.96      0.92      0.94        26
                 I-CF       0.80      0.85      0.83        39
            micro-avg       0.93      0.96      0.95     10905
            macro-avg       0.85      0.87      0.85     10905
         weighted-avg       0.93      0.96      0.95     10905

```</content><author><name>John Snow Labs</name></author><category term="bert" /><category term="finance" /><category term="broker_reports" /><category term="ner" /><category term="en" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This is a sm (small) version of a financial model trained on Broker Reports to detect financial entities (NER model). Predicted Entities LIABILITY_INCREASE, REVENUE_INCREASE, ASSET_DECREASE, AMOUNT, TICKER, TARGET_PRICE, ORG, DATE, LIABILITY_DECREASE, LIABILITY, CFO_INCREASE, ASSET_INCREASE, LOSS, CMP, ASSET, CF_DECREASE, EXPENSE, CF, PAD, CFO, FCF, PROFIT_INCREASE, REVENUE_DECLINE, CF_INCREASE, PERCENTAGE, RATING, STOCKHOLDERS_EQUITY, PROFIT_DECLINE, PROFIT, CURRENCY, FISCAL_YEAR, EXPENSE_INCREASE, EXPENSE_DECREASE, REVENUE Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) tokenClassifier = finance.BertForTokenClassification.pretrained(&quot;finner_broker_reports_specific_sm&quot;,&quot;en&quot;,&quot;finance/models&quot;)\ .setInputCols(&quot;token&quot;, &quot;document&quot;)\ .setOutputCol(&quot;label&quot;)\ .setCaseSensitive(True) converter = finance.NerConverterInternal()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;label&quot;])\ .setOutputCol(&quot;ner_span&quot;) pipeline = nlp.Pipeline( stages=[ documentAssembler, tokenizer, tokenClassifier, converter ] ) Results +-----------------+----------+ |chunk |entity | +-----------------+----------+ |revenue |REVENUE | |$ |CURRENCY | |1.7 billion |AMOUNT | |net profit margin|PROFIT | |13 |PERCENTAGE| |net debt |LIABILITY | |Rs |CURRENCY | |6.62bn |AMOUNT | +-----------------+----------+ Model Information Model Name: finner_broker_reports_specific_sm Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token] Output Labels: [ner] Language: en Size: 400.9 MB Case sensitive: true Max sentence length: 128 References In-house annotated dataset Benchmarking labels precision recall f1-score support B-REVENUE_INCREASE 0.69 0.78 0.73 126 I-ASSET_DECREASE 0.80 0.87 0.83 23 B-ASSET 0.84 0.82 0.83 50 B-REVENUE_DECLINE 0.81 0.79 0.80 28 I-STOCKHOLDERS_EQUITY 1.00 0.96 0.98 56 B-CF 0.77 0.94 0.85 18 I-LOSS 0.92 0.92 0.92 25 I-REVENUE 0.28 0.26 0.27 19 I-PROFIT_DECLINE 0.80 0.94 0.86 17 I-PROFIT 0.91 0.94 0.93 249 I-EXPENSE_DECREASE 0.77 1.00 0.87 10 I-REVENUE_INCREASE 0.58 0.68 0.63 56 B-TICKER 0.65 0.81 0.72 73 B-EXPENSE 0.76 0.90 0.83 63 I-CF_DECREASE 0.90 1.00 0.95 38 B-RATING 0.93 0.99 0.96 536 B-FCF 1.00 1.00 1.00 18 B-CF_INCREASE 1.00 1.00 1.00 20 B-CURRENCY 0.98 1.00 0.99 936 I-ASSET_INCREASE 0.76 1.00 0.86 16 B-CFO 0.96 1.00 0.98 22 I-LIABILITY 0.97 0.82 0.89 38 B-LOSS 0.85 0.94 0.89 31 I-LIABILITY_DECREASE 0.44 0.67 0.53 12 B-PROFIT_INCREASE 0.81 0.77 0.79 173 B-EXPENSE_DECREASE 0.90 1.00 0.95 26 B-CFO_INCREASE 0.92 0.96 0.94 25 B-AMOUNT 0.97 1.00 0.98 1999 B-TARGET_PRICE 0.97 0.98 0.97 171 B-PROFIT 0.85 0.92 0.88 437 I-AMOUNT 0.97 0.97 0.97 464 B-ASSET_INCREASE 0.69 0.78 0.73 23 I-EXPENSE_INCREASE 0.88 0.79 0.84 29 B-LIABILITY_DECREASE 0.85 0.88 0.86 40 B-PROFIT_DECLINE 0.90 0.85 0.87 53 B-STOCKHOLDERS_EQUITY 1.00 0.93 0.96 27 I-EXPENSE 0.91 0.87 0.89 61 B-PERCENTAGE 0.95 0.99 0.97 1133 I-ASSET 0.97 0.73 0.83 44 I-PERCENTAGE 0.33 1.00 0.50 2 I-TARGET_PRICE 0.94 1.00 0.97 119 B-CMP 0.89 1.00 0.94 33 I-PROFIT_INCREASE 0.75 0.75 0.75 48 I-DATE 0.40 0.57 0.47 14 B-REVENUE 0.78 0.83 0.80 128 B-ASSET_DECREASE 0.87 0.91 0.89 22 I-CF_INCREASE 1.00 1.00 1.00 42 I-FISCAL_YEAR 0.98 0.89 0.93 110 I-CFO 0.97 1.00 0.99 75 I-FCF 1.00 1.00 1.00 32 B-ORG 0.95 0.98 0.96 1310 I-ORG 0.95 0.98 0.97 1005 B-EXPENSE_INCREASE 1.00 0.68 0.81 34 I-REVENUE_DECLINE 0.67 0.38 0.48 21 I-RATING 0.00 0.00 0.00 1 B-DATE 0.98 0.99 0.98 358 I-CMP 0.97 1.00 0.98 29 B-LIABILITY_INCREASE 1.00 0.93 0.96 41 B-FISCAL_YEAR 0.96 0.89 0.93 28 I-CURRENCY 0.96 1.00 0.98 72 I-CFO_INCREASE 0.89 0.97 0.93 72 B-CF_DECREASE 0.96 1.00 0.98 23 I-TICKER 1.00 0.40 0.57 5 I-LIABILITY_INCREASE 1.00 0.94 0.97 31 B-LIABILITY 0.96 0.92 0.94 26 I-CF 0.80 0.85 0.83 39 micro-avg 0.93 0.96 0.95 10905 macro-avg 0.85 0.87 0.85 10905 weighted-avg 0.93 0.96 0.95 10905</summary></entry><entry><title type="html">Legal Arguments Mining in Court Decisions</title><link href="/2023/03/26/legclf_argument_mining_en.html" rel="alternate" type="text/html" title="Legal Arguments Mining in Court Decisions" /><published>2023-03-26T00:00:00+00:00</published><updated>2023-03-26T00:00:00+00:00</updated><id>/2023/03/26/legclf_argument_mining_en</id><content type="html" xml:base="/2023/03/26/legclf_argument_mining_en.html">## Description

This is a Multiclass classification model which classifies arguments in legal discourse. These are the following classes: `subsumption`, `definition`, `conclusion`, `other`.

## Predicted Entities

`subsumption`, `definition`, `conclusion`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_argument_mining_en_1.0.0_3.0_1679829561976.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_argument_mining_en_1.0.0_3.0_1679829561976.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\
    .setMaxSentenceLength(512)

embeddingsSentence = nlp.SentenceEmbeddings()\
    .setInputCols([&quot;document&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;sentence_embeddings&quot;)\
    .setPoolingStrategy(&quot;AVERAGE&quot;)

docClassifier = legal.ClassifierDLModel.pretrained(&quot;legclf_argument_mining&quot;,&quot;en&quot;, &quot;legal/models&quot;)\
      .setInputCols([&quot;sentence_embeddings&quot;])\
      .setOutputCol(&quot;category&quot;)

nlpPipeline = nlp.Pipeline(stages=[
      documentAssembler, 
      tokenizer,
      embeddings,
      embeddingsSentence,
      docClassifier
])

df = spark.createDataFrame([[&quot;There is therefore no doubt – and the Government do not contest – that the measures concerned in the present case ( the children 's continued placement in foster homes and the restrictions imposed on contact between the applicants and their children ) amounts to an “ interference ” with the applicants ' rights to respect for their family life .&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)

result = model.transform(df)

result.select(&quot;text&quot;, &quot;category.result&quot;).show()
```

&lt;/div&gt;

## Results

```bash
+--------------------+-------------+
|                text|       result|
+--------------------+-------------+
|There is therefor...|[subsumption]|
+--------------------+-------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_argument_mining|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|en|
|Size:|22.2 MB|

## References

Train dataset available [here](https://huggingface.co/datasets/MeilingShi/legal_argument_mining)

## Benchmarking

```bash
label         precision    recall    f1-score  support      
conclusion    0.93         0.79      0.85      52  
definition    0.87         0.81      0.84      58  
other         0.88         0.88      0.88      57  
subsumption   0.64         0.79      0.71      52  
accuracy         -            -      0.82      219     
macro-avg     0.83         0.82      0.82      219 
weighted-avg  0.83         0.82      0.82      219 
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="classification" /><category term="licensed" /><category term="legal" /><category term="tensorflow" /><summary type="html">Description This is a Multiclass classification model which classifies arguments in legal discourse. These are the following classes: subsumption, definition, conclusion, other. Predicted Entities subsumption, definition, conclusion, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512) embeddingsSentence = nlp.SentenceEmbeddings()\ .setInputCols([&quot;document&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;sentence_embeddings&quot;)\ .setPoolingStrategy(&quot;AVERAGE&quot;) docClassifier = legal.ClassifierDLModel.pretrained(&quot;legclf_argument_mining&quot;,&quot;en&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, tokenizer, embeddings, embeddingsSentence, docClassifier ]) df = spark.createDataFrame([[&quot;There is therefore no doubt – and the Government do not contest – that the measures concerned in the present case ( the children 's continued placement in foster homes and the restrictions imposed on contact between the applicants and their children ) amounts to an “ interference ” with the applicants ' rights to respect for their family life .&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) result.select(&quot;text&quot;, &quot;category.result&quot;).show() Results +--------------------+-------------+ | text| result| +--------------------+-------------+ |There is therefor...|[subsumption]| +--------------------+-------------+ Model Information Model Name: legclf_argument_mining Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: en Size: 22.2 MB References Train dataset available here Benchmarking label precision recall f1-score support conclusion 0.93 0.79 0.85 52 definition 0.87 0.81 0.84 58 other 0.88 0.88 0.88 57 subsumption 0.64 0.79 0.71 52 accuracy - - 0.82 219 macro-avg 0.83 0.82 0.82 219 weighted-avg 0.83 0.82 0.82 219</summary></entry><entry><title type="html">Legal Arguments Mining in Court Decisions (in German)</title><link href="/2023/03/26/legclf_argument_mining_german_de.html" rel="alternate" type="text/html" title="Legal Arguments Mining in Court Decisions (in German)" /><published>2023-03-26T00:00:00+00:00</published><updated>2023-03-26T00:00:00+00:00</updated><id>/2023/03/26/legclf_argument_mining_german_de</id><content type="html" xml:base="/2023/03/26/legclf_argument_mining_german_de.html">## Description

This is a Multiclass classification model in German which classifies arguments in legal discourse. These are the following classes: `subsumption`, `definition`, `conclusion`, `other`.

## Predicted Entities

`subsumption`, `definition`, `conclusion`, `other`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_argument_mining_german_de_1.0.0_3.0_1679848514704.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legclf_argument_mining_german_de_1.0.0_3.0_1679848514704.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_large_german_legal&quot;, &quot;de&quot;)\
        .setInputCols([&quot;document&quot;, &quot;token&quot;])\
        .setOutputCol(&quot;embeddings&quot;)\
        .setMaxSentenceLength(512)

embeddingsSentence = nlp.SentenceEmbeddings()\
        .setInputCols([&quot;document&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;sentence_embeddings&quot;)\
        .setPoolingStrategy(&quot;AVERAGE&quot;)\


docClassifier = legal.ClassifierDLModel.pretrained(&quot;legclf_argument_mining_de&quot;, &quot;de&quot;, &quot;legal/models&quot;)\
        .setInputCols([&quot;sentence_embeddings&quot;])\
        .setOutputCol(&quot;category&quot;)

nlpPipeline = nlp.Pipeline(stages=[
      documentAssembler, 
      tokenizer,
      embeddings,
      embeddingsSentence,
      docClassifier
])

df = spark.createDataFrame([[&quot;Folglich liegt eine Verletzung von Artikel 8 der Konvention vor .&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(df)
result = model.transform(df)

result.select(&quot;text&quot;, &quot;category.result&quot;).show(truncate=False)
```

&lt;/div&gt;

## Results

```bash
+-----------------------------------------------------------------+------------+
|text                                                             |result      |
+-----------------------------------------------------------------+------------+
|Folglich liegt eine Verletzung von Artikel 8 der Konvention vor .|[conclusion]|
+-----------------------------------------------------------------+------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_argument_mining_german|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[class]|
|Language:|de|
|Size:|24.0 MB|

## References

Train dataset available [here](https://huggingface.co/datasets/MeilingShi/legal_argument_mining)

## Benchmarking

```bash
label         precision  recall    f1-score  support      
conclusion    0.88       0.88      0.88      52  
definition    0.83       0.83      0.83      58  
other         0.86       0.88      0.87      49  
subsumption   0.81       0.80      0.80      64  
accuracy         -          -      0.84      223                     
macro avg     0.85       0.85      0.85      223 
weighted avg  0.84       0.84      0.84      223 
```</content><author><name>John Snow Labs</name></author><category term="de" /><category term="licensed" /><category term="classification" /><category term="legal" /><category term="tensorflow" /><summary type="html">Description This is a Multiclass classification model in German which classifies arguments in legal discourse. These are the following classes: subsumption, definition, conclusion, other. Predicted Entities subsumption, definition, conclusion, other Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_large_german_legal&quot;, &quot;de&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512) embeddingsSentence = nlp.SentenceEmbeddings()\ .setInputCols([&quot;document&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;sentence_embeddings&quot;)\ .setPoolingStrategy(&quot;AVERAGE&quot;)\ docClassifier = legal.ClassifierDLModel.pretrained(&quot;legclf_argument_mining_de&quot;, &quot;de&quot;, &quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;category&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, tokenizer, embeddings, embeddingsSentence, docClassifier ]) df = spark.createDataFrame([[&quot;Folglich liegt eine Verletzung von Artikel 8 der Konvention vor .&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(df) result = model.transform(df) result.select(&quot;text&quot;, &quot;category.result&quot;).show(truncate=False) Results +-----------------------------------------------------------------+------------+ |text |result | +-----------------------------------------------------------------+------------+ |Folglich liegt eine Verletzung von Artikel 8 der Konvention vor .|[conclusion]| +-----------------------------------------------------------------+------------+ Model Information Model Name: legclf_argument_mining_german Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [class] Language: de Size: 24.0 MB References Train dataset available here Benchmarking label precision recall f1-score support conclusion 0.88 0.88 0.88 52 definition 0.83 0.83 0.83 58 other 0.86 0.88 0.87 49 subsumption 0.81 0.80 0.80 64 accuracy - - 0.84 223 macro avg 0.85 0.85 0.85 223 weighted avg 0.84 0.84 0.84 223</summary></entry><entry><title type="html">Financial NER for German Financial Statements</title><link href="/2023/03/25/finner_financial_entity_value_de.html" rel="alternate" type="text/html" title="Financial NER for German Financial Statements" /><published>2023-03-25T00:00:00+00:00</published><updated>2023-03-25T00:00:00+00:00</updated><id>/2023/03/25/finner_financial_entity_value_de</id><content type="html" xml:base="/2023/03/25/finner_financial_entity_value_de.html">## Description

This is a German NER model trained on German Financial Statements, aimed to extract the following entities from the financial documents.

## Predicted Entities

`FINANCIAL_ENTITY`, `FINANCIAL_VALUE`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finner_financial_entity_value_de_1.0.0_3.0_1679702467400.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finner_financial_entity_value_de_1.0.0_3.0_1679702467400.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)
        
sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_sentence_embeddings_financial&quot;,&quot;de&quot;) \
    .setInputCols(&quot;sentence&quot;, &quot;token&quot;) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model= finance.NerModel.pretrained(&quot;finner_financial_entity_value&quot;, &quot;de&quot;, &quot;finance/models&quot;)\
  .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
  .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

pipeline =  nlp.Pipeline(stages=[
    documentAssembler,
    sentenceDetector,
    tokenizer,
    embeddings,
    ner_model,
    ner_converter
    ]
)

import pandas as pd

p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))


text = 'Die Kapitalstruktur wird im Wesentlichen durch eine weitere Reduzierung der langfristigen Bankverbindlichkeiten um 3.000 TEUR auf 0 TEUR , einer Erhöhung der Rückstellungen um 3.397 TEUR auf 31.717 TEUR sowie die Erhöhung des Eigenkapitals um 1.771 TEUR auf 110.668 TEUR beeinflusst .'


res = p_model.transform(spark.createDataFrame([[text]]).toDF(&quot;text&quot;))

result_df = res.select(F.explode(F.arrays_zip(res.token.result,res.ner.result, res.ner.metadata)).alias(&quot;cols&quot;))\
                          .select(F.expr(&quot;cols['0']&quot;).alias(&quot;token&quot;),
                                       F.expr(&quot;cols['1']&quot;).alias(&quot;label&quot;),
                                       F.expr(&quot;cols['2']['confidence']&quot;).alias(&quot;confidence&quot;))

result_df.show(50, truncate=100)
```

&lt;/div&gt;

## Results

```bash
+---------------------+------------------+
|                token|             label|
+---------------------+------------------+
|                  Die|                 O|
|      Kapitalstruktur|                 O|
|                 wird|                 O|
|                   im|                 O|
|         Wesentlichen|                 O|
|                durch|                 O|
|                 eine|                 O|
|              weitere|                 O|
|          Reduzierung|                 O|
|                  der|                 O|
|        langfristigen|B-FINANCIAL_ENTITY|
|Bankverbindlichkeiten|I-FINANCIAL_ENTITY|
|                   um|                 O|
|                3.000|                 O|
|                 TEUR|                 O|
|                  auf|                 O|
|                    0| B-FINANCIAL_VALUE|
|                 TEUR|                 O|
|                    ,|                 O|
|                einer|                 O|
|             Erhöhung|                 O|
|                  der|                 O|
|       Rückstellungen|B-FINANCIAL_ENTITY|
|                   um|                 O|
|                3.397|                 O|
|                 TEUR|                 O|
|                  auf|                 O|
|               31.717| B-FINANCIAL_VALUE|
|                 TEUR|                 O|
|                sowie|                 O|
|                  die|                 O|
|             Erhöhung|                 O|
|                  des|                 O|
|        Eigenkapitals|B-FINANCIAL_ENTITY|
|                   um|                 O|
|                1.771|                 O|
|                 TEUR|                 O|
|                  auf|                 O|
|              110.668| B-FINANCIAL_VALUE|
|                 TEUR|                 O|
|          beeinflusst|                 O|
|                    .|                 O|
+---------------------+------------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finner_financial_entity_value|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|de|
|Size:|1.1 MB|

## Benchmarking

```bash
label               precision   recall      f1-score   support     
B-FINANCIAL_ENTITY  0.8947      0.9444      0.9189     18 
B-FINANCIAL_VALUE   1.0000      0.8750      0.9333     16 
I-FINANCIAL_ENTITY  0.8000      0.6154      0.6957     13 
micro-avg           0.9070      0.8298      0.8667     47 
macro-avg           0.8982      0.8116      0.8493     47 
weighted-avg        0.9044      0.8298      0.8621     47 
```</content><author><name>John Snow Labs</name></author><category term="ner" /><category term="licensed" /><category term="finance" /><category term="de" /><summary type="html">Description This is a German NER model trained on German Financial Statements, aimed to extract the following entities from the financial documents. Predicted Entities FINANCIAL_ENTITY, FINANCIAL_VALUE Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_sentence_embeddings_financial&quot;,&quot;de&quot;) \ .setInputCols(&quot;sentence&quot;, &quot;token&quot;) \ .setOutputCol(&quot;embeddings&quot;) ner_model= finance.NerModel.pretrained(&quot;finner_financial_entity_value&quot;, &quot;de&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) pipeline = nlp.Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter ] ) import pandas as pd p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']}))) text = 'Die Kapitalstruktur wird im Wesentlichen durch eine weitere Reduzierung der langfristigen Bankverbindlichkeiten um 3.000 TEUR auf 0 TEUR , einer Erhöhung der Rückstellungen um 3.397 TEUR auf 31.717 TEUR sowie die Erhöhung des Eigenkapitals um 1.771 TEUR auf 110.668 TEUR beeinflusst .' res = p_model.transform(spark.createDataFrame([[text]]).toDF(&quot;text&quot;)) result_df = res.select(F.explode(F.arrays_zip(res.token.result,res.ner.result, res.ner.metadata)).alias(&quot;cols&quot;))\ .select(F.expr(&quot;cols['0']&quot;).alias(&quot;token&quot;), F.expr(&quot;cols['1']&quot;).alias(&quot;label&quot;), F.expr(&quot;cols['2']['confidence']&quot;).alias(&quot;confidence&quot;)) result_df.show(50, truncate=100) Results +---------------------+------------------+ | token| label| +---------------------+------------------+ | Die| O| | Kapitalstruktur| O| | wird| O| | im| O| | Wesentlichen| O| | durch| O| | eine| O| | weitere| O| | Reduzierung| O| | der| O| | langfristigen|B-FINANCIAL_ENTITY| |Bankverbindlichkeiten|I-FINANCIAL_ENTITY| | um| O| | 3.000| O| | TEUR| O| | auf| O| | 0| B-FINANCIAL_VALUE| | TEUR| O| | ,| O| | einer| O| | Erhöhung| O| | der| O| | Rückstellungen|B-FINANCIAL_ENTITY| | um| O| | 3.397| O| | TEUR| O| | auf| O| | 31.717| B-FINANCIAL_VALUE| | TEUR| O| | sowie| O| | die| O| | Erhöhung| O| | des| O| | Eigenkapitals|B-FINANCIAL_ENTITY| | um| O| | 1.771| O| | TEUR| O| | auf| O| | 110.668| B-FINANCIAL_VALUE| | TEUR| O| | beeinflusst| O| | .| O| +---------------------+------------------+ Model Information Model Name: finner_financial_entity_value Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: de Size: 1.1 MB Benchmarking label precision recall f1-score support B-FINANCIAL_ENTITY 0.8947 0.9444 0.9189 18 B-FINANCIAL_VALUE 1.0000 0.8750 0.9333 16 I-FINANCIAL_ENTITY 0.8000 0.6154 0.6957 13 micro-avg 0.9070 0.8298 0.8667 47 macro-avg 0.8982 0.8116 0.8493 47 weighted-avg 0.9044 0.8298 0.8621 47</summary></entry><entry><title type="html">Financial Relation Extraction on German Financial Statements</title><link href="/2023/03/25/finre_has_value_de.html" rel="alternate" type="text/html" title="Financial Relation Extraction on German Financial Statements" /><published>2023-03-25T00:00:00+00:00</published><updated>2023-03-25T00:00:00+00:00</updated><id>/2023/03/25/finre_has_value_de</id><content type="html" xml:base="/2023/03/25/finre_has_value_de.html">## Description

This model is a relation extraction model to extract financial entities and their values from text with `finner_financial_entity_value` model.

## Predicted Entities
`has_value`


{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finre_has_value_de_1.0.0_3.0_1679702750286.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finre_has_value_de_1.0.0_3.0_1679702750286.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

sen = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;sentence&quot;)\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_sentence_embeddings_financial&quot;, &quot;de&quot;)\
    .setInputCols(&quot;document&quot;, &quot;token&quot;)\
    .setOutputCol(&quot;embeddings&quot;)\
    .setMaxSentenceLength(512)\
    .setCaseSensitive(True)

pos_tagger = nlp.PerceptronModel()\
    .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;pos_tags&quot;)
    
dependency_parser = nlp.DependencyParserModel()\
    .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;pos_tags&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;dependencies&quot;)
    
ner_model = finance.NerModel().pretrained('finner_financial_entity_value', 'de', 'finance/models)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner1&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner1&quot;])\
    .setOutputCol(&quot;ner_chunks&quot;)

re_ner_chunk_filter = finance.RENerChunksFilter() \
    .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;])\
    .setOutputCol(&quot;re_ner_chunks&quot;)\
    .setRelationPairs([&quot;FINANCIAL_ENTITY-FINANCIAL_VALUE&quot;, &quot;FINANCIAL_VALUE-FINANCIAL_ENTITY&quot;])

reDL = finance.RelationExtractionDLModel().pretrained('finre_has_value', 'de', 'finance/models)\
    .setPredictionThreshold(0.5)\
    .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentence&quot;])\
    .setOutputCol(&quot;relations&quot;)
   

nlpPipeline = nlp.Pipeline(stages=[
    documentAssembler,
    sen,
    tokenizer,
    embeddings,
    pos_tagger,
    dependency_parser,
    ner_model,
    ner_converter,
    re_ner_chunk_filter,
    reDL
])


empty_df = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_df)

text= &quot;&quot;&quot;Die Darlehensverbindlichkeit gegenüber der Vaillant GmbH in Höhe von TEUR 3.433 hat eine Laufzeit bis zum 31.12.2019 , die restlichen Verbindlichkeiten haben eine Restlaufzeit bis zu einem Jahr .&quot;&quot;&quot;
sdf = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)

res = model.transform(sdf)
res.show(20,truncate=False)

result_df = res.select(F.explode(F.arrays_zip(res.relations.result, 
                                                 res.relations.metadata)).alias(&quot;cols&quot;)) \
                  .select(
                          F.expr(&quot;cols['0']&quot;).alias(&quot;relations&quot;),\
                          F.expr(&quot;cols['1']['entity1']&quot;).alias(&quot;relations_entity1&quot;),\
                          F.expr(&quot;cols['1']['chunk1']&quot; ).alias(&quot;relations_chunk1&quot; ),\
                          F.expr(&quot;cols['1']['entity2']&quot;).alias(&quot;relations_entity2&quot;),\
                          F.expr(&quot;cols['1']['chunk2']&quot; ).alias(&quot;relations_chunk2&quot; ),\
                          F.expr(&quot;cols['1']['confidence']&quot; ).alias(&quot;confidence&quot; ),\
                          F.expr(&quot;cols['1']['syntactic_distance']&quot; ).alias(&quot;syntactic_distance&quot; ),\
                          ).filter(&quot;relations!='other'&quot;)

result_df.show()
```

&lt;/div&gt;

## Results

```bash

relations relations_entity1     relations_chunk1 relations_entity2  relations_chunk2 confidence syntactic_distance 
has_value  FINANCIAL_ENTITY Darlehensverbindl...   FINANCIAL_VALUE             3.433        1.0                  8 
has_value   FINANCIAL_VALUE                3.433  FINANCIAL_ENTITY Verbindlichkeiten        1.0          undefined 
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finre_has_value|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|de|
|Size:|661.2 MB|

## Benchmarking

```bash
Relation           Recall Precision        F1   Support
has_value           1.000     1.000     1.000       100
Avg.                1.000     1.000     1.000         -
Weighted Avg.       1.000     1.000     1.000         -
```</content><author><name>John Snow Labs</name></author><category term="re" /><category term="licensed" /><category term="finance" /><category term="de" /><category term="tensorflow" /><summary type="html">Description This model is a relation extraction model to extract financial entities and their values from text with finner_financial_entity_value model. Predicted Entities has_value Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sen = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;sentence&quot;)\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_sentence_embeddings_financial&quot;, &quot;de&quot;)\ .setInputCols(&quot;document&quot;, &quot;token&quot;)\ .setOutputCol(&quot;embeddings&quot;)\ .setMaxSentenceLength(512)\ .setCaseSensitive(True) pos_tagger = nlp.PerceptronModel()\ .pretrained(&quot;pos_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;pos_tags&quot;) dependency_parser = nlp.DependencyParserModel()\ .pretrained(&quot;dependency_conllu&quot;, &quot;en&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;pos_tags&quot;, &quot;token&quot;])\ .setOutputCol(&quot;dependencies&quot;) ner_model = finance.NerModel().pretrained('finner_financial_entity_value', 'de', 'finance/models)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner1&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner1&quot;])\ .setOutputCol(&quot;ner_chunks&quot;) re_ner_chunk_filter = finance.RENerChunksFilter() \ .setInputCols([&quot;ner_chunks&quot;, &quot;dependencies&quot;])\ .setOutputCol(&quot;re_ner_chunks&quot;)\ .setRelationPairs([&quot;FINANCIAL_ENTITY-FINANCIAL_VALUE&quot;, &quot;FINANCIAL_VALUE-FINANCIAL_ENTITY&quot;]) reDL = finance.RelationExtractionDLModel().pretrained('finre_has_value', 'de', 'finance/models)\ .setPredictionThreshold(0.5)\ .setInputCols([&quot;re_ner_chunks&quot;, &quot;sentence&quot;])\ .setOutputCol(&quot;relations&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, sen, tokenizer, embeddings, pos_tagger, dependency_parser, ner_model, ner_converter, re_ner_chunk_filter, reDL ]) empty_df = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_df) text= &quot;&quot;&quot;Die Darlehensverbindlichkeit gegenüber der Vaillant GmbH in Höhe von TEUR 3.433 hat eine Laufzeit bis zum 31.12.2019 , die restlichen Verbindlichkeiten haben eine Restlaufzeit bis zu einem Jahr .&quot;&quot;&quot; sdf = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) res = model.transform(sdf) res.show(20,truncate=False) result_df = res.select(F.explode(F.arrays_zip(res.relations.result, res.relations.metadata)).alias(&quot;cols&quot;)) \ .select( F.expr(&quot;cols['0']&quot;).alias(&quot;relations&quot;),\ F.expr(&quot;cols['1']['entity1']&quot;).alias(&quot;relations_entity1&quot;),\ F.expr(&quot;cols['1']['chunk1']&quot; ).alias(&quot;relations_chunk1&quot; ),\ F.expr(&quot;cols['1']['entity2']&quot;).alias(&quot;relations_entity2&quot;),\ F.expr(&quot;cols['1']['chunk2']&quot; ).alias(&quot;relations_chunk2&quot; ),\ F.expr(&quot;cols['1']['confidence']&quot; ).alias(&quot;confidence&quot; ),\ F.expr(&quot;cols['1']['syntactic_distance']&quot; ).alias(&quot;syntactic_distance&quot; ),\ ).filter(&quot;relations!='other'&quot;) result_df.show() Results relations relations_entity1 relations_chunk1 relations_entity2 relations_chunk2 confidence syntactic_distance has_value FINANCIAL_ENTITY Darlehensverbindl... FINANCIAL_VALUE 3.433 1.0 8 has_value FINANCIAL_VALUE 3.433 FINANCIAL_ENTITY Verbindlichkeiten 1.0 undefined Model Information Model Name: finre_has_value Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Language: de Size: 661.2 MB Benchmarking Relation Recall Precision F1 Support has_value 1.000 1.000 1.000 100 Avg. 1.000 1.000 1.000 - Weighted Avg. 1.000 1.000 1.000 -</summary></entry></feed>