<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2024-10-18T16:21:37+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">English aann_detector_pipeline pipeline BertForSequenceClassification from kanishka</title><link href="/2024/09/27/aann_detector_pipeline_en.html" rel="alternate" type="text/html" title="English aann_detector_pipeline pipeline BertForSequenceClassification from kanishka" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/aann_detector_pipeline_en</id><content type="html" xml:base="/2024/09/27/aann_detector_pipeline_en.html">## Description

Pretrained BertForSequenceClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`aann_detector_pipeline` is a English model originally trained by kanishka.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/aann_detector_pipeline_en_5.5.0_3.0_1727418813682.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/aann_detector_pipeline_en_5.5.0_3.0_1727418813682.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

pipeline = PretrainedPipeline(&quot;aann_detector_pipeline&quot;, lang = &quot;en&quot;)
annotations =  pipeline.transform(df)   

```
```scala

val pipeline = new PretrainedPipeline(&quot;aann_detector_pipeline&quot;, lang = &quot;en&quot;)
val annotations = pipeline.transform(df)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|aann_detector_pipeline|
|Type:|pipeline|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Language:|en|
|Size:|409.4 MB|

## References

https://huggingface.co/kanishka/aann-detector

## Included Models

- DocumentAssembler
- TokenizerModel
- BertForSequenceClassification</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="pipeline" /><category term="onnx" /><summary type="html">Description Pretrained BertForSequenceClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.aann_detector_pipeline is a English model originally trained by kanishka. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU pipeline = PretrainedPipeline(&quot;aann_detector_pipeline&quot;, lang = &quot;en&quot;) annotations = pipeline.transform(df) val pipeline = new PretrainedPipeline(&quot;aann_detector_pipeline&quot;, lang = &quot;en&quot;) val annotations = pipeline.transform(df) Model Information Model Name: aann_detector_pipeline Type: pipeline Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Language: en Size: 409.4 MB References https://huggingface.co/kanishka/aann-detector Included Models DocumentAssembler TokenizerModel BertForSequenceClassification</summary></entry><entry><title type="html">English adversarial_trainer_pipeline pipeline BertForSequenceClassification from michalzajac</title><link href="/2024/09/27/adversarial_trainer_pipeline_en.html" rel="alternate" type="text/html" title="English adversarial_trainer_pipeline pipeline BertForSequenceClassification from michalzajac" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/adversarial_trainer_pipeline_en</id><content type="html" xml:base="/2024/09/27/adversarial_trainer_pipeline_en.html">## Description

Pretrained BertForSequenceClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`adversarial_trainer_pipeline` is a English model originally trained by michalzajac.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/adversarial_trainer_pipeline_en_5.5.0_3.0_1727419642875.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/adversarial_trainer_pipeline_en_5.5.0_3.0_1727419642875.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

pipeline = PretrainedPipeline(&quot;adversarial_trainer_pipeline&quot;, lang = &quot;en&quot;)
annotations =  pipeline.transform(df)   

```
```scala

val pipeline = new PretrainedPipeline(&quot;adversarial_trainer_pipeline&quot;, lang = &quot;en&quot;)
val annotations = pipeline.transform(df)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|adversarial_trainer_pipeline|
|Type:|pipeline|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Language:|en|
|Size:|409.4 MB|

## References

https://huggingface.co/michalzajac/adversarial_trainer

## Included Models

- DocumentAssembler
- TokenizerModel
- BertForSequenceClassification</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="pipeline" /><category term="onnx" /><summary type="html">Description Pretrained BertForSequenceClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.adversarial_trainer_pipeline is a English model originally trained by michalzajac. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU pipeline = PretrainedPipeline(&quot;adversarial_trainer_pipeline&quot;, lang = &quot;en&quot;) annotations = pipeline.transform(df) val pipeline = new PretrainedPipeline(&quot;adversarial_trainer_pipeline&quot;, lang = &quot;en&quot;) val annotations = pipeline.transform(df) Model Information Model Name: adversarial_trainer_pipeline Type: pipeline Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Language: en Size: 409.4 MB References https://huggingface.co/michalzajac/adversarial_trainer Included Models DocumentAssembler TokenizerModel BertForSequenceClassification</summary></entry><entry><title type="html">English ag_news_4800_bert_base_uncased BertForSequenceClassification from Kyle1668</title><link href="/2024/09/27/ag_news_4800_bert_base_uncased_en.html" rel="alternate" type="text/html" title="English ag_news_4800_bert_base_uncased BertForSequenceClassification from Kyle1668" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/ag_news_4800_bert_base_uncased_en</id><content type="html" xml:base="/2024/09/27/ag_news_4800_bert_base_uncased_en.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`ag_news_4800_bert_base_uncased` is a English model originally trained by Kyle1668.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ag_news_4800_bert_base_uncased_en_5.5.0_3.0_1727400326939.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/ag_news_4800_bert_base_uncased_en_5.5.0_3.0_1727400326939.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;ag_news_4800_bert_base_uncased&quot;,&quot;en&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;ag_news_4800_bert_base_uncased&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ag_news_4800_bert_base_uncased|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|409.4 MB|

## References

https://huggingface.co/Kyle1668/ag-news-4800-bert-base-uncased</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.ag_news_4800_bert_base_uncased is a English model originally trained by Kyle1668. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;ag_news_4800_bert_base_uncased&quot;,&quot;en&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;ag_news_4800_bert_base_uncased&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: ag_news_4800_bert_base_uncased Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 409.4 MB References https://huggingface.co/Kyle1668/ag-news-4800-bert-base-uncased</summary></entry><entry><title type="html">Chinese ai_generated_text_detection_pair BertForSequenceClassification from Juner</title><link href="/2024/09/27/ai_generated_text_detection_pair_zh.html" rel="alternate" type="text/html" title="Chinese ai_generated_text_detection_pair BertForSequenceClassification from Juner" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/ai_generated_text_detection_pair_zh</id><content type="html" xml:base="/2024/09/27/ai_generated_text_detection_pair_zh.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`ai_generated_text_detection_pair` is a Chinese model originally trained by Juner.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/ai_generated_text_detection_pair_zh_5.5.0_3.0_1727405235051.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/ai_generated_text_detection_pair_zh_5.5.0_3.0_1727405235051.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;ai_generated_text_detection_pair&quot;,&quot;zh&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;ai_generated_text_detection_pair&quot;, &quot;zh&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|ai_generated_text_detection_pair|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|zh|
|Size:|383.2 MB|

## References

https://huggingface.co/Juner/AI-generated-text-detection-pair</content><author><name>John Snow Labs</name></author><category term="zh" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.ai_generated_text_detection_pair is a Chinese model originally trained by Juner. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;ai_generated_text_detection_pair&quot;,&quot;zh&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;ai_generated_text_detection_pair&quot;, &quot;zh&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: ai_generated_text_detection_pair Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: zh Size: 383.2 MB References https://huggingface.co/Juner/AI-generated-text-detection-pair</summary></entry><entry><title type="html">English albert_base_chinese_finetuned_qqp_tm_5x BertForSequenceClassification from r10521708</title><link href="/2024/09/27/albert_base_chinese_finetuned_qqp_tm_5x_en.html" rel="alternate" type="text/html" title="English albert_base_chinese_finetuned_qqp_tm_5x BertForSequenceClassification from r10521708" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/albert_base_chinese_finetuned_qqp_tm_5x_en</id><content type="html" xml:base="/2024/09/27/albert_base_chinese_finetuned_qqp_tm_5x_en.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`albert_base_chinese_finetuned_qqp_tm_5x` is a English model originally trained by r10521708.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_base_chinese_finetuned_qqp_tm_5x_en_5.5.0_3.0_1727400432818.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/albert_base_chinese_finetuned_qqp_tm_5x_en_5.5.0_3.0_1727400432818.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;albert_base_chinese_finetuned_qqp_tm_5x&quot;,&quot;en&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;albert_base_chinese_finetuned_qqp_tm_5x&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|albert_base_chinese_finetuned_qqp_tm_5x|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|39.8 MB|

## References

https://huggingface.co/r10521708/albert-base-chinese-finetuned-qqp-TM-5x</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.albert_base_chinese_finetuned_qqp_tm_5x is a English model originally trained by r10521708. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;albert_base_chinese_finetuned_qqp_tm_5x&quot;,&quot;en&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;albert_base_chinese_finetuned_qqp_tm_5x&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: albert_base_chinese_finetuned_qqp_tm_5x Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 39.8 MB References https://huggingface.co/r10521708/albert-base-chinese-finetuned-qqp-TM-5x</summary></entry><entry><title type="html">English albert_chinese_base_text_classification BertForSequenceClassification from CeroShrijver</title><link href="/2024/09/27/albert_chinese_base_text_classification_en.html" rel="alternate" type="text/html" title="English albert_chinese_base_text_classification BertForSequenceClassification from CeroShrijver" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/albert_chinese_base_text_classification_en</id><content type="html" xml:base="/2024/09/27/albert_chinese_base_text_classification_en.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`albert_chinese_base_text_classification` is a English model originally trained by CeroShrijver.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/albert_chinese_base_text_classification_en_5.5.0_3.0_1727399740127.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/albert_chinese_base_text_classification_en_5.5.0_3.0_1727399740127.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;albert_chinese_base_text_classification&quot;,&quot;en&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;albert_chinese_base_text_classification&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|albert_chinese_base_text_classification|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|39.8 MB|

## References

https://huggingface.co/CeroShrijver/albert_chinese_base-text-classification</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.albert_chinese_base_text_classification is a English model originally trained by CeroShrijver. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;albert_chinese_base_text_classification&quot;,&quot;en&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;albert_chinese_base_text_classification&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: albert_chinese_base_text_classification Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 39.8 MB References https://huggingface.co/CeroShrijver/albert_chinese_base-text-classification</summary></entry><entry><title type="html">English all_classification BertForSequenceClassification from bharadwajkg</title><link href="/2024/09/27/all_classification_en.html" rel="alternate" type="text/html" title="English all_classification BertForSequenceClassification from bharadwajkg" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/all_classification_en</id><content type="html" xml:base="/2024/09/27/all_classification_en.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_classification` is a English model originally trained by bharadwajkg.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_classification_en_5.5.0_3.0_1727406683712.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_classification_en_5.5.0_3.0_1727406683712.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;all_classification&quot;,&quot;en&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;all_classification&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_classification|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|409.5 MB|

## References

https://huggingface.co/bharadwajkg/all_classification</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_classification is a English model originally trained by bharadwajkg. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;all_classification&quot;,&quot;en&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;all_classification&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: all_classification Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 409.5 MB References https://huggingface.co/bharadwajkg/all_classification</summary></entry><entry><title type="html">English all_mini_finetuned_imdb BertForSequenceClassification from DBretsko</title><link href="/2024/09/27/all_mini_finetuned_imdb_en.html" rel="alternate" type="text/html" title="English all_mini_finetuned_imdb BertForSequenceClassification from DBretsko" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/all_mini_finetuned_imdb_en</id><content type="html" xml:base="/2024/09/27/all_mini_finetuned_imdb_en.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`all_mini_finetuned_imdb` is a English model originally trained by DBretsko.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/all_mini_finetuned_imdb_en_5.5.0_3.0_1727409291205.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/all_mini_finetuned_imdb_en_5.5.0_3.0_1727409291205.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;all_mini_finetuned_imdb&quot;,&quot;en&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;all_mini_finetuned_imdb&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|all_mini_finetuned_imdb|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|en|
|Size:|84.6 MB|

## References

https://huggingface.co/DBretsko/all-Mini-finetuned-imdb</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.all_mini_finetuned_imdb is a English model originally trained by DBretsko. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;all_mini_finetuned_imdb&quot;,&quot;en&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;all_mini_finetuned_imdb&quot;, &quot;en&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: all_mini_finetuned_imdb Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: en Size: 84.6 MB References https://huggingface.co/DBretsko/all-Mini-finetuned-imdb</summary></entry><entry><title type="html">Castilian, Spanish amazon_review BertForSequenceClassification from luisu0124</title><link href="/2024/09/27/amazon_review_es.html" rel="alternate" type="text/html" title="Castilian, Spanish amazon_review BertForSequenceClassification from luisu0124" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/amazon_review_es</id><content type="html" xml:base="/2024/09/27/amazon_review_es.html">## Description

Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`amazon_review` is a Castilian, Spanish model originally trained by luisu0124.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/amazon_review_es_5.5.0_3.0_1727403309546.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/amazon_review_es_5.5.0_3.0_1727403309546.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
     
documentAssembler = DocumentAssembler() \
    .setInputCol('text') \
    .setOutputCol('document')
    
tokenizer = Tokenizer() \
    .setInputCols(['document']) \
    .setOutputCol('token')

sequenceClassifier  = BertForSequenceClassification.pretrained(&quot;amazon_review&quot;,&quot;es&quot;) \
     .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \
     .setOutputCol(&quot;class&quot;)

pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier])
data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;)
pipelineModel = pipeline.fit(data)
pipelineDF = pipelineModel.transform(data)

```
```scala

val documentAssembler = new DocumentAssembler()
    .setInputCols(&quot;text&quot;)
    .setOutputCols(&quot;document&quot;)
    
val tokenizer = new Tokenizer()
    .setInputCols(Array(&quot;document&quot;))
    .setOutputCol(&quot;token&quot;)

val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;amazon_review&quot;, &quot;es&quot;)
    .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) 
    .setOutputCol(&quot;class&quot;) 
    
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier))
val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;)
val pipelineModel = pipeline.fit(data)
val pipelineDF = pipelineModel.transform(data)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|amazon_review|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[class]|
|Language:|es|
|Size:|16.7 MB|

## References

https://huggingface.co/luisu0124/Amazon_review</content><author><name>John Snow Labs</name></author><category term="es" /><category term="open_source" /><category term="onnx" /><category term="sequence_classification" /><category term="bert" /><summary type="html">Description Pretrained BertForSequenceClassification model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.amazon_review is a Castilian, Spanish model originally trained by luisu0124. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCol('text') \ .setOutputCol('document') tokenizer = Tokenizer() \ .setInputCols(['document']) \ .setOutputCol('token') sequenceClassifier = BertForSequenceClassification.pretrained(&quot;amazon_review&quot;,&quot;es&quot;) \ .setInputCols([&quot;documents&quot;,&quot;token&quot;]) \ .setOutputCol(&quot;class&quot;) pipeline = Pipeline().setStages([documentAssembler, tokenizer, sequenceClassifier]) data = spark.createDataFrame([[&quot;I love spark-nlp&quot;]]).toDF(&quot;text&quot;) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(&quot;text&quot;) .setOutputCols(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(Array(&quot;document&quot;)) .setOutputCol(&quot;token&quot;) val sequenceClassifier = BertForSequenceClassification.pretrained(&quot;amazon_review&quot;, &quot;es&quot;) .setInputCols(Array(&quot;documents&quot;,&quot;token&quot;)) .setOutputCol(&quot;class&quot;) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, sequenceClassifier)) val data = Seq(&quot;I love spark-nlp&quot;).toDS.toDF(&quot;text&quot;) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: amazon_review Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [class] Language: es Size: 16.7 MB References https://huggingface.co/luisu0124/Amazon_review</summary></entry><entry><title type="html">Castilian, Spanish amazon_review_pipeline pipeline BertForSequenceClassification from luisu0124</title><link href="/2024/09/27/amazon_review_pipeline_es.html" rel="alternate" type="text/html" title="Castilian, Spanish amazon_review_pipeline pipeline BertForSequenceClassification from luisu0124" /><published>2024-09-27T00:00:00+00:00</published><updated>2024-09-27T00:00:00+00:00</updated><id>/2024/09/27/amazon_review_pipeline_es</id><content type="html" xml:base="/2024/09/27/amazon_review_pipeline_es.html">## Description

Pretrained BertForSequenceClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`amazon_review_pipeline` is a Castilian, Spanish model originally trained by luisu0124.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/amazon_review_pipeline_es_5.5.0_3.0_1727403310870.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/amazon_review_pipeline_es_5.5.0_3.0_1727403310870.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python

pipeline = PretrainedPipeline(&quot;amazon_review_pipeline&quot;, lang = &quot;es&quot;)
annotations =  pipeline.transform(df)   

```
```scala

val pipeline = new PretrainedPipeline(&quot;amazon_review_pipeline&quot;, lang = &quot;es&quot;)
val annotations = pipeline.transform(df)

```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|amazon_review_pipeline|
|Type:|pipeline|
|Compatibility:|Spark NLP 5.5.0+|
|License:|Open Source|
|Edition:|Official|
|Language:|es|
|Size:|16.8 MB|

## References

https://huggingface.co/luisu0124/Amazon_review

## Included Models

- DocumentAssembler
- TokenizerModel
- BertForSequenceClassification</content><author><name>John Snow Labs</name></author><category term="es" /><category term="open_source" /><category term="pipeline" /><category term="onnx" /><summary type="html">Description Pretrained BertForSequenceClassification, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.amazon_review_pipeline is a Castilian, Spanish model originally trained by luisu0124. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU pipeline = PretrainedPipeline(&quot;amazon_review_pipeline&quot;, lang = &quot;es&quot;) annotations = pipeline.transform(df) val pipeline = new PretrainedPipeline(&quot;amazon_review_pipeline&quot;, lang = &quot;es&quot;) val annotations = pipeline.transform(df) Model Information Model Name: amazon_review_pipeline Type: pipeline Compatibility: Spark NLP 5.5.0+ License: Open Source Edition: Official Language: es Size: 16.8 MB References https://huggingface.co/luisu0124/Amazon_review Included Models DocumentAssembler TokenizerModel BertForSequenceClassification</summary></entry></feed>