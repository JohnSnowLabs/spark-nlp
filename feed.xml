<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-09-25T18:04:25+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Dutch BertEmbeddings Base Cased model (from textgain)</title><link href="/2023/09/22/bert_embeddings_allnli_gronlp_base_dutch_cased_nl.html" rel="alternate" type="text/html" title="Dutch BertEmbeddings Base Cased model (from textgain)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_allnli_gronlp_base_dutch_cased_nl</id><content type="html" xml:base="/2023/09/22/bert_embeddings_allnli_gronlp_base_dutch_cased_nl.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `allnli-GroNLP-bert-base-dutch-cased` is a Dutch model originally trained by `textgain`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_allnli_gronlp_base_dutch_cased_nl_5.1.0_3.0_1695368402996.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_allnli_gronlp_base_dutch_cased_nl_5.1.0_3.0_1695368402996.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_allnli_gronlp_base_dutch_cased&quot;,&quot;nl&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_allnli_gronlp_base_dutch_cased&quot;,&quot;nl&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_allnli_gronlp_base_dutch_cased|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|nl|
|Size:|406.8 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/textgain/allnli-GroNLP-bert-base-dutch-cased
- https://www.SBERT.net
- https://www.SBERT.net
- https://www.SBERT.net
- https://seb.sbert.net?model_name=%7BMODEL_NAME%7D</content><author><name>John Snow Labs</name></author><category term="nl" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. allnli-GroNLP-bert-base-dutch-cased is a Dutch model originally trained by textgain. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_allnli_gronlp_base_dutch_cased&quot;,&quot;nl&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_allnli_gronlp_base_dutch_cased&quot;,&quot;nl&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_allnli_gronlp_base_dutch_cased Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: nl Size: 406.8 MB Case sensitive: true References https://huggingface.co/textgain/allnli-GroNLP-bert-base-dutch-cased https://www.SBERT.net https://www.SBERT.net https://www.SBERT.net https://seb.sbert.net?model_name=%7BMODEL_NAME%7D</summary></entry><entry><title type="html">English BertEmbeddings Base Cased model (from BAAI)</title><link href="/2023/09/22/bert_embeddings_bge_base_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Base Cased model (from BAAI)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_bge_base_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_bge_base_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bge-base-en` is a English model originally trained by `BAAI`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_bge_base_en_5.1.0_3.0_1695368493416.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_bge_base_en_5.1.0_3.0_1695368493416.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_base&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_bge_base|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|259.0 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/BAAI/bge-base-en
- https://github.com/FlagOpen/FlagEmbedding
- https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md
- https://arxiv.org/pdf/2309.07597.pdf
- https://data.baai.ac.cn/details/BAAI-MTP
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list
- https://www.SBERT.net
- https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md
- https://platform.openai.com/docs/guides/embeddings
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md
- https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/
- https://github.com/staoxiao/RetroMAE
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker
- https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE
- https://paperswithcode.com/sota?task=Classification&amp;dataset=MTEB+AmazonCounterfactualClassification+%28en%29</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bge-base-en is a English model originally trained by BAAI. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_bge_base Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 259.0 MB Case sensitive: true References https://huggingface.co/BAAI/bge-base-en https://github.com/FlagOpen/FlagEmbedding https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md https://arxiv.org/pdf/2309.07597.pdf https://data.baai.ac.cn/details/BAAI-MTP https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list https://www.SBERT.net https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md https://platform.openai.com/docs/guides/embeddings https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md https://platform.openai.com/docs/guides/embeddings/what-are-embeddings https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/ https://github.com/staoxiao/RetroMAE https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE https://paperswithcode.com/sota?task=Classification&amp;amp;dataset=MTEB+AmazonCounterfactualClassification+%28en%29</summary></entry><entry><title type="html">English BertEmbeddings Large Cased model (from BAAI)</title><link href="/2023/09/22/bert_embeddings_bge_large_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Large Cased model (from BAAI)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_bge_large_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_bge_large_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bge-large-en` is a English model originally trained by `BAAI`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_bge_large_en_5.1.0_3.0_1695368740777.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_bge_large_en_5.1.0_3.0_1695368740777.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_large&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_large&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_bge_large|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|795.1 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/BAAI/bge-large-en
- https://github.com/FlagOpen/FlagEmbedding
- https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md
- https://arxiv.org/pdf/2309.07597.pdf
- https://data.baai.ac.cn/details/BAAI-MTP
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list
- https://www.SBERT.net
- https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md
- https://platform.openai.com/docs/guides/embeddings
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md
- https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/
- https://github.com/staoxiao/RetroMAE
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker
- https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE
- https://paperswithcode.com/sota?task=Classification&amp;dataset=MTEB+AmazonCounterfactualClassification+%28en%29</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bge-large-en is a English model originally trained by BAAI. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_large&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_large&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_bge_large Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 795.1 MB Case sensitive: true References https://huggingface.co/BAAI/bge-large-en https://github.com/FlagOpen/FlagEmbedding https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md https://arxiv.org/pdf/2309.07597.pdf https://data.baai.ac.cn/details/BAAI-MTP https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list https://www.SBERT.net https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md https://platform.openai.com/docs/guides/embeddings https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md https://platform.openai.com/docs/guides/embeddings/what-are-embeddings https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/ https://github.com/staoxiao/RetroMAE https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE https://paperswithcode.com/sota?task=Classification&amp;amp;dataset=MTEB+AmazonCounterfactualClassification+%28en%29</summary></entry><entry><title type="html">English BertEmbeddings Small Cased model (from BAAI)</title><link href="/2023/09/22/bert_embeddings_bge_small_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Small Cased model (from BAAI)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_bge_small_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_bge_small_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bge-small-en` is a English model originally trained by `BAAI`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_bge_small_en_5.1.0_3.0_1695368784401.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_bge_small_en_5.1.0_3.0_1695368784401.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_small&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_small&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_bge_small|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|79.9 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/BAAI/bge-small-en
- https://github.com/FlagOpen/FlagEmbedding
- https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md
- https://arxiv.org/pdf/2309.07597.pdf
- https://data.baai.ac.cn/details/BAAI-MTP
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list
- https://www.SBERT.net
- https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md
- https://platform.openai.com/docs/guides/embeddings
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md
- https://platform.openai.com/docs/guides/embeddings/what-are-embeddings
- https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/
- https://github.com/staoxiao/RetroMAE
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain
- https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md
- https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker
- https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker
- https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE
- https://paperswithcode.com/sota?task=Classification&amp;dataset=MTEB+AmazonCounterfactualClassification+%28en%29</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bge-small-en is a English model originally trained by BAAI. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_small&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bge_small&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_bge_small Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 79.9 MB Case sensitive: true References https://huggingface.co/BAAI/bge-small-en https://github.com/FlagOpen/FlagEmbedding https://github.com/FlagOpen/FlagEmbedding/blob/master/README_zh.md https://arxiv.org/pdf/2309.07597.pdf https://data.baai.ac.cn/details/BAAI-MTP https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/C_MTEB https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune#hard-negatives https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list https://www.SBERT.net https://github.com/FlagOpen/FlagEmbedding/tree/master#model-list https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md https://platform.openai.com/docs/guides/embeddings https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/README.md https://platform.openai.com/docs/guides/embeddings/what-are-embeddings https://github.com/FlagOpen/FlagEmbedding/blob/master/C_MTEB/ https://github.com/staoxiao/RetroMAE https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/finetune https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/pretrain https://github.com/FlagOpen/FlagEmbedding/blob/master/FlagEmbedding/baai_general_embedding/README.md https://github.com/FlagOpen/FlagEmbedding/tree/master/examples/reranker https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker https://github.com/FlagOpen/FlagEmbedding/blob/master/LICENSE https://paperswithcode.com/sota?task=Classification&amp;amp;dataset=MTEB+AmazonCounterfactualClassification+%28en%29</summary></entry><entry><title type="html">German BertEmbeddings Base Cased model (from PM-AI)</title><link href="/2023/09/22/bert_embeddings_bi_encoder_msmarco_base_german_de.html" rel="alternate" type="text/html" title="German BertEmbeddings Base Cased model (from PM-AI)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_bi_encoder_msmarco_base_german_de</id><content type="html" xml:base="/2023/09/22/bert_embeddings_bi_encoder_msmarco_base_german_de.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bi-encoder_msmarco_bert-base_german` is a German model originally trained by `PM-AI`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_bi_encoder_msmarco_base_german_de_5.1.0_3.0_1695368809437.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_bi_encoder_msmarco_base_german_de_5.1.0_3.0_1695368809437.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bi_encoder_msmarco_base_german&quot;,&quot;de&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bi_encoder_msmarco_base_german&quot;,&quot;de&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_bi_encoder_msmarco_base_german|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|de|
|Size:|409.7 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/PM-AI/bi-encoder_msmarco_bert-base_german
- https://github.com/UKPLab/sentence-transformers
- https://microsoft.github.io/msmarco/#ranking
- https://arxiv.org/abs/2108.13897
- https://openreview.net/forum?id=wCu6T5xFjeJ
- https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/
- https://github.com/beir-cellar/beir
- https://github.com/beir-cellar/beir/blob/main/examples/retrieval/training/train_msmarco_v3_margin_MSE.py
- https://sbert.net/datasets/msmarco-hard-negatives.jsonl.gz
- https://github.com/beir-cellar/beir/blob/main/examples/retrieval/training/train_msmarco_v3_margin_MSE.py%5D
- https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/ms_marco/README.md
- https://github.com/beir-cellar/beir/blob/main/examples/retrieval/training/train_msmarco_v3_margin_MSE.py
- https://arxiv.org/abs/2104.12741
- https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#bm25
- https://en.th-wildau.de/
- https://senseaition.com/
- https://www.linkedin.com/in/herrphilipps
- https://efre.brandenburg.de/efre/de/
- https://www.senseaition.com
- https://www.th-wildau.de</content><author><name>John Snow Labs</name></author><category term="de" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bi-encoder_msmarco_bert-base_german is a German model originally trained by PM-AI. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bi_encoder_msmarco_base_german&quot;,&quot;de&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_bi_encoder_msmarco_base_german&quot;,&quot;de&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_bi_encoder_msmarco_base_german Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: de Size: 409.7 MB Case sensitive: true References https://huggingface.co/PM-AI/bi-encoder_msmarco_bert-base_german https://github.com/UKPLab/sentence-transformers https://microsoft.github.io/msmarco/#ranking https://arxiv.org/abs/2108.13897 https://openreview.net/forum?id=wCu6T5xFjeJ https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/ https://github.com/beir-cellar/beir https://github.com/beir-cellar/beir/blob/main/examples/retrieval/training/train_msmarco_v3_margin_MSE.py https://sbert.net/datasets/msmarco-hard-negatives.jsonl.gz https://github.com/beir-cellar/beir/blob/main/examples/retrieval/training/train_msmarco_v3_margin_MSE.py%5D https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/ms_marco/README.md https://github.com/beir-cellar/beir/blob/main/examples/retrieval/training/train_msmarco_v3_margin_MSE.py https://arxiv.org/abs/2104.12741 https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-similarity.html#bm25 https://en.th-wildau.de/ https://senseaition.com/ https://www.linkedin.com/in/herrphilipps https://efre.brandenburg.de/efre/de/ https://www.senseaition.com https://www.th-wildau.de</summary></entry><entry><title type="html">English BertEmbeddings Base Cased model (from fnlp)</title><link href="/2023/09/22/bert_embeddings_claif_base_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Base Cased model (from fnlp)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_claif_base_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_claif_base_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `claif-bert-base` is a English model originally trained by `fnlp`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_claif_base_en_5.1.0_3.0_1695368841856.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_claif_base_en_5.1.0_3.0_1695368841856.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_base&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_claif_base|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|407.2 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/fnlp/claif-bert-base
- https://www.SBERT.net
- https://www.SBERT.net
- https://www.SBERT.net
- https://seb.sbert.net?model_name=fnlp/claif-bert-base</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. claif-bert-base is a English model originally trained by fnlp. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_claif_base Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 407.2 MB Case sensitive: true References https://huggingface.co/fnlp/claif-bert-base https://www.SBERT.net https://www.SBERT.net https://www.SBERT.net https://seb.sbert.net?model_name=fnlp/claif-bert-base</summary></entry><entry><title type="html">English BertEmbeddings Base Cased model (from fnlp)</title><link href="/2023/09/22/bert_embeddings_claif_scaled_base_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Base Cased model (from fnlp)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_claif_scaled_base_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_claif_scaled_base_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `claif-scaled-bert-base` is a English model originally trained by `fnlp`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_claif_scaled_base_en_5.1.0_3.0_1695368874285.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_claif_scaled_base_en_5.1.0_3.0_1695368874285.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_scaled_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_scaled_base&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_claif_scaled_base|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|407.2 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/fnlp/claif-scaled-bert-base
- https://www.SBERT.net
- https://www.SBERT.net
- https://www.SBERT.net
- https://seb.sbert.net?model_name=fnlp/claif-scaled-bert-base</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. claif-scaled-bert-base is a English model originally trained by fnlp. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_scaled_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_claif_scaled_base&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_claif_scaled_base Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 407.2 MB Case sensitive: true References https://huggingface.co/fnlp/claif-scaled-bert-base https://www.SBERT.net https://www.SBERT.net https://www.SBERT.net https://seb.sbert.net?model_name=fnlp/claif-scaled-bert-base</summary></entry><entry><title type="html">English BertEmbeddings Cased model (from DragosGorduza)</title><link href="/2023/09/22/bert_embeddings_frpile_gpl_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Cased model (from DragosGorduza)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_frpile_gpl_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_frpile_gpl_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `FRPile_GPL` is a English model originally trained by `DragosGorduza`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_frpile_gpl_en_5.1.0_3.0_1695368293927.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_frpile_gpl_en_5.1.0_3.0_1695368293927.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_frpile_gpl&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_frpile_gpl&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_frpile_gpl|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|1.3 GB|
|Case sensitive:|true|

## References

- https://huggingface.co/DragosGorduza/FRPile_GPL
- https://www.SBERT.net
- https://www.SBERT.net
- https://www.SBERT.net
- https://seb.sbert.net?model_name=%7BMODEL_NAME%7D</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. FRPile_GPL is a English model originally trained by DragosGorduza. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_frpile_gpl&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_frpile_gpl&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_frpile_gpl Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 1.3 GB Case sensitive: true References https://huggingface.co/DragosGorduza/FRPile_GPL https://www.SBERT.net https://www.SBERT.net https://www.SBERT.net https://seb.sbert.net?model_name=%7BMODEL_NAME%7D</summary></entry><entry><title type="html">English BertEmbeddings Cased model (from nthakur)</title><link href="/2023/09/22/bert_embeddings_retromae_beir_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Cased model (from nthakur)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_retromae_beir_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_retromae_beir_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `RetroMAE_BEIR` is a English model originally trained by `nthakur`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_retromae_beir_en_5.1.0_3.0_1695368339221.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_retromae_beir_en_5.1.0_3.0_1695368339221.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_beir&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_beir&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_retromae_beir|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|407.6 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/nthakur/RetroMAE_BEIR
- https://www.SBERT.net
- https://www.SBERT.net
- https://www.SBERT.net
- https://seb.sbert.net?model_name=nthakur/RetroMAE_BEIR
- https://github.com/staoxiao/RetroMAE/</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. RetroMAE_BEIR is a English model originally trained by nthakur. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_beir&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_beir&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_retromae_beir Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 407.6 MB Case sensitive: true References https://huggingface.co/nthakur/RetroMAE_BEIR https://www.SBERT.net https://www.SBERT.net https://www.SBERT.net https://seb.sbert.net?model_name=nthakur/RetroMAE_BEIR https://github.com/staoxiao/RetroMAE/</summary></entry><entry><title type="html">English BertEmbeddings Cased model (from nthakur)</title><link href="/2023/09/22/bert_embeddings_retromae_msmarco_finetune_en.html" rel="alternate" type="text/html" title="English BertEmbeddings Cased model (from nthakur)" /><published>2023-09-22T00:00:00+00:00</published><updated>2023-09-22T00:00:00+00:00</updated><id>/2023/09/22/bert_embeddings_retromae_msmarco_finetune_en</id><content type="html" xml:base="/2023/09/22/bert_embeddings_retromae_msmarco_finetune_en.html">## Description

Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `RetroMAE_MSMARCO_finetune` is a English model originally trained by `nthakur`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_embeddings_retromae_msmarco_finetune_en_5.1.0_3.0_1695368370969.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_embeddings_retromae_msmarco_finetune_en_5.1.0_3.0_1695368370969.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler() \
    .setInputCols([&quot;text&quot;]) \
    .setOutputCols(&quot;document&quot;)

tokenizer = Tokenizer() \
    .setInputCols(&quot;document&quot;) \
    .setOutputCol(&quot;token&quot;)

bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_msmarco_finetune&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded])

data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler() 
    .setInputCols(Array(&quot;text&quot;)) 
    .setOutputCols(Array(&quot;document&quot;))
      
val tokenizer = new Tokenizer()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;token&quot;)
 
val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_msmarco_finetune&quot;,&quot;en&quot;) 
    .setInputCols(Array(&quot;document&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(true)    
   
val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded))

val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_embeddings_retromae_msmarco_finetune|
|Compatibility:|Spark NLP 5.1.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[bert]|
|Language:|en|
|Size:|407.7 MB|
|Case sensitive:|true|

## References

- https://huggingface.co/nthakur/RetroMAE_MSMARCO_finetune
- https://www.SBERT.net
- https://www.SBERT.net
- https://www.SBERT.net
- https://seb.sbert.net?model_name=nthakur/RetroMAE_MSMARCO_finetune
- https://github.com/staoxiao/RetroMAE/</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert_embeddings" /><category term="onnx" /><summary type="html">Description Pretrained BertEmbeddings model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. RetroMAE_MSMARCO_finetune is a English model originally trained by nthakur. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = DocumentAssembler() \ .setInputCols([&quot;text&quot;]) \ .setOutputCols(&quot;document&quot;) tokenizer = Tokenizer() \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;token&quot;) bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_msmarco_finetune&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setCaseSensitive(True) pipeline = Pipeline(stages=[documentAssembler, tokenizer, bert_loaded]) data = spark.createDataFrame([[&quot;I love Spark NLP&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCols(Array(&quot;text&quot;)) .setOutputCols(Array(&quot;document&quot;)) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val bert_loaded = BertEmbeddings.pretrained(&quot;bert_embeddings_retromae_msmarco_finetune&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(documentAssembler, tokenizer, bert_loaded)) val data = Seq(&quot;I love Spark NLP&quot;).toDS.toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: bert_embeddings_retromae_msmarco_finetune Compatibility: Spark NLP 5.1.0+ License: Open Source Edition: Official Input Labels: [document, token] Output Labels: [bert] Language: en Size: 407.7 MB Case sensitive: true References https://huggingface.co/nthakur/RetroMAE_MSMARCO_finetune https://www.SBERT.net https://www.SBERT.net https://www.SBERT.net https://seb.sbert.net?model_name=nthakur/RetroMAE_MSMARCO_finetune https://github.com/staoxiao/RetroMAE/</summary></entry></feed>