<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-01-21T17:25:38+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Legal NER (Parties, Dates, Alias, Former names, Document Type - lg)</title><link href="/2023/01/21/legner_contract_doc_parties_lg_en.html" rel="alternate" type="text/html" title="Legal NER (Parties, Dates, Alias, Former names, Document Type - lg)" /><published>2023-01-21T00:00:00+00:00</published><updated>2023-01-21T00:00:00+00:00</updated><id>/2023/01/21/legner_contract_doc_parties_lg_en</id><content type="html" xml:base="/2023/01/21/legner_contract_doc_parties_lg_en.html">&lt;h2 id=&quot;description&quot;&gt;Description&lt;/h2&gt;

&lt;p&gt;MPORTANT: Donâ€™t run this model on the whole legal agreement. Instead:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Split by paragraphs. You can use &lt;a href=&quot;https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings_JSL&quot;&gt;notebook 1&lt;/a&gt; in Finance or Legal as inspiration;&lt;/li&gt;
  &lt;li&gt;Use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;legclf_introduction_clause&lt;/code&gt; Text Classifier to select only these paragraphs;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a Legal NER Model, aimed to process the first page of the agreements when information can be found about:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Parties of the contract/agreement;&lt;/li&gt;
  &lt;li&gt;Their former names;&lt;/li&gt;
  &lt;li&gt;Aliases of those parties, or how those parties will be called further on in the document;&lt;/li&gt;
  &lt;li&gt;Document Type;&lt;/li&gt;
  &lt;li&gt;Effective Date of the agreement;&lt;/li&gt;
  &lt;li&gt;Other organizations;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This model can be used all along with its Relation Extraction model to retrieve the relations between these entities, called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;legre_contract_doc_parties&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;predicted-entities&quot;&gt;Predicted Entities&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PARTY&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EFFDATE&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DOC&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ALIAS&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ORG&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FORMER_NAME&lt;/code&gt;&lt;/p&gt;

&lt;p class=&quot;btn-box&quot;&gt;&lt;a href=&quot;https://demo.johnsnowlabs.com/finance/LEGALNER_PARTIES/&quot; class=&quot;button button-orange&quot;&gt;Live Demo&lt;/a&gt;
&lt;button class=&quot;button button-orange&quot; disabled=&quot;&quot;&gt;Open in Colab&lt;/button&gt;
&lt;a href=&quot;https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_contract_doc_parties_lg_en_1.0.0_3.0_1674321394808.zip&quot; class=&quot;button button-orange&quot;&gt;Download&lt;/a&gt;
&lt;a href=&quot;s3://auxdata.johnsnowlabs.com/legal/models/legner_contract_doc_parties_lg_en_1.0.0_3.0_1674321394808.zip&quot; class=&quot;button button-orange button-orange-trans button-icon button-copy-s3&quot;&gt;Copy S3 URI&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-to-use&quot;&gt;How to use&lt;/h2&gt;

&lt;div class=&quot;tabs-box&quot;&gt;
  &lt;div class=&quot;tabs-model-aproach-head&quot;&gt;&lt;button class=&quot;tab-li-model-aproach tabheader_active&quot;&gt;Python&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;Scala&lt;/button&gt;&lt;button class=&quot;tab-li-model-aproach&quot;&gt;NLU&lt;/button&gt;&lt;/div&gt;
  &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;documentAssembler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DocumentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;n&quot;&gt;sentenceDetector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SentenceDetectorDLModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence_detector_dl&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;xx&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RoBertaEmbeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;roberta_embeddings_legal_roberta_base&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;en&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\

&lt;span class=&quot;n&quot;&gt;ner_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;legal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NerModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'legner_contract_doc_parties_lg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'en'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'legal/models'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;embeddings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ner_converter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NerConverter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setInputCols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;token&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;\
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setOutputCol&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ner_chunk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nlpPipeline&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;documentAssembler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sentenceDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ner_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ner_converter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;empty_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlpPipeline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
INTELLECTUAL PROPERTY AGREEMENT

This INTELLECTUAL PROPERTY AGREEMENT (this &quot;Agreement&quot;), dated as of December 31, 2018 (the &quot;Effective Date&quot;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&quot;Seller&quot;) and AFI Licensing LLC, a Delaware limited liability company (&quot;Licensing&quot; and together with Seller, &quot;Arizona&quot;) and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation (&quot;Buyer&quot;) and Armstrong Hardwood Flooring Company, a Tennessee corporation (the &quot;Company&quot; and together with Buyer the &quot;Buyer Entities&quot;) (each of Arizona on the one hand and the Buyer Entities on the other hand, a &quot;Party&quot; and collectively, the &quot;Parties&quot;).
&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;createDataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;

&lt;/div&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+------------+---------+
|       token|ner_label|
+------------+---------+
|INTELLECTUAL|    B-DOC|
|    PROPERTY|    I-DOC|
|   AGREEMENT|    I-DOC|
|        This|        O|
|INTELLECTUAL|    B-DOC|
|    PROPERTY|    I-DOC|
|   AGREEMENT|    I-DOC|
|           &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;|        O|
|        this|        O|
|           &lt;span class=&quot;s2&quot;&gt;&quot;|        O|
|   Agreement|        O|
|         &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,|        O|
|       dated|        O|
|          as|        O|
|          of|        O|
|    December|B-EFFDATE|
|          31|I-EFFDATE|
|           ,|I-EFFDATE|
|        2018|I-EFFDATE|
|           &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;|        O|
|         the|        O|
|           &lt;span class=&quot;s2&quot;&gt;&quot;|        O|
|   Effective|        O|
|        Date|        O|
|          &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;|        O|
|          is|        O|
|     entered|        O|
|        into|        O|
|          by|        O|
|         and|        O|
|     between|        O|
|   Armstrong|  B-PARTY|
|    Flooring|  I-PARTY|
|           ,|  I-PARTY|
|         Inc|  I-PARTY|
|          .,|        O|
|           a|        O|
|    Delaware|        O|
| corporation|        O|
|          &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;|        O|
|      Seller|  B-ALIAS|
|          &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;|        O|
|         and|        O|
|         AFI|  B-PARTY|
|   Licensing|  I-PARTY|
|         LLC|  I-PARTY|
|           ,|        O|
|           a|        O|
|    Delaware|        O|
|     limited|        O|
|   liability|        O|
|     company|        O|
|          &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;|        O|
|   Licensing|  B-ALIAS|
|           &quot;&lt;/span&gt;|        O|
|         and|        O|
|    together|        O|
|        with|        O|
|      Seller|  B-ALIAS|
|           ,|        O|
|           &lt;span class=&quot;s2&quot;&gt;&quot;|        O|
|     Arizona|  B-ALIAS|
|          &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;|        O|
|         and|        O|
|         AHF|  B-PARTY|
|     Holding|  I-PARTY|
|           ,|  I-PARTY|
|         Inc|  I-PARTY|
|           .|        O|
|           &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;|        O|
|    formerly|        O|
|       known|        O|
|          as|        O|
|      Tarzan|        O|
|      HoldCo|        O|
|           ,|        O|
|         Inc|        O|
|         .&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;,|        O|
|           a|        O|
|    Delaware|        O|
| corporation|        O|
|          &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;|        O|
|       Buyer|  B-ALIAS|
|          &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;|        O|
|         and|        O|
|   Armstrong|  B-PARTY|
|    Hardwood|  I-PARTY|
|    Flooring|  I-PARTY|
|     Company|  I-PARTY|
&lt;span class=&quot;nt&quot;&gt;------------------------&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 class=&quot;model-param&quot; id=&quot;model-information&quot;&gt;Model Information&lt;/h2&gt;

&lt;table class=&quot;table-model&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Model Name:&lt;/td&gt;
      &lt;td&gt;legner_contract_doc_parties_lg&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Compatibility:&lt;/td&gt;
      &lt;td&gt;Legal NLP 1.0.0+&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;License:&lt;/td&gt;
      &lt;td&gt;Licensed&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edition:&lt;/td&gt;
      &lt;td&gt;Official&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Input Labels:&lt;/td&gt;
      &lt;td&gt;[sentence, token, embeddings]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Output Labels:&lt;/td&gt;
      &lt;td&gt;[ner]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Language:&lt;/td&gt;
      &lt;td&gt;en&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Size:&lt;/td&gt;
      &lt;td&gt;16.3 MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;Manual annotations on CUAD dataset&lt;/p&gt;

&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;label	 tp	 fp	 fn	 prec	 rec	 f1
I-PARTY	 513	 58	 85	 0.8984238	 0.85785955	 0.87767327
B-EFFDATE	 57	 5	 7	 0.91935486	 0.890625	 0.90476185
I-ORG	 208	 32	 49	 0.8666667	 0.8093385	 0.8370222
B-DOC	 80	 9	 21	 0.8988764	 0.7920792	 0.8421053
B-FORMER_NAME	 5	 0	 0	 1.0	 1.0	 1.0
I-EFFDATE	 214	 11	 6	 0.95111114	 0.9727273	 0.96179783
I-FORMER_NAME	 7	 1	 0	 0.875	 1.0	 0.93333334
I-ALIAS	 14	 5	 13	 0.7368421	 0.5185185	 0.6086956
I-DOC	 166	 16	 52	 0.9120879	 0.7614679	 0.83
B-ORG	 131	 28	 42	 0.8238994	 0.75722545	 0.7891567
B-PARTY	 174	 40	 57	 0.8130841	 0.7532467	 0.7820225
B-ALIAS	 170	 17	 13	 0.90909094	 0.92896175	 0.9189189
Macro-average	 1739 222 345 0.8837032 0.8368375 0.859632
Micro-average	 1739 222 345 0.8867925 0.834453 0.859827
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>John Snow Labs</name></author><category term="document" /><category term="contract" /><category term="agreement" /><category term="type" /><category term="parties" /><category term="aliases" /><category term="former" /><category term="names" /><category term="effective" /><category term="dates" /><category term="en" /><category term="licensed" /><summary type="html">Description MPORTANT: Donâ€™t run this model on the whole legal agreement. Instead: Split by paragraphs. You can use notebook 1 in Finance or Legal as inspiration; Use the legclf_introduction_clause Text Classifier to select only these paragraphs; This is a Legal NER Model, aimed to process the first page of the agreements when information can be found about: Parties of the contract/agreement; Their former names; Aliases of those parties, or how those parties will be called further on in the document; Document Type; Effective Date of the agreement; Other organizations; This model can be used all along with its Relation Extraction model to retrieve the relations between these entities, called legre_contract_doc_parties Predicted Entities PARTY, EFFDATE, DOC, ALIAS, ORG, FORMER_NAME Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;, &quot;en&quot;) \ .setInputCols(&quot;sentence&quot;, &quot;token&quot;) \ .setOutputCol(&quot;embeddings&quot;)\ ner_model = legal.NerModel.pretrained('legner_contract_doc_parties_lg', 'en', 'legal/models')\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot; INTELLECTUAL PROPERTY AGREEMENT This INTELLECTUAL PROPERTY AGREEMENT (this &quot;Agreement&quot;), dated as of December 31, 2018 (the &quot;Effective Date&quot;) is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (&quot;Seller&quot;) and AFI Licensing LLC, a Delaware limited liability company (&quot;Licensing&quot; and together with Seller, &quot;Arizona&quot;) and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation (&quot;Buyer&quot;) and Armstrong Hardwood Flooring Company, a Tennessee corporation (the &quot;Company&quot; and together with Buyer the &quot;Buyer Entities&quot;) (each of Arizona on the one hand and the Buyer Entities on the other hand, a &quot;Party&quot; and collectively, the &quot;Parties&quot;). &quot;&quot;&quot;] res = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +------------+---------+ | token|ner_label| +------------+---------+ |INTELLECTUAL| B-DOC| | PROPERTY| I-DOC| | AGREEMENT| I-DOC| | This| O| |INTELLECTUAL| B-DOC| | PROPERTY| I-DOC| | AGREEMENT| I-DOC| | (| O| | this| O| | &quot;| O| | Agreement| O| | &quot;),| O| | dated| O| | as| O| | of| O| | December|B-EFFDATE| | 31|I-EFFDATE| | ,|I-EFFDATE| | 2018|I-EFFDATE| | (| O| | the| O| | &quot;| O| | Effective| O| | Date| O| | &quot;)| O| | is| O| | entered| O| | into| O| | by| O| | and| O| | between| O| | Armstrong| B-PARTY| | Flooring| I-PARTY| | ,| I-PARTY| | Inc| I-PARTY| | .,| O| | a| O| | Delaware| O| | corporation| O| | (&quot;| O| | Seller| B-ALIAS| | &quot;)| O| | and| O| | AFI| B-PARTY| | Licensing| I-PARTY| | LLC| I-PARTY| | ,| O| | a| O| | Delaware| O| | limited| O| | liability| O| | company| O| | (&quot;| O| | Licensing| B-ALIAS| | &quot;| O| | and| O| | together| O| | with| O| | Seller| B-ALIAS| | ,| O| | &quot;| O| | Arizona| B-ALIAS| | &quot;)| O| | and| O| | AHF| B-PARTY| | Holding| I-PARTY| | ,| I-PARTY| | Inc| I-PARTY| | .| O| | (| O| | formerly| O| | known| O| | as| O| | Tarzan| O| | HoldCo| O| | ,| O| | Inc| O| | .),| O| | a| O| | Delaware| O| | corporation| O| | (&quot;| O| | Buyer| B-ALIAS| | &quot;)| O| | and| O| | Armstrong| B-PARTY| | Hardwood| I-PARTY| | Flooring| I-PARTY| | Company| I-PARTY| ------------------------ Model Information Model Name: legner_contract_doc_parties_lg Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 16.3 MB References Manual annotations on CUAD dataset Benchmarking label tp fp fn prec rec f1 I-PARTY 513 58 85 0.8984238 0.85785955 0.87767327 B-EFFDATE 57 5 7 0.91935486 0.890625 0.90476185 I-ORG 208 32 49 0.8666667 0.8093385 0.8370222 B-DOC 80 9 21 0.8988764 0.7920792 0.8421053 B-FORMER_NAME 5 0 0 1.0 1.0 1.0 I-EFFDATE 214 11 6 0.95111114 0.9727273 0.96179783 I-FORMER_NAME 7 1 0 0.875 1.0 0.93333334 I-ALIAS 14 5 13 0.7368421 0.5185185 0.6086956 I-DOC 166 16 52 0.9120879 0.7614679 0.83 B-ORG 131 28 42 0.8238994 0.75722545 0.7891567 B-PARTY 174 40 57 0.8130841 0.7532467 0.7820225 B-ALIAS 170 17 13 0.90909094 0.92896175 0.9189189 Macro-average 1739 222 345 0.8837032 0.8368375 0.859632 Micro-average 1739 222 345 0.8867925 0.834453 0.859827</summary></entry><entry><title type="html">Finance Pipeline (Headers / Subheaders)</title><link href="/2023/01/20/finpipe_header_subheader_en.html" rel="alternate" type="text/html" title="Finance Pipeline (Headers / Subheaders)" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/finpipe_header_subheader_en</id><content type="html" xml:base="/2023/01/20/finpipe_header_subheader_en.html">## Description

This is a finance pretrained pipeline that will help you split long financial documents into smaller sections. To do that, it detects Headers and Subheaders of different sections. You can then use the beginning and end information in the metadata to retrieve the text between those headers.

PART I, PART II, etc are HEADERS
Item 1, Item 2, etc are also HEADERS
Item 1A, 2B, etc are SUBHEADERS
1., 2., 2.1, etc. are SUBHEADERS

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finpipe_header_subheader_en_1.0.0_3.0_1674243435691.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finpipe_header_subheader_en_1.0.0_3.0_1674243435691.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
finance_pipeline = nlp.PretrainedPipeline(&quot;finpipe_header_subheader&quot;, &quot;en&quot;, &quot;finance/models&quot;)

text = [&quot;&quot;&quot;
Item 2. Definitions. 
For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1. 2. Appointment as Reseller.

Item 2A. Appointment. 
The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6

Item 2B. Customer Agreements.&quot;&quot;&quot;]

result = finance_pipeline.annotate(text)
```

&lt;/div&gt;

## Results

```bash
|                        chunks | begin | end |  entities |
|------------------------------:|------:|----:|----------:|
|          Item 2. Definitions. |     1 |  21 |    HEADER |
|         Item 2A. Appointment. |   158 | 179 | SUBHEADER |
| Item 2B. Customer Agreements. |   538 | 566 | SUBHEADER |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finpipe_header_subheader|
|Type:|pipeline|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|23.6 KB|

## Included Models

- DocumentAssembler
- TokenizerModel
- ContextualParserModel
- ContextualParserModel
- ChunkMergeModel</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="ner" /><category term="licensed" /><category term="contextual_parser" /><summary type="html">Description This is a finance pretrained pipeline that will help you split long financial documents into smaller sections. To do that, it detects Headers and Subheaders of different sections. You can then use the beginning and end information in the metadata to retrieve the text between those headers. PART I, PART II, etc are HEADERS Item 1, Item 2, etc are also HEADERS Item 1A, 2B, etc are SUBHEADERS 1., 2., 2.1, etc. are SUBHEADERS Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU finance_pipeline = nlp.PretrainedPipeline(&quot;finpipe_header_subheader&quot;, &quot;en&quot;, &quot;finance/models&quot;) text = [&quot;&quot;&quot; Item 2. Definitions. For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1. 2. Appointment as Reseller. Item 2A. Appointment. The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6 Item 2B. Customer Agreements.&quot;&quot;&quot;] result = finance_pipeline.annotate(text) Results | chunks | begin | end | entities | |------------------------------:|------:|----:|----------:| | Item 2. Definitions. | 1 | 21 | HEADER | | Item 2A. Appointment. | 158 | 179 | SUBHEADER | | Item 2B. Customer Agreements. | 538 | 566 | SUBHEADER | Model Information Model Name: finpipe_header_subheader Type: pipeline Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 23.6 KB Included Models DocumentAssembler TokenizerModel ContextualParserModel ContextualParserModel ChunkMergeModel</summary></entry><entry><title type="html">Legal Pipeline (Headers / Subheaders)</title><link href="/2023/01/20/legpipe_header_subheader_en.html" rel="alternate" type="text/html" title="Legal Pipeline (Headers / Subheaders)" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/legpipe_header_subheader_en</id><content type="html" xml:base="/2023/01/20/legpipe_header_subheader_en.html">## Description

This is a Legal pretrained pipeline, aimed to carry out Section Splitting by using the Headers and Subheaders entities, detected in the document.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legpipe_header_subheader_en_1.0.0_3.0_1674244247295.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legpipe_header_subheader_en_1.0.0_3.0_1674244247295.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
legal_pipeline = nlp.PretrainedPipeline(&quot;legpipe_header_subheader&quot;, &quot;en&quot;, &quot;legal/models&quot;)

text = [&quot;&quot;&quot;2. DEFINITION. 
For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1 and 2 Appointment as Reseller.
2.1 Appointment. 
The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6
2.2 Customer Agreements.&quot;&quot;&quot;]

result = legal_pipeline.annotate(text)
```

&lt;/div&gt;

## Results

```bash
|                  chunks | begin | end |  entities |
|------------------------:|------:|----:|----------:|
|           2. DEFINITION |     0 |  12 |    HEADER |
|         2.1 Appointment |   154 | 168 | SUBHEADER |
| 2.2 Customer Agreements |   530 | 552 | SUBHEADER |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legpipe_header_subheader|
|Type:|pipeline|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|23.6 KB|

## Included Models

- DocumentAssembler
- TokenizerModel
- ContextualParserModel
- ContextualParserModel
- ChunkMergeModel</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="legal" /><category term="ner" /><category term="contextual_parser" /><summary type="html">Description This is a Legal pretrained pipeline, aimed to carry out Section Splitting by using the Headers and Subheaders entities, detected in the document. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU legal_pipeline = nlp.PretrainedPipeline(&quot;legpipe_header_subheader&quot;, &quot;en&quot;, &quot;legal/models&quot;) text = [&quot;&quot;&quot;2. DEFINITION. For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1 and 2 Appointment as Reseller. 2.1 Appointment. The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6 2.2 Customer Agreements.&quot;&quot;&quot;] result = legal_pipeline.annotate(text) Results | chunks | begin | end | entities | |------------------------:|------:|----:|----------:| | 2. DEFINITION | 0 | 12 | HEADER | | 2.1 Appointment | 154 | 168 | SUBHEADER | | 2.2 Customer Agreements | 530 | 552 | SUBHEADER | Model Information Model Name: legpipe_header_subheader Type: pipeline Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 23.6 KB Included Models DocumentAssembler TokenizerModel ContextualParserModel ContextualParserModel ChunkMergeModel</summary></entry><entry><title type="html">Company Name Normalization using Nasdaq Stock Screener</title><link href="/2023/01/20/finel_nasdaq_company_name_stock_screener_en.html" rel="alternate" type="text/html" title="Company Name Normalization using Nasdaq Stock Screener" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/finel_nasdaq_company_name_stock_screener_en</id><content type="html" xml:base="/2023/01/20/finel_nasdaq_company_name_stock_screener_en.html">## Description

This is a Financial Entity Resolver model, trained to obtain normalized versions of Company Names, registered in NASDAQ Stock Screener. You can use this model after extracting a company name using any NER, and you will obtain the official name of the company as per NASDAQ Stock Screener.

After this, you can use `finmapper_nasdaq_company_name_stock_screener` to augment and obtain more information about a company using NASDAQ Stock Screener, including Ticker, Sector, Country, etc.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674233034536.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674233034536.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

chunkToDoc = nlp.Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;)

chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \
    .setInputCols(&quot;ner_chunk_doc&quot;) \
    .setOutputCol(&quot;sentence_embeddings&quot;)

use_er_model = finance.SentenceEntityResolverModel.pretrained(&quot;finel_nasdaq_company_name_stock_screener&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;normalized&quot;)\
    .setDistanceFunction(&quot;EUCLIDEAN&quot;)

nlpPipeline = nlp.Pipeline(stages=[
     documentAssembler,
     tokenizer,
     embeddings,
     ner_model,
     ner_converter,
     chunkToDoc,
     chunk_embeddings,
     use_er_model
])

text = &quot;&quot;&quot;NIKE is an American multinational corporation that is engaged in the design, development, manufacturing, and worldwide marketing and sales of footwear, apparel, equipment, accessories, and services.&quot;&quot;&quot;

test_data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(test_data)

lp = nlp.LightPipeline(model)

result = lp.annotate(text)

result[&quot;normalized&quot;]
```

&lt;/div&gt;

## Results

```bash
['Nike Inc. Common Stock']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_nasdaq_company_name_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[normalized]|
|Language:|en|
|Size:|54.7 MB|
|Case sensitive:|false|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="licensed" /><category term="nasdaq" /><category term="company" /><summary type="html">Description This is a Financial Entity Resolver model, trained to obtain normalized versions of Company Names, registered in NASDAQ Stock Screener. You can use this model after extracting a company name using any NER, and you will obtain the official name of the company as per NASDAQ Stock Screener. After this, you can use finmapper_nasdaq_company_name_stock_screener to augment and obtain more information about a company using NASDAQ Stock Screener, including Ticker, Sector, Country, etc. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) chunkToDoc = nlp.Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \ .setInputCols(&quot;ner_chunk_doc&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) use_er_model = finance.SentenceEntityResolverModel.pretrained(&quot;finel_nasdaq_company_name_stock_screener&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;normalized&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, tokenizer, embeddings, ner_model, ner_converter, chunkToDoc, chunk_embeddings, use_er_model ]) text = &quot;&quot;&quot;NIKE is an American multinational corporation that is engaged in the design, development, manufacturing, and worldwide marketing and sales of footwear, apparel, equipment, accessories, and services.&quot;&quot;&quot; test_data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(test_data) lp = nlp.LightPipeline(model) result = lp.annotate(text) result[&quot;normalized&quot;] Results ['Nike Inc. Common Stock'] Model Information Model Name: finel_nasdaq_company_name_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [normalized] Language: en Size: 54.7 MB Case sensitive: false References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Resolver Company Names to Tickers using Nasdaq Stock Screener</title><link href="/2023/01/20/finel_nasdaq_ticker_stock_screener_en.html" rel="alternate" type="text/html" title="Resolver Company Names to Tickers using Nasdaq Stock Screener" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/finel_nasdaq_ticker_stock_screener_en</id><content type="html" xml:base="/2023/01/20/finel_nasdaq_ticker_stock_screener_en.html">## Description

This is an Entity Resolution / Entity Linking model, which is able to provide Ticker / Trading Symbols using a Company Name as an input. You can use any NER which extracts Organizations / Companies / Parties to then send the input to `finel_nasdaq_company_name_stock_screener` model to get normalized company name. Finally, this Entity Linking model get the Ticker / Trading Symbol (given the company has one).

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674236954508.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674236954508.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)

ner_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

chunkToDoc = nlp.Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;) 

ticker_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\
    .setInputCols(&quot;ner_chunk_doc&quot;)\
    .setOutputCol(&quot;ticker_embeddings&quot;)

er_ticker_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_ticker_stock_screener', 'en', 'finance/model')\
    .setInputCols([&quot;ticker_embeddings&quot;])\
    .setOutputCol(&quot;ticker&quot;)\
    .setAuxLabelCol(&quot;company_name&quot;)

pipeline = nlp.Pipeline().setStages([document_assembler,
                              tokenizer, 
                              ner_embeddings,
                              ner_model, 
                              ner_converter,
                              chunkToDoc,
                              ticker_embeddings,
                              er_ticker_model])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = pipeline.fit(empty_data)

lp = nlp.LightPipeline(model)

text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot;

result = lp.annotate(text)

result[&quot;ticker&quot;]
```

&lt;/div&gt;

## Results

```bash
['NKE']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_nasdaq_ticker_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[normalized]|
|Language:|en|
|Size:|54.6 MB|
|Case sensitive:|false|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="finance" /><category term="nasdaq" /><category term="ticker" /><summary type="html">Description This is an Entity Resolution / Entity Linking model, which is able to provide Ticker / Trading Symbols using a Company Name as an input. You can use any NER which extracts Organizations / Companies / Parties to then send the input to finel_nasdaq_company_name_stock_screener model to get normalized company name. Finally, this Entity Linking model get the Ticker / Trading Symbol (given the company has one). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) ner_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) chunkToDoc = nlp.Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) ticker_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\ .setInputCols(&quot;ner_chunk_doc&quot;)\ .setOutputCol(&quot;ticker_embeddings&quot;) er_ticker_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_ticker_stock_screener', 'en', 'finance/model')\ .setInputCols([&quot;ticker_embeddings&quot;])\ .setOutputCol(&quot;ticker&quot;)\ .setAuxLabelCol(&quot;company_name&quot;) pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, ner_embeddings, ner_model, ner_converter, chunkToDoc, ticker_embeddings, er_ticker_model]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) lp = nlp.LightPipeline(model) text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot; result = lp.annotate(text) result[&quot;ticker&quot;] Results ['NKE'] Model Information Model Name: finel_nasdaq_ticker_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [normalized] Language: en Size: 54.6 MB Case sensitive: false References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Mapping Companies to NASDAQ Stock Screener by Company Name</title><link href="/2023/01/19/finmapper_nasdaq_company_name_stock_screener_en.html" rel="alternate" type="text/html" title="Mapping Companies to NASDAQ Stock Screener by Company Name" /><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>/2023/01/19/finmapper_nasdaq_company_name_stock_screener_en</id><content type="html" xml:base="/2023/01/19/finmapper_nasdaq_company_name_stock_screener_en.html">## Description

This model allows you to, given an extracted name of a company, get following information about that company from Nasdaq Stock Screener:

  - Country
  - IPO_Year
  - Industry
  - Last_Sale
  - Market_Cap
  - Name
  - Net_Change
  - Percent_Change
  - Sector
  - Ticker
  - Volume

It can be optionally combined with Entity Resolution to normalize first the name of the company.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674161310624.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674161310624.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

# Optional: To normalize the ORG name using NASDAQ data before the mapping
##########################################################################
chunkToDoc = nlp.Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;)

chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\
    .setInputCols([&quot;ner_chunk_doc&quot;])\
    .setOutputCol(&quot;chunk_embeddings&quot;)

use_er_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_company_name_stock_screener', 'en', 'finance/models')\
    .setInputCols(&quot;chunk_embeddings&quot;)\
    .setOutputCol('normalized')\
    .setDistanceFunction(&quot;EUCLIDEAN&quot;)  
##########################################################################

CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_company_name_stock_screener', 'en', 'finance/models')\
    .setInputCols([&quot;normalized&quot;])\
    .setOutputCol(&quot;mappings&quot;)

pipeline = nlp.Pipeline().setStages([document_assembler,
                                 tokenizer, 
                                 embeddings,
                                 ner_model, 
                                 ner_converter,
                                 chunkToDoc, # Optional for normalization
                                 chunk_embeddings, # Optional for normalization
                                 use_er_model, # Optional for normalization
                                 CM])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = pipeline.fit(empty_data)

lp = nlp.LightPipeline(model)

text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot;

result = lp.fullAnnotate(text)
```

&lt;/div&gt;

## Results

```bash
&quot;Country&quot;: &quot;United States&quot;,
&quot;IPO_Year&quot;: &quot;0&quot;,
&quot;Industry&quot;: &quot;Shoe Manufacturing&quot;,
&quot;Last_Sale&quot;: &quot;$128.85&quot;,
&quot;Market_Cap&quot;: &quot;1.9979004036E11&quot;,
&quot;Name&quot;: &quot;Nike Inc. Common Stock&quot;,
&quot;Net_Change&quot;: &quot;0.96&quot;,
&quot;Percent_Change&quot;: &quot;0.751%&quot;,
&quot;Sector&quot;: &quot;Consumer Discretionary&quot;,
&quot;Symbol&quot;: &quot;NKE&quot;,
&quot;Volume&quot;: &quot;4854668&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finmapper_nasdaq_company_name_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[ner_chunk]|
|Output Labels:|[mappings]|
|Language:|en|
|Size:|599.1 KB|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="licensed" /><category term="nasdaq" /><category term="company" /><summary type="html">Description This model allows you to, given an extracted name of a company, get following information about that company from Nasdaq Stock Screener: Country IPO_Year Industry Last_Sale Market_Cap Name Net_Change Percent_Change Sector Ticker Volume It can be optionally combined with Entity Resolution to normalize first the name of the company. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) # Optional: To normalize the ORG name using NASDAQ data before the mapping ########################################################################## chunkToDoc = nlp.Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\ .setInputCols([&quot;ner_chunk_doc&quot;])\ .setOutputCol(&quot;chunk_embeddings&quot;) use_er_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_company_name_stock_screener', 'en', 'finance/models')\ .setInputCols(&quot;chunk_embeddings&quot;)\ .setOutputCol('normalized')\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) ########################################################################## CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_company_name_stock_screener', 'en', 'finance/models')\ .setInputCols([&quot;normalized&quot;])\ .setOutputCol(&quot;mappings&quot;) pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, embeddings, ner_model, ner_converter, chunkToDoc, # Optional for normalization chunk_embeddings, # Optional for normalization use_er_model, # Optional for normalization CM]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) lp = nlp.LightPipeline(model) text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot; result = lp.fullAnnotate(text) Results &quot;Country&quot;: &quot;United States&quot;, &quot;IPO_Year&quot;: &quot;0&quot;, &quot;Industry&quot;: &quot;Shoe Manufacturing&quot;, &quot;Last_Sale&quot;: &quot;$128.85&quot;, &quot;Market_Cap&quot;: &quot;1.9979004036E11&quot;, &quot;Name&quot;: &quot;Nike Inc. Common Stock&quot;, &quot;Net_Change&quot;: &quot;0.96&quot;, &quot;Percent_Change&quot;: &quot;0.751%&quot;, &quot;Sector&quot;: &quot;Consumer Discretionary&quot;, &quot;Symbol&quot;: &quot;NKE&quot;, &quot;Volume&quot;: &quot;4854668&quot; Model Information Model Name: finmapper_nasdaq_company_name_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [ner_chunk] Output Labels: [mappings] Language: en Size: 599.1 KB References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Mapping Companies to NASDAQ Stock Screener by Ticker</title><link href="/2023/01/19/finmapper_nasdaq_ticker_stock_screener_en.html" rel="alternate" type="text/html" title="Mapping Companies to NASDAQ Stock Screener by Ticker" /><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>/2023/01/19/finmapper_nasdaq_ticker_stock_screener_en</id><content type="html" xml:base="/2023/01/19/finmapper_nasdaq_ticker_stock_screener_en.html">## Description

This model allows you to, given a Ticker, get the following information about a company at Nasdaq Stock Screener:

 - Country
 - IPO_Year
 - Industry
 - Last_Sale
 - Market_Cap
 - Name
 - Net_Change
 - Percent_Change
 - Sector
 - Ticker
 - Volume

Firstly, you should get the TICKER symbol from the finance text with the `finner_ticker` model, then you can get detailed information about the company with the ChunkMapper model.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674157233652.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674157233652.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained(&quot;finner_ticker&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_ticker_stock_screener', 'en', 'finance/models')\
    .setInputCols([&quot;ner_chunk&quot;])\
    .setOutputCol(&quot;mappings&quot;)

pipeline = nlp.Pipeline().setStages([document_assembler,
                                 tokenizer, 
                                 embeddings,
                                 ner_model, 
                                 ner_converter, 
                                 CM])
                                 
text = [&quot;&quot;&quot;There are some serious purchases and sales of AMZN stock today.&quot;&quot;&quot;]

test_data = spark.createDataFrame([text]).toDF(&quot;text&quot;)

model = pipeline.fit(test_data)

result = model.transform(test_data).select('mappings').collect()
```

&lt;/div&gt;

## Results

```bash
&quot;Country&quot;: &quot;United States&quot;,
&quot;IPO_Year&quot;: &quot;1997&quot;,
&quot;Industry&quot;: &quot;Catalog/Specialty Distribution&quot;,
&quot;Last_Sale&quot;: &quot;$98.12&quot;,
&quot;Market_Cap&quot;: &quot;9.98556270184E11&quot;,
&quot;Name&quot;: &quot;Amazon.com Inc. Common Stock&quot;,
&quot;Net_Change&quot;: &quot;2.85&quot;,
&quot;Percent_Change&quot;: &quot;2.991%&quot;,
&quot;Sector&quot;: &quot;Consumer Discretionary&quot;,
&quot;Ticker&quot;: &quot;AMZN&quot;,
&quot;Volume&quot;: &quot;85412563&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finmapper_nasdaq_ticker_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[ner_chunk]|
|Output Labels:|[mappings]|
|Language:|en|
|Size:|584.5 KB|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="licensed" /><category term="nasdaq" /><category term="ticker" /><summary type="html">Description This model allows you to, given a Ticker, get the following information about a company at Nasdaq Stock Screener: Country IPO_Year Industry Last_Sale Market_Cap Name Net_Change Percent_Change Sector Ticker Volume Firstly, you should get the TICKER symbol from the finance text with the finner_ticker model, then you can get detailed information about the company with the ChunkMapper model. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_ticker&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_ticker_stock_screener', 'en', 'finance/models')\ .setInputCols([&quot;ner_chunk&quot;])\ .setOutputCol(&quot;mappings&quot;) pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, embeddings, ner_model, ner_converter, CM]) text = [&quot;&quot;&quot;There are some serious purchases and sales of AMZN stock today.&quot;&quot;&quot;] test_data = spark.createDataFrame([text]).toDF(&quot;text&quot;) model = pipeline.fit(test_data) result = model.transform(test_data).select('mappings').collect() Results &quot;Country&quot;: &quot;United States&quot;, &quot;IPO_Year&quot;: &quot;1997&quot;, &quot;Industry&quot;: &quot;Catalog/Specialty Distribution&quot;, &quot;Last_Sale&quot;: &quot;$98.12&quot;, &quot;Market_Cap&quot;: &quot;9.98556270184E11&quot;, &quot;Name&quot;: &quot;Amazon.com Inc. Common Stock&quot;, &quot;Net_Change&quot;: &quot;2.85&quot;, &quot;Percent_Change&quot;: &quot;2.991%&quot;, &quot;Sector&quot;: &quot;Consumer Discretionary&quot;, &quot;Ticker&quot;: &quot;AMZN&quot;, &quot;Volume&quot;: &quot;85412563&quot; Model Information Model Name: finmapper_nasdaq_ticker_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [ner_chunk] Output Labels: [mappings] Language: en Size: 584.5 KB References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Normalize Parent Companies Names using Wikidata</title><link href="/2023/01/18/finel_wiki_parentorgs_en.html" rel="alternate" type="text/html" title="Normalize Parent Companies Names using Wikidata" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/finel_wiki_parentorgs_en</id><content type="html" xml:base="/2023/01/18/finel_wiki_parentorgs_en.html">## Description

This is an Entity Resolution model, aimed to normalize a previously extracted ORG entity, using its reference name in WIkidata. This is useful to then use `finel_wiki_parentorgs` Chunk Mapping model and get information of the subsidiaries, countries, stock exchange, etc.

It also retrieves the TICKER, which can be retrieved from `aux_label` column in metadata.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_wiki_parentorgs_en_1.0.0_3.0_1674038525188.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
      .setInputCol(&quot;text&quot;)\
      .setOutputCol(&quot;ner_chunk&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \
      .setInputCols(&quot;ner_chunk&quot;) \
      .setOutputCol(&quot;sentence_embeddings&quot;)
    
resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
      .setInputCols([&quot;sentence_embeddings&quot;]) \
      .setOutputCol(&quot;normalized_name&quot;)\
      .setDistanceFunction(&quot;EUCLIDEAN&quot;)

pipelineModel = PipelineModel(
      stages = [
          documentAssembler,
          embeddings,
          resolver
      ])

lp = nlp.LightPipeline(pipelineModel)
test_pred = lp.fullAnnotate('ALPHABET')
print(test_pred[0]['normalized_name'][0].result)
print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0])
```

&lt;/div&gt;

## Results

```bash
Alphabet Inc.
Aux data: GOOGL
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_wiki_parentorgs|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[original_company_name]|
|Language:|en|
|Size:|2.8 MB|
|Case sensitive:|false|

## References

Wikidata dump about company holdings using SparQL</content><author><name>John Snow Labs</name></author><category term="parent" /><category term="wikipedia" /><category term="wikidata" /><category term="en" /><category term="licensed" /><summary type="html">Description This is an Entity Resolution model, aimed to normalize a previously extracted ORG entity, using its reference name in WIkidata. This is useful to then use finel_wiki_parentorgs Chunk Mapping model and get information of the subsidiaries, countries, stock exchange, etc. It also retrieves the TICKER, which can be retrieved from aux_label column in metadata. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;ner_chunk&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \ .setInputCols(&quot;ner_chunk&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;]) \ .setOutputCol(&quot;normalized_name&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, embeddings, resolver ]) lp = nlp.LightPipeline(pipelineModel) test_pred = lp.fullAnnotate('ALPHABET') print(test_pred[0]['normalized_name'][0].result) print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0]) Results Alphabet Inc. Aux data: GOOGL Model Information Model Name: finel_wiki_parentorgs Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [original_company_name] Language: en Size: 2.8 MB Case sensitive: false References Wikidata dump about company holdings using SparQL</summary></entry><entry><title type="html">Resolve Company Names to Tickers using Wikidata</title><link href="/2023/01/18/finel_wiki_parentorgs_ticker_en.html" rel="alternate" type="text/html" title="Resolve Company Names to Tickers using Wikidata" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/finel_wiki_parentorgs_ticker_en</id><content type="html" xml:base="/2023/01/18/finel_wiki_parentorgs_ticker_en.html">## Description

This model helps you retrieve the TICKER of a company using a previously detected ORG entity with NER.

It also retrieves the normalized company name as per Wikidata, which can be retrieved from `aux_label` column in metadata.


## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_wiki_parentorgs_ticker_en_1.0.0_3.0_1674038769879.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
      .setInputCol(&quot;text&quot;)\
      .setOutputCol(&quot;ner_chunk&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \
      .setInputCols(&quot;ner_chunk&quot;) \
      .setOutputCol(&quot;sentence_embeddings&quot;)
    
resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs_tickers&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
      .setInputCols([&quot;sentence_embeddings&quot;]) \
      .setOutputCol(&quot;normalized_name&quot;)\
      .setDistanceFunction(&quot;EUCLIDEAN&quot;)

pipelineModel = PipelineModel(
      stages = [
          documentAssembler,
          embeddings,
          resolver
      ])

lp = nlp.LightPipeline(pipelineModel)
test_pred = lp.fullAnnotate('Alphabet Incorporated')
print(test_pred[0]['normalized_name'][0].result)
print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0])
```

&lt;/div&gt;

## Results

```bash
GOOGL
Aux data: Alphabet Inc.
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_wiki_parentorgs_ticker|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[original_company_name]|
|Language:|en|
|Size:|2.8 MB|
|Case sensitive:|false|

## References

Wikipedia dump about company subsidiaries</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><summary type="html">Description This model helps you retrieve the TICKER of a company using a previously detected ORG entity with NER. It also retrieves the normalized company name as per Wikidata, which can be retrieved from aux_label column in metadata. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;ner_chunk&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \ .setInputCols(&quot;ner_chunk&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs_tickers&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;]) \ .setOutputCol(&quot;normalized_name&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, embeddings, resolver ]) lp = nlp.LightPipeline(pipelineModel) test_pred = lp.fullAnnotate('Alphabet Incorporated') print(test_pred[0]['normalized_name'][0].result) print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0]) Results GOOGL Aux data: Alphabet Inc. Model Information Model Name: finel_wiki_parentorgs_ticker Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [original_company_name] Language: en Size: 2.8 MB Case sensitive: false References Wikipedia dump about company subsidiaries</summary></entry><entry><title type="html">Dispute Clause Binary Classifier</title><link href="/2023/01/18/legclf_dispute_clauses_cuad_en.html" rel="alternate" type="text/html" title="Dispute Clause Binary Classifier" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/legclf_dispute_clauses_cuad_en</id><content type="html" xml:base="/2023/01/18/legclf_dispute_clauses_cuad_en.html">## Description

This model is a Binary Classifier (True, False) for the `dispute_clause` clause type. To use this model, make sure you provide enough context as an input.

Senteces have been used as positive examples, so better results will be achieved if SetenceDetector is added to the pipeline.

If you have big legal documents, and you want to look for clauses, we recommend you to split the documents using any of the techniques available in our Spark NLP for Legal Workshop Tokenization &amp; Splitting Tutorial.

Take into consideration the embeddings of this model allows up to 512 tokens. If you have more than that, consider splitting in smaller pieces (you can also check the same tutorial link provided above).

This model can be combined with any of the other 300+ Legal Clauses Classifiers you will find in Models Hub, getting as an output a series of True/False values for each of the legal clause model you have added.

## Predicted Entities

`dispute_clause`, `other`

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/finance/CLASSIFY_LEGAL_CLAUSES/){:.button.button-orange}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_dispute_clauses_cuad_en_1.0.0_3.0_1674056674986.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;) \
      .setInputCols(&quot;document&quot;) \
      .setOutputCol(&quot;sentence_embeddings&quot;)

docClassifier = legal.ClassifierDLModel() \
    .pretrained(&quot;legclf_dispute_clauses_cuad&quot;,&quot;en&quot;,&quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;is_dispute_clause&quot;)

pipeline = nlp.Pipeline() \
    .setStages(
      [
        documentAssembler,
        embeddings,
        docClassifier
      ]
    )

fit_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF('text'))
lm = nlp.LightPipeline(fit_model)

pos_example = &quot;24.2 The parties irrevocably agree that the courts of Ohio shall have non-exclusive jurisdiction to settle any dispute or claim that arises out of or in connection with this agreement or its subject matter or formation ( including non - contractual disputes or claims ).&quot;

neg_example = &quot;Brokersâ€™ &lt;strong&gt;Fees and Expenses&lt;/strong&gt; Except as expressly set forth in the Transaction Documents to the contrary, each party shall pay the fees and expenses of its advisers, counsel, accountants and other experts, if any, and all other expenses incurred by such party incident to the negotiation, preparation, execution, delivery and performance of this Agreement. The Company shall pay all transfer agent fees, stamp taxes and other taxes and duties levied in connection with the delivery of any Warrant Shares to the Purchasers. Steel Pier Capital Advisors, LLC shall be reimbursed its expenses in having the Transaction Documents prepared on behalf of the Company and for its obligations under the Security Agreement in an amount not to exceed $25,000.00.&quot;

texts = [
    pos_example,
    neg_example
]

res = lm.annotate(texts)
```

&lt;/div&gt;

## Results

```bash
['dispute_clause']
['other']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_dispute_clauses_cuad|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[label]|
|Language:|en|
|Size:|22.9 MB|

## References

Manual annotations of CUAD dataset

## Benchmarking

```bash
label precision    recall  f1-score   support
dispute_clause       1.00      1.00      1.00        61
         other       1.00      1.00      1.00        96
      accuracy         -         -         1.00       157
     macro-avg       1.00      1.00      1.00       157
  weighted-avg       1.00      1.00      1.00       157
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This model is a Binary Classifier (True, False) for the dispute_clause clause type. To use this model, make sure you provide enough context as an input. Senteces have been used as positive examples, so better results will be achieved if SetenceDetector is added to the pipeline. If you have big legal documents, and you want to look for clauses, we recommend you to split the documents using any of the techniques available in our Spark NLP for Legal Workshop Tokenization &amp;amp; Splitting Tutorial. Take into consideration the embeddings of this model allows up to 512 tokens. If you have more than that, consider splitting in smaller pieces (you can also check the same tutorial link provided above). This model can be combined with any of the other 300+ Legal Clauses Classifiers you will find in Models Hub, getting as an output a series of True/False values for each of the legal clause model you have added. Predicted Entities dispute_clause, other Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;) \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = legal.ClassifierDLModel() \ .pretrained(&quot;legclf_dispute_clauses_cuad&quot;,&quot;en&quot;,&quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;is_dispute_clause&quot;) pipeline = nlp.Pipeline() \ .setStages( [ documentAssembler, embeddings, docClassifier ] ) fit_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF('text')) lm = nlp.LightPipeline(fit_model) pos_example = &quot;24.2 The parties irrevocably agree that the courts of Ohio shall have non-exclusive jurisdiction to settle any dispute or claim that arises out of or in connection with this agreement or its subject matter or formation ( including non - contractual disputes or claims ).&quot; neg_example = &quot;Brokersâ€™ &amp;lt;strong&amp;gt;Fees and Expenses&amp;lt;/strong&amp;gt; Except as expressly set forth in the Transaction Documents to the contrary, each party shall pay the fees and expenses of its advisers, counsel, accountants and other experts, if any, and all other expenses incurred by such party incident to the negotiation, preparation, execution, delivery and performance of this Agreement. The Company shall pay all transfer agent fees, stamp taxes and other taxes and duties levied in connection with the delivery of any Warrant Shares to the Purchasers. Steel Pier Capital Advisors, LLC shall be reimbursed its expenses in having the Transaction Documents prepared on behalf of the Company and for its obligations under the Security Agreement in an amount not to exceed $25,000.00.&quot; texts = [ pos_example, neg_example ] res = lm.annotate(texts) Results ['dispute_clause'] ['other'] Model Information Model Name: legclf_dispute_clauses_cuad Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [label] Language: en Size: 22.9 MB References Manual annotations of CUAD dataset Benchmarking label precision recall f1-score support dispute_clause 1.00 1.00 1.00 61 other 1.00 1.00 1.00 96 accuracy - - 1.00 157 macro-avg 1.00 1.00 1.00 157 weighted-avg 1.00 1.00 1.00 157</summary></entry></feed>