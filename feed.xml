<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-01-20T21:47:29+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Finance Pipeline (Headers / Subheaders)</title><link href="/2023/01/20/finpipe_header_subheader_en.html" rel="alternate" type="text/html" title="Finance Pipeline (Headers / Subheaders)" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/finpipe_header_subheader_en</id><content type="html" xml:base="/2023/01/20/finpipe_header_subheader_en.html">## Description

This is a finance pretrained pipeline that will help you split long financial documents into smaller sections. To do that, it detects Headers and Subheaders of different sections. You can then use the beginning and end information in the metadata to retrieve the text between those headers.

PART I, PART II, etc are HEADERS
Item 1, Item 2, etc are also HEADERS
Item 1A, 2B, etc are SUBHEADERS
1., 2., 2.1, etc. are SUBHEADERS

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finpipe_header_subheader_en_1.0.0_3.0_1674243435691.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finpipe_header_subheader_en_1.0.0_3.0_1674243435691.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
finance_pipeline = nlp.PretrainedPipeline(&quot;finpipe_header_subheader&quot;, &quot;en&quot;, &quot;finance/models&quot;)

text = [&quot;&quot;&quot;
Item 2. Definitions. 
For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1. 2. Appointment as Reseller.

Item 2A. Appointment. 
The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6

Item 2B. Customer Agreements.&quot;&quot;&quot;]

result = finance_pipeline.annotate(text)
```

&lt;/div&gt;

## Results

```bash
|                        chunks | begin | end |  entities |
|------------------------------:|------:|----:|----------:|
|          Item 2. Definitions. |     1 |  21 |    HEADER |
|         Item 2A. Appointment. |   158 | 179 | SUBHEADER |
| Item 2B. Customer Agreements. |   538 | 566 | SUBHEADER |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finpipe_header_subheader|
|Type:|pipeline|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|23.6 KB|

## Included Models

- DocumentAssembler
- TokenizerModel
- ContextualParserModel
- ContextualParserModel
- ChunkMergeModel</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="ner" /><category term="licensed" /><category term="contextual_parser" /><summary type="html">Description This is a finance pretrained pipeline that will help you split long financial documents into smaller sections. To do that, it detects Headers and Subheaders of different sections. You can then use the beginning and end information in the metadata to retrieve the text between those headers. PART I, PART II, etc are HEADERS Item 1, Item 2, etc are also HEADERS Item 1A, 2B, etc are SUBHEADERS 1., 2., 2.1, etc. are SUBHEADERS Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU finance_pipeline = nlp.PretrainedPipeline(&quot;finpipe_header_subheader&quot;, &quot;en&quot;, &quot;finance/models&quot;) text = [&quot;&quot;&quot; Item 2. Definitions. For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1. 2. Appointment as Reseller. Item 2A. Appointment. The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6 Item 2B. Customer Agreements.&quot;&quot;&quot;] result = finance_pipeline.annotate(text) Results | chunks | begin | end | entities | |------------------------------:|------:|----:|----------:| | Item 2. Definitions. | 1 | 21 | HEADER | | Item 2A. Appointment. | 158 | 179 | SUBHEADER | | Item 2B. Customer Agreements. | 538 | 566 | SUBHEADER | Model Information Model Name: finpipe_header_subheader Type: pipeline Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 23.6 KB Included Models DocumentAssembler TokenizerModel ContextualParserModel ContextualParserModel ChunkMergeModel</summary></entry><entry><title type="html">Legal Pipeline (Headers / Subheaders)</title><link href="/2023/01/20/legpipe_header_subheader_en.html" rel="alternate" type="text/html" title="Legal Pipeline (Headers / Subheaders)" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/legpipe_header_subheader_en</id><content type="html" xml:base="/2023/01/20/legpipe_header_subheader_en.html">## Description

This is a Legal pretrained pipeline, aimed to carry out Section Splitting by using the Headers and Subheaders entities, detected in the document.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legpipe_header_subheader_en_1.0.0_3.0_1674244247295.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/legal/models/legpipe_header_subheader_en_1.0.0_3.0_1674244247295.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
legal_pipeline = nlp.PretrainedPipeline(&quot;legpipe_header_subheader&quot;, &quot;en&quot;, &quot;legal/models&quot;)

text = [&quot;&quot;&quot;2. DEFINITION. 
For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1 and 2 Appointment as Reseller.
2.1 Appointment. 
The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6
2.2 Customer Agreements.&quot;&quot;&quot;]

result = legal_pipeline.annotate(text)
```

&lt;/div&gt;

## Results

```bash
|                  chunks | begin | end |  entities |
|------------------------:|------:|----:|----------:|
|           2. DEFINITION |     0 |  12 |    HEADER |
|         2.1 Appointment |   154 | 168 | SUBHEADER |
| 2.2 Customer Agreements |   530 | 552 | SUBHEADER |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legpipe_header_subheader|
|Type:|pipeline|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|23.6 KB|

## Included Models

- DocumentAssembler
- TokenizerModel
- ContextualParserModel
- ContextualParserModel
- ChunkMergeModel</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="legal" /><category term="ner" /><category term="contextual_parser" /><summary type="html">Description This is a Legal pretrained pipeline, aimed to carry out Section Splitting by using the Headers and Subheaders entities, detected in the document. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU legal_pipeline = nlp.PretrainedPipeline(&quot;legpipe_header_subheader&quot;, &quot;en&quot;, &quot;legal/models&quot;) text = [&quot;&quot;&quot;2. DEFINITION. For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1 and 2 Appointment as Reseller. 2.1 Appointment. The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6 2.2 Customer Agreements.&quot;&quot;&quot;] result = legal_pipeline.annotate(text) Results | chunks | begin | end | entities | |------------------------:|------:|----:|----------:| | 2. DEFINITION | 0 | 12 | HEADER | | 2.1 Appointment | 154 | 168 | SUBHEADER | | 2.2 Customer Agreements | 530 | 552 | SUBHEADER | Model Information Model Name: legpipe_header_subheader Type: pipeline Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Language: en Size: 23.6 KB Included Models DocumentAssembler TokenizerModel ContextualParserModel ContextualParserModel ChunkMergeModel</summary></entry><entry><title type="html">Company Name Normalization using Nasdaq Stock Screener</title><link href="/2023/01/20/finel_nasdaq_company_name_stock_screener_en.html" rel="alternate" type="text/html" title="Company Name Normalization using Nasdaq Stock Screener" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/finel_nasdaq_company_name_stock_screener_en</id><content type="html" xml:base="/2023/01/20/finel_nasdaq_company_name_stock_screener_en.html">## Description

This is a Financial Entity Resolver model, trained to obtain normalized versions of Company Names, registered in NASDAQ Stock Screener. You can use this model after extracting a company name using any NER, and you will obtain the official name of the company as per NASDAQ Stock Screener.

After this, you can use `finmapper_nasdaq_company_name_stock_screener` to augment and obtain more information about a company using NASDAQ Stock Screener, including Ticker, Sector, Country, etc.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674233034536.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674233034536.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

chunkToDoc = nlp.Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;)

chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \
    .setInputCols(&quot;ner_chunk_doc&quot;) \
    .setOutputCol(&quot;sentence_embeddings&quot;)

use_er_model = finance.SentenceEntityResolverModel.pretrained(&quot;finel_nasdaq_company_name_stock_screener&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;normalized&quot;)\
    .setDistanceFunction(&quot;EUCLIDEAN&quot;)

nlpPipeline = nlp.Pipeline(stages=[
     documentAssembler,
     tokenizer,
     embeddings,
     ner_model,
     ner_converter,
     chunkToDoc,
     chunk_embeddings,
     use_er_model
])

text = &quot;&quot;&quot;NIKE is an American multinational corporation that is engaged in the design, development, manufacturing, and worldwide marketing and sales of footwear, apparel, equipment, accessories, and services.&quot;&quot;&quot;

test_data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(test_data)

lp = nlp.LightPipeline(model)

result = lp.annotate(text)

result[&quot;normalized&quot;]
```

&lt;/div&gt;

## Results

```bash
['Nike Inc. Common Stock']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_nasdaq_company_name_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[normalized]|
|Language:|en|
|Size:|54.7 MB|
|Case sensitive:|false|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="licensed" /><category term="nasdaq" /><category term="company" /><summary type="html">Description This is a Financial Entity Resolver model, trained to obtain normalized versions of Company Names, registered in NASDAQ Stock Screener. You can use this model after extracting a company name using any NER, and you will obtain the official name of the company as per NASDAQ Stock Screener. After this, you can use finmapper_nasdaq_company_name_stock_screener to augment and obtain more information about a company using NASDAQ Stock Screener, including Ticker, Sector, Country, etc. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_orgs_prods_alias&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) chunkToDoc = nlp.Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \ .setInputCols(&quot;ner_chunk_doc&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) use_er_model = finance.SentenceEntityResolverModel.pretrained(&quot;finel_nasdaq_company_name_stock_screener&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;normalized&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, tokenizer, embeddings, ner_model, ner_converter, chunkToDoc, chunk_embeddings, use_er_model ]) text = &quot;&quot;&quot;NIKE is an American multinational corporation that is engaged in the design, development, manufacturing, and worldwide marketing and sales of footwear, apparel, equipment, accessories, and services.&quot;&quot;&quot; test_data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(test_data) lp = nlp.LightPipeline(model) result = lp.annotate(text) result[&quot;normalized&quot;] Results ['Nike Inc. Common Stock'] Model Information Model Name: finel_nasdaq_company_name_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [normalized] Language: en Size: 54.7 MB Case sensitive: false References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Resolver Company Names to Tickers using Nasdaq Stock Screener</title><link href="/2023/01/20/finel_nasdaq_ticker_stock_screener_en.html" rel="alternate" type="text/html" title="Resolver Company Names to Tickers using Nasdaq Stock Screener" /><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>/2023/01/20/finel_nasdaq_ticker_stock_screener_en</id><content type="html" xml:base="/2023/01/20/finel_nasdaq_ticker_stock_screener_en.html">## Description

This is an Entity Resolution / Entity Linking model, which is able to provide Ticker / Trading Symbols using a Company Name as an input. You can use any NER which extracts Organizations / Companies / Parties to then send the input to `finel_nasdaq_company_name_stock_screener` model to get normalized company name. Finally, this Entity Linking model get the Ticker / Trading Symbol (given the company has one).

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674236954508.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finel_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674236954508.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)

ner_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

chunkToDoc = nlp.Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;) 

ticker_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\
    .setInputCols(&quot;ner_chunk_doc&quot;)\
    .setOutputCol(&quot;ticker_embeddings&quot;)

er_ticker_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_ticker_stock_screener', 'en', 'finance/model')\
    .setInputCols([&quot;ticker_embeddings&quot;])\
    .setOutputCol(&quot;ticker&quot;)\
    .setAuxLabelCol(&quot;company_name&quot;)

pipeline = nlp.Pipeline().setStages([document_assembler,
                              tokenizer, 
                              ner_embeddings,
                              ner_model, 
                              ner_converter,
                              chunkToDoc,
                              ticker_embeddings,
                              er_ticker_model])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = pipeline.fit(empty_data)

lp = nlp.LightPipeline(model)

text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot;

result = lp.annotate(text)

result[&quot;ticker&quot;]
```

&lt;/div&gt;

## Results

```bash
['NKE']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_nasdaq_ticker_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[normalized]|
|Language:|en|
|Size:|54.6 MB|
|Case sensitive:|false|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="finance" /><category term="nasdaq" /><category term="ticker" /><summary type="html">Description This is an Entity Resolution / Entity Linking model, which is able to provide Ticker / Trading Symbols using a Company Name as an input. You can use any NER which extracts Organizations / Companies / Parties to then send the input to finel_nasdaq_company_name_stock_screener model to get normalized company name. Finally, this Entity Linking model get the Ticker / Trading Symbol (given the company has one). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) ner_embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) chunkToDoc = nlp.Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) ticker_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\ .setInputCols(&quot;ner_chunk_doc&quot;)\ .setOutputCol(&quot;ticker_embeddings&quot;) er_ticker_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_ticker_stock_screener', 'en', 'finance/model')\ .setInputCols([&quot;ticker_embeddings&quot;])\ .setOutputCol(&quot;ticker&quot;)\ .setAuxLabelCol(&quot;company_name&quot;) pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, ner_embeddings, ner_model, ner_converter, chunkToDoc, ticker_embeddings, er_ticker_model]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) lp = nlp.LightPipeline(model) text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot; result = lp.annotate(text) result[&quot;ticker&quot;] Results ['NKE'] Model Information Model Name: finel_nasdaq_ticker_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [normalized] Language: en Size: 54.6 MB Case sensitive: false References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Mapping Companies to NASDAQ Stock Screener by Company Name</title><link href="/2023/01/19/finmapper_nasdaq_company_name_stock_screener_en.html" rel="alternate" type="text/html" title="Mapping Companies to NASDAQ Stock Screener by Company Name" /><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>/2023/01/19/finmapper_nasdaq_company_name_stock_screener_en</id><content type="html" xml:base="/2023/01/19/finmapper_nasdaq_company_name_stock_screener_en.html">## Description

This model allows you to, given an extracted name of a company, get following information about that company from Nasdaq Stock Screener:

  - Country
  - IPO_Year
  - Industry
  - Last_Sale
  - Market_Cap
  - Name
  - Net_Change
  - Percent_Change
  - Sector
  - Ticker
  - Volume

It can be optionally combined with Entity Resolution to normalize first the name of the company.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674161310624.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_company_name_stock_screener_en_1.0.0_3.0_1674161310624.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

# Optional: To normalize the ORG name using NASDAQ data before the mapping
##########################################################################
chunkToDoc = nlp.Chunk2Doc()\
    .setInputCols(&quot;ner_chunk&quot;)\
    .setOutputCol(&quot;ner_chunk_doc&quot;)

chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\
    .setInputCols([&quot;ner_chunk_doc&quot;])\
    .setOutputCol(&quot;chunk_embeddings&quot;)

use_er_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_company_name_stock_screener', 'en', 'finance/models')\
    .setInputCols(&quot;chunk_embeddings&quot;)\
    .setOutputCol('normalized')\
    .setDistanceFunction(&quot;EUCLIDEAN&quot;)  
##########################################################################

CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_company_name_stock_screener', 'en', 'finance/models')\
    .setInputCols([&quot;normalized&quot;])\
    .setOutputCol(&quot;mappings&quot;)

pipeline = nlp.Pipeline().setStages([document_assembler,
                                 tokenizer, 
                                 embeddings,
                                 ner_model, 
                                 ner_converter,
                                 chunkToDoc, # Optional for normalization
                                 chunk_embeddings, # Optional for normalization
                                 use_er_model, # Optional for normalization
                                 CM])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = pipeline.fit(empty_data)

lp = nlp.LightPipeline(model)

text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot;

result = lp.fullAnnotate(text)
```

&lt;/div&gt;

## Results

```bash
&quot;Country&quot;: &quot;United States&quot;,
&quot;IPO_Year&quot;: &quot;0&quot;,
&quot;Industry&quot;: &quot;Shoe Manufacturing&quot;,
&quot;Last_Sale&quot;: &quot;$128.85&quot;,
&quot;Market_Cap&quot;: &quot;1.9979004036E11&quot;,
&quot;Name&quot;: &quot;Nike Inc. Common Stock&quot;,
&quot;Net_Change&quot;: &quot;0.96&quot;,
&quot;Percent_Change&quot;: &quot;0.751%&quot;,
&quot;Sector&quot;: &quot;Consumer Discretionary&quot;,
&quot;Symbol&quot;: &quot;NKE&quot;,
&quot;Volume&quot;: &quot;4854668&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finmapper_nasdaq_company_name_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[ner_chunk]|
|Output Labels:|[mappings]|
|Language:|en|
|Size:|599.1 KB|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="licensed" /><category term="nasdaq" /><category term="company" /><summary type="html">Description This model allows you to, given an extracted name of a company, get following information about that company from Nasdaq Stock Screener: Country IPO_Year Industry Last_Sale Market_Cap Name Net_Change Percent_Change Sector Ticker Volume It can be optionally combined with Entity Resolution to normalize first the name of the company. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained('finner_orgs_prods_alias', 'en', 'finance/models')\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) # Optional: To normalize the ORG name using NASDAQ data before the mapping ########################################################################## chunkToDoc = nlp.Chunk2Doc()\ .setInputCols(&quot;ner_chunk&quot;)\ .setOutputCol(&quot;ner_chunk_doc&quot;) chunk_embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;)\ .setInputCols([&quot;ner_chunk_doc&quot;])\ .setOutputCol(&quot;chunk_embeddings&quot;) use_er_model = finance.SentenceEntityResolverModel.pretrained('finel_nasdaq_company_name_stock_screener', 'en', 'finance/models')\ .setInputCols(&quot;chunk_embeddings&quot;)\ .setOutputCol('normalized')\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) ########################################################################## CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_company_name_stock_screener', 'en', 'finance/models')\ .setInputCols([&quot;normalized&quot;])\ .setOutputCol(&quot;mappings&quot;) pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, embeddings, ner_model, ner_converter, chunkToDoc, # Optional for normalization chunk_embeddings, # Optional for normalization use_er_model, # Optional for normalization CM]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = pipeline.fit(empty_data) lp = nlp.LightPipeline(model) text = &quot;&quot;&quot;Nike is an American multinational association that is involved in the design, development, manufacturing and worldwide marketing and sales of apparel, footwear, accessories, equipment and services.&quot;&quot;&quot; result = lp.fullAnnotate(text) Results &quot;Country&quot;: &quot;United States&quot;, &quot;IPO_Year&quot;: &quot;0&quot;, &quot;Industry&quot;: &quot;Shoe Manufacturing&quot;, &quot;Last_Sale&quot;: &quot;$128.85&quot;, &quot;Market_Cap&quot;: &quot;1.9979004036E11&quot;, &quot;Name&quot;: &quot;Nike Inc. Common Stock&quot;, &quot;Net_Change&quot;: &quot;0.96&quot;, &quot;Percent_Change&quot;: &quot;0.751%&quot;, &quot;Sector&quot;: &quot;Consumer Discretionary&quot;, &quot;Symbol&quot;: &quot;NKE&quot;, &quot;Volume&quot;: &quot;4854668&quot; Model Information Model Name: finmapper_nasdaq_company_name_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [ner_chunk] Output Labels: [mappings] Language: en Size: 599.1 KB References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Mapping Companies to NASDAQ Stock Screener by Ticker</title><link href="/2023/01/19/finmapper_nasdaq_ticker_stock_screener_en.html" rel="alternate" type="text/html" title="Mapping Companies to NASDAQ Stock Screener by Ticker" /><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>/2023/01/19/finmapper_nasdaq_ticker_stock_screener_en</id><content type="html" xml:base="/2023/01/19/finmapper_nasdaq_ticker_stock_screener_en.html">## Description

This model allows you to, given a Ticker, get the following information about a company at Nasdaq Stock Screener:

 - Country
 - IPO_Year
 - Industry
 - Last_Sale
 - Market_Cap
 - Name
 - Net_Change
 - Percent_Change
 - Sector
 - Ticker
 - Volume

Firstly, you should get the TICKER symbol from the finance text with the `finner_ticker` model, then you can get detailed information about the company with the ChunkMapper model.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674157233652.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/finance/models/finmapper_nasdaq_ticker_stock_screener_en_1.0.0_3.0_1674157233652.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol('text')\
    .setOutputCol('document')

tokenizer = nlp.Tokenizer()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;document&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = finance.NerModel.pretrained(&quot;finner_ticker&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
    .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)

CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_ticker_stock_screener', 'en', 'finance/models')\
    .setInputCols([&quot;ner_chunk&quot;])\
    .setOutputCol(&quot;mappings&quot;)

pipeline = nlp.Pipeline().setStages([document_assembler,
                                 tokenizer, 
                                 embeddings,
                                 ner_model, 
                                 ner_converter, 
                                 CM])
                                 
text = [&quot;&quot;&quot;There are some serious purchases and sales of AMZN stock today.&quot;&quot;&quot;]

test_data = spark.createDataFrame([text]).toDF(&quot;text&quot;)

model = pipeline.fit(test_data)

result = model.transform(test_data).select('mappings').collect()
```

&lt;/div&gt;

## Results

```bash
&quot;Country&quot;: &quot;United States&quot;,
&quot;IPO_Year&quot;: &quot;1997&quot;,
&quot;Industry&quot;: &quot;Catalog/Specialty Distribution&quot;,
&quot;Last_Sale&quot;: &quot;$98.12&quot;,
&quot;Market_Cap&quot;: &quot;9.98556270184E11&quot;,
&quot;Name&quot;: &quot;Amazon.com Inc. Common Stock&quot;,
&quot;Net_Change&quot;: &quot;2.85&quot;,
&quot;Percent_Change&quot;: &quot;2.991%&quot;,
&quot;Sector&quot;: &quot;Consumer Discretionary&quot;,
&quot;Ticker&quot;: &quot;AMZN&quot;,
&quot;Volume&quot;: &quot;85412563&quot;
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finmapper_nasdaq_ticker_stock_screener|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[ner_chunk]|
|Output Labels:|[mappings]|
|Language:|en|
|Size:|584.5 KB|

## References

https://www.nasdaq.com/market-activity/stocks/screener</content><author><name>John Snow Labs</name></author><category term="en" /><category term="finance" /><category term="licensed" /><category term="nasdaq" /><category term="ticker" /><summary type="html">Description This model allows you to, given a Ticker, get the following information about a company at Nasdaq Stock Screener: Country IPO_Year Industry Last_Sale Market_Cap Name Net_Change Percent_Change Sector Ticker Volume Firstly, you should get the TICKER symbol from the finance text with the finner_ticker model, then you can get detailed information about the company with the ChunkMapper model. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = nlp.DocumentAssembler()\ .setInputCol('text')\ .setOutputCol('document') tokenizer = nlp.Tokenizer()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;token&quot;) embeddings = nlp.BertEmbeddings.pretrained(&quot;bert_embeddings_sec_bert_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = finance.NerModel.pretrained(&quot;finner_ticker&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;document&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) CM = finance.ChunkMapperModel.pretrained('finmapper_nasdaq_ticker_stock_screener', 'en', 'finance/models')\ .setInputCols([&quot;ner_chunk&quot;])\ .setOutputCol(&quot;mappings&quot;) pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, embeddings, ner_model, ner_converter, CM]) text = [&quot;&quot;&quot;There are some serious purchases and sales of AMZN stock today.&quot;&quot;&quot;] test_data = spark.createDataFrame([text]).toDF(&quot;text&quot;) model = pipeline.fit(test_data) result = model.transform(test_data).select('mappings').collect() Results &quot;Country&quot;: &quot;United States&quot;, &quot;IPO_Year&quot;: &quot;1997&quot;, &quot;Industry&quot;: &quot;Catalog/Specialty Distribution&quot;, &quot;Last_Sale&quot;: &quot;$98.12&quot;, &quot;Market_Cap&quot;: &quot;9.98556270184E11&quot;, &quot;Name&quot;: &quot;Amazon.com Inc. Common Stock&quot;, &quot;Net_Change&quot;: &quot;2.85&quot;, &quot;Percent_Change&quot;: &quot;2.991%&quot;, &quot;Sector&quot;: &quot;Consumer Discretionary&quot;, &quot;Ticker&quot;: &quot;AMZN&quot;, &quot;Volume&quot;: &quot;85412563&quot; Model Information Model Name: finmapper_nasdaq_ticker_stock_screener Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [ner_chunk] Output Labels: [mappings] Language: en Size: 584.5 KB References https://www.nasdaq.com/market-activity/stocks/screener</summary></entry><entry><title type="html">Normalize Parent Companies Names using Wikidata</title><link href="/2023/01/18/finel_wiki_parentorgs_en.html" rel="alternate" type="text/html" title="Normalize Parent Companies Names using Wikidata" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/finel_wiki_parentorgs_en</id><content type="html" xml:base="/2023/01/18/finel_wiki_parentorgs_en.html">## Description

This is an Entity Resolution model, aimed to normalize a previously extracted ORG entity, using its reference name in WIkidata. This is useful to then use `finel_wiki_parentorgs` Chunk Mapping model and get information of the subsidiaries, countries, stock exchange, etc.

It also retrieves the TICKER, which can be retrieved from `aux_label` column in metadata.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_wiki_parentorgs_en_1.0.0_3.0_1674038525188.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
      .setInputCol(&quot;text&quot;)\
      .setOutputCol(&quot;ner_chunk&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \
      .setInputCols(&quot;ner_chunk&quot;) \
      .setOutputCol(&quot;sentence_embeddings&quot;)
    
resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
      .setInputCols([&quot;sentence_embeddings&quot;]) \
      .setOutputCol(&quot;normalized_name&quot;)\
      .setDistanceFunction(&quot;EUCLIDEAN&quot;)

pipelineModel = PipelineModel(
      stages = [
          documentAssembler,
          embeddings,
          resolver
      ])

lp = nlp.LightPipeline(pipelineModel)
test_pred = lp.fullAnnotate('ALPHABET')
print(test_pred[0]['normalized_name'][0].result)
print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0])
```

&lt;/div&gt;

## Results

```bash
Alphabet Inc.
Aux data: GOOGL
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_wiki_parentorgs|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[original_company_name]|
|Language:|en|
|Size:|2.8 MB|
|Case sensitive:|false|

## References

Wikidata dump about company holdings using SparQL</content><author><name>John Snow Labs</name></author><category term="parent" /><category term="wikipedia" /><category term="wikidata" /><category term="en" /><category term="licensed" /><summary type="html">Description This is an Entity Resolution model, aimed to normalize a previously extracted ORG entity, using its reference name in WIkidata. This is useful to then use finel_wiki_parentorgs Chunk Mapping model and get information of the subsidiaries, countries, stock exchange, etc. It also retrieves the TICKER, which can be retrieved from aux_label column in metadata. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;ner_chunk&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \ .setInputCols(&quot;ner_chunk&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;]) \ .setOutputCol(&quot;normalized_name&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, embeddings, resolver ]) lp = nlp.LightPipeline(pipelineModel) test_pred = lp.fullAnnotate('ALPHABET') print(test_pred[0]['normalized_name'][0].result) print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0]) Results Alphabet Inc. Aux data: GOOGL Model Information Model Name: finel_wiki_parentorgs Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [original_company_name] Language: en Size: 2.8 MB Case sensitive: false References Wikidata dump about company holdings using SparQL</summary></entry><entry><title type="html">Resolve Company Names to Tickers using Wikidata</title><link href="/2023/01/18/finel_wiki_parentorgs_ticker_en.html" rel="alternate" type="text/html" title="Resolve Company Names to Tickers using Wikidata" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/finel_wiki_parentorgs_ticker_en</id><content type="html" xml:base="/2023/01/18/finel_wiki_parentorgs_ticker_en.html">## Description

This model helps you retrieve the TICKER of a company using a previously detected ORG entity with NER.

It also retrieves the normalized company name as per Wikidata, which can be retrieved from `aux_label` column in metadata.


## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/finance/models/finel_wiki_parentorgs_ticker_en_1.0.0_3.0_1674038769879.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
      .setInputCol(&quot;text&quot;)\
      .setOutputCol(&quot;ner_chunk&quot;)

embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \
      .setInputCols(&quot;ner_chunk&quot;) \
      .setOutputCol(&quot;sentence_embeddings&quot;)
    
resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs_tickers&quot;, &quot;en&quot;, &quot;finance/models&quot;)\
      .setInputCols([&quot;sentence_embeddings&quot;]) \
      .setOutputCol(&quot;normalized_name&quot;)\
      .setDistanceFunction(&quot;EUCLIDEAN&quot;)

pipelineModel = PipelineModel(
      stages = [
          documentAssembler,
          embeddings,
          resolver
      ])

lp = nlp.LightPipeline(pipelineModel)
test_pred = lp.fullAnnotate('Alphabet Incorporated')
print(test_pred[0]['normalized_name'][0].result)
print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0])
```

&lt;/div&gt;

## Results

```bash
GOOGL
Aux data: Alphabet Inc.
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|finel_wiki_parentorgs_ticker|
|Compatibility:|Finance NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[original_company_name]|
|Language:|en|
|Size:|2.8 MB|
|Case sensitive:|false|

## References

Wikipedia dump about company subsidiaries</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><summary type="html">Description This model helps you retrieve the TICKER of a company using a previously detected ORG entity with NER. It also retrieves the normalized company name as per Wikidata, which can be retrieved from aux_label column in metadata. Predicted Entities Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;ner_chunk&quot;) embeddings = nlp.UniversalSentenceEncoder.pretrained(&quot;tfhub_use&quot;, &quot;en&quot;) \ .setInputCols(&quot;ner_chunk&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) resolver = finance.SentenceEntityResolverModel.pretrained(&quot;finel_wiki_parentorgs_tickers&quot;, &quot;en&quot;, &quot;finance/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;]) \ .setOutputCol(&quot;normalized_name&quot;)\ .setDistanceFunction(&quot;EUCLIDEAN&quot;) pipelineModel = PipelineModel( stages = [ documentAssembler, embeddings, resolver ]) lp = nlp.LightPipeline(pipelineModel) test_pred = lp.fullAnnotate('Alphabet Incorporated') print(test_pred[0]['normalized_name'][0].result) print(test_pred[0]['normalized_name'][0].metadata['all_k_aux_labels'].split(':::')[0]) Results GOOGL Aux data: Alphabet Inc. Model Information Model Name: finel_wiki_parentorgs_ticker Compatibility: Finance NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [original_company_name] Language: en Size: 2.8 MB Case sensitive: false References Wikipedia dump about company subsidiaries</summary></entry><entry><title type="html">Dispute Clause Binary Classifier</title><link href="/2023/01/18/legclf_dispute_clauses_cuad_en.html" rel="alternate" type="text/html" title="Dispute Clause Binary Classifier" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/legclf_dispute_clauses_cuad_en</id><content type="html" xml:base="/2023/01/18/legclf_dispute_clauses_cuad_en.html">## Description

This model is a Binary Classifier (True, False) for the `dispute_clause` clause type. To use this model, make sure you provide enough context as an input.

Senteces have been used as positive examples, so better results will be achieved if SetenceDetector is added to the pipeline.

If you have big legal documents, and you want to look for clauses, we recommend you to split the documents using any of the techniques available in our Spark NLP for Legal Workshop Tokenization &amp; Splitting Tutorial.

Take into consideration the embeddings of this model allows up to 512 tokens. If you have more than that, consider splitting in smaller pieces (you can also check the same tutorial link provided above).

This model can be combined with any of the other 300+ Legal Clauses Classifiers you will find in Models Hub, getting as an output a series of True/False values for each of the legal clause model you have added.

## Predicted Entities

`dispute_clause`, `other`

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/finance/CLASSIFY_LEGAL_CLAUSES/){:.button.button-orange}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legclf_dispute_clauses_cuad_en_1.0.0_3.0_1674056674986.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;) \
      .setInputCols(&quot;document&quot;) \
      .setOutputCol(&quot;sentence_embeddings&quot;)

docClassifier = legal.ClassifierDLModel() \
    .pretrained(&quot;legclf_dispute_clauses_cuad&quot;,&quot;en&quot;,&quot;legal/models&quot;)\
    .setInputCols([&quot;sentence_embeddings&quot;])\
    .setOutputCol(&quot;is_dispute_clause&quot;)

pipeline = nlp.Pipeline() \
    .setStages(
      [
        documentAssembler,
        embeddings,
        docClassifier
      ]
    )

fit_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF('text'))
lm = nlp.LightPipeline(fit_model)

pos_example = &quot;24.2 The parties irrevocably agree that the courts of Ohio shall have non-exclusive jurisdiction to settle any dispute or claim that arises out of or in connection with this agreement or its subject matter or formation ( including non - contractual disputes or claims ).&quot;

neg_example = &quot;Brokers &lt;strong&gt;Fees and Expenses&lt;/strong&gt; Except as expressly set forth in the Transaction Documents to the contrary, each party shall pay the fees and expenses of its advisers, counsel, accountants and other experts, if any, and all other expenses incurred by such party incident to the negotiation, preparation, execution, delivery and performance of this Agreement. The Company shall pay all transfer agent fees, stamp taxes and other taxes and duties levied in connection with the delivery of any Warrant Shares to the Purchasers. Steel Pier Capital Advisors, LLC shall be reimbursed its expenses in having the Transaction Documents prepared on behalf of the Company and for its obligations under the Security Agreement in an amount not to exceed $25,000.00.&quot;

texts = [
    pos_example,
    neg_example
]

res = lm.annotate(texts)
```

&lt;/div&gt;

## Results

```bash
['dispute_clause']
['other']
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legclf_dispute_clauses_cuad|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence_embeddings]|
|Output Labels:|[label]|
|Language:|en|
|Size:|22.9 MB|

## References

Manual annotations of CUAD dataset

## Benchmarking

```bash
label precision    recall  f1-score   support
dispute_clause       1.00      1.00      1.00        61
         other       1.00      1.00      1.00        96
      accuracy         -         -         1.00       157
     macro-avg       1.00      1.00      1.00       157
  weighted-avg       1.00      1.00      1.00       157
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="tensorflow" /><summary type="html">Description This model is a Binary Classifier (True, False) for the dispute_clause clause type. To use this model, make sure you provide enough context as an input. Senteces have been used as positive examples, so better results will be achieved if SetenceDetector is added to the pipeline. If you have big legal documents, and you want to look for clauses, we recommend you to split the documents using any of the techniques available in our Spark NLP for Legal Workshop Tokenization &amp;amp; Splitting Tutorial. Take into consideration the embeddings of this model allows up to 512 tokens. If you have more than that, consider splitting in smaller pieces (you can also check the same tutorial link provided above). This model can be combined with any of the other 300+ Legal Clauses Classifiers you will find in Models Hub, getting as an output a series of True/False values for each of the legal clause model you have added. Predicted Entities dispute_clause, other Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) embeddings = nlp.BertSentenceEmbeddings.pretrained(&quot;sent_bert_base_cased&quot;, &quot;en&quot;) \ .setInputCols(&quot;document&quot;) \ .setOutputCol(&quot;sentence_embeddings&quot;) docClassifier = legal.ClassifierDLModel() \ .pretrained(&quot;legclf_dispute_clauses_cuad&quot;,&quot;en&quot;,&quot;legal/models&quot;)\ .setInputCols([&quot;sentence_embeddings&quot;])\ .setOutputCol(&quot;is_dispute_clause&quot;) pipeline = nlp.Pipeline() \ .setStages( [ documentAssembler, embeddings, docClassifier ] ) fit_model = pipeline.fit(spark.createDataFrame([[&quot;&quot;]]).toDF('text')) lm = nlp.LightPipeline(fit_model) pos_example = &quot;24.2 The parties irrevocably agree that the courts of Ohio shall have non-exclusive jurisdiction to settle any dispute or claim that arises out of or in connection with this agreement or its subject matter or formation ( including non - contractual disputes or claims ).&quot; neg_example = &quot;Brokers &amp;lt;strong&amp;gt;Fees and Expenses&amp;lt;/strong&amp;gt; Except as expressly set forth in the Transaction Documents to the contrary, each party shall pay the fees and expenses of its advisers, counsel, accountants and other experts, if any, and all other expenses incurred by such party incident to the negotiation, preparation, execution, delivery and performance of this Agreement. The Company shall pay all transfer agent fees, stamp taxes and other taxes and duties levied in connection with the delivery of any Warrant Shares to the Purchasers. Steel Pier Capital Advisors, LLC shall be reimbursed its expenses in having the Transaction Documents prepared on behalf of the Company and for its obligations under the Security Agreement in an amount not to exceed $25,000.00.&quot; texts = [ pos_example, neg_example ] res = lm.annotate(texts) Results ['dispute_clause'] ['other'] Model Information Model Name: legclf_dispute_clauses_cuad Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence_embeddings] Output Labels: [label] Language: en Size: 22.9 MB References Manual annotations of CUAD dataset Benchmarking label precision recall f1-score support dispute_clause 1.00 1.00 1.00 61 other 1.00 1.00 1.00 96 accuracy - - 1.00 157 macro-avg 1.00 1.00 1.00 157 weighted-avg 1.00 1.00 1.00 157</summary></entry><entry><title type="html">Dispute Clauses NER</title><link href="/2023/01/18/legner_dispute_clauses_en.html" rel="alternate" type="text/html" title="Dispute Clauses NER" /><published>2023-01-18T00:00:00+00:00</published><updated>2023-01-18T00:00:00+00:00</updated><id>/2023/01/18/legner_dispute_clauses_en</id><content type="html" xml:base="/2023/01/18/legner_dispute_clauses_en.html">## Description

This is a Legal NER model which helps to retrieve Courts/Arbitrations, Rules and Resolution Means from legal agreements.

## Predicted Entities

`RESOLUT_MEANS`, `RULES_NAME`, `COURT_NAME`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/legal/models/legner_dispute_clauses_en_1.0.0_3.0_1674054944954.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = nlp.DocumentAssembler()\
        .setInputCol(&quot;text&quot;)\
        .setOutputCol(&quot;document&quot;)
        
sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\
        .setInputCols([&quot;document&quot;])\
        .setOutputCol(&quot;sentence&quot;)

tokenizer = nlp.Tokenizer()\
        .setInputCols([&quot;sentence&quot;])\
        .setOutputCol(&quot;token&quot;)

embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) \
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \
    .setOutputCol(&quot;embeddings&quot;)

ner_model = legal.NerModel().pretrained(&quot;legner_dispute_clauses&quot;,&quot;en&quot;,&quot;legal/models&quot;)\
        .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
        .setOutputCol(&quot;ner&quot;)

ner_converter = nlp.NerConverter()\
        .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\
        .setOutputCol(&quot;ner_chunk&quot;)

nlpPipeline = nlp.Pipeline(stages=[
        documentAssembler,
        sentenceDetector,
        tokenizer,
        embeddings,
        ner_model,
        ner_converter])

empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)

model = nlpPipeline.fit(empty_data)

text = [&quot;&quot;&quot;The contract includes a dispute clause that requires the parties to follow the rules of judicial arbitration set forth by the United Nations Commission on International Trade Law (UNCITRAL) Rules of Arbitration and the jurisdiction of the International Chamber of Commerce court in the event of a dispute.&quot;&quot;&quot;]

res = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;))
```

&lt;/div&gt;

## Results

```bash
+-------------+---------------+
|        token|      ner_label|
+-------------+---------------+
|          The|              O|
|     contract|              O|
|     includes|              O|
|            a|              O|
|      dispute|              O|
|       clause|              O|
|         that|              O|
|     requires|              O|
|          the|              O|
|      parties|              O|
|           to|              O|
|       follow|              O|
|          the|              O|
|        rules|              O|
|           of|              O|
|     judicial|B-RESOLUT_MEANS|
|  arbitration|I-RESOLUT_MEANS|
|          set|              O|
|        forth|              O|
|           by|              O|
|          the|              O|
|       United|   B-RULES_NAME|
|      Nations|   I-RULES_NAME|
|   Commission|   I-RULES_NAME|
|           on|   I-RULES_NAME|
|International|   I-RULES_NAME|
|        Trade|   I-RULES_NAME|
|          Law|   I-RULES_NAME|
|            (|   I-RULES_NAME|
|     UNCITRAL|   I-RULES_NAME|
|            )|   I-RULES_NAME|
|        Rules|   I-RULES_NAME|
|           of|   I-RULES_NAME|
|  Arbitration|   I-RULES_NAME|
|          and|              O|
|          the|              O|
| jurisdiction|              O|
|           of|              O|
|          the|              O|
|International|   B-COURT_NAME|
|      Chamber|   I-COURT_NAME|
|           of|   I-COURT_NAME|
|     Commerce|   I-COURT_NAME|
|        court|              O|
|           in|              O|
|          the|              O|
|        event|              O|
|           of|              O|
|            a|              O|
|      dispute|              O|
|            .|              O|
+-------------+---------------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|legner_dispute_clauses|
|Compatibility:|Legal NLP 1.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[sentence, token, embeddings]|
|Output Labels:|[ner]|
|Language:|en|
|Size:|16.2 MB|

## References

In-house annotations of the CUAD dataset

## Benchmarking

```bash
label	 tp	 fp	 fn	 prec	 rec	 f1
B-RESOLUT_MEANS	 14	 4	 6	 0.7777778	 0.7	 0.73684216
B-RULES_NAME	 15	 0	 5	 1.0	 0.75	 0.85714287
I-RESOLUT_MEANS	 12	 0	 3	 1.0	 0.8	 0.88888896
B-COURT_NAME	 26	 6	 6	 0.8125	 0.8125	 0.8125
I-RULES_NAME	 101	 7	 19	 0.9351852	 0.84166664	 0.8859649
I-COURT_NAME	 166	 23	 24	 0.87830687	 0.8736842	 0.87598944
Macro-average	 334 40 63 0.9006283 0.7963085 0.8452619
Micro-average	 334 40 63 0.8930481 0.84130985 0.8664072
```</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><summary type="html">Description This is a Legal NER model which helps to retrieve Courts/Arbitrations, Rules and Resolution Means from legal agreements. Predicted Entities RESOLUT_MEANS, RULES_NAME, COURT_NAME Live Demo Open in Colab Download How to use PythonScalaNLU documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;,&quot;xx&quot;)\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = nlp.RoBertaEmbeddings.pretrained(&quot;roberta_embeddings_legal_roberta_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \ .setOutputCol(&quot;embeddings&quot;) ner_model = legal.NerModel().pretrained(&quot;legner_dispute_clauses&quot;,&quot;en&quot;,&quot;legal/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = nlp.NerConverter()\ .setInputCols([&quot;sentence&quot;,&quot;token&quot;,&quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;) nlpPipeline = nlp.Pipeline(stages=[ documentAssembler, sentenceDetector, tokenizer, embeddings, ner_model, ner_converter]) empty_data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;) model = nlpPipeline.fit(empty_data) text = [&quot;&quot;&quot;The contract includes a dispute clause that requires the parties to follow the rules of judicial arbitration set forth by the United Nations Commission on International Trade Law (UNCITRAL) Rules of Arbitration and the jurisdiction of the International Chamber of Commerce court in the event of a dispute.&quot;&quot;&quot;] res = model.transform(spark.createDataFrame([text]).toDF(&quot;text&quot;)) Results +-------------+---------------+ | token| ner_label| +-------------+---------------+ | The| O| | contract| O| | includes| O| | a| O| | dispute| O| | clause| O| | that| O| | requires| O| | the| O| | parties| O| | to| O| | follow| O| | the| O| | rules| O| | of| O| | judicial|B-RESOLUT_MEANS| | arbitration|I-RESOLUT_MEANS| | set| O| | forth| O| | by| O| | the| O| | United| B-RULES_NAME| | Nations| I-RULES_NAME| | Commission| I-RULES_NAME| | on| I-RULES_NAME| |International| I-RULES_NAME| | Trade| I-RULES_NAME| | Law| I-RULES_NAME| | (| I-RULES_NAME| | UNCITRAL| I-RULES_NAME| | )| I-RULES_NAME| | Rules| I-RULES_NAME| | of| I-RULES_NAME| | Arbitration| I-RULES_NAME| | and| O| | the| O| | jurisdiction| O| | of| O| | the| O| |International| B-COURT_NAME| | Chamber| I-COURT_NAME| | of| I-COURT_NAME| | Commerce| I-COURT_NAME| | court| O| | in| O| | the| O| | event| O| | of| O| | a| O| | dispute| O| | .| O| +-------------+---------------+ Model Information Model Name: legner_dispute_clauses Compatibility: Legal NLP 1.0.0+ License: Licensed Edition: Official Input Labels: [sentence, token, embeddings] Output Labels: [ner] Language: en Size: 16.2 MB References In-house annotations of the CUAD dataset Benchmarking label tp fp fn prec rec f1 B-RESOLUT_MEANS 14 4 6 0.7777778 0.7 0.73684216 B-RULES_NAME 15 0 5 1.0 0.75 0.85714287 I-RESOLUT_MEANS 12 0 3 1.0 0.8 0.88888896 B-COURT_NAME 26 6 6 0.8125 0.8125 0.8125 I-RULES_NAME 101 7 19 0.9351852 0.84166664 0.8859649 I-COURT_NAME 166 23 24 0.87830687 0.8736842 0.87598944 Macro-average 334 40 63 0.9006283 0.7963085 0.8452619 Micro-average 334 40 63 0.8930481 0.84130985 0.8664072</summary></entry></feed>