<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-12-27T21:33:56+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">English algmonquestingansweringmodel_base RoBertaForQuestionAnswering from weijiang2009</title><link href="/2023/12/24/algmonquestingansweringmodel_base_en.html" rel="alternate" type="text/html" title="English algmonquestingansweringmodel_base RoBertaForQuestionAnswering from weijiang2009" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/algmonquestingansweringmodel_base_en</id><content type="html" xml:base="/2023/12/24/algmonquestingansweringmodel_base_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`algmonquestingansweringmodel_base` is a English model originally trained by weijiang2009.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/algmonquestingansweringmodel_base_en_5.2.1_3.0_1703407127455.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/algmonquestingansweringmodel_base_en_5.2.1_3.0_1703407127455.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;algmonquestingansweringmodel_base&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;algmonquestingansweringmodel_base&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|algmonquestingansweringmodel_base|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|463.5 MB|

## References

https://huggingface.co/weijiang2009/AlgmonQuestingAnsweringModel-base</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.algmonquestingansweringmodel_base is a English model originally trained by weijiang2009. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;algmonquestingansweringmodel_base&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;algmonquestingansweringmodel_base&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: algmonquestingansweringmodel_base Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 463.5 MB References https://huggingface.co/weijiang2009/AlgmonQuestingAnsweringModel-base</summary></entry><entry><title type="html">English allenai_biomed_roberta_base_emrqa RoBertaForQuestionAnswering from aaditya</title><link href="/2023/12/24/allenai_biomed_roberta_base_emrqa_en.html" rel="alternate" type="text/html" title="English allenai_biomed_roberta_base_emrqa RoBertaForQuestionAnswering from aaditya" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/allenai_biomed_roberta_base_emrqa_en</id><content type="html" xml:base="/2023/12/24/allenai_biomed_roberta_base_emrqa_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`allenai_biomed_roberta_base_emrqa` is a English model originally trained by aaditya.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/allenai_biomed_roberta_base_emrqa_en_5.2.1_3.0_1703397192204.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/allenai_biomed_roberta_base_emrqa_en_5.2.1_3.0_1703397192204.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;allenai_biomed_roberta_base_emrqa&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;allenai_biomed_roberta_base_emrqa&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|allenai_biomed_roberta_base_emrqa|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|466.2 MB|

## References

https://huggingface.co/aaditya/allenai_biomed_roberta_base_emrqa</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.allenai_biomed_roberta_base_emrqa is a English model originally trained by aaditya. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;allenai_biomed_roberta_base_emrqa&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;allenai_biomed_roberta_base_emrqa&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: allenai_biomed_roberta_base_emrqa Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 466.2 MB References https://huggingface.co/aaditya/allenai_biomed_roberta_base_emrqa</summary></entry><entry><title type="html">English autotrain_clinics_52256123143 RoBertaForQuestionAnswering from kabucode</title><link href="/2023/12/24/autotrain_clinics_52256123143_en.html" rel="alternate" type="text/html" title="English autotrain_clinics_52256123143 RoBertaForQuestionAnswering from kabucode" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/autotrain_clinics_52256123143_en</id><content type="html" xml:base="/2023/12/24/autotrain_clinics_52256123143_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`autotrain_clinics_52256123143` is a English model originally trained by kabucode.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/autotrain_clinics_52256123143_en_5.2.1_3.0_1703381706439.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/autotrain_clinics_52256123143_en_5.2.1_3.0_1703381706439.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;autotrain_clinics_52256123143&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;autotrain_clinics_52256123143&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|autotrain_clinics_52256123143|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|470.0 MB|

## References

https://huggingface.co/kabucode/autotrain-clinics-52256123143</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.autotrain_clinics_52256123143 is a English model originally trained by kabucode. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;autotrain_clinics_52256123143&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;autotrain_clinics_52256123143&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: autotrain_clinics_52256123143 Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 470.0 MB References https://huggingface.co/kabucode/autotrain-clinics-52256123143</summary></entry><entry><title type="html">English autotrain_qa_roberta_2791682386 RoBertaForQuestionAnswering from deba-iitbh</title><link href="/2023/12/24/autotrain_qa_roberta_2791682386_en.html" rel="alternate" type="text/html" title="English autotrain_qa_roberta_2791682386 RoBertaForQuestionAnswering from deba-iitbh" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/autotrain_qa_roberta_2791682386_en</id><content type="html" xml:base="/2023/12/24/autotrain_qa_roberta_2791682386_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`autotrain_qa_roberta_2791682386` is a English model originally trained by deba-iitbh.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/autotrain_qa_roberta_2791682386_en_5.2.1_3.0_1703390327537.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/autotrain_qa_roberta_2791682386_en_5.2.1_3.0_1703390327537.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;autotrain_qa_roberta_2791682386&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;autotrain_qa_roberta_2791682386&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|autotrain_qa_roberta_2791682386|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|432.3 MB|

## References

https://huggingface.co/deba-iitbh/autotrain-qa_roberta-2791682386</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.autotrain_qa_roberta_2791682386 is a English model originally trained by deba-iitbh. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;autotrain_qa_roberta_2791682386&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;autotrain_qa_roberta_2791682386&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: autotrain_qa_roberta_2791682386 Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 432.3 MB References https://huggingface.co/deba-iitbh/autotrain-qa_roberta-2791682386</summary></entry><entry><title type="html">English autotrain_roberta_qa_spanish_42804109318 RoBertaForQuestionAnswering from dnllns</title><link href="/2023/12/24/autotrain_roberta_qa_spanish_42804109318_en.html" rel="alternate" type="text/html" title="English autotrain_roberta_qa_spanish_42804109318 RoBertaForQuestionAnswering from dnllns" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/autotrain_roberta_qa_spanish_42804109318_en</id><content type="html" xml:base="/2023/12/24/autotrain_roberta_qa_spanish_42804109318_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`autotrain_roberta_qa_spanish_42804109318` is a English model originally trained by dnllns.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/autotrain_roberta_qa_spanish_42804109318_en_5.2.1_3.0_1703403228931.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/autotrain_roberta_qa_spanish_42804109318_en_5.2.1_3.0_1703403228931.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;autotrain_roberta_qa_spanish_42804109318&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;autotrain_roberta_qa_spanish_42804109318&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|autotrain_roberta_qa_spanish_42804109318|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|470.0 MB|

## References

https://huggingface.co/dnllns/autotrain-roberta-qa-es-42804109318</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.autotrain_roberta_qa_spanish_42804109318 is a English model originally trained by dnllns. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;autotrain_roberta_qa_spanish_42804109318&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;autotrain_roberta_qa_spanish_42804109318&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: autotrain_roberta_qa_spanish_42804109318 Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 470.0 MB References https://huggingface.co/dnllns/autotrain-roberta-qa-es-42804109318</summary></entry><entry><title type="html">English bert_finetuned_squad_cojocaruvicentiu RoBertaForQuestionAnswering from cojocaruvicentiu</title><link href="/2023/12/24/bert_finetuned_squad_cojocaruvicentiu_en.html" rel="alternate" type="text/html" title="English bert_finetuned_squad_cojocaruvicentiu RoBertaForQuestionAnswering from cojocaruvicentiu" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/bert_finetuned_squad_cojocaruvicentiu_en</id><content type="html" xml:base="/2023/12/24/bert_finetuned_squad_cojocaruvicentiu_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bert_finetuned_squad_cojocaruvicentiu` is a English model originally trained by cojocaruvicentiu.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bert_finetuned_squad_cojocaruvicentiu_en_5.2.1_3.0_1703413725479.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bert_finetuned_squad_cojocaruvicentiu_en_5.2.1_3.0_1703413725479.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bert_finetuned_squad_cojocaruvicentiu&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;bert_finetuned_squad_cojocaruvicentiu&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bert_finetuned_squad_cojocaruvicentiu|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|457.6 MB|

## References

https://huggingface.co/cojocaruvicentiu/bert-finetuned-squad</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bert_finetuned_squad_cojocaruvicentiu is a English model originally trained by cojocaruvicentiu. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bert_finetuned_squad_cojocaruvicentiu&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;bert_finetuned_squad_cojocaruvicentiu&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bert_finetuned_squad_cojocaruvicentiu Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 457.6 MB References https://huggingface.co/cojocaruvicentiu/bert-finetuned-squad</summary></entry><entry><title type="html">English bertin_roberta_base_spanish_finetuned_qa_mlqa RoBertaForQuestionAnswering from dccuchile</title><link href="/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_mlqa_en.html" rel="alternate" type="text/html" title="English bertin_roberta_base_spanish_finetuned_qa_mlqa RoBertaForQuestionAnswering from dccuchile" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_mlqa_en</id><content type="html" xml:base="/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_mlqa_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bertin_roberta_base_spanish_finetuned_qa_mlqa` is a English model originally trained by dccuchile.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bertin_roberta_base_spanish_finetuned_qa_mlqa_en_5.2.1_3.0_1703421656386.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bertin_roberta_base_spanish_finetuned_qa_mlqa_en_5.2.1_3.0_1703421656386.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_mlqa&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_mlqa&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bertin_roberta_base_spanish_finetuned_qa_mlqa|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|462.2 MB|

## References

https://huggingface.co/dccuchile/bertin-roberta-base-spanish-finetuned-qa-mlqa</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bertin_roberta_base_spanish_finetuned_qa_mlqa is a English model originally trained by dccuchile. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_mlqa&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_mlqa&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bertin_roberta_base_spanish_finetuned_qa_mlqa Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 462.2 MB References https://huggingface.co/dccuchile/bertin-roberta-base-spanish-finetuned-qa-mlqa</summary></entry><entry><title type="html">English bertin_roberta_base_spanish_finetuned_qa_sqac RoBertaForQuestionAnswering from dccuchile</title><link href="/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_sqac_en.html" rel="alternate" type="text/html" title="English bertin_roberta_base_spanish_finetuned_qa_sqac RoBertaForQuestionAnswering from dccuchile" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_sqac_en</id><content type="html" xml:base="/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_sqac_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bertin_roberta_base_spanish_finetuned_qa_sqac` is a English model originally trained by dccuchile.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bertin_roberta_base_spanish_finetuned_qa_sqac_en_5.2.1_3.0_1703395204125.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bertin_roberta_base_spanish_finetuned_qa_sqac_en_5.2.1_3.0_1703395204125.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_sqac&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_sqac&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bertin_roberta_base_spanish_finetuned_qa_sqac|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|462.2 MB|

## References

https://huggingface.co/dccuchile/bertin-roberta-base-spanish-finetuned-qa-sqac</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bertin_roberta_base_spanish_finetuned_qa_sqac is a English model originally trained by dccuchile. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_sqac&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_sqac&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bertin_roberta_base_spanish_finetuned_qa_sqac Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 462.2 MB References https://huggingface.co/dccuchile/bertin-roberta-base-spanish-finetuned-qa-sqac</summary></entry><entry><title type="html">English bertin_roberta_base_spanish_finetuned_qa_tar RoBertaForQuestionAnswering from dccuchile</title><link href="/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_tar_en.html" rel="alternate" type="text/html" title="English bertin_roberta_base_spanish_finetuned_qa_tar RoBertaForQuestionAnswering from dccuchile" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_tar_en</id><content type="html" xml:base="/2023/12/24/bertin_roberta_base_spanish_finetuned_qa_tar_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`bertin_roberta_base_spanish_finetuned_qa_tar` is a English model originally trained by dccuchile.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bertin_roberta_base_spanish_finetuned_qa_tar_en_5.2.1_3.0_1703395199777.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bertin_roberta_base_spanish_finetuned_qa_tar_en_5.2.1_3.0_1703395199777.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_tar&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_tar&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bertin_roberta_base_spanish_finetuned_qa_tar|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|462.2 MB|

## References

https://huggingface.co/dccuchile/bertin-roberta-base-spanish-finetuned-qa-tar</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.bertin_roberta_base_spanish_finetuned_qa_tar is a English model originally trained by dccuchile. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_tar&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;bertin_roberta_base_spanish_finetuned_qa_tar&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: bertin_roberta_base_spanish_finetuned_qa_tar Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 462.2 MB References https://huggingface.co/dccuchile/bertin-roberta-base-spanish-finetuned-qa-tar</summary></entry><entry><title type="html">English burmese_awesome_qa_model_danzz06 RoBertaForQuestionAnswering from danzz06</title><link href="/2023/12/24/burmese_awesome_qa_model_danzz06_en.html" rel="alternate" type="text/html" title="English burmese_awesome_qa_model_danzz06 RoBertaForQuestionAnswering from danzz06" /><published>2023-12-24T00:00:00+00:00</published><updated>2023-12-24T00:00:00+00:00</updated><id>/2023/12/24/burmese_awesome_qa_model_danzz06_en</id><content type="html" xml:base="/2023/12/24/burmese_awesome_qa_model_danzz06_en.html">## Description

Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.`burmese_awesome_qa_model_danzz06` is a English model originally trained by danzz06.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/burmese_awesome_qa_model_danzz06_en_5.2.1_3.0_1703382196830.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/burmese_awesome_qa_model_danzz06_en_5.2.1_3.0_1703382196830.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python


document_assembler = MultiDocumentAssembler() \
    .setInputCol([&quot;question&quot;, &quot;context&quot;]) \
    .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;])
    
    
spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;burmese_awesome_qa_model_danzz06&quot;,&quot;en&quot;) \
            .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \
            .setOutputCol(&quot;answer&quot;)

pipeline = Pipeline().setStages([document_assembler, spanClassifier])

pipelineModel = pipeline.fit(data)

pipelineDF = pipelineModel.transform(data)

```
```scala


val document_assembler = new MultiDocumentAssembler()
    .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) 
    .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;))
    
val spanClassifier = RoBertaForQuestionAnswering  
    .pretrained(&quot;burmese_awesome_qa_model_danzz06&quot;, &quot;en&quot;)
    .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) 
    .setOutputCol(&quot;answer&quot;) 

val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier))

val pipelineModel = pipeline.fit(data)

val pipelineDF = pipelineModel.transform(data)


```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|burmese_awesome_qa_model_danzz06|
|Compatibility:|Spark NLP 5.2.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|463.5 MB|

## References

https://huggingface.co/danzz06/my_awesome_qa_model</content><author><name>John Snow Labs</name></author><category term="roberta" /><category term="en" /><category term="open_source" /><category term="question_answering" /><category term="onnx" /><summary type="html">Description Pretrained RoBertaForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP.burmese_awesome_qa_model_danzz06 is a English model originally trained by danzz06. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU document_assembler = MultiDocumentAssembler() \ .setInputCol([&quot;question&quot;, &quot;context&quot;]) \ .setOutputCol([&quot;document_question&quot;, &quot;document_context&quot;]) spanClassifier = RoBertaForQuestionAnswering.pretrained(&quot;burmese_awesome_qa_model_danzz06&quot;,&quot;en&quot;) \ .setInputCols([&quot;document_question&quot;,&quot;document_context&quot;]) \ .setOutputCol(&quot;answer&quot;) pipeline = Pipeline().setStages([document_assembler, spanClassifier]) pipelineModel = pipeline.fit(data) pipelineDF = pipelineModel.transform(data) val document_assembler = new MultiDocumentAssembler() .setInputCol(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCol(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val spanClassifier = RoBertaForQuestionAnswering .pretrained(&quot;burmese_awesome_qa_model_danzz06&quot;, &quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;,&quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) val pipeline = new Pipeline().setStages(Array(document_assembler, spanClassifier)) val pipelineModel = pipeline.fit(data) val pipelineDF = pipelineModel.transform(data) Model Information Model Name: burmese_awesome_qa_model_danzz06 Compatibility: Spark NLP 5.2.1+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 463.5 MB References https://huggingface.co/danzz06/my_awesome_qa_model</summary></entry></feed>