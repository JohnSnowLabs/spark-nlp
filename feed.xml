<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2023-04-10T18:41:26+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">BART (large-sized model), fine-tuned on CNN Daily Mail</title><link href="/2023/04/09/bart_large_cnn_en.html" rel="alternate" type="text/html" title="BART (large-sized model), fine-tuned on CNN Daily Mail" /><published>2023-04-09T00:00:00+00:00</published><updated>2023-04-09T00:00:00+00:00</updated><id>/2023/04/09/bart_large_cnn_en</id><content type="html" xml:base="/2023/04/09/bart_large_cnn_en.html">## Description

### BART (large-sized model), fine-tuned on CNN Daily Mail 

BART model pre-trained on English language, and fine-tuned on [CNN Daily Mail](https://huggingface.co/datasets/cnn_dailymail). It was introduced in the paper [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/abs/1910.13461) by Lewis et al. and first released in [this repository (https://github.com/pytorch/fairseq/tree/master/examples/bart). 

Disclaimer: The team releasing BART did not write a model card for this model so this model card has been written by the Hugging Face team.

### Model description

BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text.

BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs.

### Intended uses &amp; limitations

You can use this model for text summarization.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bart_large_cnn_en_4.4.0_3.2_1681068423111.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bart_large_cnn_en_4.4.0_3.2_1681068423111.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
bart = BartTransformer.pretrained(&quot;bart_large_cnn&quot;) \
            .setTask(&quot;summarize:&quot;) \
            .setMaxOutputLength(200) \
            .setInputCols([&quot;documents&quot;]) \
            .setOutputCol(&quot;summaries&quot;)
```
```scala
val bart = BartTransformer.pretrained(&quot;bart_large_cnn&quot;)
            .setTask(&quot;summarize:&quot;)
            .setMaxOutputLength(200)
            .setInputCols(&quot;documents&quot;)
            .setOutputCol(&quot;summaries&quot;)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bart_large_cnn|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents]|
|Output Labels:|[summaries]|
|Language:|en|
|Size:|1.1 GB|

## References

https://huggingface.co/datasets/cnn_dailymail</content><author><name>John Snow Labs</name></author><category term="bart" /><category term="summarization" /><category term="cnn" /><category term="text_to_text" /><category term="en" /><category term="english" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description BART (large-sized model), fine-tuned on CNN Daily Mail BART model pre-trained on English language, and fine-tuned on CNN Daily Mail. It was introduced in the paper BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension by Lewis et al. and first released in [this repository (https://github.com/pytorch/fairseq/tree/master/examples/bart). Disclaimer: The team releasing BART did not write a model card for this model so this model card has been written by the Hugging Face team. Model description BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. BART is pre-trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. BART is particularly effective when fine-tuned for text generation (e.g. summarization, translation) but also works well for comprehension tasks (e.g. text classification, question answering). This particular checkpoint has been fine-tuned on CNN Daily Mail, a large collection of text-summary pairs. Intended uses &amp;amp; limitations You can use this model for text summarization. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU bart = BartTransformer.pretrained(&quot;bart_large_cnn&quot;) \ .setTask(&quot;summarize:&quot;) \ .setMaxOutputLength(200) \ .setInputCols([&quot;documents&quot;]) \ .setOutputCol(&quot;summaries&quot;) val bart = BartTransformer.pretrained(&quot;bart_large_cnn&quot;) .setTask(&quot;summarize:&quot;) .setMaxOutputLength(200) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summaries&quot;) Model Information Model Name: bart_large_cnn Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [documents] Output Labels: [summaries] Language: en Size: 1.1 GB References https://huggingface.co/datasets/cnn_dailymail</summary></entry><entry><title type="html">Abstractive Summarization by BART - DistilBART CNN</title><link href="/2023/04/09/distilbart_cnn_6_6_en.html" rel="alternate" type="text/html" title="Abstractive Summarization by BART - DistilBART CNN" /><published>2023-04-09T00:00:00+00:00</published><updated>2023-04-09T00:00:00+00:00</updated><id>/2023/04/09/distilbart_cnn_6_6_en</id><content type="html" xml:base="/2023/04/09/distilbart_cnn_6_6_en.html">## Description

&quot;BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer&quot; The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation.

This pre-trained model is DistilBART fine-tuned on the Extreme Summarization (CNN) Dataset.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distilbart_cnn_6_6_en_4.4.0_3.0_1681067201403.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distilbart_cnn_6_6_en_4.4.0_3.0_1681067201403.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
bart = BartTransformer.pretrained(&quot;distilbart_cnn_6_6&quot;) \
            .setTask(&quot;summarize:&quot;) \
            .setMaxOutputLength(200) \
            .setInputCols([&quot;documents&quot;]) \
            .setOutputCol(&quot;summaries&quot;)
```
```scala
val bart = BartTransformer.pretrained(&quot;distilbart_cnn_6_6&quot;)
            .setTask(&quot;summarize:&quot;)
            .setMaxOutputLength(200)
            .setInputCols(&quot;documents&quot;)
            .setOutputCol(&quot;summaries&quot;)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distilbart_cnn_6_6|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents]|
|Output Labels:|[summaries]|
|Language:|en|
|Size:|673.2 MB|

## References

https://huggingface.co/datasets/cnn_dailymail

## Benchmarking

```bash
### Metrics for DistilBART models

| Model Name                 |   MM Params |   Inference Time (MS) |   Speedup |   Rouge 2 |   Rouge-L |
|:---------------------------|------------:|----------------------:|----------:|----------:|----------:|
| distilbart-xsum-12-1       |         222 |                    90 |      2.54 |     18.31 |     33.37 |
| distilbart-xsum-6-6        |         230 |                   132 |      1.73 |     20.92 |     35.73 |
| distilbart-xsum-12-3       |         255 |                   106 |      2.16 |     21.37 |     36.39 |
| distilbart-xsum-9-6        |         268 |                   136 |      1.68 |     21.72 |     36.61 |
| bart-large-xsum (baseline) |         406 |                   229 |      1    |     21.85 |     36.50 |
| distilbart-xsum-12-6       |         306 |                   137 |      1.68 |     22.12 |     36.99 |
| bart-large-cnn (baseline)  |         406 |                   381 |      1    |     21.06 |     30.63 |
| distilbart-12-3-cnn        |         255 |                   214 |      1.78 |     20.57 |     30.00 |
| distilbart-12-6-cnn        |         306 |                   307 |      1.24 |     21.26 |     30.59 |
| distilbart-6-6-cnn         |         230 |                   182 |      2.09 |     20.17 |     29.70 |
```</content><author><name>John Snow Labs</name></author><category term="bart" /><category term="summarization" /><category term="cnn" /><category term="distil" /><category term="text_to_text" /><category term="en" /><category term="english" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description “BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer” The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation. This pre-trained model is DistilBART fine-tuned on the Extreme Summarization (CNN) Dataset. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU bart = BartTransformer.pretrained(&quot;distilbart_cnn_6_6&quot;) \ .setTask(&quot;summarize:&quot;) \ .setMaxOutputLength(200) \ .setInputCols([&quot;documents&quot;]) \ .setOutputCol(&quot;summaries&quot;) val bart = BartTransformer.pretrained(&quot;distilbart_cnn_6_6&quot;) .setTask(&quot;summarize:&quot;) .setMaxOutputLength(200) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summaries&quot;) Model Information Model Name: distilbart_cnn_6_6 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [documents] Output Labels: [summaries] Language: en Size: 673.2 MB References https://huggingface.co/datasets/cnn_dailymail Benchmarking ### Metrics for DistilBART models | Model Name | MM Params | Inference Time (MS) | Speedup | Rouge 2 | Rouge-L | |:---------------------------|------------:|----------------------:|----------:|----------:|----------:| | distilbart-xsum-12-1 | 222 | 90 | 2.54 | 18.31 | 33.37 | | distilbart-xsum-6-6 | 230 | 132 | 1.73 | 20.92 | 35.73 | | distilbart-xsum-12-3 | 255 | 106 | 2.16 | 21.37 | 36.39 | | distilbart-xsum-9-6 | 268 | 136 | 1.68 | 21.72 | 36.61 | | bart-large-xsum (baseline) | 406 | 229 | 1 | 21.85 | 36.50 | | distilbart-xsum-12-6 | 306 | 137 | 1.68 | 22.12 | 36.99 | | bart-large-cnn (baseline) | 406 | 381 | 1 | 21.06 | 30.63 | | distilbart-12-3-cnn | 255 | 214 | 1.78 | 20.57 | 30.00 | | distilbart-12-6-cnn | 306 | 307 | 1.24 | 21.26 | 30.59 | | distilbart-6-6-cnn | 230 | 182 | 2.09 | 20.17 | 29.70 |</summary></entry><entry><title type="html">Abstractive Summarization by BART - DistilBART XSUM</title><link href="/2023/04/09/distilbart_xsum_12_6_en.html" rel="alternate" type="text/html" title="Abstractive Summarization by BART - DistilBART XSUM" /><published>2023-04-09T00:00:00+00:00</published><updated>2023-04-09T00:00:00+00:00</updated><id>/2023/04/09/distilbart_xsum_12_6_en</id><content type="html" xml:base="/2023/04/09/distilbart_xsum_12_6_en.html">## Description

&quot;BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer&quot; The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation.

This pre-trained model is DistilBART fine-tuned on the Extreme Summarization (XSum) Dataset.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distilbart_xsum_12_6_en_4.4.0_3.0_1681064177975.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distilbart_xsum_12_6_en_4.4.0_3.0_1681064177975.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;) \
            .setTask(&quot;summarize:&quot;) \
            .setMaxOutputLength(200) \
            .setInputCols([&quot;documents&quot;]) \
            .setOutputCol(&quot;summaries&quot;)
```
```scala
val bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;)
            .setTask(&quot;summarize:&quot;)
            .setMaxOutputLength(200)
            .setInputCols(&quot;documents&quot;)
            .setOutputCol(&quot;summaries&quot;)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distilbart_xsum_12_6|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents]|
|Output Labels:|[summaries]|
|Language:|en|
|Size:|854.4 MB|

## Benchmarking

```bash
### Metrics for DistilBART models

| Model Name                 |   MM Params |   Inference Time (MS) |   Speedup |   Rouge 2 |   Rouge-L |
|:---------------------------|------------:|----------------------:|----------:|----------:|----------:|
| distilbart-xsum-12-1       |         222 |                    90 |      2.54 |     18.31 |     33.37 |
| distilbart-xsum-6-6        |         230 |                   132 |      1.73 |     20.92 |     35.73 |
| distilbart-xsum-12-3       |         255 |                   106 |      2.16 |     21.37 |     36.39 |
| distilbart-xsum-9-6        |         268 |                   136 |      1.68 |     21.72 |     36.61 |
| bart-large-xsum (baseline) |         406 |                   229 |      1    |     21.85 |     36.50 |
| distilbart-xsum-12-6       |         306 |                   137 |      1.68 |     22.12 |     36.99 |
| bart-large-cnn (baseline)  |         406 |                   381 |      1    |     21.06 |     30.63 |
| distilbart-12-3-cnn        |         255 |                   214 |      1.78 |     20.57 |     30.00 |
| distilbart-12-6-cnn        |         306 |                   307 |      1.24 |     21.26 |     30.59 |
| distilbart-6-6-cnn         |         230 |                   182 |      2.09 |     20.17 |     29.70 |
```</content><author><name>John Snow Labs</name></author><category term="bart" /><category term="summarization" /><category term="xsum" /><category term="distil" /><category term="text_to_text" /><category term="en" /><category term="english" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description “BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer” The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation. This pre-trained model is DistilBART fine-tuned on the Extreme Summarization (XSum) Dataset. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;) \ .setTask(&quot;summarize:&quot;) \ .setMaxOutputLength(200) \ .setInputCols([&quot;documents&quot;]) \ .setOutputCol(&quot;summaries&quot;) val bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;) .setTask(&quot;summarize:&quot;) .setMaxOutputLength(200) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summaries&quot;) Model Information Model Name: distilbart_xsum_12_6 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [documents] Output Labels: [summaries] Language: en Size: 854.4 MB Benchmarking ### Metrics for DistilBART models | Model Name | MM Params | Inference Time (MS) | Speedup | Rouge 2 | Rouge-L | |:---------------------------|------------:|----------------------:|----------:|----------:|----------:| | distilbart-xsum-12-1 | 222 | 90 | 2.54 | 18.31 | 33.37 | | distilbart-xsum-6-6 | 230 | 132 | 1.73 | 20.92 | 35.73 | | distilbart-xsum-12-3 | 255 | 106 | 2.16 | 21.37 | 36.39 | | distilbart-xsum-9-6 | 268 | 136 | 1.68 | 21.72 | 36.61 | | bart-large-xsum (baseline) | 406 | 229 | 1 | 21.85 | 36.50 | | distilbart-xsum-12-6 | 306 | 137 | 1.68 | 22.12 | 36.99 | | bart-large-cnn (baseline) | 406 | 381 | 1 | 21.06 | 30.63 | | distilbart-12-3-cnn | 255 | 214 | 1.78 | 20.57 | 30.00 | | distilbart-12-6-cnn | 306 | 307 | 1.24 | 21.26 | 30.59 | | distilbart-6-6-cnn | 230 | 182 | 2.09 | 20.17 | 29.70 |</summary></entry><entry><title type="html">Abstractive Summarization by BART - DistilBART XSUM</title><link href="/2023/04/07/distilbart_xsum_12_6_en.html" rel="alternate" type="text/html" title="Abstractive Summarization by BART - DistilBART XSUM" /><published>2023-04-07T00:00:00+00:00</published><updated>2023-04-07T00:00:00+00:00</updated><id>/2023/04/07/distilbart_xsum_12_6_en</id><content type="html" xml:base="/2023/04/07/distilbart_xsum_12_6_en.html">## Description

&quot;BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer&quot; The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation.

This pre-trained model is DistilBART fine-tuned on the Extreme Summarization (XSum) Dataset.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/distilbart_xsum_12_6_en_4.4.0_3.0_1680873584987.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/distilbart_xsum_12_6_en_4.4.0_3.0_1680873584987.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;) \
            .setTask(&quot;summarize:&quot;) \
            .setMaxOutputLength(200) \
            .setInputCols([&quot;documents&quot;]) \
            .setOutputCol(&quot;summaries&quot;)
```
```scala
val bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;)
            .setTask(&quot;summarize:&quot;)
            .setMaxOutputLength(200)
            .setInputCols(&quot;documents&quot;)
            .setOutputCol(&quot;summaries&quot;)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|distilbart_xsum_12_6|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents]|
|Output Labels:|[summaries]|
|Language:|en|
|Size:|854.4 MB|

## References

https://huggingface.co/sshleifer/distilbart-xsum-12-6

## Benchmarking

```bash
### Metrics for DistilBART models

| Model Name                 |   MM Params |   Inference Time (MS) |   Speedup |   Rouge 2 |   Rouge-L |
|:---------------------------|------------:|----------------------:|----------:|----------:|----------:|
| distilbart-xsum-12-1       |         222 |                    90 |      2.54 |     18.31 |     33.37 |
| distilbart-xsum-6-6        |         230 |                   132 |      1.73 |     20.92 |     35.73 |
| distilbart-xsum-12-3       |         255 |                   106 |      2.16 |     21.37 |     36.39 |
| distilbart-xsum-9-6        |         268 |                   136 |      1.68 |     21.72 |     36.61 |
| bart-large-xsum (baseline) |         406 |                   229 |      1    |     21.85 |     36.50 |
| distilbart-xsum-12-6       |         306 |                   137 |      1.68 |     22.12 |     36.99 |
| bart-large-cnn (baseline)  |         406 |                   381 |      1    |     21.06 |     30.63 |
| distilbart-12-3-cnn        |         255 |                   214 |      1.78 |     20.57 |     30.00 |
| distilbart-12-6-cnn        |         306 |                   307 |      1.24 |     21.26 |     30.59 |
| distilbart-6-6-cnn         |         230 |                   182 |      2.09 |     20.17 |     29.70 |
```</content><author><name>John Snow Labs</name></author><category term="bart" /><category term="summarization" /><category term="xsum" /><category term="distil" /><category term="text_to_text" /><category term="en" /><category term="open_source" /><category term="tensorflow" /><summary type="html">Description “BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer” The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art language generation model that was introduced by Facebook AI in 2019. It is based on the transformer architecture and is designed to handle a wide range of natural language processing tasks such as text generation, summarization, and machine translation. This pre-trained model is DistilBART fine-tuned on the Extreme Summarization (XSum) Dataset. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;) \ .setTask(&quot;summarize:&quot;) \ .setMaxOutputLength(200) \ .setInputCols([&quot;documents&quot;]) \ .setOutputCol(&quot;summaries&quot;) val bart = BartTransformer.pretrained(&quot;distilbart_xsum_12_6&quot;) .setTask(&quot;summarize:&quot;) .setMaxOutputLength(200) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;summaries&quot;) Model Information Model Name: distilbart_xsum_12_6 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [documents] Output Labels: [summaries] Language: en Size: 854.4 MB References https://huggingface.co/sshleifer/distilbart-xsum-12-6 Benchmarking ### Metrics for DistilBART models | Model Name | MM Params | Inference Time (MS) | Speedup | Rouge 2 | Rouge-L | |:---------------------------|------------:|----------------------:|----------:|----------:|----------:| | distilbart-xsum-12-1 | 222 | 90 | 2.54 | 18.31 | 33.37 | | distilbart-xsum-6-6 | 230 | 132 | 1.73 | 20.92 | 35.73 | | distilbart-xsum-12-3 | 255 | 106 | 2.16 | 21.37 | 36.39 | | distilbart-xsum-9-6 | 268 | 136 | 1.68 | 21.72 | 36.61 | | bart-large-xsum (baseline) | 406 | 229 | 1 | 21.85 | 36.50 | | distilbart-xsum-12-6 | 306 | 137 | 1.68 | 22.12 | 36.99 | | bart-large-cnn (baseline) | 406 | 381 | 1 | 21.06 | 30.63 | | distilbart-12-3-cnn | 255 | 214 | 1.78 | 20.57 | 30.00 | | distilbart-12-6-cnn | 306 | 307 | 1.24 | 21.26 | 30.59 | | distilbart-6-6-cnn | 230 | 182 | 2.09 | 20.17 | 29.70 |</summary></entry><entry><title type="html">Arabic BertForQuestionAnswering Cased model (from gfdgdfgdg)</title><link href="/2023/04/05/Bert_qa_arap_ar.html" rel="alternate" type="text/html" title="Arabic BertForQuestionAnswering Cased model (from gfdgdfgdg)" /><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>/2023/04/05/Bert_qa_arap_ar</id><content type="html" xml:base="/2023/04/05/Bert_qa_arap_ar.html">## Description

Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `arap_qa_bert` is a Arabic model originally trained by `gfdgdfgdg`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Bert_qa_arap_ar_4.4.0_3.0_1680696331852.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Bert_qa_arap_ar_4.4.0_3.0_1680696331852.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap&quot;,&quot;ar&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap&quot;,&quot;ar&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(true)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Bert_qa_arap|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|ar|
|Size:|404.2 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

- https://huggingface.co/gfdgdfgdg/arap_qa_bert</content><author><name>John Snow Labs</name></author><category term="ar" /><category term="open_source" /><category term="bert" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. arap_qa_bert is a Arabic model originally trained by gfdgdfgdg. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap&quot;,&quot;ar&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap&quot;,&quot;ar&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: Bert_qa_arap Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: ar Size: 404.2 MB Case sensitive: true Max sentence length: 512 References https://huggingface.co/gfdgdfgdg/arap_qa_bert</summary></entry><entry><title type="html">Arabic BertForQuestionAnswering Large Cased model (from gfdgdfgdg)</title><link href="/2023/04/05/Bert_qa_arap_large_v2_ar.html" rel="alternate" type="text/html" title="Arabic BertForQuestionAnswering Large Cased model (from gfdgdfgdg)" /><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>/2023/04/05/Bert_qa_arap_large_v2_ar</id><content type="html" xml:base="/2023/04/05/Bert_qa_arap_large_v2_ar.html">## Description

Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `arap_qa_bert_large_v2` is a Arabic model originally trained by `gfdgdfgdg`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Bert_qa_arap_large_v2_ar_4.4.0_3.0_1680696418684.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Bert_qa_arap_large_v2_ar_4.4.0_3.0_1680696418684.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_large_v2&quot;,&quot;ar&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_large_v2&quot;,&quot;ar&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(true)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Bert_qa_arap_large_v2|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|ar|
|Size:|1.4 GB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

- https://huggingface.co/gfdgdfgdg/arap_qa_bert_large_v2</content><author><name>John Snow Labs</name></author><category term="ar" /><category term="open_source" /><category term="bert" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. arap_qa_bert_large_v2 is a Arabic model originally trained by gfdgdfgdg. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_large_v2&quot;,&quot;ar&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_large_v2&quot;,&quot;ar&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: Bert_qa_arap_large_v2 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: ar Size: 1.4 GB Case sensitive: true Max sentence length: 512 References https://huggingface.co/gfdgdfgdg/arap_qa_bert_large_v2</summary></entry><entry><title type="html">Arabic BertForQuestionAnswering Cased model (from gfdgdfgdg)</title><link href="/2023/04/05/Bert_qa_arap_v2_ar.html" rel="alternate" type="text/html" title="Arabic BertForQuestionAnswering Cased model (from gfdgdfgdg)" /><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>/2023/04/05/Bert_qa_arap_v2_ar</id><content type="html" xml:base="/2023/04/05/Bert_qa_arap_v2_ar.html">## Description

Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `arap_qa_bert_v2` is a Arabic model originally trained by `gfdgdfgdg`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Bert_qa_arap_v2_ar_4.4.0_3.0_1680696496320.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Bert_qa_arap_v2_ar_4.4.0_3.0_1680696496320.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_v2&quot;,&quot;ar&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_v2&quot;,&quot;ar&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(true)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Bert_qa_arap_v2|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|ar|
|Size:|505.4 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

- https://huggingface.co/gfdgdfgdg/arap_qa_bert_v2</content><author><name>John Snow Labs</name></author><category term="ar" /><category term="open_source" /><category term="bert" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. arap_qa_bert_v2 is a Arabic model originally trained by gfdgdfgdg. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_v2&quot;,&quot;ar&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_arap_v2&quot;,&quot;ar&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: Bert_qa_arap_v2 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: ar Size: 505.4 MB Case sensitive: true Max sentence length: 512 References https://huggingface.co/gfdgdfgdg/arap_qa_bert_v2</summary></entry><entry><title type="html">Italian BertForQuestionAnswering Base Uncased model (from antoniocappiello)</title><link href="/2023/04/05/Bert_qa_base_alian_uncased_squad_it.html" rel="alternate" type="text/html" title="Italian BertForQuestionAnswering Base Uncased model (from antoniocappiello)" /><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>/2023/04/05/Bert_qa_base_alian_uncased_squad_it</id><content type="html" xml:base="/2023/04/05/Bert_qa_base_alian_uncased_squad_it.html">## Description

Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bert-base-italian-uncased-squad-it` is a Italian model originally trained by `antoniocappiello`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Bert_qa_base_alian_uncased_squad_it_4.4.0_3.0_1680696910615.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Bert_qa_base_alian_uncased_squad_it_4.4.0_3.0_1680696910615.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_alian_uncased_squad&quot;,&quot;it&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_alian_uncased_squad&quot;,&quot;it&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(true)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Bert_qa_base_alian_uncased_squad|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|it|
|Size:|410.3 MB|
|Case sensitive:|false|
|Max sentence length:|512|

## References

- https://huggingface.co/antoniocappiello/bert-base-italian-uncased-squad-it
- http://sag.art.uniroma2.it/demo-software/squadit/
- https://github.com/crux82/squad-it/blob/master/README.md#evaluating-a-neural-model-over-squad-it</content><author><name>John Snow Labs</name></author><category term="it" /><category term="open_source" /><category term="bert" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bert-base-italian-uncased-squad-it is a Italian model originally trained by antoniocappiello. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_alian_uncased_squad&quot;,&quot;it&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_alian_uncased_squad&quot;,&quot;it&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: Bert_qa_base_alian_uncased_squad Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: it Size: 410.3 MB Case sensitive: false Max sentence length: 512 References https://huggingface.co/antoniocappiello/bert-base-italian-uncased-squad-it http://sag.art.uniroma2.it/demo-software/squadit/ https://github.com/crux82/squad-it/blob/master/README.md#evaluating-a-neural-model-over-squad-it</summary></entry><entry><title type="html">Portuguese BertForQuestionAnswering Base Cased model (from pierreguillou)</title><link href="/2023/04/05/Bert_qa_base_cased_squad_v1.1_portuguese_pt.html" rel="alternate" type="text/html" title="Portuguese BertForQuestionAnswering Base Cased model (from pierreguillou)" /><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>/2023/04/05/Bert_qa_base_cased_squad_v1.1_portuguese_pt</id><content type="html" xml:base="/2023/04/05/Bert_qa_base_cased_squad_v1.1_portuguese_pt.html">## Description

Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bert-base-cased-squad-v1.1-portuguese` is a Portuguese model originally trained by `pierreguillou`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Bert_qa_base_cased_squad_v1.1_portuguese_pt_4.4.0_3.0_1680696828024.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Bert_qa_base_cased_squad_v1.1_portuguese_pt_4.4.0_3.0_1680696828024.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1.1_portuguese&quot;,&quot;pt&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1.1_portuguese&quot;,&quot;pt&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(true)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Bert_qa_base_cased_squad_v1.1_portuguese|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|pt|
|Size:|406.5 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

- https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese
- https://miro.medium.com/max/2000/1*te5MmdesAHCmg4KmK8zD3g.png
- http://www.deeplearningbrasil.com.br/
- https://neuralmind.ai/
- https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78
- https://colab.research.google.com/drive/18ueLdi_V321Gz37x4gHq8mb4XZSGWfZx?usp=sharing
- https://github.com/piegu/language-models/blob/master/colab_question_answering_BERT_base_cased_squad_v11_pt.ipynb
- https://www.linkedin.com/in/pierreguillou/
- https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78#c572
- https://neuralmind.ai/
- http://www.deeplearningbrasil.com.br/
- https://colab.research.google.com/
- https://ailab.unb.br/</content><author><name>John Snow Labs</name></author><category term="pt" /><category term="open_source" /><category term="bert" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bert-base-cased-squad-v1.1-portuguese is a Portuguese model originally trained by pierreguillou. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1.1_portuguese&quot;,&quot;pt&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1.1_portuguese&quot;,&quot;pt&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: Bert_qa_base_cased_squad_v1.1_portuguese Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: pt Size: 406.5 MB Case sensitive: true Max sentence length: 512 References https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese https://miro.medium.com/max/2000/1*te5MmdesAHCmg4KmK8zD3g.png http://www.deeplearningbrasil.com.br/ https://neuralmind.ai/ https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78 https://colab.research.google.com/drive/18ueLdi_V321Gz37x4gHq8mb4XZSGWfZx?usp=sharing https://github.com/piegu/language-models/blob/master/colab_question_answering_BERT_base_cased_squad_v11_pt.ipynb https://www.linkedin.com/in/pierreguillou/ https://medium.com/@pierre_guillou/nlp-modelo-de-question-answering-em-qualquer-idioma-baseado-no-bert-base-estudo-de-caso-em-12093d385e78#c572 https://neuralmind.ai/ http://www.deeplearningbrasil.com.br/ https://colab.research.google.com/ https://ailab.unb.br/</summary></entry><entry><title type="html">English BertForQuestionAnswering Base Cased model (from batterydata)</title><link href="/2023/04/05/Bert_qa_base_cased_squad_v1_en.html" rel="alternate" type="text/html" title="English BertForQuestionAnswering Base Cased model (from batterydata)" /><published>2023-04-05T00:00:00+00:00</published><updated>2023-04-05T00:00:00+00:00</updated><id>/2023/04/05/Bert_qa_base_cased_squad_v1_en</id><content type="html" xml:base="/2023/04/05/Bert_qa_base_cased_squad_v1_en.html">## Description

Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. `bert-base-cased-squad-v1` is a English model originally trained by `batterydata`.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Bert_qa_base_cased_squad_v1_en_4.4.0_3.0_1680696788251.zip){:.button.button-orange}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Bert_qa_base_cased_squad_v1_en_4.4.0_3.0_1680696788251.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
Document_Assembler = MultiDocumentAssembler()\
     .setInputCols([&quot;question&quot;, &quot;context&quot;])\
     .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;])

Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1&quot;,&quot;en&quot;)\
     .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\
     .setOutputCol(&quot;answer&quot;)\
     .setCaseSensitive(True)
    
pipeline = Pipeline(stages=[Document_Assembler, Question_Answering])

data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;)

result = pipeline.fit(data).transform(data)
```
```scala
val Document_Assembler = new MultiDocumentAssembler()
     .setInputCols(Array(&quot;question&quot;, &quot;context&quot;))
     .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))

val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1&quot;,&quot;en&quot;)
     .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;))
     .setOutputCol(&quot;answer&quot;)
     .setCaseSensitive(true)
    
val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering))

val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;)

val result = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Bert_qa_base_cased_squad_v1|
|Compatibility:|Spark NLP 4.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document_question, document_context]|
|Output Labels:|[answer]|
|Language:|en|
|Size:|404.2 MB|
|Case sensitive:|true|
|Max sentence length:|512|

## References

- https://huggingface.co/batterydata/bert-base-cased-squad-v1
- https://github.com/ShuHuang/batterybert</content><author><name>John Snow Labs</name></author><category term="en" /><category term="open_source" /><category term="bert" /><category term="question_answering" /><category term="tensorflow" /><summary type="html">Description Pretrained BertForQuestionAnswering model, adapted from Hugging Face and curated to provide scalability and production-readiness using Spark NLP. bert-base-cased-squad-v1 is a English model originally trained by batterydata. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU Document_Assembler = MultiDocumentAssembler()\ .setInputCols([&quot;question&quot;, &quot;context&quot;])\ .setOutputCols([&quot;document_question&quot;, &quot;document_context&quot;]) Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1&quot;,&quot;en&quot;)\ .setInputCols([&quot;document_question&quot;, &quot;document_context&quot;])\ .setOutputCol(&quot;answer&quot;)\ .setCaseSensitive(True) pipeline = Pipeline(stages=[Document_Assembler, Question_Answering]) data = spark.createDataFrame([[&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;]]).toDF(&quot;question&quot;, &quot;context&quot;) result = pipeline.fit(data).transform(data) val Document_Assembler = new MultiDocumentAssembler() .setInputCols(Array(&quot;question&quot;, &quot;context&quot;)) .setOutputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) val Question_Answering = BertForQuestionAnswering.pretrained(&quot;Bert_qa_base_cased_squad_v1&quot;,&quot;en&quot;) .setInputCols(Array(&quot;document_question&quot;, &quot;document_context&quot;)) .setOutputCol(&quot;answer&quot;) .setCaseSensitive(true) val pipeline = new Pipeline().setStages(Array(Document_Assembler, Question_Answering)) val data = Seq(&quot;What's my name?&quot;,&quot;My name is Clara and I live in Berkeley.&quot;).toDS.toDF(&quot;question&quot;, &quot;context&quot;) val result = pipeline.fit(data).transform(data) Model Information Model Name: Bert_qa_base_cased_squad_v1 Compatibility: Spark NLP 4.4.0+ License: Open Source Edition: Official Input Labels: [document_question, document_context] Output Labels: [answer] Language: en Size: 404.2 MB Case sensitive: true Max sentence length: 512 References https://huggingface.co/batterydata/bert-base-cased-squad-v1 https://github.com/ShuHuang/batterybert</summary></entry></feed>