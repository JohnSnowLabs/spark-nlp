<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2025-10-22T15:30:24+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">Qwen2.5-VL-7B-Instruct (Q16 GGUF Quantized)</title><link href="/2025/09/15/qwen2.5_vl_7b_instruct_q16_gguf_en.html" rel="alternate" type="text/html" title="Qwen2.5-VL-7B-Instruct (Q16 GGUF Quantized)" /><published>2025-09-15T00:00:00+00:00</published><updated>2025-09-15T00:00:00+00:00</updated><id>/2025/09/15/qwen2.5_vl_7b_instruct_q16_gguf_en</id><content type="html" xml:base="/2025/09/15/qwen2.5_vl_7b_instruct_q16_gguf_en.html">## Description

**Qwen2.5-VL-7B-Instruct (Q16 GGUF Quantized)** is a 7-billion-parameter multimodal instruction-tuned model supporting **text, image, and video understanding**. Compared to Qwen2-VL, it introduces major enhancements in **fine-grained visual analysis (objects, text, charts, layouts), structured outputs (tables, invoices, forms), visual localization (bounding boxes, points with JSON), and long-video comprehension (over 1 hour with temporal reasoning)**.  

It also adds **agentic capabilities**, enabling tool use such as computer and phone control. This version is provided in **GGUF Q16 format** for efficient inference in SparkNLP pipelines and lightweight runtimes, balancing speed and accuracy.  

Originally from [Qwen/Qwen2.5-VL-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct).

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/qwen2.5_vl_7b_instruct_q16_gguf_en_6.1.1_3.0_1757966755156.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/qwen2.5_vl_7b_instruct_q16_gguf_en_6.1.1_3.0_1757966755156.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler, ImageAssembler
from sparknlp.annotator import AutoGGUFVisionModel
from pyspark.sql.functions import lit
from pyspark.ml import Pipeline

images_path = &quot;path/to/images/folder&quot;
prompt = &quot;Caption this image.&quot;

data = ImageAssembler.loadImagesAsBytes(spark, images_path)
data = data.withColumn(&quot;caption&quot;, lit(prompt))

document_assembler = (
    DocumentAssembler()
    .setInputCol(&quot;caption&quot;)
    .setOutputCol(&quot;caption_document&quot;)
)

image_assembler = (
    ImageAssembler()
    .setInputCol(&quot;image&quot;)
    .setOutputCol(&quot;image_assembler&quot;)
)

qwen_chat_template = &quot;&quot;&quot;&lt;|im_start|&gt;user
prompt&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
&quot;&quot;&quot;

autoGGUFVisionModel = (
    AutoGGUFVisionModel.pretrained(&quot;qwen2.5_vl_7b_instruct_q16_gguf&quot;)
    .setInputCols([&quot;caption_document&quot;, &quot;image_assembler&quot;])
    .setOutputCol(&quot;completions&quot;)
    .setChatTemplate(qwen_chat_template)
    .setBatchSize(4)
    .setNGpuLayers(32)
    .setNCtx(4096)
    .setMinKeep(0)
    .setMinP(0.05)
    .setNPredict(64)
    .setNProbs(0)
    .setPenalizeNl(False)
    .setRepeatLastN(256)
    .setRepeatPenalty(1.1)
    .setStopStrings([&quot;&lt;/s&gt;&quot;, &quot;&lt;|im_end|&gt;&quot;, &quot;User:&quot;])
    .setTemperature(0.2)
    .setTfsZ(1)
    .setTypicalP(1)
    .setTopK(40)
    .setTopP(0.95)
)

pipeline = Pipeline().setStages([
    document_assembler,
    image_assembler,
    autoGGUFVisionModel
])

model = pipeline.fit(data)
result = model.transform(data)

result.selectExpr(
    &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;,
    &quot;completions.result&quot;
).show(truncate=False)
```
```scala
import com.johnsnowlabs.nlp.base._
import com.johnsnowlabs.nlp.annotators._
import org.apache.spark.sql.functions.lit
import org.apache.spark.ml.Pipeline

val images_path = &quot;path/to/images/folder&quot;
val prompt = &quot;Caption this image.&quot;

var data = ImageAssembler.loadImagesAsBytes(spark, images_path)
data = data.withColumn(&quot;caption&quot;, lit(prompt))

val document_assembler = new DocumentAssembler()
  .setInputCol(&quot;caption&quot;)
  .setOutputCol(&quot;caption_document&quot;)

val image_assembler = new ImageAssembler()
  .setInputCol(&quot;image&quot;)
  .setOutputCol(&quot;image_assembler&quot;)

val qwen_chat_template = &quot;&quot;&quot;&lt;|im_start|&gt;user
prompt&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
&quot;&quot;&quot;

val autoGGUFVisionModel = AutoGGUFVisionModel.pretrained(&quot;qwen2.5_vl_7b_instruct_q16_gguf&quot;)
  .setInputCols(Array(&quot;caption_document&quot;, &quot;image_assembler&quot;))
  .setOutputCol(&quot;completions&quot;)
  .setChatTemplate(qwen_chat_template)
  .setBatchSize(4)
  .setNGpuLayers(32)
  .setNCtx(4096)
  .setMinKeep(0)
  .setMinP(0.05)
  .setNPredict(64)
  .setNProbs(0)
  .setPenalizeNl(false)
  .setRepeatLastN(256)
  .setRepeatPenalty(1.1)
  .setStopStrings(Array(&quot;&lt;/s&gt;&quot;, &quot;&lt;|im_end|&gt;&quot;, &quot;User:&quot;))
  .setTemperature(0.2)
  .setTfsZ(1)
  .setTypicalP(1)
  .setTopK(40)
  .setTopP(0.95)

val pipeline = new Pipeline().setStages(Array(
  document_assembler,
  image_assembler,
  autoGGUFVisionModel
))

val model = pipeline.fit(data)
val result = model.transform(data)

result.selectExpr(
  &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;,
  &quot;completions.result&quot;
).show(false)
```
&lt;/div&gt;

## Results

```bash

+-------------------+-----------------------------------------------------------------------------------------------------------------------------------+
|image_name         |result                                                                                                                             |
+-------------------+-----------------------------------------------------------------------------------------------------------------------------------+
|prescription_02.png|[&quot;Medical prescription for systemic lupus erythematosus and scleroderma overlap with interstitial lung disease, dated 02/07/2021.&quot;]|
|prescription_01.png|[&quot;Prescription for malaria treatment, dated 30-Aug-2023, from SMS Hospital.&quot;]                                                      |
+-------------------+-----------------------------------------------------------------------------------------------------------------------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|qwen2.5_vl_7b_instruct_q16_gguf|
|Compatibility:|Spark NLP 6.1.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[caption_document, image_assembler]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|13.3 GB|</content><author><name>John Snow Labs</name></author><category term="qwen2_5_vl" /><category term="image_to_text" /><category term="multimodal" /><category term="conversational" /><category term="instruct" /><category term="q16" /><category term="7b" /><category term="en" /><category term="open_source" /><category term="llamacpp" /><summary type="html">Description Qwen2.5-VL-7B-Instruct (Q16 GGUF Quantized) is a 7-billion-parameter multimodal instruction-tuned model supporting text, image, and video understanding. Compared to Qwen2-VL, it introduces major enhancements in fine-grained visual analysis (objects, text, charts, layouts), structured outputs (tables, invoices, forms), visual localization (bounding boxes, points with JSON), and long-video comprehension (over 1 hour with temporal reasoning). It also adds agentic capabilities, enabling tool use such as computer and phone control. This version is provided in GGUF Q16 format for efficient inference in SparkNLP pipelines and lightweight runtimes, balancing speed and accuracy. Originally from Qwen/Qwen2.5-VL-7B-Instruct. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler, ImageAssembler from sparknlp.annotator import AutoGGUFVisionModel from pyspark.sql.functions import lit from pyspark.ml import Pipeline images_path = &quot;path/to/images/folder&quot; prompt = &quot;Caption this image.&quot; data = ImageAssembler.loadImagesAsBytes(spark, images_path) data = data.withColumn(&quot;caption&quot;, lit(prompt)) document_assembler = ( DocumentAssembler() .setInputCol(&quot;caption&quot;) .setOutputCol(&quot;caption_document&quot;) ) image_assembler = ( ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) ) qwen_chat_template = &quot;&quot;&quot;&amp;lt;|im_start|&amp;gt;user prompt&amp;lt;|im_end|&amp;gt; &amp;lt;|im_start|&amp;gt;assistant &quot;&quot;&quot; autoGGUFVisionModel = ( AutoGGUFVisionModel.pretrained(&quot;qwen2.5_vl_7b_instruct_q16_gguf&quot;) .setInputCols([&quot;caption_document&quot;, &quot;image_assembler&quot;]) .setOutputCol(&quot;completions&quot;) .setChatTemplate(qwen_chat_template) .setBatchSize(4) .setNGpuLayers(32) .setNCtx(4096) .setMinKeep(0) .setMinP(0.05) .setNPredict(64) .setNProbs(0) .setPenalizeNl(False) .setRepeatLastN(256) .setRepeatPenalty(1.1) .setStopStrings([&quot;&amp;lt;/s&amp;gt;&quot;, &quot;&amp;lt;|im_end|&amp;gt;&quot;, &quot;User:&quot;]) .setTemperature(0.2) .setTfsZ(1) .setTypicalP(1) .setTopK(40) .setTopP(0.95) ) pipeline = Pipeline().setStages([ document_assembler, image_assembler, autoGGUFVisionModel ]) model = pipeline.fit(data) result = model.transform(data) result.selectExpr( &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot; ).show(truncate=False) import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotators._ import org.apache.spark.sql.functions.lit import org.apache.spark.ml.Pipeline val images_path = &quot;path/to/images/folder&quot; val prompt = &quot;Caption this image.&quot; var data = ImageAssembler.loadImagesAsBytes(spark, images_path) data = data.withColumn(&quot;caption&quot;, lit(prompt)) val document_assembler = new DocumentAssembler() .setInputCol(&quot;caption&quot;) .setOutputCol(&quot;caption_document&quot;) val image_assembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val qwen_chat_template = &quot;&quot;&quot;&amp;lt;|im_start|&amp;gt;user prompt&amp;lt;|im_end|&amp;gt; &amp;lt;|im_start|&amp;gt;assistant &quot;&quot;&quot; val autoGGUFVisionModel = AutoGGUFVisionModel.pretrained(&quot;qwen2.5_vl_7b_instruct_q16_gguf&quot;) .setInputCols(Array(&quot;caption_document&quot;, &quot;image_assembler&quot;)) .setOutputCol(&quot;completions&quot;) .setChatTemplate(qwen_chat_template) .setBatchSize(4) .setNGpuLayers(32) .setNCtx(4096) .setMinKeep(0) .setMinP(0.05) .setNPredict(64) .setNProbs(0) .setPenalizeNl(false) .setRepeatLastN(256) .setRepeatPenalty(1.1) .setStopStrings(Array(&quot;&amp;lt;/s&amp;gt;&quot;, &quot;&amp;lt;|im_end|&amp;gt;&quot;, &quot;User:&quot;)) .setTemperature(0.2) .setTfsZ(1) .setTypicalP(1) .setTopK(40) .setTopP(0.95) val pipeline = new Pipeline().setStages(Array( document_assembler, image_assembler, autoGGUFVisionModel )) val model = pipeline.fit(data) val result = model.transform(data) result.selectExpr( &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot; ).show(false) Results +-------------------+-----------------------------------------------------------------------------------------------------------------------------------+ |image_name |result | +-------------------+-----------------------------------------------------------------------------------------------------------------------------------+ |prescription_02.png|[&quot;Medical prescription for systemic lupus erythematosus and scleroderma overlap with interstitial lung disease, dated 02/07/2021.&quot;]| |prescription_01.png|[&quot;Prescription for malaria treatment, dated 30-Aug-2023, from SMS Hospital.&quot;] | +-------------------+-----------------------------------------------------------------------------------------------------------------------------------+ Model Information Model Name: qwen2.5_vl_7b_instruct_q16_gguf Compatibility: Spark NLP 6.1.1+ License: Open Source Edition: Official Input Labels: [caption_document, image_assembler] Output Labels: [completions] Language: en Size: 13.3 GB</summary></entry><entry><title type="html">BGE Reranker V2 M3 Q4_K_M GGUF</title><link href="/2025/09/01/bge_reranker_v2_m3_Q4_K_M_en.html" rel="alternate" type="text/html" title="BGE Reranker V2 M3 Q4_K_M GGUF" /><published>2025-09-01T00:00:00+00:00</published><updated>2025-09-01T00:00:00+00:00</updated><id>/2025/09/01/bge_reranker_v2_m3_Q4_K_M_en</id><content type="html" xml:base="/2025/09/01/bge_reranker_v2_m3_Q4_K_M_en.html">## Description

Lightweight reranker model, possesses strong multilingual capabilities, easy to deploy, with fast inference.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/bge_reranker_v2_m3_Q4_K_M_en_6.1.2_3.0_1756718229635.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/bge_reranker_v2_m3_Q4_K_M_en_6.1.2_3.0_1756718229635.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline
document = DocumentAssembler() \n    .setInputCol(&quot;text&quot;) \n    .setOutputCol(&quot;document&quot;)
reranker = AutoGGUFReranker.pretrained(&quot;bge_reranker_v2_m3_Q4_K_M&quot;) \n    .setInputCols([&quot;document&quot;]) \n    .setOutputCol(&quot;reranked_documents&quot;) \n    .setBatchSize(4) \n    .setQuery(&quot;A man is eating pasta.&quot;)
pipeline = Pipeline().setStages([document, reranker])
data = spark.createDataFrame([
    [&quot;A man is eating food.&quot;],
    [&quot;A man is eating a piece of bread.&quot;],
    [&quot;The girl is carrying a baby.&quot;],
    [&quot;A man is riding a horse.&quot;]
]).toDF(&quot;text&quot;)
result = pipeline.fit(data).transform(data)
result.select(&quot;reranked_documents&quot;).show(truncate = False)
# Each document will have a relevance_score in metadata showing how relevant it is to the query

```

&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|bge_reranker_v2_m3_Q4_K_M|
|Compatibility:|Spark NLP 6.1.2+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[reranked_documents]|
|Language:|en|
|Size:|416.0 MB|</content><author><name>John Snow Labs</name></author><category term="llamacpp" /><category term="gguf" /><category term="reranker" /><category term="bge" /><category term="en" /><category term="open_source" /><summary type="html">Description Lightweight reranker model, possesses strong multilingual capabilities, easy to deploy, with fast inference. Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline document = DocumentAssembler() \n .setInputCol(&quot;text&quot;) \n .setOutputCol(&quot;document&quot;) reranker = AutoGGUFReranker.pretrained(&quot;bge_reranker_v2_m3_Q4_K_M&quot;) \n .setInputCols([&quot;document&quot;]) \n .setOutputCol(&quot;reranked_documents&quot;) \n .setBatchSize(4) \n .setQuery(&quot;A man is eating pasta.&quot;) pipeline = Pipeline().setStages([document, reranker]) data = spark.createDataFrame([ [&quot;A man is eating food.&quot;], [&quot;A man is eating a piece of bread.&quot;], [&quot;The girl is carrying a baby.&quot;], [&quot;A man is riding a horse.&quot;] ]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;reranked_documents&quot;).show(truncate = False) # Each document will have a relevance_score in metadata showing how relevant it is to the query Model Information Model Name: bge_reranker_v2_m3_Q4_K_M Compatibility: Spark NLP 6.1.2+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [reranked_documents] Language: en Size: 416.0 MB</summary></entry><entry><title type="html">Qwen2-VL-2B-Instruct (Q4 GGUF Quantized)</title><link href="/2025/08/11/qwen2_vl_2b_instruct_q4_gguf_en.html" rel="alternate" type="text/html" title="Qwen2-VL-2B-Instruct (Q4 GGUF Quantized)" /><published>2025-08-11T00:00:00+00:00</published><updated>2025-08-11T00:00:00+00:00</updated><id>/2025/08/11/qwen2_vl_2b_instruct_q4_gguf_en</id><content type="html" xml:base="/2025/08/11/qwen2_vl_2b_instruct_q4_gguf_en.html">## Description

Qwen2-VL-2B-Instruct is a 2-billion-parameter vision-language model fine-tuned for following instructions across text, image, and video inputs, enabling tasks like captioning, visual question answering, and multimodal dialogue.

Originally from [Qwen/Qwen2-VL-2B-Instruct](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct)

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/qwen2_vl_2b_instruct_q4_gguf_en_6.1.1_3.0_1754924858631.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/qwen2_vl_2b_instruct_q4_gguf_en_6.1.1_3.0_1754924858631.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler, ImageAssembler
from sparknlp.annotator import AutoGGUFVisionModel
from pyspark.sql.functions import lit
from pyspark.ml import Pipeline

images_path = &quot;path/to/images/folder&quot;
prompt = &quot;Caption this image.&quot;

data = ImageAssembler.loadImagesAsBytes(spark, images_path)
data = data.withColumn(&quot;caption&quot;, lit(prompt))

document_assembler = (
    DocumentAssembler()
    .setInputCol(&quot;caption&quot;)
    .setOutputCol(&quot;caption_document&quot;)
)

image_assembler = (
    ImageAssembler()
    .setInputCol(&quot;image&quot;)
    .setOutputCol(&quot;image_assembler&quot;)
)

qwen_chat_template = &quot;&quot;&quot;&lt;|im_start|&gt;user
{prompt}&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
&quot;&quot;&quot;

autoGGUFVisionModel = (
    AutoGGUFVisionModel.pretrained(&quot;qwen2_vl_2b_instruct_q4_gguf&quot;)
    .setInputCols([&quot;caption_document&quot;, &quot;image_assembler&quot;])
    .setOutputCol(&quot;completions&quot;)
    .setChatTemplate(qwen_chat_template)
    .setBatchSize(4)
    .setNGpuLayers(32)
    .setNCtx(4096)
    .setMinKeep(0)
    .setMinP(0.05)
    .setNPredict(64)
    .setNProbs(0)
    .setPenalizeNl(False)
    .setRepeatLastN(256)
    .setRepeatPenalty(1.1)
    .setStopStrings([&quot;&lt;/s&gt;&quot;, &quot;&lt;|im_end|&gt;&quot;, &quot;User:&quot;])
    .setTemperature(0.2)
    .setTfsZ(1)
    .setTypicalP(1)
    .setTopK(40)
    .setTopP(0.95)
)

pipeline = Pipeline().setStages([
    document_assembler,
    image_assembler,
    autoGGUFVisionModel
])

model = pipeline.fit(data)
result = model.transform(data)

result.selectExpr(
    &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;,
    &quot;completions.result&quot;
).show(truncate=False)

```
```scala
import com.johnsnowlabs.nlp.base._
import com.johnsnowlabs.nlp.annotators._
import org.apache.spark.sql.functions.lit
import org.apache.spark.ml.Pipeline

val images_path = &quot;path/to/images/folder&quot;
val prompt = &quot;Caption this image.&quot;

var data = ImageAssembler.loadImagesAsBytes(spark, images_path)
data = data.withColumn(&quot;caption&quot;, lit(prompt))

val document_assembler = new DocumentAssembler()
  .setInputCol(&quot;caption&quot;)
  .setOutputCol(&quot;caption_document&quot;)

val image_assembler = new ImageAssembler()
  .setInputCol(&quot;image&quot;)
  .setOutputCol(&quot;image_assembler&quot;)

val qwen_chat_template = &quot;&quot;&quot;&lt;|im_start|&gt;user
{prompt}&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
&quot;&quot;&quot;

val autoGGUFVisionModel = AutoGGUFVisionModel.pretrained(&quot;qwen2_vl_2b_instruct_q4_gguf&quot;)
  .setInputCols(Array(&quot;caption_document&quot;, &quot;image_assembler&quot;))
  .setOutputCol(&quot;completions&quot;)
  .setChatTemplate(qwen_chat_template)
  .setBatchSize(4)
  .setNGpuLayers(32)
  .setNCtx(4096)
  .setMinKeep(0)
  .setMinP(0.05)
  .setNPredict(64)
  .setNProbs(0)
  .setPenalizeNl(false)
  .setRepeatLastN(256)
  .setRepeatPenalty(1.1)
  .setStopStrings(Array(&quot;&lt;/s&gt;&quot;, &quot;&lt;|im_end|&gt;&quot;, &quot;User:&quot;))
  .setTemperature(0.2)
  .setTfsZ(1)
  .setTypicalP(1)
  .setTopK(40)
  .setTopP(0.95)

val pipeline = new Pipeline().setStages(Array(
  document_assembler,
  image_assembler,
  autoGGUFVisionModel
))

val model = pipeline.fit(data)
val result = model.transform(data)

result.selectExpr(
  &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;,
  &quot;completions.result&quot;
).show(false)

```
&lt;/div&gt;

## Results

```bash

+---------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|image_name                                   |result                                                                                                                                   |
+---------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+
|[prescription_02.png, images, content, file:]|[&quot;Outpatient Summary: Rheumatology Consultation for Systemic Lupus Erythematosus and Scleroderma Overlap with Interstitial Lung Disease&quot;]|
|[prescription_01.png, images, content, file:]|[&quot;Medical prescription for treatment of fever and headache with medication details.&quot;]                                                    |
+---------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|qwen2_vl_2b_instruct_q4_gguf|
|Compatibility:|Spark NLP 6.1.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[caption_document, image_assembler]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|1.6 GB|</content><author><name>John Snow Labs</name></author><category term="qwen2_vl" /><category term="image_to_text" /><category term="multimodal" /><category term="conversational" /><category term="instruct" /><category term="q4" /><category term="2b" /><category term="en" /><category term="open_source" /><category term="llamacpp" /><summary type="html">Description Qwen2-VL-2B-Instruct is a 2-billion-parameter vision-language model fine-tuned for following instructions across text, image, and video inputs, enabling tasks like captioning, visual question answering, and multimodal dialogue. Originally from Qwen/Qwen2-VL-2B-Instruct Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler, ImageAssembler from sparknlp.annotator import AutoGGUFVisionModel from pyspark.sql.functions import lit from pyspark.ml import Pipeline images_path = &quot;path/to/images/folder&quot; prompt = &quot;Caption this image.&quot; data = ImageAssembler.loadImagesAsBytes(spark, images_path) data = data.withColumn(&quot;caption&quot;, lit(prompt)) document_assembler = ( DocumentAssembler() .setInputCol(&quot;caption&quot;) .setOutputCol(&quot;caption_document&quot;) ) image_assembler = ( ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) ) qwen_chat_template = &quot;&quot;&quot;&amp;lt;|im_start|&amp;gt;user {prompt}&amp;lt;|im_end|&amp;gt; &amp;lt;|im_start|&amp;gt;assistant &quot;&quot;&quot; autoGGUFVisionModel = ( AutoGGUFVisionModel.pretrained(&quot;qwen2_vl_2b_instruct_q4_gguf&quot;) .setInputCols([&quot;caption_document&quot;, &quot;image_assembler&quot;]) .setOutputCol(&quot;completions&quot;) .setChatTemplate(qwen_chat_template) .setBatchSize(4) .setNGpuLayers(32) .setNCtx(4096) .setMinKeep(0) .setMinP(0.05) .setNPredict(64) .setNProbs(0) .setPenalizeNl(False) .setRepeatLastN(256) .setRepeatPenalty(1.1) .setStopStrings([&quot;&amp;lt;/s&amp;gt;&quot;, &quot;&amp;lt;|im_end|&amp;gt;&quot;, &quot;User:&quot;]) .setTemperature(0.2) .setTfsZ(1) .setTypicalP(1) .setTopK(40) .setTopP(0.95) ) pipeline = Pipeline().setStages([ document_assembler, image_assembler, autoGGUFVisionModel ]) model = pipeline.fit(data) result = model.transform(data) result.selectExpr( &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot; ).show(truncate=False) import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotators._ import org.apache.spark.sql.functions.lit import org.apache.spark.ml.Pipeline val images_path = &quot;path/to/images/folder&quot; val prompt = &quot;Caption this image.&quot; var data = ImageAssembler.loadImagesAsBytes(spark, images_path) data = data.withColumn(&quot;caption&quot;, lit(prompt)) val document_assembler = new DocumentAssembler() .setInputCol(&quot;caption&quot;) .setOutputCol(&quot;caption_document&quot;) val image_assembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val qwen_chat_template = &quot;&quot;&quot;&amp;lt;|im_start|&amp;gt;user {prompt}&amp;lt;|im_end|&amp;gt; &amp;lt;|im_start|&amp;gt;assistant &quot;&quot;&quot; val autoGGUFVisionModel = AutoGGUFVisionModel.pretrained(&quot;qwen2_vl_2b_instruct_q4_gguf&quot;) .setInputCols(Array(&quot;caption_document&quot;, &quot;image_assembler&quot;)) .setOutputCol(&quot;completions&quot;) .setChatTemplate(qwen_chat_template) .setBatchSize(4) .setNGpuLayers(32) .setNCtx(4096) .setMinKeep(0) .setMinP(0.05) .setNPredict(64) .setNProbs(0) .setPenalizeNl(false) .setRepeatLastN(256) .setRepeatPenalty(1.1) .setStopStrings(Array(&quot;&amp;lt;/s&amp;gt;&quot;, &quot;&amp;lt;|im_end|&amp;gt;&quot;, &quot;User:&quot;)) .setTemperature(0.2) .setTfsZ(1) .setTypicalP(1) .setTopK(40) .setTopP(0.95) val pipeline = new Pipeline().setStages(Array( document_assembler, image_assembler, autoGGUFVisionModel )) val model = pipeline.fit(data) val result = model.transform(data) result.selectExpr( &quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot; ).show(false) Results +---------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+ |image_name |result | +---------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+ |[prescription_02.png, images, content, file:]|[&quot;Outpatient Summary: Rheumatology Consultation for Systemic Lupus Erythematosus and Scleroderma Overlap with Interstitial Lung Disease&quot;]| |[prescription_01.png, images, content, file:]|[&quot;Medical prescription for treatment of fever and headache with medication details.&quot;] | +---------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------+ Model Information Model Name: qwen2_vl_2b_instruct_q4_gguf Compatibility: Spark NLP 6.1.1+ License: Open Source Edition: Official Input Labels: [caption_document, image_assembler] Output Labels: [completions] Language: en Size: 1.6 GB</summary></entry><entry><title type="html">Phi-4-mini-instruct Q4 GGUF</title><link href="/2025/08/04/Phi_4_mini_instruct_Q4_K_M_gguf_en.html" rel="alternate" type="text/html" title="Phi-4-mini-instruct Q4 GGUF" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>/2025/08/04/Phi_4_mini_instruct_Q4_K_M_gguf_en</id><content type="html" xml:base="/2025/08/04/Phi_4_mini_instruct_Q4_K_M_gguf_en.html">## Description

Phi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures.

Imported from https://huggingface.co/unsloth/Phi-4-mini-instruct-GGUF

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Phi_4_mini_instruct_Q4_K_M_gguf_en_6.1.1_3.0_1754317230916.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Phi_4_mini_instruct_Q4_K_M_gguf_en_6.1.1_3.0_1754317230916.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline

document = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
autoGGUFModel = AutoGGUFModel.pretrained(&quot;Phi_4_mini_instruct_Q4_K_M_gguf&quot;) \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;completions&quot;) \
    .setBatchSize(4) \
    .setNPredict(20) \
    .setNGpuLayers(99) \
    .setTemperature(0.4) \
    .setTopK(40) \
    .setTopP(0.9) \
    .setPenalizeNl(True)
pipeline = Pipeline().setStages([document, autoGGUFModel])
data = spark.createDataFrame([[&quot;Hello, I am a&quot;]]).toDF(&quot;text&quot;)

result = pipeline.fit(data).transform(data)
result.select(&quot;completions&quot;).show(truncate = False)
```
```scala
import com.johnsnowlabs.nlp.base._
import com.johnsnowlabs.nlp.annotator._
import org.apache.spark.ml.Pipeline
import spark.implicits._

val document = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val autoGGUFModel = AutoGGUFModel
  .pretrained(&quot;Phi_4_mini_instruct_Q4_K_M_gguf&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;completions&quot;)
  .setBatchSize(4)
  .setNPredict(20)
  .setNGpuLayers(99)
  .setTemperature(0.4f)
  .setTopK(40)
  .setTopP(0.9f)
  .setPenalizeNl(true)

val pipeline = new Pipeline().setStages(Array(document, autoGGUFModel))

val data = Seq(&quot;Hello, I am a&quot;).toDF(&quot;text&quot;)
val result = pipeline.fit(data).transform(data)
result.select(&quot;completions&quot;).show(truncate = false)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Phi_4_mini_instruct_Q4_K_M_gguf|
|Compatibility:|Spark NLP 6.1.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|2.5 GB|</content><author><name>John Snow Labs</name></author><category term="llamacpp" /><category term="gguf" /><category term="phi" /><category term="phi4" /><category term="en" /><category term="open_source" /><summary type="html">Description Phi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures. Imported from https://huggingface.co/unsloth/Phi-4-mini-instruct-GGUF Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline document = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) autoGGUFModel = AutoGGUFModel.pretrained(&quot;Phi_4_mini_instruct_Q4_K_M_gguf&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;completions&quot;) \ .setBatchSize(4) \ .setNPredict(20) \ .setNGpuLayers(99) \ .setTemperature(0.4) \ .setTopK(40) \ .setTopP(0.9) \ .setPenalizeNl(True) pipeline = Pipeline().setStages([document, autoGGUFModel]) data = spark.createDataFrame([[&quot;Hello, I am a&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;completions&quot;).show(truncate = False) import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotator._ import org.apache.spark.ml.Pipeline import spark.implicits._ val document = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val autoGGUFModel = AutoGGUFModel .pretrained(&quot;Phi_4_mini_instruct_Q4_K_M_gguf&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;completions&quot;) .setBatchSize(4) .setNPredict(20) .setNGpuLayers(99) .setTemperature(0.4f) .setTopK(40) .setTopP(0.9f) .setPenalizeNl(true) val pipeline = new Pipeline().setStages(Array(document, autoGGUFModel)) val data = Seq(&quot;Hello, I am a&quot;).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.select(&quot;completions&quot;).show(truncate = false) Model Information Model Name: Phi_4_mini_instruct_Q4_K_M_gguf Compatibility: Spark NLP 6.1.1+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [completions] Language: en Size: 2.5 GB</summary></entry><entry><title type="html">Qwen2.5 VL 3B Instruct Q4 GGUF</title><link href="/2025/08/04/Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf_en.html" rel="alternate" type="text/html" title="Qwen2.5 VL 3B Instruct Q4 GGUF" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>/2025/08/04/Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf_en</id><content type="html" xml:base="/2025/08/04/Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf_en.html">## Description

In the past five months since Qwen2-VL’s release, numerous developers have built new models on the Qwen2-VL vision-language models, providing us with valuable feedback. During this period, we focused on building more useful vision-language models. Today, we are excited to introduce the latest addition to the Qwen family: Qwen2.5-VL.

Imported from https://huggingface.co/ggml-org/Qwen2.5-VL-3B-Instruct-GGUF

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf_en_6.1.1_3.0_1754318104734.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf_en_6.1.1_3.0_1754318104734.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline
from pyspark.sql.functions import lit
documentAssembler = DocumentAssembler() \
    .setInputCol(&quot;caption&quot;) \
    .setOutputCol(&quot;caption_document&quot;)
imageAssembler = ImageAssembler() \
    .setInputCol(&quot;image&quot;) \
    .setOutputCol(&quot;image_assembler&quot;)
imagesPath = &quot;src/test/resources/image/&quot;
data = ImageAssembler \
    .loadImagesAsBytes(spark, imagesPath) \
    .withColumn(&quot;caption&quot;, lit(&quot;Caption this image.&quot;)) # Add a caption to each image.
nPredict = 40
model = AutoGGUFVisionModel.pretrained(&quot;Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf&quot;) \
    .setInputCols([&quot;caption_document&quot;, &quot;image_assembler&quot;]) \
    .setOutputCol(&quot;completions&quot;) \
    .setBatchSize(4) \
    .setNGpuLayers(99) \
    .setNCtx(4096) \
    .setNPredict(nPredict)
pipeline = Pipeline().setStages([documentAssembler, imageAssembler, model])
pipeline.fit(data).transform(data) \
    .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot;) \
    .show(truncate = False)

```
```scala
import com.johnsnowlabs.nlp.ImageAssembler
import com.johnsnowlabs.nlp.annotator._
import com.johnsnowlabs.nlp.base._
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.functions.lit

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;caption&quot;)
  .setOutputCol(&quot;caption_document&quot;)

val imageAssembler = new ImageAssembler()
  .setInputCol(&quot;image&quot;)
  .setOutputCol(&quot;image_assembler&quot;)

val imagesPath = &quot;src/test/resources/image/&quot;
val data: DataFrame = ImageAssembler
  .loadImagesAsBytes(ResourceHelper.spark, imagesPath)
  .withColumn(&quot;caption&quot;, lit(&quot;Caption this image.&quot;)) // Add a caption to each image.

val nPredict = 40
val model = AutoGGUFVisionModel.pretrained(&quot;Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf&quot;)
  .setInputCols(&quot;caption_document&quot;, &quot;image_assembler&quot;)
  .setOutputCol(&quot;completions&quot;)
  .setBatchSize(4)
  .setNGpuLayers(99)
  .setNCtx(4096)
  .setNPredict(nPredict)

val pipeline = new Pipeline().setStages(Array(documentAssembler, imageAssembler, model))
pipeline
  .fit(data)
  .transform(data)
  .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot;)
  .show(truncate = false)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf|
|Compatibility:|Spark NLP 6.1.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[caption_document, image_assembler]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|2.6 GB|</content><author><name>John Snow Labs</name></author><category term="gguf" /><category term="qwen" /><category term="vlm" /><category term="vl" /><category term="q4" /><category term="llamacpp" /><category term="en" /><category term="open_source" /><summary type="html">Description In the past five months since Qwen2-VL’s release, numerous developers have built new models on the Qwen2-VL vision-language models, providing us with valuable feedback. During this period, we focused on building more useful vision-language models. Today, we are excited to introduce the latest addition to the Qwen family: Qwen2.5-VL. Imported from https://huggingface.co/ggml-org/Qwen2.5-VL-3B-Instruct-GGUF Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline from pyspark.sql.functions import lit documentAssembler = DocumentAssembler() \ .setInputCol(&quot;caption&quot;) \ .setOutputCol(&quot;caption_document&quot;) imageAssembler = ImageAssembler() \ .setInputCol(&quot;image&quot;) \ .setOutputCol(&quot;image_assembler&quot;) imagesPath = &quot;src/test/resources/image/&quot; data = ImageAssembler \ .loadImagesAsBytes(spark, imagesPath) \ .withColumn(&quot;caption&quot;, lit(&quot;Caption this image.&quot;)) # Add a caption to each image. nPredict = 40 model = AutoGGUFVisionModel.pretrained(&quot;Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf&quot;) \ .setInputCols([&quot;caption_document&quot;, &quot;image_assembler&quot;]) \ .setOutputCol(&quot;completions&quot;) \ .setBatchSize(4) \ .setNGpuLayers(99) \ .setNCtx(4096) \ .setNPredict(nPredict) pipeline = Pipeline().setStages([documentAssembler, imageAssembler, model]) pipeline.fit(data).transform(data) \ .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot;) \ .show(truncate = False) import com.johnsnowlabs.nlp.ImageAssembler import com.johnsnowlabs.nlp.annotator._ import com.johnsnowlabs.nlp.base._ import org.apache.spark.ml.Pipeline import org.apache.spark.sql.DataFrame import org.apache.spark.sql.functions.lit val documentAssembler = new DocumentAssembler() .setInputCol(&quot;caption&quot;) .setOutputCol(&quot;caption_document&quot;) val imageAssembler = new ImageAssembler() .setInputCol(&quot;image&quot;) .setOutputCol(&quot;image_assembler&quot;) val imagesPath = &quot;src/test/resources/image/&quot; val data: DataFrame = ImageAssembler .loadImagesAsBytes(ResourceHelper.spark, imagesPath) .withColumn(&quot;caption&quot;, lit(&quot;Caption this image.&quot;)) // Add a caption to each image. val nPredict = 40 val model = AutoGGUFVisionModel.pretrained(&quot;Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf&quot;) .setInputCols(&quot;caption_document&quot;, &quot;image_assembler&quot;) .setOutputCol(&quot;completions&quot;) .setBatchSize(4) .setNGpuLayers(99) .setNCtx(4096) .setNPredict(nPredict) val pipeline = new Pipeline().setStages(Array(documentAssembler, imageAssembler, model)) pipeline .fit(data) .transform(data) .selectExpr(&quot;reverse(split(image.origin, '/'))[0] as image_name&quot;, &quot;completions.result&quot;) .show(truncate = false) Model Information Model Name: Qwen2.5_VL_3B_Instruct_Q4_K_M_gguf Compatibility: Spark NLP 6.1.1+ License: Open Source Edition: Official Input Labels: [caption_document, image_assembler] Output Labels: [completions] Language: en Size: 2.6 GB</summary></entry><entry><title type="html">Qwen3-Embedding-0.6B-GGUF</title><link href="/2025/08/04/Qwen3_Embedding_0.6B_Q8_0_gguf_en.html" rel="alternate" type="text/html" title="Qwen3-Embedding-0.6B-GGUF" /><published>2025-08-04T00:00:00+00:00</published><updated>2025-08-04T00:00:00+00:00</updated><id>/2025/08/04/Qwen3_Embedding_0.6B_Q8_0_gguf_en</id><content type="html" xml:base="/2025/08/04/Qwen3_Embedding_0.6B_Q8_0_gguf_en.html">## Description

The Qwen3 Embedding model series is the latest proprietary model of the Qwen family, specifically designed for text embedding and ranking tasks. Building upon the dense foundational models of the Qwen3 series, it provides a comprehensive range of text embeddings and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the exceptional multilingual capabilities, long-text understanding, and reasoning skills of its foundational model. The Qwen3 Embedding series represents significant advancements in multiple text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bitext mining.

Imported from https://huggingface.co/Qwen/Qwen3-Embedding-0.6B-GGUF

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Qwen3_Embedding_0.6B_Q8_0_gguf_en_6.1.1_3.0_1754314464060.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Qwen3_Embedding_0.6B_Q8_0_gguf_en_6.1.1_3.0_1754314464060.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
import sparknlp
from sparknlp.base import *
from sparknlp.annotator import *
from pyspark.ml import Pipeline

document = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)
autoGGUFEmbeddings = AutoGGUFEmbeddings.pretrained(&quot;Qwen3_Embedding_0.6B_Q8_0_gguf&quot;) \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;embeddings&quot;) \
    .setBatchSize(4) \
    .setNGpuLayers(99) \
    .setPoolingType(&quot;MEAN&quot;)
pipeline = Pipeline().setStages([document, autoGGUFEmbeddings])

data = spark.createDataFrame([[&quot;The moons of Jupiter are 77 in total, with 79 confirmed natural satellites and 2 man-made ones.&quot;]]).toDF(&quot;text&quot;)
result = pipeline.fit(data).transform(data)
result.select(&quot;embeddings.embeddings&quot;).show(truncate = False)

```
```scala
import com.johnsnowlabs.nlp.base._
import com.johnsnowlabs.nlp.annotator._
import org.apache.spark.ml.Pipeline
import spark.implicits._

val document = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;)

val autoGGUFModel = AutoGGUFEmbeddings
  .pretrained(&quot;Qwen3_Embedding_0.6B_Q8_0_gguf&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;embeddings&quot;)
  .setBatchSize(4)
  .setPoolingType(&quot;MEAN&quot;)

val pipeline = new Pipeline().setStages(Array(document, autoGGUFModel))

val data = Seq(
  &quot;The moons of Jupiter are 77 in total, with 79 confirmed natural satellites and 2 man-made ones.&quot;)
  .toDF(&quot;text&quot;)
val result = pipeline.fit(data).transform(data)
result.select(&quot;embeddings.embeddings&quot;).show(truncate = false)
```
&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Qwen3_Embedding_0.6B_Q8_0_gguf|
|Compatibility:|Spark NLP 6.1.1+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[embeddings]|
|Language:|en|
|Size:|609.4 MB|</content><author><name>John Snow Labs</name></author><category term="gguf" /><category term="qwen3" /><category term="qwen" /><category term="embedding" /><category term="q8" /><category term="llamacpp" /><category term="en" /><category term="open_source" /><summary type="html">Description The Qwen3 Embedding model series is the latest proprietary model of the Qwen family, specifically designed for text embedding and ranking tasks. Building upon the dense foundational models of the Qwen3 series, it provides a comprehensive range of text embeddings and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the exceptional multilingual capabilities, long-text understanding, and reasoning skills of its foundational model. The Qwen3 Embedding series represents significant advancements in multiple text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bitext mining. Imported from https://huggingface.co/Qwen/Qwen3-Embedding-0.6B-GGUF Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU import sparknlp from sparknlp.base import * from sparknlp.annotator import * from pyspark.ml import Pipeline document = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) autoGGUFEmbeddings = AutoGGUFEmbeddings.pretrained(&quot;Qwen3_Embedding_0.6B_Q8_0_gguf&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;embeddings&quot;) \ .setBatchSize(4) \ .setNGpuLayers(99) \ .setPoolingType(&quot;MEAN&quot;) pipeline = Pipeline().setStages([document, autoGGUFEmbeddings]) data = spark.createDataFrame([[&quot;The moons of Jupiter are 77 in total, with 79 confirmed natural satellites and 2 man-made ones.&quot;]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) result.select(&quot;embeddings.embeddings&quot;).show(truncate = False) import com.johnsnowlabs.nlp.base._ import com.johnsnowlabs.nlp.annotator._ import org.apache.spark.ml.Pipeline import spark.implicits._ val document = new DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;) val autoGGUFModel = AutoGGUFEmbeddings .pretrained(&quot;Qwen3_Embedding_0.6B_Q8_0_gguf&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;embeddings&quot;) .setBatchSize(4) .setPoolingType(&quot;MEAN&quot;) val pipeline = new Pipeline().setStages(Array(document, autoGGUFModel)) val data = Seq( &quot;The moons of Jupiter are 77 in total, with 79 confirmed natural satellites and 2 man-made ones.&quot;) .toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) result.select(&quot;embeddings.embeddings&quot;).show(truncate = false) Model Information Model Name: Qwen3_Embedding_0.6B_Q8_0_gguf Compatibility: Spark NLP 6.1.1+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [embeddings] Language: en Size: 609.4 MB</summary></entry><entry><title type="html">Qwen3-4B GGUF (F16 Quantized) by Qwen</title><link href="/2025/07/31/qwen3_4b_bf16_gguf_en.html" rel="alternate" type="text/html" title="Qwen3-4B GGUF (F16 Quantized) by Qwen" /><published>2025-07-31T00:00:00+00:00</published><updated>2025-07-31T00:00:00+00:00</updated><id>/2025/07/31/qwen3_4b_bf16_gguf_en</id><content type="html" xml:base="/2025/07/31/qwen3_4b_bf16_gguf_en.html">## Description

Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support

Original model from https://huggingface.co/Qwen/Qwen3-4B

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/qwen3_4b_bf16_gguf_en_6.0.3_3.0_1753977562790.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/qwen3_4b_bf16_gguf_en_6.0.3_3.0_1753977562790.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import AutoGGUFModel
from pyspark.ml import Pipeline

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

auto_gguf_model = AutoGGUFModel.pretrained(&quot;qwen3_4b_bf16_gguf&quot;, &quot;en&quot;) \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;completions&quot;) \
    .setBatchSize(4) \
    .setNPredict(-1) \
    .setNGpuLayers(99) \
    .setTemperature(0.4) \
    .setTopK(40) \
    .setTopP(0.9) \
    .setPenalizeNl(True)

pipeline = Pipeline().setStages([
    document_assembler,
    auto_gguf_model
])

data = spark.createDataFrame([
    [&quot;Give me a short introduction to large language model.&quot;]
]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)

result.select(&quot;completions&quot;).show(truncate=False)

```
```scala
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.annotators.auto.gguf.AutoGGUFModel
import org.apache.spark.ml.Pipeline

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val autoGGUFModel = AutoGGUFModel.pretrained(&quot;qwen3_4b_bf16_gguf&quot;, &quot;en&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;completions&quot;)
  .setBatchSize(4)
  .setNPredict(20)
  .setNGpuLayers(99)
  .setTemperature(0.4f)
  .setTopK(40)
  .setTopP(0.9f)
  .setPenalizeNl(true)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  autoGGUFModel
))

val data = Seq(&quot;Give me a short introduction to large language model.&quot;).toDF(&quot;text&quot;)

val model = pipeline.fit(data)
val result = model.transform(data)

result.select(&quot;completions&quot;).show(false)

```
&lt;/div&gt;

## Results

```bash
Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. Trained on vast amounts of data, they can answer questions, write essays, code, create stories, and engage in conversations. These models use deep learning algorithms to recognize patterns in language, enabling them to produce coherent and contextually relevant responses. LLMs have revolutionized fields like customer service, content creation, and research, offering powerful tools for tasks ranging from translation to creative writing. While they are highly capable, their outputs depend on the quality of their training data and the specific instructions given.
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|qwen3_4b_bf16_gguf|
|Compatibility:|Spark NLP 6.0.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|6.4 GB|</content><author><name>John Snow Labs</name></author><category term="qwen3" /><category term="float16" /><category term="quantized" /><category term="conversational" /><category term="en" /><category term="open_source" /><category term="llamacpp" /><category term="gguf" /><summary type="html">Description Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support Original model from https://huggingface.co/Qwen/Qwen3-4B Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import AutoGGUFModel from pyspark.ml import Pipeline document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) auto_gguf_model = AutoGGUFModel.pretrained(&quot;qwen3_4b_bf16_gguf&quot;, &quot;en&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;completions&quot;) \ .setBatchSize(4) \ .setNPredict(-1) \ .setNGpuLayers(99) \ .setTemperature(0.4) \ .setTopK(40) \ .setTopP(0.9) \ .setPenalizeNl(True) pipeline = Pipeline().setStages([ document_assembler, auto_gguf_model ]) data = spark.createDataFrame([ [&quot;Give me a short introduction to large language model.&quot;] ]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.select(&quot;completions&quot;).show(truncate=False) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.auto.gguf.AutoGGUFModel import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val autoGGUFModel = AutoGGUFModel.pretrained(&quot;qwen3_4b_bf16_gguf&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;completions&quot;) .setBatchSize(4) .setNPredict(20) .setNGpuLayers(99) .setTemperature(0.4f) .setTopK(40) .setTopP(0.9f) .setPenalizeNl(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, autoGGUFModel )) val data = Seq(&quot;Give me a short introduction to large language model.&quot;).toDF(&quot;text&quot;) val model = pipeline.fit(data) val result = model.transform(data) result.select(&quot;completions&quot;).show(false) Results Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. Trained on vast amounts of data, they can answer questions, write essays, code, create stories, and engage in conversations. These models use deep learning algorithms to recognize patterns in language, enabling them to produce coherent and contextually relevant responses. LLMs have revolutionized fields like customer service, content creation, and research, offering powerful tools for tasks ranging from translation to creative writing. While they are highly capable, their outputs depend on the quality of their training data and the specific instructions given. Model Information Model Name: qwen3_4b_bf16_gguf Compatibility: Spark NLP 6.0.3+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [completions] Language: en Size: 6.4 GB</summary></entry><entry><title type="html">Qwen3-4B GGUF (Q4_K_M Quantized) by Qwen</title><link href="/2025/07/31/qwen3_4b_q4_k_m_gguf_en.html" rel="alternate" type="text/html" title="Qwen3-4B GGUF (Q4_K_M Quantized) by Qwen" /><published>2025-07-31T00:00:00+00:00</published><updated>2025-07-31T00:00:00+00:00</updated><id>/2025/07/31/qwen3_4b_q4_k_m_gguf_en</id><content type="html" xml:base="/2025/07/31/qwen3_4b_q4_k_m_gguf_en.html">## Description

Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support

Original model from https://huggingface.co/Qwen/Qwen3-4B

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/qwen3_4b_q4_k_m_gguf_en_6.0.3_3.0_1753972317683.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/qwen3_4b_q4_k_m_gguf_en_6.0.3_3.0_1753972317683.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import AutoGGUFModel
from pyspark.ml import Pipeline

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

auto_gguf_model = AutoGGUFModel.pretrained(&quot;qwen3_4b_q4_k_m_gguf&quot;, &quot;en&quot;) \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;completions&quot;) \
    .setBatchSize(4) \
    .setNPredict(20) \
    .setNGpuLayers(99) \
    .setTemperature(0.4) \
    .setTopK(40) \
    .setTopP(0.9) \
    .setPenalizeNl(True)

pipeline = Pipeline().setStages([
    document_assembler,
    auto_gguf_model
])

data = spark.createDataFrame([
    [&quot;A farmer has 17 sheep. All but 9 run away. How many sheep does the farmer have left?&quot;]
]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)

result.select(&quot;completions&quot;).show(truncate=False)

```
```scala
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.annotators.auto.gguf.AutoGGUFModel
import org.apache.spark.ml.Pipeline

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val autoGGUFModel = AutoGGUFModel.pretrained(&quot;qwen3_4b_q4_k_m_gguf&quot;, &quot;en&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;completions&quot;)
  .setBatchSize(4)
  .setNPredict(20)
  .setNGpuLayers(99)
  .setTemperature(0.4f)
  .setTopK(40)
  .setTopP(0.9f)
  .setPenalizeNl(true)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  autoGGUFModel
))

val data = Seq(&quot;A farmer has 17 sheep. All but 9 run away. How many sheep does the farmer have left?&quot;).toDF(&quot;text&quot;)

val model = pipeline.fit(data)
val result = model.transform(data)

result.select(&quot;completions&quot;).show(false)

```
&lt;/div&gt;

## Results

```bash
Explanation:
The phrase &quot;all but 9 run away&quot; means that 9 sheep did not run away, while the remaining (17 - 9 = 8) did. Therefore, the farmer still has the 9 sheep that stayed behind.
Answer: 9.
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|qwen3_4b_q4_k_m_gguf|
|Compatibility:|Spark NLP 6.0.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|2.5 GB|</content><author><name>John Snow Labs</name></author><category term="qwen3" /><category term="q4" /><category term="quantized" /><category term="conversational" /><category term="en" /><category term="open_source" /><category term="llamacpp" /><category term="gguf" /><summary type="html">Description Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support Original model from https://huggingface.co/Qwen/Qwen3-4B Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import AutoGGUFModel from pyspark.ml import Pipeline document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) auto_gguf_model = AutoGGUFModel.pretrained(&quot;qwen3_4b_q4_k_m_gguf&quot;, &quot;en&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;completions&quot;) \ .setBatchSize(4) \ .setNPredict(20) \ .setNGpuLayers(99) \ .setTemperature(0.4) \ .setTopK(40) \ .setTopP(0.9) \ .setPenalizeNl(True) pipeline = Pipeline().setStages([ document_assembler, auto_gguf_model ]) data = spark.createDataFrame([ [&quot;A farmer has 17 sheep. All but 9 run away. How many sheep does the farmer have left?&quot;] ]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.select(&quot;completions&quot;).show(truncate=False) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.auto.gguf.AutoGGUFModel import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val autoGGUFModel = AutoGGUFModel.pretrained(&quot;qwen3_4b_q4_k_m_gguf&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;completions&quot;) .setBatchSize(4) .setNPredict(20) .setNGpuLayers(99) .setTemperature(0.4f) .setTopK(40) .setTopP(0.9f) .setPenalizeNl(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, autoGGUFModel )) val data = Seq(&quot;A farmer has 17 sheep. All but 9 run away. How many sheep does the farmer have left?&quot;).toDF(&quot;text&quot;) val model = pipeline.fit(data) val result = model.transform(data) result.select(&quot;completions&quot;).show(false) Results Explanation: The phrase &quot;all but 9 run away&quot; means that 9 sheep did not run away, while the remaining (17 - 9 = 8) did. Therefore, the farmer still has the 9 sheep that stayed behind. Answer: 9. Model Information Model Name: qwen3_4b_q4_k_m_gguf Compatibility: Spark NLP 6.0.3+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [completions] Language: en Size: 2.5 GB</summary></entry><entry><title type="html">Qwen3-4B GGUF (Q8 Quantized) by Qwen</title><link href="/2025/07/31/qwen3_4b_q8_0_gguf_en.html" rel="alternate" type="text/html" title="Qwen3-4B GGUF (Q8 Quantized) by Qwen" /><published>2025-07-31T00:00:00+00:00</published><updated>2025-07-31T00:00:00+00:00</updated><id>/2025/07/31/qwen3_4b_q8_0_gguf_en</id><content type="html" xml:base="/2025/07/31/qwen3_4b_q8_0_gguf_en.html">## Description

Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support

Original model from https://huggingface.co/Qwen/Qwen3-4B

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/qwen3_4b_q8_0_gguf_en_6.0.3_3.0_1753974988649.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/qwen3_4b_q8_0_gguf_en_6.0.3_3.0_1753974988649.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import AutoGGUFModel
from pyspark.ml import Pipeline

document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

auto_gguf_model = AutoGGUFModel.pretrained(&quot;qwen3_4b_q8_0_gguf&quot;, &quot;en&quot;) \
    .setInputCols([&quot;document&quot;]) \
    .setOutputCol(&quot;completions&quot;) \
    .setBatchSize(4) \
    .setNPredict(-1) \
    .setNGpuLayers(99) \
    .setTemperature(0.4) \
    .setTopK(40) \
    .setTopP(0.9) \
    .setPenalizeNl(True)

pipeline = Pipeline().setStages([
    document_assembler,
    auto_gguf_model
])

data = spark.createDataFrame([
    [&quot;Give me a short introduction to large language model.&quot;]
]).toDF(&quot;text&quot;)

model = pipeline.fit(data)
result = model.transform(data)

result.select(&quot;completions&quot;).show(truncate=False)

```
```scala
import com.johnsnowlabs.nlp.base.DocumentAssembler
import com.johnsnowlabs.nlp.annotators.auto.gguf.AutoGGUFModel
import org.apache.spark.ml.Pipeline

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val autoGGUFModel = AutoGGUFModel.pretrained(&quot;qwen3_4b_q8_0_gguf&quot;, &quot;en&quot;)
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;completions&quot;)
  .setBatchSize(4)
  .setNPredict(20)
  .setNGpuLayers(99)
  .setTemperature(0.4f)
  .setTopK(40)
  .setTopP(0.9f)
  .setPenalizeNl(true)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  autoGGUFModel
))

val data = Seq(&quot;Give me a short introduction to large language model.&quot;).toDF(&quot;text&quot;)

val model = pipeline.fit(data)
val result = model.transform(data)

result.select(&quot;completions&quot;).show(false)

```
&lt;/div&gt;

## Results

```bash
Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. Trained on vast amounts of textual data, they can perform tasks such as answering questions, writing stories, coding, summarizing information, and engaging in conversations. These models leverage deep learning techniques to recognize patterns, context, and semantics in language, making them highly versatile tools for various applications, from customer service to creative writing. While powerful, they require careful use to ensure accuracy and ethical considerations.
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|qwen3_4b_q8_0_gguf|
|Compatibility:|Spark NLP 6.0.3+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document]|
|Output Labels:|[completions]|
|Language:|en|
|Size:|4.1 GB|</content><author><name>John Snow Labs</name></author><category term="qwen3" /><category term="q8" /><category term="quantized" /><category term="conversational" /><category term="en" /><category term="open_source" /><category term="llamacpp" /><category term="gguf" /><summary type="html">Description Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support Original model from https://huggingface.co/Qwen/Qwen3-4B Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import AutoGGUFModel from pyspark.ml import Pipeline document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) auto_gguf_model = AutoGGUFModel.pretrained(&quot;qwen3_4b_q8_0_gguf&quot;, &quot;en&quot;) \ .setInputCols([&quot;document&quot;]) \ .setOutputCol(&quot;completions&quot;) \ .setBatchSize(4) \ .setNPredict(-1) \ .setNGpuLayers(99) \ .setTemperature(0.4) \ .setTopK(40) \ .setTopP(0.9) \ .setPenalizeNl(True) pipeline = Pipeline().setStages([ document_assembler, auto_gguf_model ]) data = spark.createDataFrame([ [&quot;Give me a short introduction to large language model.&quot;] ]).toDF(&quot;text&quot;) model = pipeline.fit(data) result = model.transform(data) result.select(&quot;completions&quot;).show(truncate=False) import com.johnsnowlabs.nlp.base.DocumentAssembler import com.johnsnowlabs.nlp.annotators.auto.gguf.AutoGGUFModel import org.apache.spark.ml.Pipeline val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val autoGGUFModel = AutoGGUFModel.pretrained(&quot;qwen3_4b_q8_0_gguf&quot;, &quot;en&quot;) .setInputCols(&quot;document&quot;) .setOutputCol(&quot;completions&quot;) .setBatchSize(4) .setNPredict(20) .setNGpuLayers(99) .setTemperature(0.4f) .setTopK(40) .setTopP(0.9f) .setPenalizeNl(true) val pipeline = new Pipeline().setStages(Array( documentAssembler, autoGGUFModel )) val data = Seq(&quot;Give me a short introduction to large language model.&quot;).toDF(&quot;text&quot;) val model = pipeline.fit(data) val result = model.transform(data) result.select(&quot;completions&quot;).show(false) Results Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. Trained on vast amounts of textual data, they can perform tasks such as answering questions, writing stories, coding, summarizing information, and engaging in conversations. These models leverage deep learning techniques to recognize patterns, context, and semantics in language, making them highly versatile tools for various applications, from customer service to creative writing. While powerful, they require careful use to ensure accuracy and ethical considerations. Model Information Model Name: qwen3_4b_q8_0_gguf Compatibility: Spark NLP 6.0.3+ License: Open Source Edition: Official Input Labels: [document] Output Labels: [completions] Language: en Size: 4.1 GB</summary></entry><entry><title type="html">Phi-4-mini-Instruct OpenVINO (Q4 Quantized) by Microsoft</title><link href="/2025/07/25/Phi_4_mini_instruct_int4_openvino_en.html" rel="alternate" type="text/html" title="Phi-4-mini-Instruct OpenVINO (Q4 Quantized) by Microsoft" /><published>2025-07-25T00:00:00+00:00</published><updated>2025-07-25T00:00:00+00:00</updated><id>/2025/07/25/Phi_4_mini_instruct_int4_openvino_en</id><content type="html" xml:base="/2025/07/25/Phi_4_mini_instruct_int4_openvino_en.html">## Description

Phi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures.

Original model from https://huggingface.co/microsoft/Phi-4-mini-instruct

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/Phi_4_mini_instruct_int4_openvino_en_6.0.0_3.0_1753454352119.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/Phi_4_mini_instruct_int4_openvino_en_6.0.0_3.0_1753454352119.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.base import DocumentAssembler
from sparknlp.annotator import Phi4Transformer
from pyspark.ml import Pipeline

test_data = spark.createDataFrame(
    [
        [
            1,
            &quot;&quot;&quot;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;
You are a helpful assistant that provides concise and accurate answers to user queries.
&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
Explain the concept of the Internet to a medieval knight.
&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;&quot;&quot;&quot;
            .strip().replace(&quot;\n&quot;, &quot; &quot;),
        ]
    ]
).toDF(&quot;id&quot;, &quot;text&quot;)

document_assembler = DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;documents&quot;)

Phi4 = (
    Phi4Transformer.pretrained(&quot;Phi_4_mini_instruct_int4_openvino&quot;)
    .setMaxOutputLength(120)
    .setInputCols([&quot;documents&quot;])
    .setOutputCol(&quot;generation&quot;)
)

pipeline = Pipeline().setStages(
    [document_assembler, Phi4]
)

model = pipeline.fit(test_data)
results = model.transform(test_data)

results.select(&quot;generation.result&quot;).show(truncate=False)

```
```scala
import com.johnsnowlabs.nlp.DocumentAssembler
import com.johnsnowlabs.nlp.annotators.transformer.Phi4Transformer
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.functions._

val text =
  &quot;&quot;&quot;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;
You are a helpful assistant that provides concise and accurate answers to user queries.
&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
Explain the concept of the Internet to a medieval knight.
&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;&quot;&quot;&quot;
    .stripMargin
    .replaceAll(&quot;\n&quot;, &quot; &quot;)

val testData = Seq(
  (1, text)
).toDF(&quot;id&quot;, &quot;text&quot;)

val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;documents&quot;)

val phi4 = Phi4Transformer.pretrained(&quot;Phi_4_mini_instruct_int4_openvino&quot;)
  .setMaxOutputLength(120)
  .setInputCols(&quot;documents&quot;)
  .setOutputCol(&quot;generation&quot;)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  phi4
))

val model = pipeline.fit(testData)
val results = model.transform(testData)

results.selectExpr(&quot;explode(generation.result) as result&quot;).show(false)

```
&lt;/div&gt;

## Results

```bash

&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;
You are a helpful assistant that provides concise and accurate answers to user queries.

&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;
Explain the concept of the Internet to a medieval knight.

&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;
The internet, my good sir Knight Sir Gareth,
is akin unto an invisible network much like our cobblestone roads but spanning across kingdoms far greater than any map you possess.
Imagine if every squire in your land could send messages instantly over vast distances without crossing paths or carrying physical missives on horseback! 
This is what we call 'the web', where information travels at lightning speed through unseen pathways known as cables buried deep below earth's surface connecting castles worldwide.
Furthermore imagine gathering all knowledge from libraries scattered around realms within moments using magical mirrors reflecting light instead...
Wait no longer!
The magic behind it involves bits

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|Phi_4_mini_instruct_int4_openvino|
|Compatibility:|Spark NLP 6.0.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[documents]|
|Output Labels:|[generation]|
|Language:|en|
|Size:|2.4 GB|</content><author><name>John Snow Labs</name></author><category term="openvino" /><category term="phi4" /><category term="mini" /><category term="q4" /><category term="quantized" /><category term="instruct" /><category term="conversational" /><category term="128k" /><category term="en" /><category term="open_source" /><summary type="html">Description Phi-4-mini-instruct is a lightweight open model built upon synthetic data and filtered publicly available websites - with a focus on high-quality, reasoning dense data. The model belongs to the Phi-4 model family and supports 128K token context length. The model underwent an enhancement process, incorporating both supervised fine-tuning and direct preference optimization to support precise instruction adherence and robust safety measures. Original model from https://huggingface.co/microsoft/Phi-4-mini-instruct Live Demo Open in Colab Download Copy S3 URI How to use PythonScalaNLU from sparknlp.base import DocumentAssembler from sparknlp.annotator import Phi4Transformer from pyspark.ml import Pipeline test_data = spark.createDataFrame( [ [ 1, &quot;&quot;&quot;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful assistant that provides concise and accurate answers to user queries. &amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; Explain the concept of the Internet to a medieval knight. &amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&quot;&quot;&quot; .strip().replace(&quot;\n&quot;, &quot; &quot;), ] ] ).toDF(&quot;id&quot;, &quot;text&quot;) document_assembler = DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;documents&quot;) Phi4 = ( Phi4Transformer.pretrained(&quot;Phi_4_mini_instruct_int4_openvino&quot;) .setMaxOutputLength(120) .setInputCols([&quot;documents&quot;]) .setOutputCol(&quot;generation&quot;) ) pipeline = Pipeline().setStages( [document_assembler, Phi4] ) model = pipeline.fit(test_data) results = model.transform(test_data) results.select(&quot;generation.result&quot;).show(truncate=False) import com.johnsnowlabs.nlp.DocumentAssembler import com.johnsnowlabs.nlp.annotators.transformer.Phi4Transformer import org.apache.spark.ml.Pipeline import org.apache.spark.sql.functions._ val text = &quot;&quot;&quot;&amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful assistant that provides concise and accurate answers to user queries. &amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; Explain the concept of the Internet to a medieval knight. &amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt;&quot;&quot;&quot; .stripMargin .replaceAll(&quot;\n&quot;, &quot; &quot;) val testData = Seq( (1, text) ).toDF(&quot;id&quot;, &quot;text&quot;) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;documents&quot;) val phi4 = Phi4Transformer.pretrained(&quot;Phi_4_mini_instruct_int4_openvino&quot;) .setMaxOutputLength(120) .setInputCols(&quot;documents&quot;) .setOutputCol(&quot;generation&quot;) val pipeline = new Pipeline().setStages(Array( documentAssembler, phi4 )) val model = pipeline.fit(testData) val results = model.transform(testData) results.selectExpr(&quot;explode(generation.result) as result&quot;).show(false) Results &amp;lt;|start_header_id|&amp;gt;system&amp;lt;|end_header_id|&amp;gt; You are a helpful assistant that provides concise and accurate answers to user queries. &amp;lt;|start_header_id|&amp;gt;user&amp;lt;|end_header_id|&amp;gt; Explain the concept of the Internet to a medieval knight. &amp;lt;|start_header_id|&amp;gt;assistant&amp;lt;|end_header_id|&amp;gt; The internet, my good sir Knight Sir Gareth, is akin unto an invisible network much like our cobblestone roads but spanning across kingdoms far greater than any map you possess. Imagine if every squire in your land could send messages instantly over vast distances without crossing paths or carrying physical missives on horseback! This is what we call 'the web', where information travels at lightning speed through unseen pathways known as cables buried deep below earth's surface connecting castles worldwide. Furthermore imagine gathering all knowledge from libraries scattered around realms within moments using magical mirrors reflecting light instead... Wait no longer! The magic behind it involves bits Model Information Model Name: Phi_4_mini_instruct_int4_openvino Compatibility: Spark NLP 6.0.0+ License: Open Source Edition: Official Input Labels: [documents] Output Labels: [generation] Language: en Size: 2.4 GB</summary></entry></feed>