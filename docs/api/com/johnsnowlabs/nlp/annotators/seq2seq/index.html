<!DOCTYPE html >
<html>
        <head>
          <meta http-equiv="X-UA-Compatible" content="IE=edge" />
          <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
          <title>Spark NLP 5.5.0 ScalaDoc  - com.johnsnowlabs.nlp.annotators.seq2seq</title>
          <meta name="description" content="Spark NLP 5.5.0 ScalaDoc - com.johnsnowlabs.nlp.annotators.seq2seq" />
          <meta name="keywords" content="Spark NLP 5.5.0 ScalaDoc com.johnsnowlabs.nlp.annotators.seq2seq" />
          <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
          
      
      <link href="../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet" />
      <link href="../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css" />
      <script type="text/javascript" src="../../../../../lib/jquery.min.js"></script>
      <script type="text/javascript" src="../../../../../lib/jquery.panzoom.min.js"></script>
      <script type="text/javascript" src="../../../../../lib/jquery.mousewheel.min.js"></script>
      <script type="text/javascript" src="../../../../../lib/index.js"></script>
      <script type="text/javascript" src="../../../../../index.js"></script>
      <script type="text/javascript" src="../../../../../lib/scheduler.js"></script>
      <script type="text/javascript" src="../../../../../lib/template.js"></script>
      
      <script type="text/javascript">
        /* this variable can be used by the JS to determine the path to the root document */
        var toRoot = '../../../../../';
      </script>
    
        </head>
        <body>
      <div id="search">
        <span id="doc-title">Spark NLP 5.5.0 ScalaDoc<span id="doc-version"></span></span>
        <span class="close-results"><span class="left">&lt;</span> Back</span>
        <div id="textfilter">
          <span class="input">
            <input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/" />
            <i class="clear material-icons"></i>
            <i id="search-icon" class="material-icons"></i>
          </span>
        </div>
    </div>
      <div id="search-results">
        <div id="search-progress">
          <div id="progress-fill"></div>
        </div>
        <div id="results-content">
          <div id="entity-results"></div>
          <div id="member-results"></div>
        </div>
      </div>
      <div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;">
        <div id="content-container" style="-webkit-overflow-scrolling: touch;">
          <div id="subpackage-spacer">
            <div id="packages">
              <h1>Packages</h1>
              <ul>
                <li name="_root_.root" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="_root_"></a><a id="root:_root_"></a>
      <span class="permalink">
      <a href="../../../../../index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../../../index.html"><span class="name">root</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="_root_.com" visbl="pub" class="indented1 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="com"></a><a id="com:com"></a>
      <span class="permalink">
      <a href="../../../../../com/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../../index.html"><span class="name">com</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../../index.html" class="extype" name="_root_">root</a></dd></dl></div>
    </li><li name="com.johnsnowlabs" visbl="pub" class="indented2 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="johnsnowlabs"></a><a id="johnsnowlabs:johnsnowlabs"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../../index.html"><span class="name">johnsnowlabs</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../../index.html" class="extype" name="com">com</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp" visbl="pub" class="indented3 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="nlp"></a><a id="nlp:nlp"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../../index.html"><span class="name">nlp</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../../index.html" class="extype" name="com.johnsnowlabs">johnsnowlabs</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators" visbl="pub" class="indented4 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="annotators"></a><a id="annotators:annotators"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../index.html"><span class="name">annotators</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../../index.html" class="extype" name="com.johnsnowlabs.nlp">nlp</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.audio" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="audio"></a><a id="audio:audio"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/audio/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../audio/index.html"><span class="name">audio</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.btm" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="btm"></a><a id="btm:btm"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/btm/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../btm/index.html"><span class="name">btm</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.classifier" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="classifier"></a><a id="classifier:classifier"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/classifier/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../classifier/index.html"><span class="name">classifier</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.common" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="common"></a><a id="common:common"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/common/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../common/index.html"><span class="name">common</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.coref" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="coref"></a><a id="coref:coref"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/coref/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../coref/index.html"><span class="name">coref</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.cv" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="cv"></a><a id="cv:cv"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/cv/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../cv/index.html"><span class="name">cv</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.er" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="er"></a><a id="er:er"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/er/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../er/index.html"><span class="name">er</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.keyword" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="keyword"></a><a id="keyword:keyword"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/keyword/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../keyword/index.html"><span class="name">keyword</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.ld" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ld"></a><a id="ld:ld"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/ld/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../ld/index.html"><span class="name">ld</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.ner" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ner"></a><a id="ner:ner"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/ner/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../ner/index.html"><span class="name">ner</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.param" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="param"></a><a id="param:param"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/param/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../param/index.html"><span class="name">param</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.parser" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="parser"></a><a id="parser:parser"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/parser/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../parser/index.html"><span class="name">parser</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.pos" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="pos"></a><a id="pos:pos"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/pos/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../pos/index.html"><span class="name">pos</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.sbd" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sbd"></a><a id="sbd:sbd"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/sbd/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../sbd/index.html"><span class="name">sbd</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.sda" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sda"></a><a id="sda:sda"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/sda/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../sda/index.html"><span class="name">sda</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.sentence_detector_dl" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="sentence_detector_dl"></a><a id="sentence_detector_dl:sentence_detector_dl"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/sentence_detector_dl/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../sentence_detector_dl/index.html"><span class="name">sentence_detector_dl</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq" visbl="pub" class="indented5 current" data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="seq2seq"></a><a id="seq2seq:seq2seq"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">seq2seq</span>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li class="current-entities indented5">
                        <a class="object" href="AutoGGUFModel$.html" title="This is the companion object of AutoGGUFModel."></a>
                        <a class="class" href="AutoGGUFModel.html" title="Annotator that uses the llama.cpp library to generate text completions with large language models."></a>
                        <a href="AutoGGUFModel.html" title="Annotator that uses the llama.cpp library to generate text completions with large language models.">AutoGGUFModel</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="BartTransformer$.html" title=""></a>
                        <a class="class" href="BartTransformer.html" title="BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer"></a>
                        <a href="BartTransformer.html" title="BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer">BartTransformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="CPMTransformer$.html" title=""></a>
                        <a class="class" href="CPMTransformer.html" title="MiniCPM: Unveiling the Potential of End-side Large Language Models"></a>
                        <a href="CPMTransformer.html" title="MiniCPM: Unveiling the Potential of End-side Large Language Models">CPMTransformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="GPT2Transformer$.html" title=""></a>
                        <a class="class" href="GPT2Transformer.html" title="GPT-2: the OpenAI Text-To-Text Transformer"></a>
                        <a href="GPT2Transformer.html" title="GPT-2: the OpenAI Text-To-Text Transformer">GPT2Transformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="LLAMA2Transformer$.html" title=""></a>
                        <a class="class" href="LLAMA2Transformer.html" title="Llama 2: Open Foundation and Fine-Tuned Chat Models"></a>
                        <a href="LLAMA2Transformer.html" title="Llama 2: Open Foundation and Fine-Tuned Chat Models">LLAMA2Transformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="LLAMA3Transformer$.html" title=""></a>
                        <a class="class" href="LLAMA3Transformer.html" title="Llama 3: Cutting-Edge Foundation and Fine-Tuned Chat Models"></a>
                        <a href="LLAMA3Transformer.html" title="Llama 3: Cutting-Edge Foundation and Fine-Tuned Chat Models">LLAMA3Transformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="M2M100Transformer$.html" title=""></a>
                        <a class="class" href="M2M100Transformer.html" title="M2M100 : multilingual translation model"></a>
                        <a href="M2M100Transformer.html" title="M2M100 : multilingual translation model">M2M100Transformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="MarianTransformer$.html" title="This is the companion object of MarianTransformer."></a>
                        <a class="class" href="MarianTransformer.html" title="MarianTransformer: Fast Neural Machine Translation"></a>
                        <a href="MarianTransformer.html" title="MarianTransformer: Fast Neural Machine Translation">MarianTransformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="MistralTransformer$.html" title=""></a>
                        <a class="class" href="MistralTransformer.html" title="Mistral 7B"></a>
                        <a href="MistralTransformer.html" title="Mistral 7B">MistralTransformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="NLLBTransformer$.html" title=""></a>
                        <a class="class" href="NLLBTransformer.html" title="NLLB : multilingual translation model"></a>
                        <a href="NLLBTransformer.html" title="NLLB : multilingual translation model">NLLBTransformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="Phi2Transformer$.html" title=""></a>
                        <a class="class" href="Phi2Transformer.html" title="Phi-2: Textbooks Are All You Need."></a>
                        <a href="Phi2Transformer.html" title="Phi-2: Textbooks Are All You Need.">Phi2Transformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="Phi3Transformer$.html" title=""></a>
                        <a class="class" href="Phi3Transformer.html" title="Phi-3"></a>
                        <a href="Phi3Transformer.html" title="Phi-3">Phi3Transformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="QwenTransformer$.html" title=""></a>
                        <a class="class" href="QwenTransformer.html" title="Qwen: comprehensive language model series"></a>
                        <a href="QwenTransformer.html" title="Qwen: comprehensive language model series">QwenTransformer</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadAutoGGUFModel.html" title=""></a>
                        <a href="ReadAutoGGUFModel.html" title="">ReadAutoGGUFModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadBartTransformerDLModel.html" title=""></a>
                        <a href="ReadBartTransformerDLModel.html" title="">ReadBartTransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadCPMTransformerDLModel.html" title=""></a>
                        <a href="ReadCPMTransformerDLModel.html" title="">ReadCPMTransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadGPT2TransformerDLModel.html" title=""></a>
                        <a href="ReadGPT2TransformerDLModel.html" title="">ReadGPT2TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadLLAMA2TransformerDLModel.html" title=""></a>
                        <a href="ReadLLAMA2TransformerDLModel.html" title="">ReadLLAMA2TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadLLAMA3TransformerDLModel.html" title=""></a>
                        <a href="ReadLLAMA3TransformerDLModel.html" title="">ReadLLAMA3TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadM2M100TransformerDLModel.html" title=""></a>
                        <a href="ReadM2M100TransformerDLModel.html" title="">ReadM2M100TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadMarianMTDLModel.html" title=""></a>
                        <a href="ReadMarianMTDLModel.html" title="">ReadMarianMTDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadMistralTransformerDLModel.html" title=""></a>
                        <a href="ReadMistralTransformerDLModel.html" title="">ReadMistralTransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadNLLBTransformerDLModel.html" title=""></a>
                        <a href="ReadNLLBTransformerDLModel.html" title="">ReadNLLBTransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadPhi2TransformerDLModel.html" title=""></a>
                        <a href="ReadPhi2TransformerDLModel.html" title="">ReadPhi2TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadPhi3TransformerDLModel.html" title=""></a>
                        <a href="ReadPhi3TransformerDLModel.html" title="">ReadPhi3TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadQwenTransformerDLModel.html" title=""></a>
                        <a href="ReadQwenTransformerDLModel.html" title="">ReadQwenTransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadStarCoderTransformerDLModel.html" title=""></a>
                        <a href="ReadStarCoderTransformerDLModel.html" title="">ReadStarCoderTransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadT5TransformerDLModel.html" title=""></a>
                        <a href="ReadT5TransformerDLModel.html" title="">ReadT5TransformerDLModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedAutoGGUFModel.html" title=""></a>
                        <a href="ReadablePretrainedAutoGGUFModel.html" title="">ReadablePretrainedAutoGGUFModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedBartTransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedBartTransformerModel.html" title="">ReadablePretrainedBartTransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedCPMTransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedCPMTransformerModel.html" title="">ReadablePretrainedCPMTransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedGPT2TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedGPT2TransformerModel.html" title="">ReadablePretrainedGPT2TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedLLAMA2TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedLLAMA2TransformerModel.html" title="">ReadablePretrainedLLAMA2TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedLLAMA3TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedLLAMA3TransformerModel.html" title="">ReadablePretrainedLLAMA3TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedM2M100TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedM2M100TransformerModel.html" title="">ReadablePretrainedM2M100TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedMarianMTModel.html" title=""></a>
                        <a href="ReadablePretrainedMarianMTModel.html" title="">ReadablePretrainedMarianMTModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedMistralTransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedMistralTransformerModel.html" title="">ReadablePretrainedMistralTransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedNLLBTransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedNLLBTransformerModel.html" title="">ReadablePretrainedNLLBTransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedPhi2TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedPhi2TransformerModel.html" title="">ReadablePretrainedPhi2TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedPhi3TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedPhi3TransformerModel.html" title="">ReadablePretrainedPhi3TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedQwenTransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedQwenTransformerModel.html" title="">ReadablePretrainedQwenTransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedStarCoderTransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedStarCoderTransformerModel.html" title="">ReadablePretrainedStarCoderTransformerModel</a>
                      </li><li class="current-entities indented5">
                        <span class="separator"></span>
                        <a class="trait" href="ReadablePretrainedT5TransformerModel.html" title=""></a>
                        <a href="ReadablePretrainedT5TransformerModel.html" title="">ReadablePretrainedT5TransformerModel</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="StarCoderTransformer$.html" title=""></a>
                        <a class="class" href="StarCoderTransformer.html" title="StarCoder2: The Versatile Code Companion."></a>
                        <a href="StarCoderTransformer.html" title="StarCoder2: The Versatile Code Companion.">StarCoderTransformer</a>
                      </li><li class="current-entities indented5">
                        <a class="object" href="T5Transformer$.html" title="This is the companion object of T5Transformer."></a>
                        <a class="class" href="T5Transformer.html" title="T5: the Text-To-Text Transfer Transformer"></a>
                        <a href="T5Transformer.html" title="T5: the Text-To-Text Transfer Transformer">T5Transformer</a>
                      </li><li name="com.johnsnowlabs.nlp.annotators.similarity" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="similarity"></a><a id="similarity:similarity"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/similarity/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../similarity/index.html"><span class="name">similarity</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.spell" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="spell"></a><a id="spell:spell"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/spell/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../spell/index.html"><span class="name">spell</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.tapas" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="tapas"></a><a id="tapas:tapas"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/tapas/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../tapas/index.html"><span class="name">tapas</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.tokenizer" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="tokenizer"></a><a id="tokenizer:tokenizer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/tokenizer/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../tokenizer/index.html"><span class="name">tokenizer</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.ws" visbl="pub" class="indented5 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="ws"></a><a id="ws:ws"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/ws/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <a title="" href="../ws/index.html"><span class="name">ws</span></a>
      </span>
      
      <div class="fullcomment"><dl class="attributes block"> <dt>Definition Classes</dt><dd><a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></dd></dl></div>
    </li>
              </ul>
            </div>
          </div>
          <div id="content">
            <body class="package value">
      <div id="definition">
        <div class="big-circle package">p</div>
        <p id="owner"><a href="../../../../index.html" class="extype" name="com">com</a>.<a href="../../../index.html" class="extype" name="com.johnsnowlabs">johnsnowlabs</a>.<a href="../../index.html" class="extype" name="com.johnsnowlabs.nlp">nlp</a>.<a href="../index.html" class="extype" name="com.johnsnowlabs.nlp.annotators">annotators</a></p>
        <h1>seq2seq<span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/index.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span></h1>
        
      </div>

      <h4 id="signature" class="signature">
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">package</span>
      </span>
      <span class="symbol">
        <span class="name">seq2seq</span>
      </span>
      </h4>

      
          <div id="comment" class="fullcommenttop"></div>
        

      <div id="mbrsel">
        <div class="toggle"></div>
        <div id="memberfilter">
          <i class="material-icons arrow"></i>
          <span class="input">
            <input id="mbrsel-input" placeholder="Filter all members" type="text" accesskey="/" />
          </span>
          <i class="clear material-icons"></i>
        </div>
        <div id="filterby">
          <div id="order">
            <span class="filtertype">Ordering</span>
            <ol>
              
              <li class="alpha in"><span>Alphabetic</span></li>
              
            </ol>
          </div>
          
          <div id="visbl">
              <span class="filtertype">Visibility</span>
              <ol><li class="public in"><span>Public</span></li><li class="all out"><span>All</span></li></ol>
            </div>
        </div>
      </div>

      <div id="template">
        <div id="allMembers">
        

        <div id="types" class="types members">
              <h3>Type Members</h3>
              <ol><li name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="AutoGGUFModelextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel]withHasEnginewithHasLlamaCppPropertieswithHasProtectedParams"></a><a id="AutoGGUFModel:AutoGGUFModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/AutoGGUFModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Annotator that uses the llama.cpp library to generate text completions with large language models." href="AutoGGUFModel.html"><span class="name">AutoGGUFModel</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="AutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel">AutoGGUFModel</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="AutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel">AutoGGUFModel</a>] with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a> with <a href="../../HasLlamaCppProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasLlamaCppProperties">HasLlamaCppProperties</a> with <a href="../../HasProtectedParams.html" class="extype" name="com.johnsnowlabs.nlp.HasProtectedParams">HasProtectedParams</a></span>
      </span>
      
      <p class="shortcomment cmt">Annotator that uses the llama.cpp library to generate text completions with large language
models.</p><div class="fullcomment"><div class="comment cmt"><p>Annotator that uses the llama.cpp library to generate text completions with large language
models.</p><p>For settable parameters, and their explanations, see <a href="../../HasLlamaCppProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasLlamaCppProperties">HasLlamaCppProperties</a> and refer to
the llama.cpp documentation of
<a href="https://github.com/ggerganov/llama.cpp/tree/7d5e8777ae1d21af99d4f95be10db4870720da91/examples/server" target="_blank">server.cpp</a>
for more information.</p><p>If the parameters are not set, the annotator will default to use the parameters provided by
the model.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> autoGGUFModel = AutoGGUFModel.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"completions"</span>)</pre><p>The default model is <code>&quot;phi3.5_mini_4k_instruct_q4_gguf&quot;</code>, if no name is provided.</p><p>For available pretrained models please see the <a href="https://sparknlp.org/models" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see the
<a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/AutoGGUFModelTest.scala" target="_blank">AutoGGUFModelTest</a>
and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/examples/python/llama.cpp/llama.cpp_in_Spark_NLP_AutoGGUFModel.ipynb" target="_blank">example notebook</a>.</p><h4>Note</h4><p>To use GPU inference with this annotator, make sure to use the Spark NLP GPU package and set
the number of GPU layers with the <code>setNGpuLayers</code> method.</p><p>When using larger models, we recommend adjusting GPU usage with <code>setNCtx</code> and <code>setNGpuLayers</code>
according to your hardware to avoid out-of-memory errors.</p><h4>Example</h4><pre><span class="kw">import</span> com.johnsnowlabs.nlp.base._
<span class="kw">import</span> com.johnsnowlabs.nlp.annotator._
<span class="kw">import</span> org.apache.spark.ml.Pipeline
<span class="kw">import</span> spark.implicits._

<span class="kw">val</span> document = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"document"</span>)

<span class="kw">val</span> autoGGUFModel = AutoGGUFModel
  .pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"completions"</span>)
  .setBatchSize(<span class="num">4</span>)
  .setNPredict(<span class="num">20</span>)
  .setNGpuLayers(<span class="num">99</span>)
  .setTemperature(<span class="num">0.4</span>f)
  .setTopK(<span class="num">40</span>)
  .setTopP(<span class="num">0.9</span>f)
  .setPenalizeNl(<span class="kw">true</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(document, autoGGUFModel))

<span class="kw">val</span> data = <span class="std">Seq</span>(<span class="lit">"Hello, I am a"</span>).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)
result.select(<span class="lit">"completions"</span>).show(truncate = <span class="kw">false</span>)
+-----------------------------------------------------------------------------------------------------------------------------------+
|completions                                                                                                                        |
+-----------------------------------------------------------------------------------------------------------------------------------+
|[{document, <span class="num">0</span>, <span class="num">78</span>,  <span class="kw">new</span> user.  I am currently working on a project and I need to create a list of , {prompt -&gt; Hello, I am a}, []}]|
+-----------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="BartTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer]withParamsAndFeaturesWritablewithWriteTensorflowModelwithWriteOnnxModelwithHasEnginewithHasGeneratorProperties"></a><a id="BartTransformer:BartTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/BartTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension Transformer" href="BartTransformer.html"><span class="name">BartTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="BartTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer">BartTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="BartTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer">BartTransformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/tensorflow/WriteTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.WriteTensorflowModel">WriteTensorflowModel</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a></span>
      </span>
      
      <p class="shortcomment cmt">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,
Translation, and Comprehension Transformer</p><div class="fullcomment"><div class="comment cmt"><p>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,
Translation, and Comprehension Transformer</p><p>The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art
language generation model that was introduced by Facebook AI in 2019. It is based on the
transformer architecture and is designed to handle a wide range of natural language processing
tasks such as text generation, summarization, and machine translation.</p><p>BART is unique in that it is both bidirectional and auto-regressive, meaning that it can
generate text both from left-to-right and from right-to-left. This allows it to capture
contextual information from both past and future tokens in a sentence,resulting in more
accurate and natural language generation.</p><p>The model was trained on a large corpus of text data using a combination of unsupervised and
supervised learning techniques. It incorporates pretraining and fine-tuning phases, where the
model is first trained on a large unlabeled corpus of text, and then fine-tuned on specific
downstream tasks.</p><p>BART has achieved state-of-the-art performance on a wide range of NLP tasks, including
summarization, question-answering, and language translation. Its ability to handle multiple
tasks and its high performance on each of these tasks make it a versatile and valuable tool
for natural language processing applications.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> bart = BartTransformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;distilbart_xsum_12_6&quot;</code>, if no name is provided. For available
pretrained models please see the <a href="https://sparknlp.org/models?q=bart" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/BartTestSpec.scala" target="_blank">BartTestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://aclanthology.org/2020.acl-main.703.pdf" target="_blank">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></li><li><a href="https://github.com/pytorch/fairseq" target="_blank">https://github.com/pytorch/fairseq</a></li></ul><p><b>Paper Abstract:</b></p><p><i> We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART
is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model
to reconstruct the original text. It uses a standard Tranformer-based neural machine
translation architecture which, despite its simplicity, can be seen as generalizing BERT (due
to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent
pretraining schemes. We evaluate a number of noising approaches, finding the best performance
by both randomly shuffling the order of sentences and using a novel in-filling scheme, where
spans of text are replaced with a single mask token. BART is particularly effective when fine
tuned for text generation but also works well for comprehension tasks. It matches the
performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range
of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5
ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine
translation, with only target language pretraining. We also replicate other pretraining
schemes within the BART framework, to understand their effect on end-task performance </i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> bart = BartTransformer.pretrained(<span class="lit">"distilbart_xsum_12_6"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">30</span>)
  .setDoSample(<span class="kw">true</span>)
  .setTopK(<span class="num">50</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, bart))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"PG&E stated it scheduled the blackouts in response to forecasts for high winds "</span> +
  <span class="lit">"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were "</span> +
  <span class="lit">"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+--------------------------------------------------------------+
|result                                                        |
+--------------------------------------------------------------+
|[Nearly <span class="num">800</span> thousand customers were affected by the shutoffs.]|
+--------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="CPMTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithWriteSentencePieceModelwithHasEngine"></a><a id="CPMTransformer:CPMTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/CPMTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="MiniCPM: Unveiling the Potential of End-side Large Language Models" href="CPMTransformer.html"><span class="name">CPMTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="CPMTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer">CPMTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="CPMTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer">CPMTransformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">MiniCPM: Unveiling the Potential of End-side Large Language Models</p><div class="fullcomment"><div class="comment cmt"><p>MiniCPM: Unveiling the Potential of End-side Large Language Models</p><p>MiniCPM is a series of edge-side large language models, with the base model, MiniCPM-2B,
having 2.4B non-embedding parameters. It ranks closely with Mistral-7B on comprehensive
benchmarks (with better performance in Chinese, mathematics, and coding abilities), surpassing
models like Llama2-13B, MPT-30B, and Falcon-40B. On the MTBench benchmark, which is closest to
user experience, MiniCPM-2B also outperforms many representative open-source models such as
Llama2-70B-Chat, Vicuna-33B, Mistral-7B-Instruct-v0.1, and Zephyr-7B-alpha.</p><p>After DPO, MiniCPM outperforms Llama2-70B-Chat, Vicuna-33B, Mistral-7B-Instruct-v0.1,
Zephyr-7B-alpha, etc. on MTBench.</p><p>MiniCPM-V, based on MiniCPM-2B, achieves the best overall performance among multimodel models
of the same scale, surpassing existing multimodal large models built on Phi-2 and achieving
performance comparable to or even better than 9.6B Qwen-VL-Chat on some tasks.</p><p>MiniCPM can be deployed and infer on smartphones, and the speed of streaming output is
relatively higher than the verbal speed of human.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> cpm = CPMTransformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;llama_2_7b_chat_hf_int4&quot;</code>, if no name is provided. For available
pretrained models please see the <a href="https://sparknlp.org/models?q=cpm" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/CPMTestSpec.scala" target="_blank">CPMTestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20" target="_blank">MiniCPM: Unveiling the Potential of End-side Large Language Models</a></li><li><a href="https://github.com/OpenBMB/MiniCPM" target="_blank">https://github.com/OpenBMB/MiniCPM</a></li></ul><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> cpm = CPMTransformer.pretrained(<span class="lit">"llama_2_7b_chat_hf_int4"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, cpm))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                                 |
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[ My name is Leonardo. I am a student at the University of California, Los Angeles. I have a passion <span class="kw">for</span> writing and learning about different cultures. I enjoy playing basketball and watching movies]|
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="GPT2TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer]withParamsAndFeaturesWritablewithWriteTensorflowModelwithWriteOnnxModelwithHasEngine"></a><a id="GPT2Transformer:GPT2Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="GPT-2: the OpenAI Text-To-Text Transformer" href="GPT2Transformer.html"><span class="name">GPT2Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="GPT2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer">GPT2Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="GPT2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer">GPT2Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/tensorflow/WriteTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.WriteTensorflowModel">WriteTensorflowModel</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">GPT-2: the OpenAI Text-To-Text Transformer</p><div class="fullcomment"><div class="comment cmt"><p>GPT-2: the OpenAI Text-To-Text Transformer</p><p>GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a
dataset of 8 million web pages. GPT-2 is trained with a simple objective: predict the next
word, given all of the previous words within some text. The diversity of the dataset causes
this simple goal to contain naturally occurring demonstrations of many tasks across diverse
domains. GPT-2 is a direct scale-up of GPT, with more than 10X the parameters and trained on
more than 10X the amount of data.</p><p>GPT-2 displays a broad set of capabilities, including the ability to generate conditional
synthetic text samples of unprecedented quality, where we prime the model with an input and
have it generate a lengthy continuation. In addition, GPT-2 outperforms other language models
trained on specific domains (like Wikipedia, news, or books) without needing to use these
domain-specific training datasets. On language tasks like question answering, reading
comprehension, summarization, and translation, GPT-2 begins to learn these tasks from the raw
text, using no task-specific training data. While scores on these downstream tasks are far
from state-of-the-art, they suggest that the tasks can benefit from unsupervised techniques,
given sufficient (unlabeled) data and compute.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> gpt2 = GPT2Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;gpt2&quot;</code>, if no name is provided. For available pretrained models please
see the <a href="https://sparknlp.org/models?q=gpt2" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2TestSpec.scala" target="_blank">GPT2TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank">Language Models are Unsupervised Multitask Learners</a></li><li><a href="https://github.com/openai/gpt-2" target="_blank">https://github.com/openai/gpt-2</a></li></ul><p><b>Paper Abstract:</b></p><p><i>Natural language processing tasks, such as question answering, machine translation, reading
comprehension, and summarization, are typically approached with supervised learning on
taskspecific datasets. We demonstrate that language models begin to learn these tasks without
any explicit supervision when trained on a new dataset of millions of webpages called WebText.
When conditioned on a document plus questions, the answers generated by the language model
reach F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline
systems without using the 127,000+ training examples. The capacity of the language model is
essential to the success of zero-shot task transfer and increasing it improves performance in
a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer
that achieves state of the art results on 7 out of 8 tested language modeling datasets in a
zero-shot setting but still underfits WebText. Samples from the model reflect these
improvements and contain coherent paragraphs of text. These findings suggest a promising path
towards building language processing systems which learn to perform tasks from their naturally
occurring demonstrations.</i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> gpt2 = GPT2Transformer.pretrained(<span class="lit">"gpt2"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, gpt2))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[ My name is Leonardo. I am a man of letters. I have been a man <span class="kw">for</span> many years. I was born in the year <span class="num">1776.</span> I came to the United States in <span class="num">1776</span>, and I have lived in the United Kingdom since <span class="num">1776</span>]|
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="LLAMA2TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithWriteSentencePieceModelwithHasEngine"></a><a id="LLAMA2Transformer:LLAMA2Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/LLAMA2Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Llama 2: Open Foundation and Fine-Tuned Chat Models" href="LLAMA2Transformer.html"><span class="name">LLAMA2Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="LLAMA2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer">LLAMA2Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="LLAMA2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer">LLAMA2Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">Llama 2: Open Foundation and Fine-Tuned Chat Models</p><div class="fullcomment"><div class="comment cmt"><p>Llama 2: Open Foundation and Fine-Tuned Chat Models</p><p>The Llama 2 release introduces a family of pretrained and fine-tuned LLMs, ranging in scale
from 7B to 70B parameters (7B, 13B, 70B). The pretrained models come with significant
improvements over the Llama 1 models, including being trained on 40% more tokens, having a
much longer context length (4k tokens 🤯), and using grouped-query attention for fast
inference of the 70B model🔥!</p><p>However, the most exciting part of this release is the fine-tuned models (Llama 2-Chat), which
have been optimized for dialogue applications using Reinforcement Learning from Human Feedback
(RLHF). Across a wide range of helpfulness and safety benchmarks, the Llama 2-Chat models
perform better than most open models and achieve comparable performance to ChatGPT according
to human evaluations.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> llama2 = LLAMA2Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;llama_2_7b_chat_hf_int4&quot;</code>, if no name is provided. For available
pretrained models please see the <a href="https://sparknlp.org/models?q=llama2" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/LLAMA2TestSpec.scala" target="_blank">LLAMA2TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/" target="_blank">Llama 2: Open Foundation and Fine-Tuned Chat Models</a></li><li><a href="https://github.com/facebookresearch/llama" target="_blank">https://github.com/facebookresearch/llama</a></li></ul><p><b>Paper Abstract:</b></p><p><i>In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned
large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our
fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models
outperform open-source chat models on most benchmarks we tested, and based on our human
evaluations for helpfulness and safety, may be a suitable substitute for closed-source models.
We provide a detailed description of our approach to fine-tuning and safety improvements of
Llama 2-Chat in order to enable the community to build on our work and contribute to the
responsible development of LLMs.</i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> llama2 = LLAMA2Transformer.pretrained(<span class="lit">"llama_2_7b_chat_hf_int4"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, llama2))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[ My name is Leonardo. I am a man of letters. I have been a man <span class="kw">for</span> many years. I was born in the year <span class="num">1776.</span> I came to the United States in <span class="num">1776</span>, and I have lived in the United Kingdom since <span class="num">1776</span>]|
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="LLAMA3TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithHasEngine"></a><a id="LLAMA3Transformer:LLAMA3Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/LLAMA3Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Llama 3: Cutting-Edge Foundation and Fine-Tuned Chat Models" href="LLAMA3Transformer.html"><span class="name">LLAMA3Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="LLAMA3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer">LLAMA3Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="LLAMA3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer">LLAMA3Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">Llama 3: Cutting-Edge Foundation and Fine-Tuned Chat Models</p><div class="fullcomment"><div class="comment cmt"><p>Llama 3: Cutting-Edge Foundation and Fine-Tuned Chat Models</p><p>The Llama 3 release introduces a new family of large language models, ranging from 8B to 70B
parameters. Llama 3 models are designed with a greater emphasis on efficiency, performance,
and safety, achieving remarkable advancements in training and deployment processes. These
models are trained on a diversified dataset that significantly enhances their capability to
generate more accurate and contextually relevant outputs.</p><p>The fine-tuned variants, known as Llama 3-instruct, are specifically optimized for
dialogue-based applications, making use of Reinforcement Learning from Human Feedback (RLHF)
with an advanced reward model. Llama 3-instruct models demonstrate state-of-the-art
performance across multiple benchmarks and surpass the capabilities of Llama 2, particularly
in conversational settings.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> llama3 = LLAMA3Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;llama_3_7b_chat_hf_int8&quot;</code>, if no name is provided. For available
pretrained models please see the <a href="https://sparknlp.org/models?q=llama3" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/LLAMA3TestSpec.scala" target="_blank">LLAMA3TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://ai.meta.com/blog/meta-llama-3/" target="_blank">Meta's Llama 3: Cutting-Edge Foundation and Fine-Tuned Chat Models</a></li><li><a href="https://github.com/facebookresearch/llama" target="_blank">https://github.com/facebookresearch/llama</a></li></ul><p><b>Paper Abstract:</b></p><p><i>Llama 3 represents Meta’s latest innovation in the development of large language models
(LLMs), offering a series of models from 1 billion to 70 billion parameters. These models have
been fine-tuned for dialogue applications under the Llama 3-Chat series, ensuring they are
highly responsive and context-aware. Our Llama 3 models not only excel in various benchmarks
but also incorporate enhanced safety and alignment features to address ethical concerns and
ensure responsible AI deployment. We invite the community to explore the capabilities of Llama
3 and contribute to ongoing research in the field of natural language processing.</i></p><p><b>Note:</b></p><p>This is a resource-intensive module, especially with larger models and sequences. Use of
accelerators such as GPUs is strongly recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> llama3 = LLAMA3Transformer.pretrained(<span class="lit">"llama_3_7b_chat_hf_int8"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">15</span>)
  .setMaxOutputLength(<span class="num">60</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">40</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, llama3))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  (
    <span class="num">1</span>,
    <span class="lit">""</span><span class="lit">"&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;

    You are a minion chatbot who always responds in minion speak!

    &lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;

    Who are you?

    &lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;
    "</span><span class="lit">""</span>.stripMargin)
).toDF(<span class="lit">"id"</span>, <span class="lit">"text"</span>)

<span class="kw">val</span> result = pipeline.fit(data).transform(data)

result.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                                  |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[Oooh, me am Minion! Me help you <span class="kw">with</span> things! Me speak Minion language, yeah! Bana-na-na!]                                                                         |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="M2M100TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithWriteSentencePieceModelwithHasEngine"></a><a id="M2M100Transformer:M2M100Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/M2M100Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="M2M100 : multilingual translation model" href="M2M100Transformer.html"><span class="name">M2M100Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="M2M100Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer">M2M100Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="M2M100Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer">M2M100Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">M2M100 : multilingual translation model</p><div class="fullcomment"><div class="comment cmt"><p>M2M100 : multilingual translation model</p><p>M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many
multilingual translation.</p><p>The model can directly translate between the 9,900 directions of 100 languages.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> m2m100 = M2M100Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;m2m100_418M&quot;</code>, if no name is provided. For available pretrained models
please see the <a href="https://sparknlp.org/models?q=m2m100" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/M2M100TestSpec.scala" target="_blank">M2M100TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://arxiv.org/pdf/2010.11125.pdf" target="_blank">Beyond English-Centric Multilingual Machine Translation</a></li><li><a href="https://github.com/pytorch/fairseq/tree/master/examples/m2m_100" target="_blank">https://github.com/pytorch/fairseq/tree/master/examples/m2m_100</a></li></ul><p><b>Paper Abstract:</b></p><p><i>Existing work in translation demonstrated the potential of massively multilingual machine
translation by training a single model able to translate between any pair of languages.
However, much of this work is English-Centric by training only on data which was translated
from or to English. While this is supported by large sources of training data, it does not
reflect translation needs worldwide. In this work, we create a true Many-to-Many multilingual
translation model that can translate directly between any pair of 100 languages. We build and
open source a training dataset that covers thousands of language directions with supervised
data, created through large-scale mining. Then, we explore how to effectively increase model
capacity through a combination of dense scaling and language-specific sparse parameters to
create high quality models. Our focus on non-English-Centric models brings gains of more than
10 BLEU when directly translating between non-English directions while performing
competitively to the best single systems of WMT. We open-source our scripts so that others may
reproduce the data, evaluation, and final M2M-100 model.</i></p><p><b>Languages Covered:</b></p><p>Afrikaans (af), Amharic (am), Arabic (ar), Asturian (ast), Azerbaijani (az), Bashkir (ba),
Belarusian (be), Bulgarian (bg), Bengali (bn), Breton (br), Bosnian (bs), Catalan; Valencian
(ca), Cebuano (ceb), Czech (cs), Welsh (cy), Danish (da), German (de), Greeek (el), English
(en), Spanish (es), Estonian (et), Persian (fa), Fulah (ff), Finnish (fi), French (fr),
Western Frisian (fy), Irish (ga), Gaelic; Scottish Gaelic (gd), Galician (gl), Gujarati (gu),
Hausa (ha), Hebrew (he), Hindi (hi), Croatian (hr), Haitian; Haitian Creole (ht), Hungarian
(hu), Armenian (hy), Indonesian (id), Igbo (ig), Iloko (ilo), Icelandic (is), Italian (it),
Japanese (ja), Javanese (jv), Georgian (ka), Kazakh (kk), Central Khmer (km), Kannada (kn),
Korean (ko), Luxembourgish; Letzeburgesch (lb), Ganda (lg), Lingala (ln), Lao (lo), Lithuanian
(lt), Latvian (lv), Malagasy (mg), Macedonian (mk), Malayalam (ml), Mongolian (mn), Marathi
(mr), Malay (ms), Burmese (my), Nepali (ne), Dutch; Flemish (nl), Norwegian (no), Northern
Sotho (ns), Occitan (post 1500) (oc), Oriya (or), Panjabi; Punjabi (pa), Polish (pl), Pushto;
Pashto (ps), Portuguese (pt), Romanian; Moldavian; Moldovan (ro), Russian (ru), Sindhi (sd),
Sinhala; Sinhalese (si), Slovak (sk), Slovenian (sl), Somali (so), Albanian (sq), Serbian
(sr), Swati (ss), Sundanese (su), Swedish (sv), Swahili (sw), Tamil (ta), Thai (th), Tagalog
(tl), Tswana (tn), Turkish (tr), Ukrainian (uk), Urdu (ur), Uzbek (uz), Vietnamese (vi), Wolof
(wo), Xhosa (xh), Yiddish (yi), Yoruba (yo), Chinese (zh), Zulu (zu)</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> m2m100 = M2M100Transformer.pretrained(<span class="lit">"m2m100_418M"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setSrcLang(<span class="lit">"zh"</span>)
  .serTgtLang(<span class="lit">"en"</span>)
  .setMaxOutputLength(<span class="num">100</span>)
  .setDoSample(<span class="kw">false</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, m2m100))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"生活就像一盒巧克力。"</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+-------------------------------------------------------------------------------------------+
|result                                                                                     |
+-------------------------------------------------------------------------------------------+
|[ Life is like a box of chocolate.]                                                        |
+-------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="MarianTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer]withWriteTensorflowModelwithWriteOnnxModelwithWriteSentencePieceModelwithHasEnginewithHasProtectedParams"></a><a id="MarianTransformer:MarianTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="MarianTransformer: Fast Neural Machine Translation" href="MarianTransformer.html"><span class="name">MarianTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="MarianTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer">MarianTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="MarianTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer">MarianTransformer</a>] with <a href="../../../ml/tensorflow/WriteTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.WriteTensorflowModel">WriteTensorflowModel</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a> with <a href="../../HasProtectedParams.html" class="extype" name="com.johnsnowlabs.nlp.HasProtectedParams">HasProtectedParams</a></span>
      </span>
      
      <p class="shortcomment cmt">MarianTransformer: Fast Neural Machine Translation</p><div class="fullcomment"><div class="comment cmt"><p>MarianTransformer: Fast Neural Machine Translation</p><p>Marian is an efficient, free Neural Machine Translation framework written in pure C++ with
minimal dependencies. It is mainly being developed by the Microsoft Translator team. Many
academic (most notably the University of Edinburgh and in the past the Adam Mickiewicz
University in Poznań) and commercial contributors help with its development. MarianTransformer
uses the models trained by MarianNMT.</p><p>It is currently the engine behind the Microsoft Translator Neural Machine Translation services
and being deployed by many companies, organizations and research projects.</p><p>Note that this model only supports inputs up to 512 tokens. If you are working with longer
inputs, consider splitting them first. For example, you can use the SentenceDetectorDL
annotator to split longer texts into sentences first.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> marian = MarianTransformer.pretrained()
  .setInputCols(<span class="lit">"sentence"</span>)
  .setOutputCol(<span class="lit">"translation"</span>)</pre><p>The default model is <code>&quot;opus_mt_en_fr&quot;</code>, default language is <code>&quot;xx&quot;</code> (meaning multi-lingual), if
no values are provided. For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Translation" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/multilingual/Translation_Marian.ipynb" target="_blank">Examples</a>
and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformerTestSpec.scala" target="_blank">MarianTransformerTestSpec</a>.</p><p><b>Sources</b> :</p><p><a href="https://marian-nmt.github.io/" target="_blank">MarianNMT at GitHub</a></p><p><a href="https://www.aclweb.org/anthology/P18-4020/" target="_blank">Marian: Fast Neural Machine Translation in C++</a></p><p><b>Paper Abstract:</b></p><p><i>We present Marian, an efficient and self-contained Neural Machine Translation framework with
an integrated automatic differentiation engine based on dynamic computation graphs. Marian is
written entirely in C++. We describe the design of the encoder-decoder framework and
demonstrate that a research-friendly toolkit can achieve high training and translation
speed.</i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotator.SentenceDetectorDLModel
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"document"</span>)

<span class="kw">val</span> sentence = SentenceDetectorDLModel.pretrained(<span class="lit">"sentence_detector_dl"</span>, <span class="lit">"xx"</span>)
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"sentence"</span>)

<span class="kw">val</span> marian = MarianTransformer.pretrained()
  .setInputCols(<span class="lit">"sentence"</span>)
  .setOutputCol(<span class="lit">"translation"</span>)
  .setMaxInputLength(<span class="num">30</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline()
  .setStages(<span class="std">Array</span>(
    documentAssembler,
    sentence,
    marian
  ))

<span class="kw">val</span> data = <span class="std">Seq</span>(<span class="lit">"What is the capital of France? We should know this in french."</span>).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

result.selectExpr(<span class="lit">"explode(translation.result) as result"</span>).show(<span class="kw">false</span>)
+-------------------------------------+
|result                               |
+-------------------------------------+
|Quelle est la capitale de la France ?|
|On devrait le savoir en français.    |
+-------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="MistralTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithWriteSentencePieceModelwithHasEngine"></a><a id="MistralTransformer:MistralTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/MistralTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Mistral 7B" href="MistralTransformer.html"><span class="name">MistralTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="MistralTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer">MistralTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="MistralTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer">MistralTransformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">Mistral 7B</p><div class="fullcomment"><div class="comment cmt"><p>Mistral 7B</p><p>Mistral 7B, a 7.3 billion-parameter model that stands out for its efficient and effective
performance in natural language processing. Surpassing Llama 2 13B across all benchmarks and
excelling over Llama 1 34B in various aspects, Mistral 7B strikes a balance between English
language tasks and code comprehension, rivaling the capabilities of CodeLlama 7B in the
latter.</p><p>Mistral 7B introduces Grouped-query attention (GQA) for quicker inference, enhancing
processing speed without compromising accuracy. This streamlined approach ensures a smoother
user experience, making Mistral 7B a practical choice for real-world applications.</p><p>Additionally, Mistral 7B adopts Sliding Window Attention (SWA) to efficiently handle longer
sequences at a reduced computational cost. This feature enhances the model's ability to
process extensive textual input, expanding its utility in handling more complex tasks.</p><p>In summary, Mistral 7B represents a notable advancement in language models, offering a
reliable and versatile solution for various natural language processing challenges.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> mistral = MistralTransformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;mistral_7b&quot;</code>, if no name is provided. For available pretrained models
please see the <a href="https://sparknlp.org/models?q=mistral" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/MistralTestSpec.scala" target="_blank">MistralTestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://mistral.ai/news/announcing-mistral_7b/" target="_blank">Mistral 7B</a></li><li><a href="https://github.com/mistralai/mistral-src" target="_blank">https://github.com/mistralai/mistral-src</a></li></ul><p><b>Paper Abstract:</b></p><p><i>We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior
performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated
benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model
leverages grouped-query attention (GQA) for faster inference, coupled with sliding window
attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference
cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that
surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are
released under the Apache 2.0 license.</i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> mistral = MistralTransformer.pretrained(<span class="lit">"mistral_7b"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, mistral))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
 +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
 |result                                                                                                                                                                                              |
 +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
 |[Leonardo Da Vinci invented the microscope?\n Question: Leonardo Da Vinci invented the microscope?\n Answer: No, Leonardo Da Vinci did not invent the microscope. The first microscope was invented |
 | in the late <span class="num">16</span>th century, long after Leonardo']                                                                                                                                                    |
 -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
 +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="NLLBTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithWriteSentencePieceModelwithHasEngine"></a><a id="NLLBTransformer:NLLBTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/NLLBTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="NLLB : multilingual translation model" href="NLLBTransformer.html"><span class="name">NLLBTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="NLLBTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer">NLLBTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="NLLBTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer">NLLBTransformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">NLLB : multilingual translation model</p><div class="fullcomment"><div class="comment cmt"><p>NLLB : multilingual translation model</p><p>NLLB is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many
multilingual translation.</p><p>The model can directly translate between 200+ languages.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> nllb = NLLBTransformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;nllb_418M&quot;</code>, if no name is provided. For available pretrained models
please see the <a href="https://sparknlp.org/models?q=nllb" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/NLLBTestSpec.scala" target="_blank">NLLBTestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://arxiv.org/pdf/2207.04672.pdf" target="_blank">No Language Left Behind: Scaling Human-Centered Machine Translation</a></li><li><a href="https://github.com/facebookresearch/fairseq/tree/nllb" target="_blank">https://github.com/facebookresearch/fairseq/tree/nllb</a></li></ul><p><b>Paper Abstract:</b></p><p><i>Driven by the goal of eradicating language barriers on a global scale, machine translation
has solidified itself as a key focus of artificial intelligence research today. However, such
efforts have coalesced around a small subset of languages, leaving behind the vast majority of
mostly low-resource languages. What does it take to break the 200 language barrier while
ensuring safe, high quality results, all while keeping ethical considerations in mind? In No
Language Left Behind, we took on this challenge by first contextualizing the need for
low-resource language translation support through exploratory interviews with native speakers.
Then, we created datasets and models aimed at narrowing the performance gap between low and
high-resource languages. More specifically, we developed a conditional compute model based on
Sparsely Gated Mixture of Experts that is trained on data obtained with novel and effective
data mining techniques tailored for low-resource languages. We propose multiple architectural
and training improvements to counteract overfitting while training on thousands of tasks.
Critically, we evaluated the performance of over 40,000 different translation directions using
a human-translated benchmark, Flores-200, and combined human evaluation with a novel toxicity
benchmark covering all languages in Flores-200 to assess translation safety. Our model
achieves an improvement of 44% BLEU relative to the previous state-of-the-art, laying
important groundwork towards realizing a universal translation system. Finally, we open source
all contributions described in this work, accessible at this https URL. </i></p><p><b>Languages Covered:</b></p><p>Acehnese (Arabic script) (ace_Arab), Acehnese (Latin script) (ace_Latn), Mesopotamian Arabic
(acm_Arab), Ta’izzi-Adeni Arabic (acq_Arab), Tunisian Arabic (aeb_Arab), Afrikaans (afr_Latn),
South Levantine Arabic (ajp_Arab), Akan (aka_Latn), Amharic (amh_Ethi), North Levantine Arabic
(apc_Arab), Modern Standard Arabic (arb_Arab), Modern Standard Arabic (Romanized) (arb_Latn),
Najdi Arabic (ars_Arab), Moroccan Arabic (ary_Arab), Egyptian Arabic (arz_Arab), Assamese
(asm_Beng), Asturian (ast_Latn), Awadhi (awa_Deva), Central Aymara (ayr_Latn), South
Azerbaijani (azb_Arab), North Azerbaijani (azj_Latn), Bashkir (bak_Cyrl), Bambara (bam_Latn),
Balinese (ban_Latn), Belarusian (bel_Cyrl), Bemba (bem_Latn), Bengali (ben_Beng), Bhojpuri
(bho_Deva), Banjar (Arabic script) (bjn_Arab), Banjar (Latin script) (bjn_Latn), Standard
Tibetan (bod_Tibt), Bosnian (bos_Latn), Buginese (bug_Latn), Bulgarian (bul_Cyrl), Catalan
(cat_Latn), Cebuano (ceb_Latn), Czech (ces_Latn), Chokwe (cjk_Latn), Central Kurdish
(ckb_Arab), Crimean Tatar (crh_Latn), Welsh (cym_Latn), Danish (dan_Latn), German (deu_Latn),
Southwestern Dinka (dik_Latn), Dyula (dyu_Latn), Dzongkha (dzo_Tibt), Greek (ell_Grek),
English (eng_Latn), Esperanto (epo_Latn), Estonian (est_Latn), Basque (eus_Latn), Ewe
(ewe_Latn), Faroese (fao_Latn), Fijian (fij_Latn), Finnish (fin_Latn), Fon (fon_Latn), French
(fra_Latn), Friulian (fur_Latn), Nigerian Fulfulde (fuv_Latn), Scottish Gaelic (gla_Latn),
Irish (gle_Latn), Galician (glg_Latn), Guarani (grn_Latn), Gujarati (guj_Gujr), Haitian Creole
(hat_Latn), Hausa (hau_Latn), Hebrew (heb_Hebr), Hindi (hin_Deva), Chhattisgarhi (hne_Deva),
Croatian (hrv_Latn), Hungarian (hun_Latn), Armenian (hye_Armn), Igbo (ibo_Latn), Ilocano
(ilo_Latn), Indonesian (ind_Latn), Icelandic (isl_Latn), Italian (ita_Latn), Javanese
(jav_Latn), Japanese (jpn_Jpan), Kabyle (kab_Latn), Jingpho (kac_Latn), Kamba (kam_Latn),
Kannada (kan_Knda), Kashmiri (Arabic script) (kas_Arab), Kashmiri (Devanagari script)
(kas_Deva), Georgian (kat_Geor), Central Kanuri (Arabic script) (knc_Arab), Central Kanuri
(Latin script) (knc_Latn), Kazakh (kaz_Cyrl), Kabiyè (kbp_Latn), Kabuverdianu (kea_Latn),
Khmer (khm_Khmr), Kikuyu (kik_Latn), Kinyarwanda (kin_Latn), Kyrgyz (kir_Cyrl), Kimbundu
(kmb_Latn), Northern Kurdish (kmr_Latn), Kikongo (kon_Latn), Korean (kor_Hang), Lao
(lao_Laoo), Ligurian (lij_Latn), Limburgish (lim_Latn), Lingala (lin_Latn), Lithuanian
(lit_Latn), Lombard (lmo_Latn), Latgalian (ltg_Latn), Luxembourgish (ltz_Latn), Luba-Kasai
(lua_Latn), Ganda (lug_Latn), Luo (luo_Latn), Mizo (lus_Latn), Standard Latvian (lvs_Latn),
Magahi (mag_Deva), Maithili (mai_Deva), Malayalam (mal_Mlym), Marathi (mar_Deva), Minangkabau
(Arabic script) (min_Arab), Minangkabau (Latin script) (min_Latn), Macedonian (mkd_Cyrl),
Plateau Malagasy (plt_Latn), Maltese (mlt_Latn), Meitei (Bengali script) (mni_Beng), Halh
Mongolian (khk_Cyrl), Mossi (mos_Latn), Maori (mri_Latn), Burmese (mya_Mymr), Dutch
(nld_Latn), Norwegian Nynorsk (nno_Latn), Norwegian Bokmål (nob_Latn), Nepali (npi_Deva),
Northern Sotho (nso_Latn), Nuer (nus_Latn), Nyanja (nya_Latn), Occitan (oci_Latn), West
Central Oromo (gaz_Latn), Odia (ory_Orya), Pangasinan (pag_Latn), Eastern Panjabi (pan_Guru),
Papiamento (pap_Latn), Western Persian (pes_Arab), Polish (pol_Latn), Portuguese (por_Latn),
Dari (prs_Arab), Southern Pashto (pbt_Arab), Ayacucho Quechua (quy_Latn), Romanian (ron_Latn),
Rundi (run_Latn), Russian (rus_Cyrl), Sango (sag_Latn), Sanskrit (san_Deva), Santali
(sat_Olck), Sicilian (scn_Latn), Shan (shn_Mymr), Sinhala (sin_Sinh), Slovak (slk_Latn),
Slovenian (slv_Latn), Samoan (smo_Latn), Shona (sna_Latn), Sindhi (snd_Arab), Somali
(som_Latn), Southern Sotho (sot_Latn), Spanish (spa_Latn), Tosk Albanian (als_Latn), Sardinian
(srd_Latn), Serbian (srp_Cyrl), Swati (ssw_Latn), Sundanese (sun_Latn), Swedish (swe_Latn),
Swahili (swh_Latn), Silesian (szl_Latn), Tamil (tam_Taml), Tatar (tat_Cyrl), Telugu
(tel_Telu), Tajik (tgk_Cyrl), Tagalog (tgl_Latn), Thai (tha_Thai), Tigrinya (tir_Ethi),
Tamasheq (Latin script) (taq_Latn), Tamasheq (Tifinagh script) (taq_Tfng), Tok Pisin
(tpi_Latn), Tswana (tsn_Latn), Tsonga (tso_Latn), Turkmen (tuk_Latn), Tumbuka (tum_Latn),
Turkish (tur_Latn), Twi (twi_Latn), Central Atlas Tamazight (tzm_Tfng), Uyghur (uig_Arab),
Ukrainian (ukr_Cyrl), Umbundu (umb_Latn), Urdu (urd_Arab), Northern Uzbek (uzn_Latn), Venetian
(vec_Latn), Vietnamese (vie_Latn), Waray (war_Latn), Wolof (wol_Latn), Xhosa (xho_Latn),
Eastern Yiddish (ydd_Hebr), Yoruba (yor_Latn), Yue Chinese (yue_Hant), Chinese (Simplified)
(zho_Hans), Chinese (Traditional) (zho_Hant), Standard Malay (zsm_Latn), Zulu (zul_Latn).</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> nllb = NLLBTransformer.pretrained(<span class="lit">"nllb_418M"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setSrcLang(<span class="lit">"zho_Hans"</span>)
  .serTgtLang(<span class="lit">"eng_Latn"</span>)
  .setMaxOutputLength(<span class="num">100</span>)
  .setDoSample(<span class="kw">false</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, nllb))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"生活就像一盒巧克力。"</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+-------------------------------------------------------------------------------------------+
|result                                                                                     |
+-------------------------------------------------------------------------------------------+
|[ Life is like a box of chocolate.]                                                        |
+-------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Phi2TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithHasEngine"></a><a id="Phi2Transformer:Phi2Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/Phi2Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Phi-2: Textbooks Are All You Need." href="Phi2Transformer.html"><span class="name">Phi2Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="Phi2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer">Phi2Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="Phi2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer">Phi2Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">Phi-2: Textbooks Are All You Need.</p><div class="fullcomment"><div class="comment cmt"><p>Phi-2: Textbooks Are All You Need.</p><p>Phi-2 is a Transformer with 2.7 billion parameters. It was trained using the same data sources
as Phi-1.5, augmented with a new data source that consists of various NLP synthetic texts and
filtered websites (for safety and educational value). When assessed against benchmarks testing
common sense, language understanding, and logical reasoning, Phi-2 showcased a nearly
state-of-the-art performance among models with less than 13 billion parameters.</p><p>Phi-2 hasn't been fine-tuned through reinforcement learning from human feedback. The intention
behind crafting this open-source model is to provide the research community with a
non-restricted small model to explore vital safety challenges, such as reducing toxicity,
understanding societal biases, enhancing controllability, and more.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> Phi2 = Phi2Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;Phi2-13b&quot;</code>, if no name is provided. For available pretrained models
please see the <a href="https://sparknlp.org/models?q=Phi2" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/Phi2TestSpec.scala" target="_blank">Phi2TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/" target="_blank">Phi-2: Textbooks Are All You Need.</a></li><li><a href="https://huggingface.co/microsoft/phi-2" target="_blank">https://huggingface.co/microsoft/phi-2</a></li></ul><p><b>Paper Abstract:</b></p><p><i>The massive increase in the size of language models to hundreds of billions of parameters
has unlocked a host of emerging capabilities that have redefined the landscape of natural
language processing. A question remains whether such emergent abilities can be achieved at a
smaller scale using strategic choices for training, e.g., data selection.</i></p><p><i>Our line of work with the Phi models aims to answer this question by training SLMs that
achieve performance on par with models of much higher scale (yet still far from the frontier
models). Our key insights for breaking the conventional language model scaling laws with Phi-2
are twofold:</i></p><p><i>Firstly, training data quality plays a critical role in model performance. This has been
known for decades, but we take this insight to its extreme by focusing on “textbook-quality”
data, following upon our prior work “Textbooks Are All You Need.” Our training data mixture
contains synthetic datasets specifically created to teach the model common sense reasoning and
general knowledge, including science, daily activities, and theory of mind, among others. We
further augment our training corpus with carefully selected web data that is filtered based on
educational value and content quality. Secondly, we use innovative techniques to scale up,
starting from our 1.3 billion parameter model, Phi-1.5, and embedding its knowledge within the
2.7 billion parameter Phi-2. This scaled knowledge transfer not only accelerates training
convergence but shows clear boost in Phi-2 benchmark scores.</i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> Phi2 = Phi2Transformer.pretrained(<span class="lit">"phi2"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, Phi2))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[ My name is Leonardo . I am a student of the University of California, Berkeley. I am interested in the field of Artificial Intelligence and its applications in the real world. I have a strong   |
| passion <span class="kw">for</span> learning and am always looking <span class="kw">for</span> ways to improve my knowledge and skills]                                                                                                            |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="Phi3TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithWriteSentencePieceModelwithHasEngine"></a><a id="Phi3Transformer:Phi3Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/Phi3Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Phi-3" href="Phi3Transformer.html"><span class="name">Phi3Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="Phi3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer">Phi3Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="Phi3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer">Phi3Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">Phi-3</p><div class="fullcomment"><div class="comment cmt"><p>Phi-3</p><p>The Phi-3-Mini-128K-Instruct is a 3.8 billion-parameter, lightweight, state-of-the-art open
model trained using the Phi-3 datasets. This dataset includes both synthetic data and filtered
publicly available website data, with an emphasis on high-quality and reasoning-dense
properties. The model belongs to the Phi-3 family with the Mini version in two variants 4K and
128K which is the context length (in tokens) that it can support.</p><p>After initial training, the model underwent a post-training process that involved supervised
fine-tuning and direct preference optimization to enhance its ability to follow instructions
and adhere to safety measures. When evaluated against benchmarks that test common sense,
language understanding, mathematics, coding, long-term context, and logical reasoning, the
Phi-3 Mini-128K-Instruct demonstrated robust and state-of-the-art performance among models
with fewer than 13 billion parameters.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> phi3 = Phi3Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;phi_3_mini_128k_instruct_int8&quot;</code>, if no name is provided. For available
pretrained models please see the <a href="https://sparknlp.org/models?q=phi3" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/Phi3TestSpec.scala" target="_blank">Phi3TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/" target="_blank">https://news.microsoft.com/source/features/ai/the-phi-3-small-language-models-with-big-potential/</a></li><li><a href="https://arxiv.org/abs/2404.14219" target="_blank">https://arxiv.org/abs/2404.14219</a></li></ul><p><b>Paper Abstract:</b></p><p><i>We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion
tokens, whose overall performance, as measured by both academic benchmarks and internal
testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69%
on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The
innovation lies entirely in our dataset for training, a scaled-up version of the one used for
phi-2, composed of heavily filtered publicly available web data and synthetic data. The model
is also further aligned for robustness, safety, and chat format. We also provide some initial
parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small
and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75% and
78% on MMLU, and 8.7 and 8.9 on MT-bench). Moreover, we also introduce phi-3-vision, a 4.2
billion parameter model based on phi-3-mini with strong reasoning capabilities for image and
text prompts. </i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> phi3 = Phi3Transformer.pretrained(<span class="lit">"phi_3_mini_128k_instruct_int8"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, phi3))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[ My name is Leonardo. I am a man of letters. I have been a man <span class="kw">for</span> many years. I was born in the year <span class="num">1776.</span> I came to the United States in <span class="num">1776</span>, and I have lived in the United Kingdom since <span class="num">1776</span>]|
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="QwenTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithHasEngine"></a><a id="QwenTransformer:QwenTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/QwenTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="Qwen: comprehensive language model series" href="QwenTransformer.html"><span class="name">QwenTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="QwenTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer">QwenTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="QwenTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer">QwenTransformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">Qwen: comprehensive language model series</p><div class="fullcomment"><div class="comment cmt"><p>Qwen: comprehensive language model series</p><p>Qwen1.5 is the beta version of Qwen2, a transformer-based decoder-only language model
pretrained on a large amount of data. In comparison with the previous released Qwen, the
improvements include:</p><p>6 model sizes, including 0.5B, 1.8B, 4B, 7B, 14B, and 72B; Significant performance improvement
in Chat models; Multilingual support of both base and chat models; Stable support of 32K
context length for models of all sizes</p><p>Qwen1.5 is a language model series including decoder language models of different model sizes.
For each size, we release the base language model and the aligned chat model. It is based on
the Transformer architecture with SwiGLU activation, attention QKV bias, group query
attention, mixture of sliding window attention and full attention, etc. Additionally, we have
an improved tokenizer adaptive to multiple natural languages and codes. For the beta version,
temporarily we did not include GQA and the mixture of SWA and full attention.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> Qwen = QwenTransformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;Qwen-13b&quot;</code>, if no name is provided. For available pretrained models
please see the <a href="https://sparknlp.org/models?q=Qwen" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/QwenTestSpec.scala" target="_blank">QwenTestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://arxiv.org/pdf/2309.16609.pdf:" target="_blank">Qwen Technical Report</a></li><li><a href="https://qwenlm.github.io/blog/qwen1.5/" target="_blank">https://qwenlm.github.io/blog/qwen1.5/</a></li><li><a href="https://github.com/QwenLM/Qwen1.5" target="_blank">https://github.com/QwenLM/Qwen1.5</a></li></ul><p><b>Paper Abstract:</b></p><p><i>Large language models (LLMs) have revolutionized the field of artificial intelligence,
enabling natural language processing tasks that were previously thought to be exclusive to
humans. In this work, we introduce Qwen, the first installment of our large language model
series. Qwen is a comprehensive language model series that encompasses distinct models with
varying parameter counts. It includes Qwen, the base pretrained language models, and
Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models
consistently demonstrate superior performance across a multitude of downstream tasks, and the
chat models, particularly those trained using Reinforcement Learning from Human Feedback
(RLHF), are highly competitive. The chat models possess advanced tool-use and planning
capabilities for creating agent applications, showcasing impressive performance even when
compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we
have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as
mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These
models demonstrate significantly improved performance in comparison with open-source models,
and slightly fall behind the proprietary models. </i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> Qwen = QwenTransformer.pretrained(<span class="lit">"Qwen-7b"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, Qwen))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"My name is Leonardo."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[ My name is Leonardo . I am a student of the University of California, Berkeley. I am interested in the field of Artificial Intelligence and its applications in the real world. I have a strong   |
| passion <span class="kw">for</span> learning and am always looking <span class="kw">for</span> ways to improve my knowledge and skills]                                                                                                            |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadAutoGGUFModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadAutoGGUFModelextendsAnyRef"></a><a id="ReadAutoGGUFModel:ReadAutoGGUFModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadAutoGGUFModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadAutoGGUFModel.html"><span class="name">ReadAutoGGUFModel</span></a><span class="result"> extends <a href="../../../../../scala/index.html#AnyRef=Object" class="extmbr" name="scala.AnyRef">AnyRef</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadBartTransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadBartTransformerDLModelextendsReadTensorflowModelwithReadOnnxModel"></a><a id="ReadBartTransformerDLModel:ReadBartTransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadBartTransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadBartTransformerDLModel.html"><span class="name">ReadBartTransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/tensorflow/ReadTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel">ReadTensorflowModel</a> with <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadCPMTransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadCPMTransformerDLModelextendsReadOnnxModelwithReadOpenvinoModelwithReadSentencePieceModel"></a><a id="ReadCPMTransformerDLModel:ReadCPMTransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadCPMTransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadCPMTransformerDLModel.html"><span class="name">ReadCPMTransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadGPT2TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadGPT2TransformerDLModelextendsReadTensorflowModelwithReadOnnxModel"></a><a id="ReadGPT2TransformerDLModel:ReadGPT2TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadGPT2TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadGPT2TransformerDLModel.html"><span class="name">ReadGPT2TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/tensorflow/ReadTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel">ReadTensorflowModel</a> with <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadLLAMA2TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadLLAMA2TransformerDLModelextendsReadOnnxModelwithReadOpenvinoModelwithReadSentencePieceModel"></a><a id="ReadLLAMA2TransformerDLModel:ReadLLAMA2TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadLLAMA2TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadLLAMA2TransformerDLModel.html"><span class="name">ReadLLAMA2TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadLLAMA3TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadLLAMA3TransformerDLModelextendsReadOnnxModelwithReadOpenvinoModel"></a><a id="ReadLLAMA3TransformerDLModel:ReadLLAMA3TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadLLAMA3TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadLLAMA3TransformerDLModel.html"><span class="name">ReadLLAMA3TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadM2M100TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadM2M100TransformerDLModelextendsReadOnnxModelwithReadOpenvinoModelwithReadSentencePieceModel"></a><a id="ReadM2M100TransformerDLModel:ReadM2M100TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadM2M100TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadM2M100TransformerDLModel.html"><span class="name">ReadM2M100TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadMarianMTDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadMarianMTDLModelextendsReadTensorflowModelwithReadSentencePieceModelwithReadOnnxModel"></a><a id="ReadMarianMTDLModel:ReadMarianMTDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadMarianMTDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadMarianMTDLModel.html"><span class="name">ReadMarianMTDLModel</span></a><span class="result"> extends <a href="../../../ml/tensorflow/ReadTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel">ReadTensorflowModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a> with <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadMistralTransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadMistralTransformerDLModelextendsReadOnnxModelwithReadOpenvinoModelwithReadSentencePieceModel"></a><a id="ReadMistralTransformerDLModel:ReadMistralTransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadMistralTransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadMistralTransformerDLModel.html"><span class="name">ReadMistralTransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadNLLBTransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadNLLBTransformerDLModelextendsReadOnnxModelwithReadOpenvinoModelwithReadSentencePieceModel"></a><a id="ReadNLLBTransformerDLModel:ReadNLLBTransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadNLLBTransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadNLLBTransformerDLModel.html"><span class="name">ReadNLLBTransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadPhi2TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadPhi2TransformerDLModelextendsReadOnnxModelwithReadOpenvinoModel"></a><a id="ReadPhi2TransformerDLModel:ReadPhi2TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadPhi2TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadPhi2TransformerDLModel.html"><span class="name">ReadPhi2TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadPhi3TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadPhi3TransformerDLModelextendsReadOnnxModelwithReadOpenvinoModelwithReadSentencePieceModel"></a><a id="ReadPhi3TransformerDLModel:ReadPhi3TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadPhi3TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadPhi3TransformerDLModel.html"><span class="name">ReadPhi3TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadQwenTransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadQwenTransformerDLModelextendsReadOnnxModelwithReadOpenvinoModel"></a><a id="ReadQwenTransformerDLModel:ReadQwenTransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadQwenTransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadQwenTransformerDLModel.html"><span class="name">ReadQwenTransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadStarCoderTransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadStarCoderTransformerDLModelextendsReadOnnxModelwithReadOpenvinoModel"></a><a id="ReadStarCoderTransformerDLModel:ReadStarCoderTransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadStarCoderTransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadStarCoderTransformerDLModel.html"><span class="name">ReadStarCoderTransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadT5TransformerDLModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadT5TransformerDLModelextendsReadTensorflowModelwithReadSentencePieceModelwithReadOnnxModelwithReadOpenvinoModel"></a><a id="ReadT5TransformerDLModel:ReadT5TransformerDLModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadT5TransformerDLModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadT5TransformerDLModel.html"><span class="name">ReadT5TransformerDLModel</span></a><span class="result"> extends <a href="../../../ml/tensorflow/ReadTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.ReadTensorflowModel">ReadTensorflowModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a> with <a href="../../../ml/onnx/ReadOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.ReadOnnxModel">ReadOnnxModel</a> with <a href="../../../ml/openvino/ReadOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.ReadOpenvinoModel">ReadOpenvinoModel</a></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedAutoGGUFModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedAutoGGUFModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel]"></a><a id="ReadablePretrainedAutoGGUFModel:ReadablePretrainedAutoGGUFModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedAutoGGUFModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedAutoGGUFModel.html"><span class="name">ReadablePretrainedAutoGGUFModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="AutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel">AutoGGUFModel</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="AutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel">AutoGGUFModel</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedBartTransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedBartTransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer]"></a><a id="ReadablePretrainedBartTransformerModel:ReadablePretrainedBartTransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedBartTransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedBartTransformerModel.html"><span class="name">ReadablePretrainedBartTransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="BartTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer">BartTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="BartTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer">BartTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedCPMTransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedCPMTransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer]"></a><a id="ReadablePretrainedCPMTransformerModel:ReadablePretrainedCPMTransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedCPMTransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedCPMTransformerModel.html"><span class="name">ReadablePretrainedCPMTransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="CPMTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer">CPMTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="CPMTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer">CPMTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedGPT2TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedGPT2TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer]"></a><a id="ReadablePretrainedGPT2TransformerModel:ReadablePretrainedGPT2TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedGPT2TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedGPT2TransformerModel.html"><span class="name">ReadablePretrainedGPT2TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="GPT2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer">GPT2Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="GPT2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer">GPT2Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedLLAMA2TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedLLAMA2TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer]"></a><a id="ReadablePretrainedLLAMA2TransformerModel:ReadablePretrainedLLAMA2TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedLLAMA2TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedLLAMA2TransformerModel.html"><span class="name">ReadablePretrainedLLAMA2TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="LLAMA2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer">LLAMA2Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="LLAMA2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer">LLAMA2Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedLLAMA3TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedLLAMA3TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer]"></a><a id="ReadablePretrainedLLAMA3TransformerModel:ReadablePretrainedLLAMA3TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedLLAMA3TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedLLAMA3TransformerModel.html"><span class="name">ReadablePretrainedLLAMA3TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="LLAMA3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer">LLAMA3Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="LLAMA3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer">LLAMA3Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedM2M100TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedM2M100TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer]"></a><a id="ReadablePretrainedM2M100TransformerModel:ReadablePretrainedM2M100TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedM2M100TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedM2M100TransformerModel.html"><span class="name">ReadablePretrainedM2M100TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="M2M100Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer">M2M100Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="M2M100Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer">M2M100Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedMarianMTModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedMarianMTModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer]"></a><a id="ReadablePretrainedMarianMTModel:ReadablePretrainedMarianMTModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedMarianMTModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedMarianMTModel.html"><span class="name">ReadablePretrainedMarianMTModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="MarianTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer">MarianTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="MarianTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer">MarianTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedMistralTransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedMistralTransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer]"></a><a id="ReadablePretrainedMistralTransformerModel:ReadablePretrainedMistralTransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedMistralTransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedMistralTransformerModel.html"><span class="name">ReadablePretrainedMistralTransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="MistralTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer">MistralTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="MistralTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer">MistralTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedNLLBTransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedNLLBTransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer]"></a><a id="ReadablePretrainedNLLBTransformerModel:ReadablePretrainedNLLBTransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedNLLBTransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedNLLBTransformerModel.html"><span class="name">ReadablePretrainedNLLBTransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="NLLBTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer">NLLBTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="NLLBTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer">NLLBTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedPhi2TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedPhi2TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer]"></a><a id="ReadablePretrainedPhi2TransformerModel:ReadablePretrainedPhi2TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedPhi2TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedPhi2TransformerModel.html"><span class="name">ReadablePretrainedPhi2TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="Phi2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer">Phi2Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="Phi2Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer">Phi2Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedPhi3TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedPhi3TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer]"></a><a id="ReadablePretrainedPhi3TransformerModel:ReadablePretrainedPhi3TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedPhi3TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedPhi3TransformerModel.html"><span class="name">ReadablePretrainedPhi3TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="Phi3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer">Phi3Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="Phi3Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer">Phi3Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedQwenTransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedQwenTransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer]"></a><a id="ReadablePretrainedQwenTransformerModel:ReadablePretrainedQwenTransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedQwenTransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedQwenTransformerModel.html"><span class="name">ReadablePretrainedQwenTransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="QwenTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer">QwenTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="QwenTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer">QwenTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedStarCoderTransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedStarCoderTransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer]"></a><a id="ReadablePretrainedStarCoderTransformerModel:ReadablePretrainedStarCoderTransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedStarCoderTransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedStarCoderTransformerModel.html"><span class="name">ReadablePretrainedStarCoderTransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="StarCoderTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer">StarCoderTransformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="StarCoderTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer">StarCoderTransformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedT5TransformerModel" visbl="pub" class="indented0 " data-isabs="true" fullComment="no" group="Ungrouped">
      <a id="ReadablePretrainedT5TransformerModelextendsParamsAndFeaturesReadable[com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer]withHasPretrained[com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer]"></a><a id="ReadablePretrainedT5TransformerModel:ReadablePretrainedT5TransformerModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/ReadablePretrainedT5TransformerModel.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">trait</span>
      </span>
      <span class="symbol">
        <a title="" href="ReadablePretrainedT5TransformerModel.html"><span class="name">ReadablePretrainedT5TransformerModel</span></a><span class="result"> extends <a href="../../ParamsAndFeaturesReadable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesReadable">ParamsAndFeaturesReadable</a>[<a href="T5Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer">T5Transformer</a>] with <a href="../../HasPretrained.html" class="extype" name="com.johnsnowlabs.nlp.HasPretrained">HasPretrained</a>[<a href="T5Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer">T5Transformer</a>]</span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="StarCoderTransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer]withParamsAndFeaturesWritablewithWriteOnnxModelwithWriteOpenvinoModelwithHasGeneratorPropertieswithHasEngine"></a><a id="StarCoderTransformer:StarCoderTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/StarCoderTransformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="StarCoder2: The Versatile Code Companion." href="StarCoderTransformer.html"><span class="name">StarCoderTransformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="StarCoderTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer">StarCoderTransformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="StarCoderTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer">StarCoderTransformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasGeneratorProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasGeneratorProperties">HasGeneratorProperties</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">StarCoder2: The Versatile Code Companion.</p><div class="fullcomment"><div class="comment cmt"><p>StarCoder2: The Versatile Code Companion.</p><p>StarCoder2 is a Transformer model designed specifically for code generation and understanding.
With 13 billion parameters, it builds upon the advancements of its predecessors and is trained
on a diverse dataset that includes multiple programming languages. This extensive training
allows StarCoder2 to support a wide array of coding tasks, from code completion to generation.</p><p>StarCoder2 was developed to assist developers in writing and understanding code more
efficiently, making it a valuable tool for various software development and data science
tasks.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> starcoder2 = StarCoder2Transformer.pretrained()
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"generation"</span>)</pre><p>The default model is <code>&quot;StarCoder2-3B&quot;</code>, if no name is provided. For available pretrained
models please see the <a href="https://sparknlp.org/models?q=StarCoder2" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/StarCoder2TestSpec.scala" target="_blank">StarCoder2TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://huggingface.co/blog/starcoder" target="_blank">StarCoder2: The Versatile Code Companion</a></li><li><a href="https://github.com/bigcode-project/starcoder" target="_blank">https://github.com/bigcode-project/starcoder</a></li></ul><p><b>Paper Abstract:</b></p><p><i>The BigCode project,1 an open-scientific collaboration focused on the responsible
development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In
partnership with Software Heritage (SWH),2 we build The Stack v2 on top of the digital commons
of their source code archive. Alongside the SWH repositories spanning 619 programming
languages, we carefully select other high-quality data sources, such as GitHub pull requests,
Kaggle notebooks, and code documentation. This results in a training set that is 4× larger
than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters
on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM
benchmarks.</i></p><p><i> We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on
most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B,
significantly outperforms other models of comparable size. In addition, it matches or
outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is
the best-performing model at code completion for high-resource languages, we find that
StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several
low-resource languages. We make the model weights available under an OpenRAIL license and
ensure full transparency regarding the training data by releasing the SoftWare Heritage
persistent IDentifiers (SWHIDs) of the source code data.</i></p><p><b>Note:</b></p><p>This is a computationally intensive module, especially for larger code sequences. The use of
an accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.StarCoder2Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> starcoder2 = StarCoder2Transformer.pretrained(<span class="lit">"starcoder2"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMinOutputLength(<span class="num">10</span>)
  .setMaxOutputLength(<span class="num">50</span>)
  .setDoSample(<span class="kw">false</span>)
  .setTopK(<span class="num">50</span>)
  .setNoRepeatNgramSize(<span class="num">3</span>)
  .setOutputCol(<span class="lit">"generation"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, starcoder2))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"def add(a, b):"</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

results.select(<span class="lit">"generation.result"</span>).show(truncate = <span class="kw">false</span>)
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[<span class="kw">def</span> add(a, b): <span class="kw">return</span> a + b]                                                                                                                                                                       |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="T5TransformerextendsAnnotatorModel[com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer]withHasBatchedAnnotate[com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer]withParamsAndFeaturesWritablewithWriteTensorflowModelwithWriteOnnxModelwithWriteOpenvinoModelwithHasCaseSensitivePropertieswithWriteSentencePieceModelwithHasProtectedParamswithHasEngine"></a><a id="T5Transformer:T5Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">class</span>
      </span>
      <span class="symbol">
        <a title="T5: the Text-To-Text Transfer Transformer" href="T5Transformer.html"><span class="name">T5Transformer</span></a><span class="result"> extends <a href="../../AnnotatorModel.html" class="extype" name="com.johnsnowlabs.nlp.AnnotatorModel">AnnotatorModel</a>[<a href="T5Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer">T5Transformer</a>] with <a href="../../HasBatchedAnnotate.html" class="extype" name="com.johnsnowlabs.nlp.HasBatchedAnnotate">HasBatchedAnnotate</a>[<a href="T5Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer">T5Transformer</a>] with <a href="../../ParamsAndFeaturesWritable.html" class="extype" name="com.johnsnowlabs.nlp.ParamsAndFeaturesWritable">ParamsAndFeaturesWritable</a> with <a href="../../../ml/tensorflow/WriteTensorflowModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.WriteTensorflowModel">WriteTensorflowModel</a> with <a href="../../../ml/onnx/WriteOnnxModel.html" class="extype" name="com.johnsnowlabs.ml.onnx.WriteOnnxModel">WriteOnnxModel</a> with <a href="../../../ml/openvino/WriteOpenvinoModel.html" class="extype" name="com.johnsnowlabs.ml.openvino.WriteOpenvinoModel">WriteOpenvinoModel</a> with <a href="../../HasCaseSensitiveProperties.html" class="extype" name="com.johnsnowlabs.nlp.HasCaseSensitiveProperties">HasCaseSensitiveProperties</a> with <a href="../../../ml/tensorflow/sentencepiece/WriteSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.WriteSentencePieceModel">WriteSentencePieceModel</a> with <a href="../../HasProtectedParams.html" class="extype" name="com.johnsnowlabs.nlp.HasProtectedParams">HasProtectedParams</a> with <a href="../../HasEngine.html" class="extype" name="com.johnsnowlabs.nlp.HasEngine">HasEngine</a></span>
      </span>
      
      <p class="shortcomment cmt">T5: the Text-To-Text Transfer Transformer</p><div class="fullcomment"><div class="comment cmt"><p>T5: the Text-To-Text Transfer Transformer</p><p>T5 reconsiders all NLP tasks into a unified text-to-text-format where the input and output are
always text strings, in contrast to BERT-style models that can only output either a class
label or a span of the input. The text-to-text framework is able to use the same model, loss
function, and hyper-parameters on any NLP task, including machine translation, document
summarization, question answering, and classification tasks (e.g., sentiment analysis). T5 can
even apply to regression tasks by training it to predict the string representation of a number
instead of the number itself.</p><p>Pretrained models can be loaded with <code>pretrained</code> of the companion object:</p><pre><span class="kw">val</span> t5 = T5Transformer.pretrained()
  .setTask(<span class="lit">"summarize:"</span>)
  .setInputCols(<span class="lit">"document"</span>)
  .setOutputCol(<span class="lit">"summaries"</span>)</pre><p>The default model is <code>&quot;t5_small&quot;</code>, if no name is provided. For available pretrained models
please see the <a href="https://sparknlp.org/models?q=t5" target="_blank">Models Hub</a>.</p><p>For extended examples of usage, see the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/question-answering/Question_Answering_and_Summarization_with_T5.ipynb" target="_blank">Examples</a>
and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/T5TestSpec.scala" target="_blank">T5TestSpec</a>.</p><p><b>References:</b></p><ul><li><a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" target="_blank">Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer</a></li><li><a href="https://arxiv.org/abs/1910.10683" target="_blank">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></li><li><a href="https://github.com/google-research/text-to-text-transfer-transformer" target="_blank">https://github.com/google-research/text-to-text-transfer-transformer</a></li></ul><p><b>Paper Abstract:</b></p><p><i>Transfer learning, where a model is first pre-trained on a data-rich task before being
fine-tuned on a downstream task, has emerged as a powerful technique in natural language
processing (NLP). The effectiveness of transfer learning has given rise to a diversity of
approaches, methodology, and practice. In this paper, we explore the landscape of transfer
learning techniques for NLP by introducing a unified framework that converts all text-based
language problems into a text-to-text format. Our systematic study compares pre-training
objectives, architectures, unlabeled data sets, transfer approaches, and other factors on
dozens of language understanding tasks. By combining the insights from our exploration with
scale and our new Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many
benchmarks covering summarization, question answering, text classification, and more. To
facilitate future work on transfer learning for NLP, we release our data set, pre-trained
models, and code.</i></p><p><b>Note:</b></p><p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p><h4>Example</h4><pre><span class="kw">import</span> spark.implicits._
<span class="kw">import</span> com.johnsnowlabs.nlp.base.DocumentAssembler
<span class="kw">import</span> com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer
<span class="kw">import</span> org.apache.spark.ml.Pipeline

<span class="kw">val</span> documentAssembler = <span class="kw">new</span> DocumentAssembler()
  .setInputCol(<span class="lit">"text"</span>)
  .setOutputCol(<span class="lit">"documents"</span>)

<span class="kw">val</span> t5 = T5Transformer.pretrained(<span class="lit">"t5_small"</span>)
  .setTask(<span class="lit">"summarize:"</span>)
  .setInputCols(<span class="std">Array</span>(<span class="lit">"documents"</span>))
  .setMaxOutputLength(<span class="num">200</span>)
  .setOutputCol(<span class="lit">"summaries"</span>)

<span class="kw">val</span> pipeline = <span class="kw">new</span> Pipeline().setStages(<span class="std">Array</span>(documentAssembler, t5))

<span class="kw">val</span> data = <span class="std">Seq</span>(
  <span class="lit">"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a "</span> +
    <span class="lit">"downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness"</span> +
    <span class="lit">" of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this "</span> +
    <span class="lit">"paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework "</span> +
    <span class="lit">"that converts all text-based language problems into a text-to-text format. Our systematic study compares "</span> +
    <span class="lit">"pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens "</span> +
    <span class="lit">"of language understanding tasks. By combining the insights from our exploration with scale and our new "</span> +
    <span class="lit">"Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering "</span> +
    <span class="lit">"summarization, question answering, text classification, and more. To facilitate future work on transfer "</span> +
    <span class="lit">"learning for NLP, we release our data set, pre-trained models, and code."</span>
).toDF(<span class="lit">"text"</span>)
<span class="kw">val</span> result = pipeline.fit(data).transform(data)

result.select(<span class="lit">"summaries.result"</span>).show(<span class="kw">false</span>)
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                                                                        |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[transfer learning has emerged as a powerful technique in natural language processing (NLP) the effectiveness of transfer learning has given rise to a diversity of approaches, methodologies, and practice .]|
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</pre></div></div>
    </li></ol>
            </div>

        

        <div class="values members">
              <h3>Value Members</h3>
              <ol>
                <li name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="AutoGGUFModel"></a><a id="AutoGGUFModel:AutoGGUFModel"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/AutoGGUFModel$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="This is the companion object of AutoGGUFModel." href="AutoGGUFModel$.html"><span class="name">AutoGGUFModel</span></a><span class="result"> extends <a href="ReadablePretrainedAutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedAutoGGUFModel">ReadablePretrainedAutoGGUFModel</a> with <a href="ReadAutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadAutoGGUFModel">ReadAutoGGUFModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">This is the companion object of <a href="AutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel">AutoGGUFModel</a>.</p><div class="fullcomment"><div class="comment cmt"><p>This is the companion object of <a href="AutoGGUFModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.AutoGGUFModel">AutoGGUFModel</a>. Please refer to that class for the
documentation.
</p></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="BartTransformer"></a><a id="BartTransformer:BartTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/BartTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="BartTransformer$.html"><span class="name">BartTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedBartTransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedBartTransformerModel">ReadablePretrainedBartTransformerModel</a> with <a href="ReadBartTransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadBartTransformerDLModel">ReadBartTransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.CPMTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="CPMTransformer"></a><a id="CPMTransformer:CPMTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/CPMTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="CPMTransformer$.html"><span class="name">CPMTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedCPMTransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedCPMTransformerModel">ReadablePretrainedCPMTransformerModel</a> with <a href="ReadCPMTransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadCPMTransformerDLModel">ReadCPMTransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="GPT2Transformer"></a><a id="GPT2Transformer:GPT2Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="GPT2Transformer$.html"><span class="name">GPT2Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedGPT2TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedGPT2TransformerModel">ReadablePretrainedGPT2TransformerModel</a> with <a href="ReadGPT2TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadGPT2TransformerDLModel">ReadGPT2TransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA2Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="LLAMA2Transformer"></a><a id="LLAMA2Transformer:LLAMA2Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/LLAMA2Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="LLAMA2Transformer$.html"><span class="name">LLAMA2Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedLLAMA2TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedLLAMA2TransformerModel">ReadablePretrainedLLAMA2TransformerModel</a> with <a href="ReadLLAMA2TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadLLAMA2TransformerDLModel">ReadLLAMA2TransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.LLAMA3Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="LLAMA3Transformer"></a><a id="LLAMA3Transformer:LLAMA3Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/LLAMA3Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="LLAMA3Transformer$.html"><span class="name">LLAMA3Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedLLAMA3TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedLLAMA3TransformerModel">ReadablePretrainedLLAMA3TransformerModel</a> with <a href="ReadLLAMA3TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadLLAMA3TransformerDLModel">ReadLLAMA3TransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.M2M100Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="M2M100Transformer"></a><a id="M2M100Transformer:M2M100Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/M2M100Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="M2M100Transformer$.html"><span class="name">M2M100Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedM2M100TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedM2M100TransformerModel">ReadablePretrainedM2M100TransformerModel</a> with <a href="ReadM2M100TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadM2M100TransformerDLModel">ReadM2M100TransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="MarianTransformer"></a><a id="MarianTransformer:MarianTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="This is the companion object of MarianTransformer." href="MarianTransformer$.html"><span class="name">MarianTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedMarianMTModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedMarianMTModel">ReadablePretrainedMarianMTModel</a> with <a href="ReadMarianMTDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadMarianMTDLModel">ReadMarianMTDLModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">This is the companion object of <a href="MarianTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer">MarianTransformer</a>.</p><div class="fullcomment"><div class="comment cmt"><p>This is the companion object of <a href="MarianTransformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer">MarianTransformer</a>. Please refer to that class for the
documentation.
</p></div></div>
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.MistralTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="MistralTransformer"></a><a id="MistralTransformer:MistralTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/MistralTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="MistralTransformer$.html"><span class="name">MistralTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedMistralTransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedMistralTransformerModel">ReadablePretrainedMistralTransformerModel</a> with <a href="ReadMistralTransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadMistralTransformerDLModel">ReadMistralTransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.NLLBTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="NLLBTransformer"></a><a id="NLLBTransformer:NLLBTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/NLLBTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="NLLBTransformer$.html"><span class="name">NLLBTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedNLLBTransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedNLLBTransformerModel">ReadablePretrainedNLLBTransformerModel</a> with <a href="ReadNLLBTransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadNLLBTransformerDLModel">ReadNLLBTransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi2Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="Phi2Transformer"></a><a id="Phi2Transformer:Phi2Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/Phi2Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="Phi2Transformer$.html"><span class="name">Phi2Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedPhi2TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedPhi2TransformerModel">ReadablePretrainedPhi2TransformerModel</a> with <a href="ReadPhi2TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadPhi2TransformerDLModel">ReadPhi2TransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.Phi3Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="Phi3Transformer"></a><a id="Phi3Transformer:Phi3Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/Phi3Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="Phi3Transformer$.html"><span class="name">Phi3Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedPhi3TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedPhi3TransformerModel">ReadablePretrainedPhi3TransformerModel</a> with <a href="ReadPhi3TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadPhi3TransformerDLModel">ReadPhi3TransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.QwenTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="QwenTransformer"></a><a id="QwenTransformer:QwenTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/QwenTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="QwenTransformer$.html"><span class="name">QwenTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedQwenTransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedQwenTransformerModel">ReadablePretrainedQwenTransformerModel</a> with <a href="ReadQwenTransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadQwenTransformerDLModel">ReadQwenTransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.StarCoderTransformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="no" group="Ungrouped">
      <a id="StarCoderTransformer"></a><a id="StarCoderTransformer:StarCoderTransformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/StarCoderTransformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="" href="StarCoderTransformer$.html"><span class="name">StarCoderTransformer</span></a><span class="result"> extends <a href="ReadablePretrainedStarCoderTransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedStarCoderTransformerModel">ReadablePretrainedStarCoderTransformerModel</a> with <a href="ReadStarCoderTransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadStarCoderTransformerDLModel">ReadStarCoderTransformerDLModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      
    </li><li name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer" visbl="pub" class="indented0 " data-isabs="false" fullComment="yes" group="Ungrouped">
      <a id="T5Transformer"></a><a id="T5Transformer:T5Transformer"></a>
      <span class="permalink">
      <a href="../../../../../com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer$.html" title="Permalink">
        <i class="material-icons"></i>
      </a>
    </span>
      <span class="modifier_kind">
        <span class="modifier"></span>
        <span class="kind">object</span>
      </span>
      <span class="symbol">
        <a title="This is the companion object of T5Transformer." href="T5Transformer$.html"><span class="name">T5Transformer</span></a><span class="result"> extends <a href="ReadablePretrainedT5TransformerModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadablePretrainedT5TransformerModel">ReadablePretrainedT5TransformerModel</a> with <a href="ReadT5TransformerDLModel.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.ReadT5TransformerDLModel">ReadT5TransformerDLModel</a> with <a href="../../../ml/tensorflow/sentencepiece/ReadSentencePieceModel.html" class="extype" name="com.johnsnowlabs.ml.tensorflow.sentencepiece.ReadSentencePieceModel">ReadSentencePieceModel</a> with <span class="extype" name="scala.Serializable">Serializable</span></span>
      </span>
      
      <p class="shortcomment cmt">This is the companion object of <a href="T5Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer">T5Transformer</a>.</p><div class="fullcomment"><div class="comment cmt"><p>This is the companion object of <a href="T5Transformer.html" class="extype" name="com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer">T5Transformer</a>. Please refer to that class for the
documentation.
</p></div></div>
    </li>
              </ol>
            </div>

        

        
        </div>

        <div id="inheritedMembers">
        
        
        </div>

        <div id="groupedMembers">
        <div class="group" name="Ungrouped">
              <h3>Ungrouped</h3>
              
            </div>
        </div>

      </div>

      <div id="tooltip"></div>

      <div id="footer">  </div>
    </body>
          </div>
        </div>
      </div>
    </body>
      </html>
