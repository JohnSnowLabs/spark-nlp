

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>sparknlp.annotator.seq2seq.bart_transformer &#8212; Spark NLP 4.4.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../../static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../../../static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../../../static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../../../../static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../../static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../../static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../../static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../../../static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../../static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../../../../static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../../../../" id="documentation_options" src="../../../../../../static/documentation_options.js"></script>
    <script src="../../../../../../static/jquery.js"></script>
    <script src="../../../../../../static/underscore.js"></script>
    <script src="../../../../../../static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../../../static/doctools.js"></script>
    <script src="../../../../../../static/sphinx_highlight.js"></script>
    <script src="../../../../../../static/toggleprompt.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index';</script>
    <link rel="shortcut icon" href="../../../../../../static/fav.ico"/>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../../../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../../../static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../../../static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../../getting_started/index.html">
                        Getting Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../../user_guide/index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../../third_party/index.html">
                        Third Party Projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../index.html">
                        API Reference
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../../getting_started/index.html">
                        Getting Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../../user_guide/index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../../third_party/index.html">
                        Third Party Projects
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../../index.html">
                        API Reference
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../classifier_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/albert_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/albert_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/bert_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/bert_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/bert_for_zero_shot_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/camembert_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.camembert_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/camembert_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/classifier_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.classifier_dl</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/deberta_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/deberta_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/distil_bert_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/distil_bert_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/distil_bert_for_zero_shot_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/longformer_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/longformer_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/multi_classifier_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/roberta_bert_for_zero_shot_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.roberta_bert_for_zero_shot_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/roberta_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/roberta_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/sentiment_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.sentiment_dl</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/xlm_roberta_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/xlm_roberta_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/xlnet_for_sequence_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classifier_dl/xlnet_for_token_classification/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dependency/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.dependency</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dependency/dependency_parser/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.dependency.dependency_parser</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dependency/typed_dependency_parser/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.dependency.typed_dependency_parser</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/albert_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.albert_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/bert_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.bert_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/bert_sentence_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/camembert_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.camembert_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/chunk_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.chunk_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/deberta_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.deberta_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/distil_bert_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.distil_bert_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/doc2vec/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.doc2vec</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/elmo_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.elmo_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/longformer_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.longformer_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/roberta_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.roberta_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/roberta_sentence_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/sentence_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.sentence_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/universal_sentence_encoder/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.universal_sentence_encoder</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/word2vec/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.word2vec</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/word_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.word_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/xlm_roberta_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/xlm_roberta_sentence_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../embeddings/xlnet_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.embeddings.xlnet_embeddings</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../er/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.er</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../er/entity_ruler/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.er.entity_ruler</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../keyword_extraction/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.keyword_extraction</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../keyword_extraction/yake_keyword_extraction/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ld_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ld_dl</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ld_dl/language_detector_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ld_dl.language_detector_dl</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../matcher/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.matcher</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../matcher/big_text_matcher/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.matcher.big_text_matcher</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../matcher/date_matcher/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.matcher.date_matcher</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../matcher/multi_date_matcher/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.matcher.multi_date_matcher</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../matcher/regex_matcher/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.matcher.regex_matcher</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../matcher/text_matcher/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.matcher.text_matcher</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ner/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ner</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ner/ner_approach/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ner.ner_approach</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ner/ner_converter/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ner.ner_converter</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ner/ner_crf/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ner.ner_crf</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ner/ner_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ner.ner_dl</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ner/ner_overwriter/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ner.ner_overwriter</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../param/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.param</span></code></a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../pos/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.pos</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../pos/perceptron/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.pos.perceptron</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sentence/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.sentence</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../sentence/sentence_detector/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.sentence.sentence_detector</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sentence/sentence_detector_dl/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.sentence.sentence_detector_dl</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../sentiment/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.sentiment</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../sentiment/sentiment_detector/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.sentiment.sentiment_detector</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sentiment/vivekn_sentiment/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.sentiment.vivekn_sentiment</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq</span></code></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq.bart_transformer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../gpt2_transformer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq.gpt2_transformer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../marian_transformer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq.marian_transformer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../t5_transformer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq.t5_transformer</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../spell_check/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.spell_check</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../spell_check/context_spell_checker/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.spell_check.context_spell_checker</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../spell_check/norvig_sweeting/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.spell_check.norvig_sweeting</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../spell_check/symmetric_delete/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.spell_check.symmetric_delete</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../token/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.token</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../token/chunk_tokenizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.token.chunk_tokenizer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../token/recursive_tokenizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.token.recursive_tokenizer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../token/regex_tokenizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.token.regex_tokenizer</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../token/tokenizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.token.tokenizer</span></code></a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ws/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ws</span></code></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ws/word_segmenter/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.ws.word_segmenter</span></code></a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../chunk2_doc/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.chunk2_doc</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chunker/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.chunker</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../date2_chunk/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.date2_chunk</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../document_normalizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.document_normalizer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../graph_extraction/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.graph_extraction</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lemmatizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.lemmatizer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../n_gram_generator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.n_gram_generator</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../normalizer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.normalizer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stemmer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.stemmer</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stop_words_cleaner/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.stop_words_cleaner</span></code></a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq.bart_transformer</span></code></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="module-sparknlp.annotator.seq2seq.bart_transformer">
<span id="sparknlp-annotator-seq2seq-bart-transformer"></span><h1><a class="reference internal" href="#module-sparknlp.annotator.seq2seq.bart_transformer" title="sparknlp.annotator.seq2seq.bart_transformer"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp.annotator.seq2seq.bart_transformer</span></code></a><a class="headerlink" href="#module-sparknlp.annotator.seq2seq.bart_transformer" title="Permalink to this heading">#</a></h1>
<p>Contains classes for the BartTransformer.</p>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this heading">#</a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading">#</a></h3>
<table class="autosummary longtable table autosummary">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer" title="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BartTransformer</span></code></a></p></td>
<td><p>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">BartTransformer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">classname</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'com.johnsnowlabs.nlp.annotators.seq2seq.BartTransformer'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">java_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer" title="Permalink to this definition">#</a></dt>
<dd><p>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,
Translation, and Comprehension Transformer</p>
<p>The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art
language generation model that was introduced by Facebook AI in 2019. It is based on the
transformer architecture and is designed to handle a wide range of natural language processing
tasks such as text generation, summarization, and machine translation.</p>
<p>BART is unique in that it is both bidirectional and auto-regressive, meaning that it can
generate text both from left-to-right and from right-to-left. This allows it to capture
contextual information from both past and future tokens in a sentence,resulting in more
accurate and natural language generation.</p>
<p>The model was trained on a large corpus of text data using a combination of unsupervised and
supervised learning techniques. It incorporates pretraining and fine-tuning phases, where the
model is first trained on a large unlabeled corpus of text, and then fine-tuned on specific
downstream tasks.</p>
<p>BART has achieved state-of-the-art performance on a wide range of NLP tasks, including
summarization, question-answering, and language translation. Its ability to handle multiple
tasks and its high performance on each of these tasks make it a versatile and valuable tool
for natural language processing applications.</p>
<p>Pretrained models can be loaded with <a class="reference internal" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained" title="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pretrained()</span></code></a> of the companion
object:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bart</span> <span class="o">=</span> <span class="n">BartTransformer</span><span class="o">.</span><span class="n">pretrained</span><span class="p">()</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setTask</span><span class="p">(</span><span class="s2">&quot;summarize:&quot;</span><span class="p">)</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s2">&quot;document&quot;</span><span class="p">])</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;summaries&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The default model is <code class="docutils literal notranslate"><span class="pre">&quot;distilbart_xsum_12_6&quot;</span></code>, if no name is provided. For available
pretrained models please see the <a class="reference external" href="https://sparknlp.org/models?q=bart">Models Hub</a>.</p>
<p>For extended examples of usage, see the <a class="reference external" href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/BartTestSpec.scala">BartTestSpec</a>.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Input Annotation types</p></th>
<th class="head"><p>Output Annotation type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DOCUMENT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">DOCUMENT</span></code></p></td>
</tr>
</tbody>
</table>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>batchSize</strong></dt><dd><p>Batch Size, by default <cite>1</cite>.</p>
</dd>
<dt><strong>configProtoBytes</strong></dt><dd><p>ConfigProto from tensorflow, serialized into byte array.</p>
</dd>
<dt><strong>task</strong></dt><dd><p>Transformer’s task, e.g. <code class="docutils literal notranslate"><span class="pre">summarize:</span></code>, by default <cite>“”</cite>.</p>
</dd>
<dt><strong>minOutputLength</strong></dt><dd><p>Minimum length of the sequence to be generated, by default <cite>0</cite>.</p>
</dd>
<dt><strong>maxOutputLength</strong></dt><dd><p>Maximum length of output text, by default <cite>20</cite>.</p>
</dd>
<dt><strong>doSample</strong></dt><dd><p>Whether or not to use sampling; use greedy decoding otherwise, by default <cite>False</cite>.</p>
</dd>
<dt><strong>temperature</strong></dt><dd><p>The value used to module the next token probabilities, by default <cite>1.0</cite>.</p>
</dd>
<dt><strong>topK</strong></dt><dd><p>The number of highest probability vocabulary tokens to keep for
top-k-filtering, by default <cite>50</cite>.</p>
</dd>
<dt><strong>beamSize</strong></dt><dd><p>The number of beam size for beam search, by default <cite>1</cite>.</p>
</dd>
<dt><strong>topP</strong></dt><dd><p>Top cumulative probability for vocabulary tokens, by default <cite>1.0</cite>.</p>
<p>If set to float &lt; 1, only the most probable tokens with probabilities
that add up to <code class="docutils literal notranslate"><span class="pre">topP</span></code> or higher are kept for generation.</p>
</dd>
<dt><strong>repetitionPenalty</strong></dt><dd><p>The parameter for repetition penalty. 1.0 means no penalty, by default <cite>1.0</cite>.</p>
</dd>
<dt><strong>noRepeatNgramSize</strong></dt><dd><p>If set to int &gt; 0, all ngrams of that size can only occur once, by default <cite>0</cite>.</p>
</dd>
<dt><strong>ignoreTokenIds</strong></dt><dd><p>A list of token ids which are ignored in the decoder’s output, by default <cite>[]</cite>.</p>
</dd>
<dt><strong>useCache</strong></dt><dd><p>Whether or not to use cache, by default <cite>False</cite>.</p>
</dd>
<dt><strong>Notes</strong></dt><dd></dd>
<dt><strong>—–</strong></dt><dd></dd>
<dt><strong>This is a very computationally expensive module especially on larger</strong></dt><dd></dd>
<dt><strong>sequence. The use of an accelerator such as GPU is recommended.</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<ul class="simple">
<li><p><a href="#id1"><span class="problematic" id="id2">`</span></a>Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</p></li>
</ul>
<blockquote>
<div><p>&lt;<a class="reference external" href="https://arxiv.org/abs/1910.13461">https://arxiv.org/abs/1910.13461</a>&gt;`__</p>
</div></blockquote>
<ul class="simple">
<li><p><a class="github reference external" href="https://github.com/pytorch/fairseq">pytorch/fairseq</a></p></li>
</ul>
<p><strong>Paper Abstract:</strong>
<em>We present BART, a denoising autoencoder for pretraining sequence-to-sequence models.
BART is trained by (1) corrupting text with an arbitrary noising function, and (2)
learning a model to reconstruct the original text. It uses a standard Tranformer-based
neural machine translation architecture which, despite its simplicity, can be seen as
generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder),
and many other more recent pretraining schemes. We evaluate a number of noising approaches,
finding the best performance by both randomly shuffling the order of the original sentences
and using a novel in-filling scheme, where spans of text are replaced with a single mask token.
BART is particularly effective when fine tuned for text generation but also works well for
comprehension tasks. It matches the performance of RoBERTa with comparable training resources
on GLUE and SQuAD, achieves new state-of-the-art results on a range of abstractive dialogue,
question answering, and summarization tasks, with gains of up to 6 ROUGE. BART also provides
a 1.1 BLEU increase over a back-translation system for machine translation, with only target
language pretraining. We also report ablation experiments that replicate other pretraining
schemes within the BART framework, to better measure which factors most influence end-task performance.</em></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;documents&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bart</span> <span class="o">=</span> <span class="n">BartTransformer</span><span class="o">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s2">&quot;distilbart_xsum_12_6&quot;</span><span class="p">)</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setTask</span><span class="p">(</span><span class="s2">&quot;summarize:&quot;</span><span class="p">)</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s2">&quot;documents&quot;</span><span class="p">])</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setMaxOutputLength</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> \
<span class="gp">... </span>    <span class="o">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s2">&quot;summaries&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span><span class="o">.</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">bart</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
<span class="gp">... </span>    <span class="s2">&quot;Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness&quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot; of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;that converts all text-based language problems into a text-to-text format. Our systematic study compares &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;of language understanding tasks. By combining the insights from our exploration with scale and our new &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;summarization, question answering, text classification, and more. To facilitate future work on transfer &quot;</span> <span class="o">+</span>
<span class="gp">... </span>    <span class="s2">&quot;learning for NLP, we release our data set, pre-trained models, and code.&quot;</span>
<span class="gp">... </span><span class="p">]])</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;summaries.result&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="go">|result                                                                                                                                                                                                        |</span>
<span class="go">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="go">|[transfer learning has emerged as a powerful technique in natural language processing (NLP) the effectiveness of transfer learning has given rise to a diversity of approaches, methodologies, and practice .]|</span>
<span class="go">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setIgnoreTokenIds">
<span class="sig-name descname"><span class="pre">setIgnoreTokenIds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setIgnoreTokenIds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setIgnoreTokenIds" title="Permalink to this definition">#</a></dt>
<dd><p>A list of token ids which are ignored in the decoder’s output, by default <cite>[]</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">List[int]</span></dt><dd><p>The words to be filtered out</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setConfigProtoBytes">
<span class="sig-name descname"><span class="pre">setConfigProtoBytes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setConfigProtoBytes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setConfigProtoBytes" title="Permalink to this definition">#</a></dt>
<dd><p>Sets configProto from tensorflow, serialized into byte array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>b</strong><span class="classifier">List[int]</span></dt><dd><p>ConfigProto from tensorflow, serialized into byte array</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTask">
<span class="sig-name descname"><span class="pre">setTask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setTask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTask" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the transformer’s task, e.g. <code class="docutils literal notranslate"><span class="pre">summarize:</span></code>, by default <cite>“”</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">str</span></dt><dd><p>The transformer’s task</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMinOutputLength">
<span class="sig-name descname"><span class="pre">setMinOutputLength</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setMinOutputLength"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMinOutputLength" title="Permalink to this definition">#</a></dt>
<dd><p>Sets minimum length of the sequence to be generated, by default <cite>0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">int</span></dt><dd><p>Minimum length of the sequence to be generated</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMaxOutputLength">
<span class="sig-name descname"><span class="pre">setMaxOutputLength</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setMaxOutputLength"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMaxOutputLength" title="Permalink to this definition">#</a></dt>
<dd><p>Sets maximum length of output text, by default <cite>20</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">int</span></dt><dd><p>Maximum length of output text</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setDoSample">
<span class="sig-name descname"><span class="pre">setDoSample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setDoSample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setDoSample" title="Permalink to this definition">#</a></dt>
<dd><p>Sets whether or not to use sampling, use greedy decoding otherwise, by default <cite>False</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">bool</span></dt><dd><p>Whether or not to use sampling; use greedy decoding otherwise</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTemperature">
<span class="sig-name descname"><span class="pre">setTemperature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setTemperature"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTemperature" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the value used to module the next token probabilities, by default <cite>1.0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">float</span></dt><dd><p>The value used to module the next token probabilities</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopK">
<span class="sig-name descname"><span class="pre">setTopK</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setTopK"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopK" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the number of highest probability vocabulary tokens to keep for
top-k-filtering, by default <cite>50</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">int</span></dt><dd><p>Number of highest probability vocabulary tokens to keep</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopP">
<span class="sig-name descname"><span class="pre">setTopP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setTopP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopP" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the top cumulative probability for vocabulary tokens, by default <cite>1.0</cite>.</p>
<p>If set to float &lt; 1, only the most probable tokens with probabilities
that add up to <code class="docutils literal notranslate"><span class="pre">topP</span></code> or higher are kept for generation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">float</span></dt><dd><p>Cumulative probability for vocabulary tokens</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setRepetitionPenalty">
<span class="sig-name descname"><span class="pre">setRepetitionPenalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setRepetitionPenalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setRepetitionPenalty" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the parameter for repetition penalty. 1.0 means no penalty, by default <cite>1.0</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">float</span></dt><dd><p>The repetition penalty</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p>See <a class="reference external" href="https://arxiv.org/pdf/1909.05858.pdf">Ctrl: A Conditional Transformer Language Model For Controllable
Generation</a> for more details.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setNoRepeatNgramSize">
<span class="sig-name descname"><span class="pre">setNoRepeatNgramSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setNoRepeatNgramSize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setNoRepeatNgramSize" title="Permalink to this definition">#</a></dt>
<dd><p>Sets size of n-grams that can only occur once, by default <cite>0</cite>.</p>
<p>If set to int &gt; 0, all ngrams of that size can only occur once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">int</span></dt><dd><p>N-gram size can only occur once</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setBeamSize">
<span class="sig-name descname"><span class="pre">setBeamSize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setBeamSize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setBeamSize" title="Permalink to this definition">#</a></dt>
<dd><p>Sets the number of beam size for beam search, by default <cite>4</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">int</span></dt><dd><p>Number of beam size for beam search</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setCache">
<span class="sig-name descname"><span class="pre">setCache</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.setCache"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setCache" title="Permalink to this definition">#</a></dt>
<dd><p>Sets whether or not to use caching to enhance performance, by default <cite>False</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>value</strong><span class="classifier">bool</span></dt><dd><p>Whether or not to use caching to enhance performance</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.loadSavedModel">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loadSavedModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spark_session</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_cache</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.loadSavedModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.loadSavedModel" title="Permalink to this definition">#</a></dt>
<dd><p>Loads a locally saved model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>folder</strong><span class="classifier">str</span></dt><dd><p>Folder of the saved model</p>
</dd>
<dt><strong>spark_session</strong><span class="classifier">pyspark.sql.SparkSession</span></dt><dd><p>The current SparkSession</p>
</dd>
<dt><strong>use_cache: bool</strong></dt><dd><p>The model uses caching to facilitate performance</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>BartTransformer</dt><dd><p>The restored model</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">pretrained</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'distilbart_xsum_12_6'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lang</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'en'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remote_loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp/annotator/seq2seq/bart_transformer.html#BartTransformer.pretrained"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained" title="Permalink to this definition">#</a></dt>
<dd><p>Downloads and loads a pretrained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name</strong><span class="classifier">str, optional</span></dt><dd><p>Name of the pretrained model, by default “distilbart_xsum_12_6”</p>
</dd>
<dt><strong>lang</strong><span class="classifier">str, optional</span></dt><dd><p>Language of the pretrained model, by default “en”</p>
</dd>
<dt><strong>remote_loc</strong><span class="classifier">str, optional</span></dt><dd><p>Optional remote address of the resource, by default None. Will use
Spark NLPs repositories otherwise.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>BartTransformer</dt><dd><p>The restored model</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-contents">Module Contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classes">Classes</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer"><code class="docutils literal notranslate"><span class="pre">BartTransformer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setIgnoreTokenIds"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setIgnoreTokenIds()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setConfigProtoBytes"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setConfigProtoBytes()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTask"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setTask()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMinOutputLength"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setMinOutputLength()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMaxOutputLength"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setMaxOutputLength()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setDoSample"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setDoSample()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTemperature"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setTemperature()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopK"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setTopK()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopP"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setTopP()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setRepetitionPenalty"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setRepetitionPenalty()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setNoRepeatNgramSize"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setNoRepeatNgramSize()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setBeamSize"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setBeamSize()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setCache"><code class="docutils literal notranslate"><span class="pre">BartTransformer.setCache()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.loadSavedModel"><code class="docutils literal notranslate"><span class="pre">BartTransformer.loadSavedModel()</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained"><code class="docutils literal notranslate"><span class="pre">BartTransformer.pretrained()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../../../../../_sources/reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../../static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../../../../static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2023, John Snow Labs.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 5.3.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>