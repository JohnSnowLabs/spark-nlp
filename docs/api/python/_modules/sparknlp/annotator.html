
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sparknlp.annotator &#8212; Spark NLP 3.2.0 documentation</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/toggleprompt.js"></script>
    <link rel="shortcut icon" href="../../_static/fav.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/logo.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../user_guide/index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reference/index.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for sparknlp.annotator</h1><div class="highlight"><pre>
<span></span><span class="c1">#  Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="c1">#  contributor license agreements.  See the NOTICE file distributed with</span>
<span class="c1">#  this work for additional information regarding copyright ownership.</span>
<span class="c1">#  The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="c1">#  (the &quot;License&quot;); you may not use this file except in compliance with</span>
<span class="c1">#  the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1">#  Unless required by applicable law or agreed to in writing, software</span>
<span class="c1">#  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1">#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1">#  See the License for the specific language governing permissions and</span>
<span class="c1">#  limitations under the License.</span>

<span class="sd">&quot;&quot;&quot;Module containing all available Annotators of Spark NLP and their base classes.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Do NOT delete. Looks redundant but this is key work around for python 2 support.</span>
<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="n">DocumentAssembler</span><span class="p">,</span> <span class="n">Finisher</span><span class="p">,</span> <span class="n">EmbeddingsFinisher</span><span class="p">,</span> <span class="n">TokenAssembler</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">com.johnsnowlabs.nlp</span>

<span class="n">annotators</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">pos</span><span class="o">.</span><span class="n">perceptron</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">ner</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">ner</span><span class="o">.</span><span class="n">crf</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">ner</span><span class="o">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">regex</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">sbd</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">sbd</span><span class="o">.</span><span class="n">pragmatic</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">sda</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">sda</span><span class="o">.</span><span class="n">pragmatic</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">sda</span><span class="o">.</span><span class="n">vivekn</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">spell</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">spell</span><span class="o">.</span><span class="n">norvig</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">spell</span><span class="o">.</span><span class="n">symmetric</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">spell</span><span class="o">.</span><span class="n">context</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">parser</span><span class="o">.</span><span class="n">dep</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">parser</span><span class="o">.</span><span class="n">typdep</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">ld</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">ld</span><span class="o">.</span><span class="n">dl</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">keyword</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">keyword</span><span class="o">.</span><span class="n">yake</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">sentence_detector_dl</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">seq2seq</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>
<span class="n">ws</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">]</span>


<div class="viewcode-block" id="RecursiveTokenizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.RecursiveTokenizer.html#sparknlp.annotator.RecursiveTokenizer">[docs]</a><span class="k">class</span> <span class="nc">RecursiveTokenizer</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenizes raw text recursively based on a handful of definable rules.</span>

<span class="sd">    Unlike the Tokenizer, the RecursiveTokenizer operates based on these array</span>
<span class="sd">    string parameters only:</span>

<span class="sd">    - ``prefixes``: Strings that will be split when found at the beginning of</span>
<span class="sd">      token.</span>
<span class="sd">    - ``suffixes``: Strings that will be split when found at the end of token.</span>
<span class="sd">    - ``infixes``: Strings that will be split when found at the middle of token.</span>
<span class="sd">    - ``whitelist``: Whitelist of strings not to split</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/7.Context_Spell_Checker.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    prefixes</span>
<span class="sd">        strings to be considered independent tokens when found at the beginning of a word, by default [&quot;&#39;&quot;, &#39;&quot;&#39;, &#39;(&#39;, &#39;[&#39;, &#39;\\n&#39;]</span>
<span class="sd">    suffixes</span>
<span class="sd">        strings to be considered independent tokens when found at the end of a word, by default [&#39;.&#39;, &#39;:&#39;, &#39;%&#39;, &#39;,&#39;, &#39;;&#39;, &#39;?&#39;, &quot;&#39;&quot;, &#39;&quot;&#39;, &#39;)&#39;, &#39;]&#39;, &#39;\\n&#39;, &#39;!&#39;, &quot;&#39;s&quot;]</span>
<span class="sd">    infixes</span>
<span class="sd">        strings to be considered independent tokens when found in the middle of a word, by default [&#39;\\n&#39;, &#39;(&#39;, &#39;)&#39;]</span>
<span class="sd">    whitelist</span>
<span class="sd">        strings to be considered as single tokens , by default [&quot;it\&#39;s&quot;, &quot;that\&#39;s&quot;, &quot;there\&#39;s&quot;, &quot;he\&#39;s&quot;, &quot;she\&#39;s&quot;, &quot;what\&#39;s&quot;, &quot;let\&#39;s&quot;, &quot;who\&#39;s&quot;, &quot;It\&#39;s&quot;, &quot;That\&#39;s&quot;, &quot;There\&#39;s&quot;, &quot;He\&#39;s&quot;, &quot;She\&#39;s&quot;, &quot;What\&#39;s&quot;, &quot;Let\&#39;s&quot;, &quot;Who\&#39;s&quot;]</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = RecursiveTokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;One, after the Other, (and) again. PO, QAM,&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;token.result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------------------------------+</span>
<span class="sd">        |result                                                            |</span>
<span class="sd">        +------------------------------------------------------------------+</span>
<span class="sd">        |[One, ,, after, the, Other, ,, (, and, ), again, ., PO, ,, QAM, ,]|</span>
<span class="sd">        +------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;RecursiveTokenizer&#39;</span>

    <span class="n">prefixes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;prefixes&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;strings to be considered independent tokens when found at the beginning of a word&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">suffixes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;suffixes&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;strings to be considered independent tokens when found at the end of a word&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">infixes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                    <span class="s2">&quot;infixes&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;strings to be considered independent tokens when found in the middle of a word&quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">whitelist</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;whitelist&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;strings to be considered as single tokens&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPrefixes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">prefixes</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSuffixes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">suffixes</span><span class="o">=</span><span class="n">s</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setInfixes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">infixes</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWhitelist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">whitelist</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.RecursiveTokenizer&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RecursiveTokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.RecursiveTokenizer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">prefixes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;(&quot;</span><span class="p">,</span> <span class="s2">&quot;[&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">],</span>
            <span class="n">infixes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;(&quot;</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">],</span>
            <span class="n">suffixes</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;%&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot;;&quot;</span><span class="p">,</span> <span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">,</span> <span class="s2">&quot;]&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;!&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;s&quot;</span><span class="p">],</span>
            <span class="n">whitelist</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;it&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;that&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;there&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;he&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;she&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;what&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;let&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;who&#39;s&quot;</span><span class="p">,</span> \
                       <span class="s2">&quot;It&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;That&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;There&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;He&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;She&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;What&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;Let&#39;s&quot;</span><span class="p">,</span> <span class="s2">&quot;Who&#39;s&quot;</span><span class="p">]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">RecursiveTokenizerModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="RecursiveTokenizerModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.RecursiveTokenizerModel.html#sparknlp.annotator.RecursiveTokenizerModel">[docs]</a><span class="k">class</span> <span class="nc">RecursiveTokenizerModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated model of the RecursiveTokenizer.</span>
<span class="sd">    For usage and examples see the documentation of the main class.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;RecursiveTokenizerModel&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.RecursiveTokenizerModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RecursiveTokenizerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Tokenizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.Tokenizer.html#sparknlp.annotator.Tokenizer">[docs]</a><span class="k">class</span> <span class="nc">Tokenizer</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenizes raw text in document type columns into TokenizedSentence .</span>

<span class="sd">    This class represents a non fitted tokenizer. Fitting it will cause the internal RuleFactory to construct the rules for tokenizing from the input configuration.</span>

<span class="sd">    Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.</span>

<span class="sd">    For extended examples of usage see the</span>
<span class="sd">    `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    =================================================================================== ======================</span>
<span class="sd">    Input Annotation types                                                              Output Annotation type</span>
<span class="sd">    =================================================================================== ======================</span>
<span class="sd">    ``DOCUMENT // A Tokenizer could require only for now a SentenceDetector annotator`` ``TOKEN``</span>
<span class="sd">    =================================================================================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    targetPattern</span>
<span class="sd">        pattern to grab from text as token candidates, by default &quot;\S+&quot;</span>
<span class="sd">    prefixPattern</span>
<span class="sd">        regex with groups and begins with \A to match target prefix, by default &quot;\A([^\s\w\$\.]*)&quot;</span>
<span class="sd">    suffixPattern</span>
<span class="sd">        regex with groups and ends with \z to match target suffix, by default &quot;([^\s\w]?)([^\s\w]*)\z&quot;</span>
<span class="sd">    infixPatterns</span>
<span class="sd">        regex patterns that match tokens within a single target. groups identify different sub-tokens. multiple defaults</span>
<span class="sd">    exceptions</span>
<span class="sd">        Words that won&#39;t be affected by tokenization rules</span>
<span class="sd">    exceptionsPath</span>
<span class="sd">        path to file containing list of exceptions</span>
<span class="sd">    caseSensitiveExceptions</span>
<span class="sd">        Whether to care for case sensitiveness in exceptions, by default True</span>
<span class="sd">    contextChars</span>
<span class="sd">        character list used to separate from token boundaries, by default [&#39;.&#39;, &#39;,&#39;, &#39;;&#39;, &#39;:&#39;, &#39;!&#39;, &#39;?&#39;, &#39;*&#39;, &#39;-&#39;, &#39;(&#39;, &#39;)&#39;, &#39;&quot;&#39;, &quot;&#39;&quot;]</span>
<span class="sd">    splitPattern</span>
<span class="sd">        character list used to separate from the inside of tokens</span>
<span class="sd">    splitChars</span>
<span class="sd">        character list used to separate from the inside of tokens</span>
<span class="sd">    minLength</span>
<span class="sd">        Set the minimum allowed legth for each token, by default 0</span>
<span class="sd">    maxLength</span>
<span class="sd">        Set the maximum allowed legth for each token, by default 99999</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        data = spark.createDataFrame([[&quot;I&#39;d like to say we didn&#39;t expect that. Jane&#39;s boyfriend.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;)</span>
<span class="sd">        tokenizer = Tokenizer().setInputCols([&quot;document&quot;]).setOutputCol(&quot;token&quot;).fit(data)</span>

<span class="sd">        pipeline = Pipeline().setStages([documentAssembler, tokenizer]).fit(data)</span>
<span class="sd">        result = pipeline.transform(data)</span>

<span class="sd">        result.selectExpr(&quot;token.result&quot;).show(truncate=False)</span>
<span class="sd">        +-----------------------------------------------------------------------+</span>
<span class="sd">        |output                                                                 |</span>
<span class="sd">        +-----------------------------------------------------------------------+</span>
<span class="sd">        |[I&#39;d, like, to, say, we, didn&#39;t, expect, that, ., Jane&#39;s, boyfriend, .]|</span>
<span class="sd">        +-----------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">targetPattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;targetPattern&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;pattern to grab from text as token candidates. Defaults \S+&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">prefixPattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;prefixPattern&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;regex with groups and begins with \A to match target prefix. Defaults to \A([^\s\w\$\.]*)&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">suffixPattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;suffixPattern&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;regex with groups and ends with \z to match target suffix. Defaults to ([^\s\w]?)([^\s\w]*)\z&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">infixPatterns</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;infixPatterns&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;regex patterns that match tokens within a single target. groups identify different sub-tokens. multiple defaults&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">exceptions</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;exceptions&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;Words that won&#39;t be affected by tokenization rules&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">exceptionsPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;exceptionsPath&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;path to file containing list of exceptions&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">caseSensitiveExceptions</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                    <span class="s2">&quot;caseSensitiveExceptions&quot;</span><span class="p">,</span>
                                    <span class="s2">&quot;Whether to care for case sensitiveness in exceptions&quot;</span><span class="p">,</span>
                                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">contextChars</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;contextChars&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;character list used to separate from token boundaries&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">splitPattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;splitPattern&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;character list used to separate from the inside of tokens&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">splitChars</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;splitChars&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;character list used to separate from the inside of tokens&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">minLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;minLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the minimum allowed legth for each token&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;maxLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the maximum allowed legth for each token&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;Tokenizer&#39;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.Tokenizer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">targetPattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">S+&quot;</span><span class="p">,</span>
            <span class="n">contextChars</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="p">,</span> <span class="s2">&quot;;&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="s2">&quot;!&quot;</span><span class="p">,</span> <span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot;(&quot;</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;&quot;</span><span class="p">],</span>
            <span class="n">caseSensitiveExceptions</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">minLength</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">maxLength</span><span class="o">=</span><span class="mi">99999</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">getInfixPatterns</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;infixPatterns&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getSuffixPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;suffixPattern&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getPrefixPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;prefixPattern&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getContextChars</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;contextChars&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getSplitChars</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;splitChars&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTargetPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">targetPattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPrefixPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">prefixPattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSuffixPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">suffixPattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setInfixPatterns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">infixPatterns</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addInfixPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">infix_patterns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getInfixPatterns</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">infix_patterns</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">infix_patterns</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">infixPatterns</span><span class="o">=</span><span class="n">infix_patterns</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExceptions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">exceptions</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getExceptions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;exceptions&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addException</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">exception_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getExceptions</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">exception_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">exception_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">exceptions</span><span class="o">=</span><span class="n">exception_tokens</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCaseSensitiveExceptions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitiveExceptions</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getCaseSensitiveExceptions</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="s2">&quot;caseSensitiveExceptions&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setContextChars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">contextChars</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addContextChars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">context_chars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getContextChars</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">context_chars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">context_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">contextChars</span><span class="o">=</span><span class="n">context_chars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSplitPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitPattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSplitChars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitChars</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addSplitChars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">split_chars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getSplitChars</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">split_chars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">split_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitChars</span><span class="o">=</span><span class="n">split_chars</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TokenizerModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="TokenizerModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.TokenizerModel.html#sparknlp.annotator.TokenizerModel">[docs]</a><span class="k">class</span> <span class="nc">TokenizerModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenizes raw text into word pieces, tokens. Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.</span>

<span class="sd">    This class represents an already fitted Tokenizer model.</span>

<span class="sd">    See the main class Tokenizer for more examples of usage.</span>

<span class="sd">    ======================  ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================  ======================</span>
<span class="sd">    ``DOCUMENT``            ``TOKEN``</span>
<span class="sd">    ======================  ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    exceptions</span>
<span class="sd">        Words that won&#39;t be affected by tokenization rules</span>
<span class="sd">    caseSensitiveExceptions</span>
<span class="sd">        Whether to care for case sensitiveness in exceptions, by default True</span>
<span class="sd">    targetPattern</span>
<span class="sd">        pattern to grab from text as token candidates, by default &quot;\S+&quot;</span>
<span class="sd">    rules</span>
<span class="sd">        Rules structure factory containing pre processed regex rules</span>
<span class="sd">    splitPattern</span>
<span class="sd">        character list used to separate from the inside of tokens</span>
<span class="sd">    splitChars</span>
<span class="sd">        character list used to separate from the inside of tokens</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;TokenizerModel&quot;</span>

    <span class="n">exceptions</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;exceptions&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;Words that won&#39;t be affected by tokenization rules&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">caseSensitiveExceptions</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                    <span class="s2">&quot;caseSensitiveExceptions&quot;</span><span class="p">,</span>
                                    <span class="s2">&quot;Whether to care for case sensitiveness in exceptions&quot;</span><span class="p">,</span>
                                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">targetPattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;targetPattern&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;pattern to grab from text as token candidates. Defaults \S+&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">rules</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                  <span class="s2">&quot;rules&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;Rules structure factory containing pre processed regex rules&quot;</span><span class="p">,</span>
                  <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">splitPattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;splitPattern&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;character list used to separate from the inside of tokens&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">splitChars</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;splitChars&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;character list used to separate from the inside of tokens&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.TokenizerModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TokenizerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">targetPattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">S+&quot;</span><span class="p">,</span>
            <span class="n">caseSensitiveExceptions</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSplitPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitPattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSplitChars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitChars</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addSplitChars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">split_chars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getSplitChars</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">split_chars</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">split_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitChars</span><span class="o">=</span><span class="n">split_chars</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;token_rules&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">TokenizerModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="RegexTokenizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.RegexTokenizer.html#sparknlp.annotator.RegexTokenizer">[docs]</a><span class="k">class</span> <span class="nc">RegexTokenizer</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A tokenizer that splits text by a regex pattern.</span>

<span class="sd">    The pattern needs to be set with ``setPattern`` and this sets the delimiting pattern or how the tokens should be split.</span>
<span class="sd">    By default this pattern is ``\s+`` which means that tokens should be split by 1 or more whitespace characters.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    minLength</span>
<span class="sd">        Set the minimum allowed legth for each token, by default 1</span>
<span class="sd">    maxLength</span>
<span class="sd">        Set the maximum allowed legth for each token</span>
<span class="sd">    toLowercase</span>
<span class="sd">        Indicates whether to convert all characters to lowercase before tokenizing, by default False</span>
<span class="sd">    pattern</span>
<span class="sd">        regex pattern used for tokenizing, by default &quot;\s+&quot;</span>
<span class="sd">    positionalMask</span>
<span class="sd">        Using a positional mask to guarantee the incremental progression of the tokenization, by default False</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        regexTokenizer = RegexTokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;regexToken&quot;) \\</span>
<span class="sd">            .setToLowercase(True) \\</span>
<span class="sd">            .setPattern(&quot;\\s+&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">                documentAssembler,</span>
<span class="sd">                regexTokenizer</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is my first sentence. This is my second.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;regexToken.result&quot;).show(truncate=False)</span>
<span class="sd">        +-------------------------------------------------------+</span>
<span class="sd">        |result                                                 |</span>
<span class="sd">        +-------------------------------------------------------+</span>
<span class="sd">        |[this, is, my, first, sentence., this, is, my, second.]|</span>
<span class="sd">        +-------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;RegexTokenizer&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RegexTokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.RegexTokenizer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;document&quot;</span><span class="p">],</span>
            <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;regexToken&quot;</span><span class="p">,</span>
            <span class="n">toLowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">minLength</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">pattern</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">s+&quot;</span><span class="p">,</span>
            <span class="n">positionalMask</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="n">minLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;minLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the minimum allowed legth for each token&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;maxLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the maximum allowed legth for each token&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">toLowercase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;toLowercase&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Indicates whether to convert all characters to lowercase before tokenizing.&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">pattern</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                    <span class="s2">&quot;pattern&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;regex pattern used for tokenizing. Defaults \S+&quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">positionalMask</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;positionalMask&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Using a positional mask to guarantee the incremental progression of the tokenization.&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setToLowercase</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">toLowercase</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">pattern</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPositionalMask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">positionalMask</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>


<div class="viewcode-block" id="ChunkTokenizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ChunkTokenizer.html#sparknlp.annotator.ChunkTokenizer">[docs]</a><span class="k">class</span> <span class="nc">ChunkTokenizer</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tokenizes and flattens extracted NER chunks.</span>

<span class="sd">    The ChunkTokenizer will split the extracted NER ``CHUNK`` type Annotations and will create ``TOKEN`` type Annotations.</span>
<span class="sd">    The result is then flattened, resulting in a single array.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``CHUNK``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentenceDetector = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        entityExtractor = TextMatcher() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setEntities(&quot;src/test/resources/entity-extractor/test-chunks.txt&quot;, ReadAs.TEXT) \\</span>
<span class="sd">            .setOutputCol(&quot;entity&quot;)</span>

<span class="sd">        chunkTokenizer = ChunkTokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;entity&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;chunk_token&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentenceDetector,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              entityExtractor,</span>
<span class="sd">              chunkTokenizer</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Hello world, my name is Michael, I am an artist and I work at Benezar&quot;,</span>
<span class="sd">            &quot;Robert, an engineer from Farendell, graduated last year. The other one, Lucas, graduated last week.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;entity.result as entity&quot; , &quot;chunk_token.result as chunk_token&quot;).show(truncate=False)</span>
<span class="sd">        +-----------------------------------------------+---------------------------------------------------+</span>
<span class="sd">        |entity                                         |chunk_token                                        |</span>
<span class="sd">        +-----------------------------------------------+---------------------------------------------------+</span>
<span class="sd">        |[world, Michael, work at Benezar]              |[world, Michael, work, at, Benezar]                |</span>
<span class="sd">        |[engineer from Farendell, last year, last week]|[engineer, from, Farendell, last, year, last, week]|</span>
<span class="sd">        +-----------------------------------------------+---------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;ChunkTokenizer&#39;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ChunkTokenizer&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ChunkTokenizerModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="ChunkTokenizerModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ChunkTokenizerModel.html#sparknlp.annotator.ChunkTokenizerModel">[docs]</a><span class="k">class</span> <span class="nc">ChunkTokenizerModel</span><span class="p">(</span><span class="n">TokenizerModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated model of the ChunkTokenizer.</span>
<span class="sd">    For usage and examples see the documentation of the main class.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``CHUNK``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;ChunkTokenizerModel&#39;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ChunkTokenizerModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TokenizerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Token2Chunk"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.Token2Chunk.html#sparknlp.annotator.Token2Chunk">[docs]</a><span class="k">class</span> <span class="nc">Token2Chunk</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts ``TOKEN`` type Annotations to ``CHUNK`` type.</span>

<span class="sd">    This can be useful if a entities have been already extracted as ``TOKEN`` and following annotators require ``CHUNK`` types.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>


<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        token2chunk = Token2Chunk() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;chunk&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            token2chunk</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;One Two Three Four&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(chunk) as result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------+</span>
<span class="sd">        |result                                    |</span>
<span class="sd">        +------------------------------------------+</span>
<span class="sd">        |[chunk, 0, 2, One, [sentence -&gt; 0], []]   |</span>
<span class="sd">        |[chunk, 4, 6, Two, [sentence -&gt; 0], []]   |</span>
<span class="sd">        |[chunk, 8, 12, Three, [sentence -&gt; 0], []]|</span>
<span class="sd">        |[chunk, 14, 17, Four, [sentence -&gt; 0], []]|</span>
<span class="sd">        +------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Token2Chunk&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Token2Chunk</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.Token2Chunk&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="Stemmer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.Stemmer.html#sparknlp.annotator.Stemmer">[docs]</a><span class="k">class</span> <span class="nc">Stemmer</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns hard-stems out of words with the objective of retrieving the meaningful part of the word.</span>
<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    language</span>
<span class="sd">        stemmer algorithm, by default &quot;english&quot;</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        stemmer = Stemmer() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;stem&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            stemmer</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;]]) \\</span>
<span class="sd">            .toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;stem.result&quot;).show(truncate = False)</span>
<span class="sd">        +-------------------------------------------------------------+</span>
<span class="sd">        |result                                                       |</span>
<span class="sd">        +-------------------------------------------------------------+</span>
<span class="sd">        |[peter, piper, employe, ar, pick, peck, of, pickl, pepper, .]|</span>
<span class="sd">        +-------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">language</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;language&quot;</span><span class="p">,</span> <span class="s2">&quot;stemmer algorithm&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Stemmer&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Stemmer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.Stemmer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">language</span><span class="o">=</span><span class="s2">&quot;english&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Chunker"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.Chunker.html#sparknlp.annotator.Chunker">[docs]</a><span class="k">class</span> <span class="nc">Chunker</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document.</span>
<span class="sd">    Extracted part-of-speech tags are mapped onto the sentence, which can then be parsed by regular expressions.</span>
<span class="sd">    The part-of-speech tags are wrapped by angle brackets ``&lt;&gt;`` to be easily distinguishable in the text itself.</span>
<span class="sd">    This example sentence will result in the form:</span>

<span class="sd">    .. code-block:: none</span>

<span class="sd">        &quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;</span>
<span class="sd">        &quot;&lt;NNP&gt;&lt;NNP&gt;&lt;NNS&gt;&lt;VBP&gt;&lt;VBG&gt;&lt;NNS&gt;&lt;IN&gt;&lt;JJ&gt;&lt;NNS&gt;&lt;.&gt;&quot;</span>


<span class="sd">    To then extract these tags, ``regexParsers`` need to be set with e.g.:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        chunker = Chunker() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;chunk&quot;) \\</span>
<span class="sd">            .setRegexParsers([&quot;&lt;NNP&gt;+&quot;, &quot;&lt;NNS&gt;+&quot;])</span>


<span class="sd">    When defining the regular expressions, tags enclosed in angle brackets are treated as groups, so here specifically</span>
<span class="sd">    ``&quot;&lt;NNP&gt;+&quot;`` means 1 or more nouns in succession. Additional patterns can also be set with ``addRegexParsers``.</span>

<span class="sd">    For more extended examples see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, POS``      ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    regexParsers</span>
<span class="sd">        an array of grammar based chunk parsers</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        POSTag = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        chunker = Chunker() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;chunk&quot;) \\</span>
<span class="sd">            .setRegexParsers([&quot;&lt;NNP&gt;+&quot;, &quot;&lt;NNS&gt;+&quot;])</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentence,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              POSTag,</span>
<span class="sd">              chunker</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(chunk) as result&quot;).show(truncate=False)</span>
<span class="sd">        +-------------------------------------------------------------+</span>
<span class="sd">        |result                                                       |</span>
<span class="sd">        +-------------------------------------------------------------+</span>
<span class="sd">        |[chunk, 0, 11, Peter Pipers, [sentence -&gt; 0, chunk -&gt; 0], []]|</span>
<span class="sd">        |[chunk, 13, 21, employees, [sentence -&gt; 0, chunk -&gt; 1], []]  |</span>
<span class="sd">        |[chunk, 35, 39, pecks, [sentence -&gt; 0, chunk -&gt; 2], []]      |</span>
<span class="sd">        |[chunk, 52, 58, peppers, [sentence -&gt; 0, chunk -&gt; 3], []]    |</span>
<span class="sd">        +-------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">regexParsers</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;regexParsers&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;an array of grammar based chunk parsers&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Chunker&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Chunker</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.Chunker&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRegexParsers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">regexParsers</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>


<div class="viewcode-block" id="DocumentNormalizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DocumentNormalizer.html#sparknlp.annotator.DocumentNormalizer">[docs]</a><span class="k">class</span> <span class="nc">DocumentNormalizer</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotator which normalizes raw text from tagged text, e.g. scraped web pages or xml documents, from document type columns into Sentence.</span>
<span class="sd">    Removes all dirty characters from text following one or more input regex patterns.</span>
<span class="sd">    Can apply not wanted character removal with a specific policy.</span>
<span class="sd">    Can apply lower case normalization.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DOCUMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    action</span>
<span class="sd">        action to perform applying regex patterns on text, by default &quot;clean&quot;</span>
<span class="sd">    patterns</span>
<span class="sd">        normalization regex patterns which match will be removed from document, by default [&#39;&lt;[^&gt;]*&gt;&#39;]</span>
<span class="sd">    replacement</span>
<span class="sd">        replacement string to apply when regexes match, by default &quot; &quot;</span>
<span class="sd">    lowercase</span>
<span class="sd">        whether to convert strings to lowercase, by default False</span>
<span class="sd">    policy</span>
<span class="sd">        policy to remove pattern from text, by default &quot;pretty_all&quot;</span>
<span class="sd">    encoding</span>
<span class="sd">        file encoding to apply on normalized documents, by default &quot;UTF-8&quot;</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        cleanUpPatterns = [&quot;&lt;[^&gt;]&gt;&quot;]</span>

<span class="sd">        documentNormalizer = DocumentNormalizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;normalizedDocument&quot;) \\</span>
<span class="sd">            .setAction(&quot;clean&quot;) \\</span>
<span class="sd">            .setPatterns(cleanUpPatterns) \\</span>
<span class="sd">            .setReplacement(&quot; &quot;) \\</span>
<span class="sd">            .setPolicy(&quot;pretty_all&quot;) \\</span>
<span class="sd">            .setLowercase(True)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            documentNormalizer</span>
<span class="sd">        ])</span>

<span class="sd">        text =</span>
<span class="sd">            \&quot;\&quot;\&quot;</span>
<span class="sd">        &lt;div id=&quot;theworldsgreatest&quot; class=&#39;my-right my-hide-small my-wide toptext&#39; style=&quot;font-family:&#39;Segoe UI&#39;,Arial,sans-serif&quot;&gt;</span>
<span class="sd">            THE WORLD&#39;S LARGEST WEB DEVELOPER SITE</span>
<span class="sd">            &lt;h1 style=&quot;font-size:300%;&quot;&gt;THE WORLD&#39;S LARGEST WEB DEVELOPER SITE&lt;/h1&gt;</span>
<span class="sd">            &lt;p style=&quot;font-size:160%;&quot;&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt;</span>
<span class="sd">        &lt;/div&gt;</span>

<span class="sd">        &lt;/div&gt;\&quot;\&quot;\&quot;</span>
<span class="sd">        data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)</span>
<span class="sd">        pipelineModel = pipeline.fit(data)</span>

<span class="sd">        result = pipelineModel.transform(data)</span>
<span class="sd">        result.selectExpr(&quot;normalizedDocument.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |</span>
<span class="sd">        +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        |[ the world&#39;s largest web developer site the world&#39;s largest web developer site lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..]|</span>
<span class="sd">        +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">action</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;action&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;action to perform applying regex patterns on text&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">patterns</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;patterns&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;normalization regex patterns which match will be removed from document. Defaults is &lt;[^&gt;]*&gt;&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">replacement</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;replacement&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;replacement string to apply when regexes match&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">lowercase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;lowercase&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;whether to convert strings to lowercase&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">policy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;policy&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;policy to remove pattern from text&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">encoding</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;encoding&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;file encoding to apply on normalized documents&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DocumentNormalizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.DocumentNormalizer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">action</span><span class="o">=</span><span class="s2">&quot;clean&quot;</span><span class="p">,</span>
            <span class="n">patterns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&lt;[^&gt;]*&gt;&quot;</span><span class="p">],</span>
            <span class="n">replacement</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">,</span>
            <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">policy</span><span class="o">=</span><span class="s2">&quot;pretty_all&quot;</span><span class="p">,</span>
            <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;UTF-8&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setAction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPatterns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">patterns</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setReplacement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">replacement</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLowercase</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lowercase</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPolicy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">policy</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEncoding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>


<div class="viewcode-block" id="Normalizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.Normalizer.html#sparknlp.annotator.Normalizer">[docs]</a><span class="k">class</span> <span class="nc">Normalizer</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotator that cleans out tokens. Requires stems, hence tokens.</span>
<span class="sd">    Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    cleanupPatterns</span>
<span class="sd">        normalization regex patterns which match will be removed from token, by default [&#39;[^\\pL+]&#39;]</span>
<span class="sd">    lowercase</span>
<span class="sd">        whether to convert strings to lowercase, by default False</span>
<span class="sd">    slangDictionary</span>
<span class="sd">        slang dictionary is a delimited text. needs &#39;delimiter&#39; in options</span>
<span class="sd">    minLength</span>
<span class="sd">        Set the minimum allowed legth for each token, by default 0</span>
<span class="sd">    maxLength</span>
<span class="sd">        Set the maximum allowed legth for each token</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        normalizer = Normalizer() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;normalized&quot;) \\</span>
<span class="sd">            .setLowercase(True) \\</span>
<span class="sd">            .setCleanupPatterns([\&quot;\&quot;\&quot;[^\w\d\s]\&quot;\&quot;\&quot;]) # remove punctuations (keep alphanumeric chars)</span>
<span class="sd">        # if we don&#39;t set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            normalizer</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;John and Peter are brothers. However they don&#39;t support each other that much.&quot;]]) \\</span>
<span class="sd">            .toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;normalized.result&quot;).show(truncate = False)</span>
<span class="sd">        +----------------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                                  |</span>
<span class="sd">        +----------------------------------------------------------------------------------------+</span>
<span class="sd">        |[john, and, peter, are, brothers, however, they, dont, support, each, other, that, much]|</span>
<span class="sd">        +----------------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">cleanupPatterns</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;cleanupPatterns&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;normalization regex patterns which match will be removed from token&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">lowercase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;lowercase&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;whether to convert strings to lowercase&quot;</span><span class="p">)</span>

    <span class="n">slangMatchCase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;slangMatchCase&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;whether or not to be case sensitive to match slangs. Defaults to false.&quot;</span><span class="p">)</span>

    <span class="n">slangDictionary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;slangDictionary&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;slang dictionary is a delimited text. needs &#39;delimiter&#39; in options&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">minLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;minLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the minimum allowed legth for each token&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;maxLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the maximum allowed legth for each token&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Normalizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.Normalizer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">cleanupPatterns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;[^</span><span class="se">\\</span><span class="s2">pL+]&quot;</span><span class="p">],</span>
            <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">slangMatchCase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">minLength</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCleanupPatterns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">cleanupPatterns</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLowercase</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lowercase</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSlangDictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;delimiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;delimiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delimiter</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">slangDictionary</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setMinLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">NormalizerModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="NormalizerModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NormalizerModel.html#sparknlp.annotator.NormalizerModel">[docs]</a><span class="k">class</span> <span class="nc">NormalizerModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated Model of the Normalizer. For usage and examples, please see the documentation of that class.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    cleanupPatterns</span>
<span class="sd">        normalization regex patterns which match will be removed from token</span>
<span class="sd">    lowercase</span>
<span class="sd">        whether to convert strings to lowercase</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">cleanupPatterns</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;cleanupPatterns&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;normalization regex patterns which match will be removed from token&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">lowercase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;lowercase&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;whether to convert strings to lowercase&quot;</span><span class="p">)</span>

    <span class="n">slangMatchCase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;slangMatchCase&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;whether or not to be case sensitive to match slangs. Defaults to false.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.NormalizerModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NormalizerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;NormalizerModel&quot;</span></div>


<div class="viewcode-block" id="RegexMatcher"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.RegexMatcher.html#sparknlp.annotator.RegexMatcher">[docs]</a><span class="k">class</span> <span class="nc">RegexMatcher</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Uses a reference file to match a set of regular expressions and associate them with a provided identifier.</span>

<span class="sd">    A dictionary of predefined regular expressions must be provided with ``setExternalRules``.</span>
<span class="sd">    The dictionary can be set in either in the form of a delimited text file or directly as an</span>
<span class="sd">    ExternalResource.</span>

<span class="sd">    Pretrained pipelines are available for this module, see `Pipelines &lt;https://nlp.johnsnowlabs.com/docs/en/pipelines&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    strategy</span>
<span class="sd">        Can be either MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE, by default &quot;MATCH_ALL&quot;</span>
<span class="sd">    externalRules</span>
<span class="sd">        external resource to rules, needs &#39;delimiter&#39; in options</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the `rules.txt` has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # the\s\w+, followed by &#39;the&#39;</span>
<span class="sd">        # ceremonies, ceremony</span>
<span class="sd">        #</span>
<span class="sd">        # where each regex is separated by the identifier by `&quot;,&quot;`</span>

<span class="sd">        documentAssembler = DocumentAssembler().setInputCol(&quot;text&quot;).setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector().setInputCols([&quot;document&quot;]).setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        regexMatcher = RegexMatcher() \\</span>
<span class="sd">            .setExternalRules(&quot;src/test/resources/regex-matcher/rules.txt&quot;,  &quot;,&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;regex&quot;) \\</span>
<span class="sd">            .setStrategy(&quot;MATCH_ALL&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([documentAssembler, sentence, regexMatcher])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;My first sentence with the first rule. This is my second sentence with ceremonies rule.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        results = pipeline.fit(data).transform(data)</span>

<span class="sd">        results.selectExpr(&quot;explode(regex) as result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                                      |</span>
<span class="sd">        +--------------------------------------------------------------------------------------------+</span>
<span class="sd">        |[chunk, 23, 31, the first, [identifier -&gt; followed by &#39;the&#39;, sentence -&gt; 0, chunk -&gt; 0], []]|</span>
<span class="sd">        |[chunk, 71, 80, ceremonies, [identifier -&gt; ceremony, sentence -&gt; 1, chunk -&gt; 0], []]        |</span>
<span class="sd">        +--------------------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">strategy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;strategy&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>
    <span class="n">externalRules</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;externalRules&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;external resource to rules, needs &#39;delimiter&#39; in options&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RegexMatcher</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.RegexMatcher&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;MATCH_ALL&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setStrategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExternalRules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;delimiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;delimiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delimiter</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">externalRules</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">RegexMatcherModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="RegexMatcherModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.RegexMatcherModel.html#sparknlp.annotator.RegexMatcherModel">[docs]</a><span class="k">class</span> <span class="nc">RegexMatcherModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated model of the RegexMatcher.</span>
<span class="sd">    For usage and examples see the documentation of the main class.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.RegexMatcherModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RegexMatcherModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;RegexMatcherModel&quot;</span></div>


<div class="viewcode-block" id="Lemmatizer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.Lemmatizer.html#sparknlp.annotator.Lemmatizer">[docs]</a><span class="k">class</span> <span class="nc">Lemmatizer</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Class to find lemmas out of words with the objective of returning a base dictionary word.</span>
<span class="sd">    Retrieves the significant part of a word. A dictionary of predefined lemmas must be provided with ``setDictionary``.</span>
<span class="sd">    The dictionary can be set in either in the form of a delimited text file or directly as an</span>
<span class="sd">    ExternalResource.</span>
<span class="sd">    Pretrained models can be loaded with LemmatizerModel.pretrained.</span>

<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Lemmatization&gt;`__.</span>
<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dictionary</span>
<span class="sd">        lemmatizer external dictionary.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the lemma dictionary `lemmas_small.txt` has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # pick	-&gt;	pick	picks	picking	picked</span>
<span class="sd">        # peck	-&gt;	peck	pecking	pecked	pecks</span>
<span class="sd">        # pickle	-&gt;	pickle	pickles	pickled	pickling</span>
<span class="sd">        # pepper	-&gt;	pepper	peppers	peppered	peppering</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # where each key is delimited by `-&gt;` and values are delimited by `\t`</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentenceDetector = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        lemmatizer = Lemmatizer() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;lemma&quot;) \\</span>
<span class="sd">            .setDictionary(&quot;src/test/resources/lemma-corpus-small/lemmas_small.txt&quot;, &quot;-&gt;&quot;, &quot;\t&quot;)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentenceDetector,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              lemmatizer</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers.&quot;]]) \\</span>
<span class="sd">            .toDF(&quot;text&quot;)</span>

<span class="sd">        result = pipeline.fit(data).transform(data)</span>
<span class="sd">        result.selectExpr(&quot;lemma.result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------------------------------+</span>
<span class="sd">        |result                                                            |</span>
<span class="sd">        +------------------------------------------------------------------+</span>
<span class="sd">        |[Peter, Pipers, employees, are, pick, peck, of, pickle, pepper, .]|</span>
<span class="sd">        +------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;dictionary&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;lemmatizer external dictionary.&quot;</span> <span class="o">+</span>
                       <span class="s2">&quot; needs &#39;keyDelimiter&#39; and &#39;valueDelimiter&#39; in options for parsing target text&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Lemmatizer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.Lemmatizer&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">LemmatizerModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">key_delimiter</span><span class="p">,</span> <span class="n">value_delimiter</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span>
                      <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;keyDelimiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;keyDelimiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">key_delimiter</span>
        <span class="k">if</span> <span class="s2">&quot;valueDelimiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;valueDelimiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_delimiter</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dictionary</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span></div>


<div class="viewcode-block" id="LemmatizerModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.LemmatizerModel.html#sparknlp.annotator.LemmatizerModel">[docs]</a><span class="k">class</span> <span class="nc">LemmatizerModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated Model of the Lemmatizer. For usage and examples, please see the documentation of that class.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Lemmatization&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # The lemmatizer from the example of the Lemmatizer can be replaced with:</span>
<span class="sd">        lemmatizer = LemmatizerModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;lemma&quot;)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;LemmatizerModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.LemmatizerModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LemmatizerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;lemma_antbnc&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">LemmatizerModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="DateMatcherUtils"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DateMatcherUtils.html#sparknlp.annotator.DateMatcherUtils">[docs]</a><span class="k">class</span> <span class="nc">DateMatcherUtils</span><span class="p">(</span><span class="n">Params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for DateMatcher Annotators</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dateFormat</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;dateFormat&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;desired format for dates extracted&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">readMonthFirst</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;readMonthFirst&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Whether to parse july 07/05/2015 or as 05/07/2015&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span>
                           <span class="p">)</span>

    <span class="n">defaultDayWhenMissing</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                  <span class="s2">&quot;defaultDayWhenMissing&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;which day to set when it is missing from parsed input&quot;</span><span class="p">,</span>
                                  <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span>
                                  <span class="p">)</span>

    <span class="n">anchorDateYear</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;anchorDateYear&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Add an anchor year for the relative dates such as a day after tomorrow. If not set it &quot;</span>
                           <span class="s2">&quot;will use the current year. Example: 2021&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span>
                           <span class="p">)</span>

    <span class="n">anchorDateMonth</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;anchorDateMonth&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Add an anchor month for the relative dates such as a day after tomorrow. If not set it &quot;</span>
                            <span class="s2">&quot;will use the current month. Example: 1 which means January&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span>
                            <span class="p">)</span>

    <span class="n">anchorDateDay</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;anchorDateDay&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;Add an anchor day of the day for the relative dates such as a day after tomorrow. If not &quot;</span>
                          <span class="s2">&quot;set it will use the current day. Example: 11&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span>
                          <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setFormat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dateFormat</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setReadMonthFirst</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">readMonthFirst</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDefaultDayWhenMissing</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">defaultDayWhenMissing</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setAnchorDateYear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">anchorDateYear</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setAnchorDateMonth</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">normalizedMonth</span> <span class="o">=</span> <span class="n">value</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">anchorDateMonth</span><span class="o">=</span><span class="n">normalizedMonth</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setAnchorDateDay</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">anchorDateDay</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>


<div class="viewcode-block" id="DateMatcher"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DateMatcher.html#sparknlp.annotator.DateMatcher">[docs]</a><span class="k">class</span> <span class="nc">DateMatcher</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">DateMatcherUtils</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Matches standard date formats into a provided format</span>
<span class="sd">    Reads from different forms of date and time expressions and converts them to a provided date format.</span>

<span class="sd">    Extracts only **one** date per document. Use with sentence detector to find matches in each sentence.</span>
<span class="sd">    To extract multiple dates from a document, please use the MultiDateMatcher.</span>

<span class="sd">    Reads the following kind of dates:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        &quot;1978-01-28&quot;, &quot;1984/04/02,1/02/1980&quot;, &quot;2/28/79&quot;, &quot;The 31st of April in the year 2008&quot;,</span>
<span class="sd">        &quot;Fri, 21 Nov 1997&quot;, &quot;Jan 21, 97&quot;, &quot;Sun&quot;, &quot;Nov 21&quot;, &quot;jan 1st&quot;, &quot;next thursday&quot;,</span>
<span class="sd">        &quot;last wednesday&quot;, &quot;today&quot;, &quot;tomorrow&quot;, &quot;yesterday&quot;, &quot;next week&quot;, &quot;next month&quot;,</span>
<span class="sd">        &quot;next year&quot;, &quot;day after&quot;, &quot;the day before&quot;, &quot;0600h&quot;, &quot;06:00 hours&quot;, &quot;6pm&quot;, &quot;5:30 a.m.&quot;,</span>
<span class="sd">        &quot;at 5&quot;, &quot;12:59&quot;, &quot;23:59&quot;, &quot;1988/11/23 6pm&quot;, &quot;next week at 7.30&quot;, &quot;5 am tomorrow&quot;</span>



<span class="sd">    For example ``&quot;The 31st of April in the year 2008&quot;`` will be converted into ``2008/04/31``.</span>

<span class="sd">    Pretrained pipelines are available for this module, see `Pipelines &lt;https://nlp.johnsnowlabs.com/docs/en/pipelines&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DATE``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dateFormat</span>
<span class="sd">        desired format for dates extracted</span>
<span class="sd">    readMonthFirst</span>
<span class="sd">        Whether to parse july 07/05/2015 or as 05/07/2015</span>
<span class="sd">    defaultDayWhenMissing</span>
<span class="sd">        which day to set when it is missing from parsed input</span>
<span class="sd">    anchorDateYear</span>
<span class="sd">        Add an anchor year for the relative dates such as a day after tomorrow. If not set it</span>
<span class="sd">        will use the current year. Example: 2021</span>
<span class="sd">    anchorDateMonth</span>
<span class="sd">        Add an anchor month for the relative dates such as a day after tomorrow. If not set it</span>
<span class="sd">        will use the current month. Example: 1 which means January</span>
<span class="sd">    anchorDateDay</span>
<span class="sd">        Add an anchor day of the day for the relative dates such as a day after tomorrow. If not</span>
<span class="sd">        set it will use the current day. Example: 11</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        date = DateMatcher() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;date&quot;) \\</span>
<span class="sd">            .setAnchorDateYear(2020) \\</span>
<span class="sd">            .setAnchorDateMonth(1) \\</span>
<span class="sd">            .setAnchorDateDay(11)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            date</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Fri, 21 Nov 1997&quot;, &quot;next week at 7.30&quot;, &quot;see you a day after&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;date&quot;).show(truncate=False)</span>
<span class="sd">        +-------------------------------------------------+</span>
<span class="sd">        |date                                             |</span>
<span class="sd">        +-------------------------------------------------+</span>
<span class="sd">        |5, 15, 1997/11/21, [sentence -&gt; 0], [] |</span>
<span class="sd">        |0, 8, 2020/01/18, [sentence -&gt; 0], []  |</span>
<span class="sd">        |10, 18, 2020/01/12, [sentence -&gt; 0], []|</span>
<span class="sd">        +-------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;DateMatcher&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DateMatcher</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.DateMatcher&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dateFormat</span><span class="o">=</span><span class="s2">&quot;yyyy/MM/dd&quot;</span><span class="p">,</span>
            <span class="n">readMonthFirst</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">defaultDayWhenMissing</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">anchorDateYear</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">anchorDateMonth</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">anchorDateDay</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MultiDateMatcher"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.MultiDateMatcher.html#sparknlp.annotator.MultiDateMatcher">[docs]</a><span class="k">class</span> <span class="nc">MultiDateMatcher</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">DateMatcherUtils</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Matches standard date formats into a provided format.</span>

<span class="sd">    Reads the following kind of dates:</span>

<span class="sd">    .. code-block:: none</span>

<span class="sd">        &quot;1978-01-28&quot;, &quot;1984/04/02,1/02/1980&quot;, &quot;2/28/79&quot;, &quot;The 31st of April in the year 2008&quot;,</span>
<span class="sd">        &quot;Fri, 21 Nov 1997&quot;, &quot;Jan 21, 97&quot;, &quot;Sun&quot;, &quot;Nov 21&quot;, &quot;jan 1st&quot;, &quot;next thursday&quot;,</span>
<span class="sd">        &quot;last wednesday&quot;, &quot;today&quot;, &quot;tomorrow&quot;, &quot;yesterday&quot;, &quot;next week&quot;, &quot;next month&quot;,</span>
<span class="sd">        &quot;next year&quot;, &quot;day after&quot;, &quot;the day before&quot;, &quot;0600h&quot;, &quot;06:00 hours&quot;, &quot;6pm&quot;, &quot;5:30 a.m.&quot;,</span>
<span class="sd">        &quot;at 5&quot;, &quot;12:59&quot;, &quot;23:59&quot;, &quot;1988/11/23 6pm&quot;, &quot;next week at 7.30&quot;, &quot;5 am tomorrow&quot;</span>



<span class="sd">    For example ``&quot;The 31st of April in the year 2008&quot;`` will be converted into ``2008/04/31``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DATE``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dateFormat</span>
<span class="sd">        desired format for dates extracted</span>
<span class="sd">    readMonthFirst</span>
<span class="sd">        Whether to parse july 07/05/2015 or as 05/07/2015</span>
<span class="sd">    defaultDayWhenMissing</span>
<span class="sd">        which day to set when it is missing from parsed input</span>
<span class="sd">    anchorDateYear</span>
<span class="sd">        Add an anchor year for the relative dates such as a day after tomorrow. If not set it</span>
<span class="sd">        will use the current year. Example: 2021</span>
<span class="sd">    anchorDateMonth</span>
<span class="sd">        Add an anchor month for the relative dates such as a day after tomorrow. If not set it</span>
<span class="sd">        will use the current month. Example: 1 which means January</span>
<span class="sd">    anchorDateDay</span>
<span class="sd">        Add an anchor day of the day for the relative dates such as a day after tomorrow. If not</span>
<span class="sd">        set it will use the current day. Example: 11</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        date = MultiDateMatcher() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;date&quot;) \\</span>
<span class="sd">            .setAnchorDateYear(2020) \\</span>
<span class="sd">            .setAnchorDateMonth(1) \\</span>
<span class="sd">            .setAnchorDateDay(11)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            date</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;I saw him yesterday and he told me that he will visit us next week&quot;]]) \\</span>
<span class="sd">            .toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(date) as dates&quot;).show(truncate=False)</span>
<span class="sd">        +-----------------------------------------------+</span>
<span class="sd">        |dates                                          |</span>
<span class="sd">        +-----------------------------------------------+</span>
<span class="sd">        |[date, 57, 65, 2020/01/18, [sentence -&gt; 0], []]|</span>
<span class="sd">        |[date, 10, 18, 2020/01/10, [sentence -&gt; 0], []]|</span>
<span class="sd">        +-----------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;MultiDateMatcher&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiDateMatcher</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.MultiDateMatcher&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dateFormat</span><span class="o">=</span><span class="s2">&quot;yyyy/MM/dd&quot;</span><span class="p">,</span>
            <span class="n">readMonthFirst</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">defaultDayWhenMissing</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="TextMatcher"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.TextMatcher.html#sparknlp.annotator.TextMatcher">[docs]</a><span class="k">class</span> <span class="nc">TextMatcher</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotator to match exact phrases (by token) provided in a file against a Document.</span>

<span class="sd">    A text file of predefined phrases must be provided with ``setEntities``.</span>
<span class="sd">    The text file can als be set directly as an</span>
<span class="sd">    ExternalResource.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    entities</span>
<span class="sd">        ExternalResource for entities</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        whether to match regardless of case. Defaults true</span>
<span class="sd">    mergeOverlapping</span>
<span class="sd">        whether to merge overlapping matched chunks. Defaults false</span>
<span class="sd">    entityValue</span>
<span class="sd">        value for the entity metadata field</span>
<span class="sd">    buildFromTokens</span>
<span class="sd">        whether the TextMatcher should take the CHUNK from TOKEN or not</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the entities file is of the form</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # dolore magna aliqua</span>
<span class="sd">        # lorem ipsum dolor. sit</span>
<span class="sd">        # laborum</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # where each line represents an entity phrase to be extracted.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        entityExtractor = TextMatcher() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setEntities(&quot;src/test/resources/entity-extractor/test-phrases.txt&quot;, ReadAs.TEXT) \\</span>
<span class="sd">            .setOutputCol(&quot;entity&quot;) \\</span>
<span class="sd">            .setCaseSensitive(False) \\</span>
<span class="sd">            .setTokenizer(tokenizer.fit(data))</span>

<span class="sd">        pipeline = Pipeline().setStages([documentAssembler, tokenizer, entityExtractor])</span>
<span class="sd">        results = pipeline.fit(data).transform(data)</span>

<span class="sd">        results.selectExpr(&quot;explode(entity) as result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                                    |</span>
<span class="sd">        +------------------------------------------------------------------------------------------+</span>
<span class="sd">        |[chunk, 6, 24, dolore magna aliqua, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 0], []]    |</span>
<span class="sd">        |[chunk, 27, 48, Lorem ipsum dolor. sit, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 1], []]|</span>
<span class="sd">        |[chunk, 53, 59, laborum, [entity -&gt; entity, sentence -&gt; 0, chunk -&gt; 2], []]               |</span>
<span class="sd">        +------------------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">entities</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;entities&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;ExternalResource for entities&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">caseSensitive</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;caseSensitive&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;whether to match regardless of case. Defaults true&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">mergeOverlapping</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;mergeOverlapping&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to merge overlapping matched chunks. Defaults false&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">entityValue</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;entityValue&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;value for the entity metadata field&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">buildFromTokens</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;buildFromTokens&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;whether the TextMatcher should take the CHUNK from TOKEN or not&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TextMatcher</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.TextMatcher&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">mergeOverlapping</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TextMatcherModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEntities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">entities</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">setCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMergeOverlapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">mergeOverlapping</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEntityValue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">entityValue</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setBuildFromTokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">buildFromTokens</span><span class="o">=</span><span class="n">b</span><span class="p">)</span></div>


<div class="viewcode-block" id="TextMatcherModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.TextMatcherModel.html#sparknlp.annotator.TextMatcherModel">[docs]</a><span class="k">class</span> <span class="nc">TextMatcherModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated model of the TextMatcher.</span>
<span class="sd">    For usage and examples see the documentation of the main class.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    mergeOverlapping</span>
<span class="sd">        whether to merge overlapping matched chunks. Defaults false</span>
<span class="sd">    searchTrie</span>
<span class="sd">        searchTrie</span>
<span class="sd">    entityValue</span>
<span class="sd">        value for the entity metadata field</span>
<span class="sd">    buildFromTokens</span>
<span class="sd">        whether the TextMatcher should take the CHUNK from TOKEN or not</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;TextMatcherModel&quot;</span>

    <span class="n">mergeOverlapping</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;mergeOverlapping&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to merge overlapping matched chunks. Defaults false&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">searchTrie</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;searchTrie&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;searchTrie&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">entityValue</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;entityValue&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;value for the entity metadata field&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">buildFromTokens</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;buildFromTokens&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;whether the TextMatcher should take the CHUNK from TOKEN or not&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.TextMatcherModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TextMatcherModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMergeOverlapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">mergeOverlapping</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEntityValue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">entityValue</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setBuildFromTokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">buildFromTokens</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">TextMatcherModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="BigTextMatcher"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.BigTextMatcher.html#sparknlp.annotator.BigTextMatcher">[docs]</a><span class="k">class</span> <span class="nc">BigTextMatcher</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">,</span> <span class="n">HasStorage</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotator to match exact phrases (by token) provided in a file against a Document.</span>

<span class="sd">    A text file of predefined phrases must be provided with ``setStoragePath``.</span>
<span class="sd">    The text file can als be set directly as an</span>
<span class="sd">    ExternalResource.</span>

<span class="sd">    In contrast to the normal ``TextMatcher``, the ``BigTextMatcher`` is designed for large corpora.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    entities</span>
<span class="sd">        ExternalResource for entities</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        whether to ignore case in index lookups , by default True</span>
<span class="sd">    mergeOverlapping</span>
<span class="sd">        whether to merge overlapping matched chunks, by default False</span>
<span class="sd">    tokenizer</span>
<span class="sd">        TokenizerModel to use to tokenize input file for building a Trie</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the entities file is of the form</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # dolore magna aliqua</span>
<span class="sd">        # lorem ipsum dolor. sit</span>
<span class="sd">        # laborum</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # where each line represents an entity phrase to be extracted.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        entityExtractor = BigTextMatcher() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setStoragePath(&quot;src/test/resources/entity-extractor/test-phrases.txt&quot;, ReadAs.TEXT) \\</span>
<span class="sd">            .setOutputCol(&quot;entity&quot;) \\</span>
<span class="sd">            .setCaseSensitive(False)</span>

<span class="sd">        pipeline = Pipeline().setStages([documentAssembler, tokenizer, entityExtractor])</span>
<span class="sd">        results = pipeline.fit(data).transform(data)</span>
<span class="sd">        results.selectExpr(&quot;explode(entity)&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------------------------+</span>
<span class="sd">        |col                                                                 |</span>
<span class="sd">        +--------------------------------------------------------------------+</span>
<span class="sd">        |[chunk, 6, 24, dolore magna aliqua, [sentence -&gt; 0, chunk -&gt; 0], []]|</span>
<span class="sd">        |[chunk, 53, 59, laborum, [sentence -&gt; 0, chunk -&gt; 1], []]           |</span>
<span class="sd">        +--------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">entities</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;entities&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;ExternalResource for entities&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">caseSensitive</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;caseSensitive&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;whether to ignore case in index lookups&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">mergeOverlapping</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;mergeOverlapping&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to merge overlapping matched chunks. Defaults false&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;tokenizer&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;TokenizerModel to use to tokenize input file for building a Trie&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BigTextMatcher</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.btm.BigTextMatcher&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">mergeOverlapping</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TextMatcherModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEntities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">entities</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">setCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMergeOverlapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">mergeOverlapping</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer_model</span><span class="p">):</span>
        <span class="n">tokenizer_model</span><span class="o">.</span><span class="n">_transfer_params_to_java</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">tokenizer_model</span><span class="o">.</span><span class="n">_java_obj</span><span class="p">)</span></div>


<div class="viewcode-block" id="BigTextMatcherModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.BigTextMatcherModel.html#sparknlp.annotator.BigTextMatcherModel">[docs]</a><span class="k">class</span> <span class="nc">BigTextMatcherModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasStorageModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiated model of the BigTextMatcher.</span>
<span class="sd">    For usage and examples see the documentation of the main class.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    caseSensitive</span>
<span class="sd">        whether to ignore case in index lookups</span>
<span class="sd">    mergeOverlapping</span>
<span class="sd">        whether to merge overlapping matched chunks. Defaults false</span>
<span class="sd">    searchTrie</span>
<span class="sd">        searchTrie</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;BigTextMatcherModel&quot;</span>
    <span class="n">databases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TMVOCAB&#39;</span><span class="p">,</span> <span class="s1">&#39;TMEDGES&#39;</span><span class="p">,</span> <span class="s1">&#39;TMNODES&#39;</span><span class="p">]</span>

    <span class="n">caseSensitive</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;caseSensitive&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;whether to ignore case in index lookups&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">mergeOverlapping</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;mergeOverlapping&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to merge overlapping matched chunks. Defaults false&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">searchTrie</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;searchTrie&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;searchTrie&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.btm.TextMatcherModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BigTextMatcherModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMergeOverlapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">mergeOverlapping</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">TextMatcherModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadStorage</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">storage_ref</span><span class="p">):</span>
        <span class="n">HasStorageModel</span><span class="o">.</span><span class="n">loadStorages</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">storage_ref</span><span class="p">,</span> <span class="n">BigTextMatcherModel</span><span class="o">.</span><span class="n">databases</span><span class="p">)</span></div>


<div class="viewcode-block" id="PerceptronApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.PerceptronApproach.html#sparknlp.annotator.PerceptronApproach">[docs]</a><span class="k">class</span> <span class="nc">PerceptronApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains an averaged Perceptron model to tag words part-of-speech.</span>
<span class="sd">    Sets a POS tag to each word within a sentence.</span>

<span class="sd">    For pretrained models please see the PerceptronModel.</span>

<span class="sd">    The training data needs to be in a Spark DataFrame, where the column needs to consist of</span>
<span class="sd">    Annotations of type ``POS``. The ``Annotation`` needs to have member ``result``</span>
<span class="sd">    set to the POS tag and have a ``&quot;word&quot;`` mapping to its word inside of member ``metadata``.</span>
<span class="sd">    This DataFrame for training can easily created by the helper class POS.</span>


<span class="sd">    &gt;&gt;&gt; POS().readDataset(spark, datasetPath).selectExpr(&quot;explode(tags) as tags&quot;).show(truncate=False)</span>
<span class="sd">    +---------------------------------------------+</span>
<span class="sd">    |tags                                         |</span>
<span class="sd">    +---------------------------------------------+</span>
<span class="sd">    |[pos, 0, 5, NNP, [word -&gt; Pierre], []]       |</span>
<span class="sd">    |[pos, 7, 12, NNP, [word -&gt; Vinken], []]      |</span>
<span class="sd">    |[pos, 14, 14, ,, [word -&gt; ,], []]            |</span>
<span class="sd">    |[pos, 31, 34, MD, [word -&gt; will], []]        |</span>
<span class="sd">    |[pos, 36, 39, VB, [word -&gt; join], []]        |</span>
<span class="sd">    |[pos, 41, 43, DT, [word -&gt; the], []]         |</span>
<span class="sd">    |[pos, 45, 49, NN, [word -&gt; board], []]       |</span>
<span class="sd">                            ...</span>


<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/french/Train-Perceptron-French.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN, DOCUMENT``    ``POS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    posCol</span>
<span class="sd">        column of Array of POS tags that match tokens</span>
<span class="sd">    nIterations</span>
<span class="sd">        Number of iterations in training, converges to better accuracy, by default 5</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        datasetPath = &quot;src/test/resources/anc-pos-corpus-small/test-training.txt&quot;</span>
<span class="sd">        trainingPerceptronDF = POS().readDataset(spark, datasetPath)</span>

<span class="sd">        trainedPos = PerceptronApproach() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;) \\</span>
<span class="sd">            .setPosColumn(&quot;tags&quot;) \\</span>
<span class="sd">            .fit(trainingPerceptronDF)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            trainedPos</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;To be or not to be, is this the question?&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;pos.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------+</span>
<span class="sd">        |result                                            |</span>
<span class="sd">        +--------------------------------------------------+</span>
<span class="sd">        |[NNP, NNP, CD, JJ, NNP, NNP, ,, MD, VB, DT, CD, .]|</span>
<span class="sd">        +--------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">posCol</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;posCol&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;column of Array of POS tags that match tokens&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">nIterations</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;nIterations&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Number of iterations in training, converges to better accuracy&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PerceptronApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">nIterations</span><span class="o">=</span><span class="mi">5</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPosColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">posCol</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIterations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">nIterations</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getNIterations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nIterations</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">PerceptronModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="PerceptronModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.PerceptronModel.html#sparknlp.annotator.PerceptronModel">[docs]</a><span class="k">class</span> <span class="nc">PerceptronModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Averaged Perceptron model to tag words part-of-speech.</span>
<span class="sd">    Sets a POS tag to each word within a sentence.</span>

<span class="sd">    This is the instantiated model of the</span>
<span class="sd">    PerceptronApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>


<span class="sd">    The default model is ``&quot;pos_anc&quot;``, if no name is provided.</span>

<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Part+of+Speech+Tagging&gt;`__.</span>
<span class="sd">    Additionally, pretrained pipelines are available for this module, see `Pipelines &lt;https://nlp.johnsnowlabs.com/docs/en/pipelines&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN, DOCUMENT``    ``POS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    None</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            posTagger</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Peter Pipers employees are picking pecks of pickled peppers&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(pos) as pos&quot;).show(truncate=False)</span>
<span class="sd">        +-------------------------------------------+</span>
<span class="sd">        |pos                                        |</span>
<span class="sd">        +-------------------------------------------+</span>
<span class="sd">        |[pos, 0, 4, NNP, [word -&gt; Peter], []]      |</span>
<span class="sd">        |[pos, 6, 11, NNP, [word -&gt; Pipers], []]    |</span>
<span class="sd">        |[pos, 13, 21, NNS, [word -&gt; employees], []]|</span>
<span class="sd">        |[pos, 23, 25, VBP, [word -&gt; are], []]      |</span>
<span class="sd">        |[pos, 27, 33, VBG, [word -&gt; picking], []]  |</span>
<span class="sd">        |[pos, 35, 39, NNS, [word -&gt; pecks], []]    |</span>
<span class="sd">        |[pos, 41, 42, IN, [word -&gt; of], []]        |</span>
<span class="sd">        |[pos, 44, 50, JJ, [word -&gt; pickled], []]   |</span>
<span class="sd">        |[pos, 52, 58, NNS, [word -&gt; peppers], []]  |</span>
<span class="sd">        +-------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;PerceptronModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PerceptronModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;pos_anc&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">PerceptronModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="SentenceDetectorParams"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentenceDetectorParams.html#sparknlp.annotator.SentenceDetectorParams">[docs]</a><span class="k">class</span> <span class="nc">SentenceDetectorParams</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Base class for SentenceDetector parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">useAbbreviations</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;useAbbreviations&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to apply abbreviations at sentence detection&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">customBounds</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;customBounds&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;characters used to explicitly mark sentence bounds&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">useCustomBoundsOnly</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                <span class="s2">&quot;useCustomBoundsOnly&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;Only utilize custom bounds in sentence detection&quot;</span><span class="p">,</span>
                                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">explodeSentences</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;explodeSentences&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to explode each sentence into a different row, for better parallelization. Defaults to false.&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">splitLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;splitLength&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;length at which sentences will be forcibly split.&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">minLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;minLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the minimum allowed length for each sentence.&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;maxLength&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Set the maximum allowed length for each sentence&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span></div>


<div class="viewcode-block" id="SentenceDetector"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentenceDetector.html#sparknlp.annotator.SentenceDetector">[docs]</a><span class="k">class</span> <span class="nc">SentenceDetector</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">SentenceDetectorParams</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotator that detects sentence boundaries using any provided approach.</span>

<span class="sd">    Each extracted sentence can be returned in an Array or exploded to separate rows,</span>
<span class="sd">    if ``explodeSentences`` is set to ``true``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DOCUMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    useAbbreviations</span>
<span class="sd">        whether to apply abbreviations at sentence detection, by default True</span>
<span class="sd">    customBounds</span>
<span class="sd">        characters used to explicitly mark sentence bounds, by default []</span>
<span class="sd">    useCustomBoundsOnly</span>
<span class="sd">        Only utilize custom bounds in sentence detection, by default False</span>
<span class="sd">    explodeSentences</span>
<span class="sd">        whether to explode each sentence into a different row, for better parallelization , by default False</span>
<span class="sd">    splitLength</span>
<span class="sd">        length at which sentences will be forcibly split</span>
<span class="sd">    minLength</span>
<span class="sd">        Set the minimum allowed length for each sentence, by default 0</span>
<span class="sd">    maxLength</span>
<span class="sd">        Set the maximum allowed length for each sentence, by default 99999</span>
<span class="sd">    detectLists</span>
<span class="sd">        whether detect lists during sentence detection, by default True</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is my first sentence. This my second. How about a third?&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(sentence) as sentences&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------------------------------+</span>
<span class="sd">        |sentences                                                         |</span>
<span class="sd">        +------------------------------------------------------------------+</span>
<span class="sd">        |[document, 0, 25, This is my first sentence., [sentence -&gt; 0], []]|</span>
<span class="sd">        |[document, 27, 41, This my second., [sentence -&gt; 1], []]          |</span>
<span class="sd">        |[document, 43, 60, How about a third?, [sentence -&gt; 2], []]       |</span>
<span class="sd">        +------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;SentenceDetector&#39;</span>

    <span class="c1"># this one is exclusive to this detector</span>
    <span class="n">detectLists</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;detectLists&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;whether detect lists during sentence detection&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCustomBounds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">customBounds</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setUseAbbreviations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">useAbbreviations</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDetectLists</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">detectLists</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setUseCustomBoundsOnly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">useCustomBoundsOnly</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExplodeSentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">explodeSentences</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSplitLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">splitLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentenceDetector</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">useAbbreviations</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">detectLists</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">useCustomBoundsOnly</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">customBounds</span><span class="o">=</span><span class="p">[],</span>
            <span class="n">explodeSentences</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">minLength</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">maxLength</span><span class="o">=</span><span class="mi">99999</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="SentimentDetector"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentimentDetector.html#sparknlp.annotator.SentimentDetector">[docs]</a><span class="k">class</span> <span class="nc">SentimentDetector</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a rule based sentiment detector, which calculates a score based on predefined keywords.</span>

<span class="sd">    A dictionary of predefined sentiment keywords must be provided with ``setDictionary``, where each line is a word</span>
<span class="sd">    delimited to its class (either ``positive`` or ``negative``).</span>
<span class="sd">    The dictionary can be set in either in the form of a delimited text file or directly as an</span>
<span class="sd">    ExternalResource.</span>

<span class="sd">    By default, the sentiment score will be assigned labels ``&quot;positive&quot;`` if the score is ``&gt;= 0``, else ``&quot;negative&quot;``.</span>
<span class="sd">    To retrieve the raw sentiment scores, ``enableScore`` needs to be set to ``true``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dictionary-sentiment/sentiment.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN, DOCUMENT``    ``SENTIMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dictionary</span>
<span class="sd">        path for dictionary to sentiment analysis</span>
<span class="sd">    positiveMultiplier</span>
<span class="sd">        multiplier for positive sentiments. Defaults 1.0</span>
<span class="sd">    negativeMultiplier</span>
<span class="sd">        multiplier for negative sentiments. Defaults -1.0</span>
<span class="sd">    incrementMultiplier</span>
<span class="sd">        multiplier for increment sentiments. Defaults 2.0</span>
<span class="sd">    decrementMultiplier</span>
<span class="sd">        multiplier for decrement sentiments. Defaults -2.0</span>
<span class="sd">    reverseMultiplier</span>
<span class="sd">        multiplier for revert sentiments. Defaults -1.0</span>
<span class="sd">    enableScore</span>
<span class="sd">        if true, score will show as the double value, else will output string &quot;positive&quot; or &quot;negative&quot;, by default False</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the dictionary `default-sentiment-dict.txt` has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # cool,positive</span>
<span class="sd">        # superb,positive</span>
<span class="sd">        # bad,negative</span>
<span class="sd">        # uninspired,negative</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # where each sentiment keyword is delimited by `&quot;,&quot;`.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        lemmatizer = Lemmatizer() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;lemma&quot;) \\</span>
<span class="sd">            .setDictionary(&quot;src/test/resources/lemma-corpus-small/lemmas_small.txt&quot;, &quot;-&gt;&quot;, &quot;\t&quot;)</span>

<span class="sd">        sentimentDetector = SentimentDetector() \\</span>
<span class="sd">            .setInputCols([&quot;lemma&quot;, &quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentimentScore&quot;) \\</span>
<span class="sd">            .setDictionary(&quot;src/test/resources/sentiment-corpus/default-sentiment-dict.txt&quot;, &quot;,&quot;, ReadAs.TEXT)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            lemmatizer,</span>
<span class="sd">            sentimentDetector,</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;The staff of the restaurant is nice&quot;,</span>
<span class="sd">            &quot;I recommend others to avoid because it is too expensive&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;sentimentScore.result&quot;).show(truncate=False)</span>
<span class="sd">        +----------+  #  +------+ for enableScore set to True</span>
<span class="sd">        |result    |  #  |result|</span>
<span class="sd">        +----------+  #  +------+</span>
<span class="sd">        |[positive]|  #  |[1.0] |</span>
<span class="sd">        |[negative]|  #  |[-2.0]|</span>
<span class="sd">        +----------+  #  +------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;dictionary&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;path for dictionary to sentiment analysis&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">positiveMultiplier</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;positiveMultiplier&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;multiplier for positive sentiments. Defaults 1.0&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">negativeMultiplier</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;negativeMultiplier&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;multiplier for negative sentiments. Defaults -1.0&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">incrementMultiplier</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                <span class="s2">&quot;incrementMultiplier&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;multiplier for increment sentiments. Defaults 2.0&quot;</span><span class="p">,</span>
                                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">decrementMultiplier</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                <span class="s2">&quot;decrementMultiplier&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;multiplier for decrement sentiments. Defaults -2.0&quot;</span><span class="p">,</span>
                                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">reverseMultiplier</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;reverseMultiplier&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;multiplier for revert sentiments. Defaults -1.0&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">enableScore</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;enableScore&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;if true, score will show as the double value, else will output string </span><span class="se">\&quot;</span><span class="s2">positive</span><span class="se">\&quot;</span><span class="s2"> or </span><span class="se">\&quot;</span><span class="s2">negative</span><span class="se">\&quot;</span><span class="s2">. Defaults false&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentimentDetector</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sda.pragmatic.SentimentDetector&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">positiveMultiplier</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">negativeMultiplier</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">incrementMultiplier</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                         <span class="n">decrementMultiplier</span><span class="o">=-</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">reverseMultiplier</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">enableScore</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;format&#39;</span><span class="p">:</span> <span class="s1">&#39;text&#39;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;delimiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;delimiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delimiter</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dictionary</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">SentimentDetectorModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="SentimentDetectorModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentimentDetectorModel.html#sparknlp.annotator.SentimentDetectorModel">[docs]</a><span class="k">class</span> <span class="nc">SentimentDetectorModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Rule based sentiment detector, which calculates a score based on predefined keywords.</span>

<span class="sd">    This is the instantiated model of the SentimentDetector.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    A dictionary of predefined sentiment keywords must be provided with ``setDictionary``, where each line is a word</span>
<span class="sd">    delimited to its class (either ``positive`` or ``negative``).</span>
<span class="sd">    The dictionary can be set in either in the form of a delimited text file or directly as an</span>
<span class="sd">    ExternalResource.</span>

<span class="sd">    By default, the sentiment score will be assigned labels ``&quot;positive&quot;`` if the score is ``&gt;= 0``, else ``&quot;negative&quot;``.</span>
<span class="sd">    To retrieve the raw sentiment scores, ``enableScore`` needs to be set to ``true``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dictionary-sentiment/sentiment.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN, DOCUMENT``    ``SENTIMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    positiveMultiplier</span>
<span class="sd">        multiplier for positive sentiments. Defaults 1.0</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;SentimentDetectorModel&quot;</span>

    <span class="n">positiveMultiplier</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;positiveMultiplier&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;multiplier for positive sentiments. Defaults 1.0&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sda.pragmatic.SentimentDetectorModel&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentimentDetectorModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ViveknSentimentApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ViveknSentimentApproach.html#sparknlp.annotator.ViveknSentimentApproach">[docs]</a><span class="k">class</span> <span class="nc">ViveknSentimentApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a sentiment analyser inspired by the algorithm by Vivek Narayanan https://github.com/vivekn/sentiment/.</span>

<span class="sd">    The algorithm is based on the paper</span>
<span class="sd">    `&quot;Fast and accurate sentiment classification using an enhanced Naive Bayes model&quot; &lt;https://arxiv.org/abs/1305.6143&gt;`__.</span>

<span class="sd">    The analyzer requires sentence boundaries to give a score in context.</span>
<span class="sd">    Tokenization is needed to make sure tokens are within bounds. Transitivity requirements are also required.</span>

<span class="sd">    The training data needs to consist of a column for normalized text and a label column (either ``&quot;positive&quot;`` or ``&quot;negative&quot;``).</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN, DOCUMENT``    ``SENTIMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    sentimentCol</span>
<span class="sd">        column with the sentiment result of every row. Must be &#39;positive&#39; or &#39;negative&#39;</span>
<span class="sd">    pruneCorpus</span>
<span class="sd">        Removes unfrequent scenarios from scope. The higher the better performance. Defaults 1</span>
<span class="sd">    importantFeatureRatio</span>
<span class="sd">        proportion of feature content to be considered relevant. Defaults to 0.5</span>
<span class="sd">    unimportantFeatureStep</span>
<span class="sd">        proportion to lookahead in unimportant features. Defaults to 0.025</span>
<span class="sd">    featureLimit</span>
<span class="sd">        content feature limit, to boost performance in very dirt text. Default disabled with -1</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        document = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        token = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        normalizer = Normalizer() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;normal&quot;)</span>

<span class="sd">        vivekn = ViveknSentimentApproach() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;normal&quot;]) \\</span>
<span class="sd">            .setSentimentCol(&quot;train_sentiment&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;result_sentiment&quot;)</span>

<span class="sd">        finisher = Finisher() \\</span>
<span class="sd">            .setInputCols([&quot;result_sentiment&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;final_sentiment&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([document, token, normalizer, vivekn, finisher])</span>

<span class="sd">        training = spark.createDataFrame([[</span>
<span class="sd">            &quot;I really liked this movie!&quot;, &quot;positive&quot;),</span>
<span class="sd">            (&quot;The cast was horrible&quot;, &quot;negative&quot;),</span>
<span class="sd">            (&quot;Never going to watch this again or recommend it to anyone&quot;, &quot;negative&quot;),</span>
<span class="sd">            (&quot;It&#39;s a waste of time&quot;, &quot;negative&quot;),</span>
<span class="sd">            (&quot;I loved the protagonist&quot;, &quot;positive&quot;),</span>
<span class="sd">            (&quot;The music was really really good&quot;, &quot;positive&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;, &quot;train_sentiment&quot;)</span>
<span class="sd">        pipelineModel = pipeline.fit(training)</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;I recommend this movie&quot;,</span>
<span class="sd">            &quot;Dont waste your time!!!&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipelineModel.transform(data)</span>

<span class="sd">        result.select(&quot;final_sentiment&quot;).show(truncate=False)</span>
<span class="sd">        +---------------+</span>
<span class="sd">        |final_sentiment|</span>
<span class="sd">        +---------------+</span>
<span class="sd">        |[positive]     |</span>
<span class="sd">        |[negative]     |</span>
<span class="sd">        +---------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sentimentCol</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;sentimentCol&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;column with the sentiment result of every row. Must be &#39;positive&#39; or &#39;negative&#39;&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">pruneCorpus</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;pruneCorpus&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Removes unfrequent scenarios from scope. The higher the better performance. Defaults 1&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">importantFeatureRatio</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                  <span class="s2">&quot;importantFeatureRatio&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;proportion of feature content to be considered relevant. Defaults to 0.5&quot;</span><span class="p">,</span>
                                  <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">unimportantFeatureStep</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                   <span class="s2">&quot;unimportantFeatureStep&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;proportion to lookahead in unimportant features. Defaults to 0.025&quot;</span><span class="p">,</span>
                                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">featureLimit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;featureLimit&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;content feature limit, to boost performance in very dirt text. Default disabled with -1&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ViveknSentimentApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">pruneCorpus</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">importantFeatureRatio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">unimportantFeatureStep</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">featureLimit</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setSentimentCol</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">sentimentCol</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPruneCorpus</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">pruneCorpus</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ViveknSentimentModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="ViveknSentimentModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ViveknSentimentModel.html#sparknlp.annotator.ViveknSentimentModel">[docs]</a><span class="k">class</span> <span class="nc">ViveknSentimentModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sentiment analyser inspired by the algorithm by Vivek Narayanan https://github.com/vivekn/sentiment/.</span>

<span class="sd">    The algorithm is based on the paper</span>
<span class="sd">    `&quot;Fast and accurate sentiment classification using an enhanced Naive Bayes model&quot; &lt;https://arxiv.org/abs/1305.6143&gt;`__.</span>

<span class="sd">    This is the instantiated model of the ViveknSentimentApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    The analyzer requires sentence boundaries to give a score in context.</span>
<span class="sd">    Tokenization is needed to make sure tokens are within bounds. Transitivity requirements are also required.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN, DOCUMENT``    ``SENTIMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    importantFeatureRatio</span>
<span class="sd">        proportion of feature content to be considered relevant. Defaults to 0.5</span>
<span class="sd">    unimportantFeatureStep</span>
<span class="sd">        proportion to lookahead in unimportant features. Defaults to 0.025</span>
<span class="sd">    featureLimit</span>
<span class="sd">        content feature limit, to boost performance in very dirt text. Default disabled with -1</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ViveknSentimentModel&quot;</span>

    <span class="n">importantFeatureRatio</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                  <span class="s2">&quot;importantFeatureRatio&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;proportion of feature content to be considered relevant. Defaults to 0.5&quot;</span><span class="p">,</span>
                                  <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">unimportantFeatureStep</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                   <span class="s2">&quot;unimportantFeatureStep&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;proportion to lookahead in unimportant features. Defaults to 0.025&quot;</span><span class="p">,</span>
                                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">featureLimit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;featureLimit&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;content feature limit, to boost performance in very dirt text. Default disabled with -1&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ViveknSentimentModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;sentiment_vivekn&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">ViveknSentimentModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="NorvigSweetingApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NorvigSweetingApproach.html#sparknlp.annotator.NorvigSweetingApproach">[docs]</a><span class="k">class</span> <span class="nc">NorvigSweetingApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains annotator, that retrieves tokens and makes corrections automatically if not found in an English dictionary.</span>

<span class="sd">    The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and</span>
<span class="sd">    dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster</span>
<span class="sd">    (than the standard approach with deletes + transposes + replaces + inserts) and language independent.</span>
<span class="sd">    A dictionary of correct spellings must be provided with ``setDictionary`` either in the form of a text file or directly</span>
<span class="sd">    as an ExternalResource, where each word is parsed by a regex pattern.</span>

<span class="sd">    Inspired by Norvig model and `SymSpell &lt;https://github.com/wolfgarbe/SymSpell&gt;`__.</span>

<span class="sd">    For instantiated/pretrained models, see NorvigSweetingModel.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dictionary</span>
<span class="sd">        Dictionary needs &#39;tokenPattern&#39; regex in dictionary for separating words</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case sensitivty, by default False</span>
<span class="sd">    doubleVariants</span>
<span class="sd">        Whether to use more expensive spell checker, by default False</span>
<span class="sd">    shortCircuit</span>
<span class="sd">        Whether to use faster mode, by default False</span>
<span class="sd">    frequencyPriority</span>
<span class="sd">        Applies frequency over hamming in intersections, when false hamming takes priority, by default True</span>
<span class="sd">    wordSizeIgnore</span>
<span class="sd">        minimum size of word before ignoring, by default 3</span>
<span class="sd">    dupsLimit</span>
<span class="sd">        maximum duplicate of characters in a word to consider, by default 2</span>
<span class="sd">    reductLimit</span>
<span class="sd">        word reductions limit, by default 3</span>
<span class="sd">    intersections</span>
<span class="sd">        hamming intersections to attempt, by default 10</span>
<span class="sd">    vowelSwapLimit</span>
<span class="sd">        vowel swap attempts, by default 6</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the dictionary `&quot;words.txt&quot;` has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # gummy</span>
<span class="sd">        # gummic</span>
<span class="sd">        # gummier</span>
<span class="sd">        # gummiest</span>
<span class="sd">        # gummiferous</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # This dictionary is then set to be the basis of the spell checker.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        spellChecker = NorvigSweetingApproach() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;spell&quot;) \\</span>
<span class="sd">            .setDictionary(&quot;src/test/resources/spell/words.txt&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            spellChecker</span>
<span class="sd">        ])</span>

<span class="sd">        pipelineModel = pipeline.fit(trainingData)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;dictionary&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;dictionary needs &#39;tokenPattern&#39; regex in dictionary for separating words&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">caseSensitive</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;caseSensitive&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;whether to ignore case sensitivty&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">doubleVariants</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;doubleVariants&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;whether to use more expensive spell checker&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">shortCircuit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;shortCircuit&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;whether to use faster mode&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">frequencyPriority</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;frequencyPriority&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;applies frequency over hamming in intersections. When false hamming takes priority&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">wordSizeIgnore</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;wordSizeIgnore&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;minimum size of word before ignoring. Defaults to 3&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">dupsLimit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;dupsLimit&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;maximum duplicate of characters in a word to consider. Defaults to 2&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">reductLimit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;reductLimit&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;word reductions limit. Defaults to 3&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">intersections</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;intersections&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;hamming intersections to attempt. Defaults to 10&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">vowelSwapLimit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;vowelSwapLimit&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;vowel swap attempts. Defaults to 6&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NorvigSweetingApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">doubleVariants</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shortCircuit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">wordSizeIgnore</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dupsLimit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                         <span class="n">reductLimit</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">intersections</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">vowelSwapLimit</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">frequencyPriority</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dictionary_path</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">setDictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">token_pattern</span><span class="o">=</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dictionary_path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;tokenPattern&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;tokenPattern&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_pattern</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dictionary</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDoubleVariants</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">doubleVariants</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setShortCircuit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">shortCircuit</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setFrequencyPriority</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">frequencyPriority</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">NorvigSweetingModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="NorvigSweetingModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NorvigSweetingModel.html#sparknlp.annotator.NorvigSweetingModel">[docs]</a><span class="k">class</span> <span class="nc">NorvigSweetingModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary.</span>
<span class="sd">    Inspired by Norvig model and `SymSpell &lt;https://github.com/wolfgarbe/SymSpell&gt;`__.</span>

<span class="sd">    The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and</span>
<span class="sd">    dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster</span>
<span class="sd">    (than the standard approach with deletes + transposes + replaces + inserts) and language independent.</span>

<span class="sd">    This is the instantiated model of the NorvigSweetingApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        spellChecker = NorvigSweetingModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;spell&quot;) \\</span>
<span class="sd">            .setDoubleVariants(True)</span>


<span class="sd">    The default model is ``&quot;spellcheck_norvig&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Spell+Check&gt;`__.</span>


<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>



<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>


<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        spellChecker = NorvigSweetingModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;spell&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            spellChecker</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;somtimes i wrrite wordz erong.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>
<span class="sd">        result.select(&quot;spell.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------+</span>
<span class="sd">        |result                                |</span>
<span class="sd">        +--------------------------------------+</span>
<span class="sd">        |[sometimes, i, write, words, wrong, .]|</span>
<span class="sd">        +--------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;NorvigSweetingModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NorvigSweetingModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;spellcheck_norvig&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">NorvigSweetingModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="SymmetricDeleteApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SymmetricDeleteApproach.html#sparknlp.annotator.SymmetricDeleteApproach">[docs]</a><span class="k">class</span> <span class="nc">SymmetricDeleteApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a Symmetric Delete spelling correction algorithm.</span>
<span class="sd">    Retrieves tokens and utilizes distance metrics to compute possible derived words.</span>

<span class="sd">    Inspired by `SymSpell &lt;https://github.com/wolfgarbe/SymSpell&gt;`__.</span>

<span class="sd">    For instantiated/pretrained models, see SymmetricDeleteModel.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    corpus</span>
<span class="sd">        folder or file with text that teaches about the language</span>
<span class="sd">    dictionary</span>
<span class="sd">        folder or file with text that teaches about the language</span>
<span class="sd">    maxEditDistance</span>
<span class="sd">        max edit distance characters to derive strings from a word, by default 3</span>
<span class="sd">    frequencyThreshold</span>
<span class="sd">        minimum frequency of words to be considered from training, by default 0</span>
<span class="sd">    deletesThreshold</span>
<span class="sd">        minimum frequency of corrections a word needs to have to be considered from training, by default 0</span>
<span class="sd">    dupsLimit</span>
<span class="sd">        maximum duplicate of characters in a word to consider, by default 2</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the dictionary `&quot;words.txt&quot;` has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # gummy</span>
<span class="sd">        # gummic</span>
<span class="sd">        # gummier</span>
<span class="sd">        # gummiest</span>
<span class="sd">        # gummiferous</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # This dictionary is then set to be the basis of the spell checker.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        spellChecker = SymmetricDeleteApproach() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;spell&quot;) \\</span>
<span class="sd">            .setDictionary(&quot;src/test/resources/spell/words.txt&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            spellChecker</span>
<span class="sd">        ])</span>

<span class="sd">        pipelineModel = pipeline.fit(trainingData)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;corpus&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;folder or file with text that teaches about the language&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">dictionary</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;dictionary&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;folder or file with text that teaches about the language&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">maxEditDistance</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;maxEditDistance&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;max edit distance characters to derive strings from a word&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">frequencyThreshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;frequencyThreshold&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;minimum frequency of words to be considered from training. &quot;</span> <span class="o">+</span>
                               <span class="s2">&quot;Increase if training set is LARGE. Defaults to 0&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">deletesThreshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;deletesThreshold&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;minimum frequency of corrections a word needs to have to be considered from training.&quot;</span> <span class="o">+</span>
                             <span class="s2">&quot;Increase if training set is LARGE. Defaults to 0&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">dupsLimit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;dupsLimit&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;maximum duplicate of characters in a word to consider. Defaults to 2&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SymmetricDeleteApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">maxEditDistance</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">frequencyThreshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">deletesThreshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dupsLimit</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dictionary_path</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">setDictionary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">token_pattern</span><span class="o">=</span><span class="s2">&quot;\S+&quot;</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dictionary_path</span> <span class="o">=</span> <span class="n">path</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;tokenPattern&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;tokenPattern&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">token_pattern</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dictionary</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setMaxEditDistance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxEditDistance</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setFrequencyThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">frequencyThreshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDeletesThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">deletesThreshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">SymmetricDeleteModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="SymmetricDeleteModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SymmetricDeleteModel.html#sparknlp.annotator.SymmetricDeleteModel">[docs]</a><span class="k">class</span> <span class="nc">SymmetricDeleteModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Symmetric Delete spelling correction algorithm.</span>

<span class="sd">    The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and</span>
<span class="sd">    dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster</span>
<span class="sd">    (than the standard approach with deletes + transposes + replaces + inserts) and language independent.</span>

<span class="sd">    Inspired by `SymSpell &lt;https://github.com/wolfgarbe/SymSpell&gt;`__.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        spell = SymmetricDeleteModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;spell&quot;)</span>


<span class="sd">    The default model is ``&quot;spellcheck_sd&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Spell+Check&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>



<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        spellChecker = SymmetricDeleteModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;spell&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            spellChecker</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;spmetimes i wrrite wordz erong.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>
<span class="sd">        result.select(&quot;spell.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------+</span>
<span class="sd">        |result                                |</span>
<span class="sd">        +--------------------------------------+</span>
<span class="sd">        |[sometimes, i, write, words, wrong, .]|</span>
<span class="sd">        +--------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;SymmetricDeleteModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteModel&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SymmetricDeleteModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;spellcheck_sd&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">SymmetricDeleteModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="NerApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerApproach.html#sparknlp.annotator.NerApproach">[docs]</a><span class="k">class</span> <span class="nc">NerApproach</span><span class="p">(</span><span class="n">Params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for Ner*Approach Annotators</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">labelColumn</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;labelColumn&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Column with label per each token&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">entities</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;entities&quot;</span><span class="p">,</span> <span class="s2">&quot;Entities to recognize&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">minEpochs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minEpochs&quot;</span><span class="p">,</span> <span class="s2">&quot;Minimum number of epochs to train&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">maxEpochs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxEpochs&quot;</span><span class="p">,</span> <span class="s2">&quot;Maximum number of epochs to train&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">verbose</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="s2">&quot;Level of verbosity during training&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">randomSeed</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;randomSeed&quot;</span><span class="p">,</span> <span class="s2">&quot;Random seed&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLabelColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">labelColumn</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEntities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tags</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">entities</span><span class="o">=</span><span class="n">tags</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinEpochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minEpochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxEpochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxEpochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setVerbose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verboseValue</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">verboseValue</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRandomSeed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">randomSeed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getLabelColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labelColumn</span><span class="p">)</span></div>


<div class="viewcode-block" id="NerCrfApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerCrfApproach.html#sparknlp.annotator.NerCrfApproach">[docs]</a><span class="k">class</span> <span class="nc">NerCrfApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">,</span> <span class="n">NerApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Algorithm for training a Named Entity Recognition Model</span>

<span class="sd">    For instantiated/pretrained models, see NerCrfModel.</span>

<span class="sd">    This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning</span>
<span class="sd">    algorithm. The training data should be a labeled Spark Dataset, e.g. CoNLL 2003 IOB with</span>
<span class="sd">    ``Annotation`` type columns. The data should have columns of type ``DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS`` and an</span>
<span class="sd">    additional label column of annotator type ``NAMED_ENTITY``.</span>
<span class="sd">    Excluding the label, this can be done with for example</span>

<span class="sd">    * a SentenceDetector,</span>
<span class="sd">    * a Tokenizer,</span>
<span class="sd">    * a PerceptronModel and</span>
<span class="sd">    * a WordEmbeddingsModel.</span>

<span class="sd">    Optionally the user can provide an entity dictionary file with setExternalFeatures for better accuracy.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/crf-ner/ner_dl_crf.ipynb&gt;`__.</span>

<span class="sd">    ========================================= ======================</span>
<span class="sd">    Input Annotation types                    Output Annotation type</span>
<span class="sd">    ========================================= ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS`` ``NAMED_ENTITY``</span>
<span class="sd">    ========================================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    labelColumn</span>
<span class="sd">        Column with label per each token</span>
<span class="sd">    entities</span>
<span class="sd">        Entities to recognize</span>
<span class="sd">    minEpochs</span>
<span class="sd">        Minimum number of epochs to train, by default 0</span>
<span class="sd">    maxEpochs</span>
<span class="sd">        Maximum number of epochs to train, by default 1000</span>
<span class="sd">    verbose</span>
<span class="sd">        Level of verbosity during training, by default 4</span>
<span class="sd">    randomSeed</span>
<span class="sd">        Random seed</span>
<span class="sd">    l2</span>
<span class="sd">        L2 regularization coefficient, by default 1.0</span>
<span class="sd">    c0</span>
<span class="sd">        c0 params defining decay speed for gradient, by default 2250000</span>
<span class="sd">    lossEps</span>
<span class="sd">        If Epoch relative improvement less than eps then training is stopped, by default 0.001</span>
<span class="sd">    minW</span>
<span class="sd">        Features with less weights then this param value will be filtered</span>
<span class="sd">    includeConfidence</span>
<span class="sd">        external features is a delimited text. needs &#39;delimiter&#39; in options, by default False</span>
<span class="sd">    externalFeatures</span>
<span class="sd">        Additional dictionaries paths to use as a features</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types.</span>
<span class="sd">        # If a custom dataset is used, these need to be defined.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;) \\</span>
<span class="sd">            .setCaseSensitive(False)</span>

<span class="sd">        nerTagger = NerCrfApproach() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;pos&quot;, &quot;embeddings&quot;]) \\</span>
<span class="sd">            .setLabelColumn(&quot;label&quot;) \\</span>
<span class="sd">            .setMinEpochs(1) \\</span>
<span class="sd">            .setMaxEpochs(3) \\</span>
<span class="sd">            .setC0(34) \\</span>
<span class="sd">            .setL2(3.0) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            nerTagger</span>
<span class="sd">        ])</span>


<span class="sd">        conll = CoNLL()</span>
<span class="sd">        trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;)</span>

<span class="sd">        pipelineModel = pipeline.fit(trainingData)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">l2</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="s2">&quot;L2 regularization coefficient&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">c0</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;c0&quot;</span><span class="p">,</span> <span class="s2">&quot;c0 params defining decay speed for gradient&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">lossEps</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;lossEps&quot;</span><span class="p">,</span> <span class="s2">&quot;If Epoch relative improvement less than eps then training is stopped&quot;</span><span class="p">,</span>
                    <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">minW</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minW&quot;</span><span class="p">,</span> <span class="s2">&quot;Features with less weights then this param value will be filtered&quot;</span><span class="p">,</span>
                 <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">includeConfidence</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;includeConfidence&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;external features is a delimited text. needs &#39;delimiter&#39; in options&quot;</span><span class="p">,</span>
                              <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">externalFeatures</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;externalFeatures&quot;</span><span class="p">,</span> <span class="s2">&quot;Additional dictionaries paths to use as a features&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setL2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l2value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">l2</span><span class="o">=</span><span class="n">l2value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setC0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c0value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">c0</span><span class="o">=</span><span class="n">c0value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLossEps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lossEps</span><span class="o">=</span><span class="n">eps</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinW</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minW</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExternalFeatures</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">delimiter</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;delimiter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">opts</span><span class="p">:</span>
            <span class="n">opts</span><span class="p">[</span><span class="s2">&quot;delimiter&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delimiter</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">externalFeatures</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setIncludeConfidence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeConfidence</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">NerCrfModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NerCrfApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">minEpochs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">maxEpochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
            <span class="n">l2</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">c0</span><span class="o">=</span><span class="mi">2250000</span><span class="p">,</span>
            <span class="n">lossEps</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
            <span class="n">includeConfidence</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="NerCrfModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerCrfModel.html#sparknlp.annotator.NerCrfModel">[docs]</a><span class="k">class</span> <span class="nc">NerCrfModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Extracts Named Entities based on a CRF Model.</span>

<span class="sd">    This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning</span>
<span class="sd">    algorithm. The data should have columns of type ``DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS``.</span>
<span class="sd">    These can be extracted with for example</span>

<span class="sd">    * a SentenceDetector,</span>
<span class="sd">    * a Tokenizer and</span>
<span class="sd">    * a PerceptronModel.</span>

<span class="sd">    This is the instantiated model of the NerCrfApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        nerTagger = NerCrfModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;, &quot;pos&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;</span>


<span class="sd">    The default model is ``&quot;ner_crf&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/model-downloader/Running_Pretrained_pipelines.ipynb&gt;`__.</span>

<span class="sd">    ========================================= ======================</span>
<span class="sd">    Input Annotation types                    Output Annotation type</span>
<span class="sd">    ========================================= ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS`` ``NAMED_ENTITY``</span>
<span class="sd">    ========================================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    includeConfidence</span>
<span class="sd">        external features is a delimited text. needs &#39;delimiter&#39; in options</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        # First extract the prerequisites for the NerCrfModel</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;word_embeddings&quot;)</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        # Then NER can be extracted</span>
<span class="sd">        nerTagger = NerCrfModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;word_embeddings&quot;, &quot;pos&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            posTagger,</span>
<span class="sd">            nerTagger</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;U.N. official Ekeus heads for Baghdad.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;ner.result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------+</span>
<span class="sd">        |result                              |</span>
<span class="sd">        +------------------------------------+</span>
<span class="sd">        |[I-ORG, O, O, I-PER, O, O, I-LOC, O]|</span>
<span class="sd">        +------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;NerCrfModel&quot;</span>

    <span class="n">includeConfidence</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;includeConfidence&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;external features is a delimited text. needs &#39;delimiter&#39; in options&quot;</span><span class="p">,</span>
                              <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ner.crf.NerCrfModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NerCrfModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIncludeConfidence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeConfidence</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;ner_crf&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">NerCrfModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="NerDLApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerDLApproach.html#sparknlp.annotator.NerDLApproach">[docs]</a><span class="k">class</span> <span class="nc">NerDLApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">,</span> <span class="n">NerApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This Named Entity recognition annotator allows to train generic NER model based on Neural Networks.</span>

<span class="sd">    The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</span>

<span class="sd">    For instantiated/pretrained models, see NerDLModel.</span>

<span class="sd">    The training data should be a labeled Spark Dataset, in the format of CoNLL</span>
<span class="sd">    2003 IOB with ``Annotation`` type columns. The data should have columns of type ``DOCUMENT, TOKEN, WORD_EMBEDDINGS`` and an</span>
<span class="sd">    additional label column of annotator type ``NAMED_ENTITY``.</span>
<span class="sd">    Excluding the label, this can be done with for example</span>
<span class="sd">    * a SentenceDetector,</span>
<span class="sd">    * a Tokenizer and</span>
<span class="sd">    * a WordEmbeddingsModel (any embeddings can be chosen, e.g. BertEmbeddings for BERT based embeddings).</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/training/english/dl-ner&gt;`__.</span>

<span class="sd">    ==================================== ======================</span>
<span class="sd">    Input Annotation types               Output Annotation type</span>
<span class="sd">    ==================================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN, WORD_EMBEDDINGS`` ``NAMED_ENTITY``</span>
<span class="sd">    ==================================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    labelColumn</span>
<span class="sd">        Column with label per each token</span>
<span class="sd">    entities</span>
<span class="sd">        Entities to recognize</span>
<span class="sd">    minEpochs</span>
<span class="sd">        Minimum number of epochs to train, by default 0</span>
<span class="sd">    maxEpochs</span>
<span class="sd">        Maximum number of epochs to train, by default 50</span>
<span class="sd">    verbose</span>
<span class="sd">        Level of verbosity during training, by default 2</span>
<span class="sd">    randomSeed</span>
<span class="sd">        Random seed</span>
<span class="sd">    lr</span>
<span class="sd">        Learning Rate, by default 0.001</span>
<span class="sd">    po</span>
<span class="sd">        Learning rate decay coefficient. Real Learning Rage = lr / (1 + po * epoch), by default 0.005</span>
<span class="sd">    batchSize</span>
<span class="sd">        Batch size, by default 8</span>
<span class="sd">    dropout</span>
<span class="sd">        Dropout coefficient, by default 0.5</span>
<span class="sd">    graphFolder</span>
<span class="sd">        Folder path that contain external graph files</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    useContrib</span>
<span class="sd">        whether to use contrib LSTM Cells. Not compatible with Windows. Might slightly improve accuracy</span>
<span class="sd">    validationSplit</span>
<span class="sd">        Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off, by default 0.0</span>
<span class="sd">    evaluationLogExtended</span>
<span class="sd">        Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off, by default False</span>
<span class="sd">    testDataset</span>
<span class="sd">        Path to test dataset. If set used to calculate statistic on it during training.</span>
<span class="sd">    includeConfidence</span>
<span class="sd">        whether to include confidence scores in annotation metadata, by default False</span>
<span class="sd">    includeAllConfidenceScores</span>
<span class="sd">        whether to include all confidence scores in annotation metadata or just the score of the predicted tag, by default False</span>
<span class="sd">    enableOutputLogs</span>
<span class="sd">        Whether to use stdout in addition to Spark logs, by default False</span>
<span class="sd">    outputLogsPath</span>
<span class="sd">        Folder path to save training logs</span>
<span class="sd">    enableMemoryOptimizer</span>
<span class="sd">        Whether to optimize for large datasets or not. Enabling this option can slow down training, by default False</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        # First extract the prerequisites for the NerDLApproach</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = BertEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        # Then the training can start</span>
<span class="sd">        nerTagger = NerDLApproach() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \\</span>
<span class="sd">            .setLabelColumn(&quot;label&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;) \\</span>
<span class="sd">            .setMaxEpochs(1) \\</span>
<span class="sd">            .setRandomSeed(0) \\</span>
<span class="sd">            .setVerbose(0)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            nerTagger</span>
<span class="sd">        ])</span>

<span class="sd">        # We use the text and labels from the CoNLL dataset</span>
<span class="sd">        conll = CoNLL()</span>
<span class="sd">        trainingData = conll.readDataset(spark, &quot;src/test/resources/conll2003/eng.train&quot;)</span>

<span class="sd">        pipelineModel = pipeline.fit(trainingData)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">po</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;po&quot;</span><span class="p">,</span> <span class="s2">&quot;Learning rate decay coefficient. Real Learning Rage = lr / (1 + po * epoch)&quot;</span><span class="p">,</span>
               <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">batchSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;batchSize&quot;</span><span class="p">,</span> <span class="s2">&quot;Batch size&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">dropout</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="s2">&quot;Dropout coefficient&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">graphFolder</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;graphFolder&quot;</span><span class="p">,</span> <span class="s2">&quot;Folder path that contain external graph files&quot;</span><span class="p">,</span>
                        <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">useContrib</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;useContrib&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;whether to use contrib LSTM Cells. Not compatible with Windows. Might slightly improve accuracy.&quot;</span><span class="p">,</span>
                       <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">validationSplit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;validationSplit&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.&quot;</span><span class="p">,</span>
                            <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">evaluationLogExtended</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;evaluationLogExtended&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.&quot;</span><span class="p">,</span>
                                  <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">testDataset</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;testDataset&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Path to test dataset. If set used to calculate statistic on it during training.&quot;</span><span class="p">,</span>
                        <span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">includeConfidence</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;includeConfidence&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;whether to include confidence scores in annotation metadata&quot;</span><span class="p">,</span>
                              <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">includeAllConfidenceScores</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;includeAllConfidenceScores&quot;</span><span class="p">,</span>
                                       <span class="s2">&quot;whether to include all confidence scores in annotation metadata or just the score of the predicted tag&quot;</span><span class="p">,</span>
                                       <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">enableOutputLogs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;enableOutputLogs&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;Whether to use stdout in addition to Spark logs.&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">outputLogsPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;outputLogsPath&quot;</span><span class="p">,</span> <span class="s2">&quot;Folder path to save training logs&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">enableMemoryOptimizer</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;enableMemoryOptimizer&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;Whether to optimize for large datasets or not. Enabling this option can slow down training.&quot;</span><span class="p">,</span>
                                  <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setGraphFolder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">graphFolder</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setUseContrib</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">v</span> <span class="ow">and</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span> <span class="o">==</span> <span class="s1">&#39;win32&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Windows not supported to use contrib&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">useContrib</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setPo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">po</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">batchSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">NerDLModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setValidationSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">validationSplit</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">evaluationLogExtended</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setTestDataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">SPARK</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;parquet&quot;</span><span class="p">}):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">testDataset</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">setIncludeConfidence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeConfidence</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIncludeAllConfidenceScores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeAllConfidenceScores</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEnableOutputLogs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">enableOutputLogs</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">enableMemoryOptimizer</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setOutputLogsPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">outputLogsPath</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NerDLApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach&quot;</span><span class="p">)</span>
        <span class="n">uc</span> <span class="o">=</span> <span class="kc">False</span> <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;win32&#39;</span> <span class="k">else</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">minEpochs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">maxEpochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
            <span class="n">po</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.005</span><span class="p">),</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">useContrib</span><span class="o">=</span><span class="n">uc</span><span class="p">,</span>
            <span class="n">validationSplit</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
            <span class="n">evaluationLogExtended</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">includeConfidence</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">includeAllConfidenceScores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">enableOutputLogs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">enableMemoryOptimizer</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="NerDLModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerDLModel.html#sparknlp.annotator.NerDLModel">[docs]</a><span class="k">class</span> <span class="nc">NerDLModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">,</span> <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This Named Entity recognition annotator is a generic NER model based on Neural Networks.</span>

<span class="sd">    Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</span>

<span class="sd">    This is the instantiated model of the NerDLApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        nerModel = NerDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;)</span>


<span class="sd">    The default model is ``&quot;ner_dl&quot;``, if no name is provided.</span>

<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition&gt;`__.</span>
<span class="sd">    Additionally, pretrained pipelines are available for this module, see `Pipelines &lt;https://nlp.johnsnowlabs.com/docs/en/pipelines&gt;`__.</span>

<span class="sd">    Note that some pretrained models require specific types of embeddings, depending on which they were trained on.</span>
<span class="sd">    For example, the default model ``&quot;ner_dl&quot;`` requires the</span>
<span class="sd">    WordEmbeddings ``&quot;glove_100d&quot;``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ==================================== ======================</span>
<span class="sd">    Input Annotation types               Output Annotation type</span>
<span class="sd">    ==================================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN, WORD_EMBEDDINGS`` ``NAMED_ENTITY``</span>
<span class="sd">    ==================================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    includeConfidence</span>
<span class="sd">        whether to include confidence scores in annotation metadata, by default False</span>
<span class="sd">    includeAllConfidenceScores</span>
<span class="sd">        whether to include all confidence scores in annotation metadata or just the score of the predicted tag, by default False</span>
<span class="sd">    classes</span>
<span class="sd">        get the tags used to trained this NerDLModel</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        # First extract the prerequisites for the NerDLModel</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;bert&quot;)</span>

<span class="sd">        # Then NER can be extracted</span>
<span class="sd">        nerTagger = NerDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            nerTagger</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;U.N. official Ekeus heads for Baghdad.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;ner.result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------+</span>
<span class="sd">        |result                              |</span>
<span class="sd">        +------------------------------------+</span>
<span class="sd">        |[B-ORG, O, O, B-PER, O, O, B-LOC, O]|</span>
<span class="sd">        +------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;NerDLModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NerDLModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">includeConfidence</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">includeAllConfidenceScores</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span>
        <span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">includeConfidence</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;includeConfidence&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;whether to include confidence scores in annotation metadata&quot;</span><span class="p">,</span>
                              <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">includeAllConfidenceScores</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;includeAllConfidenceScores&quot;</span><span class="p">,</span>
                                       <span class="s2">&quot;whether to include all confidence scores in annotation metadata or just the score of the predicted tag&quot;</span><span class="p">,</span>
                                       <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;classes&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;get the tags used to trained this NerDLModel&quot;</span><span class="p">,</span>
                    <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIncludeConfidence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeConfidence</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIncludeAllConfidenceScores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeAllConfidenceScores</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;ner_dl&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">NerDLModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="NerConverter"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerConverter.html#sparknlp.annotator.NerConverter">[docs]</a><span class="k">class</span> <span class="nc">NerConverter</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts a IOB or IOB2 representation of NER to a user-friendly one,</span>
<span class="sd">    by associating the tokens of recognized entities and their label. Results in ``CHUNK`` Annotation type.</span>

<span class="sd">    NER chunks can then be filtered by setting a whitelist with ``setWhiteList``.</span>
<span class="sd">    Chunks with no associated entity (tagged &quot;O&quot;) are filtered.</span>

<span class="sd">    See also `Insideoutsidebeginning (tagging) &lt;https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)&gt;`__ for more information.</span>

<span class="sd">    ================================= ======================</span>
<span class="sd">    Input Annotation types            Output Annotation type</span>
<span class="sd">    ================================= ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN, NAMED_ENTITY`` ``CHUNK``</span>
<span class="sd">    ================================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    whiteList</span>
<span class="sd">        If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # This is a continuation of the example of the NerDLModel. See that class</span>
<span class="sd">        # on how to extract the entities.</span>
<span class="sd">        # The output of the NerDLModel follows the Annotator schema and can be converted like so:</span>
<span class="sd">        result.selectExpr(&quot;explode(ner)&quot;).show(truncate=False)</span>
<span class="sd">        +----------------------------------------------------+</span>
<span class="sd">        |col                                                 |</span>
<span class="sd">        +----------------------------------------------------+</span>
<span class="sd">        |[named_entity, 0, 2, B-ORG, [word -&gt; U.N], []]      |</span>
<span class="sd">        |[named_entity, 3, 3, O, [word -&gt; .], []]            |</span>
<span class="sd">        |[named_entity, 5, 12, O, [word -&gt; official], []]    |</span>
<span class="sd">        |[named_entity, 14, 18, B-PER, [word -&gt; Ekeus], []]  |</span>
<span class="sd">        |[named_entity, 20, 24, O, [word -&gt; heads], []]      |</span>
<span class="sd">        |[named_entity, 26, 28, O, [word -&gt; for], []]        |</span>
<span class="sd">        |[named_entity, 30, 36, B-LOC, [word -&gt; Baghdad], []]|</span>
<span class="sd">        |[named_entity, 37, 37, O, [word -&gt; .], []]          |</span>
<span class="sd">        +----------------------------------------------------+</span>

<span class="sd">        # After the converter is used:</span>
<span class="sd">        converter = NerConverter() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;entities&quot;) \\</span>
<span class="sd">            .setPreservePosition(False)</span>

<span class="sd">        converter.transform(result).selectExpr(&quot;explode(entities)&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------------------------------------+</span>
<span class="sd">        |col                                                                     |</span>
<span class="sd">        +------------------------------------------------------------------------+</span>
<span class="sd">        |[chunk, 0, 2, U.N, [entity -&gt; ORG, sentence -&gt; 0, chunk -&gt; 0], []]      |</span>
<span class="sd">        |[chunk, 14, 18, Ekeus, [entity -&gt; PER, sentence -&gt; 0, chunk -&gt; 1], []]  |</span>
<span class="sd">        |[chunk, 30, 36, Baghdad, [entity -&gt; LOC, sentence -&gt; 0, chunk -&gt; 2], []]|</span>
<span class="sd">        +------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;NerConverter&#39;</span>

    <span class="n">whiteList</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span>
        <span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
        <span class="s2">&quot;whiteList&quot;</span><span class="p">,</span>
        <span class="s2">&quot;If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels&quot;</span><span class="p">,</span>
        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWhiteList</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">entities</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">whiteList</span><span class="o">=</span><span class="n">entities</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NerConverter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ner.NerConverter&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="DependencyParserApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DependencyParserApproach.html#sparknlp.annotator.DependencyParserApproach">[docs]</a><span class="k">class</span> <span class="nc">DependencyParserApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains an unlabeled parser that finds a grammatical relations between two words in a sentence.</span>

<span class="sd">    For instantiated/pretrained models, see DependencyParserModel.</span>

<span class="sd">    Dependency parser provides information about word relationship. For example, dependency parsing can tell you what</span>
<span class="sd">    the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help</span>
<span class="sd">    you find precise answers to specific questions.</span>

<span class="sd">    The required training data can be set in two different ways (only one can be chosen for a particular model):</span>
<span class="sd">      - Dependency treebank in the `Penn Treebank format &lt;http://www.nltk.org/nltk_data/&gt;`__ set with ``setDependencyTreeBank``</span>
<span class="sd">      - Dataset in the `CoNLL-U format &lt;https://universaldependencies.org/format.html&gt;`__ set with ``setConllU``</span>

<span class="sd">    Apart from that, no additional training data is needed.</span>

<span class="sd">    ======================== ======================</span>
<span class="sd">    Input Annotation types   Output Annotation type</span>
<span class="sd">    ======================== ======================</span>
<span class="sd">    ``DOCUMENT, POS, TOKEN`` ``DEPENDENCY``</span>
<span class="sd">    ======================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dependencyTreeBank</span>
<span class="sd">        Dependency treebank source files</span>
<span class="sd">    conllU</span>
<span class="sd">        Universal Dependencies source files</span>
<span class="sd">    numberOfIterations</span>
<span class="sd">        Number of iterations in training, converges to better accuracy , by default 10</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        dependencyParserApproach = DependencyParserApproach() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency&quot;) \\</span>
<span class="sd">            .setDependencyTreeBank(&quot;src/test/resources/parser/unlabeled/dependency_treebank&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            posTagger,</span>
<span class="sd">            dependencyParserApproach</span>
<span class="sd">        ])</span>

<span class="sd">        # Additional training data is not needed, the dependency parser relies on the dependency tree bank / CoNLL-U only.</span>
<span class="sd">        emptyDataSet = .empty[String].toDF(&quot;text&quot;)</span>
<span class="sd">        pipelineModel = pipeline.fit(emptyDataSet)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dependencyTreeBank</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;dependencyTreeBank&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;Dependency treebank source files&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">conllU</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;conllU&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Universal Dependencies source files&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">numberOfIterations</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;numberOfIterations&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;Number of iterations in training, converges to better accuracy&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DependencyParserApproach</span><span class="p">,</span>
              <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span><span class="n">numberOfIterations</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setNumberOfIterations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">numberOfIterations</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDependencyTreeBank</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;value&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dependencyTreeBank</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setConllU</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;value&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">conllU</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DependencyParserModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="DependencyParserModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DependencyParserModel.html#sparknlp.annotator.DependencyParserModel">[docs]</a><span class="k">class</span> <span class="nc">DependencyParserModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Unlabeled parser that finds a grammatical relation between two words in a sentence.</span>

<span class="sd">    Dependency parser provides information about word relationship. For example, dependency parsing can tell you what</span>
<span class="sd">    the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help</span>
<span class="sd">    you find precise answers to specific questions.</span>

<span class="sd">    This is the instantiated model of the DependencyParserApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        dependencyParserApproach = DependencyParserModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency&quot;)</span>


<span class="sd">    The default model is ``&quot;dependency_conllu&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ================================ ======================</span>
<span class="sd">    Input Annotation types           Output Annotation type</span>
<span class="sd">    ================================ ======================</span>
<span class="sd">    ``[String]DOCUMENT, POS, TOKEN`` ``DEPENDENCY``</span>
<span class="sd">    ================================ ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    perceptron</span>
<span class="sd">        Dependency parsing perceptron features</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        dependencyParser = DependencyParserModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            posTagger,</span>
<span class="sd">            dependencyParser</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Unions representing workers at Turner Newall say they are &#39;disappointed&#39; after talks with stricken parent &quot; +</span>
<span class="sd">              &quot;firm Federal Mogul.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(arrays_zip(token.result, dependency.result)) as cols&quot;) \\</span>
<span class="sd">            .selectExpr(&quot;cols[&#39;0&#39;] as token&quot;, &quot;cols[&#39;1&#39;] as dependency&quot;).show(8, truncate = False)</span>
<span class="sd">        +------------+------------+</span>
<span class="sd">        |token       |dependency  |</span>
<span class="sd">        +------------+------------+</span>
<span class="sd">        |Unions      |ROOT        |</span>
<span class="sd">        |representing|workers     |</span>
<span class="sd">        |workers     |Unions      |</span>
<span class="sd">        |at          |Turner      |</span>
<span class="sd">        |Turner      |workers     |</span>
<span class="sd">        |Newall      |say         |</span>
<span class="sd">        |say         |Unions      |</span>
<span class="sd">        |they        |disappointed|</span>
<span class="sd">        +------------+------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;DependencyParserModel&quot;</span>

    <span class="n">perceptron</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;perceptron&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;Dependency parsing perceptron features&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DependencyParserModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;dependency_conllu&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">DependencyParserModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="TypedDependencyParserApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.TypedDependencyParserApproach.html#sparknlp.annotator.TypedDependencyParserApproach">[docs]</a><span class="k">class</span> <span class="nc">TypedDependencyParserApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Labeled parser that finds a grammatical relation between two words in a sentence.</span>
<span class="sd">    Its input is either a CoNLL2009 or ConllU dataset.</span>

<span class="sd">    For instantiated/pretrained models, see TypedDependencyParserModel.</span>

<span class="sd">    Dependency parsers provide information about word relationship. For example, dependency parsing can tell you what</span>
<span class="sd">    the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help</span>
<span class="sd">    you find precise answers to specific questions.</span>

<span class="sd">    The parser requires the dependant tokens beforehand with e.g. DependencyParser.</span>
<span class="sd">    The required training data can be set in two different ways (only one can be chosen for a particular model):</span>

<span class="sd">    * Dataset in the `CoNLL 2009 format &lt;https://ufal.mff.cuni.cz/conll2009-st/trial-data.html&gt;`__ set with ``setConll2009``</span>
<span class="sd">    * Dataset in the `CoNLL-U format &lt;https://universaldependencies.org/format.html&gt;`__ set with ``setConllU``</span>

<span class="sd">    Apart from that, no additional training data is needed.</span>

<span class="sd">    ========================== ======================</span>
<span class="sd">    Input Annotation types     Output Annotation type</span>
<span class="sd">    ========================== ======================</span>
<span class="sd">    ``TOKEN, POS, DEPENDENCY`` ``LABELED_DEPENDENCY``</span>
<span class="sd">    ========================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    conll2009</span>
<span class="sd">        Path to file with CoNLL 2009 format</span>
<span class="sd">    conllU</span>
<span class="sd">        Universal Dependencies source files</span>
<span class="sd">    numberOfIterations</span>
<span class="sd">        Number of iterations in training, converges to better accuracy</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        dependencyParser = DependencyParserModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency&quot;)</span>

<span class="sd">        typedDependencyParser = TypedDependencyParserApproach() \\</span>
<span class="sd">            .setInputCols([&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency_type&quot;) \\</span>
<span class="sd">            .setConllU(&quot;src/test/resources/parser/labeled/train_small.conllu.txt&quot;) \\</span>
<span class="sd">            .setNumberOfIterations(1)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            posTagger,</span>
<span class="sd">            dependencyParser,</span>
<span class="sd">            typedDependencyParser</span>
<span class="sd">        ])</span>

<span class="sd">        # Additional training data is not needed, the dependency parser relies on CoNLL-U only.</span>
<span class="sd">        emptyDataSet = .empty[String].toDF(&quot;text&quot;)</span>
<span class="sd">        pipelineModel = pipeline.fit(emptyDataSet)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">conll2009</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;conll2009&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Path to file with CoNLL 2009 format&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">conllU</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;conllU&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Universal Dependencies source files&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">numberOfIterations</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;numberOfIterations&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;Number of iterations in training, converges to better accuracy&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TypedDependencyParserApproach</span><span class="p">,</span>
              <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserApproach&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConll2009</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;value&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">conll2009</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setConllU</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="n">ReadAs</span><span class="o">.</span><span class="n">TEXT</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;key&quot;</span><span class="p">:</span> <span class="s2">&quot;value&quot;</span><span class="p">}):</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">options</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">conllU</span><span class="o">=</span><span class="n">ExternalResource</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">read_as</span><span class="p">,</span> <span class="n">opts</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">setNumberOfIterations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">numberOfIterations</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TypedDependencyParserModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="TypedDependencyParserModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.TypedDependencyParserModel.html#sparknlp.annotator.TypedDependencyParserModel">[docs]</a><span class="k">class</span> <span class="nc">TypedDependencyParserModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Labeled parser that finds a grammatical relation between two words in a sentence.</span>
<span class="sd">    Its input is either a CoNLL2009 or ConllU dataset.</span>

<span class="sd">    Dependency parsers provide information about word relationship. For example, dependency parsing can tell you what</span>
<span class="sd">    the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help</span>
<span class="sd">    you find precise answers to specific questions.</span>

<span class="sd">    The parser requires the dependant tokens beforehand with e.g. DependencyParser.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        typedDependencyParser = TypedDependencyParserModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency_type&quot;)</span>


<span class="sd">    The default model is ``&quot;dependency_typed_conllu&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ========================== ======================</span>
<span class="sd">    Input Annotation types     Output Annotation type</span>
<span class="sd">    ========================== ======================</span>
<span class="sd">    ``TOKEN, POS, DEPENDENCY`` ``LABELED_DEPENDENCY``</span>
<span class="sd">    ========================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    trainOptions</span>
<span class="sd">        Training Options</span>
<span class="sd">    trainParameters</span>
<span class="sd">        Training Parameters</span>
<span class="sd">    trainDependencyPipe</span>
<span class="sd">        Training dependency pipe</span>
<span class="sd">    conllFormat</span>
<span class="sd">        CoNLL Format</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        posTagger = PerceptronModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;pos&quot;)</span>

<span class="sd">        dependencyParser = DependencyParserModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency&quot;)</span>

<span class="sd">        typedDependencyParser = TypedDependencyParserModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;dependency&quot;, &quot;pos&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;dependency_type&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            posTagger,</span>
<span class="sd">            dependencyParser,</span>
<span class="sd">            typedDependencyParser</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Unions representing workers at Turner Newall say they are &#39;disappointed&#39; after talks with stricken parent &quot; +</span>
<span class="sd">              &quot;firm Federal Mogul.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(arrays_zip(token.result, dependency.result, dependency_type.result)) as cols&quot;) \\</span>
<span class="sd">            .selectExpr(&quot;cols[&#39;0&#39;] as token&quot;, &quot;cols[&#39;1&#39;] as dependency&quot;, &quot;cols[&#39;2&#39;] as dependency_type&quot;) \\</span>
<span class="sd">            .show(8, truncate = False)</span>
<span class="sd">        +------------+------------+---------------+</span>
<span class="sd">        |token       |dependency  |dependency_type|</span>
<span class="sd">        +------------+------------+---------------+</span>
<span class="sd">        |Unions      |ROOT        |root           |</span>
<span class="sd">        |representing|workers     |amod           |</span>
<span class="sd">        |workers     |Unions      |flat           |</span>
<span class="sd">        |at          |Turner      |case           |</span>
<span class="sd">        |Turner      |workers     |flat           |</span>
<span class="sd">        |Newall      |say         |nsubj          |</span>
<span class="sd">        |say         |Unions      |parataxis      |</span>
<span class="sd">        |they        |disappointed|nsubj          |</span>
<span class="sd">        +------------+------------+---------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;TypedDependencyParserModel&quot;</span>

    <span class="n">trainOptions</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;trainOptions&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;Training Options&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">trainParameters</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;trainParameters&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Training Parameters&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">trainDependencyPipe</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                <span class="s2">&quot;trainDependencyPipe&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;Training dependency pipe&quot;</span><span class="p">,</span>
                                <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">identity</span><span class="p">)</span>

    <span class="n">conllFormat</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;conllFormat&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;CoNLL Format&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserModel&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TypedDependencyParserModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;dependency_typed_conllu&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">TypedDependencyParserModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="WordEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.WordEmbeddings.html#sparknlp.annotator.WordEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">WordEmbeddings</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">,</span> <span class="n">HasEmbeddingsProperties</span><span class="p">,</span> <span class="n">HasStorage</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Word Embeddings lookup annotator that maps tokens to vectors.</span>

<span class="sd">    For instantiated/pretrained models, see WordEmbeddingsModel.</span>

<span class="sd">    A custom token lookup dictionary for embeddings can be set with ``setStoragePath``.</span>
<span class="sd">    Each line of the provided file needs to have a token, followed by their vector representation, delimited by a spaces.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        ...</span>
<span class="sd">        are 0.39658191506190343 0.630968081620067 0.5393722253731201 0.8428180123359783</span>
<span class="sd">        were 0.7535235923631415 0.9699218875629833 0.10397182122983872 0.11833962569383116</span>
<span class="sd">        stress 0.0492683418305907 0.9415954572751959 0.47624463167525755 0.16790967216778263</span>
<span class="sd">        induced 0.1535748762292387 0.33498936903209897 0.9235178224122094 0.1158772920395934</span>
<span class="sd">        ...</span>


<span class="sd">    If a token is not found in the dictionary, then the result will be a zero vector of the same dimension.</span>
<span class="sd">    Statistics about the rate of converted tokens, can be retrieved with WordEmbeddingsModel.withCoverageColumn</span>
<span class="sd">    and WordEmbeddingsModel.overallCoverage.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    writeBufferSize</span>
<span class="sd">        buffer size limit before dumping to disk storage while writing, by default 10000</span>
<span class="sd">    readCacheSize</span>
<span class="sd">        cache size for items retrieved from storage. Increase for performance but higher memory consumption</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the file `random_embeddings_dim4.txt` has the form of the content above.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = WordEmbeddings() \\</span>
<span class="sd">            .setStoragePath(&quot;src/test/resources/random_embeddings_dim4.txt&quot;, ReadAs.TEXT) \\</span>
<span class="sd">            .setStorageRe(&quot;glove_4d&quot;) \\</span>
<span class="sd">            .setDimension(4) \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;The patient was diagnosed with diabetes.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(truncate=False)</span>
<span class="sd">        +----------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                            |</span>
<span class="sd">        +----------------------------------------------------------------------------------+</span>
<span class="sd">        |[0.9439099431037903,0.4707513153553009,0.806300163269043,0.16176554560661316]     |</span>
<span class="sd">        |[0.7966810464859009,0.5551124811172485,0.8861005902290344,0.28284206986427307]    |</span>
<span class="sd">        |[0.025029370561242104,0.35177749395370483,0.052506182342767715,0.1887107789516449]|</span>
<span class="sd">        |[0.08617766946554184,0.8399239182472229,0.5395117998123169,0.7864698767662048]    |</span>
<span class="sd">        |[0.6599600911140442,0.16109347343444824,0.6041093468666077,0.8913561105728149]    |</span>
<span class="sd">        |[0.5955275893211365,0.01899011991918087,0.4397728443145752,0.8911281824111938]    |</span>
<span class="sd">        |[0.9840458631515503,0.7599489092826843,0.9417727589607239,0.8624503016471863]     |</span>
<span class="sd">        +----------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;WordEmbeddings&quot;</span>

    <span class="n">writeBufferSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;writeBufferSize&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;buffer size limit before dumping to disk storage while writing&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">readCacheSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;readCacheSize&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;cache size for items retrieved from storage. Increase for performance but higher memory consumption&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWriteBufferSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">writeBufferSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setReadCacheSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">readCacheSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WordEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.WordEmbeddings&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">writeBufferSize</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
            <span class="n">storageRef</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">uid</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">WordEmbeddingsModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="WordEmbeddingsModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.WordEmbeddingsModel.html#sparknlp.annotator.WordEmbeddingsModel">[docs]</a><span class="k">class</span> <span class="nc">WordEmbeddingsModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasEmbeddingsProperties</span><span class="p">,</span> <span class="n">HasStorageModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Word Embeddings lookup annotator that maps tokens to vectors</span>

<span class="sd">    This is the instantiated model of WordEmbeddings.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">              .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">              .setOutputCol(&quot;embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;glove_100d&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    There are also two convenient functions to retrieve the embeddings coverage with respect to the transformed dataset:</span>
<span class="sd">      - ``withCoverageColumn(dataset, embeddingsCol, outputCol)``:</span>
<span class="sd">        Adds a custom column with word coverage stats for the embedded field:</span>
<span class="sd">        (``coveredWords``, ``totalWords``, ``coveragePercentage``). This creates a new column with statistics for each row.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">              wordsCoverage = WordEmbeddingsModel.withCoverageColumn(resultDF, &quot;embeddings&quot;, &quot;cov_embeddings&quot;)</span>
<span class="sd">              wordsCoverage.select(&quot;text&quot;,&quot;cov_embeddings&quot;).show(truncate=False)</span>
<span class="sd">              +-------------------+--------------+</span>
<span class="sd">              |text               |cov_embeddings|</span>
<span class="sd">              +-------------------+--------------+</span>
<span class="sd">              |This is a sentence.|[5, 5, 1.0]   |</span>
<span class="sd">              +-------------------+--------------+</span>


<span class="sd">      - ``overallCoverage(dataset, embeddingsCol)``:</span>
<span class="sd">        Calculates overall word coverage for the whole data in the embedded field.</span>
<span class="sd">        This returns a single coverage object considering all rows in the field.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">              wordsOverallCoverage = WordEmbeddingsModel.overallCoverage(wordsCoverage,&quot;embeddings&quot;).percentage</span>
<span class="sd">              1.0</span>



<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions</span>
<span class="sd">    readCacheSize</span>
<span class="sd">        cache size for items retrieved from storage. Increase for performance but higher memory consumption</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[-0.570580005645752,0.44183000922203064,0.7010200023651123,-0.417129993438720...|</span>
<span class="sd">        |[-0.542639970779419,0.4147599935531616,1.0321999788284302,-0.4024400115013122...|</span>
<span class="sd">        |[-0.2708599865436554,0.04400600120425224,-0.020260000601410866,-0.17395000159...|</span>
<span class="sd">        |[0.6191999912261963,0.14650000631809235,-0.08592499792575836,-0.2629800140857...|</span>
<span class="sd">        |[-0.3397899866104126,0.20940999686717987,0.46347999572753906,-0.6479200124740...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;WordEmbeddingsModel&quot;</span>
    <span class="n">databases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EMBEDDINGS&#39;</span><span class="p">]</span>

    <span class="n">readCacheSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;readCacheSize&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;cache size for items retrieved from storage. Increase for performance but higher memory consumption&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setReadCacheSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">readCacheSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WordEmbeddingsModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">overallCoverage</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">embeddings_col</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_EmbeddingsOverallCoverage</span>
        <span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="n">CoverageResult</span>
        <span class="k">return</span> <span class="n">CoverageResult</span><span class="p">(</span><span class="n">_EmbeddingsOverallCoverage</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">embeddings_col</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">())</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">withCoverageColumn</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">embeddings_col</span><span class="p">,</span> <span class="n">output_col</span><span class="o">=</span><span class="s1">&#39;coverage&#39;</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_EmbeddingsCoverageColumn</span>
        <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">DataFrame</span>
        <span class="k">return</span> <span class="n">DataFrame</span><span class="p">(</span><span class="n">_EmbeddingsCoverageColumn</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">embeddings_col</span><span class="p">,</span> <span class="n">output_col</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(),</span> <span class="n">dataset</span><span class="o">.</span><span class="n">sql_ctx</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;glove_100d&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">WordEmbeddingsModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadStorage</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">storage_ref</span><span class="p">):</span>
        <span class="n">HasStorageModel</span><span class="o">.</span><span class="n">loadStorages</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">spark</span><span class="p">,</span> <span class="n">storage_ref</span><span class="p">,</span> <span class="n">WordEmbeddingsModel</span><span class="o">.</span><span class="n">databases</span><span class="p">)</span></div>


<div class="viewcode-block" id="BertEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.BertEmbeddings.html#sparknlp.annotator.BertEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">BertEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                     <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                     <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                     <span class="n">HasStorageRef</span><span class="p">,</span>
                     <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Token-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense</span>
<span class="sd">    vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = BertEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;, &quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;bert_embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;small_bert_L2_768&quot;``, if no name is provided.</span>

<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/blogposts/3.NER_with_BERT.ipynb&gt;`__.</span>
<span class="sd">    Models from the HuggingFace  Transformers library are also compatible with Spark NLP . The Spark NLP Workshop</span>
<span class="sd">    example shows how to import them https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</span>

<span class="sd">    **Sources** :</span>

<span class="sd">    `BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding &lt;https://arxiv.org/abs/1810.04805&gt;`__</span>

<span class="sd">    https://github.com/google-research/bert</span>

<span class="sd">    **Paper abstract**</span>

<span class="sd">    *We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations</span>
<span class="sd">    from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional</span>
<span class="sd">    representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a</span>
<span class="sd">    result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create</span>
<span class="sd">    state-of-the-art models for a wide range of tasks, such as question answering and language inference, without</span>
<span class="sd">    substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It</span>
<span class="sd">    obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score</span>
<span class="sd">    to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1</span>
<span class="sd">    question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point</span>
<span class="sd">    absolute improvement).*</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch , by default 8</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default False</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = BertEmbeddings.pretrained(&quot;small_bert_L2_128&quot;, &quot;en&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;, &quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;bert_embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;bert_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            embeddingsFinisher</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[-2.3497989177703857,0.480538547039032,-0.3238905668258667,-1.612930893898010...|</span>
<span class="sd">        |[-2.1357314586639404,0.32984697818756104,-0.6032363176345825,-1.6791689395904...|</span>
<span class="sd">        |[-1.8244884014129639,-0.27088963985443115,-1.059438943862915,-0.9817547798156...|</span>
<span class="sd">        |[-1.1648050546646118,-0.4725411534309387,-0.5938255786895752,-1.5780693292617...|</span>
<span class="sd">        |[-0.9125322699546814,0.4563939869403839,-0.3975459933280945,-1.81611204147338...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;BertEmbeddings&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.BertEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BertEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_BertLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_BertLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">BertEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;small_bert_L2_768&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">BertEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="BertSentenceEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.BertSentenceEmbeddings.html#sparknlp.annotator.BertSentenceEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">BertSentenceEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                             <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                             <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                             <span class="n">HasStorageRef</span><span class="p">,</span>
                             <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sentence-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense</span>
<span class="sd">    vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = BertSentenceEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_bert_embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;sent_small_bert_L2_768&quot;``, if no name is provided.</span>

<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BERT%20Sentence.ipynb&gt;`__.</span>

<span class="sd">    **Sources** :</span>

<span class="sd">    `BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding &lt;https://arxiv.org/abs/1810.04805&gt;`__</span>

<span class="sd">    https://github.com/google-research/bert</span>

<span class="sd">    **Paper abstract**</span>

<span class="sd">    *We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations</span>
<span class="sd">    from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional</span>
<span class="sd">    representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a</span>
<span class="sd">    result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create</span>
<span class="sd">    state-of-the-art models for a wide range of tasks, such as question answering and language inference, without</span>
<span class="sd">    substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It</span>
<span class="sd">    obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score</span>
<span class="sd">    to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1</span>
<span class="sd">    question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point</span>
<span class="sd">    absolute improvement).*</span>

<span class="sd">    ====================== =======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== =======================</span>
<span class="sd">    ``DOCUMENT``           ``SENTENCE_EMBEDDINGS``</span>
<span class="sd">    ====================== =======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default False</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>
<span class="sd">    isLong</span>
<span class="sd">        Use Long type instead of Int type for inputs buffer - Some Bert models require Long instead of Int.</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        embeddings = BertSentenceEmbeddings.pretrained(&quot;sent_small_bert_L2_128&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_bert_embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_bert_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            embeddingsFinisher</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;John loves apples. Mary loves oranges. John loves Mary.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[-0.8951074481010437,0.13753940165042877,0.3108254075050354,-1.65693199634552...|</span>
<span class="sd">        |[-0.6180210709571838,-0.12179657071828842,-0.191165953874588,-1.4497021436691...|</span>
<span class="sd">        |[-0.822715163230896,0.7568016648292542,-0.1165061742067337,-1.59048593044281,...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;BertSentenceEmbeddings&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">isLong</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;isLong&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Use Long type instead of Int type for inputs buffer - Some Bert models require Long instead of Int.&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIsLong</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">isLong</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BertSentenceEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_BertSentenceLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_BertSentenceLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">BertSentenceEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;sent_small_bert_L2_768&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">BertSentenceEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="SentenceEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentenceEmbeddings.html#sparknlp.annotator.SentenceEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">SentenceEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasEmbeddingsProperties</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts the results from WordEmbeddings, BertEmbeddings, or ElmoEmbeddings into sentence</span>
<span class="sd">    or document embeddings by either summing up or averaging all the word embeddings in a sentence or a document</span>
<span class="sd">    (depending on the inputCols).</span>

<span class="sd">    This can be configured with ``setPoolingStrategy``, which either be ``&quot;AVERAGE&quot;`` or ``&quot;SUM&quot;``.</span>

<span class="sd">    For more extended examples see the</span>
<span class="sd">    `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/12.Named_Entity_Disambiguation.ipynb&gt;`__..</span>

<span class="sd">    ============================= =======================</span>
<span class="sd">    Input Annotation types        Output Annotation type</span>
<span class="sd">    ============================= =======================</span>
<span class="sd">    ``DOCUMENT, WORD_EMBEDDINGS`` ``SENTENCE_EMBEDDINGS``</span>
<span class="sd">    ============================= =======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions</span>
<span class="sd">    poolingStrategy</span>
<span class="sd">        Choose how you would like to aggregate Word Embeddings to Sentence Embeddings: AVERAGE or SUM, by default AVERAGE</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        embeddingsSentence = SentenceEmbeddings() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;) \\</span>
<span class="sd">            .setPoolingStrategy(&quot;AVERAGE&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsSentence,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[-0.22093398869037628,0.25130119919776917,0.41810303926467896,-0.380883991718...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;SentenceEmbeddings&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentenceEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.SentenceEmbeddings&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">poolingStrategy</span><span class="o">=</span><span class="s2">&quot;AVERAGE&quot;</span>
        <span class="p">)</span>

    <span class="n">poolingStrategy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;poolingStrategy&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose how you would like to aggregate Word Embeddings to Sentence Embeddings: AVERAGE or SUM&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPoolingStrategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;AVERAGE&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingStrategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;SUM&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingStrategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingStrategy</span><span class="o">=</span><span class="s2">&quot;AVERAGE&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="StopWordsCleaner"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.StopWordsCleaner.html#sparknlp.annotator.StopWordsCleaner">[docs]</a><span class="k">class</span> <span class="nc">StopWordsCleaner</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This annotator takes a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer)</span>
<span class="sd">    and drops all the stop words from the input sequences.</span>

<span class="sd">    By default, it uses stop words from MLlibs</span>
<span class="sd">    `StopWordsRemover &lt;https://spark.apache.org/docs/latest/ml-features#stopwordsremover&gt;`__.</span>
<span class="sd">    Stop words can also be defined by explicitly setting them with ``setStopWords(value: Array[String])`` or loaded from</span>
<span class="sd">    pretrained models using ``pretrained`` of its companion object.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        stopWords = StopWordsCleaner.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;cleanTokens&quot;) \\</span>
<span class="sd">            .setCaseSensitive(False)</span>
<span class="sd">        # will load the default pretrained model ``&quot;stopwords_en&quot;``.</span>


<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Stop+Words+Removal&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    stopWords</span>
<span class="sd">        The words to be filtered out, by default english stopwords from Spark ML</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        whether to do a case sensitive, by default False</span>
<span class="sd">    locale</span>
<span class="sd">        locale of the input. ignored when case sensitive, by default locale of the JVM</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentenceDetector = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        stopWords = StopWordsCleaner() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;cleanTokens&quot;) \\</span>
<span class="sd">            .setCaseSensitive(False)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentenceDetector,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              stopWords</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;This is my first sentence. This is my second.&quot;,</span>
<span class="sd">            &quot;This is my third sentence. This is my forth.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;cleanTokens.result&quot;).show(truncate=False)</span>
<span class="sd">        +-------------------------------+</span>
<span class="sd">        |result                         |</span>
<span class="sd">        +-------------------------------+</span>
<span class="sd">        |[first, sentence, ., second, .]|</span>
<span class="sd">        |[third, sentence, ., forth, .] |</span>
<span class="sd">        +-------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;StopWordsCleaner&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.StopWordsCleaner&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StopWordsCleaner</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">stopWords</span><span class="o">=</span><span class="n">StopWordsCleaner</span><span class="o">.</span><span class="n">loadDefaultStopWords</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">),</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">locale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_java_obj</span><span class="o">.</span><span class="n">getLocale</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="n">stopWords</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;stopWords&quot;</span><span class="p">,</span> <span class="s2">&quot;The words to be filtered out&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">caseSensitive</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;caseSensitive&quot;</span><span class="p">,</span> <span class="s2">&quot;whether to do a case sensitive &quot;</span> <span class="o">+</span>
                          <span class="s2">&quot;comparison over the stop words&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">locale</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;locale&quot;</span><span class="p">,</span> <span class="s2">&quot;locale of the input. ignored when case sensitive &quot;</span> <span class="o">+</span>
                   <span class="s2">&quot;is true&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">stopWords</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCaseSensitive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseSensitive</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLocale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">locale</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loadDefaultStopWords</span><span class="p">(</span><span class="n">language</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">pyspark.ml.wrapper</span> <span class="kn">import</span> <span class="n">_jvm</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the default stop words for the given language.</span>
<span class="sd">        Supported languages: danish, dutch, english, finnish, french, german, hungarian,</span>
<span class="sd">        italian, norwegian, portuguese, russian, spanish, swedish, turkish</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stopWordsObj</span> <span class="o">=</span> <span class="n">_jvm</span><span class="p">()</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">ml</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">StopWordsRemover</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">stopWordsObj</span><span class="o">.</span><span class="n">loadDefaultStopWords</span><span class="p">(</span><span class="n">language</span><span class="p">))</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;stopwords_en&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">StopWordsCleaner</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="NGramGenerator"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NGramGenerator.html#sparknlp.annotator.NGramGenerator">[docs]</a><span class="k">class</span> <span class="nc">NGramGenerator</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A feature transformer that converts the input array of strings (annotatorType TOKEN) into an</span>
<span class="sd">    array of n-grams (annotatorType CHUNK).</span>
<span class="sd">    Null values in the input array are ignored.</span>
<span class="sd">    It returns an array of n-grams where each n-gram is represented by a space-separated string of</span>
<span class="sd">    words.</span>

<span class="sd">    When the input is empty, an empty array is returned.</span>
<span class="sd">    When the input array length is less than n (number of elements per n-gram), no n-grams are</span>
<span class="sd">    returned.</span>

<span class="sd">    For more extended examples see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/chunking/NgramGenerator.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``CHUNK``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n</span>
<span class="sd">        number elements per n-gram (&gt;=1), by default 2</span>
<span class="sd">    enableCumulative</span>
<span class="sd">        whether to calculate just the actual n-grams, by default False</span>
<span class="sd">    delimiter</span>
<span class="sd">        String to use to join the tokens</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        nGrams = NGramGenerator() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ngrams&quot;) \\</span>
<span class="sd">            .setN(2)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentence,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              nGrams</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is my sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        results = pipeline.fit(data).transform(data)</span>

<span class="sd">        results.selectExpr(&quot;explode(ngrams) as result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------------------------------------+</span>
<span class="sd">        |result                                                      |</span>
<span class="sd">        +------------------------------------------------------------+</span>
<span class="sd">        |[chunk, 0, 6, This is, [sentence -&gt; 0, chunk -&gt; 0], []]     |</span>
<span class="sd">        |[chunk, 5, 9, is my, [sentence -&gt; 0, chunk -&gt; 1], []]       |</span>
<span class="sd">        |[chunk, 8, 18, my sentence, [sentence -&gt; 0, chunk -&gt; 2], []]|</span>
<span class="sd">        |[chunk, 11, 19, sentence ., [sentence -&gt; 0, chunk -&gt; 3], []]|</span>
<span class="sd">        +------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;NGramGenerator&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NGramGenerator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.NGramGenerator&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">enableCumulative</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="n">n</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;n&quot;</span><span class="p">,</span> <span class="s2">&quot;number elements per n-gram (&gt;=1)&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">enableCumulative</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;enableCumulative&quot;</span><span class="p">,</span> <span class="s2">&quot;whether to calculate just the actual n-grams &quot;</span> <span class="o">+</span>
                             <span class="s2">&quot;or all n-grams from 1 through n&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">delimiter</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;delimiter&quot;</span><span class="p">,</span> <span class="s2">&quot;String to use to join the tokens &quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

<div class="viewcode-block" id="NGramGenerator.setN"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NGramGenerator.html#sparknlp.annotator.NGramGenerator.setN">[docs]</a>    <span class="k">def</span> <span class="nf">setN</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`n`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="NGramGenerator.setEnableCumulative"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NGramGenerator.html#sparknlp.annotator.NGramGenerator.setEnableCumulative">[docs]</a>    <span class="k">def</span> <span class="nf">setEnableCumulative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`enableCumulative`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">enableCumulative</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

<div class="viewcode-block" id="NGramGenerator.setDelimiter"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NGramGenerator.html#sparknlp.annotator.NGramGenerator.setDelimiter">[docs]</a>    <span class="k">def</span> <span class="nf">setDelimiter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`delimiter`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Delimiter should have length == 1&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">delimiter</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ChunkEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ChunkEmbeddings.html#sparknlp.annotator.ChunkEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">ChunkEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This annotator utilizes WordEmbeddings, BertEmbeddings etc. to generate chunk embeddings from either</span>
<span class="sd">    Chunker, NGramGenerator,</span>
<span class="sd">    or NerConverter outputs.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    ========================== ======================</span>
<span class="sd">    Input Annotation types     Output Annotation type</span>
<span class="sd">    ========================== ======================</span>
<span class="sd">    ``CHUNK, WORD_EMBEDDINGS`` ``WORD_EMBEDDINGS``</span>
<span class="sd">    ========================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    poolingStrategy</span>
<span class="sd">        Choose how you would like to aggregate Word Embeddings to Chunk Embeddings, by default AVERAGE</span>
<span class="sd">    skipOOV</span>
<span class="sd">        Whether to discard default vectors for OOV words from the aggregation / pooling</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        # Extract the Embeddings from the NGrams</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        nGrams = NGramGenerator() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;chunk&quot;) \\</span>
<span class="sd">            .setN(2)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;) \\</span>
<span class="sd">            .setCaseSensitive(False)</span>

<span class="sd">        # Convert the NGram chunks into Word Embeddings</span>
<span class="sd">        chunkEmbeddings = ChunkEmbeddings() \\</span>
<span class="sd">            .setInputCols([&quot;chunk&quot;, &quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;chunk_embeddings&quot;) \\</span>
<span class="sd">            .setPoolingStrategy(&quot;AVERAGE&quot;)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentence,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              nGrams,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              chunkEmbeddings</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(chunk_embeddings) as result&quot;) \\</span>
<span class="sd">            .select(&quot;result.annotatorType&quot;, &quot;result.result&quot;, &quot;result.embeddings&quot;) \\</span>
<span class="sd">            .show(5, 80)</span>
<span class="sd">        +---------------+----------+--------------------------------------------------------------------------------+</span>
<span class="sd">        |  annotatorType|    result|                                                                      embeddings|</span>
<span class="sd">        +---------------+----------+--------------------------------------------------------------------------------+</span>
<span class="sd">        |word_embeddings|   This is|[-0.55661, 0.42829502, 0.86661, -0.409785, 0.06316501, 0.120775, -0.0732005, ...|</span>
<span class="sd">        |word_embeddings|      is a|[-0.40674996, 0.22938299, 0.50597, -0.288195, 0.555655, 0.465145, 0.140118, 0...|</span>
<span class="sd">        |word_embeddings|a sentence|[0.17417, 0.095253006, -0.0530925, -0.218465, 0.714395, 0.79860497, 0.0129999...|</span>
<span class="sd">        |word_embeddings|sentence .|[0.139705, 0.177955, 0.1887775, -0.45545, 0.20030999, 0.461557, -0.07891501, ...|</span>
<span class="sd">        +---------------+----------+--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ChunkEmbeddings&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ChunkEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.ChunkEmbeddings&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">poolingStrategy</span><span class="o">=</span><span class="s2">&quot;AVERAGE&quot;</span>
        <span class="p">)</span>

    <span class="n">poolingStrategy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;poolingStrategy&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose how you would like to aggregate Word Embeddings to Chunk Embeddings:&quot;</span> <span class="o">+</span>
                            <span class="s2">&quot;AVERAGE or SUM&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>
    <span class="n">skipOOV</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;skipOOV&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;Whether to discard default vectors for OOV words from the aggregation / pooling &quot;</span><span class="p">,</span>
                    <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

<div class="viewcode-block" id="ChunkEmbeddings.setPoolingStrategy"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ChunkEmbeddings.html#sparknlp.annotator.ChunkEmbeddings.setPoolingStrategy">[docs]</a>    <span class="k">def</span> <span class="nf">setPoolingStrategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`poolingStrategy`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;AVERAGE&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingStrategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">strategy</span> <span class="o">==</span> <span class="s2">&quot;SUM&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingStrategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingStrategy</span><span class="o">=</span><span class="s2">&quot;AVERAGE&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ChunkEmbeddings.setSkipOOV"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ChunkEmbeddings.html#sparknlp.annotator.ChunkEmbeddings.setSkipOOV">[docs]</a>    <span class="k">def</span> <span class="nf">setSkipOOV</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`skipOOV`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">skipOOV</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="NerOverwriter"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.NerOverwriter.html#sparknlp.annotator.NerOverwriter">[docs]</a><span class="k">class</span> <span class="nc">NerOverwriter</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Overwrites entities of specified strings.</span>

<span class="sd">    The input for this Annotator have to be entities that are already extracted, Annotator type ``NAMED_ENTITY``.</span>
<span class="sd">    The strings specified with ``setStopWords`` will have new entities assigned to, specified with ``setNewResult``.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``NAMED_ENTITY``       ``NAMED_ENTITY``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    stopWords</span>
<span class="sd">        The words to be overwritten</span>
<span class="sd">    newResult</span>
<span class="sd">        new NER class to apply to those stopwords, by default I-OVERWRITE</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        # First extract the prerequisite Entities</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = WordEmbeddingsModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;bert&quot;)</span>

<span class="sd">        nerTagger = NerDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;bert&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ner&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            nerTagger</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;Spark NLP Crosses Five Million Downloads, John Snow Labs Announces.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(ner)&quot;).show(truncate=False)</span>
<span class="sd">        # +------------------------------------------------------+</span>
<span class="sd">        # |col                                                   |</span>
<span class="sd">        # +------------------------------------------------------+</span>
<span class="sd">        # |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []]      |</span>
<span class="sd">        # |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []]        |</span>
<span class="sd">        # |[named_entity, 10, 16, O, [word -&gt; Crosses], []]      |</span>
<span class="sd">        # |[named_entity, 18, 21, O, [word -&gt; Five], []]         |</span>
<span class="sd">        # |[named_entity, 23, 29, O, [word -&gt; Million], []]      |</span>
<span class="sd">        # |[named_entity, 31, 39, O, [word -&gt; Downloads], []]    |</span>
<span class="sd">        # |[named_entity, 40, 40, O, [word -&gt; ,], []]            |</span>
<span class="sd">        # |[named_entity, 42, 45, B-ORG, [word -&gt; John], []]     |</span>
<span class="sd">        # |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []]     |</span>
<span class="sd">        # |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []]     |</span>
<span class="sd">        # |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []]|</span>
<span class="sd">        # |[named_entity, 66, 66, O, [word -&gt; .], []]            |</span>
<span class="sd">        # +------------------------------------------------------+</span>

<span class="sd">        # The recognized entities can then be overwritten</span>
<span class="sd">        nerOverwriter = NerOverwriter() \\</span>
<span class="sd">            .setInputCols([&quot;ner&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;ner_overwritten&quot;) \\</span>
<span class="sd">            .setStopWords([&quot;Million&quot;]) \\</span>
<span class="sd">            .setNewResult(&quot;B-CARDINAL&quot;)</span>

<span class="sd">        nerOverwriter.transform(result).selectExpr(&quot;explode(ner_overwritten)&quot;).show(truncate=False)</span>
<span class="sd">        +---------------------------------------------------------+</span>
<span class="sd">        |col                                                      |</span>
<span class="sd">        +---------------------------------------------------------+</span>
<span class="sd">        |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []]         |</span>
<span class="sd">        |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []]           |</span>
<span class="sd">        |[named_entity, 10, 16, O, [word -&gt; Crosses], []]         |</span>
<span class="sd">        |[named_entity, 18, 21, O, [word -&gt; Five], []]            |</span>
<span class="sd">        |[named_entity, 23, 29, B-CARDINAL, [word -&gt; Million], []]|</span>
<span class="sd">        |[named_entity, 31, 39, O, [word -&gt; Downloads], []]       |</span>
<span class="sd">        |[named_entity, 40, 40, O, [word -&gt; ,], []]               |</span>
<span class="sd">        |[named_entity, 42, 45, B-ORG, [word -&gt; John], []]        |</span>
<span class="sd">        |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []]        |</span>
<span class="sd">        |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []]        |</span>
<span class="sd">        |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []]   |</span>
<span class="sd">        |[named_entity, 66, 66, O, [word -&gt; .], []]               |</span>
<span class="sd">        +---------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;NerOverwriter&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NerOverwriter</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ner.NerOverwriter&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">newResult</span><span class="o">=</span><span class="s2">&quot;I-OVERWRITE&quot;</span>
        <span class="p">)</span>

    <span class="n">stopWords</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;stopWords&quot;</span><span class="p">,</span> <span class="s2">&quot;The words to be overwritten&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">newResult</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;newResult&quot;</span><span class="p">,</span> <span class="s2">&quot;new NER class to apply to those stopwords&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">stopWords</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setNewResult</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">newResult</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>


<div class="viewcode-block" id="UniversalSentenceEncoder"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.UniversalSentenceEncoder.html#sparknlp.annotator.UniversalSentenceEncoder">[docs]</a><span class="k">class</span> <span class="nc">UniversalSentenceEncoder</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasEmbeddingsProperties</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        useEmbeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;tfhub_use&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb&gt;`__.</span>

<span class="sd">    **Sources:**</span>

<span class="sd">    `Universal Sentence Encoder &lt;https://arxiv.org/abs/1803.11175&gt;`__</span>

<span class="sd">    https://tfhub.dev/google/universal-sentence-encoder/2</span>

<span class="sd">    **Paper abstract:**</span>

<span class="sd">    *We present models for encoding sentences into embedding vectors that specifically target transfer learning to other</span>
<span class="sd">    NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the</span>
<span class="sd">    encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and</span>
<span class="sd">    report the relationship between model complexity, resource consumption, the availability of transfer task training</span>
<span class="sd">    data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained</span>
<span class="sd">    word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence</span>
<span class="sd">    embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe</span>
<span class="sd">    surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain</span>
<span class="sd">    encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained</span>
<span class="sd">    sentence encoding models are made freely available for download and on TF Hub.*</span>

<span class="sd">    ====================== =======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== =======================</span>
<span class="sd">    ``DOCUMENT``           ``SENTENCE_EMBEDDINGS``</span>
<span class="sd">    ====================== =======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions</span>
<span class="sd">    loadSP</span>
<span class="sd">        Whether to load SentencePiece ops file which is required only by multi-lingual models, by default False</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        embeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentence,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[0.04616805538535118,0.022307956591248512,-0.044395286589860916,-0.0016493503...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;UniversalSentenceEncoder&quot;</span>

    <span class="n">loadSP</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;loadSP&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Whether to load SentencePiece ops file which is required only by multi-lingual models. &quot;</span>
                   <span class="s2">&quot;This is not changeable after it&#39;s set with a pretrained model nor it is compatible with Windows.&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

<div class="viewcode-block" id="UniversalSentenceEncoder.setLoadSP"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.UniversalSentenceEncoder.html#sparknlp.annotator.UniversalSentenceEncoder.setLoadSP">[docs]</a>    <span class="k">def</span> <span class="nf">setLoadSP</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the value of :py:attr:`loadSP`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">loadSP</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UniversalSentenceEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">loadSP</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">,</span> <span class="n">loadsp</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_USELoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_USELoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">,</span> <span class="n">loadsp</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">UniversalSentenceEncoder</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;tfhub_use&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">UniversalSentenceEncoder</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="ElmoEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ElmoEmbeddings.html#sparknlp.annotator.ElmoEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">ElmoEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasEmbeddingsProperties</span><span class="p">,</span> <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Word embeddings from ELMo (Embeddings from Language Models), a language model trained on the 1 Billion Word Benchmark.</span>

<span class="sd">    Note that this is a very computationally expensive module compared to word embedding modules that only perform</span>
<span class="sd">    embedding lookups. The use of an accelerator is recommended.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = ElmoEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;elmo_embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;elmo&quot;``, if no name is provided.</span>

<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    The pooling layer can be set with ``setPoolingLayer`` to the following values:</span>
<span class="sd">      - ``&quot;word_emb&quot;``: the character-based word representations with shape ``[batch_size, max_length, 512]``.</span>
<span class="sd">      - ``&quot;lstm_outputs1&quot;``: the first LSTM hidden state with shape ``[batch_size, max_length, 1024]``.</span>
<span class="sd">      - ``&quot;lstm_outputs2&quot;``: the second LSTM hidden state with shape ``[batch_size, max_length, 1024]``.</span>
<span class="sd">      - ``&quot;elmo&quot;``: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape ``[batch_size, max_length, 1024]``.</span>

<span class="sd">    For extended examples of usage, see the</span>
<span class="sd">    `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_elmo.ipynb&gt;`__.</span>

<span class="sd">    **Sources:**</span>

<span class="sd">    https://tfhub.dev/google/elmo/3</span>

<span class="sd">    `Deep contextualized word representations &lt;https://arxiv.org/abs/1802.05365&gt;`__</span>

<span class="sd">    **Paper abstract:**</span>

<span class="sd">    *We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of</span>
<span class="sd">    word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model</span>
<span class="sd">    polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model</span>
<span class="sd">    (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to</span>
<span class="sd">    existing models and significantly improve the state of the art across six challenging NLP problems, including</span>
<span class="sd">    question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the</span>
<span class="sd">    deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of</span>
<span class="sd">    semi-supervision signals.*</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Batch size. Large values allows faster processing but requires more memory, by default 32</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    poolingLayer</span>
<span class="sd">        Set ELMO pooling layer to: word_emb, lstm_outputs1, lstm_outputs2, or elmo, by default word_emb</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = ElmoEmbeddings.pretrained() \\</span>
<span class="sd">            .setPoolingLayer(&quot;word_emb&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;, &quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            embeddingsFinisher</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[6.662458181381226E-4,-0.2541114091873169,-0.6275503039360046,0.5787073969841...|</span>
<span class="sd">        |[0.19154725968837738,0.22998669743537903,-0.2894386649131775,0.21524395048618...|</span>
<span class="sd">        |[0.10400570929050446,0.12288510054349899,-0.07056470215320587,-0.246389418840...|</span>
<span class="sd">        |[0.49932169914245605,-0.12706467509269714,0.30969417095184326,0.2643227577209...|</span>
<span class="sd">        |[-0.8871506452560425,-0.20039963722229004,-1.0601330995559692,0.0348707810044...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ElmoEmbeddings&quot;</span>

    <span class="n">batchSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;batchSize&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Batch size. Large values allows faster processing but requires more memory.&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">poolingLayer</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;poolingLayer&quot;</span><span class="p">,</span> <span class="s2">&quot;Set ELMO pooling layer to: word_emb, lstm_outputs1, lstm_outputs2, or elmo&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">batchSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPoolingLayer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">layer</span> <span class="o">==</span> <span class="s2">&quot;word_emb&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingLayer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer</span> <span class="o">==</span> <span class="s2">&quot;lstm_outputs1&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingLayer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer</span> <span class="o">==</span> <span class="s2">&quot;lstm_outputs2&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingLayer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer</span> <span class="o">==</span> <span class="s2">&quot;elmo&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingLayer</span><span class="o">=</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">poolingLayer</span><span class="o">=</span><span class="s2">&quot;word_emb&quot;</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ElmoEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
            <span class="n">poolingLayer</span><span class="o">=</span><span class="s2">&quot;word_emb&quot;</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_ElmoLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_ElmoLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">ElmoEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;elmo&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">ElmoEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="ClassifierDLApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ClassifierDLApproach.html#sparknlp.annotator.ClassifierDLApproach">[docs]</a><span class="k">class</span> <span class="nc">ClassifierDLApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a ClassifierDL for generic Multi-class Text Classification.</span>

<span class="sd">    ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications.</span>
<span class="sd">    The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to</span>
<span class="sd">    100 classes.</span>

<span class="sd">    For instantiated/pretrained models, see ClassifierDLModel.</span>

<span class="sd">    **Notes**:</span>
<span class="sd">      - This annotator accepts a label column of a single item in either type of String, Int, Float, or Double.</span>
<span class="sd">      - UniversalSentenceEncoder,</span>
<span class="sd">        BertSentenceEmbeddings, or</span>
<span class="sd">        SentenceEmbeddings can be used for the ``inputCol``.</span>

<span class="sd">    For extended examples of usage, see the Spark NLP Workshop</span>
<span class="sd">    `Spark NLP Workshop  &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb&gt;`__.</span>

<span class="sd">    ======================= ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================= ======================</span>
<span class="sd">    ``SENTENCE_EMBEDDINGS`` ``CATEGORY``</span>
<span class="sd">    ======================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lr</span>
<span class="sd">        Learning Rate, by default 0.005</span>
<span class="sd">    batchSize</span>
<span class="sd">        Batch size, by default 64</span>
<span class="sd">    dropout</span>
<span class="sd">        Dropout coefficient, by default 0.5</span>
<span class="sd">    maxEpochs</span>
<span class="sd">        Maximum number of epochs to train, by default 30</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    validationSplit</span>
<span class="sd">        Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.</span>
<span class="sd">    enableOutputLogs</span>
<span class="sd">        Whether to use stdout in addition to Spark logs, by default False</span>
<span class="sd">    outputLogsPath</span>
<span class="sd">        Folder path to save training logs</span>
<span class="sd">    labelColumn</span>
<span class="sd">        Column with label per each token</span>
<span class="sd">    verbose</span>
<span class="sd">        Level of verbosity during training</span>
<span class="sd">    randomSeed</span>
<span class="sd">        Random seed</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the training data `&quot;sentiment.csv&quot;` has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # text,label</span>
<span class="sd">        # This movie is the best movie I have wached ever! In my opinion this movie can win an award.,0</span>
<span class="sd">        # This was a terrible movie! The acting was bad really bad!,1</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # Then traning can be done like so:</span>

<span class="sd">        smallCorpus = spark.read.option(&quot;header&quot;,&quot;True&quot;).csv(&quot;src/test/resources/classifier/sentiment.csv&quot;)</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        useEmbeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>

<span class="sd">        docClassifier = ClassifierDLApproach() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;category&quot;) \\</span>
<span class="sd">            .setLabelColumn(&quot;label&quot;) \\</span>
<span class="sd">            .setBatchSize(64) \\</span>
<span class="sd">            .setMaxEpochs(20) \\</span>
<span class="sd">            .setLr(5e-3) \\</span>
<span class="sd">            .setDropout(0.5)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages(</span>
<span class="sd">              [</span>
<span class="sd">                documentAssembler,</span>
<span class="sd">                useEmbeddings,</span>
<span class="sd">                docClassifier</span>
<span class="sd">              ]</span>
<span class="sd">            )</span>

<span class="sd">        pipelineModel = pipeline.fit(smallCorpus)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">batchSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;batchSize&quot;</span><span class="p">,</span> <span class="s2">&quot;Batch size&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">dropout</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="s2">&quot;Dropout coefficient&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">maxEpochs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxEpochs&quot;</span><span class="p">,</span> <span class="s2">&quot;Maximum number of epochs to train&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">validationSplit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;validationSplit&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.&quot;</span><span class="p">,</span>
                            <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">enableOutputLogs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;enableOutputLogs&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;Whether to use stdout in addition to Spark logs.&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">outputLogsPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;outputLogsPath&quot;</span><span class="p">,</span> <span class="s2">&quot;Folder path to save training logs&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">labelColumn</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;labelColumn&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Column with label per each token&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">verbose</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="s2">&quot;Level of verbosity during training&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">randomSeed</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;randomSeed&quot;</span><span class="p">,</span> <span class="s2">&quot;Random seed&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setVerbose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRandomSeed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">randomSeed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLabelColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">labelColumn</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">batchSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setMaxEpochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxEpochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ClassifierDLModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setValidationSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">validationSplit</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setEnableOutputLogs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">enableOutputLogs</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setOutputLogsPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">outputLogsPath</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassifierDLApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">maxEpochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.005</span><span class="p">),</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">enableOutputLogs</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ClassifierDLModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ClassifierDLModel.html#sparknlp.annotator.ClassifierDLModel">[docs]</a><span class="k">class</span> <span class="nc">ClassifierDLModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;ClassifierDL for generic Multi-class Text Classification.</span>

<span class="sd">    ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications.</span>
<span class="sd">    The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to</span>
<span class="sd">    100 classes.</span>

<span class="sd">    This is the instantiated model of the ClassifierDLApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        classifierDL = ClassifierDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;classification&quot;)</span>


<span class="sd">    The default model is ``&quot;classifierdl_use_trec6&quot;``, if no name is provided. It uses embeddings from the</span>
<span class="sd">    UniversalSentenceEncoder and is trained on the</span>
<span class="sd">    `TREC-6 &lt;https://deepai.org/dataset/trec-6#:~:text=The%20TREC%20dataset%20is%20dataset,50%20has%20finer%2Dgrained%20labels&gt;`__ dataset.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Text+Classification&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the</span>
<span class="sd">    `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb&gt;`__.</span>

<span class="sd">    ======================= ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================= ======================</span>
<span class="sd">    ``SENTENCE_EMBEDDINGS`` ``CATEGORY``</span>
<span class="sd">    ======================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    classes</span>
<span class="sd">        get the tags used to trained this ClassifierDLModel</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        useEmbeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>

<span class="sd">        sarcasmDL = ClassifierDLModel.pretrained(&quot;classifierdl_use_sarcasm&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sarcasm&quot;)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentence,</span>
<span class="sd">              useEmbeddings,</span>
<span class="sd">              sarcasmDL</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;I&#39;m ready!&quot;,</span>
<span class="sd">            &quot;If I could put into words how much I love waking up at 6 am on Mondays I would.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(arrays_zip(sentence, sarcasm)) as out&quot;) \\</span>
<span class="sd">            .selectExpr(&quot;out.sentence.result as sentence&quot;, &quot;out.sarcasm.result as sarcasm&quot;) \\</span>
<span class="sd">            .show(truncate=False)</span>
<span class="sd">        +-------------------------------------------------------------------------------+-------+</span>
<span class="sd">        |sentence                                                                       |sarcasm|</span>
<span class="sd">        +-------------------------------------------------------------------------------+-------+</span>
<span class="sd">        |I&#39;m ready!                                                                     |normal |</span>
<span class="sd">        |If I could put into words how much I love waking up at 6 am on Mondays I would.|sarcasm|</span>
<span class="sd">        +-------------------------------------------------------------------------------+-------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ClassifierDLModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassifierDLModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">classes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;classes&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;get the tags used to trained this ClassifierDLModel&quot;</span><span class="p">,</span>
                    <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;classifierdl_use_trec6&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">ClassifierDLModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="AlbertEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.AlbertEmbeddings.html#sparknlp.annotator.AlbertEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">AlbertEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                       <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                       <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                       <span class="n">HasStorageRef</span><span class="p">,</span>
                       <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS - Google Research, Toyota Technological Institute at Chicago</span>

<span class="sd">    These word embeddings represent the outputs generated by the Albert model.</span>
<span class="sd">    All official Albert releases by google in TF-HUB are supported with this Albert Wrapper:</span>

<span class="sd">    **Ported TF-Hub Models:**</span>

<span class="sd">    ``&quot;albert_base_uncased&quot;``    | `albert_base &lt;https://tfhub.dev/google/albert_base/3&gt;`__       |  768-embed-dim,   12-layer,  12-heads, 12M parameters</span>

<span class="sd">    ``&quot;albert_large_uncased&quot;``   | `albert_large &lt;https://tfhub.dev/google/albert_large/3&gt;`__     |  1024-embed-dim,  24-layer,  16-heads, 18M parameters</span>

<span class="sd">    ``&quot;albert_xlarge_uncased&quot;``  | `albert_xlarge &lt;https://tfhub.dev/google/albert_xlarge/3&gt;`__   |  2048-embed-dim,  24-layer,  32-heads, 60M parameters</span>

<span class="sd">    ``&quot;albert_xxlarge_uncased&quot;`` | `albert_xxlarge &lt;https://tfhub.dev/google/albert_xxlarge/3&gt;`__ |  4096-embed-dim,  12-layer,  64-heads, 235M parameters</span>

<span class="sd">    This model requires input tokenization with SentencePiece model, which is provided by Spark-NLP (See tokenizers package).</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = AlbertEmbeddings.pretrained() \\</span>
<span class="sd">         .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">         .setOutputCol(&quot;embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;albert_base_uncased&quot;``, if no name is provided.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_albert.ipynb&gt;`__.</span>
<span class="sd">    Models from the HuggingFace  Transformers library are also compatible with Spark NLP . The Spark NLP Workshop</span>
<span class="sd">    example shows how to import them https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</span>

<span class="sd">    **Sources:**</span>

<span class="sd">    `ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS &lt;https://arxiv.org/pdf/1909.11942.pdf&gt;`__</span>

<span class="sd">    https://github.com/google-research/ALBERT</span>

<span class="sd">    https://tfhub.dev/s?q=albert</span>

<span class="sd">    **Paper abstract:**</span>

<span class="sd">    *Increasing model size when pretraining natural language representations often results in improved performance on</span>
<span class="sd">    downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and</span>
<span class="sd">    longer training times. To address these problems, we present two parameter reduction techniques to lower memory</span>
<span class="sd">    consumption and increase the training speed of BERT (Devlin et al., 2019). Comprehensive empirical evidence shows</span>
<span class="sd">    that our proposed methods lead to models that scale much better compared to</span>
<span class="sd">    the original BERT. We also use a self-supervised loss that focuses on modeling</span>
<span class="sd">    inter-sentence coherence, and show it consistently helps downstream tasks with</span>
<span class="sd">    multi-sentence inputs. As a result, our best model establishes new state-of-the-art</span>
<span class="sd">    results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large.*</span>

<span class="sd">    **Tips:**</span>
<span class="sd">    ALBERT uses repeating layers which results in a small memory footprint,</span>
<span class="sd">    however the computational cost remains similar to a BERT-like architecture with</span>
<span class="sd">    the same number of hidden layers as it has to iterate through the same number of (repeating) layers.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default False</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = AlbertEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;, &quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            embeddingsFinisher</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[1.1342473030090332,-1.3855540752410889,0.9818322062492371,-0.784737348556518...|</span>
<span class="sd">        |[0.847029983997345,-1.047153353691101,-0.1520637571811676,-0.6245765686035156...|</span>
<span class="sd">        |[-0.009860038757324219,-0.13450059294700623,2.707749128341675,1.2916892766952...|</span>
<span class="sd">        |[-0.04192575812339783,-0.5764210224151611,-0.3196685314178467,-0.527840495109...|</span>
<span class="sd">        |[0.15583214163780212,-0.1614152491092682,-0.28423872590065,-0.135491415858268...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;AlbertEmbeddings&quot;</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AlbertEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_AlbertLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_AlbertLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">AlbertEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;albert_base_uncased&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">AlbertEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="XlnetEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.XlnetEmbeddings.html#sparknlp.annotator.XlnetEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">XlnetEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                      <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                      <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                      <span class="n">HasStorageRef</span><span class="p">,</span>
                      <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;XlnetEmbeddings (XLNet): Generalized Autoregressive Pretraining for Language Understanding</span>

<span class="sd">    XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language</span>
<span class="sd">    modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance</span>
<span class="sd">    for language tasks involving long context. Overall, XLNet achieves state-of-the-art (SOTA) results on various</span>
<span class="sd">    downstream language tasks including question answering, natural language inference, sentiment analysis, and document</span>
<span class="sd">    ranking.</span>

<span class="sd">    These word embeddings represent the outputs generated by the XLNet models.</span>

<span class="sd">    Note that this is a very computationally expensive module compared to word embedding modules that only perform embedding lookups.</span>
<span class="sd">    The use of an accelerator is recommended.</span>

<span class="sd">    ``&quot;xlnet_large_cased&quot;`` = `XLNet-Large &lt;https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip&gt;`__ | 24-layer, 1024-hidden, 16-heads</span>

<span class="sd">    ``&quot;xlnet_base_cased&quot;`` = `XLNet-Base &lt;https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip&gt;`__    |  12-layer, 768-hidden, 12-heads. This model is trained on full data (different from the one in the paper).</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = XlnetEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;xlnet_base_cased&quot;``, if no name is provided.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_xlnet.ipynb&gt;`__.</span>
<span class="sd">    Models from the HuggingFace  Transformers library are also compatible with Spark NLP . The Spark NLP Workshop</span>
<span class="sd">    example shows how to import them https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</span>

<span class="sd">    **Sources :**</span>

<span class="sd">    `XLNet: Generalized Autoregressive Pretraining for Language Understanding &lt;https://arxiv.org/abs/1906.08237&gt;`__</span>

<span class="sd">    https://github.com/zihangdai/xlnet</span>

<span class="sd">    **Paper abstract:**</span>

<span class="sd">    *With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves</span>
<span class="sd">    better performance than pretraining approaches based on autoregressive language modeling. However, relying on</span>
<span class="sd">    corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune</span>
<span class="sd">    discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that</span>
<span class="sd">    (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the</span>
<span class="sd">    factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore,</span>
<span class="sd">    XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically,</span>
<span class="sd">    under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question</span>
<span class="sd">    answering, natural language inference, sentiment analysis, and document ranking.*</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default True</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = XlnetEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;, &quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            embeddings,</span>
<span class="sd">            embeddingsFinisher</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[-0.6287205219268799,-0.4865287244319916,-0.186111718416214,0.234187275171279...|</span>
<span class="sd">        |[-1.1967450380325317,0.2746637463569641,0.9481253027915955,0.3431355059146881...|</span>
<span class="sd">        |[-1.0777631998062134,-2.092679977416992,-1.5331977605819702,-1.11190271377563...|</span>
<span class="sd">        |[-0.8349916934967041,-0.45627787709236145,-0.7890847325325012,-1.028069257736...|</span>
<span class="sd">        |[-0.134845569729805,-0.11672890186309814,0.4945235550403595,-0.66587203741073...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;XlnetEmbeddings&quot;</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">XlnetEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_XlnetLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_XlnetLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">XlnetEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;xlnet_base_cased&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">XlnetEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="ContextSpellCheckerApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ContextSpellCheckerApproach.html#sparknlp.annotator.ContextSpellCheckerApproach">[docs]</a><span class="k">class</span> <span class="nc">ContextSpellCheckerApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a deep-learning based Noisy Channel Model Spell Algorithm.</span>
<span class="sd">    Correction candidates are extracted combining context information and word information.</span>

<span class="sd">    For instantiated/pretrained models, see ContextSpellCheckerModel.</span>

<span class="sd">    Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a</span>
<span class="sd">    certain number of errors, ``ContextSpellChecker`` will rank correction sequences according to three things:</span>

<span class="sd">    #. Different correction candidates for each word  **word level**.</span>
<span class="sd">    #. The surrounding text of each word, i.e. its context  **sentence level**.</span>
<span class="sd">    #. The relative cost of different correction candidates according to the edit operations at the character level it requires  **subword level**.</span>

<span class="sd">    For an in-depth explanation of the module see the article `Applying Context Aware Spell Checking in Spark NLP &lt;https://medium.com/spark-nlp/applying-context-aware-spell-checking-in-spark-nlp-3c29c46963bc&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the article `Training a Contextual Spell Checker for Italian Language &lt;https://towardsdatascience.com/training-a-contextual-spell-checker-for-italian-language-66dda528e4bf&gt;`__,</span>
<span class="sd">    the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/blogposts/5.TrainingContextSpellChecker.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    languageModelClasses</span>
<span class="sd">        Number of classes to use during factorization of the softmax output in the LM.</span>
<span class="sd">    wordMaxDistance</span>
<span class="sd">        Maximum distance for the generated candidates for every word.</span>
<span class="sd">    maxCandidates</span>
<span class="sd">        Maximum number of candidates for every word.</span>
<span class="sd">    caseStrategy</span>
<span class="sd">        What case combinations to try when generating candidates.</span>
<span class="sd">    errorThreshold</span>
<span class="sd">        Threshold perplexity for a word to be considered as an error.</span>
<span class="sd">    epochs</span>
<span class="sd">        Number of epochs to train the language model.</span>
<span class="sd">    batchSize</span>
<span class="sd">        Batch size for the training in NLM.</span>
<span class="sd">    initialRate</span>
<span class="sd">        Initial learning rate for the LM.</span>
<span class="sd">    finalRate</span>
<span class="sd">        Final learning rate for the LM.</span>
<span class="sd">    validationFraction</span>
<span class="sd">        Percentage of datapoints to use for validation.</span>
<span class="sd">    minCount</span>
<span class="sd">        Min number of times a token should appear to be included in vocab.</span>
<span class="sd">    compoundCount</span>
<span class="sd">        Min number of times a compound word should appear to be included in vocab.</span>
<span class="sd">    classCount</span>
<span class="sd">        Min number of times the word need to appear in corpus to not be considered of a special class.</span>
<span class="sd">    tradeoff</span>
<span class="sd">        Tradeoff between the cost of a word error and a transition in the language model.</span>
<span class="sd">    weightedDistPath</span>
<span class="sd">        The path to the file containing the weights for the levenshtein distance.</span>
<span class="sd">    maxWindowLen</span>
<span class="sd">        Maximum size for the window used to remember history prior to every correction.</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # For this example, we use the first Sherlock Holmes book as the training dataset.</span>


<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>


<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        spellChecker = ContextSpellCheckerApproach() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;corrected&quot;) \\</span>
<span class="sd">            .setWordMaxDistance(3) \\</span>
<span class="sd">            .setBatchSize(24) \\</span>
<span class="sd">            .setEpochs(8) \\</span>
<span class="sd">            .setLanguageModelClasses(1650)  # dependant on vocabulary size</span>
<span class="sd">            # .addVocabClass(&quot;_NAME_&quot;, names) # Extra classes for correction could be added like this</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            spellChecker</span>
<span class="sd">        ])</span>

<span class="sd">        path = &quot;src/test/resources/spell/sherlockholmes.txt&quot;</span>
<span class="sd">        dataset = spark.sparkContext.textFile(path) \\</span>
<span class="sd">            .toDF(&quot;text&quot;)</span>
<span class="sd">        pipelineModel = pipeline.fit(dataset)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ContextSpellCheckerApproach&quot;</span>

    <span class="n">languageModelClasses</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                 <span class="s2">&quot;languageModelClasses&quot;</span><span class="p">,</span>
                                 <span class="s2">&quot;Number of classes to use during factorization of the softmax output in the LM.&quot;</span><span class="p">,</span>
                                 <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">wordMaxDistance</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;wordMaxDistance&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Maximum distance for the generated candidates for every word.&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxCandidates</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;maxCandidates&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;Maximum number of candidates for every word.&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">caseStrategy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;caseStrategy&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;What case combinations to try when generating candidates.&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">errorThreshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;errorThreshold&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Threshold perplexity for a word to be considered as an error.&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;epochs&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Number of epochs to train the language model.&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">batchSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;batchSize&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Batch size for the training in NLM.&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">initialRate</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;initialRate&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Initial learning rate for the LM.&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">finalRate</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;finalRate&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Final learning rate for the LM.&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">validationFraction</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;validationFraction&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;Percentage of datapoints to use for validation.&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">minCount</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;minCount&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;Min number of times a token should appear to be included in vocab.&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">compoundCount</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;compoundCount&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;Min number of times a compound word should appear to be included in vocab.&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">classCount</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;classCount&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;Min number of times the word need to appear in corpus to not be considered of a special class.&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">tradeoff</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;tradeoff&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;Tradeoff between the cost of a word error and a transition in the language model.&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">weightedDistPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;weightedDistPath&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;The path to the file containing the weights for the levenshtein distance.&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">maxWindowLen</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;maxWindowLen&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;Maximum size for the window used to remember history prior to every correction.&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLanguageModelClasses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">languageModelClasses</span><span class="o">=</span><span class="n">count</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWordMaxDistance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">wordMaxDistance</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxCandidates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">candidates</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxCandidates</span><span class="o">=</span><span class="n">candidates</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCaseStrategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseStrategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setErrorThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">errorThreshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEpochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="n">count</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">batchSize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setInitialRate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rate</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">initialRate</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setFinalRate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rate</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">finalRate</span><span class="o">=</span><span class="n">rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setValidationFraction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fraction</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">validationFraction</span><span class="o">=</span><span class="n">fraction</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinCount</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minCount</span><span class="o">=</span><span class="n">count</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCompoundCount</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">compoundCount</span><span class="o">=</span><span class="n">count</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setClassCount</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">classCount</span><span class="o">=</span><span class="n">count</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTradeoff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">tradeoff</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWeightedDistPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">weightedDistPath</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWeightedDistPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">weightedDistPath</span><span class="o">=</span><span class="n">path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxWindowLen</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxWindowLen</span><span class="o">=</span><span class="n">length</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addVocabClass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">userdist</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s1">&#39;addVocabClass&#39;</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">userdist</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">addRegexClass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">regex</span><span class="p">,</span> <span class="n">userdist</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s1">&#39;addRegexClass&#39;</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">regex</span><span class="p">,</span> <span class="n">userdist</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ContextSpellCheckerApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span> \
            <span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerApproach&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ContextSpellCheckerModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="ContextSpellCheckerModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.ContextSpellCheckerModel.html#sparknlp.annotator.ContextSpellCheckerModel">[docs]</a><span class="k">class</span> <span class="nc">ContextSpellCheckerModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements a deep-learning based Noisy Channel Model Spell Algorithm.</span>
<span class="sd">    Correction candidates are extracted combining context information and word information.</span>

<span class="sd">    Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a</span>
<span class="sd">    certain number of errors, ``ContextSpellChecker`` will rank correction sequences according to three things:</span>

<span class="sd">    #. Different correction candidates for each word  **word level**.</span>
<span class="sd">    #. The surrounding text of each word, i.e. its context  **sentence level**.</span>
<span class="sd">    #. The relative cost of different correction candidates according to the edit operations at the character level it requires  **subword level**.</span>

<span class="sd">    For an in-depth explanation of the module see the article `Applying Context Aware Spell Checking in Spark NLP &lt;https://medium.com/spark-nlp/applying-context-aware-spell-checking-in-spark-nlp-3c29c46963bc&gt;`__.</span>

<span class="sd">    This is the instantiated model of the ContextSpellCheckerApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        spellChecker = ContextSpellCheckerModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;checked&quot;)</span>


<span class="sd">    The default model is ``&quot;spellcheck_dl&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Spell+Check&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    wordMaxDistance</span>
<span class="sd">        Maximum distance for the generated candidates for every word.</span>
<span class="sd">    maxCandidates</span>
<span class="sd">        Maximum number of candidates for every word.</span>
<span class="sd">    caseStrategy</span>
<span class="sd">        What case combinations to try when generating candidates.</span>
<span class="sd">    errorThreshold</span>
<span class="sd">        Threshold perplexity for a word to be considered as an error.</span>
<span class="sd">    tradeoff</span>
<span class="sd">        Tradeoff between the cost of a word error and a transition in the language model.</span>
<span class="sd">    weightedDistPath</span>
<span class="sd">        The path to the file containing the weights for the levenshtein distance.</span>
<span class="sd">    maxWindowLen</span>
<span class="sd">        Maximum size for the window used to remember history prior to every correction.</span>
<span class="sd">    gamma</span>
<span class="sd">        Controls the influence of individual word frequency in the decision.</span>
<span class="sd">    correctSymbols</span>
<span class="sd">        Whether to correct special symbols or skip spell checking for them</span>
<span class="sd">    compareLowcase</span>
<span class="sd">        If true will compare tokens in low case with vocabulary</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;doc&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;doc&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        spellChecker = ContextSpellCheckerModel \\</span>
<span class="sd">            .pretrained() \\</span>
<span class="sd">            .setTradeOff(12.0) \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;checked&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            tokenizer,</span>
<span class="sd">            spellChecker</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;It was a cold , dreary day and the country was white with smow .&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;checked.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                          |</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[It, was, a, cold, ,, dreary, day, and, the, country, was, white, with, snow, .]|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;ContextSpellCheckerModel&quot;</span>

    <span class="n">wordMaxDistance</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;wordMaxDistance&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Maximum distance for the generated candidates for every word.&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxCandidates</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;maxCandidates&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;Maximum number of candidates for every word.&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">caseStrategy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;caseStrategy&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;What case combinations to try when generating candidates.&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">errorThreshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;errorThreshold&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Threshold perplexity for a word to be considered as an error.&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">tradeoff</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;tradeoff&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;Tradeoff between the cost of a word error and a transition in the language model.&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">weightedDistPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;weightedDistPath&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;The path to the file containing the weights for the levenshtein distance.&quot;</span><span class="p">,</span>
                             <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">maxWindowLen</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;maxWindowLen&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;Maximum size for the window used to remember history prior to every correction.&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">gamma</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                  <span class="s2">&quot;gamma&quot;</span><span class="p">,</span>
                  <span class="s2">&quot;Controls the influence of individual word frequency in the decision.&quot;</span><span class="p">,</span>
                  <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">correctSymbols</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;correctSymbols&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Whether to correct special symbols or skip spell checking for them&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">compareLowcase</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;compareLowcase&quot;</span><span class="p">,</span> <span class="s2">&quot;If true will compare tokens in low case with vocabulary&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWordMaxDistance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">wordMaxDistance</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxCandidates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">candidates</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxCandidates</span><span class="o">=</span><span class="n">candidates</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCaseStrategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">strategy</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">caseStrategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setErrorThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">errorThreshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTradeoff</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">tradeoff</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s1">&#39;setWeights&#39;</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxWindowLen</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxWindowLen</span><span class="o">=</span><span class="n">length</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setGamma</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getWordClasses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">it</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s1">&#39;getWordClasses&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">toIterator</span><span class="p">()</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">hasNext</span><span class="p">()):</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">it</span><span class="o">.</span><span class="n">next</span><span class="p">()</span><span class="o">.</span><span class="n">toString</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">updateRegexClass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">regex</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s1">&#39;updateRegexClass&#39;</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">regex</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">updateVocabClass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_java</span><span class="p">(</span><span class="s1">&#39;updateVocabClass&#39;</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">append</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setCorrectSymbols</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">correctSymbols</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCompareLowcase</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">compareLowcase</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerModel&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ContextSpellCheckerModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;spellcheck_dl&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">ContextSpellCheckerModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="SentimentDLApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentimentDLApproach.html#sparknlp.annotator.SentimentDLApproach">[docs]</a><span class="k">class</span> <span class="nc">SentimentDLApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a SentimentDL, an annotator for multi-class sentiment analysis.</span>

<span class="sd">    In natural language processing, sentiment analysis is the task of classifying the affective state or subjective view</span>
<span class="sd">    of a text. A common example is if either a product review or tweet can be interpreted positively or negatively.</span>

<span class="sd">    For the instantiated/pretrained models, see SentimentDLModel.</span>

<span class="sd">    **Notes**:</span>

<span class="sd">    * This annotator accepts a label column of a single item in either type of String, Int, Float, or Double.</span>
<span class="sd">      So positive sentiment can be expressed as either ``&quot;positive&quot;`` or ``0``, negative sentiment as ``&quot;negative&quot;`` or ``1``.</span>
<span class="sd">    * UniversalSentenceEncoder,</span>
<span class="sd">      BertSentenceEmbeddings, or</span>
<span class="sd">      SentenceEmbeddings can be used for the ``inputCol``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/SentimentDL_train_multiclass_sentiment_classifier.ipynb&gt;`__.</span>

<span class="sd">    ======================= ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================= ======================</span>
<span class="sd">    ``SENTENCE_EMBEDDINGS`` ``CATEGORY``</span>
<span class="sd">    ======================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    lr</span>
<span class="sd">        Learning Rate, by default 0.005</span>
<span class="sd">    batchSize</span>
<span class="sd">        Batch size, by default 64</span>
<span class="sd">    dropout</span>
<span class="sd">        Dropout coefficient, by default 0.5</span>
<span class="sd">    maxEpochs</span>
<span class="sd">        Maximum number of epochs to train, by default 30</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    validationSplit</span>
<span class="sd">        Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.</span>
<span class="sd">    enableOutputLogs</span>
<span class="sd">        Whether to use stdout in addition to Spark logs, by default False</span>
<span class="sd">    outputLogsPath</span>
<span class="sd">        Folder path to save training logs</span>
<span class="sd">    labelColumn</span>
<span class="sd">        Column with label per each token</span>
<span class="sd">    verbose</span>
<span class="sd">        Level of verbosity during training</span>
<span class="sd">    randomSeed</span>
<span class="sd">        Random seed</span>
<span class="sd">    threshold</span>
<span class="sd">        The minimum threshold for the final result otheriwse it will be neutral, by default 0.6</span>
<span class="sd">    thresholdLabel</span>
<span class="sd">        In case the score is less than threshold, what should be the label. Default is neutral, by default &quot;neutral&quot;</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, `sentiment.csv` is in the form</span>
<span class="sd">        #</span>
<span class="sd">        # text,label</span>
<span class="sd">        # This movie is the best movie I have watched ever! In my opinion this movie can win an award.,0</span>
<span class="sd">        # This was a terrible movie! The acting was bad really bad!,1</span>
<span class="sd">        #</span>
<span class="sd">        # The model can then be trained with</span>

<span class="sd">        smallCorpus = spark.read.option(&quot;header&quot;, &quot;True&quot;).csv(&quot;src/test/resources/classifier/sentiment.csv&quot;)</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        useEmbeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>

<span class="sd">        docClassifier = SentimentDLApproach() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentiment&quot;) \\</span>
<span class="sd">            .setLabelColumn(&quot;label&quot;) \\</span>
<span class="sd">            .setBatchSize(32) \\</span>
<span class="sd">            .setMaxEpochs(1) \\</span>
<span class="sd">            .setLr(5e-3) \\</span>
<span class="sd">            .setDropout(0.5)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages(</span>
<span class="sd">              [</span>
<span class="sd">                documentAssembler,</span>
<span class="sd">                useEmbeddings,</span>
<span class="sd">                docClassifier</span>
<span class="sd">              ]</span>
<span class="sd">            )</span>

<span class="sd">        pipelineModel = pipeline.fit(smallCorpus)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">batchSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;batchSize&quot;</span><span class="p">,</span> <span class="s2">&quot;Batch size&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">dropout</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="s2">&quot;Dropout coefficient&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">maxEpochs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxEpochs&quot;</span><span class="p">,</span> <span class="s2">&quot;Maximum number of epochs to train&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">validationSplit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;validationSplit&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.&quot;</span><span class="p">,</span>
                            <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">enableOutputLogs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;enableOutputLogs&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;Whether to use stdout in addition to Spark logs.&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">outputLogsPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;outputLogsPath&quot;</span><span class="p">,</span> <span class="s2">&quot;Folder path to save training logs&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">labelColumn</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;labelColumn&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Column with label per each token&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">verbose</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="s2">&quot;Level of verbosity during training&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">randomSeed</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;randomSeed&quot;</span><span class="p">,</span> <span class="s2">&quot;Random seed&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;The minimum threshold for the final result otheriwse it will be neutral&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">thresholdLabel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;thresholdLabel&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;In case the score is less than threshold, what should be the label. Default is neutral.&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setVerbose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRandomSeed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">randomSeed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLabelColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">labelColumn</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">batchSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setDropout</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dropout</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setMaxEpochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxEpochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">SentimentDLModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setValidationSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">validationSplit</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setEnableOutputLogs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">enableOutputLogs</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setOutputLogsPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">outputLogsPath</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setThresholdLabel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">thresholdLabel</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentimentDLApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">maxEpochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.005</span><span class="p">),</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">enableOutputLogs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
            <span class="n">thresholdLabel</span><span class="o">=</span><span class="s2">&quot;neutral&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="SentimentDLModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentimentDLModel.html#sparknlp.annotator.SentimentDLModel">[docs]</a><span class="k">class</span> <span class="nc">SentimentDLModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;SentimentDL, an annotator for multi-class sentiment analysis.</span>

<span class="sd">    In natural language processing, sentiment analysis is the task of classifying the affective state or subjective view</span>
<span class="sd">    of a text. A common example is if either a product review or tweet can be interpreted positively or negatively.</span>

<span class="sd">    This is the instantiated model of the SentimentDLApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        sentiment = SentimentDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentiment&quot;)</span>


<span class="sd">    The default model is ``&quot;sentimentdl_use_imdb&quot;``, if no name is provided. It is english sentiment analysis trained on</span>
<span class="sd">    the IMDB dataset.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Sentiment+Analysis&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb&gt;`__.</span>

<span class="sd">    ======================= ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================= ======================</span>
<span class="sd">    ``SENTENCE_EMBEDDINGS`` ``CATEGORY``</span>
<span class="sd">    ======================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    threshold</span>
<span class="sd">        The minimum threshold for the final result otheriwse it will be neutral, by default 0.6</span>
<span class="sd">    thresholdLabel</span>
<span class="sd">        In case the score is less than threshold, what should be the label. Default is neutral, by default &quot;neutral&quot;</span>
<span class="sd">    classes</span>
<span class="sd">        get the tags used to trained this SentimentDLModel</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        useEmbeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>

<span class="sd">        sentiment = SentimentDLModel.pretrained(&quot;sentimentdl_use_twitter&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setThreshold(0.7) \\</span>
<span class="sd">            .setOutputCol(&quot;sentiment&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            useEmbeddings,</span>
<span class="sd">            sentiment</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Wow, the new video is awesome!&quot;,</span>
<span class="sd">            &quot;bruh what a damn waste of time&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;text&quot;, &quot;sentiment.result&quot;).show(truncate=False)</span>
<span class="sd">        +------------------------------+----------+</span>
<span class="sd">        |text                          |result    |</span>
<span class="sd">        +------------------------------+----------+</span>
<span class="sd">        |Wow, the new video is awesome!|[positive]|</span>
<span class="sd">        |bruh what a damn waste of time|[negative]|</span>
<span class="sd">        +------------------------------+----------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;SentimentDLModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentimentDLModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">threshold</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
            <span class="n">thresholdLabel</span><span class="o">=</span><span class="s2">&quot;neutral&quot;</span>
        <span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;The minimum threshold for the final result otheriwse it will be neutral&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">thresholdLabel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;thresholdLabel&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;In case the score is less than threshold, what should be the label. Default is neutral.&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;classes&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;get the tags used to trained this SentimentDLModel&quot;</span><span class="p">,</span>
                    <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setThresholdLabel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">thresholdLabel</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;sentimentdl_use_imdb&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">SentimentDLModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="LanguageDetectorDL"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.LanguageDetectorDL.html#sparknlp.annotator.LanguageDetectorDL">[docs]</a><span class="k">class</span> <span class="nc">LanguageDetectorDL</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Language Identification and Detection by using CNN and RNN architectures in TensorFlow.</span>

<span class="sd">    ``LanguageDetectorDL`` is an annotator that detects the language of documents or sentences depending on the inputCols.</span>
<span class="sd">    The models are trained on large datasets such as Wikipedia and Tatoeba.</span>
<span class="sd">    Depending on the language (how similar the characters are), the LanguageDetectorDL works</span>
<span class="sd">    best with text longer than 140 characters.</span>
<span class="sd">    The output is a language code in `Wiki Code style &lt;https://en.wikipedia.org/wiki/List_of_Wikipedias&gt;`__.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        Val languageDetector = LanguageDetectorDL.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;language&quot;)</span>


<span class="sd">    The default model is ``&quot;ld_wiki_tatoeba_cnn_21&quot;``, default language is ``&quot;xx&quot;`` (meaning multi-lingual),</span>
<span class="sd">    if no values are provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Language+Detection&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/language-detection/Language_Detection_and_Indentification.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``LANGUAGE``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    threshold</span>
<span class="sd">        The minimum threshold for the final result otheriwse it will be either neutral or the value set in thresholdLabel, by default 0.5</span>
<span class="sd">    thresholdLabel</span>
<span class="sd">        In case the score is less than threshold, what should be the label. Default is neutral, by default Unknown</span>
<span class="sd">    coalesceSentences</span>
<span class="sd">        If sets to true the output of all sentences will be averaged to one output instead of one output per sentence. Default to false, by default True</span>
<span class="sd">    languages</span>
<span class="sd">        get the languages used to trained the model</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        languageDetector = LanguageDetectorDL.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;language&quot;)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              languageDetector</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Spark NLP is an open-source text processing library for advanced natural language processing for the Python, Java and Scala programming languages.&quot;,</span>
<span class="sd">            &quot;Spark NLP est une bibliothque de traitement de texte open source pour le traitement avanc du langage naturel pour les langages de programmation Python, Java et Scala.&quot;,</span>
<span class="sd">            &quot;Spark NLP ist eine Open-Source-Textverarbeitungsbibliothek fr fortgeschrittene natrliche Sprachverarbeitung fr die Programmiersprachen Python, Java und Scala.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;language.result&quot;).show(truncate=False)</span>
<span class="sd">        +------+</span>
<span class="sd">        |result|</span>
<span class="sd">        +------+</span>
<span class="sd">        |[en]  |</span>
<span class="sd">        |[fr]  |</span>
<span class="sd">        |[de]  |</span>
<span class="sd">        +------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;LanguageDetectorDL&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LanguageDetectorDL</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">thresholdLabel</span><span class="o">=</span><span class="s2">&quot;Unknown&quot;</span><span class="p">,</span>
            <span class="n">coalesceSentences</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;The minimum threshold for the final result otheriwse it will be either neutral or the value set in thresholdLabel.&quot;</span><span class="p">,</span>
                      <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">thresholdLabel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;thresholdLabel&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;In case the score is less than threshold, what should be the label. Default is neutral.&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>
    <span class="n">coalesceSentences</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;coalesceSentences&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;If sets to true the output of all sentences will be averaged to one output instead of one output per sentence. Default to false.&quot;</span><span class="p">,</span>
                              <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">languages</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;languages&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;get the languages used to trained the model&quot;</span><span class="p">,</span>
                      <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setThresholdLabel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">thresholdLabel</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setCoalesceSentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">coalesceSentences</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;ld_wiki_tatoeba_cnn_21&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;xx&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">LanguageDetectorDL</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiClassifierDLApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.MultiClassifierDLApproach.html#sparknlp.annotator.MultiClassifierDLApproach">[docs]</a><span class="k">class</span> <span class="nc">MultiClassifierDLApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a MultiClassifierDL for Multi-label Text Classification.</span>

<span class="sd">    MultiClassifierDL uses a Bidirectional GRU with a convolutional model that we have built inside TensorFlow and supports</span>
<span class="sd">    up to 100 classes.</span>

<span class="sd">    For instantiated/pretrained models, see MultiClassifierDLModel.</span>

<span class="sd">    The input to ``MultiClassifierDL`` are Sentence Embeddings such as the state-of-the-art</span>
<span class="sd">    UniversalSentenceEncoder,</span>
<span class="sd">    BertSentenceEmbeddings, or</span>
<span class="sd">    SentenceEmbeddings.</span>

<span class="sd">    In machine learning, multi-label classification and the strongly related problem of multi-output classification are</span>
<span class="sd">    variants of the classification problem where multiple labels may be assigned to each instance. Multi-label</span>
<span class="sd">    classification is a generalization of multiclass classification, which is the single-label problem of categorizing</span>
<span class="sd">    instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many</span>
<span class="sd">    of the classes the instance can be assigned to.</span>
<span class="sd">    Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y</span>
<span class="sd">    (assigning a value of 0 or 1 for each element (label) in y).</span>

<span class="sd">    **Notes**:</span>
<span class="sd">      - This annotator requires an array of labels in type of String.</span>
<span class="sd">      - UniversalSentenceEncoder,</span>
<span class="sd">        BertSentenceEmbeddings, or</span>
<span class="sd">        SentenceEmbeddings can be used for the ``inputCol``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/MultiClassifierDL_train_multi_label_E2E_challenge_classifier.ipynb&gt;`__.</span>

<span class="sd">    ======================= ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================= ======================</span>
<span class="sd">    ``SENTENCE_EMBEDDINGS`` ``CATEGORY``</span>
<span class="sd">    ======================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    lr</span>
<span class="sd">        Learning Rate, by default 0.001</span>
<span class="sd">    batchSize</span>
<span class="sd">        Batch size, by default 64</span>
<span class="sd">    maxEpochs</span>
<span class="sd">        Maximum number of epochs to train, by default 10</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    validationSplit</span>
<span class="sd">        Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off, by default 0.0</span>
<span class="sd">    enableOutputLogs</span>
<span class="sd">        Whether to use stdout in addition to Spark logs, by default False</span>
<span class="sd">    outputLogsPath</span>
<span class="sd">        Folder path to save training logs</span>
<span class="sd">    labelColumn</span>
<span class="sd">        Column with label per each token</span>
<span class="sd">    verbose</span>
<span class="sd">        Level of verbosity during training</span>
<span class="sd">    randomSeed</span>
<span class="sd">        Random seed, by default 44</span>
<span class="sd">    shufflePerEpoch</span>
<span class="sd">        whether to shuffle the training data on each Epoch, by default False</span>
<span class="sd">    threshold</span>
<span class="sd">        The minimum threshold for each label to be accepted, by default 0.5</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the training data has the form (Note: labels can be arbitrary)</span>
<span class="sd">        #</span>
<span class="sd">        # mr,re</span>
<span class="sd">        # &quot;name[Alimentum], area[city centre], familyFriendly[no], near[Burger King]&quot;,Alimentum is an adult establish found in the city centre area near Burger King.</span>
<span class="sd">        # &quot;name[Alimentum], area[city centre], familyFriendly[yes]&quot;,Alimentum is a family-friendly place in the city centre.</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # It needs some pre-processing first, so the labels are of type `Array[String]`. This can be done like so:</span>

<span class="sd">        # Process training data to create text with associated array of labels</span>
<span class="sd">        de splitAndTrim = udf { labels: String =&gt;</span>
<span class="sd">            labels.split(&quot;, &quot;).map(x=&gt;x.trim)</span>
<span class="sd">        }</span>

<span class="sd">        smallCorpus = spark.read \\</span>
<span class="sd">            .option(&quot;header&quot;, True) \\</span>
<span class="sd">            .option(&quot;inferSchema&quot;, True) \\</span>
<span class="sd">            .option(&quot;mode&quot;, &quot;DROPMALFORMED&quot;) \\</span>
<span class="sd">            .csv(&quot;src/test/resources/classifier/e2e.csv&quot;) \\</span>
<span class="sd">            .withColumn(&quot;labels&quot;, splitAndTrim(col(&quot;mr&quot;))) \\</span>
<span class="sd">            .withColumn(&quot;text&quot;, col(&quot;re&quot;)) \\</span>
<span class="sd">            .drop(&quot;mr&quot;)</span>

<span class="sd">        smallCorpus.printSchema()</span>
<span class="sd">        # root</span>
<span class="sd">        # |-- re: string (nullable = True)</span>
<span class="sd">        # |-- labels: array (nullable = True)</span>
<span class="sd">        # |    |-- element: string (containsNull = True)</span>

<span class="sd">        # Then create pipeline for training</span>
<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;) \\</span>
<span class="sd">            .setCleanupMode(&quot;shrink&quot;)</span>

<span class="sd">        embeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>

<span class="sd">        docClassifier = MultiClassifierDLApproach() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;category&quot;) \\</span>
<span class="sd">            .setLabelColumn(&quot;labels&quot;) \\</span>
<span class="sd">            .setBatchSize(128) \\</span>
<span class="sd">            .setMaxEpochs(10) \\</span>
<span class="sd">            .setLr(1e-3) \\</span>
<span class="sd">            .setThreshold(0.5) \\</span>
<span class="sd">            .setValidationSplit(0.1)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages(</span>
<span class="sd">              [</span>
<span class="sd">                documentAssembler,</span>
<span class="sd">                embeddings,</span>
<span class="sd">                docClassifier</span>
<span class="sd">              ]</span>
<span class="sd">            )</span>

<span class="sd">        pipelineModel = pipeline.fit(smallCorpus)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">lr</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">batchSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;batchSize&quot;</span><span class="p">,</span> <span class="s2">&quot;Batch size&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxEpochs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxEpochs&quot;</span><span class="p">,</span> <span class="s2">&quot;Maximum number of epochs to train&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">validationSplit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;validationSplit&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose the proportion of training dataset to be validated against the model on each Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.&quot;</span><span class="p">,</span>
                            <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">enableOutputLogs</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;enableOutputLogs&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;Whether to use stdout in addition to Spark logs.&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">outputLogsPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;outputLogsPath&quot;</span><span class="p">,</span> <span class="s2">&quot;Folder path to save training logs&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">labelColumn</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;labelColumn&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Column with label per each token&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">verbose</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="s2">&quot;Level of verbosity during training&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">randomSeed</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;randomSeed&quot;</span><span class="p">,</span> <span class="s2">&quot;Random seed&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">shufflePerEpoch</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;shufflePerEpoch&quot;</span><span class="p">,</span> <span class="s2">&quot;whether to shuffle the training data on each Epoch&quot;</span><span class="p">,</span>
                            <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;The minimum threshold for each label to be accepted. Default is 0.5&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setVerbose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRandomSeed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">randomSeed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLabelColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">labelColumn</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setBatchSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">batchSize</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setMaxEpochs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxEpochs</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ClassifierDLModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setValidationSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">validationSplit</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setEnableOutputLogs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">enableOutputLogs</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setOutputLogsPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">outputLogsPath</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setShufflePerEpoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">shufflePerEpoch</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiClassifierDLApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">maxEpochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
            <span class="n">validationSplit</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span>
            <span class="n">threshold</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">randomSeed</span><span class="o">=</span><span class="mi">44</span><span class="p">,</span>
            <span class="n">shufflePerEpoch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">enableOutputLogs</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="MultiClassifierDLModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.MultiClassifierDLModel.html#sparknlp.annotator.MultiClassifierDLModel">[docs]</a><span class="k">class</span> <span class="nc">MultiClassifierDLModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasStorageRef</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;MultiClassifierDL for Multi-label Text Classification.</span>

<span class="sd">    MultiClassifierDL Bidirectional GRU with Convolution model we have built inside TensorFlow and supports up to 100 classes.</span>
<span class="sd">    The input to MultiClassifierDL is Sentence Embeddings such as state-of-the-art</span>
<span class="sd">    UniversalSentenceEncoder,</span>
<span class="sd">    BertSentenceEmbeddings, or</span>
<span class="sd">    SentenceEmbeddings.</span>

<span class="sd">    This is the instantiated model of the MultiClassifierDLApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        multiClassifier = MultiClassifierDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;categories&quot;)</span>


<span class="sd">    The default model is ``&quot;multiclassifierdl_use_toxic&quot;``, if no name is provided. It uses embeddings from the</span>
<span class="sd">    UniversalSentenceEncoder and classifies toxic comments.</span>
<span class="sd">    The data is based on the</span>
<span class="sd">    `Jigsaw Toxic Comment Classification Challenge &lt;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview&gt;`__.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Text+Classification&gt;`__.</span>

<span class="sd">    In machine learning, multi-label classification and the strongly related problem of multi-output classification are</span>
<span class="sd">    variants of the classification problem where multiple labels may be assigned to each instance. Multi-label</span>
<span class="sd">    classification is a generalization of multiclass classification, which is the single-label problem of categorizing</span>
<span class="sd">    instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many</span>
<span class="sd">    of the classes the instance can be assigned to.</span>
<span class="sd">    Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y</span>
<span class="sd">    (assigning a value of 0 or 1 for each element (label) in y).</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/MultiClassifierDL_train_multi_label_E2E_challenge_classifier.ipynb&gt;`__.</span>

<span class="sd">    ======================= ======================</span>
<span class="sd">    Input Annotation types  Output Annotation type</span>
<span class="sd">    ======================= ======================</span>
<span class="sd">    ``SENTENCE_EMBEDDINGS`` ``CATEGORY``</span>
<span class="sd">    ======================= ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    threshold</span>
<span class="sd">        The minimum threshold for each label to be accepted, by default 0.5</span>
<span class="sd">    classes</span>
<span class="sd">        get the tags used to trained this MultiClassifierDLModel</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        useEmbeddings = UniversalSentenceEncoder.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence_embeddings&quot;)</span>

<span class="sd">        multiClassifierDl = MultiClassifierDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence_embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;classifications&quot;)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              useEmbeddings,</span>
<span class="sd">              multiClassifierDl</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;This is pretty good stuff!&quot;,</span>
<span class="sd">            &quot;Wtf kind of crap is this&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;text&quot;, &quot;classifications.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------+----------------+</span>
<span class="sd">        |text                      |result          |</span>
<span class="sd">        +--------------------------+----------------+</span>
<span class="sd">        |This is pretty good stuff!|[]              |</span>
<span class="sd">        |Wtf kind of crap is this  |[toxic, obscene]|</span>
<span class="sd">        +--------------------------+----------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;MultiClassifierDLModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiClassifierDLModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">threshold</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;The minimum threshold for each label to be accepted. Default is 0.5&quot;</span><span class="p">,</span> <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;classes&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;get the tags used to trained this MultiClassifierDLModel&quot;</span><span class="p">,</span>
                    <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;multiclassifierdl_use_toxic&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">MultiClassifierDLModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="YakeModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.YakeModel.html#sparknlp.annotator.YakeModel">[docs]</a><span class="k">class</span> <span class="nc">YakeModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction</span>
<span class="sd">    algorithm.</span>

<span class="sd">    Extracting keywords from texts has become a challenge for individuals and organizations as the information grows in</span>
<span class="sd">    complexity and size. The need to automate this task so that text can be processed in a timely and adequate manner has</span>
<span class="sd">    led to the emergence of automatic keyword extraction tools. Yake is a novel feature-based system for multi-lingual</span>
<span class="sd">    keyword extraction, which supports texts of different sizes, domain or languages. Unlike other approaches, Yake does</span>
<span class="sd">    not rely on dictionaries nor thesauri, neither is trained against any corpora. Instead, it follows an unsupervised</span>
<span class="sd">    approach which builds upon features extracted from the text, making it thus applicable to documents written in</span>
<span class="sd">    different languages without the need for further knowledge. This can be beneficial for a large number of tasks and a</span>
<span class="sd">    plethora of situations where access to training corpora is either limited or restricted.</span>
<span class="sd">    The algorithm makes use of the position of a sentence and token. Therefore, to use the annotator, the text should be</span>
<span class="sd">    first sent through a Sentence Boundary Detector and then a tokenizer.</span>

<span class="sd">    See the parameters section for tweakable parameters to get the best result from the annotator.</span>

<span class="sd">    Note that each keyword will be given a keyword score greater than 0 (The lower the score better the keyword).</span>
<span class="sd">    Therefore to filter the keywords, an upper bound for the score can be set with ``setThreshold``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/8.Keyword_Extraction_YAKE.ipynb&gt;`__.</span>

<span class="sd">    **Sources** :</span>

<span class="sd">    `Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289 &lt;https://www.sciencedirect.com/science/article/pii/S0020025519308588&gt;`__</span>

<span class="sd">    **Paper abstract:**</span>

<span class="sd">    *As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms,</span>
<span class="sd">    thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically</span>
<span class="sd">    identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available.</span>
<span class="sd">    An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on</span>
<span class="sd">    statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents,</span>
<span class="sd">    nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art</span>
<span class="sd">    unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on</span>
<span class="sd">    texts of different sizes, languages, and domains.*</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``TOKEN``              ``KEYWORD``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    minNGrams</span>
<span class="sd">        Minimum N-grams a keyword should have, by default 2</span>
<span class="sd">    maxNGrams</span>
<span class="sd">        Maximum N-grams a keyword should have, by default 3</span>
<span class="sd">    threshold</span>
<span class="sd">        Keyword Score threshold, by default -1</span>
<span class="sd">    windowSize</span>
<span class="sd">        Window size for Co-Occurrence, by default 3</span>
<span class="sd">    nKeywords</span>
<span class="sd">        Number of Keywords to extract, by default 30</span>
<span class="sd">    stopWords</span>
<span class="sd">        the words to be filtered out, by default english stop words from Spark ML</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentenceDetector = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        token = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;) \\</span>
<span class="sd">            .setContextChars([&quot;(&quot;, &quot;]&quot;, &quot;?&quot;, &quot;!&quot;, &quot;.&quot;, &quot;,&quot;))</span>

<span class="sd">        keywords = YakeModel() \\</span>
<span class="sd">            .setInputCols([&quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;keywords&quot;) \\</span>
<span class="sd">            .setThreshold(0.6) \\</span>
<span class="sd">            .setMinNGrams(2) \\</span>
<span class="sd">            .setNKeywords(10)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentenceDetector,</span>
<span class="sd">            token,</span>
<span class="sd">            keywords</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud Next conference in San Francisco this week, the official announcement could come as early as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. Google itself declined &#39;to comment on rumors&#39;. Kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom  and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). Kaggle has a bit of a history with Google, too, but that&#39;s pretty recent. Earlier this month, Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle&#39;s community than technology, Kaggle did build some interesting tools for hosting its competition and &#39;kernels&#39;, too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them &#39;scripts&#39;). Like similar competition-centric sites, Kaggle also runs a job board, too. It&#39;s unclear what Google will do with that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it&#39;s $12.75) since its   launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, NaRavikant, Google chie economist Hal Varian, Khosla Ventures and Yuri Milner&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        # combine the result and score (contained in keywords.metadata)</span>
<span class="sd">        scores = result \\</span>
<span class="sd">            .selectExpr(&quot;explode(arrays_zip(keywords.result, keywords.metadata)) as resultTuples&quot;) \\</span>
<span class="sd">            .select($&quot;resultTuples.0&quot; as &quot;keyword&quot;, $&quot;resultTuples.1.score&quot;)</span>

<span class="sd">        # Order ascending, as lower scores means higher importance</span>
<span class="sd">        scores.orderBy(&quot;score&quot;).show(5, truncate = False)</span>
<span class="sd">        +---------------------+-------------------+</span>
<span class="sd">        |keyword              |score              |</span>
<span class="sd">        +---------------------+-------------------+</span>
<span class="sd">        |google cloud         |0.32051516486864573|</span>
<span class="sd">        |google cloud platform|0.37786450577630676|</span>
<span class="sd">        |ceo anthony goldbloom|0.39922830978423146|</span>
<span class="sd">        |san francisco        |0.40224744669493756|</span>
<span class="sd">        |anthony goldbloom    |0.41584827825302534|</span>
<span class="sd">        +---------------------+-------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;YakeModel&quot;</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">YakeModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.keyword.yake.YakeModel&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">minNGrams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">maxNGrams</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">nKeywords</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
            <span class="n">windowSize</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">stopWords</span><span class="o">=</span><span class="n">YakeModel</span><span class="o">.</span><span class="n">loadDefaultStopWords</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">minNGrams</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minNGrams&quot;</span><span class="p">,</span> <span class="s2">&quot;Minimum N-grams a keyword should have&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">maxNGrams</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxNGrams&quot;</span><span class="p">,</span> <span class="s2">&quot;Maximum N-grams a keyword should have&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">threshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;threshold&quot;</span><span class="p">,</span> <span class="s2">&quot;Keyword Score threshold&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">windowSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;windowSize&quot;</span><span class="p">,</span> <span class="s2">&quot;Window size for Co-Occurrence&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">nKeywords</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;nKeywords&quot;</span><span class="p">,</span> <span class="s2">&quot;Number of Keywords to extract&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">stopWords</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;stopWords&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;the words to be filtered out. by default it&#39;s english stop words from Spark ML&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setWindowSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">windowSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinNGrams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minNGrams</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxNGrams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxNGrams</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setNKeywords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">nKeywords</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">stopWords</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getStopWords</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stopWords</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">loadDefaultStopWords</span><span class="p">(</span><span class="n">language</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">pyspark.ml.wrapper</span> <span class="kn">import</span> <span class="n">_jvm</span>

        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads the default stop words for the given language.</span>
<span class="sd">        Supported languages: danish, dutch, english, finnish, french, german, hungarian,</span>
<span class="sd">        italian, norwegian, portuguese, russian, spanish, swedish, turkish</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stopWordsObj</span> <span class="o">=</span> <span class="n">_jvm</span><span class="p">()</span><span class="o">.</span><span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">ml</span><span class="o">.</span><span class="n">feature</span><span class="o">.</span><span class="n">StopWordsRemover</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">stopWordsObj</span><span class="o">.</span><span class="n">loadDefaultStopWords</span><span class="p">(</span><span class="n">language</span><span class="p">))</span></div>


<div class="viewcode-block" id="SentenceDetectorDLModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentenceDetectorDLModel.html#sparknlp.annotator.SentenceDetectorDLModel">[docs]</a><span class="k">class</span> <span class="nc">SentenceDetectorDLModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Annotator that detects sentence boundaries using a deep learning approach.</span>

<span class="sd">    Instantiated Model of the SentenceDetectorDLApproach.</span>
<span class="sd">    Detects sentence boundaries using a deep learning approach.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        sentenceDL = SentenceDetectorDLModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentencesDL&quot;)</span>


<span class="sd">    The default model is ``&quot;sentence_detector_dl&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Sentence+Detection&gt;`__.</span>

<span class="sd">    Each extracted sentence can be returned in an Array or exploded to separate rows,</span>
<span class="sd">    if ``explodeSentences`` is set to ``true``.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DOCUMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    modelArchitecture</span>
<span class="sd">        Model architecture (CNN)</span>
<span class="sd">    explodeSentences</span>
<span class="sd">        whether to explode each sentence into a different row, for better parallelization. Defaults to false.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, the normal `SentenceDetector` is compared to the `SentenceDetectorDLModel`. In a pipeline,</span>
<span class="sd">        # `SentenceDetectorDLModel` can be used as a replacement for the `SentenceDetector`.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetector() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentences&quot;)</span>

<span class="sd">        sentenceDL = SentenceDetectorDLModel \\</span>
<span class="sd">            .pretrained(&quot;sentence_detector_dl&quot;, &quot;en&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentencesDL&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            sentence,</span>
<span class="sd">            sentenceDL</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[\&quot;\&quot;\&quot;John loves Mary.Mary loves Peter</span>
<span class="sd">            Peter loves Helen .Helen loves John;</span>
<span class="sd">            Total: four people involved.\&quot;\&quot;\&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(sentences.result) as sentences&quot;).show(truncate=False)</span>
<span class="sd">        +----------------------------------------------------------+</span>
<span class="sd">        |sentences                                                 |</span>
<span class="sd">        +----------------------------------------------------------+</span>
<span class="sd">        |John loves Mary.Mary loves Peter\n     Peter loves Helen .|</span>
<span class="sd">        |Helen loves John;                                         |</span>
<span class="sd">        |Total: four people involved.                              |</span>
<span class="sd">        +----------------------------------------------------------+</span>

<span class="sd">        result.selectExpr(&quot;explode(sentencesDL.result) as sentencesDL&quot;).show(truncate=False)</span>
<span class="sd">        +----------------------------+</span>
<span class="sd">        |sentencesDL                 |</span>
<span class="sd">        +----------------------------+</span>
<span class="sd">        |John loves Mary.            |</span>
<span class="sd">        |Mary loves Peter            |</span>
<span class="sd">        |Peter loves Helen .         |</span>
<span class="sd">        |Helen loves John;           |</span>
<span class="sd">        |Total: four people involved.|</span>
<span class="sd">        +----------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;SentenceDetectorDLModel&quot;</span>

    <span class="n">modelArchitecture</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;modelArchitecture&quot;</span><span class="p">,</span> <span class="s2">&quot;Model architecture (CNN)&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">explodeSentences</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;explodeSentences&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to explode each sentence into a different row, for better parallelization. Defaults to false.&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modelArchitecture</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">modelArchitecture</span><span class="o">=</span><span class="n">modelArchitecture</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExplodeSentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">explodeSentences</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sentence_detector_dl.SentenceDetectorDLModel&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentenceDetectorDLModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;sentence_detector_dl&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">SentenceDetectorDLModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="SentenceDetectorDLApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.SentenceDetectorDLApproach.html#sparknlp.annotator.SentenceDetectorDLApproach">[docs]</a><span class="k">class</span> <span class="nc">SentenceDetectorDLApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains an annotator that detects sentence boundaries using a deep learning approach.</span>

<span class="sd">    For pretrained models see SentenceDetectorDLModel.</span>

<span class="sd">    Currently, only the CNN model is supported for training, but in the future the architecture of the model can</span>
<span class="sd">    be set with ``setModelArchitecture``.</span>

<span class="sd">    The default model ``&quot;cnn&quot;`` is based on the paper</span>
<span class="sd">    `Deep-EOS: General-Purpose Neural Networks for Sentence Boundary Detection (2020, Stefan Schweter, Sajawel Ahmed) &lt;https://konvens.org/proceedings/2019/papers/KONVENS2019_paper_41.pdf&gt;`__</span>
<span class="sd">    using a CNN architecture. We also modified the original implementation a little bit to cover broken sentences and some impossible end of line chars.</span>

<span class="sd">    Each extracted sentence can be returned in an Array or exploded to separate rows,</span>
<span class="sd">    if ``explodeSentences`` is set to ``true``.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DOCUMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    modelArchitecture</span>
<span class="sd">        Model architecture (CNN)</span>
<span class="sd">    impossiblePenultimates</span>
<span class="sd">        Impossible penultimates - list of strings which a sentence can&#39;t end with</span>
<span class="sd">    validationSplit</span>
<span class="sd">        Choose the proportion of training dataset to be validated against the model on each</span>
<span class="sd">    epochsNumber</span>
<span class="sd">        Number of epochs for the optimization process</span>
<span class="sd">    outputLogsPath</span>
<span class="sd">        Path to folder where logs will be saved. If no path is specified, no logs are generated</span>
<span class="sd">    explodeSentences</span>
<span class="sd">        whether to explode each sentence into a different row, for better parallelization. Defaults to false.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # The training process needs data, where each data point is a sentence.</span>
<span class="sd">        # In this example the `train.txt` file has the form of</span>
<span class="sd">        #</span>
<span class="sd">        # ...</span>
<span class="sd">        # Slightly more moderate language would make our present situation  namely the lack of progress  a little easier.</span>
<span class="sd">        # His political successors now have great responsibilities to history and to the heritage of values bequeathed to them by Nelson Mandela.</span>
<span class="sd">        # ...</span>
<span class="sd">        #</span>
<span class="sd">        # where each line is one sentence.</span>
<span class="sd">        # Training can then be started like so:</span>

<span class="sd">        trainingData = spark.read.text(&quot;train.txt&quot;).toDF(&quot;text&quot;)</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentenceDetector = SentenceDetectorDLApproach() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentences&quot;) \\</span>
<span class="sd">            .setEpochsNumber(100)</span>

<span class="sd">        pipeline = Pipeline().setStages([documentAssembler, sentenceDetector])</span>

<span class="sd">        model = pipeline.fit(trainingData)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;SentenceDetectorDLApproach&quot;</span>

    <span class="n">modelArchitecture</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;modelArchitecture&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Model architecture (CNN)&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">impossiblePenultimates</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                   <span class="s2">&quot;impossiblePenultimates&quot;</span><span class="p">,</span>
                                   <span class="s2">&quot;Impossible penultimates - list of strings which a sentence can&#39;t end with&quot;</span><span class="p">,</span>
                                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">validationSplit</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;validationSplit&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Choose the proportion of training dataset to be validated against the model on each &quot;</span>
                            <span class="s2">&quot;Epoch. The value should be between 0.0 and 1.0 and by default it is 0.0 and off.&quot;</span><span class="p">,</span>
                            <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="n">epochsNumber</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;epochsNumber&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;Number of epochs for the optimization process&quot;</span><span class="p">,</span>
                         <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">outputLogsPath</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                           <span class="s2">&quot;outputLogsPath&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Path to folder where logs will be saved. If no path is specified, no logs are generated&quot;</span><span class="p">,</span>
                           <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">explodeSentences</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;explodeSentences&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;whether to explode each sentence into a different row, for better parallelization. Defaults to false.&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_architecture</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">modelArchitecture</span><span class="o">=</span><span class="n">model_architecture</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setValidationSplit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation_split</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">validationSplit</span><span class="o">=</span><span class="n">validation_split</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEpochsNumber</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs_number</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">epochsNumber</span><span class="o">=</span><span class="n">epochs_number</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setOutputLogsPath</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_logs_path</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">outputLogsPath</span><span class="o">=</span><span class="n">output_logs_path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setImpossiblePenultimates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">impossible_penultimates</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">impossiblePenultimates</span><span class="o">=</span><span class="n">impossible_penultimates</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExplodeSentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">explodeSentences</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">SentenceDetectorDLModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.sentence_detector_dl.SentenceDetectorDLApproach&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SentenceDetectorDLApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">)</span></div>


<div class="viewcode-block" id="WordSegmenterApproach"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.WordSegmenterApproach.html#sparknlp.annotator.WordSegmenterApproach">[docs]</a><span class="k">class</span> <span class="nc">WordSegmenterApproach</span><span class="p">(</span><span class="n">AnnotatorApproach</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Trains a WordSegmenter which tokenizes non-english or non-whitespace separated texts.</span>

<span class="sd">    Many languages are not whitespace separated and their sentences are a concatenation of many symbols, like Korean,</span>
<span class="sd">    Japanese or Chinese. Without understanding the language, splitting the words into their corresponding tokens is</span>
<span class="sd">    impossible. The WordSegmenter is trained to understand these languages and split them into semantically correct parts.</span>

<span class="sd">    For instantiated/pretrained models, see WordSegmenterModel.</span>

<span class="sd">    To train your own model, a training dataset consisting of</span>
<span class="sd">    `Part-Of-Speech tags &lt;https://en.wikipedia.org/wiki/Part-of-speech_tagging&gt;`__ is required. The data has to be loaded</span>
<span class="sd">    into a dataframe, where the column is an Annotation of type ``&quot;POS&quot;``. This can be</span>
<span class="sd">    set with ``setPosColumn``.</span>

<span class="sd">    **Tip**: The helper class POS might be useful to read training data into data frames.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/annotation/chinese/word_segmentation&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    posCol</span>
<span class="sd">        column of Array of POS tags that match tokens</span>
<span class="sd">    nIterations</span>
<span class="sd">        Number of iterations in training, converges to better accuracy, by default 5</span>
<span class="sd">    frequencyThreshold</span>
<span class="sd">        How many times at least a tag on a word to be marked as frequent, by default 5</span>
<span class="sd">    ambiguityThreshold</span>
<span class="sd">        How much percentage of total amount of words are covered to be marked as frequent, by default 0.97</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>
<span class="sd">        # In this example, `&quot;chinese_train.utf8&quot;` is in the form of</span>
<span class="sd">        #</span>
<span class="sd">        # |LL |RR |LL |RR |LL |RR</span>
<span class="sd">        #</span>
<span class="sd">        # and is loaded with the `POS` class to create a dataframe of `&quot;POS&quot;` type Annotations.</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        wordSegmenter = WordSegmenterApproach() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;) \\</span>
<span class="sd">            .setPosColumn(&quot;tags&quot;) \\</span>
<span class="sd">            .setNIterations(5)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            wordSegmenter</span>
<span class="sd">        ])</span>

<span class="sd">        trainingDataSet = POS().readDataset(</span>
<span class="sd">            spark,</span>
<span class="sd">            &quot;src/test/resources/word-segmenter/chinese_train.utf8&quot;</span>
<span class="sd">        )</span>

<span class="sd">        pipelineModel = pipeline.fit(trainingDataSet)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;WordSegmenterApproach&quot;</span>

    <span class="n">posCol</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                   <span class="s2">&quot;posCol&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;column of Array of POS tags that match tokens&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">nIterations</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;nIterations&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Number of iterations in training, converges to better accuracy&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">frequencyThreshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;frequencyThreshold&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;How many times at least a tag on a word to be marked as frequent&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">ambiguityThreshold</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                               <span class="s2">&quot;ambiguityThreshold&quot;</span><span class="p">,</span>
                               <span class="s2">&quot;How much percentage of total amount of words are covered to be marked as frequent&quot;</span><span class="p">,</span>
                               <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WordSegmenterApproach</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ws.WordSegmenterApproach&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">nIterations</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">frequencyThreshold</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ambiguityThreshold</span><span class="o">=</span><span class="mf">0.97</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPosColumn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">posCol</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setNIterations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">nIterations</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setFrequencyThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">frequencyThreshold</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setAmbiguityThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">ambiguityThreshold</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getNIterations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nIterations</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getFrequencyThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frequencyThreshold</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">getAmbiguityThreshold</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getOrDefault</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ambiguityThreshold</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_create_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">java_model</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">WordSegmenterModel</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span><span class="p">)</span></div>


<div class="viewcode-block" id="WordSegmenterModel"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.WordSegmenterModel.html#sparknlp.annotator.WordSegmenterModel">[docs]</a><span class="k">class</span> <span class="nc">WordSegmenterModel</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;WordSegmenter which tokenizes non-english or non-whitespace separated texts.</span>

<span class="sd">    Many languages are not whitespace separated and their sentences are a concatenation of many symbols, like Korean,</span>
<span class="sd">    Japanese or Chinese. Without understanding the language, splitting the words into their corresponding tokens is</span>
<span class="sd">    impossible. The WordSegmenter is trained to understand these languages and plit them into semantically correct parts.</span>

<span class="sd">    This is the instantiated model of the WordSegmenterApproach.</span>
<span class="sd">    For training your own model, please see the documentation of that class.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        wordSegmenter = WordSegmenterModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;words_segmented&quot;)</span>


<span class="sd">    The default model is ``&quot;wordseg_pku&quot;``, default language is ``&quot;zh&quot;``, if no values are provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Word+Segmentation&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/chinese/word_segmentation/words_segmenter_demo.ipynb&gt;`__.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``TOKEN``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>



<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        wordSegmenter = WordSegmenterModel.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([</span>
<span class="sd">            documentAssembler,</span>
<span class="sd">            wordSegmenter</span>
<span class="sd">        ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;token.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------------+</span>
<span class="sd">        |result                                                  |</span>
<span class="sd">        +--------------------------------------------------------+</span>
<span class="sd">        |[, , , , , , , , , ,     ]|</span>
<span class="sd">        +--------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;WordSegmenterModel&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.ws.WordSegmenterModel&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">WordSegmenterModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;wordseg_pku&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;zh&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">WordSegmenterModel</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="T5Transformer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.T5Transformer.html#sparknlp.annotator.T5Transformer">[docs]</a><span class="k">class</span> <span class="nc">T5Transformer</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;T5: the Text-To-Text Transfer Transformer</span>

<span class="sd">    T5 reconsiders all NLP tasks into a unified text-to-text-format where the input and output are always</span>
<span class="sd">    text strings, in contrast to BERT-style models that can only output either a class label or a span of the input.</span>
<span class="sd">    The text-to-text framework is able to use the same model, loss function, and hyper-parameters on any NLP task,</span>
<span class="sd">    including machine translation, document summarization, question answering, and classification tasks</span>
<span class="sd">    (e.g., sentiment analysis). T5 can even apply to regression tasks by training it to predict the string</span>
<span class="sd">    representation of a number instead of the number itself.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        t5 = T5Transformer.pretrained() \\</span>
<span class="sd">            .setTask(&quot;summarize:&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;summaries&quot;)</span>


<span class="sd">    The default model is ``&quot;t5_small&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?q=t5&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/10.T5_Workshop_with_Spark_NLP.ipynb&gt;`__.</span>

<span class="sd">    **Sources:**</span>
<span class="sd">     - `Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer &lt;https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html&gt;`__</span>
<span class="sd">     - `Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer &lt;https://arxiv.org/abs/1910.10683&gt;`__</span>
<span class="sd">     - https://github.com/google-research/text-to-text-transfer-transformer</span>

<span class="sd">    **Paper Abstract:**</span>

<span class="sd">    *Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream</span>
<span class="sd">    task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer</span>
<span class="sd">    learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the</span>
<span class="sd">    landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based</span>
<span class="sd">    language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures,</span>
<span class="sd">    unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining</span>
<span class="sd">    the insights from our exploration with scale and our new Colossal Clean Crawled Corpus, we achieve state-of-the-art</span>
<span class="sd">    results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate</span>
<span class="sd">    future work on transfer learning for NLP, we release our data set, pre-trained models, and code.*</span>

<span class="sd">    **Note:**</span>

<span class="sd">    This is a very computationally expensive module especially on larger sequence.</span>
<span class="sd">    The use of an accelerator such as GPU is recommended.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DOCUMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    task</span>
<span class="sd">        Transformer&#39;s task, e.g. summarize&gt;</span>
<span class="sd">    minOutputLength</span>
<span class="sd">        Minimum length of the sequence to be generated</span>
<span class="sd">    maxOutputLength</span>
<span class="sd">        Maximum length of output text</span>
<span class="sd">    doSample</span>
<span class="sd">        Whether or not to use sampling; use greedy decoding otherwise</span>
<span class="sd">    temperature</span>
<span class="sd">        The value used to module the next token probabilities</span>
<span class="sd">    topK</span>
<span class="sd">        The number of highest probability vocabulary tokens to keep for top-k-filtering</span>
<span class="sd">    topP</span>
<span class="sd">        If set to float &lt; 1, only the most probable tokens with probabilities that add up to ``top_p`` or higher are kept for generation</span>
<span class="sd">    repetitionPenalty</span>
<span class="sd">        The parameter for repetition penalty. 1.0 means no penalty. See `this paper &lt;https://arxiv.org/pdf/1909.05858.pdf&gt;`__ for more details</span>
<span class="sd">    noRepeatNgramSize</span>
<span class="sd">        If set to int &gt; 0, all ngrams of that size can only occur once</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;documents&quot;)</span>

<span class="sd">        t5 = T5Transformer.pretrained(&quot;t5_small&quot;) \\</span>
<span class="sd">            .setTask(&quot;summarize:&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;documents&quot;]) \\</span>
<span class="sd">            .setMaxOutputLength(200) \\</span>
<span class="sd">            .setOutputCol(&quot;summaries&quot;)</span>

<span class="sd">        pipeline = Pipeline().setStages([documentAssembler, t5])</span>

<span class="sd">        data = spark.createDataFrame([[</span>
<span class="sd">            &quot;Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a &quot; +</span>
<span class="sd">              &quot;downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness&quot; +</span>
<span class="sd">              &quot; of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this &quot; +</span>
<span class="sd">              &quot;paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework &quot; +</span>
<span class="sd">              &quot;that converts all text-based language problems into a text-to-text format. Our systematic study compares &quot; +</span>
<span class="sd">              &quot;pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens &quot; +</span>
<span class="sd">              &quot;of language understanding tasks. By combining the insights from our exploration with scale and our new &quot; +</span>
<span class="sd">              &quot;Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering &quot; +</span>
<span class="sd">              &quot;summarization, question answering, text classification, and more. To facilitate future work on transfer &quot; +</span>
<span class="sd">              &quot;learning for NLP, we release our data set, pre-trained models, and code.&quot;</span>
<span class="sd">        ]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.select(&quot;summaries.result&quot;).show(truncate=False)</span>
<span class="sd">        +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        |result                                                                                                                                                                                                        |</span>
<span class="sd">        +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="sd">        |[transfer learning has emerged as a powerful technique in natural language processing (NLP) the effectiveness of transfer learning has given rise to a diversity of approaches, methodologies, and practice .]|</span>
<span class="sd">        +--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;T5Transformer&quot;</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">task</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;task&quot;</span><span class="p">,</span> <span class="s2">&quot;Transformer&#39;s task, e.g. summarize&gt;&quot;</span><span class="p">,</span> <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">minOutputLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;minOutputLength&quot;</span><span class="p">,</span> <span class="s2">&quot;Minimum length of the sequence to be generated&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">maxOutputLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxOutputLength&quot;</span><span class="p">,</span> <span class="s2">&quot;Maximum length of output text&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">doSample</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;doSample&quot;</span><span class="p">,</span> <span class="s2">&quot;Whether or not to use sampling; use greedy decoding otherwise&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>
    <span class="n">temperature</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="s2">&quot;The value used to module the next token probabilities&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">topK</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;topK&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;The number of highest probability vocabulary tokens to keep for top-k-filtering&quot;</span><span class="p">,</span>
                 <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>
    <span class="n">topP</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;topP&quot;</span><span class="p">,</span>
                 <span class="s2">&quot;If set to float &lt; 1, only the most probable tokens with probabilities that add up to ``top_p`` or higher are kept for generation&quot;</span><span class="p">,</span>
                 <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">repetitionPenalty</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;repetitionPenalty&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;The parameter for repetition penalty. 1.0 means no penalty. See `this paper &lt;https://arxiv.org/pdf/1909.05858.pdf&gt;`__ for more details&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toFloat</span><span class="p">)</span>
    <span class="n">noRepeatNgramSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;noRepeatNgramSize&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;If set to int &gt; 0, all ngrams of that size can only occur once&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinOutputLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minOutputLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxOutputLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxOutputLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDoSample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">doSample</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTemperature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTopK</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">topK</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTopP</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">topP</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRepetitionPenalty</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">repetitionPenalty</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setNoRepeatNgramSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">noRepeatNgramSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">T5Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_T5Loader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_T5Loader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">T5Transformer</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;t5_small&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">T5Transformer</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="MarianTransformer"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.MarianTransformer.html#sparknlp.annotator.MarianTransformer">[docs]</a><span class="k">class</span> <span class="nc">MarianTransformer</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span> <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;MarianTransformer: Fast Neural Machine Translation</span>

<span class="sd">    Marian is an efficient, free Neural Machine Translation framework written in pure C++ with minimal dependencies.</span>
<span class="sd">    It is mainly being developed by the Microsoft Translator team. Many academic (most notably the University of</span>
<span class="sd">    Edinburgh and in the past the Adam Mickiewicz University in Pozna) and commercial contributors help with its</span>
<span class="sd">    development. MarianTransformer uses the models trained by MarianNMT.</span>

<span class="sd">    It is currently the engine behind the Microsoft Translator Neural Machine Translation services and being deployed by</span>
<span class="sd">    many companies, organizations and research projects.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        marian = MarianTransformer.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;translation&quot;)</span>


<span class="sd">    The default model is ``&quot;opus_mt_en_fr&quot;``, default language is ``&quot;xx&quot;`` (meaning multi-lingual), if no values are provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Translation&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/TRANSLATION_MARIAN.ipynb&gt;`__.</span>

<span class="sd">    **Sources** :</span>

<span class="sd">    `MarianNMT at GitHub &lt;https://marian-nmt.github.io/&gt;`__</span>

<span class="sd">    `Marian: Fast Neural Machine Translation in C++  &lt;https://www.aclweb.org/anthology/P18-4020/&gt;`__</span>

<span class="sd">    **Paper Abstract:**</span>

<span class="sd">    *We present Marian, an efficient and self-contained Neural Machine Translation framework with an integrated</span>
<span class="sd">    automatic differentiation engine based on dynamic computation graphs. Marian is written entirely in C++. We describe</span>
<span class="sd">    the design of the encoder-decoder framework and demonstrate that a research-friendly toolkit can achieve high</span>
<span class="sd">    training and translation speed.*</span>

<span class="sd">    **Note:**</span>

<span class="sd">    This is a very computationally expensive module especially on larger sequence.</span>
<span class="sd">    The use of an accelerator such as GPU is recommended.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT``           ``DOCUMENT``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>
<span class="sd">    langId</span>
<span class="sd">        Transformer&#39;s task, e.g. summarize&gt;, by default &quot;&quot;</span>
<span class="sd">    maxInputLength</span>
<span class="sd">        Controls the maximum length for encoder inputs (source language texts), by default 40</span>
<span class="sd">    maxOutputLength</span>
<span class="sd">        Controls the maximum length for decoder outputs (target language texts), by default 40</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        sentence = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl&quot;, &quot;xx&quot;) \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;sentence&quot;)</span>

<span class="sd">        marian = MarianTransformer.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;sentence&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;translation&quot;) \\</span>
<span class="sd">            .setMaxInputLength(30)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              sentence,</span>
<span class="sd">              marian</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;What is the capital of France? We should know this in french.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(translation.result) as result&quot;).show(truncate=False)</span>
<span class="sd">        +-------------------------------------+</span>
<span class="sd">        |result                               |</span>
<span class="sd">        +-------------------------------------+</span>
<span class="sd">        |Quelle est la capitale de la France ?|</span>
<span class="sd">        |On devrait le savoir en franais.    |</span>
<span class="sd">        +-------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;MarianTransformer&quot;</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">langId</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;langId&quot;</span><span class="p">,</span> <span class="s2">&quot;Transformer&#39;s task, e.g. summarize&gt;&quot;</span><span class="p">,</span>
                   <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">maxInputLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxInputLength&quot;</span><span class="p">,</span>
                           <span class="s2">&quot;Controls the maximum length for encoder inputs (source language texts)&quot;</span><span class="p">,</span>
                           <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">maxOutputLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span> <span class="s2">&quot;maxOutputLength&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Controls the maximum length for decoder outputs (target language texts)&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setLangId</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">langId</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxInputLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxInputLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxOutputLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxOutputLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MarianTransformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxInputLength</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
            <span class="n">maxOutputLength</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
            <span class="n">langId</span><span class="o">=</span><span class="s2">&quot;&quot;</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_MarianLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_MarianLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">MarianTransformer</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;opus_mt_en_fr&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;xx&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">MarianTransformer</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistilBertEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DistilBertEmbeddings.html#sparknlp.annotator.DistilBertEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">DistilBertEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                           <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                           <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                           <span class="n">HasStorageRef</span><span class="p">,</span>
                           <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than</span>
<span class="sd">    ``bert-base-uncased``, runs 60% faster while preserving over 95% of BERT&#39;s performances as measured on the GLUE language understanding benchmark.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = DistilBertEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;distilbert_base_cased&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBERT.ipynb&gt;`__.</span>
<span class="sd">    Models from the HuggingFace  Transformers library are also compatible with Spark NLP . The Spark NLP Workshop</span>
<span class="sd">    example shows how to import them https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</span>

<span class="sd">    The DistilBERT model was proposed in the paper</span>
<span class="sd">    `DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter &lt;https://arxiv.org/abs/1910.01108&gt;`__.</span>

<span class="sd">    **Paper Abstract:**</span>

<span class="sd">    *As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP),</span>
<span class="sd">    operating these large models in on-the-edge and/or under constrained computational training or inference budgets</span>
<span class="sd">    remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation</span>
<span class="sd">    model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger</span>
<span class="sd">    counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage</span>
<span class="sd">    knowledge distillation during the pretraining phase and show that it is possible to reduce the size of a BERT model by</span>
<span class="sd">    40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive</span>
<span class="sd">    biases learned by larger models during pretraining, we introduce a triple loss combining language modeling,</span>
<span class="sd">    distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we</span>
<span class="sd">    demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device</span>
<span class="sd">    study.*</span>

<span class="sd">    Tips:</span>
<span class="sd">      - DistilBERT doesn&#39;t have ``:obj:token_type_ids``, you don&#39;t need to indicate which token belongs to which segment. Just</span>
<span class="sd">        separate your segments with the separation token ``:obj:tokenizer.sep_token`` (or ``:obj:[SEP]``).</span>
<span class="sd">      - DistilBERT doesn&#39;t have options to select the input positions (``:obj:position_ids`` input). This could be added if</span>
<span class="sd">        necessary though, just let us know if you need this option.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default False</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = DistilBertEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;) \\</span>
<span class="sd">            .setCaseSensitive(True)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[0.1127224713563919,-0.1982710212469101,0.5360898375511169,-0.272536993026733...|</span>
<span class="sd">        |[0.35534414649009705,0.13215228915214539,0.40981462597846985,0.14036104083061...|</span>
<span class="sd">        |[0.328085333108902,-0.06269335001707077,-0.017595693469047546,-0.024373905733...|</span>
<span class="sd">        |[0.15617232024669647,0.2967822253704071,0.22324979305267334,-0.04568954557180...|</span>
<span class="sd">        |[0.45411425828933716,0.01173491682857275,0.190129816532135,0.1178255230188369...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;DistilBertEmbeddings&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.DistilBertEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistilBertEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_DistilBertLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_DistilBertLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">DistilBertEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;distilbert_base_cased&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">DistilBertEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="RoBertaEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.RoBertaEmbeddings.html#sparknlp.annotator.RoBertaEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">RoBertaEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                        <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                        <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                        <span class="n">HasStorageRef</span><span class="p">,</span>
                        <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The RoBERTa model was proposed in `RoBERTa: A Robustly Optimized BERT Pretraining Approach &lt;https://arxiv.org/abs/1907.11692&gt;`__</span>
<span class="sd">    by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.</span>
<span class="sd">    It is based on Google&#39;s BERT model released in 2018.</span>

<span class="sd">    It builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = RoBertaEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;roberta_base&quot;``, if no name is provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBERTa.ipynb&gt;`__.</span>
<span class="sd">    Models from the HuggingFace  Transformers library are also compatible with Spark NLP . The Spark NLP Workshop</span>
<span class="sd">    example shows how to import them https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</span>

<span class="sd">    **Paper Abstract:**</span>

<span class="sd">    *Language model pretraining has led to significant performance gains but careful comparison between different</span>
<span class="sd">    approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes,</span>
<span class="sd">    and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication</span>
<span class="sd">    study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and</span>
<span class="sd">    training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every</span>
<span class="sd">    model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results</span>
<span class="sd">    highlight the importance of previously overlooked design choices, and raise questions about the source of recently</span>
<span class="sd">    reported improvements. We release our models and code.*</span>

<span class="sd">    Tips:</span>
<span class="sd">      - RoBERTa has the same architecture as BERT, but uses a byte-level BPE as a tokenizer (same as GPT-2) and uses a different pretraining scheme.</span>
<span class="sd">      - RoBERTa doesn&#39;t have :obj:``token_type_ids``, you don&#39;t need to indicate which token belongs to which segment. Just separate your segments with the separation token :obj:``tokenizer.sep_token`` (or :obj:``&lt;/s&gt;``)</span>

<span class="sd">    The original code can be found `````here````` https://github.com/pytorch/fairseq/tree/master/examples/roberta.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default True</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = RoBertaEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;) \\</span>
<span class="sd">            .setCaseSensitive(True)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[0.18792399764060974,-0.14591649174690247,0.20547787845134735,0.1468472778797...|</span>
<span class="sd">        |[0.22845706343650818,0.18073144555091858,0.09725798666477203,-0.0417917296290...|</span>
<span class="sd">        |[0.07037967443466187,-0.14801117777824402,-0.03603338822722435,-0.17893412709...|</span>
<span class="sd">        |[-0.08734266459941864,0.2486150562763214,-0.009067727252840996,-0.24408400058...|</span>
<span class="sd">        |[0.22409197688102722,-0.4312366545200348,0.1401449590921402,0.356410235166549...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;RoBertaEmbeddings&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RoBertaEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_RoBertaLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_RoBertaLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">RoBertaEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;roberta_base&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">RoBertaEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="XlmRoBertaEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.XlmRoBertaEmbeddings.html#sparknlp.annotator.XlmRoBertaEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">XlmRoBertaEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                           <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                           <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                           <span class="n">HasStorageRef</span><span class="p">,</span>
                           <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The XLM-RoBERTa model was proposed in `Unsupervised Cross-lingual Representation Learning at Scale &lt;https://arxiv.org/abs/1911.02116&gt;`__</span>
<span class="sd">    by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume</span>
<span class="sd">    Wenzek, Francisco Guzmn, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov. It is based on Facebook&#39;s</span>
<span class="sd">    RoBERTa model released in 2019. It is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl</span>
<span class="sd">    data.</span>

<span class="sd">    Pretrained models can be loaded with ``pretrained`` of the companion object:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        embeddings = XlmRoBertaEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;)</span>


<span class="sd">    The default model is ``&quot;xlm_roberta_base&quot;``, default language is ``&quot;xx&quot;`` (meaning multi-lingual), if no values are provided.</span>
<span class="sd">    For available pretrained models please see the `Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;`__.</span>

<span class="sd">    For extended examples of usage, see the `Spark NLP Workshop &lt;https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLM-RoBERTa.ipynb&gt;`__.</span>
<span class="sd">    Models from the HuggingFace  Transformers library are also compatible with Spark NLP . The Spark NLP Workshop</span>
<span class="sd">    example shows how to import them https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</span>

<span class="sd">    **Paper Abstract:**</span>

<span class="sd">    *This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a</span>
<span class="sd">    wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred</span>
<span class="sd">    languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly</span>
<span class="sd">    outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +13.8% average accuracy on</span>
<span class="sd">    XNLI, +12.3% average F1 score on MLQA, and +2.1% average F1 score on NER. XLM-R performs particularly well on</span>
<span class="sd">    low-resource languages, improving 11.8% in XNLI accuracy for Swahili and 9.2% for Urdu over the previous XLM model. We</span>
<span class="sd">    also present a detailed empirical evaluation of the key factors that are required to achieve these gains, including the</span>
<span class="sd">    trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource</span>
<span class="sd">    languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing</span>
<span class="sd">    per-language performance; XLM-Ris very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We</span>
<span class="sd">    will make XLM-R code, data, and models publicly available.*</span>

<span class="sd">    **Tips:**</span>
<span class="sd">      - XLM-RoBERTa is a multilingual model trained on 100 different languages. Unlike some XLM multilingual models, it does</span>
<span class="sd">        not require **lang** parameter to understand which language is used, and should be able to determine the correct</span>
<span class="sd">        language from the input ids.</span>
<span class="sd">      - This implementation is the same as RoBERTa. Refer to the RoBertaEmbeddings for usage examples</span>
<span class="sd">        as well as the information relative to the inputs and outputs.</span>

<span class="sd">    ====================== ======================</span>
<span class="sd">    Input Annotation types Output Annotation type</span>
<span class="sd">    ====================== ======================</span>
<span class="sd">    ``DOCUMENT, TOKEN``    ``WORD_EMBEDDINGS``</span>
<span class="sd">    ====================== ======================</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    batchSize</span>
<span class="sd">        Size of every batch, by default 8</span>
<span class="sd">    dimension</span>
<span class="sd">        Number of embedding dimensions, by default 768</span>
<span class="sd">    caseSensitive</span>
<span class="sd">        Whether to ignore case in tokens for embeddings matching, by default True</span>
<span class="sd">    maxSentenceLength</span>
<span class="sd">        Max sentence length to process, by default 128</span>
<span class="sd">    configProtoBytes</span>
<span class="sd">        ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import sparknlp</span>
<span class="sd">        from sparknlp.base import *</span>
<span class="sd">        from sparknlp.common import *</span>
<span class="sd">        from sparknlp.annotator import *</span>
<span class="sd">        from sparknlp.training import *</span>
<span class="sd">        from pyspark.ml import Pipeline</span>

<span class="sd">        documentAssembler = DocumentAssembler() \\</span>
<span class="sd">            .setInputCol(&quot;text&quot;) \\</span>
<span class="sd">            .setOutputCol(&quot;document&quot;)</span>

<span class="sd">        tokenizer = Tokenizer() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;token&quot;)</span>

<span class="sd">        embeddings = XlmRoBertaEmbeddings.pretrained() \\</span>
<span class="sd">            .setInputCols([&quot;document&quot;, &quot;token&quot;]) \\</span>
<span class="sd">            .setOutputCol(&quot;embeddings&quot;) \\</span>
<span class="sd">            .setCaseSensitive(True)</span>

<span class="sd">        embeddingsFinisher = EmbeddingsFinisher() \\</span>
<span class="sd">            .setInputCols([&quot;embeddings&quot;]) \\</span>
<span class="sd">            .setOutputCols(&quot;finished_embeddings&quot;) \\</span>
<span class="sd">            .setOutputAsVector(True) \\</span>
<span class="sd">            .setCleanAnnotations(False)</span>

<span class="sd">        pipeline = Pipeline() \\</span>
<span class="sd">            .setStages([</span>
<span class="sd">              documentAssembler,</span>
<span class="sd">              tokenizer,</span>
<span class="sd">              embeddings,</span>
<span class="sd">              embeddingsFinisher</span>
<span class="sd">            ])</span>

<span class="sd">        data = spark.createDataFrame([[&quot;This is a sentence.&quot;]]).toDF(&quot;text&quot;)</span>
<span class="sd">        result = pipeline.fit(data).transform(data)</span>

<span class="sd">        result.selectExpr(&quot;explode(finished_embeddings) as result&quot;).show(5, 80)</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |                                                                          result|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>
<span class="sd">        |[-0.05969233065843582,-0.030789051204919815,0.04443822056055069,0.09564960747...|</span>
<span class="sd">        |[-0.038839809596538544,0.011712731793522835,0.019954433664679527,0.0667808502...|</span>
<span class="sd">        |[-0.03952755779027939,-0.03455188870429993,0.019103847444057465,0.04311436787...|</span>
<span class="sd">        |[-0.09579929709434509,0.02494969218969345,-0.014753809198737144,0.10259044915...|</span>
<span class="sd">        |[0.004710011184215546,-0.022148698568344116,0.011723337695002556,-0.013356896...|</span>
<span class="sd">        +--------------------------------------------------------------------------------+</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;XlmRoBertaEmbeddings&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.XlmRoBertaEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">XlmRoBertaEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_XlmRoBertaLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_XlmRoBertaLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">XlmRoBertaEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;xlm_roberta_base&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;xx&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">XlmRoBertaEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="GraphExtraction"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.GraphExtraction.html#sparknlp.annotator.GraphExtraction">[docs]</a><span class="k">class</span> <span class="nc">GraphExtraction</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;GraphExtraction&quot;</span>

    <span class="n">relationshipTypes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;relationshipTypes&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Find paths between a pair of token and entity&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">entityTypes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                        <span class="s2">&quot;entityTypes&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;Find paths between a pair of entities&quot;</span><span class="p">,</span>
                        <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">explodeEntities</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;explodeEntities&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;When set to true find paths between entities&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">rootTokens</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                       <span class="s2">&quot;rootTokens&quot;</span><span class="p">,</span>
                       <span class="s2">&quot;Tokens to be consider as root to start traversing the paths. Use it along with explodeEntities&quot;</span><span class="p">,</span>
                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">maxSentenceSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;maxSentenceSize&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Maximum sentence size that the annotator will process. Above this, the sentence is skipped&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">minSentenceSize</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                            <span class="s2">&quot;minSentenceSize&quot;</span><span class="p">,</span>
                            <span class="s2">&quot;Minimum sentence size that the annotator will process. Above this, the sentence is skipped&quot;</span><span class="p">,</span>
                            <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">mergeEntities</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                          <span class="s2">&quot;mergeEntities&quot;</span><span class="p">,</span>
                          <span class="s2">&quot;Merge same neighboring entities as a single token&quot;</span><span class="p">,</span>
                          <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">includeEdges</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                         <span class="s2">&quot;includeEdges&quot;</span><span class="p">,</span>
                         <span class="s2">&quot;Whether to include edges when building paths&quot;</span><span class="p">,</span>
                         <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toBoolean</span><span class="p">)</span>

    <span class="n">delimiter</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                      <span class="s2">&quot;delimiter&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;Delimiter symbol used for path output&quot;</span><span class="p">,</span>
                      <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toString</span><span class="p">)</span>

    <span class="n">posModel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                     <span class="s2">&quot;posModel&quot;</span><span class="p">,</span>
                     <span class="s2">&quot;Coordinates (name, lang, remoteLoc) to a pretrained POS model&quot;</span><span class="p">,</span>
                     <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">dependencyParserModel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                  <span class="s2">&quot;dependencyParserModel&quot;</span><span class="p">,</span>
                                  <span class="s2">&quot;Coordinates (name, lang, remoteLoc) to a pretrained Dependency Parser model&quot;</span><span class="p">,</span>
                                  <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="n">typedDependencyParserModel</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                                       <span class="s2">&quot;typedDependencyParserModel&quot;</span><span class="p">,</span>
                                       <span class="s2">&quot;Coordinates (name, lang, remoteLoc) to a pretrained Typed Dependency Parser model&quot;</span><span class="p">,</span>
                                       <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRelationshipTypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">relationshipTypes</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setEntityTypes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">entityTypes</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setExplodeEntities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">explodeEntities</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setRootTokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">rootTokens</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMinSentenceSize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">minSentenceSize</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMergeEntities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">mergeEntities</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setIncludeEdges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">includeEdges</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDelimiter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">delimiter</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setPosModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">posModel</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setDependencyParserModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">dependencyParserModel</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setTypedDependencyParserModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">typedDependencyParserModel</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.GraphExtraction&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphExtraction</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">maxSentenceSize</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
            <span class="n">minSentenceSize</span><span class="o">=</span><span class="mi">2</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="BertForTokenClassification"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.BertForTokenClassification.html#sparknlp.annotator.BertForTokenClassification">[docs]</a><span class="k">class</span> <span class="nc">BertForTokenClassification</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                                 <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                                 <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;BERT_FOR_TOKEN_CLASSIFICATION&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.BertForTokenClassification&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BertForTokenClassification</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_BertTokenClassifierLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_BertTokenClassifierLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">BertForTokenClassification</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;bert_base_token_classifier_conll03&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">BertForTokenClassification</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistilBertForTokenClassification"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.DistilBertForTokenClassification.html#sparknlp.annotator.DistilBertForTokenClassification">[docs]</a><span class="k">class</span> <span class="nc">DistilBertForTokenClassification</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                                       <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                                       <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;DISTILBERT_FOR_TOKEN_CLASSIFICATION&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.annotators.classifier.dl.DistilBertForTokenClassification&quot;</span><span class="p">,</span>
                 <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistilBertForTokenClassification</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_DistilBertTokenClassifierLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_DistilBertTokenClassifierLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">DistilBertForTokenClassification</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;distilbert_base_token_classifier_conll03&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">DistilBertForTokenClassification</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>


<div class="viewcode-block" id="LongformerEmbeddings"><a class="viewcode-back" href="../../reference/_autosummary/sparknlp.annotator.LongformerEmbeddings.html#sparknlp.annotator.LongformerEmbeddings">[docs]</a><span class="k">class</span> <span class="nc">LongformerEmbeddings</span><span class="p">(</span><span class="n">AnnotatorModel</span><span class="p">,</span>
                           <span class="n">HasEmbeddingsProperties</span><span class="p">,</span>
                           <span class="n">HasCaseSensitiveProperties</span><span class="p">,</span>
                           <span class="n">HasStorageRef</span><span class="p">,</span>
                           <span class="n">HasBatchedAnnotate</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;LONGFORMER_EMBEDDINGS&quot;</span>

    <span class="n">maxSentenceLength</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                              <span class="s2">&quot;maxSentenceLength&quot;</span><span class="p">,</span>
                              <span class="s2">&quot;Max sentence length to process&quot;</span><span class="p">,</span>
                              <span class="n">typeConverter</span><span class="o">=</span><span class="n">TypeConverters</span><span class="o">.</span><span class="n">toInt</span><span class="p">)</span>

    <span class="n">configProtoBytes</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">Params</span><span class="o">.</span><span class="n">_dummy</span><span class="p">(),</span>
                             <span class="s2">&quot;configProtoBytes&quot;</span><span class="p">,</span>
                             <span class="s2">&quot;ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()&quot;</span><span class="p">,</span>
                             <span class="n">TypeConverters</span><span class="o">.</span><span class="n">toListString</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setConfigProtoBytes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">configProtoBytes</span><span class="o">=</span><span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">setMaxSentenceLength</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="n">maxSentenceLength</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@keyword_only</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">classname</span><span class="o">=</span><span class="s2">&quot;com.johnsnowlabs.nlp.embeddings.LongformerEmbeddings&quot;</span><span class="p">,</span> <span class="n">java_model</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LongformerEmbeddings</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">classname</span><span class="o">=</span><span class="n">classname</span><span class="p">,</span>
            <span class="n">java_model</span><span class="o">=</span><span class="n">java_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_setDefault</span><span class="p">(</span>
            <span class="n">dimension</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
            <span class="n">batchSize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">maxSentenceLength</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
            <span class="n">caseSensitive</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">loadSavedModel</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.internal</span> <span class="kn">import</span> <span class="n">_LongformerLoader</span>
        <span class="n">jModel</span> <span class="o">=</span> <span class="n">_LongformerLoader</span><span class="p">(</span><span class="n">folder</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">_jsparkSession</span><span class="p">)</span><span class="o">.</span><span class="n">_java_obj</span>
        <span class="k">return</span> <span class="n">LongformerEmbeddings</span><span class="p">(</span><span class="n">java_model</span><span class="o">=</span><span class="n">jModel</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;longformer_base_4096&quot;</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">remote_loc</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>
        <span class="k">return</span> <span class="n">ResourceDownloader</span><span class="o">.</span><span class="n">downloadModel</span><span class="p">(</span><span class="n">LongformerEmbeddings</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">remote_loc</span><span class="p">)</span></div>
</pre></div>

              </div>
              
              
              <div class='prev-next-bottom'>
                

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, John Snow Labs.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.2.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>