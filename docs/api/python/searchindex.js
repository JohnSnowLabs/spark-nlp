Search.setIndex({"docnames": ["_templates/_autoapi/base/base", "_templates/_autoapi/index", "_templates/_autoapi/python/attribute", "_templates/_autoapi/python/class", "_templates/_autoapi/python/data", "_templates/_autoapi/python/exception", "_templates/_autoapi/python/function", "_templates/_autoapi/python/method", "_templates/_autoapi/python/module", "_templates/_autoapi/python/package", "getting_started/index", "index", "reference/autosummary/sparknlp/annotation/index", "reference/autosummary/sparknlp/annotation_audio/index", "reference/autosummary/sparknlp/annotation_image/index", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index", "reference/autosummary/sparknlp/annotator/audio/index", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/sparknlp/annotator/chunker/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/sparknlp/annotator/coref/index", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/sparknlp/annotator/cv/index", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/sparknlp/annotator/dependency/index", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/sparknlp/annotator/document_normalizer/index", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/sparknlp/annotator/er/index", "reference/autosummary/sparknlp/annotator/graph_extraction/index", "reference/autosummary/sparknlp/annotator/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/sparknlp/annotator/ld_dl/index", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/sparknlp/annotator/lemmatizer/index", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/index", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/sparknlp/annotator/ner/index", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/sparknlp/annotator/normalizer/index", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/sparknlp/annotator/param/index", "reference/autosummary/sparknlp/annotator/pos/index", "reference/autosummary/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/sparknlp/annotator/sentence/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/sparknlp/annotator/sentiment/index", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/index", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/sparknlp/annotator/spell_check/index", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/sparknlp/annotator/stemmer/index", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/index", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/token2_chunk/index", "reference/autosummary/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/sparknlp/annotator/ws/index", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/sparknlp/base/audio_assembler/index", "reference/autosummary/sparknlp/base/chunk2_doc/index", "reference/autosummary/sparknlp/base/doc2_chunk/index", "reference/autosummary/sparknlp/base/document_assembler/index", "reference/autosummary/sparknlp/base/embeddings_finisher/index", "reference/autosummary/sparknlp/base/finisher/index", "reference/autosummary/sparknlp/base/graph_finisher/index", "reference/autosummary/sparknlp/base/has_recursive_fit/index", "reference/autosummary/sparknlp/base/has_recursive_transform/index", "reference/autosummary/sparknlp/base/image_assembler/index", "reference/autosummary/sparknlp/base/index", "reference/autosummary/sparknlp/base/light_pipeline/index", "reference/autosummary/sparknlp/base/multi_document_assembler/index", "reference/autosummary/sparknlp/base/recursive_pipeline/index", "reference/autosummary/sparknlp/base/table_assembler/index", "reference/autosummary/sparknlp/base/token_assembler/index", "reference/autosummary/sparknlp/common/annotator_approach/index", "reference/autosummary/sparknlp/common/annotator_model/index", "reference/autosummary/sparknlp/common/annotator_properties/index", "reference/autosummary/sparknlp/common/annotator_type/index", "reference/autosummary/sparknlp/common/coverage_result/index", "reference/autosummary/sparknlp/common/index", "reference/autosummary/sparknlp/common/properties/index", "reference/autosummary/sparknlp/common/read_as/index", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/sparknlp/common/storage/index", "reference/autosummary/sparknlp/common/utils/index", "reference/autosummary/sparknlp/functions/index", "reference/autosummary/sparknlp/index", "reference/autosummary/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/sparknlp/internal/annotator_transformer/index", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/sparknlp/internal/index", "reference/autosummary/sparknlp/internal/params_getters_setters/index", "reference/autosummary/sparknlp/internal/recursive/index", "reference/autosummary/sparknlp/logging/comet/index", "reference/autosummary/sparknlp/logging/index", "reference/autosummary/sparknlp/pretrained/index", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/sparknlp/pretrained/utils/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/graph_builders/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/create_graph/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/dataset_encoder/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/ner_model/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/ner_model_saver/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/sentence_grouper/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/core_rnn_cell/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/fused_rnn_cell/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/gru_ops/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/lstm_ops/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/rnn/index", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/rnn_cell/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/graph_builders/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/create_graph/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/dataset_encoder/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model_saver/index", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/sentence_grouper/index", "reference/autosummary/sparknlp/training/conll/index", "reference/autosummary/sparknlp/training/conllu/index", "reference/autosummary/sparknlp/training/index", "reference/autosummary/sparknlp/training/pos/index", "reference/autosummary/sparknlp/training/pub_tator/index", "reference/autosummary/sparknlp/training/tfgraphs/index", "reference/autosummary/sparknlp/upload_to_hub/index", "reference/autosummary/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["_templates/_autoapi/base/base.rst", "_templates/_autoapi/index.rst", "_templates/_autoapi/python/attribute.rst", "_templates/_autoapi/python/class.rst", "_templates/_autoapi/python/data.rst", "_templates/_autoapi/python/exception.rst", "_templates/_autoapi/python/function.rst", "_templates/_autoapi/python/method.rst", "_templates/_autoapi/python/module.rst", "_templates/_autoapi/python/package.rst", "getting_started/index.rst", "index.rst", "reference/autosummary/sparknlp/annotation/index.rst", "reference/autosummary/sparknlp/annotation_audio/index.rst", "reference/autosummary/sparknlp/annotation_image/index.rst", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/audio/index.rst", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/chunker/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/coref/index.rst", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/sparknlp/annotator/cv/index.rst", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/dependency/index.rst", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/sparknlp/annotator/er/index.rst", "reference/autosummary/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/sparknlp/annotator/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/sparknlp/annotator/ner/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/sparknlp/annotator/param/index.rst", "reference/autosummary/sparknlp/annotator/pos/index.rst", "reference/autosummary/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/sparknlp/annotator/sentence/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/index.rst", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/token2_chunk/index.rst", "reference/autosummary/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/ws/index.rst", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/sparknlp/base/chunk2_doc/index.rst", "reference/autosummary/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/sparknlp/base/document_assembler/index.rst", "reference/autosummary/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/sparknlp/base/finisher/index.rst", "reference/autosummary/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/sparknlp/base/image_assembler/index.rst", "reference/autosummary/sparknlp/base/index.rst", "reference/autosummary/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/sparknlp/base/table_assembler/index.rst", "reference/autosummary/sparknlp/base/token_assembler/index.rst", "reference/autosummary/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/sparknlp/common/annotator_model/index.rst", "reference/autosummary/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/sparknlp/common/annotator_type/index.rst", "reference/autosummary/sparknlp/common/coverage_result/index.rst", "reference/autosummary/sparknlp/common/index.rst", "reference/autosummary/sparknlp/common/properties/index.rst", "reference/autosummary/sparknlp/common/read_as/index.rst", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/sparknlp/common/storage/index.rst", "reference/autosummary/sparknlp/common/utils/index.rst", "reference/autosummary/sparknlp/functions/index.rst", "reference/autosummary/sparknlp/index.rst", "reference/autosummary/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/sparknlp/internal/index.rst", "reference/autosummary/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/sparknlp/internal/recursive/index.rst", "reference/autosummary/sparknlp/logging/comet/index.rst", "reference/autosummary/sparknlp/logging/index.rst", "reference/autosummary/sparknlp/pretrained/index.rst", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/sparknlp/pretrained/utils/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/graph_builders/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/create_graph/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/dataset_encoder/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/ner_model/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/ner_model_saver/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/ner_dl/sentence_grouper/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/core_rnn_cell/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/fused_rnn_cell/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/gru_ops/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/lstm_ops/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/rnn/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders/tf2contrib/rnn_cell/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/graph_builders/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/create_graph/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/dataset_encoder/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model_saver/index.rst", "reference/autosummary/sparknlp/training/_tf_graph_builders_1x/ner_dl/sentence_grouper/index.rst", "reference/autosummary/sparknlp/training/conll/index.rst", "reference/autosummary/sparknlp/training/conllu/index.rst", "reference/autosummary/sparknlp/training/index.rst", "reference/autosummary/sparknlp/training/pos/index.rst", "reference/autosummary/sparknlp/training/pub_tator/index.rst", "reference/autosummary/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/sparknlp/upload_to_hub/index.rst", "reference/autosummary/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["&lt;no title&gt;", "API Reference", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.hubert_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.swin_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_type</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.ner_dl.create_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.ner_dl.ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib.gru_ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib.rnn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215], "thi": [1, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 87, 88, 89, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 127, 128, 129, 131, 132, 135, 136, 138, 141, 143, 144, 145, 146, 147, 149, 150, 154, 160, 161, 165, 166, 167, 170, 173, 181, 182, 183, 184, 185, 186, 187, 188, 199, 204, 205, 208, 209, 210, 212, 213, 214], "page": [1, 11, 58, 113, 170, 204, 212, 214], "list": [1, 3, 8, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 79, 81, 84, 86, 89, 92, 96, 97, 99, 100, 101, 102, 108, 109, 113, 115, 116, 117, 122, 126, 129, 136, 137, 143, 144, 150, 159, 166, 167, 170, 185, 186, 204, 209], "an": [1, 12, 15, 17, 18, 28, 39, 43, 44, 53, 54, 55, 58, 62, 64, 67, 69, 78, 79, 84, 86, 88, 89, 91, 92, 93, 94, 98, 99, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 124, 129, 131, 134, 135, 136, 137, 138, 143, 144, 147, 150, 154, 158, 159, 161, 165, 166, 167, 181, 182, 185, 186, 187, 196, 197, 199, 200, 204, 206, 208, 209, 210, 212, 213], "overview": [1, 204, 212], "all": [1, 8, 10, 12, 13, 14, 20, 23, 26, 30, 33, 37, 41, 44, 46, 48, 53, 58, 59, 60, 61, 62, 72, 75, 78, 79, 82, 86, 89, 99, 101, 113, 116, 117, 122, 127, 131, 136, 138, 167, 173, 184, 187, 188, 204, 209, 214], "spark": [1, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 147, 153, 155, 159, 160, 162, 163, 164, 167, 170, 173, 188, 196, 197, 199, 200, 204, 206, 207, 208, 209, 211, 212, 213, 215], "nlp": [1, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 129, 131, 133, 134, 135, 136, 137, 141, 142, 143, 144, 145, 146, 147, 153, 160, 164, 167, 170, 173, 188, 196, 197, 199, 200, 204, 206, 207, 208, 209, 210, 211, 212, 213, 215], "modul": [1, 8, 9, 11, 35, 56, 68, 80, 82, 83, 85, 90, 95, 104, 105, 107, 110, 114, 118, 125, 130, 142, 153, 164, 169, 184, 198], "class": [1, 3, 5, 8, 82, 153, 157, 164, 171, 198, 204, 205, 213, 215], "function": [1, 6, 8, 11, 67, 75, 116, 136, 184, 204, 212], "method": [1, 3, 7, 28, 39, 43, 59, 65, 66, 74, 78, 84, 99, 173, 185, 188, 204], "extend": [2, 5, 9, 15, 17, 18, 28, 39, 43, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 67, 70, 72, 73, 75, 76, 78, 84, 86, 87, 89, 91, 92, 93, 94, 98, 99, 101, 103, 106, 108, 109, 111, 112, 115, 116, 117, 119, 121, 122, 126, 129, 131, 133, 134, 135, 136, 137, 144, 147, 170], "python": [2, 5, 9, 11, 86, 182, 183, 184, 187], "data": [2, 8, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 141, 143, 144, 145, 146, 147, 159, 167, 170, 185, 186, 187, 196, 197, 198, 199, 200, 206, 208, 209, 213, 214, 215], "rst": [2, 5, 8, 9], "obj": [3, 4, 6, 7, 8, 197], "displai": [3, 4, 6, 7, 8, 28, 39, 43, 103, 113, 167, 205], "py": [3, 4, 6, 7, 148, 149, 156, 162, 166], "type": [3, 4, 8, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 159, 161, 170, 185, 186, 187, 199, 208, 209, 212], "short_nam": [3, 6, 7, 8], "arg": [3, 6, 7, 145, 163, 185, 186, 187], "endif": [3, 4, 6, 7, 8], "return_annot": [3, 6, 7], "overload": [3, 6, 7], "length": [3, 7, 8, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 78, 94, 101, 108, 109, 113, 115, 116, 117, 127, 129, 185, 186], "endfor": [3, 6, 7, 8], "base": [3, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 148, 149, 150, 153, 156, 160, 162, 166, 167, 173, 183, 185, 187, 188, 205, 209, 210, 213], "show": [3, 4, 8, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 144, 146, 147, 159, 196, 197, 199, 200, 205, 208, 209, 210, 214], "inherit": [3, 149, 166], "autoapi_opt": [3, 8], "link_obj": 3, "loop": [3, 182], "last": [3, 12, 89, 91, 124, 213], "diagram": 3, "object": [3, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 98, 99, 106, 109, 113, 115, 116, 117, 119, 120, 121, 122, 131, 155, 162, 163, 167, 182, 208, 209], "autoapi": [3, 8], "full_nam": 3, "part": [3, 18, 62, 84, 87, 105, 106, 121, 131, 134, 187, 199, 215], "1": [3, 4, 6, 7, 8, 10, 15, 18, 20, 23, 26, 28, 30, 33, 37, 39, 41, 43, 46, 48, 51, 53, 55, 57, 59, 60, 61, 64, 66, 67, 71, 74, 75, 76, 77, 78, 84, 88, 89, 91, 92, 93, 94, 97, 98, 99, 102, 103, 108, 109, 112, 113, 115, 116, 117, 123, 127, 133, 136, 137, 150, 154, 160, 165, 166, 167, 170, 173, 183, 184, 185, 186, 187, 188, 196, 197, 200, 205, 208, 209, 213, 214], "privat": [3, 70, 71, 161], "member": [3, 106, 170], "docstr": [3, 4, 6, 7, 8], "indent": [3, 4, 6, 7, 8], "set": [3, 8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 123, 126, 127, 129, 131, 132, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 149, 150, 154, 158, 160, 165, 166, 167, 187, 196, 205, 209, 212, 213], "visible_class": [3, 8], "selectattr": [3, 8], "els": [3, 4, 6, 7, 8, 111], "rejectattr": [3, 8], "klass": [3, 8], "render": [3, 8], "visible_attribut": [3, 8], "attribut": [3, 8, 167], "visible_method": 3, "name": [4, 8, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 93, 95, 96, 98, 99, 102, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 123, 124, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 144, 146, 147, 150, 159, 165, 167, 170, 173, 183, 185, 187, 188, 196, 199, 205, 209], "valu": [4, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 79, 81, 84, 86, 87, 89, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 112, 113, 115, 116, 117, 119, 122, 123, 127, 129, 131, 132, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 150, 154, 155, 165, 167, 185, 186, 205, 215], "i": [4, 6, 7, 8, 10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 127, 129, 131, 132, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 158, 159, 160, 166, 167, 182, 183, 184, 185, 186, 187, 196, 199, 200, 205, 206, 208, 209, 210, 212, 213, 214, 215], "none": [4, 6, 7, 8, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 86, 87, 88, 92, 93, 98, 99, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 128, 129, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141, 144, 146, 149, 166, 167, 170, 181, 183, 185, 186, 187, 210], "annot": [4, 11, 13, 14, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 158, 159, 160, 161, 162, 164, 166, 167, 170, 172, 173, 188, 199, 205, 206, 211, 212, 213, 214, 215], "string": [4, 12, 28, 39, 43, 51, 55, 58, 79, 92, 94, 100, 101, 109, 116, 120, 122, 126, 134, 135, 137, 141, 143, 144, 187, 213], "splitlin": 4, "count": [4, 44, 117], "multilin": 4, "width": [4, 14, 141], "truncat": [4, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 55, 57, 58, 75, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 133, 134, 135, 137, 138, 144, 146, 147, 159, 199, 208, 209, 210], "100": [4, 15, 28, 39, 44, 54, 66, 74, 76, 84, 109, 146], "sphinx_vers": [6, 7], "properti": [6, 7, 59, 139, 140, 150, 153, 160, 185, 186], "method_typ": 7, "orphan": 8, "nest": [8, 186], "pars": [8, 18, 55, 56, 57, 62, 79, 87, 89, 91, 117, 119, 120, 143, 146, 170, 199], "block": [8, 183, 185], "subpackag": 8, "visible_subpackag": 8, "toctre": 8, "titlesonli": 8, "maxdepth": 8, "index": [8, 12, 84, 88, 127, 160, 196], "endblock": 8, "submodul": 8, "visible_submodul": 8, "content": [8, 208, 214], "visible_children": 8, "children": 8, "elif": 8, "equalto": 8, "packag": [8, 10, 59, 64, 167, 206, 207], "import": [8, 10, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 141, 143, 144, 145, 146, 147, 159, 167, 170, 173, 188, 196, 197, 199, 200, 205, 208, 209, 212, 213, 214, 215], "titl": [8, 200, 215], "visible_funct": 8, "summari": [8, 113, 116], "scope": [8, 112, 185, 186, 187], "id": [8, 39, 58, 76, 79, 113, 115, 116, 133, 134, 135, 137, 144, 147, 167, 187], "obj_item": 8, "0": [8, 10, 15, 17, 18, 28, 39, 43, 51, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 86, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 113, 116, 117, 120, 123, 128, 129, 131, 133, 135, 136, 137, 143, 144, 146, 147, 150, 154, 159, 160, 163, 165, 166, 167, 170, 173, 183, 185, 187, 188, 197, 199, 200, 205, 208, 209, 214, 215], "can": [10, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 92, 97, 98, 99, 100, 106, 108, 109, 111, 113, 115, 116, 117, 119, 120, 122, 128, 131, 135, 136, 144, 145, 146, 158, 167, 170, 186, 196, 197, 199, 205, 207, 209, 210, 212, 213, 214, 215], "quick": [10, 205, 210], "refer": [10, 11, 15, 51, 53, 54, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 78, 84, 108, 109, 112, 113, 115, 116, 117, 119, 120, 134, 135, 144, 209, 211, 212], "how": [10, 11, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 69, 70, 72, 76, 78, 79, 81, 86, 87, 88, 92, 93, 97, 98, 99, 101, 103, 108, 111, 119, 120, 127, 129, 131, 135, 138, 144, 155, 158, 160, 196, 197, 205, 209, 214], "up": [10, 11, 15, 28, 39, 66, 69, 72, 74, 84, 113, 116, 160, 205, 209, 212, 213], "your": [10, 11, 28, 39, 43, 55, 65, 66, 70, 72, 74, 87, 88, 92, 93, 98, 99, 101, 106, 111, 112, 117, 119, 124, 126, 131, 136, 181, 207, 209, 212, 213, 215], "environ": [10, 206], "pypi": 10, "pip": 10, "anaconda": 10, "c": [10, 62, 66, 74, 84, 115, 183, 187], "johnsnowlab": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 86, 87, 88, 92, 93, 98, 99, 101, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 129, 131, 146, 160], "load": [10, 11, 13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 84, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 141, 170, 209, 212], "shell": 10, "com": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 86, 87, 88, 92, 93, 98, 99, 101, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 129, 131, 146, 160, 187], "nlp_2": [10, 160], "12": [10, 59, 76, 77, 78, 84, 89, 91, 97, 106, 117, 128, 143, 159, 160, 170, 173, 188, 199, 208], "pyspark": [10, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 134, 135, 136, 141, 143, 144, 146, 147, 159, 160, 163, 166, 167, 170, 196, 197, 199, 200, 209, 210], "submit": [10, 167, 187, 205], "extern": [10, 84, 87, 92, 93, 99, 123, 145, 158, 196, 197, 199, 200], "jar": [10, 160], "after": [10, 55, 57, 66, 70, 71, 74, 89, 91, 97, 126, 147, 167, 187, 208, 209], "compil": 10, "build": [10, 64, 65, 70, 71, 81, 84, 88, 113, 167, 173, 183, 187, 188, 205], "sbt": 10, "assembli": 10, "built": [10, 28, 39, 144, 187], "top": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 53, 59, 84, 113, 116, 144], "apach": [10, 144, 160], "x": [10, 39, 159, 183, 184, 187, 196, 215], "For": [10, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 129, 131, 133, 134, 135, 136, 137, 144, 147, 167, 170, 182, 187, 200, 205, 206, 208, 209, 210, 211, 212, 213], "you": [10, 55, 57, 63, 65, 70, 72, 81, 89, 100, 136, 138, 143, 167, 173, 188, 199, 205, 207, 209, 210, 213, 214, 215], "need": [10, 15, 17, 18, 55, 57, 65, 70, 75, 79, 81, 84, 89, 92, 98, 99, 101, 103, 106, 109, 112, 113, 117, 119, 120, 127, 129, 132, 141, 143, 167, 181, 186, 187, 196, 197, 199, 205, 207, 209, 210, 213, 215], "java": [10, 86, 148, 149, 156, 162, 163, 166], "ar": [10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 53, 54, 55, 57, 59, 60, 62, 64, 65, 67, 69, 70, 73, 75, 76, 77, 78, 79, 81, 84, 86, 87, 89, 92, 94, 97, 99, 100, 101, 106, 108, 109, 112, 113, 115, 116, 117, 121, 123, 131, 133, 136, 143, 145, 146, 155, 159, 167, 182, 183, 184, 186, 187, 200, 205, 206, 207, 208, 209, 210, 213, 214, 215], "6": [10, 28, 43, 53, 60, 61, 64, 67, 84, 88, 93, 94, 100, 106, 119, 128, 173, 187, 188, 197, 209], "7": [10, 43, 53, 60, 61, 64, 89, 91, 106, 113, 133, 137, 199, 208], "It": [10, 20, 23, 28, 30, 33, 37, 39, 41, 43, 44, 46, 48, 53, 58, 60, 61, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 79, 84, 94, 112, 115, 117, 119, 120, 126, 137, 143, 185, 187, 208, 213], "recommend": [10, 67, 78, 111, 112, 113, 115, 116], "have": [10, 15, 28, 39, 43, 59, 62, 65, 70, 71, 75, 84, 92, 94, 98, 99, 100, 106, 108, 109, 113, 120, 128, 147, 162, 186, 187, 209, 210, 213], "basic": [10, 53, 84, 108, 185, 187, 208], "knowledg": [10, 65, 84, 138], "framework": [10, 17, 115, 116], "work": [10, 65, 69, 86, 116, 124, 208, 210, 214], "befor": [10, 58, 75, 89, 91, 116, 119, 127, 131, 149, 166, 187, 205], "pleas": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 86, 87, 88, 89, 92, 93, 98, 99, 101, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 131, 135, 144, 145, 206, 207, 211, 214], "document": [10, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 143, 144, 146, 147, 167, 170, 196, 197, 199, 205, 209, 210, 212, 213, 214], "first": [10, 12, 64, 66, 67, 74, 76, 77, 84, 92, 98, 99, 100, 108, 116, 117, 122, 127, 136, 147, 186, 187, 205, 209, 210, 214], "let": [10, 65, 126, 209], "": [10, 11, 19, 22, 25, 29, 32, 36, 40, 45, 58, 59, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 79, 84, 92, 99, 101, 112, 113, 115, 116, 117, 119, 120, 126, 127, 129, 131, 132, 137, 143, 148, 149, 156, 159, 162, 166, 167, 187, 205, 208, 209, 210, 213], "make": [10, 53, 58, 62, 69, 76, 77, 84, 109, 112, 119, 211, 215], "sure": [10, 112], "version": [10, 58, 65, 102, 103, 123, 150, 154, 160, 165, 166, 170, 173, 209], "oracl": 10, "openjdk": 10, "0_292": 10, "creat": [10, 12, 13, 14, 28, 39, 43, 60, 61, 66, 70, 74, 75, 81, 99, 103, 106, 124, 131, 143, 145, 159, 173, 185, 186, 188, 196, 197, 199, 200, 209, 210, 213, 215], "new": [10, 12, 13, 14, 43, 51, 53, 59, 60, 61, 64, 67, 69, 75, 78, 100, 102, 103, 113, 116, 117, 123, 133, 137, 150, 154, 165, 166, 187, 208, 209], "manag": [10, 84, 206], "depend": [10, 12, 51, 62, 72, 78, 79, 81, 82, 84, 86, 99, 115, 117, 160, 186, 187], "Then": [10, 28, 39, 98, 99, 147, 167, 209], "we": [10, 15, 17, 28, 39, 53, 54, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 78, 84, 98, 99, 101, 109, 113, 115, 116, 117, 119, 129, 143, 159, 185, 187, 205, 208, 209, 210, 213, 214, 215], "sparknlp": [10, 205, 208, 209, 210, 211, 213, 214, 215], "n": [10, 77, 84, 94, 97, 98, 99, 108, 109, 113, 116, 126, 143, 146, 159, 170, 187], "y": [10, 39, 187], "activ": [10, 20, 23, 26, 33, 37, 41, 46, 48, 84, 181, 187], "jupyt": [10, 167, 205], "now": [10, 62, 109, 143, 210], "should": [10, 12, 13, 14, 18, 28, 39, 43, 66, 74, 76, 84, 86, 93, 94, 98, 99, 103, 108, 109, 115, 117, 127, 143, 149, 150, 162, 166, 170, 185, 187, 196, 197], "readi": [10, 28, 170, 209], "notebook": [10, 167, 205], "run": [10, 65, 84, 167, 181, 185, 186, 187, 206, 214], "also": [10, 28, 39, 43, 53, 54, 58, 59, 67, 69, 75, 76, 77, 79, 81, 84, 89, 92, 97, 98, 99, 102, 103, 109, 112, 122, 143, 146, 150, 154, 165, 187, 205, 209, 210, 211, 212], "python3": 10, "sourc": [10, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 154, 155, 156, 158, 159, 160, 161, 162, 163, 165, 166, 167, 170, 173, 181, 182, 183, 184, 185, 186, 187, 188, 196, 197, 199, 200, 206], "bin": 10, "A": [10, 15, 17, 43, 51, 59, 70, 71, 75, 79, 84, 87, 88, 92, 93, 94, 101, 111, 113, 115, 116, 119, 120, 127, 129, 167, 182, 185, 186, 187, 199, 207, 209, 215], "retriev": [10, 75, 87, 119, 120, 121, 167, 170, 205, 209, 210], "If": [10, 20, 23, 26, 28, 30, 33, 37, 39, 41, 43, 46, 48, 72, 75, 79, 86, 89, 91, 97, 98, 99, 101, 103, 108, 109, 113, 116, 117, 123, 160, 166, 167, 173, 185, 186, 187, 188, 205, 207, 209], "manual": [10, 208], "sparksess": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 75, 76, 77, 78, 88, 113, 115, 116, 160, 196, 197, 199, 200], "becaus": [10, 111, 149, 166, 186], "other": [10, 15, 39, 62, 72, 73, 81, 84, 101, 111, 113, 116, 124, 126, 133, 136, 137, 144, 209], "configur": [10, 72, 129, 160, 173, 188], "includ": [10, 53, 58, 60, 61, 66, 67, 74, 76, 77, 78, 81, 84, 89, 97, 98, 99, 113, 116, 117, 137, 167, 184, 200, 206, 208, 209, 210, 215], "them": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 53, 54, 59, 60, 62, 64, 65, 69, 70, 76, 78, 79, 81, 84, 89, 92, 109, 117, 122, 131, 145, 147, 209, 210], "builder": [10, 123, 160], "appnam": [10, 160], "master": [10, 53, 160], "local": [10, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 84, 113, 115, 116, 122, 143, 160, 170, 213], "config": [10, 160, 206], "driver": [10, 160], "memori": [10, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 59, 67, 75, 160, 185, 186, 187], "16g": [10, 160], "maxresults": [10, 160], "kryoseri": [10, 160], "buffer": [10, 61, 75, 160], "max": [10, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 59, 60, 61, 62, 64, 65, 69, 70, 71, 76, 77, 78, 84, 120, 160], "2000m": [10, 160], "getorcr": [10, 160], "main": [11, 79, 129, 208, 212, 215], "github": [11, 53, 64, 70, 115, 170], "issu": 11, "workshop": [11, 18, 28, 39, 43, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 65, 67, 70, 72, 73, 75, 76, 78, 84, 86, 87, 89, 91, 92, 93, 94, 98, 99, 101, 106, 108, 109, 111, 112, 115, 116, 117, 119, 121, 122, 126, 129, 131, 133, 134, 135, 136, 137, 144, 147, 167, 187, 205, 212], "model": [11, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 86, 87, 88, 92, 93, 98, 99, 101, 103, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 123, 124, 126, 129, 131, 149, 160, 166, 167, 170, 173, 186, 187, 188, 205, 206, 208, 212, 214, 215], "hub": [11, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 86, 87, 98, 99, 106, 109, 113, 115, 116, 117, 119, 120, 122, 131], "welcom": [11, 15, 17], "contain": [11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 146, 147, 148, 149, 150, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 165, 166, 167, 168, 170, 171, 172, 185, 186, 187, 196, 197, 199, 200, 203, 205, 208, 209], "inform": [11, 55, 57, 75, 76, 84, 89, 97, 117, 135, 144, 186, 187, 200, 205, 206, 207, 208, 209, 215], "us": [11, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 103, 106, 108, 109, 112, 113, 115, 116, 117, 119, 120, 122, 123, 127, 128, 129, 131, 133, 134, 135, 136, 137, 143, 144, 145, 146, 147, 159, 160, 167, 170, 181, 182, 183, 185, 186, 187, 196, 197, 199, 200, 206, 207, 208, 209, 210, 212], "librari": [11, 53, 54, 86, 134, 135, 136, 144, 147, 214], "exampl": [11, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 145, 146, 147, 159, 167, 170, 173, 182, 187, 188, 196, 197, 199, 200, 205, 208, 209, 210, 212, 213, 214, 215], "get": [11, 28, 39, 84, 96, 106, 117, 123, 129, 131, 132, 135, 136, 137, 141, 143, 144, 150, 154, 165, 205, 209, 214, 215], "start": [11, 15, 19, 22, 25, 29, 32, 36, 40, 45, 69, 81, 84, 98, 99, 109, 134, 160, 167, 181, 185, 205, 208, 210, 213, 214], "cheat": 11, "sheet": [11, 58], "requir": [11, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 57, 59, 61, 64, 67, 73, 76, 77, 84, 99, 101, 112, 117, 128, 131, 134, 136, 147, 185, 186, 187, 208, 209, 210], "instal": [11, 167, 207], "session": [11, 160, 196, 197, 199, 200], "from": [11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 102, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 145, 146, 147, 149, 159, 160, 163, 166, 167, 170, 173, 181, 183, 185, 186, 187, 188, 196, 197, 199, 200, 205, 208, 209, 210, 213, 214, 215], "user": [11, 97, 98, 129, 145, 160, 167, 205], "guid": [11, 206], "own": [11, 28, 39, 43, 55, 66, 74, 87, 88, 92, 93, 98, 99, 101, 106, 111, 112, 117, 119, 124, 126, 131, 187, 212, 213, 215], "pipelin": [11, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 141, 143, 144, 145, 146, 147, 160, 166, 167, 169, 170, 172, 206, 208, 209, 212], "pretrain": [11, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 86, 87, 88, 89, 92, 93, 98, 99, 100, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 133, 136, 137, 143, 159, 160, 167, 205, 208, 212], "dataset": [11, 28, 39, 43, 55, 57, 62, 66, 69, 70, 71, 74, 75, 84, 86, 98, 99, 103, 109, 113, 117, 131, 166, 170, 196, 197, 199, 200, 212], "train": [11, 15, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 70, 71, 73, 74, 76, 77, 78, 84, 86, 87, 88, 92, 93, 96, 98, 99, 101, 102, 103, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 124, 126, 131, 134, 143, 160, 167, 170, 205, 209, 210, 212, 213], "light": [11, 15, 65, 78, 84, 143, 212, 214], "helper": [11, 106, 131, 138, 159, 185, 186, 199, 200, 212, 215], "third": [11, 108, 122, 168], "parti": [11, 168], "project": [11, 84, 115, 167, 181, 187, 206], "log": [11, 28, 39, 43, 99, 103, 109, 113, 160], "api": [11, 205, 209, 212], "format": [12, 13, 14, 53, 54, 55, 57, 79, 81, 87, 88, 89, 91, 92, 93, 98, 99, 101, 103, 111, 116, 119, 120, 129, 132, 135, 137, 138, 141, 144, 146, 186, 196, 197, 199, 200, 206, 215], "annotatortyp": [12, 13, 14, 63, 94, 134, 135, 141, 144, 208], "begin": [12, 51, 97, 113, 126, 129, 134, 135, 144, 159, 185, 186, 187, 208], "end": [12, 19, 22, 25, 29, 32, 36, 40, 45, 51, 99, 109, 126, 129, 135, 144, 159, 167, 186, 196, 205, 208, 210], "result": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 159, 160, 167, 170, 187, 196, 197, 205, 206, 208, 209, 210, 213, 214], "metadata": [12, 13, 14, 44, 51, 84, 93, 98, 99, 106, 135, 137, 141, 143, 144, 159, 167, 208, 210], "embed": [12, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 81, 82, 98, 99, 100, 135, 136, 137, 143, 144, 154, 159, 160, 166, 170, 173, 181, 188, 208], "repres": [12, 13, 14, 55, 57, 59, 64, 78, 79, 81, 88, 93, 94, 129, 167, 170, 182, 187, 209], "output": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 150, 159, 160, 167, 181, 185, 186, 187, 199, 205, 208, 209, 210], "detail": [12, 13, 14, 76, 77, 84, 113, 116, 187], "paramet": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 150, 154, 158, 159, 160, 165, 166, 167, 170, 173, 186, 188, 196, 197, 199, 200], "annotator_typ": [12, 13, 14], "str": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 123, 126, 127, 129, 131, 132, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 150, 158, 159, 160, 165, 167, 170, 173, 188, 196, 197, 199, 200], "The": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 127, 129, 131, 135, 137, 143, 144, 146, 159, 160, 167, 170, 173, 183, 184, 185, 186, 187, 188, 196, 197, 199, 200, 205, 208, 209, 210, 212, 213, 215], "possibl": [12, 13, 14, 63, 65, 76, 77, 79, 108, 117, 120, 135, 144, 155, 167, 205], "token": [12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 87, 88, 93, 94, 96, 97, 98, 99, 100, 101, 103, 106, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 131, 133, 134, 136, 143, 145, 147, 160, 170, 173, 188, 196, 200, 209, 213, 214], "wordpiec": 12, "word_embed": [12, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 72, 74, 76, 78, 82, 98, 99, 103], "sentence_embed": [12, 28, 39, 43, 61, 66, 68, 71, 73, 77, 82, 167, 205, 209], "categori": [12, 20, 23, 26, 28, 30, 33, 37, 39, 41, 43, 46, 48, 53, 54, 167, 205, 209], "date": [12, 89, 91, 92], "entiti": [12, 21, 24, 27, 31, 34, 38, 42, 47, 49, 51, 53, 62, 79, 80, 81, 88, 93, 95, 96, 97, 98, 99, 100, 124, 128, 133, 137, 143, 170], "sentiment": [12, 28, 39, 43, 67, 78, 82, 116, 160, 209, 210], "po": [12, 18, 20, 23, 26, 30, 33, 37, 41, 46, 48, 55, 57, 81, 82, 98, 99, 126, 131, 143, 159, 160, 170, 196, 198, 208, 212, 213, 214], "chunk": [12, 18, 19, 22, 25, 29, 32, 36, 40, 45, 63, 66, 74, 79, 84, 88, 92, 93, 94, 97, 124, 128, 133, 134, 137, 159, 167, 200, 205, 215], "named_ent": [12, 21, 24, 27, 31, 34, 38, 42, 47, 49, 81, 97, 98, 99, 100, 103, 143, 170], "negex": 12, "labeled_depend": [12, 57], "languag": [12, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 134, 144, 147, 209], "keyword": [12, 83, 84, 111, 187], "dummi": [12, 58], "int": [12, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 75, 76, 77, 78, 81, 84, 86, 89, 94, 96, 98, 99, 101, 102, 103, 106, 108, 109, 112, 113, 115, 116, 117, 120, 123, 127, 129, 131, 154, 160, 167, 187, 196], "charact": [12, 58, 67, 69, 79, 86, 92, 94, 101, 108, 109, 117, 119, 120, 127, 129, 131, 137], "under": [12, 65, 78, 84, 160], "dict": [12, 13, 14, 55, 57, 79, 87, 88, 92, 93, 98, 100, 101, 103, 111, 117, 119, 120, 129, 143, 158, 166, 167, 170, 173, 188], "associ": [12, 13, 14, 39, 73, 79, 92, 97, 167], "vector": [12, 39, 60, 61, 63, 64, 66, 67, 73, 74, 75, 136, 137, 144, 185, 186, 187, 208], "where": [12, 39, 64, 67, 79, 84, 87, 88, 92, 93, 94, 106, 109, 111, 113, 116, 119, 120, 131, 134, 173, 186, 187, 188, 199], "applic": [12, 54, 84, 167, 168, 205, 207], "copi": [12, 13, 14], "differ": [12, 13, 14, 53, 55, 57, 67, 70, 71, 76, 78, 84, 89, 108, 109, 117, 129, 143, 167, 173, 183, 187, 188, 213], "return": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 84, 86, 87, 88, 93, 94, 96, 98, 99, 106, 108, 109, 112, 113, 115, 116, 117, 119, 120, 121, 122, 126, 129, 131, 134, 143, 158, 159, 160, 161, 166, 170, 173, 185, 186, 187, 188, 196, 197, 199, 200], "newli": [12, 13, 14], "static": [12, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 173, 187, 188, 209], "datatyp": [12, 159], "structtyp": 12, "schema": [12, 97, 167, 205], "look": [12, 99, 119, 208], "like": [12, 15, 19, 22, 25, 28, 29, 32, 36, 40, 45, 51, 58, 59, 63, 65, 69, 72, 78, 81, 84, 92, 97, 109, 112, 113, 117, 129, 131, 167, 205, 207, 208], "struct": [12, 135, 141, 144], "containsnul": [12, 39, 132, 135, 141, 144], "true": [12, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 53, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 86, 88, 89, 91, 93, 97, 99, 101, 108, 109, 117, 119, 127, 129, 131, 132, 134, 135, 136, 137, 138, 141, 144, 146, 167, 173, 182, 186, 187, 188, 196, 197, 200, 205, 209, 210], "nullabl": [12, 39, 132, 135, 141, 144], "fals": [12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 143, 144, 146, 147, 159, 160, 167, 170, 182, 185, 186, 187, 196, 197, 199, 205, 208, 209, 210, 215], "integ": [12, 135, 141, 144], "map": [12, 18, 39, 75, 79, 102, 103, 106, 117, 135, 141, 144, 150, 154, 159, 165, 166, 187, 208], "kei": [12, 15, 55, 57, 70, 71, 76, 77, 87, 135, 141, 143, 144, 167, 170, 205], "valuecontainsnul": [12, 135, 141, 144], "arrai": [12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 73, 76, 77, 78, 86, 87, 94, 99, 102, 106, 108, 109, 113, 115, 116, 117, 124, 126, 131, 132, 134, 135, 136, 137, 138, 141, 143, 144, 159, 210, 213], "element": [12, 39, 94, 132, 135, 141, 144, 185, 186], "float": [12, 13, 15, 17, 28, 39, 43, 86, 98, 99, 102, 103, 109, 113, 116, 117, 131, 132, 135, 136, 143, 144], "sql": [12, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 75, 76, 77, 78, 88, 113, 115, 116, 143, 159, 166, 170, 196, 197, 199, 200], "arraytyp": [12, 134, 159], "fromrow": 12, "row": [12, 44, 75, 108, 109, 112, 135, 144, 146, 159, 196], "column": [12, 28, 39, 43, 58, 75, 87, 96, 98, 99, 102, 103, 106, 112, 123, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 144, 147, 150, 159, 170, 187, 196, 199, 209], "torow": 12, "transform": [12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 143, 144, 146, 147, 159, 162, 166, 167, 170, 205, 208, 209, 210, 213, 214, 215], "annotationaudio": 13, "audio": [13, 132, 167], "alreadi": [13, 81, 84, 98, 99, 100, 128, 129, 143, 170, 187, 213], "process": [13, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 74, 76, 77, 78, 81, 84, 86, 97, 98, 99, 103, 109, 113, 116, 132, 133, 134, 135, 136, 137, 141, 144, 145, 147, 167, 187, 205, 208, 209, 210, 211], "file": [13, 15, 17, 28, 39, 43, 55, 57, 58, 73, 75, 79, 87, 88, 92, 93, 98, 99, 101, 103, 109, 111, 117, 119, 120, 123, 129, 132, 146, 155, 160, 167, 173, 184, 188, 196, 197, 199, 200, 205, 215], "byte": [13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 86, 99, 102, 113, 115, 116, 117, 167], "annotationimag": [14, 143, 170], "origin": [14, 59, 66, 69, 70, 74, 97, 109, 141, 184, 187], "height": [14, 141], "nchannel": [14, 141], "mode": [14, 28, 39, 43, 99, 103, 119, 135, 141, 144, 167], "imag": [14, 53, 54, 141, 143, 170], "uri": 14, "pixel": [14, 53], "number": [14, 28, 39, 43, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 94, 96, 98, 99, 102, 106, 108, 109, 113, 116, 117, 123, 131, 185, 186, 187, 196, 197], "color": 14, "channel": [14, 117], "opencv": 14, "concern": [15, 17, 20, 53, 54, 59], "hubertforctc": 15, "classnam": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 86, 87, 88, 92, 93, 98, 99, 101, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 129, 131, 146, 148, 149, 156, 162], "java_model": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 86, 87, 88, 92, 93, 98, 99, 101, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 126, 129, 131, 140, 146, 149, 166], "hubert": 15, "head": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 51, 59, 78, 97, 98, 99, 143, 159, 170], "connectionist": [15, 17], "tempor": [15, 17, 186], "classif": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 53, 54, 59, 73, 112, 116, 209], "ctc": [15, 17], "wa": [15, 17, 20, 21, 23, 24, 28, 30, 31, 33, 34, 37, 38, 41, 42, 43, 46, 47, 48, 49, 53, 58, 62, 64, 65, 69, 70, 71, 75, 76, 77, 84, 112, 113, 117, 170, 187, 209, 210], "propos": [15, 17, 53, 59, 62, 64, 65, 70, 71, 76, 77, 78], "self": [15, 17, 53, 59, 69, 115, 185, 187], "supervis": [15, 17, 59, 67, 73, 84, 113], "speech": [15, 17, 18, 62, 105, 106, 131, 199, 215], "represent": [15, 17, 53, 59, 60, 61, 65, 66, 67, 74, 75, 76, 77, 78, 97, 116, 144, 146, 158], "learn": [15, 17, 28, 39, 43, 59, 65, 66, 67, 70, 71, 73, 74, 76, 77, 78, 84, 98, 99, 102, 109, 113, 116, 117, 167, 187, 207], "mask": [15, 53, 64, 76, 77, 78, 127], "predict": [15, 53, 64, 99, 113, 116, 167, 187, 205], "hidden": [15, 19, 21, 22, 24, 25, 27, 29, 31, 32, 34, 36, 38, 40, 42, 45, 47, 49, 59, 67, 78, 123, 187], "unit": [15, 113, 123, 185, 187], "wei": [15, 53], "ning": 15, "hsu": 15, "benjamin": [15, 62], "bolt": 15, "yao": 15, "hung": 15, "tsai": 15, "kushal": 15, "lakhotia": 15, "ruslan": 15, "salakhutdinov": 15, "abdelrahman": [15, 17], "moham": [15, 17], "take": [15, 17, 44, 62, 81, 93, 102, 103, 119, 122, 129, 145, 150, 154, 165, 186, 196, 208, 209, 213, 214], "transcrib": [15, 17], "text": [15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 51, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 144, 146, 147, 155, 158, 159, 167, 196, 197, 199, 200, 205, 208, 209, 210, 214, 215], "provid": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 86, 87, 88, 89, 91, 92, 93, 98, 99, 101, 102, 103, 106, 109, 111, 113, 115, 116, 117, 119, 120, 131, 143, 150, 154, 159, 161, 165, 170, 185, 186, 187, 210], "pre": [15, 17, 28, 39, 43, 54, 60, 61, 64, 65, 67, 73, 99, 103, 116, 133, 134, 135, 137, 144, 147, 197, 209], "note": [15, 17, 28, 39, 43, 59, 65, 67, 70, 72, 75, 76, 78, 84, 99, 113, 115, 116, 143, 160, 181, 214], "current": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 75, 76, 77, 78, 84, 88, 89, 91, 109, 113, 115, 116, 123, 143, 146, 150, 160, 187, 208, 209, 210], "support": [15, 17, 28, 39, 59, 69, 84, 99, 101, 109, 122, 146, 160, 206], "appl": [15, 17, 61, 71, 77], "silicon": [15, 17], "processor": [15, 17], "m1": [15, 17, 160], "due": [15, 17, 20, 23, 26, 30, 33, 37, 41, 46, 48, 59, 69], "instruct": [15, 17], "xla": [15, 17, 187], "companion": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 98, 99, 106, 109, 113, 115, 116, 117, 119, 120, 122, 131, 163], "speechtotext": [15, 17], "setinputcol": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 144, 146, 147, 150, 167, 173, 188, 205, 209, 210], "audio_assembl": [15, 17, 142, 160], "setoutputcol": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 144, 146, 147, 150, 167, 173, 188, 205, 209, 210], "default": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 123, 126, 127, 129, 131, 134, 135, 136, 137, 138, 143, 144, 146, 158, 159, 160, 167, 170, 185, 186, 187, 196, 197, 199, 200, 209], "asr_hubert_large_ls960": 15, "avail": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 82, 84, 86, 87, 89, 92, 98, 99, 106, 109, 113, 115, 116, 117, 119, 120, 122, 131, 162, 170, 173, 184, 188, 205, 212], "see": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 129, 131, 133, 134, 135, 136, 137, 138, 144, 147, 167, 170, 187, 200, 205, 206, 207, 212, 214, 215], "To": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 53, 59, 60, 62, 64, 65, 69, 70, 76, 78, 79, 84, 89, 92, 106, 108, 113, 116, 131, 138, 143, 145, 167, 187, 205, 213], "which": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 72, 73, 74, 76, 78, 81, 84, 89, 91, 92, 99, 101, 108, 109, 111, 113, 115, 116, 119, 127, 131, 136, 143, 159, 182, 186, 187, 196, 197, 209, 210], "compat": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 53, 54, 59, 60, 62, 64, 65, 69, 70, 76, 78, 99, 136, 182, 185], "5669": [15, 17, 53, 54, 62], "more": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 53, 54, 58, 62, 65, 67, 72, 76, 77, 81, 84, 94, 97, 109, 113, 116, 119, 127, 129, 133, 134, 135, 136, 137, 144, 147, 167, 170, 181, 182, 185, 186, 200, 205, 206, 207, 209, 212, 215], "hubertforctctestspec": 15, "paper": [15, 53, 54, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 78, 84, 109, 112, 113, 115, 116, 187, 200, 215], "abstract": [15, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 84, 113, 115, 116, 123, 182, 185, 200, 215], "approach": [15, 53, 70, 71, 78, 84, 96, 98, 99, 109, 111, 113, 116, 117, 119, 120, 148, 212], "challeng": [15, 39, 53, 65, 67, 70, 71, 84], "three": [15, 117, 128], "uniqu": 15, "problem": [15, 39, 59, 67, 116, 117], "multipl": [15, 39, 54, 62, 79, 84, 89, 108, 129, 159, 167, 187, 196], "sound": 15, "each": [15, 17, 28, 39, 43, 64, 66, 72, 74, 75, 79, 81, 84, 87, 88, 89, 92, 93, 94, 96, 98, 99, 101, 103, 106, 108, 109, 111, 117, 119, 120, 127, 129, 135, 144, 159, 166, 185, 186, 187, 199, 210], "input": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 143, 144, 146, 147, 150, 159, 166, 170, 181, 182, 183, 185, 186, 187, 196, 197, 199, 200, 209, 210, 213, 215], "utter": 15, "lexicon": 15, "dure": [15, 28, 39, 43, 65, 98, 99, 103, 108, 117, 160, 167, 205], "phase": [15, 65, 187], "variabl": [15, 66, 74, 183, 185, 187], "explicit": [15, 108, 113], "segment": [15, 51, 53, 65, 70, 130, 131], "deal": [15, 143, 213], "bert": [15, 20, 22, 23, 24, 26, 30, 33, 34, 37, 41, 44, 46, 48, 59, 60, 61, 64, 65, 69, 70, 71, 76, 77, 78, 99, 100, 116], "util": [15, 63, 98, 108, 109, 120, 145, 152, 153, 155, 157, 160, 161, 165, 169], "offlin": [15, 167], "cluster": [15, 73, 160], "step": [15, 28, 39, 43, 66, 74, 99, 103, 167, 183, 187, 205, 209], "align": 15, "target": [15, 73, 115, 129, 134, 143, 170], "label": [15, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 53, 54, 55, 57, 79, 86, 96, 97, 98, 99, 102, 103, 111, 112, 116, 117, 123, 167, 173, 188, 196, 205, 209], "loss": [15, 59, 65, 99, 116, 187, 205], "ingredi": 15, "our": [15, 59, 62, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 84, 109, 113, 116, 159, 170, 214], "appli": [15, 28, 39, 43, 54, 58, 79, 81, 99, 100, 103, 108, 116, 117, 119, 133, 137, 159, 187, 196], "over": [15, 65, 76, 77, 78, 119, 129, 159, 167, 182, 205], "region": 15, "onli": [15, 55, 57, 58, 67, 73, 78, 89, 92, 101, 108, 109, 113, 116, 126, 131, 145, 183, 184, 187, 196], "forc": 15, "combin": [15, 65, 69, 75, 84, 116, 117, 119, 186, 187], "acoust": [15, 187], "continu": [15, 97, 113, 138, 187, 205], "reli": [15, 55, 57, 78, 84], "primarili": 15, "consist": [15, 59, 64, 69, 92, 106, 112, 131, 146, 185, 187, 199], "unsupervis": [15, 76, 77, 78, 84, 113], "rather": 15, "than": [15, 39, 43, 65, 66, 74, 76, 77, 78, 84, 86, 94, 98, 113, 119, 120, 185, 209], "intrins": 15, "qualiti": [15, 53, 113], "assign": [15, 39, 79, 100, 111], "simpl": [15, 60, 61, 79, 113, 187, 210], "k": [15, 113, 116, 136, 187], "mean": [15, 18, 39, 76, 84, 86, 89, 91, 113, 115, 116, 127, 136, 143, 187, 209, 210, 213], "teacher": 15, "two": [15, 39, 53, 55, 57, 59, 64, 73, 75, 76, 77, 81, 128, 187, 196, 209], "iter": [15, 55, 57, 59, 66, 74, 106, 131, 167, 186, 205], "either": [15, 28, 43, 54, 57, 62, 63, 72, 79, 84, 86, 92, 111, 112, 116, 134, 135, 143, 144, 146, 170, 186, 210], "match": [15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 74, 76, 77, 78, 79, 88, 89, 90, 91, 92, 93, 101, 106, 108, 113, 129, 131, 134, 185, 186, 208], "improv": [15, 59, 60, 61, 62, 64, 67, 70, 71, 76, 77, 98, 99, 113, 187, 214], "upon": [15, 84], "state": [15, 19, 21, 22, 24, 25, 27, 28, 29, 31, 32, 34, 36, 38, 39, 40, 42, 43, 45, 47, 49, 53, 54, 59, 60, 61, 62, 67, 69, 70, 71, 78, 84, 99, 113, 116, 144, 181, 185, 186, 187, 206, 209], "art": [15, 28, 39, 53, 54, 59, 60, 61, 62, 67, 69, 70, 71, 78, 84, 99, 113, 116, 144], "wav2vec": [15, 17], "perform": [15, 53, 54, 58, 59, 62, 64, 65, 67, 70, 71, 73, 75, 76, 77, 78, 99, 112, 113, 119, 186, 187], "librispeech": 15, "960h": 15, "libri": 15, "60": [15, 65, 108], "000h": 15, "benchmark": [15, 54, 59, 64, 65, 67, 76, 77, 116], "10min": 15, "1h": 15, "10h": 15, "100h": 15, "fine": [15, 51, 60, 61, 65, 116], "tune": [15, 51, 60, 61, 65, 116], "subset": 15, "1b": 15, "19": [15, 94, 199], "13": [15, 18, 51, 76, 77, 81, 106, 133, 137], "rel": [15, 62, 64, 76, 89, 91, 98, 117, 208], "wer": 15, "reduct": [15, 59, 119], "dev": [15, 53, 59, 67, 73], "test": [15, 28, 39, 43, 53, 54, 55, 57, 60, 61, 73, 75, 87, 88, 92, 93, 98, 99, 103, 106, 113, 119, 120, 124, 131, 196, 197, 199, 200, 209, 215], "evalu": [15, 28, 39, 43, 62, 69, 76, 77, 103, 150, 167], "batchsiz": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 76, 77, 78, 99, 115, 117], "size": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 74, 75, 76, 77, 78, 81, 84, 99, 102, 113, 115, 116, 117, 119, 185, 186, 187, 208, 213, 214], "batch": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 76, 77, 78, 99, 102, 115, 117, 181, 186, 187], "ml": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 132, 134, 135, 136, 141, 143, 144, 145, 146, 147, 167, 205, 209, 213], "audioassembl": [15, 17, 132], "audio_cont": [15, 17, 132], "setstag": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 134, 136, 146, 147, 209, 210], "processedaudiofloat": [15, 17], "createdatafram": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 144, 146, 147, 159, 167, 205, 208, 209, 210, 214], "rawfloat": [15, 17], "todf": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 141, 144, 146, 147, 159, 208, 209, 210, 214], "fit": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 134, 136, 143, 145, 146, 147, 166, 167, 186, 205, 209, 210, 213], "select": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 63, 65, 75, 81, 84, 86, 98, 99, 112, 113, 116, 117, 119, 120, 126, 131, 132, 135, 137, 138, 141, 144, 146, 147, 159, 167, 205, 210], "mister": [15, 17], "quilter": [15, 17], "THE": [15, 17, 58], "apostl": [15, 17], "OF": [15, 17, 59], "midl": [15, 17], "clase": [15, 17], "AND": [15, 17], "glad": [15, 17], "TO": [15, 17, 196, 215], "hi": [15, 17, 109], "gospel": [15, 17], "setconfigprotobyt": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 86, 99, 102, 113, 115, 116, 117], "b": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 86, 88, 93, 97, 98, 99, 100, 102, 108, 113, 115, 116, 117, 143, 159, 170, 187, 196, 200, 215], "configproto": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 86, 99, 102, 113, 115, 116, 117], "tensorflow": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 84, 86, 99, 102, 113, 115, 116, 117, 173, 184, 186, 188], "serial": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 79, 86, 99, 102, 113, 115, 116, 117, 160], "loadsavedmodel": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 113, 115, 116], "folder": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 99, 103, 109, 113, 115, 116, 120, 123, 196], "spark_sess": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 113, 115, 116], "save": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 99, 103, 109, 113, 115, 116, 160, 167, 173, 188, 205, 209], "restor": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131], "lang": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 81, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 170], "en": [15, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 78, 81, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 170, 197, 215], "remote_loc": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 170], "download": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 81, 86, 87, 88, 93, 98, 99, 100, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 160, 170, 208, 209, 212, 213], "option": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 84, 86, 87, 88, 92, 93, 98, 99, 101, 103, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 132, 135, 139, 140, 143, 144, 158, 159, 160, 166, 167, 170, 186, 187, 196, 197, 199, 200, 209], "remot": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 170], "address": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131], "resourc": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 86, 87, 88, 92, 93, 98, 99, 101, 103, 106, 109, 111, 112, 113, 115, 116, 117, 119, 120, 122, 124, 129, 131, 145, 155, 158, 169, 196, 197, 199, 200, 209, 215], "Will": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 108, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131], "repositori": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 170, 206], "otherwis": [15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 86, 87, 88, 93, 98, 99, 106, 109, 112, 113, 115, 116, 117, 119, 120, 122, 129, 131, 134, 167, 187], "hubert_for_ctc": 16, "wav2vec2_for_ctc": 16, "wav2vec2forctc": 17, "wav2vec2": 17, "alexei": 17, "baevski": 17, "henri": 17, "zhou": 17, "michael": [17, 124], "auli": 17, "asr_wav2vec2_base_960h": 17, "wav2vec2forctctestspec": 17, "pattern": [18, 58, 79, 89, 92, 101, 119, 120, 127, 129, 131, 187], "tag": [18, 28, 39, 43, 58, 62, 96, 97, 98, 99, 100, 105, 106, 131, 159, 167, 196, 199, 200, 215], "order": [18, 78, 79, 84, 119, 120, 143, 147, 159, 185, 187, 209, 210, 213, 215], "meaning": [18, 121], "phrase": [18, 62, 66, 74, 88, 93], "extract": [18, 19, 22, 25, 29, 32, 36, 40, 45, 55, 63, 75, 79, 80, 81, 83, 84, 88, 89, 91, 93, 97, 98, 99, 100, 108, 109, 111, 117, 120, 124, 128, 133, 136, 137, 138, 143, 160, 167, 170, 205], "onto": [18, 159, 210], "sentenc": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 97, 98, 99, 100, 106, 112, 115, 117, 122, 124, 127, 128, 131, 133, 135, 137, 143, 144, 146, 147, 160, 170, 173, 188, 196, 197, 199, 200, 209, 213, 214], "regular": [18, 92, 98, 108, 187], "express": [18, 43, 51, 89, 92, 108], "wrap": [18, 148, 149, 156, 162, 166, 187], "angl": 18, "bracket": 18, "easili": [18, 67, 106, 136, 205], "distinguish": 18, "itself": [18, 84, 116, 145, 210], "form": [18, 28, 39, 43, 75, 79, 87, 88, 89, 92, 93, 109, 111, 119, 120, 131, 136, 167, 186, 196, 197, 209], "peter": [18, 69, 87, 101, 106, 109, 119, 121, 196], "piper": [18, 87, 106, 121], "employe": [18, 87, 106, 121], "pick": [18, 87, 106, 121], "peck": [18, 87, 106, 121], "pickl": [18, 87, 106, 121], "pepper": [18, 87, 106, 121], "nnp": [18, 106, 143, 159, 196, 197, 199, 200, 208, 213, 214, 215], "nn": [18, 106, 182, 196, 197, 199, 200, 215], "vbp": [18, 106, 143, 197, 208, 213, 214], "vbg": [18, 106], "IN": [18, 106, 143, 159, 197, 199, 200, 208, 213, 214], "jj": [18, 106, 143, 159, 196, 199, 208, 213, 214, 215], "regexpars": 18, "e": [18, 20, 21, 23, 24, 26, 27, 30, 31, 33, 34, 37, 38, 41, 42, 46, 47, 48, 49, 57, 58, 67, 69, 79, 81, 98, 99, 113, 115, 116, 117, 122, 146, 167, 187, 205], "g": [18, 20, 21, 23, 24, 26, 27, 30, 31, 33, 34, 37, 38, 41, 42, 46, 47, 48, 49, 57, 58, 67, 81, 98, 99, 113, 115, 116, 117, 122, 146, 167, 187, 205], "setregexpars": 18, "when": [18, 20, 23, 30, 33, 37, 41, 46, 48, 54, 58, 59, 81, 89, 91, 94, 99, 113, 117, 119, 122, 126, 131, 133, 143, 187, 196, 209, 210, 213], "defin": [18, 97, 98, 99, 122, 126, 133, 137, 159, 167, 170, 185, 205, 209, 213], "enclos": 18, "treat": 18, "group": [18, 129, 187], "so": [18, 28, 43, 84, 97, 109, 145, 167, 186, 187, 205], "here": [18, 87, 159, 187, 209], "specif": [18, 44, 55, 57, 58, 60, 61, 65, 73, 81, 84, 99, 113, 123, 143, 145, 167, 173, 188, 213], "noun": [18, 197], "success": [18, 62, 113], "grammar": 18, "parser": [18, 55, 57, 81], "perceptronmodel": [18, 55, 57, 81, 98, 106, 196], "Of": [18, 59, 131], "documentassembl": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 98, 99, 100, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 124, 126, 127, 128, 129, 131, 134, 135, 136, 144, 145, 146, 147, 167, 196, 205, 209], "sentencedetector": [18, 28, 44, 51, 55, 57, 61, 63, 71, 73, 77, 81, 84, 87, 92, 94, 98, 99, 100, 106, 108, 109, 122, 124, 145, 147, 196, 209, 210], "postag": 18, "selectexpr": [18, 28, 44, 51, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 87, 88, 89, 91, 92, 93, 94, 97, 100, 101, 106, 108, 109, 111, 115, 121, 122, 124, 127, 128, 129, 133, 134, 136, 137, 159, 196, 197, 199, 208, 209, 214], "explod": [18, 28, 44, 51, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 88, 91, 92, 93, 94, 97, 100, 106, 108, 109, 115, 128, 133, 136, 137, 159, 196, 199, 208, 209, 214], "11": [18, 76, 77, 89, 91, 94, 106], "21": [18, 89, 91, 100, 106], "35": [18, 106], "39": [18, 100, 106, 199], "52": [18, 100, 106, 199], "58": [18, 53, 106], "albertforquestionansw": 19, "classifi": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 84, 136, 209], "dl": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 86, 99, 119, 120], "albert": [19, 20, 21, 59], "span": [19, 22, 25, 29, 32, 36, 40, 45, 116], "question": [19, 22, 25, 29, 32, 36, 40, 44, 45, 55, 57, 60, 61, 67, 70, 71, 78, 106, 113, 116, 143], "answer": [19, 22, 25, 29, 32, 36, 40, 44, 45, 55, 57, 60, 61, 67, 78, 113, 116, 143], "task": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 53, 54, 59, 60, 61, 62, 64, 65, 69, 73, 76, 77, 78, 84, 113, 115, 116, 145, 187], "squad": [19, 22, 25, 29, 32, 36, 40, 45, 59, 60, 61, 64, 70, 71], "linear": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 53, 113, 187], "layer": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 59, 60, 61, 64, 67, 78, 186, 187], "comput": [19, 22, 25, 29, 32, 36, 40, 45, 53, 54, 59, 64, 65, 73, 113, 115, 120, 143, 183, 186, 187, 213], "logit": [19, 20, 22, 23, 25, 26, 29, 32, 33, 36, 37, 40, 41, 45, 46, 48], "spanclassifi": [19, 22, 25, 29, 32, 36, 40, 45], "document_quest": [19, 22, 25, 29, 32, 36, 40, 44, 45], "document_context": [19, 22, 25, 29, 32, 36, 40, 45], "albert_base_qa_squad2": 19, "larg": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 53, 54, 59, 64, 65, 67, 76, 77, 78, 84, 86, 88, 93, 99, 113, 187], "allow": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 53, 67, 73, 98, 99, 101, 108, 109, 127, 129, 145, 173, 186, 187, 188], "faster": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 65, 67, 119, 120, 185], "casesensit": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 76, 77, 78, 88, 93, 119, 122], "whether": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 58, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 79, 81, 88, 89, 91, 93, 94, 97, 98, 99, 101, 103, 108, 109, 113, 116, 117, 119, 122, 127, 129, 131, 134, 136, 137, 138, 143, 146, 147, 150, 160, 170, 187, 196, 200, 210], "ignor": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 76, 77, 78, 88, 94, 97, 113, 115, 116, 119, 122, 143], "case": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 76, 77, 78, 79, 86, 88, 93, 117, 119, 122, 129, 134, 181, 185, 187, 196, 197, 209], "configprotobyt": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 76, 77, 78, 86, 99, 113, 115, 116, 117], "maxsentencelength": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 51, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 78], "128": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 48, 49, 59, 60, 61, 62, 64, 65, 70, 71, 76, 77, 78, 167, 187, 205], "multidocumentassembl": [19, 22, 25, 29, 32, 36, 40, 44, 45, 144], "context": [19, 22, 25, 29, 32, 36, 40, 45, 60, 61, 66, 67, 74, 78, 112, 117, 129], "setcasesensit": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 63, 65, 69, 70, 76, 88, 93, 98, 119, 122, 136, 147], "what": [19, 22, 25, 29, 32, 36, 40, 43, 45, 55, 57, 84, 86, 115, 117, 126, 197, 206], "my": [19, 21, 22, 24, 25, 28, 29, 31, 32, 34, 36, 38, 40, 42, 43, 45, 47, 49, 58, 92, 94, 108, 113, 122, 124, 127, 209], "clara": [19, 22, 25, 29, 32, 36, 40, 45], "live": [19, 21, 22, 24, 25, 29, 31, 32, 34, 36, 38, 40, 42, 45, 47, 49, 113, 167, 205], "berkelei": [19, 22, 25, 29, 32, 36, 40, 45], "setmaxsentencelength": [19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 45, 46, 47, 48, 49, 51, 59, 60, 61, 62, 64, 65, 66, 69, 70, 71, 74, 76, 77, 78], "albertforsequenceclassif": [20, 30], "sequenc": [20, 23, 26, 30, 33, 37, 41, 46, 48, 54, 69, 113, 114, 115, 116, 117, 122, 181, 182, 185, 186], "regress": [20, 23, 26, 30, 33, 37, 41, 46, 48, 116], "pool": [20, 23, 26, 30, 33, 37, 41, 46, 48, 63, 67, 72], "multi": [20, 23, 26, 28, 30, 33, 37, 39, 41, 43, 46, 48, 59, 73, 76, 77, 84, 86, 115], "sequenceclassifi": [20, 23, 26, 30, 33, 37, 41, 46, 48], "albert_base_sequence_classifier_imdb": 20, "coalescesent": [20, 23, 26, 30, 33, 37, 41, 46, 48, 86], "instead": [20, 23, 26, 30, 33, 37, 41, 46, 48, 61, 84, 86, 89, 91, 116, 136, 137, 143, 181, 183, 213], "per": [20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 46, 47, 48, 49, 76, 77, 86, 89, 94, 96, 97, 98, 99, 143, 159, 170, 186, 187, 196], "inputcol": [20, 23, 26, 28, 30, 33, 37, 39, 41, 43, 46, 48, 72, 86, 132, 135, 136, 137, 138, 141, 144], "averag": [20, 23, 26, 30, 33, 37, 41, 44, 46, 48, 63, 72, 76, 77, 86, 99, 106], "probabl": [20, 23, 26, 30, 33, 37, 41, 46, 48, 84, 113, 116, 119], "calcul": [20, 23, 26, 28, 33, 37, 39, 41, 43, 46, 48, 75, 94, 99, 103, 111, 186, 187], "via": [20, 23, 26, 33, 37, 41, 46, 48, 73, 141, 160, 187], "softmax": [20, 23, 26, 33, 37, 41, 46, 48, 64, 66, 74, 117, 181], "sigmoid": [20, 23, 26, 33, 37, 41, 46, 48, 183], "love": [20, 23, 28, 30, 33, 37, 41, 46, 48, 61, 71, 77, 109, 112, 209], "movi": [20, 23, 28, 30, 33, 37, 41, 43, 46, 48, 112, 209], "child": [20, 23, 30, 33, 37, 41, 46, 48], "pretti": [20, 23, 30, 33, 37, 39, 41, 46, 48, 84], "bore": [20, 23, 30, 33, 37, 41, 46, 48], "neg": [20, 23, 26, 30, 33, 37, 41, 43, 46, 48, 111, 112, 167, 205], "getclass": [20, 21, 23, 24, 26, 27, 30, 31, 33, 34, 37, 38, 41, 42, 46, 47, 48, 49, 53, 54], "setcoalescesent": [20, 23, 26, 30, 33, 37, 41, 46, 48, 86], "limit": [20, 23, 26, 30, 33, 37, 41, 46, 48, 53, 54, 59, 62, 69, 75, 78, 84, 116, 119], "almost": [20, 23, 26, 30, 33, 37, 41, 46, 48], "512": [20, 23, 26, 30, 33, 37, 41, 44, 46, 48, 67], "help": [20, 23, 26, 30, 33, 37, 41, 46, 48, 55, 57, 59, 115, 129, 167, 205, 210, 214], "feed": [20, 23, 26, 30, 33, 37, 41, 46, 48, 181], "entir": [20, 23, 26, 30, 33, 37, 41, 46, 48, 115, 182, 185], "bool": [20, 23, 26, 30, 33, 37, 41, 46, 48, 58, 61, 63, 73, 79, 81, 86, 88, 89, 93, 94, 97, 98, 99, 101, 103, 108, 109, 113, 116, 117, 119, 122, 127, 129, 131, 134, 136, 137, 138, 143, 146, 150, 160, 167, 170, 196], "one": [20, 23, 26, 30, 33, 37, 39, 41, 46, 48, 51, 55, 57, 58, 60, 61, 72, 76, 77, 78, 84, 86, 89, 92, 97, 109, 119, 124, 147, 186, 187, 205, 209], "albertfortokenclassif": [21, 59], "recognit": [21, 24, 27, 31, 34, 38, 42, 47, 49, 54, 62, 95, 98, 99, 187], "ner": [21, 24, 27, 31, 34, 38, 42, 47, 49, 76, 77, 81, 82, 124, 143, 159, 160, 167, 170, 173, 188, 205], "token_classifi": [21, 27, 38, 42, 47, 49], "albert_base_token_classifier_conll03": 21, "albertembed": [21, 59], "level": [21, 28, 39, 43, 60, 61, 69, 70, 71, 73, 75, 77, 79, 98, 99, 103, 117, 160, 196], "tokenclassifi": [21, 24, 27, 31, 34, 38, 42, 47, 49], "john": [21, 24, 31, 34, 38, 42, 47, 49, 51, 61, 71, 77, 79, 81, 100, 101, 109, 138], "lenon": [21, 24, 31, 34, 38, 42, 47, 49], "born": [21, 24, 31, 34, 38, 42, 47, 49, 113], "london": [21, 24, 31, 34, 38, 42, 47, 49], "pari": [21, 24, 31, 34, 38, 42, 47, 49], "sarah": [21, 24, 31, 34, 38, 42, 47, 49], "o": [21, 24, 27, 31, 34, 38, 42, 47, 49, 97, 98, 99, 100, 143, 159, 170, 187, 196, 200, 215], "loc": [21, 24, 27, 31, 34, 38, 42, 47, 49, 81, 97, 98, 99, 133, 137, 143, 159, 170, 196], "bertforquestionansw": [22, 44], "bert_base_cased_qa_squad2": 22, "bertforsequenceclassif": 23, "bert_base_sequence_classifier_imdb": 23, "bertfortokenclassif": 24, "bert_base_token_classifier_conll03": 24, "camembertforquestionansw": 25, "camembert": [25, 26, 27, 62], "camembert_base_qa_fquad": 25, "fr": [25, 26, 62, 86], "camembertforsequenceclassif": 26, "sequence_classifi": 26, "camembert_base_sequence_classifier_allocin": 26, "j": [26, 79, 187], "ai": [26, 167, 205], "ador\u00e9": 26, "ce": 26, "film": 26, "lorsqu": 26, "\u00e9tai": 26, "enfant": 26, "je": 26, "d\u00e9test": 26, "\u00e7a": 26, "camembertfortokenclassif": 27, "camembert_base_token_classifier_wikin": 27, "georg": 27, "washington": 27, "est": [27, 62, 86, 115], "all\u00e9": 27, "\u00e0": 27, "classifierdl": [28, 209], "classifierdlapproach": [28, 39, 209], "gener": [28, 39, 53, 59, 63, 65, 69, 72, 78, 81, 84, 98, 99, 109, 113, 116, 117, 119, 120, 137, 138, 167, 173, 188, 205, 208, 209, 210], "univers": [28, 55, 57, 73, 115], "encod": [28, 58, 60, 61, 64, 69, 73, 115, 167], "deep": [28, 60, 61, 67, 84, 98, 109, 117, 187], "dnn": 28, "insid": [28, 39, 97, 106, 129, 182, 196], "instanti": [28, 39, 43, 55, 57, 66, 74, 75, 79, 87, 88, 92, 93, 98, 99, 101, 106, 109, 111, 112, 117, 119, 120, 124, 126, 131, 196, 197], "classifierdlmodel": [28, 39, 209], "monitor": [28, 39, 43, 99, 167, 205], "metric": [28, 39, 43, 99, 120, 167], "done": [28, 39, 43, 70, 71, 98, 99, 210], "settestdataset": [28, 39, 43, 99, 103], "expect": [28, 39, 43, 78, 99, 129, 159, 185], "path": [28, 39, 43, 55, 57, 66, 74, 75, 79, 81, 87, 88, 92, 93, 98, 99, 101, 103, 109, 111, 113, 117, 119, 120, 123, 129, 141, 143, 158, 167, 170, 173, 188, 196, 197, 199, 200, 205], "parquet": [28, 39, 43, 99, 103, 132], "datafram": [28, 39, 43, 53, 54, 75, 99, 103, 106, 131, 143, 155, 159, 166, 167, 170, 196, 197, 199, 200, 205, 209, 213, 215], "ha": [28, 39, 43, 44, 53, 54, 58, 59, 64, 65, 67, 70, 71, 75, 84, 87, 92, 99, 103, 109, 111, 116, 119, 120, 131, 132, 134, 141, 143, 167, 185, 186, 187, 199, 205, 209, 210], "same": [28, 39, 43, 51, 59, 70, 75, 76, 79, 81, 99, 103, 116, 145, 167, 186, 187, 210], "follow": [28, 39, 43, 51, 58, 67, 69, 75, 84, 89, 91, 92, 97, 99, 101, 108, 128, 146, 182, 183, 205, 207, 210], "universalsentenceencod": [28, 39, 43, 73, 167, 205, 209], "preprocessingpipelin": [28, 39, 43, 99, 103], "randomsplit": [28, 39, 43, 99, 103], "write": [28, 39, 43, 75, 99, 103, 119, 120, 210], "overwrit": [28, 39, 43, 99, 100, 103, 167], "test_data": [28, 39, 43, 99, 103], "setlabelcolumn": [28, 39, 43, 96, 98, 99, 102, 123, 167, 173, 188, 205, 209], "usag": [28, 39, 43, 51, 55, 57, 58, 59, 60, 61, 62, 63, 65, 67, 70, 73, 75, 76, 78, 79, 84, 86, 87, 89, 91, 92, 93, 98, 99, 101, 106, 108, 109, 111, 112, 115, 116, 117, 119, 121, 122, 126, 129, 131], "64": [28, 39, 43, 59, 99, 102, 173, 188, 209], "dropout": [28, 43, 99, 187], "coeffici": [28, 43, 98, 99], "5": [28, 39, 43, 51, 53, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 84, 86, 89, 91, 94, 97, 99, 106, 113, 131, 136, 143, 159, 167, 170, 187, 197, 199, 200, 205, 208, 209, 215], "enableoutputlog": [28, 39, 43, 99], "stdout": [28, 39, 43, 99, 103], "addit": [28, 39, 43, 55, 57, 60, 61, 79, 98, 99, 103, 108, 113, 129, 167, 187, 208, 209], "evaluationlogextend": [28, 39, 43, 99], "valid": [28, 39, 43, 89, 99, 103, 109, 117, 205], "time": [28, 39, 43, 59, 66, 74, 76, 77, 84, 89, 103, 112, 117, 131, 160, 181, 182, 183, 186, 187, 208, 209, 213, 214], "labelcolumn": [28, 39, 43, 98, 99], "lr": [28, 39, 43, 99], "rate": [28, 39, 43, 66, 70, 71, 74, 75, 99, 102, 117], "005": [28, 43, 99, 102], "maxepoch": [28, 39, 43, 98, 99], "maximum": [28, 39, 43, 51, 66, 74, 81, 84, 96, 98, 99, 101, 102, 108, 109, 113, 115, 116, 117, 119, 127, 129], "epoch": [28, 39, 43, 96, 98, 99, 102, 103, 109, 117, 167], "30": [28, 43, 84, 89, 91, 97, 102, 115, 143, 159, 170, 208], "outputlogspath": [28, 39, 43, 99, 109], "randomse": [28, 39, 43, 98, 99], "random": [28, 39, 43, 66, 74, 96, 98, 99, 102, 136], "seed": [28, 39, 43, 66, 74, 96, 98, 99, 102], "shuffl": [28, 39, 96, 102], "testdataset": [28, 39, 43, 99, 167, 205], "statist": [28, 39, 43, 75, 84, 99, 103], "validationsplit": [28, 39, 43, 99, 109], "choos": [28, 39, 43, 63, 72, 99, 109, 119], "proport": [28, 39, 43, 99, 103, 109], "against": [28, 39, 43, 79, 84, 88, 93, 99, 103, 109, 145], "between": [28, 39, 43, 53, 55, 57, 70, 71, 73, 76, 77, 78, 81, 99, 103, 108, 109, 117, 186, 187], "off": [28, 39, 43, 73, 76, 77, 99, 103, 109, 186], "verbos": [28, 39, 43, 98, 99, 103], "multiclassifierdlapproach": [28, 39, 167, 205], "sentimentdlapproach": [28, 39, 43], "analysi": [28, 39, 43, 67, 78, 110, 111, 116, 133, 152, 187, 210], "accept": [28, 39, 43, 186], "singl": [28, 39, 43, 75, 81, 84, 124, 126, 129, 185, 186, 187, 196], "item": [28, 43, 75, 167, 205], "doubl": [28, 43, 132, 146], "sentenceembed": [28, 39, 43, 72, 75, 136], "In": [28, 39, 43, 54, 62, 64, 65, 69, 75, 78, 79, 84, 86, 87, 88, 92, 93, 108, 109, 111, 113, 116, 119, 120, 131, 167, 173, 182, 187, 199, 205, 209, 210, 214, 215], "csv": [28, 43, 79, 103, 146, 209], "best": [28, 43, 59, 62, 70, 71, 84, 86, 99, 187, 209], "wach": [28, 209], "ever": [28, 43, 58, 209], "opinion": [28, 43, 209], "win": [28, 43, 209], "award": [28, 43, 209], "terribl": [28, 43, 209], "act": [28, 43, 187, 209], "bad": [28, 43, 111, 167, 205, 209], "realli": [28, 43, 112, 209], "trane": 28, "smallcorpu": [28, 43, 209], "read": [28, 43, 53, 54, 55, 57, 66, 74, 84, 87, 88, 89, 91, 92, 93, 98, 101, 103, 109, 111, 113, 117, 119, 120, 129, 131, 132, 135, 141, 144, 155, 158, 161, 167, 187, 196, 197, 199, 200, 205, 209, 215], "header": [28, 43, 44, 146, 209], "src": [28, 43, 53, 54, 55, 57, 75, 87, 88, 92, 93, 98, 99, 106, 119, 120, 124, 131, 196, 197, 199, 200, 209, 215], "useembed": [28, 39, 43, 73, 209], "docclassifi": [28, 39, 43, 209], "setbatchs": [28, 39, 43, 67, 99, 102, 117, 167, 173, 188, 205, 209], "setmaxepoch": [28, 39, 43, 96, 98, 99, 102, 167, 173, 188, 205, 209], "20": [28, 44, 78, 97, 113, 143, 146, 159, 170, 187, 209], "setlr": [28, 39, 43, 99, 102, 167, 205, 209], "5e": [28, 43, 209], "setdropout": [28, 43, 99, 209], "pipelinemodel": [28, 39, 43, 55, 57, 58, 66, 74, 98, 99, 112, 117, 119, 120, 131, 143, 145, 167, 209, 212], "v": [28, 39, 43, 64, 75, 84, 86, 88, 99, 102, 103, 120, 159, 187], "classifierdl_use_trec6": 28, "trec": 28, "multiclassifierdlmodel": [28, 39], "sentimentdlmodel": [28, 39, 43], "sarcasmdl": [28, 209], "classifierdl_use_sarcasm": [28, 209], "sarcasm": [28, 209], "m": [28, 89, 91, 209], "could": [28, 65, 84, 92, 103, 117, 208, 209, 210], "put": [28, 159, 173, 182, 188, 209], "word": [28, 53, 54, 55, 57, 59, 63, 64, 66, 67, 70, 72, 73, 74, 75, 78, 79, 81, 84, 87, 94, 97, 100, 101, 106, 111, 113, 115, 116, 117, 119, 120, 121, 122, 126, 129, 130, 131, 143, 159, 170, 199, 200, 208, 209], "much": [28, 44, 59, 70, 71, 101, 131, 160, 182, 185, 209], "wake": [28, 209], "am": [28, 89, 91, 113, 124, 209], "mondai": [28, 209], "would": [28, 51, 63, 72, 89, 109, 160, 186, 209], "arrays_zip": [28, 55, 57, 84, 209], "out": [28, 84, 87, 101, 113, 115, 116, 121, 122, 209], "normal": [28, 58, 82, 88, 109, 112, 122, 136, 145, 147, 160, 187, 209, 210], "debertaforquestionansw": 29, "deberta": [29, 30, 31, 64], "deberta_v3_xsmall_qa_squad2": 29, "debertaforsequenceclassif": 30, "v2": [30, 31, 60, 61, 64], "v3": [30, 31], "deberta_v3_xsmall_sequence_classifier_imdb": 30, "deberta_base_sequence_classifier_imdb": 30, "debertafortokenclassif": 31, "deberta_v3_xsmall_token_classifier_conll03": 31, "distilbertforquestionansw": 32, "distilbert": [32, 33, 65], "distilbert_base_cased_qa_squad2": 32, "distilbertforsequenceclassif": 33, "distilbert_base_sequence_classifier_imdb": 33, "distilbertfortokenclassif": 34, "distilbert_base_token_classifier_conll03": 34, "albert_for_sequence_classif": [35, 82], "albert_for_token_classif": [35, 82], "bert_for_sequence_classif": [35, 82], "bert_for_token_classif": [35, 82], "camembert_for_sequence_classif": [35, 82], "camembert_for_token_classif": [35, 82], "deberta_for_sequence_classif": [35, 82], "deberta_for_token_classif": [35, 82], "distil_bert_for_sequence_classif": [35, 82], "distil_bert_for_token_classif": [35, 82], "longformer_for_sequence_classif": [35, 82], "longformer_for_token_classif": [35, 82], "multi_classifier_dl": [35, 82], "roberta_for_sequence_classif": [35, 82], "roberta_for_token_classif": [35, 82], "sentiment_dl": [35, 82], "xlm_roberta_for_sequence_classif": [35, 82], "xlm_roberta_for_token_classif": [35, 82], "xlnet_for_sequence_classif": [35, 82], "xlnet_for_token_classif": [35, 82], "longformerforquestionansw": 36, "longform": [36, 37, 38, 69], "longformer_base_base_qa_squad2": 36, "longformerforsequenceclassif": 37, "longformer_base_sequence_classifier_imdb": 37, "4096": [37, 59, 69], "longformerfortokenclassif": 38, "xlnet_base_token_classifier_conll03": [38, 49], "longformer_base_token_classifier_conll03": 38, "multiclassifierdl": 39, "bidirect": [39, 60, 61, 67, 78, 186, 187], "gru": [39, 183, 187], "convolut": [39, 54, 187], "machin": [39, 66, 74, 84, 98, 113, 115, 116, 167, 187, 207], "strongli": 39, "relat": [39, 55, 57, 81, 214], "variant": [39, 69, 73], "mai": [39, 134, 181, 185, 187, 208, 209, 210, 213, 214], "instanc": [39, 102, 103, 150, 154, 160, 161, 165, 186], "multiclass": 39, "categor": 39, "precis": [39, 55, 57], "constraint": 39, "mani": [39, 64, 70, 71, 84, 113, 115, 116, 131, 181], "formal": 39, "find": [39, 55, 57, 70, 71, 73, 79, 81, 87, 89, 113], "binari": [39, 141, 155, 167], "bertsentenceembed": [39, 43, 61, 71, 77], "multiclassifi": [39, 167, 205], "001": [39, 98, 99, 187], "10": [39, 51, 55, 84, 89, 91, 100, 119, 167, 182, 208], "44": [39, 66, 74, 106], "shuffleperepoch": 39, "threshold": [39, 43, 66, 74, 84, 86, 98, 117, 131], "minimum": [39, 43, 66, 74, 81, 84, 86, 96, 98, 99, 101, 108, 109, 113, 116, 119, 120, 127, 129, 196], "ed58abb40640f983": 39, "pn": 39, "newsyou": 39, "toxic": 39, "a1237f726b5f5d89": 39, "dude": 39, "place": [39, 54], "obscen": 39, "insult": 39, "24b0d6c8733c2abe": 39, "thank": [39, 78, 84], "8c4478fb239bcfc0": 39, "gee": 39, "minut": 39, "traindataset": [39, 167, 205], "printschema": [39, 132, 135, 141, 144], "root": [39, 51, 55, 57, 81, 132, 135, 141, 144, 197], "setcleanupmod": [39, 135, 144], "shrink": [39, 135, 144], "1e": [39, 167, 205], "setthreshold": [39, 43, 84, 86, 167, 205], "setvalidationsplit": [39, 103, 109, 173, 188], "setverbos": [39, 98, 99, 103, 173, 188], "multiclassifierdl_use_tox": 39, "comment": [39, 84], "jigsaw": 39, "good": [39, 62, 65, 73, 112], "stuff": 39, "wtf": 39, "kind": [39, 84, 89, 91], "crap": 39, "robertaforquestionansw": 40, "roberta": [40, 41, 42, 45, 46, 47, 62, 64, 69, 70, 71, 76, 77], "roberta_base_qa_squad2": 40, "robertaforsequenceclassif": 41, "roberta_base_sequence_classifier_imdb": 41, "robertafortokenclassif": 42, "roberta_base_token_classifier_conll03": 42, "sentimentdl": 43, "natur": [43, 54, 59, 60, 61, 62, 64, 65, 66, 73, 74, 78, 86, 113, 116, 134, 144, 147], "affect": [43, 129, 187], "subject": [43, 55, 57], "view": 43, "common": [43, 79, 124, 134, 160, 173, 188, 212], "product": [43, 187], "review": [43, 163], "tweet": 43, "interpret": [43, 79], "posit": [43, 64, 65, 76, 77, 78, 84, 97, 111, 112, 127, 147, 167, 205], "final": [43, 69, 70, 71, 76, 77, 86, 99, 117, 185, 186, 209], "otheriws": [43, 86], "neutral": [43, 86], "thresholdlabel": [43, 86], "score": [43, 60, 61, 76, 77, 84, 86, 98, 99, 111, 112, 113], "less": [43, 65, 86, 94, 98, 119, 182, 186], "watch": [43, 112], "32": [43, 59, 67, 186, 187, 208, 214], "setthresholdlabel": [43, 86], "p": [43, 58, 66, 74, 86, 99, 103, 126, 187], "sentimentdl_use_imdb": 43, "english": [43, 62, 84, 119, 122, 131], "imdb": 43, "sentimentdl_use_twitt": 43, "wow": 43, "video": [43, 84], "awesom": 43, "bruh": 43, "damn": 43, "wast": [43, 112], "tapasforquestionansw": 44, "implement": [44, 66, 74, 76, 109, 117, 139, 140, 148, 149, 156, 162, 166, 181, 182, 183, 185, 187], "tapa": 44, "design": [44, 53, 60, 61, 70, 71, 88, 115, 167, 187, 205], "about": [44, 55, 57, 70, 71, 75, 84, 108, 120, 143, 145, 208, 210, 213, 214], "tabular": [44, 146], "tabl": [44, 146], "tri": 44, "share": [44, 84, 186, 187, 210], "its": [44, 54, 64, 65, 69, 78, 84, 106, 111, 115, 122, 167, 187, 199], "table_qa_tapas_base_finetuned_wtq": 44, "document_assembl": [44, 142, 146, 160], "table_json": 44, "document_t": [44, 146], "sentence_detector": [44, 82, 107], "table_assembl": [44, 142, 160], "tableassembl": [44, 146], "stage": [44, 143, 145, 167, 205, 209, 210, 213], "json_data": 44, "monei": [44, 146], "ag": [44, 146], "donald": [44, 146], "trump": [44, 146], "000": [44, 84, 113, 146], "75": [44, 84, 146], "elon": [44, 146], "musk": [44, 146], "55": [44, 100, 146], "AS": [44, 51], "who": [44, 126, 209], "earn": 44, "thei": [44, 55, 57, 99, 101, 113, 145, 162, 197, 209], "old": [44, 51, 199], "xlmrobertaforquestionansw": 45, "xlm": [45, 46, 47, 76, 77], "xlm_roberta_base_qa_squad2": 45, "xlmrobertaforsequenceclassif": 46, "xlm_roberta_base_sequence_classifier_imdb": 46, "xlmrobertafortokenclassif": 47, "xlm_roberta_base_token_classifier_conll03": 47, "xlnetforsequenceclassif": 48, "xlnet": [48, 49, 78], "xlnet_base_sequence_classifier_imdb": 48, "xlnetfortokenclassif": 49, "spanbert_coref": 50, "spanbertcorefmodel": 51, "corefer": 51, "resolut": [51, 53], "spanbert": 51, "identifi": [51, 75, 84, 88, 92, 127, 129, 167, 210], "given": [51, 79, 84, 113, 116, 117, 119, 120, 122, 166, 167, 181, 185, 187], "told": [51, 91], "mari": [51, 61, 71, 77, 109], "he": [51, 64, 91, 126], "borrow": 51, "book": [51, 58, 113, 117, 197], "her": 51, "link": [51, 170], "ontonot": 51, "corefresolut": 51, "spanbert_base_coref": 51, "maxsegmentlength": 51, "textgenr": 51, "genr": 51, "One": [51, 84, 126, 128], "bc": 51, "broadcast": 51, "convers": 51, "bn": 51, "nw": 51, "wire": 51, "pt": 51, "pivot": 51, "testament": 51, "tc": 51, "telephon": 51, "wb": 51, "web": [51, 58, 62, 113, 167, 205], "setmaxsegmentlength": 51, "settextgenr": 51, "code": [51, 64, 66, 69, 70, 71, 74, 76, 77, 84, 86, 116, 184, 187, 206, 214], "swin_for_image_classif": 52, "vit_for_image_classif": 52, "swinforimageclassif": 53, "swinimageclassif": 53, "swin": 53, "hierarch": [53, 66, 74], "vision": [53, 54], "shift": 53, "window": [53, 66, 69, 74, 84, 99, 117], "ze": 53, "liu": [53, 64, 70, 71], "yutong": 53, "lin": 53, "yue": 53, "cao": 53, "han": 53, "hu": 53, "yixuan": 53, "zheng": 53, "zhang": 53, "stephen": 53, "bain": 53, "guo": 53, "whose": 53, "scheme": [53, 70, 183], "bring": [53, 209], "greater": [53, 84], "effici": [53, 64, 66, 73, 74, 115, 181, 182, 185, 186, 208], "attent": [53, 54, 64, 69, 187], "non": [53, 129, 131, 173, 187, 188], "overlap": [53, 88, 93], "while": [53, 54, 59, 65, 75, 84, 103, 113, 167, 186, 205, 210], "cross": [53, 76, 77, 100], "connect": [53, 187], "imageclassifi": [53, 54], "image_assembl": [53, 54, 142, 160], "image_classifier_swin_base_patch_4_window_7_224": 53, "huggingfac": [53, 54, 62], "swinforimageclassificationtest": 53, "http": [53, 59, 62, 64, 66, 67, 73, 74, 183, 185, 186, 187, 206], "blob": 53, "scala": [53, 86, 148, 149, 156, 162, 166], "__": 53, "present": [53, 59, 67, 69, 70, 71, 73, 76, 77, 81, 103, 109, 115], "call": [53, 60, 61, 65, 79, 84, 113, 166, 181, 183, 185, 187, 196, 209, 215], "capabl": [53, 65, 78, 113], "serv": [53, 206], "purpos": [53, 65, 109], "backbon": [53, 78], "adapt": [53, 187], "aris": 53, "domain": [53, 84, 113], "variat": [53, 187], "scale": [53, 54, 59, 65, 69, 76, 77, 113, 116, 185, 187], "visual": [53, 167], "high": [53, 73, 76, 77, 115], "compar": [53, 54, 59, 64, 65, 67, 78, 84, 109, 116, 117, 167, 205], "architectur": [53, 54, 59, 60, 61, 64, 70, 86, 99, 109, 116, 187], "flexibl": [53, 182], "variou": [53, 78, 203], "complex": [53, 67, 73, 84, 119, 120, 182], "respect": [53, 64, 75, 98, 99, 187, 199], "These": [53, 59, 70, 71, 78, 84, 98, 113, 170, 207], "broad": [53, 113], "rang": [53, 60, 61, 64, 65, 76, 77], "87": 53, "accuraci": [53, 55, 57, 60, 61, 66, 73, 74, 76, 77, 98, 99, 106, 119, 131, 205], "imagenet": [53, 54], "1k": 53, "dens": [53, 60, 61], "detect": [53, 73, 85, 86, 107, 108, 109], "box": 53, "ap": 53, "51": [53, 135, 144, 199], "coco": 53, "semant": [53, 67, 73, 131], "53": [53, 88, 93], "miou": 53, "ade20k": 53, "val": 53, "Its": [53, 57], "surpass": [53, 64], "previou": [53, 76, 77, 113, 187, 209], "margin": [53, 78], "demonstr": [53, 65, 69, 84, 113, 115], "potenti": [53, 117], "prove": 53, "benefici": [53, 84], "mlp": 53, "imagedf": [53, 54], "dropinvalid": [53, 54], "imageassembl": [53, 54, 141], "pipelinedf": [53, 54], "setdorescal": 53, "rescal": 53, "rescalefactor": 53, "boolean": [53, 187], "setrescalefactor": 53, "factor": [53, 76, 77, 78, 116, 117, 187], "255": 53, "vitforimageclassif": 54, "vit": 54, "altern": [54, 84, 111, 117, 119, 120, 143, 146, 185], "neural": [54, 60, 61, 64, 99, 109, 115, 186, 187], "network": [54, 60, 61, 67, 99, 109, 182, 185, 186, 187], "usual": [54, 147, 182], "image_classifier_vit_base_patch16_224": 54, "vitimageclassificationtestspec": 54, "becom": [54, 59, 65, 84], "de": [54, 62, 84, 86, 115], "facto": [54, 84], "standard": [54, 58, 69, 89, 91, 119, 120, 129], "remain": [54, 58, 59, 65, 84], "conjunct": 54, "replac": [54, 58, 64, 69, 86, 87, 100, 109, 119, 120, 187, 209], "certain": [54, 117], "compon": [54, 102, 103, 132, 141, 150, 154, 165, 213], "keep": [54, 84, 101, 113, 116], "overal": [54, 75, 78], "structur": [54, 147, 208], "relianc": 54, "cnn": [54, 86, 99, 109, 187], "necessari": [54, 65, 205, 212], "pure": [54, 115], "directli": [54, 143, 167, 181, 205], "patch": 54, "veri": [54, 62, 67, 76, 77, 78, 113, 115, 116, 143, 186, 208, 210, 213, 214], "well": [54, 55, 57, 73, 76, 77, 84, 146, 187], "amount": [54, 73, 84, 93, 113, 131, 143, 213], "transfer": [54, 65, 73, 76, 77, 113, 116], "mid": 54, "small": [54, 58, 59, 62, 65, 66, 74, 87, 106, 143, 199, 213], "cifar": 54, "vtab": 54, "etc": [54, 63, 136, 147, 205], "attain": 54, "excel": [54, 78], "substanti": [54, 60, 61], "fewer": [54, 59], "worth": 54, "16x16": 54, "dependencypars": [55, 57, 81], "dependencyparserapproach": [55, 197, 215], "unlabel": [55, 60, 61, 113, 116], "grammat": [55, 57], "dependencyparsermodel": [55, 57, 81], "relationship": [55, 57, 73, 81], "tell": [55, 57, 84, 159], "verb": [55, 57, 197], "modifi": [55, 57, 70, 71, 97, 109, 184], "describ": [55, 57, 81, 84, 115, 186, 187], "wai": [55, 57, 79, 81, 145, 170], "chosen": [55, 57, 99], "particular": [55, 57, 84], "treebank": 55, "penn": 55, "setdependencytreebank": 55, "conll": [55, 57, 98, 99, 160, 197, 198, 212], "u": [55, 57, 64, 65, 84, 91, 97, 98, 99, 143, 159, 170, 183, 187, 197, 207, 210, 215], "setconllu": [55, 57], "apart": [55, 57, 133, 137], "dependencytreebank": 55, "conllu": [55, 57, 87, 160, 198, 212], "numberofiter": [55, 57], "converg": [55, 57, 106, 131], "better": [55, 57, 59, 64, 78, 84, 98, 106, 108, 109, 112, 131], "typeddependencyparserapproach": [55, 57], "postagg": [55, 57, 81, 98, 106], "dependency_treebank": 55, "emptydataset": [55, 57], "tree": [55, 81], "bank": 55, "setnumberofiter": [55, 57], "read_a": [55, 57, 79, 87, 88, 92, 93, 98, 101, 103, 111, 119, 120, 129, 153, 158, 160, 196, 197], "reada": [55, 57, 75, 79, 87, 88, 92, 93, 98, 101, 103, 111, 119, 120, 124, 129, 155, 158, 196, 197], "dep": 55, "dependency_conllu": [55, 81], "perceptron": [55, 82, 105], "featur": [55, 66, 74, 84, 94, 98, 103, 167, 187, 212], "typeddependencyparsermdoel": 55, "union": [55, 57], "worker": [55, 57], "turner": [55, 57], "newal": [55, 57], "sai": [55, 57, 84, 129], "disappoint": [55, 57], "talk": [55, 57], "stricken": [55, 57], "parent": [55, 57], "firm": [55, 57], "feder": [55, 57], "mogul": [55, 57], "col": [55, 57, 79, 88, 97, 100, 133, 137, 159, 208], "dependency_pars": [56, 82], "typed_dependency_pars": [56, 82], "typeddependencypars": [57, 81], "conll2009": 57, "typeddependencyparsermodel": [57, 81], "beforehand": 57, "2009": 57, "setconll2009": 57, "dependency_typ": [57, 81], "train_smal": 57, "txt": [57, 66, 74, 75, 87, 88, 92, 93, 106, 109, 111, 117, 119, 120, 124, 129, 199, 200, 215], "descript": [57, 72, 84, 89, 119, 126, 155, 173, 188], "typdep": 57, "dependency_typed_conllu": [57, 81], "amod": 57, "flat": [57, 81, 138], "nsubj": [57, 81, 138, 197], "parataxi": 57, "documentnorm": 58, "raw": [58, 113, 126, 129, 208, 210], "scrape": 58, "xml": 58, "remov": [58, 70, 71, 101, 112, 127, 136, 137, 138], "dirti": [58, 101], "regex": [58, 79, 89, 92, 101, 117, 119, 120, 127, 129, 131], "want": [58, 79, 100, 173, 188, 210], "polici": 58, "lower": [58, 59, 84, 117, 134], "action": 58, "clean": [58, 101, 116, 147, 210], "lowercas": [58, 101, 127, 131, 134], "convert": [58, 63, 72, 75, 89, 91, 94, 97, 101, 116, 127, 128, 131, 133, 134, 137, 138, 167, 205, 212], "pretty_al": 58, "utf": 58, "cleanuppattern": [58, 101], "normalizeddocu": 58, "setact": 58, "setpattern": [58, 127, 131], "setreplac": 58, "setpolici": 58, "setlowercas": [58, 101, 134, 147], "div": 58, "theworldsgreatest": 58, "right": [58, 60, 61], "hide": 58, "wide": [58, 60, 61, 64, 65, 76, 77], "toptext": 58, "style": [58, 86, 116], "font": 58, "famili": 58, "sego": 58, "ui": 58, "arial": 58, "san": [58, 84], "serif": 58, "world": [58, 124, 167, 205], "largest": [58, 84, 113], "develop": [58, 84, 115, 164], "site": [58, 84], "h1": 58, "300": 58, "160": 58, "lorem": [58, 88, 93], "ipsum": [58, 88, 93], "simpli": [58, 210], "print": 58, "typeset": 58, "industri": 58, "been": [58, 62, 113, 128, 147], "sinc": [58, 84, 113, 209, 210, 214], "1500": 58, "unknown": [58, 86], "printer": 58, "took": 58, "gallei": 58, "scrambl": 58, "specimen": 58, "surviv": 58, "five": [58, 100], "centuri": 58, "leap": 58, "electron": 58, "essenti": [58, 113], "unchang": 58, "popularis": 58, "1960": 58, "releas": [58, 59, 62, 64, 70, 71, 76, 77, 116, 160], "letraset": 58, "passag": 58, "recent": [58, 60, 61, 64, 70, 71, 84], "desktop": 58, "publish": [58, 70, 71], "softwar": 58, "aldu": 58, "pagemak": 58, "setencod": 58, "lite": 59, "googl": [59, 60, 61, 64, 66, 67, 70, 71, 73, 74, 84, 116, 187, 197], "research": [59, 60, 61, 64, 66, 74, 115, 116, 187], "toyota": 59, "technolog": 59, "institut": 59, "chicago": 59, "offici": [59, 84, 97, 98, 99, 143, 159, 170, 206], "tf": [59, 73, 173, 182, 184, 185, 186, 188], "wrapper": [59, 163, 181, 183, 187], "port": 59, "albert_base_uncas": 59, "albert_bas": 59, "768": [59, 60, 61, 62, 64, 65, 69, 70, 71, 76, 77, 78], "emb": 59, "dim": [59, 187], "12m": 59, "albert_large_uncas": 59, "albert_larg": 59, "1024": [59, 67, 69, 78], "24": [59, 78, 88, 93, 97, 117, 143, 159, 170, 208], "16": [59, 78, 100, 199, 208], "18m": 59, "albert_xlarge_uncas": 59, "albert_xlarg": 59, "2048": 59, "60m": 59, "albert_xxlarge_uncas": 59, "albert_xxlarg": 59, "235m": 59, "sentencepiec": [59, 64, 73], "everi": [59, 60, 61, 62, 64, 65, 69, 70, 71, 76, 77, 78, 99, 112, 115, 117, 135, 144, 145, 173, 182, 188, 210], "dimens": [59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 154, 182, 185, 187], "repeat": 59, "footprint": 59, "howev": [59, 72, 78, 84, 101, 186, 208], "cost": [59, 117, 119], "similar": [59, 73, 84, 86, 185, 187], "through": [59, 81, 84, 138, 187, 210], "FOR": 59, "tfhub": [59, 67, 73], "q": 59, "increas": [59, 75, 84, 113, 119], "often": [59, 70, 71, 78], "downstream": [59, 62, 64, 67, 69, 78, 113, 116], "some": [59, 61, 76, 84, 99, 109, 113, 145, 167, 208, 209, 213, 214], "point": [59, 60, 61, 108, 109, 135, 144, 196], "further": [59, 84, 98, 99, 133, 147], "harder": 59, "gpu": [59, 113, 115, 116, 160, 186], "tpu": 59, "longer": [59, 66, 69, 74, 86, 186, 214], "techniqu": [59, 64, 113, 116], "consumpt": [59, 73, 75], "speed": [59, 98, 115], "devlin": [59, 70, 71], "et": [59, 70, 71, 86, 187], "al": [59, 70, 71, 187], "2019": [59, 62, 64, 70, 71, 76, 77], "comprehens": [59, 113], "empir": [59, 60, 61, 76, 77, 78], "evid": 59, "lead": [59, 62, 76, 77, 182], "focus": [59, 84], "inter": 59, "coher": [59, 113], "As": [59, 60, 61, 65, 84, 186, 187], "establish": 59, "glue": [59, 60, 61, 65, 70, 71, 76, 77], "race": [59, 64, 70, 71], "embeddingsfinish": [59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 136], "finished_embed": [59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "setoutputasvector": [59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 136], "setcleanannot": [59, 64, 65, 67, 69, 70, 72, 73, 75, 76, 78, 136, 137, 138], "80": [59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 92, 136, 147], "1342473030090332": [59, 64], "3855540752410889": [59, 64], "9818322062492371": [59, 64], "784737348556518": [59, 64], "847029983997345": [59, 64], "047153353691101": [59, 64], "1520637571811676": [59, 64], "6245765686035156": [59, 64], "009860038757324219": [59, 64], "13450059294700623": [59, 64], "707749128341675": [59, 64], "2916892766952": [59, 64], "04192575812339783": [59, 64], "5764210224151611": [59, 64], "3196685314178467": [59, 64], "527840495109": [59, 64], "15583214163780212": [59, 64], "1614152491092682": [59, 64], "28423872590065": [59, 64], "135491415858268": [59, 64], "bertembed": [60, 63, 72, 99, 136], "small_bert_l2_768": 60, "understand": [60, 61, 65, 76, 78, 84, 116, 131, 208], "introduc": [60, 61, 65, 67, 69, 116], "stand": [60, 61], "unlik": [60, 61, 76, 84, 126, 182, 185], "jointli": [60, 61], "condit": [60, 61, 113, 116], "both": [60, 61, 67, 73, 81, 185, 186, 187, 209, 210], "left": [60, 61], "just": [60, 61, 65, 70, 94, 99, 184], "infer": [60, 61, 62, 65, 78, 186, 187], "without": [60, 61, 76, 77, 84, 113, 131, 187], "modif": [60, 61], "conceptu": [60, 61], "power": [60, 61, 116], "obtain": [60, 61, 62, 73], "eleven": [60, 61], "push": [60, 61], "absolut": [60, 61], "multinli": [60, 61], "86": [60, 61, 64], "v1": [60, 61, 182], "f1": [60, 61, 76, 77, 99, 113], "93": [60, 61], "83": [60, 61, 64, 173, 188, 199, 200, 215], "small_bert_l2_128": 60, "3497989177703857": 60, "480538547039032": 60, "3238905668258667": 60, "612930893898010": 60, "1357314586639404": 60, "32984697818756104": 60, "6032363176345825": 60, "6791689395904": 60, "8244884014129639": 60, "27088963985443115": 60, "059438943862915": 60, "9817547798156": 60, "1648050546646118": 60, "4725411534309387": 60, "5938255786895752": 60, "5780693292617": 60, "9125322699546814": 60, "4563939869403839": 60, "3975459933280945": 60, "81611204147338": 60, "sentence_bert_embed": 61, "sent_small_bert_l2_768": 61, "islong": 61, "long": [61, 69, 78, 185, 187], "sent_small_bert_l2_128": 61, "orang": [61, 71, 77], "8951074481010437": [61, 71, 77], "13753940165042877": [61, 71, 77], "3108254075050354": [61, 71, 77], "65693199634552": [61, 71, 77], "6180210709571838": [61, 71, 77], "12179657071828842": [61, 71, 77], "191165953874588": [61, 71, 77], "4497021436691": [61, 71, 77], "822715163230896": [61, 71, 77], "7568016648292542": [61, 71, 77], "1165061742067337": [61, 71, 77], "59048593044281": [61, 71, 77], "setislong": 61, "camembertembed": 62, "tasti": 62, "french": [62, 84, 115, 122], "loui": 62, "martin": 62, "muller": 62, "pedro": 62, "javier": 62, "ortiz": 62, "su\u00e1rez": 62, "yoann": 62, "dupont": 62, "laurent": [62, 187], "romari": 62, "\u00e9ric": 62, "villemont": 62, "la": [62, 115], "clergeri": 62, "djam\u00e9": 62, "seddah": 62, "beno\u00eet": 62, "sagot": 62, "facebook": [62, 64, 76, 77], "138gb": 62, "camembert_bas": 62, "camembertembeddingstestspec": 62, "co": [62, 84], "ubiquit": 62, "despit": 62, "most": [62, 65, 69, 84, 99, 113, 115, 116, 186], "concaten": [62, 131, 181, 186], "practic": [62, 116], "except": [62, 94, 99, 129, 173, 188], "investig": [62, 65, 73], "feasibl": 62, "monolingu": [62, 76, 77], "crawl": [62, 116], "prefer": [62, 81, 138], "wikipedia": [62, 86, 113], "surprisingli": [62, 73], "4gb": 62, "those": [62, 81, 100, 186, 209, 210], "larger": [62, 65, 70, 71, 113, 115, 116], "130": 62, "gb": 62, "reach": [62, 84, 113], "four": [62, 109, 128], "un": [62, 86], "08442357927560806": 62, "12863239645957947": 62, "03835778683423996": 62, "200479581952": 62, "048462312668561935": 62, "12637358903884888": 62, "27429091930389404": 62, "07516729831": 62, "02690504491329193": 62, "12104076147079468": 62, "012526623904705048": 62, "031543646007": 62, "05877285450696945": 62, "08773420006036758": 62, "06381352990865707": 62, "122621834278": 62, "chunkembed": [63, 136], "wordembed": [63, 72, 75, 99, 136, 160], "chunker": [63, 82, 160], "ngramgener": [63, 94], "nerconvert": [63, 97, 98, 99, 167, 205], "poolingstrategi": [63, 72], "aggreg": [63, 72], "sum": [63, 67, 72, 187], "skipoov": 63, "discard": 63, "oov": 63, "ngram": [63, 94, 113, 116], "setn": [63, 94], "wordembeddingsmodel": [63, 72, 75, 81, 98, 99, 100, 136], "setpoolingstrategi": [63, 72], "55661": 63, "42829502": 63, "86661": 63, "409785": 63, "06316501": 63, "120775": 63, "0732005": 63, "40674996": 63, "22938299": 63, "50597": 63, "288195": 63, "555655": 63, "465145": 63, "140118": 63, "17417": 63, "095253006": 63, "0530925": 63, "218465": 63, "714395": 63, "79860497": 63, "0129999": 63, "139705": 63, "177955": 63, "1887775": 63, "45545": 63, "20030999": 63, "461557": 63, "07891501": 63, "strategi": [63, 72, 92, 108, 117], "setskipoov": 63, "debertaembed": 64, "decod": [64, 69, 113, 115, 116], "enhanc": [64, 112], "disentangl": 64, "pengcheng": 64, "xiaodong": 64, "jianfeng": 64, "gao": 64, "weizhu": 64, "chen": [64, 70, 71, 187], "2018": [64, 70, 71, 187], "half": [64, 84], "deberta_v3_bas": 64, "microsoft": [64, 115], "www": 64, "blog": 64, "human": [64, 84], "superglu": 64, "progress": [64, 109, 127], "significantli": [64, 67, 70, 71, 76, 77, 84], "novel": [64, 78, 84], "mechan": [64, 69], "weight": [64, 67, 84, 98, 100, 117, 185, 187], "among": 64, "matric": [64, 185, 187], "second": [64, 67, 92, 108, 122, 127, 187, 209], "achiev": [64, 69, 70, 71, 76, 77, 78, 99, 113, 115, 116, 143, 187, 213], "mnli": 64, "9": [64, 76, 77, 94, 208, 213, 214], "90": 64, "91": 64, "88": 64, "made": [64, 73, 205], "publicli": [64, 76, 77], "distilbertembed": 65, "fast": [65, 112, 115, 143, 187, 213], "cheap": 65, "distil": 65, "40": [65, 100, 115], "uncas": 65, "preserv": [65, 97, 127, 147], "95": 65, "measur": [65, 70, 71, 167], "distilbert_base_cas": 65, "doesn": [65, 70, 187], "t": [65, 70, 87, 101, 109, 111, 129, 133, 137, 186, 187], "token_type_id": [65, 70], "don": [65, 70, 101], "indic": [65, 70, 127, 131], "belong": [65, 70], "separ": [65, 70, 92, 94, 108, 109, 119, 129, 131, 137, 159, 196, 207], "sep_token": [65, 70], "sep": 65, "position_id": 65, "ad": [65, 67, 117, 181], "though": [65, 84], "know": [65, 115, 145], "smaller": [65, 66, 74, 186], "cheaper": 65, "lighter": 65, "preval": 65, "oper": [65, 69, 117, 126, 181, 182, 186, 187, 208], "edg": [65, 81], "constrain": 65, "budget": 65, "counterpart": 65, "prior": [65, 69, 117], "leverag": [65, 167, 205], "reduc": [65, 119, 120, 147, 185, 187], "retain": 65, "97": [65, 89, 91, 131], "being": [65, 99, 103, 115, 116, 187], "induct": 65, "bias": [65, 183, 185, 187], "tripl": [65, 81], "cosin": 65, "distanc": [65, 117, 119, 120], "devic": 65, "proof": 65, "concept": [65, 210], "experi": [65, 78, 167, 206], "studi": [65, 70, 71, 116], "1127224713563919": 65, "1982710212469101": 65, "5360898375511169": 65, "272536993026733": 65, "35534414649009705": 65, "13215228915214539": 65, "40981462597846985": 65, "14036104083061": 65, "328085333108902": 65, "06269335001707077": 65, "017595693469047546": 65, "024373905733": 65, "15617232024669647": 65, "2967822253704071": 65, "22324979305267334": 65, "04568954557180": 65, "45411425828933716": 65, "01173491682857275": 65, "190129816532135": 65, "1178255230188369": 65, "doc2vecapproach": 66, "word2vec": [66, 68, 82], "corpu": [66, 67, 74, 84, 87, 106, 116, 117, 199, 215], "algorithm": [66, 74, 84, 98, 112, 117, 119, 120], "construct": [66, 74, 129, 170, 182, 187, 212], "vocabulari": [66, 74, 113, 116, 117], "skip": [66, 74, 81, 117], "gram": [66, 74, 84, 94, 113, 116], "doc2vecmodel": 66, "vectors": [66, 74], "windows": [66, 74, 84], "numpartit": [66, 74], "partit": [66, 74, 196], "mincount": [66, 74, 117], "must": [66, 74, 87, 88, 92, 93, 103, 111, 112, 119, 120, 134, 159, 160, 167, 182, 185, 186, 187, 196], "appear": [66, 74, 117], "ani": [66, 73, 74, 79, 84, 99, 113, 116, 136, 137, 186, 206, 209, 210, 215], "divid": [66, 74], "1000": [66, 74, 81, 98, 187], "stepsiz": [66, 74], "optim": [66, 70, 71, 74, 99, 109], "025": [66, 74], "maxit": [66, 74], "estim": [66, 74, 123, 139, 148, 156, 166, 209], "space": [66, 74, 75, 94, 147, 186, 187], "distribut": [66, 74, 184], "composition": [66, 74], "sherlockholm": [66, 74, 117, 215], "setvectors": [66, 74], "setwindows": [66, 74, 84], "setsteps": [66, 74], "initi": [66, 74, 117, 127, 145, 160, 181, 183, 185, 186, 187, 196, 197, 199, 200, 205], "setnumpartit": [66, 74], "setmaxit": [66, 74], "numiter": [66, 74], "equal": [66, 74, 187], "setse": [66, 74], "setmincount": [66, 74, 117], "doc2vec_gigaword_300": 66, "06222493574023247": [66, 74], "011579325422644615": [66, 74], "009919632226228714": [66, 74], "109361454844": [66, 74], "doc2vec_wiki": 66, "elmoembed": 67, "elmo": 67, "billion": [67, 113], "computation": [67, 70, 71, 78, 113, 115, 116], "expens": [67, 70, 71, 78, 111, 113, 115, 116, 119], "lookup": [67, 75, 78, 88, 119, 120], "acceler": [67, 78, 113, 115, 116, 160, 187], "setpoolinglay": 67, "word_emb": 67, "shape": [67, 185, 186, 187], "batch_siz": [67, 185, 186, 187], "max_length": 67, "lstm_outputs1": 67, "lstm": [67, 99, 185, 187], "lstm_outputs2": 67, "trainabl": [67, 187], "tensor": [67, 185, 186, 187], "poolinglay": 67, "contextu": [67, 117], "characterist": 67, "syntax": 67, "vari": 67, "across": [67, 113], "linguist": 67, "polysemi": 67, "intern": [67, 102, 103, 129, 146, 150, 154, 160, 187], "bilm": 67, "exist": [67, 117, 136, 138, 167, 187], "six": [67, 119, 120], "textual": 67, "entail": 67, "expos": 67, "crucial": 67, "mix": [67, 149, 166], "semi": 67, "signal": [67, 187], "662458181381226e": 67, "2541114091873169": 67, "6275503039360046": 67, "5787073969841": 67, "19154725968837738": 67, "22998669743537903": 67, "2894386649131775": 67, "21524395048618": 67, "10400570929050446": 67, "12288510054349899": 67, "07056470215320587": 67, "246389418840": 67, "49932169914245605": 67, "12706467509269714": 67, "30969417095184326": 67, "2643227577209": 67, "8871506452560425": 67, "20039963722229004": 67, "0601330995559692": 67, "0348707810044": 67, "albert_embed": [68, 82], "bert_embed": [68, 82], "bert_sentence_embed": [68, 82], "camembert_embed": [68, 82], "chunk_embed": [68, 82], "deberta_embed": [68, 82], "distil_bert_embed": [68, 82], "doc2vec": [68, 82], "elmo_embed": [68, 82], "longformer_embed": [68, 82], "roberta_embed": [68, 82], "roberta_sentence_embed": [68, 82], "universal_sentence_encod": [68, 82], "xlm_roberta_embed": [68, 82], "xlm_roberta_sentence_embed": [68, 82], "xlnet_embed": [68, 82], "longformerembed": 69, "iz": 69, "beltagi": 69, "matthew": 69, "arman": 69, "cohan": 69, "checkpoint": 69, "mlm": 69, "096": 69, "longformer_base_4096": 69, "unabl": 69, "quadrat": 69, "linearli": 69, "easi": 69, "thousand": 69, "drop": [69, 122], "motiv": 69, "global": 69, "text8": 69, "enwik8": 69, "contrast": [69, 88, 116], "finetun": [69, 78], "varieti": [69, 76, 77, 214], "outperform": [69, 73, 76, 77, 78, 84, 113], "wikihop": 69, "triviaqa": 69, "led": [69, 70, 71, 84], "effect": [69, 108, 116, 182], "arxiv": [69, 183, 185, 186, 187], "summar": [69, 84, 113, 115, 116], "found": [69, 75, 84, 119, 126, 134, 212], "18792399764060974": [69, 70], "14591649174690247": [69, 70], "20547787845134735": [69, 70], "1468472778797": [69, 70], "22845706343650818": [69, 70], "18073144555091858": [69, 70], "09725798666477203": [69, 70], "0417917296290": [69, 70], "07037967443466187": [69, 70], "14801117777824402": [69, 70], "03603338822722435": [69, 70], "17893412709": [69, 70], "08734266459941864": [69, 70], "2486150562763214": [69, 70], "009067727252840996": [69, 70], "24408400058": [69, 70], "22409197688102722": [69, 70], "4312366545200348": [69, 70], "1401449590921402": [69, 70], "356410235166549": [69, 70], "robertaembed": [70, 76], "robustli": [70, 71], "yinhan": [70, 71], "myle": [70, 71, 76, 77], "ott": [70, 71, 76, 77], "naman": [70, 71, 76, 77], "goyal": [70, 71, 76, 77], "jingfei": [70, 71], "du": [70, 71, 86], "mandar": [70, 71], "joshi": [70, 71], "danqi": [70, 71], "omer": [70, 71], "levi": [70, 71], "mike": [70, 71], "lewi": [70, 71], "luke": [70, 71, 76, 77], "zettlemoy": [70, 71, 76, 77], "veselin": [70, 71, 76, 77], "stoyanov": [70, 71, 76, 77], "hyperparamet": [70, 71], "next": [70, 71, 84, 89, 91, 113, 116, 186], "mini": [70, 71], "roberta_bas": 70, "bpe": 70, "gpt": [70, 113], "signific": [70, 71, 76, 77, 84, 87], "gain": [70, 71, 76, 77, 187], "care": [70, 71, 129], "comparison": [70, 71, 73, 122], "choic": [70, 71, 92], "impact": [70, 71], "replic": [70, 71], "carefulli": [70, 71], "undertrain": [70, 71], "exce": [70, 71], "highlight": [70, 71], "previous": [70, 71, 84], "overlook": [70, 71], "rais": [70, 71, 84, 94, 99, 167, 185, 186, 187], "report": [70, 71, 73, 167, 205], "robertasentenceembed": 71, "sent_roberta_bas": 71, "embeddingssent": 72, "22093398869037628": 72, "25130119919776917": 72, "41810303926467896": 72, "380883991718": 72, "dimension": [73, 187], "tfhub_us": 73, "loadsp": 73, "op": [73, 183, 184, 185], "lingual": [73, 76, 77, 84, 86, 115], "accur": [73, 112, 119], "divers": [73, 113, 116, 206], "trade": [73, 76, 77, 186], "baselin": [73, 113, 187], "do": [73, 84, 97, 122, 129, 133, 143, 181, 186, 205, 209, 213], "tend": 73, "With": [73, 78, 84], "observ": 73, "minim": [73, 115, 186], "encourag": 73, "weat": 73, "bia": [73, 185, 187], "freeli": 73, "04616805538535118": 73, "022307956591248512": 73, "044395286589860916": 73, "0016493503": 73, "setloadsp": 73, "word2vecapproach": 74, "word2vecmodel": 74, "word2vec_gigaword_300": 74, "word2vec_wiki": 74, "custom": [75, 98, 99, 108, 109, 129, 167], "dictionari": [75, 84, 87, 92, 98, 100, 101, 111, 119, 120, 167], "setstoragepath": [75, 88], "line": [75, 79, 88, 93, 109, 111, 170, 199], "delimit": [75, 79, 81, 87, 92, 94, 98, 101, 111, 127, 146, 196, 199], "39658191506190343": 75, "630968081620067": 75, "5393722253731201": 75, "8428180123359783": 75, "were": [75, 99, 167, 205], "7535235923631415": 75, "9699218875629833": 75, "10397182122983872": 75, "11833962569383116": 75, "stress": 75, "0492683418305907": 75, "9415954572751959": 75, "47624463167525755": 75, "16790967216778263": 75, "induc": 75, "1535748762292387": 75, "33498936903209897": 75, "9235178224122094": 75, "1158772920395934": 75, "zero": [75, 113, 185, 186], "withcoveragecolumn": 75, "overallcoverag": 75, "writebuffers": 75, "dump": 75, "disk": [75, 209, 210], "storag": [75, 79, 88, 153, 160], "10000": 75, "readcaches": 75, "cach": 75, "higher": [75, 84, 112, 113, 116], "random_embeddings_dim4": 75, "abov": [75, 81, 185, 199], "setstorageref": 75, "glove_4d": 75, "setdimens": [75, 154], "patient": 75, "diagnos": 75, "diabet": 75, "9439099431037903": 75, "4707513153553009": 75, "806300163269043": 75, "16176554560661316": 75, "7966810464859009": 75, "5551124811172485": 75, "8861005902290344": 75, "28284206986427307": 75, "025029370561242104": 75, "35177749395370483": 75, "052506182342767715": 75, "1887107789516449": 75, "08617766946554184": 75, "8399239182472229": 75, "5395117998123169": 75, "7864698767662048": 75, "6599600911140442": 75, "16109347343444824": 75, "6041093468666077": 75, "8913561105728149": 75, "5955275893211365": 75, "01899011991918087": 75, "4397728443145752": 75, "8911281824111938": 75, "9840458631515503": 75, "7599489092826843": 75, "9417727589607239": 75, "8624503016471863": 75, "setwritebuffers": 75, "setreadcaches": 75, "glove_100d": [75, 99], "There": [75, 79, 81, 126, 187, 207, 209, 210, 215], "conveni": 75, "coverag": [75, 152], "add": [75, 89, 91, 108, 113, 116, 117, 129, 185, 187, 209], "stat": 75, "field": [75, 79, 93, 187], "whole": [75, 170, 181], "consid": [75, 81, 84, 117, 119, 120, 122, 126], "570580005645752": 75, "44183000922203064": 75, "7010200023651123": 75, "417129993438720": 75, "542639970779419": 75, "4147599935531616": 75, "0321999788284302": 75, "4024400115013122": 75, "2708599865436554": 75, "04400600120425224": 75, "020260000601410866": 75, "17395000159": 75, "6191999912261963": 75, "14650000631809235": 75, "08592499792575836": 75, "2629800140857": 75, "3397899866104126": 75, "20940999686717987": 75, "46347999572753906": 75, "6479200124740": 75, "embeddings_col": 75, "coverageresult": 75, "coverateresult": 75, "wordsoverallcoverag": 75, "resultdf": 75, "percentag": [75, 117, 131], "output_col": 75, "wordscoverag": 75, "cov_embed": 75, "loadstorag": [75, 88], "storage_ref": [75, 88], "xlmrobertaembed": 76, "alexi": [76, 77], "conneau": [76, 77], "kartikai": [76, 77], "khandelw": [76, 77], "vishrav": [76, 77], "chaudhari": [76, 77], "guillaum": [76, 77], "wenzek": [76, 77], "francisco": [76, 77, 84], "guzman": 76, "edouard": [76, 77], "grave": [76, 77, 187], "5tb": [76, 77], "filter": [76, 77, 84, 97, 98, 113, 115, 116, 122, 159], "commoncrawl": [76, 77], "xlm_roberta_bas": 76, "xx": [76, 77, 86, 115], "multilingu": [76, 77, 131], "doe": [76, 84, 97, 143, 145, 186, 187, 210, 213, 214], "abl": [76, 116, 167, 208], "determin": [76, 187], "correct": [76, 117, 119, 120, 131], "hundr": [76, 77], "terabyt": [76, 77], "dub": [76, 77], "r": [76, 77, 84, 183, 187], "mbert": [76, 77], "xnli": [76, 77], "mlqa": [76, 77], "particularli": [76, 77], "low": [76, 77, 117], "swahili": [76, 77], "urdu": [76, 77], "capac": [76, 77, 113, 187], "dilut": [76, 77], "sacrif": [76, 77], "ri": [76, 77], "competit": [76, 77, 84], "strong": [76, 77], "05969233065843582": 76, "030789051204919815": 76, "04443822056055069": 76, "09564960747": 76, "038839809596538544": 76, "011712731793522835": 76, "019954433664679527": 76, "0667808502": 76, "03952755779027939": 76, "03455188870429993": 76, "019103847444057465": 76, "04311436787": 76, "09579929709434509": 76, "02494969218969345": 76, "014753809198737144": 76, "10259044915": 76, "004710011184215546": 76, "022148698568344116": 76, "011723337695002556": 76, "013356896": 76, "xlmrobertasentenceembed": 77, "guzm\u00e3": 77, "sent_xlm_roberta_bas": 77, "xlnetembed": 78, "autoregress": 78, "permut": 78, "addition": [78, 99, 106, 135, 144, 170], "emploi": 78, "xl": 78, "exhibit": 78, "involv": [78, 109], "sota": 78, "rank": [78, 117], "xlnet_large_cas": 78, "xlnet_base_cas": 78, "full": [78, 209], "zihangdai": 78, "denois": 78, "autoencod": 78, "corrupt": 78, "neglect": 78, "suffer": 78, "discrep": 78, "pro": 78, "con": 78, "enabl": [78, 79, 99, 119, 160, 184, 187], "maxim": [78, 117], "likelihood": 78, "overcom": 78, "formul": 78, "furthermor": 78, "integr": [78, 84, 115, 167, 187, 205, 207], "idea": [78, 187], "6287205219268799": 78, "4865287244319916": 78, "186111718416214": 78, "234187275171279": 78, "1967450380325317": 78, "2746637463569641": 78, "9481253027915955": 78, "3431355059146881": 78, "0777631998062134": 78, "092679977416992": 78, "5331977605819702": 78, "11190271377563": 78, "8349916934967041": 78, "45627787709236145": 78, "7890847325325012": 78, "028069257736": 78, "134845569729805": 78, "11672890186309814": 78, "4945235550403595": 78, "66587203741073": 78, "entityrul": 79, "entityrulerapproach": 79, "exact": [79, 88, 93], "definit": [79, 196], "json": [79, 146, 167], "jsonl": 79, "setpatternsresourc": 79, "might": [79, 99, 131, 214], "setenablepatternregex": 79, "rule": [79, 92, 111, 126, 129], "person": [79, 197], "w": [79, 82, 92, 98, 101, 126, 129, 160, 187], "locat": [79, 108, 133, 160, 170, 209], "winterfel": 79, "jon": 79, "snow": [79, 100, 117], "stark": 79, "eddard": 79, "patternsresourc": 79, "enablepatternregex": 79, "usestorag": 79, "rocksdb": 79, "lord": 79, "29": [79, 100, 199], "38": 79, "setusestorag": 79, "setsentencematch": 79, "setalphabetresourc": 79, "alphabet": [79, 101], "plain": [79, 215], "entityrulermodel": 79, "entity_rul": [80, 82], "graphextract": [81, 138], "graph": [81, 99, 115, 123, 138, 173, 188], "nerdlmodel": [81, 97, 98, 99, 100, 167, 205], "store": [81, 102, 103, 146, 150, 154, 165, 170, 187, 206], "node": [81, 187], "relev": [81, 84], "taken": 81, "implicitli": 81, "setmergeent": 81, "automat": [81, 84, 115, 119, 208, 209], "setdependencyparsermodel": 81, "settypeddependencyparsermodel": 81, "setrelationshiptyp": 81, "public": [81, 209], "relationshiptyp": 81, "pair": [81, 167, 185, 187], "entitytyp": 81, "explodeent": 81, "roottoken": 81, "travers": 81, "along": 81, "maxsentences": 81, "minsentences": 81, "below": [81, 214], "mergeent": 81, "merg": [81, 88, 93], "neighbor": 81, "includeedg": 81, "symbol": [81, 117, 131], "posmodel": 81, "coordin": [81, 108], "remoteloc": 81, "graphfinish": [81, 138], "rdf": [81, 138], "nertagg": [81, 98, 99, 100, 173, 188], "morn": [81, 138], "flight": [81, 138], "denver": [81, 138], "18": [81, 89, 91, 94, 97, 100, 143, 159, 170, 208], "path1": 81, "setentitytyp": 81, "setexplodeent": 81, "setroottoken": 81, "setmaxsentences": 81, "setminsentences": 81, "setmergeentitiesiobformat": 81, "iob": [81, 97, 98, 99], "iob2": [81, 97], "setincludeedg": 81, "setdelimit": [81, 92, 94], "setposmodel": 81, "classifier_dl": [82, 160], "er": [82, 160], "keyword_extract": [82, 160], "yake_keyword_extract": [82, 83], "ld_dl": [82, 160], "language_detector_dl": [82, 85], "matcher": [82, 160], "big_text_match": [82, 90], "date_match": [82, 90], "multi_date_match": [82, 90], "regex_match": [82, 90], "text_match": [82, 90], "ner_approach": [82, 95], "ner_convert": [82, 95], "ner_crf": [82, 95], "ner_dl": [82, 95, 173, 188], "ner_overwrit": [82, 95], "param": [82, 98, 149, 150, 154, 160, 165, 166, 173, 188], "sentence_detector_dl": [82, 107, 115], "sentiment_detector": [82, 110], "vivekn_senti": [82, 110], "seq2seq": [82, 160], "gpt2_transform": [82, 114], "marian_transform": [82, 114], "t5_transform": [82, 114], "spell_check": [82, 160], "context_spell_check": [82, 118], "norvig_sweet": [82, 118], "symmetric_delet": [82, 118], "chunk_token": [82, 125], "recursive_token": [82, 125], "regex_token": [82, 125], "token2_chunk": [82, 125], "word_segment": [82, 130], "document_norm": [82, 160], "graph_extract": [82, 160], "lemmat": [82, 111, 122, 145, 147, 160], "n_gram_gener": [82, 160], "stemmer": [82, 122, 160], "stop_words_clean": [82, 160], "yakekeywordextract": 84, "yake": 84, "independ": [84, 119, 120, 126, 187], "individu": [84, 117], "organ": [84, 115], "grow": 84, "autom": 84, "adequ": 84, "manner": 84, "emerg": [84, 116], "tool": 84, "system": [84, 113, 187], "nor": 84, "thesauri": 84, "neither": 84, "corpora": [84, 88], "thu": 84, "written": [84, 115], "plethora": 84, "situat": [84, 109], "access": 84, "restrict": 84, "therefor": [84, 184, 187, 213], "sent": 84, "boundari": [84, 108, 109, 112, 129], "detector": [84, 89, 111], "section": [84, 135, 144, 205, 207, 213], "tweakabl": 84, "upper": 84, "bound": [84, 108, 109, 112], "minngram": 84, "maxngram": 84, "occurr": 84, "nkeyword": 84, "stopword": [84, 100, 122], "stop": [84, 98, 122], "campo": 84, "mangaravit": 84, "pasquali": 84, "jatowt": 84, "jorg": 84, "nune": 84, "2020": [84, 89, 91, 109], "scienc": [84, 206], "journal": 84, "elsevi": 84, "vol": 84, "509": 84, "pp": 84, "257": 84, "289": 84, "collect": [84, 167, 205], "turn": [84, 147, 187, 209], "come": 84, "term": [84, 185, 187], "fly": 84, "demand": 84, "abil": [84, 113], "within": [84, 106, 112, 113, 129, 134], "resort": 84, "alwai": [84, 116], "solut": 84, "articl": [84, 117], "rest": [84, 97], "merit": 84, "ten": 84, "experiment": 84, "carri": 84, "twenti": 84, "setcontextchar": [84, 129], "setminngram": 84, "setnkeyword": 84, "acquir": 84, "kaggl": 84, "platform": [84, 167, 207], "host": 84, "transact": 84, "somewhat": 84, "vagu": 84, "cloud": 84, "confer": 84, "week": [84, 89, 91, 124], "announc": [84, 100], "earli": 84, "tomorrow": [84, 89, 91], "phone": 84, "founder": 84, "ceo": 84, "anthoni": 84, "goldbloom": 84, "declin": 84, "deni": 84, "acquisit": 84, "happen": 84, "rumor": 84, "million": [84, 100, 113], "scientist": 84, "ben": 84, "hamner": 84, "2010": 84, "servic": [84, 115], "got": 84, "even": [84, 116], "few": [84, 129, 199, 215], "competitor": 84, "drivendata": 84, "topcod": 84, "hackerrank": 84, "stai": 84, "ahead": 84, "nich": 84, "home": [84, 160], "bui": [84, 197], "commun": 84, "mindshar": 84, "too": [84, 111, 208], "plenti": 84, "bit": [84, 109, 186, 214], "histori": [84, 109, 117], "earlier": 84, "month": [84, 89, 91, 199, 215], "team": [84, 115, 167, 205], "around": 84, "youtub": 84, "That": [84, 126, 167, 205, 210], "had": 84, "technologi": 84, "did": 84, "interest": 84, "kernel": [84, 183], "On": [84, 113, 115], "analyz": [84, 112], "compani": [84, 115], "script": 84, "centric": 84, "job": [84, 134], "board": [84, 106, 199], "unclear": 84, "accord": [84, 117, 196], "crunchbas": 84, "pitchbook": 84, "launch": 84, "investor": 84, "ventur": 84, "sv": 84, "angel": 84, "levchin": 84, "naravik": 84, "chie": 84, "economist": 84, "hal": 84, "varian": 84, "khosla": 84, "yuri": 84, "milner": 84, "resulttupl": 84, "ascend": 84, "orderbi": 84, "32051516486864573": 84, "37786450577630676": 84, "39922830978423146": 84, "40224744669493756": 84, "41584827825302534": 84, "setmaxngram": 84, "setstopword": [84, 100, 122], "getstopword": 84, "loaddefaultstopword": [84, 122], "danish": [84, 122], "dutch": [84, 122], "finnish": [84, 122], "german": [84, 122, 196, 215], "hungarian": [84, 122], "italian": [84, 117, 122], "norwegian": [84, 122], "portugues": [84, 122], "russian": [84, 122], "spanish": [84, 122], "swedish": [84, 122], "turkish": [84, 122], "languagedetectordl": 86, "ld": 86, "identif": 86, "rnn": [86, 174, 181, 182, 184, 185, 187], "tatoeba": 86, "140": 86, "wiki": 86, "languagedetector": 86, "ld_wiki_tatoeba_cnn_21": 86, "open": [86, 129, 134, 135, 136, 144, 147, 206], "advanc": [86, 134, 147], "program": 86, "biblioth\u00e8qu": 86, "traitement": 86, "pour": 86, "le": [86, 115, 187], "avanc\u00e9": 86, "langag": 86, "naturel": 86, "programm": 86, "ist": 86, "ein": 86, "textverarbeitungsbibliothek": 86, "f\u00fcr": 86, "fortgeschritten": 86, "nat\u00fcrlich": 86, "sprachverarbeitung": 86, "die": 86, "programmiersprachen": 86, "und": 86, "lemma": [87, 111, 143, 170, 197, 210, 213, 214], "predefin": [87, 88, 92, 93, 111], "setdictionari": [87, 111, 119, 120], "lemmatizermodel": 87, "lemmas_smal": [87, 111], "setformcol": 87, "correspend": 87, "formcol": [87, 197], "setlemmacol": 87, "fromlemma": 87, "key_delimit": 87, "value_delimit": 87, "lemma_antbnc": 87, "bigtextmatch": [88, 93], "textmatch": [88, 93, 124], "externalresourc": [88, 93, 158], "mergeoverlap": [88, 93], "tokenizermodel": [88, 129], "trie": 88, "dolor": [88, 93], "magna": [88, 93], "aliqua": [88, 93], "sit": [88, 93], "laborum": [88, 93], "hello": [88, 93, 124], "entityextractor": [88, 93, 124], "extractor": [88, 93, 124], "59": [88, 89, 91, 93], "setent": [88, 93, 96, 124], "setmergeoverlap": [88, 93], "settoken": 88, "tokenizer_model": 88, "bigtextmatchermodel": 88, "btm": 88, "textmatchermodel": [88, 93], "searchtri": 88, "datematch": 89, "datematcherutil": 89, "setinputformat": [89, 146], "setoutputformat": [89, 91], "desir": [89, 91], "yyyi": [89, 91], "mm": [89, 91], "dd": [89, 91, 92], "Not": [89, 99, 145], "setreadmonthfirst": 89, "juli": 89, "5th": 89, "2015": [89, 187], "07": 89, "05": 89, "setdefaultdaywhenmiss": 89, "dai": [89, 91, 117], "miss": [89, 91, 134], "setanchordateyear": [89, 91], "anchor": [89, 91], "year": [89, 91, 113, 124, 199], "2021": [89, 91], "setanchordatemonth": [89, 91], "januari": [89, 91], "setanchordatedai": [89, 91], "multidatematch": [89, 91], "1978": [89, 91], "01": [89, 91, 92], "28": [89, 91, 97, 143, 159, 170, 208], "1984": [89, 91], "04": [89, 91], "02": [89, 91], "1980": [89, 91], "79": [89, 91], "31st": [89, 91], "april": [89, 91], "2008": [89, 91], "fri": [89, 91], "nov": [89, 91, 199], "1997": [89, 91], "jan": [89, 91], "sun": [89, 91], "1st": [89, 91], "thursdai": [89, 91], "wednesdai": [89, 91], "todai": [89, 91], "yesterdai": [89, 91], "0600h": [89, 91], "06": [89, 91], "00": [89, 91], "hour": [89, 91], "6pm": [89, 91], "23": [89, 91, 92, 100, 106, 199, 200, 215], "1988": [89, 91], "31": [89, 91, 92, 100, 106, 199], "dateformat": [89, 91], "readmonthfirst": [89, 91], "defaultdaywhenmiss": [89, 91], "anchordateyear": [89, 91], "anchordatemonth": [89, 91], "anchordatedai": [89, 91], "15": 89, "saw": 91, "him": 91, "me": 91, "visit": 91, "57": [91, 100], "65": [91, 100], "regexmatch": 92, "d": [92, 101, 129, 185, 187, 207], "1970": 92, "setrul": 92, "setexternalrul": 92, "match_first": 92, "match_al": 92, "match_complet": 92, "externalrul": 92, "ceremoni": 92, "setstrategi": 92, "71": 92, "short_dat": 92, "regexmatchermodel": 92, "regardless": 93, "entityvalu": 93, "buildfromtoken": 93, "27": [93, 106, 108, 199], "48": 93, "setentityvalu": 93, "setbuildfromtoken": 93, "null": 94, "empti": [94, 134, 186], "enablecumul": 94, "actual": [94, 133, 137, 147, 186], "join": [94, 106, 146, 199], "setenablecumul": 94, "nerapproach": 96, "recogn": [96, 97, 98, 99, 100], "setminepoch": [96, 98], "setrandomse": [96, 99, 102, 173, 188], "getlabelcolumn": [96, 123], "friendli": [97, 115], "whitelist": [97, 126], "setwhitelist": [97, 126], "outsid": 97, "prefix": [97, 126, 129, 167, 205], "preserveposit": [97, 127, 147], "org": [97, 98, 99, 100, 143, 159, 160, 170, 183, 185, 186, 187, 196, 206, 215], "14": [97, 106, 128, 143, 159, 170, 199], "ekeu": [97, 98, 99, 143, 159, 170], "26": [97, 143, 159, 170], "36": [97, 106, 143, 159, 170, 199], "baghdad": [97, 98, 99, 143, 159, 170], "37": [97, 143, 159, 170], "setpreserveposit": [97, 127, 147], "nercrf": 98, "nercrfapproach": [98, 99], "nercrfmodel": [98, 99], "crf": [98, 99], "2003": [98, 99, 196, 215], "exclud": [98, 99], "setexternalfeatur": 98, "minepoch": [98, 99], "l2": 98, "c0": 98, "decai": [98, 99], "gradient": 98, "2250000": 98, "lossep": 98, "ep": 98, "minw": 98, "includeconfid": [98, 99], "confid": [98, 99], "externalfeatur": 98, "nerdlapproach": [98, 99, 188, 196, 215], "trainingdata": [98, 99, 109, 119, 120, 196], "readdataset": [98, 99, 106, 131, 196, 197, 199, 200, 215], "conll2003": [98, 99, 196, 215], "eng": [98, 99, 196, 215], "setl2": 98, "l2valu": 98, "setc0": 98, "c0valu": 98, "setlossep": 98, "setminw": 98, "setincludeconfid": [98, 99, 173, 188], "verbosevalu": 98, "prerequisit": [98, 99, 100, 209], "nerdl": 99, "char": [99, 101, 109], "bilstm": 99, "tagger": [99, 199, 215], "50": [99, 100, 106, 113, 187], "real": [99, 160, 167, 187, 205], "rage": 99, "graphfold": 99, "usecontrib": 99, "contrib": [99, 182, 184], "cell": [99, 146, 181, 182, 183, 185, 186, 187], "slightli": [99, 109], "includeallconfidencescor": 99, "enablememoryoptim": 99, "slow": 99, "down": [99, 209, 210], "usebestmodel": 99, "bestmodelmetr": 99, "check": [99, 108, 117, 118, 119, 120, 143, 147, 170], "micro": 99, "macro": 99, "setgraphfold": [99, 123, 173, 188], "setusecontrib": 99, "setpo": 99, "setincludeallconfidencescor": 99, "setenablememoryoptim": [99, 173, 188], "setusebestmodel": 99, "setbestmodelmetr": 99, "nermodel": 99, "neroverwrit": 100, "specifi": [100, 109, 185, 187, 196, 197], "setnewresult": 100, "nerword": 100, "overwritten": 100, "newnerent": 100, "lab": 100, "42": [100, 106], "45": [100, 106, 199], "47": [100, 199], "66": 100, "ner_overwritten": 100, "setnerword": 100, "setnewnerent": 100, "cardin": 100, "setreplaceent": 100, "rw": 100, "stem": [101, 121, 143, 170, 213, 214], "henc": [101, 187], "pl": 101, "slangdictionari": 101, "slang": 101, "minlength": [101, 108, 109, 127, 129], "maxlength": [101, 108, 109, 127, 129], "setcleanuppattern": 101, "punctuat": [101, 108], "alphanumer": 101, "letter": [101, 113, 117, 199, 215], "za": 101, "z": [101, 129], "brother": 101, "dont": [101, 112], "setslangdictionari": 101, "setminlength": [101, 108, 109, 127, 129], "setmaxlength": [101, 108, 109, 127, 129], "normalizermodel": 101, "classifierencod": 102, "attach": [102, 103, 150, 154, 165, 167], "evaluationdlparam": 103, "setevaluationlogextend": [103, 173, 188], "setenableoutputlog": [103, 167, 173, 188, 205], "setoutputlogspath": [103, 109, 167, 173, 188, 205], "assum": 103, "perceptronapproach": [106, 199, 215], "datasetpath": 106, "pierr": [106, 199], "vinken": [106, 199], "34": [106, 199], "md": [106, 199], "vb": [106, 196, 199, 215], "41": [106, 108, 199], "43": [106, 108, 199], "dt": [106, 199, 200, 215], "49": [106, 199], "poscol": [106, 131, 196], "niter": [106, 131], "anc": [106, 199, 215], "trainingperceptrondf": 106, "trainedpo": 106, "setposcolumn": [106, 131], "cd": [106, 196, 199], "setiter": 106, "getniter": [106, 131], "pos_anc": 106, "25": [106, 108, 199], "33": 106, "sentencedetectorparam": 108, "ii": 108, "abbrevi": 108, "period": 108, "geo": 108, "1026": 108, "253": 108, "553": 108, "ellipsi": 108, "quotat": 108, "mark": [108, 109, 131, 187], "exclam": 108, "breaker": 108, "pragmaticcontentformatt": 108, "custombound": [108, 109], "setcustombound": [108, 109], "usecustomboundsonli": [108, 109], "explodesent": [108, 109, 196, 197], "useabbrevi": 108, "explicitli": [108, 109, 122, 159, 209], "customboundsstrategi": 108, "prepend": [108, 134], "break": 108, "append": [108, 117, 209], "parallel": [108, 109, 143, 186, 196, 213], "splitlength": [108, 109], "forcibli": [108, 109], "split": [108, 109, 124, 126, 127, 131, 181, 187], "99999": [108, 109, 129], "detectlist": 108, "nhow": 108, "setcustomboundsstrategi": 108, "setuseabbrevi": 108, "setdetectlist": 108, "setusecustomboundsonli": [108, 109], "setexplodesent": [108, 109], "setsplitlength": [108, 109], "sentencedetectordl": 109, "sentencedetectordlapproach": 109, "futur": [109, 116], "setmodel": 109, "sentencedetectordlmodel": [109, 115], "modelarchitectur": 109, "impossiblepenultim": 109, "imposs": [109, 131], "penultim": 109, "epochsnumb": 109, "eo": 109, "stefan": 109, "schweter": 109, "sajawel": 109, "ahm": 109, "littl": [109, 214], "cover": [109, 116, 131], "broken": 109, "moder": 109, "lack": 109, "easier": [109, 137, 211, 215], "polit": 109, "successor": 109, "great": 109, "respons": 109, "heritag": 109, "bequeath": 109, "nelson": 109, "mandela": 109, "setepochsnumb": 109, "model_architectur": 109, "validation_split": 109, "epochs_numb": 109, "output_logs_path": 109, "setimpossiblepenultim": 109, "impossible_penultim": 109, "sentencedl": 109, "sentencesdl": 109, "helen": 109, "total": [109, 131], "peopl": 109, "sentimentdetector": 111, "By": [111, 116, 122, 127, 136, 160, 167, 205], "viveknsentimentapproach": [111, 112], "cool": 111, "superb": 111, "uninspir": 111, "sentimentscor": 111, "staff": 111, "restaur": 111, "nice": [111, 167, 205], "avoid": [111, 186, 187], "entri": [111, 135, 144], "sttr": 111, "sentimentdetectormodel": 111, "sda": [111, 112], "pragmat": 111, "viveknsenti": 112, "analys": 112, "inspir": [112, 119, 120, 163], "vivek": 112, "narayanan": 112, "give": 112, "transit": [112, 117], "sentimentcol": 112, "prunecorpu": 112, "unfrequ": 112, "scenario": 112, "naiv": 112, "bay": 112, "vivekn": 112, "setsentimentcol": 112, "train_senti": 112, "result_senti": 112, "finish": [112, 136, 138, 142, 145, 160], "final_senti": 112, "cast": [112, 132], "horribl": 112, "never": [112, 209], "go": [112, 209], "again": [112, 126], "anyon": 112, "protagonist": 112, "music": 112, "setprunecorpu": 112, "frequenc": [112, 117, 119, 120, 131, 187], "viveknsentimentmodel": 112, "sentiment_vivekn": 112, "gpt2transform": 113, "gpt2": 113, "openai": 113, "caus": [113, 129], "goal": 113, "occur": [113, 116], "direct": [113, 186, 187], "10x": 113, "synthet": 113, "sampl": [113, 116], "unpreced": 113, "prime": 113, "lengthi": 113, "translat": [113, 115, 116], "far": [113, 133, 137], "suggest": 113, "benefit": 113, "suffici": 113, "minoutputlength": [113, 116], "maxoutputlength": [113, 115, 116], "dosampl": [113, 116], "greedi": [113, 116], "temperatur": [113, 116], "topk": [113, 116], "highest": [113, 116, 119], "topp": [113, 116], "cumul": [113, 116], "kept": [113, 116], "repetitionpenalti": [113, 116], "repetit": [113, 116], "penalti": [113, 116, 186], "norepeatngrams": [113, 116], "onc": [113, 116, 182], "ignoretokenid": [113, 116], "especi": [113, 115, 116], "multitask": 113, "learner": 113, "typic": [113, 186], "taskspecif": 113, "webpag": [113, 206], "webtext": 113, "plu": 113, "coqa": 113, "exceed": 113, "127": 113, "shot": 113, "fashion": 113, "5b": 113, "still": [113, 167], "underfit": 113, "reflect": 113, "paragraph": 113, "promis": 113, "toward": 113, "setmaxoutputlength": [113, 115, 116], "leonardo": 113, "man": 113, "1776": 113, "came": 113, "kingdom": 113, "settask": [113, 116], "setignoretokenid": [113, 115, 116], "setminoutputlength": [113, 116], "setdosampl": [113, 116], "settemperatur": [113, 116], "settopk": [113, 116], "settopp": [113, 116], "setrepetitionpenalti": [113, 116], "ctrl": [113, 116], "control": [113, 115, 116, 117, 187], "setnorepeatngrams": [113, 116], "mariantransform": 115, "marian": 115, "free": [115, 187], "mainli": 115, "academ": 115, "notabl": 115, "edinburgh": 115, "past": 115, "adam": 115, "mickiewicz": 115, "pozna\u0144": 115, "commerci": 115, "contributor": 115, "mariannmt": 115, "engin": [115, 124], "behind": 115, "deploi": [115, 206], "opus_mt_en_fr": 115, "langid": 115, "maxinputlength": 115, "differenti": 115, "dynam": [115, 186, 187], "toolkit": 115, "setmaxinputlength": 115, "capit": [115, 117], "franc": 115, "quell": 115, "capital": 115, "devrait": 115, "savoir": 115, "fran\u00e7ai": 115, "setlangid": 115, "t5transform": 116, "t5": 116, "reconsid": 116, "unifi": 116, "hyper": 116, "t5_small": 116, "explor": 116, "rich": 116, "rise": 116, "methodologi": 116, "landscap": 116, "systemat": 116, "dozen": 116, "insight": 116, "coloss": 116, "facilit": 116, "200": [116, 173, 187, 188], "contextspellcheck": 117, "contextspellcheckerapproach": [117, 119, 120], "noisi": 117, "spell": [117, 118, 119, 120, 143, 147, 212, 213, 214], "candid": [117, 119, 120, 129], "contextspellcheckermodel": [117, 119, 120], "error": [117, 187], "thing": [117, 133, 137], "surround": [117, 146], "edit": [117, 119, 120], "subword": 117, "checker": [117, 119, 120, 212], "languagemodelclass": 117, "lm": 117, "wordmaxdist": 117, "maxcandid": 117, "casestrategi": 117, "try": [117, 133], "uppercas": 117, "errorthreshold": 117, "perplex": 117, "nlm": 117, "initialr": 117, "finalr": 117, "validationfract": 117, "datapoint": 117, "min": 117, "vocab": 117, "compoundcount": 117, "compound": 117, "classcount": 117, "special": [117, 161, 210], "tradeoff": 117, "weighteddistpath": 117, "levenshtein": [117, 119, 120], "maxwindowlen": 117, "rememb": 117, "norvigsweetingapproach": [117, 119, 120, 215], "symmetricdeleteapproach": [117, 119, 120, 215], "depth": [117, 186, 187, 212], "explan": [117, 212], "awar": 117, "sherlock": 117, "holm": 117, "spellcheck": [117, 119, 120], "setwordmaxdist": 117, "setepoch": 117, "setlanguagemodelclass": 117, "1650": 117, "addvocabclass": 117, "_name_": 117, "extra": [117, 119, 209], "dist": 117, "setmaxcandid": 117, "setcasestrategi": 117, "seterrorthreshold": 117, "setinitialr": 117, "setfinalr": 117, "setvalidationfract": 117, "fraction": 117, "setcompoundcount": 117, "setclasscount": 117, "settradeoff": 117, "alpha": 117, "setweighteddistpath": 117, "setmaxwindowlen": 117, "userdist": 117, "addregexclass": 117, "spellcheck_dl": 117, "gamma": 117, "influenc": 117, "decis": 117, "correctsymbol": 117, "comparelowcas": 117, "norvigsweetingmodel": [117, 119, 120], "symmetricdeletemodel": [117, 119, 120], "doc": [117, 200, 215], "cold": 117, "dreari": 117, "countri": 117, "white": 117, "smow": 117, "setweight": 117, "setgamma": 117, "getwordclass": 117, "updateregexclass": 117, "updat": [117, 187], "updatevocabclass": 117, "setcorrectsymbol": 117, "setcomparelowcas": 117, "norvigsweet": 119, "norvig": 119, "bayesian": 119, "tokenpattern": 119, "sensit": [119, 122, 129], "doublevari": 119, "search": [119, 187], "shortcircuit": 119, "frequencyprior": 119, "ham": 119, "intersect": [119, 187], "prioriti": [119, 129], "wordsizeignor": 119, "dupslimit": 119, "duplic": 119, "reductlimit": 119, "attempt": 119, "vowelswaplimit": 119, "vowel": 119, "swap": [119, 186], "corrector": 119, "gummi": [119, 120], "gummic": [119, 120], "gummier": [119, 120], "gummiest": [119, 120], "gummifer": [119, 120], "basi": [119, 120], "token_pattern": [119, 120], "setdoublevari": 119, "setshortcircuit": 119, "setfrequencyprior": 119, "symmetr": [119, 120], "delet": [119, 120, 209], "damerau": [119, 120], "magnitud": [119, 120], "transpos": [119, 120, 186], "insert": [119, 120, 209], "spellcheck_norvig": 119, "symspel": [119, 120], "somtim": 119, "wrrite": [119, 120], "wordz": [119, 120], "erong": [119, 120], "sometim": [119, 120, 209], "wrong": [119, 120], "symmetricdelet": 120, "deriv": 120, "teach": 120, "maxeditdist": 120, "frequencythreshold": [120, 131], "deletesthreshold": 120, "patttern": 120, "setmaxeditdist": 120, "setfrequencythreshold": [120, 131], "setdeletesthreshold": 120, "spellcheck_sd": 120, "spmetim": 120, "hard": 121, "employ": 121, "stopwordsclean": [122, 136, 147], "mllib": [122, 206], "stopwordsremov": 122, "cleantoken": [122, 136, 147], "stopwords_en": 122, "jvm": 122, "forth": 122, "setlocal": 122, "tfnerdlgraphbuildermodel": 123, "tfnerdlgraphbuild": 123, "sethiddenunitsnumb": 123, "assertiondlapproach": 123, "medicalnerapproach": [123, 173, 188], "gethiddenunitsnumb": 123, "getinputcol": [123, 136, 137, 150], "srt": 123, "getgraphfold": 123, "setgraphfil": 123, "greaph": 123, "auto": [123, 173, 188], "getgraphfil": 123, "chunktoken": 124, "flatten": 124, "artist": 124, "benezar": 124, "robert": 124, "farendel": 124, "graduat": 124, "luca": 124, "chunktokenizermodel": 124, "recursivetoken": 126, "recurs": [126, 145, 156, 160, 164], "hand": 126, "suffix": [126, 129, 209], "infix": [126, 129], "middl": 126, "she": 126, "qam": 126, "setprefix": 126, "setsuffix": 126, "setinfix": 126, "recursivetokenizermodel": 126, "regextoken": [127, 131, 210], "whitespac": [127, 131, 134], "tolowercas": [127, 131], "positionalmask": 127, "guarante": 127, "increment": 127, "trimwhitespac": 127, "flag": [127, 187], "eventu": 127, "settolowercas": [127, 131], "nthi": 127, "setpositionalmask": 127, "settrimwhitespac": 127, "token2chunk": 128, "17": [128, 199], "tokenizedsent": 129, "rulefactori": 129, "targetpattern": 129, "grab": 129, "prefixpattern": 129, "suffixpattern": 129, "infixpattern": 129, "sub": [129, 187], "won": 129, "exceptionspath": 129, "casesensitiveexcept": 129, "contextchar": 129, "splitpattern": 129, "splitchar": 129, "didn": 129, "jane": 129, "boyfriend": 129, "getinfixpattern": 129, "getsuffixpattern": 129, "getprefixpattern": 129, "getcontextchar": 129, "getsplitchar": 129, "settargetpattern": 129, "setprefixpattern": 129, "setsuffixpattern": 129, "setinfixpattern": 129, "addinfixpattern": 129, "setexcept": 129, "getexcept": 129, "setexceptionspath": 129, "addexcept": 129, "setcasesensitiveexcept": 129, "getcasesensitiveexcept": 129, "addcontextchar": 129, "setsplitpattern": 129, "setsplitchar": 129, "addsplitchar": 129, "piec": 129, "token_rul": 129, "wordsegment": 131, "wordsegmenterapproach": 131, "korean": 131, "japanes": 131, "chines": 131, "correspond": [131, 167, 186], "wordsegmentermodel": 131, "tip": 131, "frame": 131, "least": 131, "frequent": 131, "ambiguitythreshold": 131, "enableregextoken": 131, "chinese_train": 131, "utf8": 131, "\u5341": 131, "ll": 131, "\u56db": 131, "rr": 131, "\u4e0d": 131, "\u662f": 131, "setniter": 131, "trainingdataset": 131, "setambiguitythreshold": 131, "getfrequencythreshold": 131, "getambiguitythreshold": 131, "setenableregextoken": 131, "plit": 131, "words_seg": 131, "wordseg_pku": 131, "zh": 131, "\u7136\u800c": 131, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 131, "\u9019\u6a23": 131, "\u7684": 131, "\u8655\u7406": 131, "\u4e5f": 131, "\u884d\u751f": 131, "\u4e86": 131, "\u4e00\u4e9b": 131, "\u554f\u984c": 131, "prepar": [132, 135, 141, 144], "outputcol": [132, 135, 136, 137, 138, 141, 144], "inferschema": 132, "tmp": [132, 141, 160, 205], "librispeech_asr_dummy_clean_audio_array_parquet": 132, "float_arrai": 132, "getoutputcol": [132, 135, 136, 137, 141, 144, 150], "chunk2doc": [133, 134], "back": [133, 186], "re": [133, 209], "doc2chunk": [133, 134], "pretrainedpipelin": [133, 137, 143, 159, 170, 208, 213, 214], "york": [133, 137], "jersei": [133, 137], "aren": [133, 137], "amongst": [133, 137], "explain_document_dl": [133, 137, 143, 159, 170], "chunktodoc": 133, "chunkconvert": 133, "explainresult": [133, 137], "22": [133, 137, 196, 208], "chunkcol": 134, "stringtyp": 134, "setisarrai": 134, "startcol": 134, "startcolbytokenindex": 134, "isarrai": 134, "failonmiss": 134, "fail": 134, "chunkassembl": 134, "setchunkcol": 134, "setstartcol": 134, "setstartcolbytokenindex": 134, "setfailonmiss": 134, "disabl": [135, 144], "idcol": [135, 144], "metadatacol": [135, 144], "cleanupmod": [135, 144], "cleanup": [135, 144], "inplac": [135, 144], "inplace_ful": [135, 144], "shrink_ful": [135, 144], "each_ful": [135, 144], "delete_ful": [135, 144], "setidcol": [135, 144], "setmetadatacol": [135, 144], "usabl": 136, "lda": 136, "forest": 136, "featurecol": 136, "cleanannot": [136, 137, 138], "outputasvector": 136, "gloveembed": 136, "finished_sentence_embed": 136, "resultwiths": 136, "1619900017976761": 136, "045552998781204224": 136, "03229299932718277": 136, "685609996318": 136, "42416998744010925": 136, "1378999948501587": 136, "5717899799346924": 136, "5078899860382": 136, "08621499687433243": 136, "15772999823093414": 136, "06067200005054474": 136, "395359992980": 136, "4970499873161316": 136, "7164199948310852": 136, "40119001269340515": 136, "05761000141501": 136, "08170200139284134": 136, "7159299850463867": 136, "20677000284194946": 136, "0295659992843": 136, "valuesplitsymbol": 137, "annotationsplitsymbol": 137, "includemetadata": 137, "outputasarrai": [137, 138], "parseembeddingsvector": 137, "setvaluesplitsymbol": 137, "setannotationsplitsymbol": 137, "setincludemetadata": [137, 210], "setoutputasarrai": [137, 138], "setparseembeddingsvector": 137, "finishedresult": 138, "hasrecursivefit": [139, 140], "java_obj": [139, 163, 166], "py4j": [139, 140, 166], "java_gatewai": [139, 140, 166], "javaobject": [139, 140, 166], "recursivepipelin": [139, 140, 145, 150], "hasrecursivetransform": 140, "chunk2_doc": [142, 160], "doc2_chunk": [142, 160], "embeddings_finish": [142, 160], "graph_finish": [142, 160], "has_recursive_fit": [142, 160], "has_recursive_transform": [142, 160], "light_pipelin": [142, 160], "recursive_pipelin": [142, 160], "token_assembl": [142, 160], "lightpipelin": [143, 170, 213], "parse_embed": [143, 170], "equival": [143, 160, 213], "execut": [143, 187, 209, 213], "hold": [143, 213], "principl": [143, 213], "everyth": [143, 213, 214], "fullannot": [143, 170], "happi": [143, 208, 210, 213, 214], "prp": [143, 197, 199, 208, 213, 214, 215], "rb": [143, 173, 188, 199, 208, 213, 214, 215], "optional_target": [143, 170], "explain_document_pipelin": [143, 159, 170, 208, 213, 214], "dict_kei": [143, 170], "fullannotateimag": [143, 170], "path_to_imag": [143, 170], "setignoreunsupport": 143, "unsupport": 143, "annotatormodel": [143, 149], "getignoreunsupport": 143, "calculationscol": 144, "text2": 144, "document1": 144, "document2": 144, "kwarg": [145, 187], "decid": 145, "advantag": 145, "behav": 145, "exactli": 145, "intent": 145, "recursivepipelinemodel": 145, "pipeline_model": [145, 167, 205], "intend": 145, "tab": [146, 167, 205], "escap": 146, "quot": 146, "inputformat": 146, "csvdelimit": 146, "defailt": 146, "comma": 146, "escapecsvdelimit": 146, "table_csv": 146, "csv_data": 146, "118": 146, "input_format": 146, "setcsvdelimit": 146, "setescapecsvdelimit": 146, "tokenassembl": 147, "reconstruct": 147, "cleantext": 147, "opensourc": 147, "annotatorapproach": [148, 156, 167], "subclass": [149, 162, 166, 182, 185], "ins": [149, 166], "uid": [149, 166], "annotatorproperti": 150, "setlazyannot": 150, "lazili": 150, "getlazyannot": 150, "annotator_approach": [153, 160], "annotator_model": [153, 160], "annotator_properti": [153, 160], "coverage_result": [153, 160], "recursive_annotator_approach": [153, 160], "hasembeddingsproperti": 154, "getdimens": 154, "constant": 155, "recursiveannotatorapproach": 156, "handl": [157, 198], "fo": 158, "assist": 159, "map_annot": 159, "f": [159, 167, 205], "output_typ": 159, "udf": 159, "userdefinedfunct": 159, "def": 159, "nnp_token": 159, "lambda": 159, "alia": 159, "epeu": 159, "map_annotations_arrai": 159, "map_annotations_strict": 159, "map_annotations_col": 159, "output_column": 159, "annotatyon_typ": 159, "chunks_df": 159, "pos_chunk": 159, "vbz": [159, 196, 215], "filter_by_annotations_col": 159, "filter_po": 159, "explode_annotations_col": 159, "annotator_java_ml": [160, 164], "annotator_transform": [160, 164], "extended_java_wrapp": [160, 164], "params_getters_sett": [160, 164], "comet": [160, 168, 207], "pretrained_pipelin": [160, 169], "resource_download": [160, 169], "pub_tat": [160, 198], "annotation_audio": 160, "annotation_imag": 160, "aarch64": 160, "cache_fold": 160, "log_fold": 160, "cluster_tmp_dir": 160, "real_time_output": 160, "output_level": 160, "correctli": 160, "maco": 160, "linux": 160, "alloc": 160, "directori": [160, 205], "cache_pretrain": 160, "temporarili": 160, "unpack": 160, "hadoop": 160, "dir": 160, "s3": 160, "hdf": 160, "dbf": 160, "annotator_log": 160, "annotatorjavamlread": 161, "mixin": 161, "javamlread": 161, "classmethod": 161, "mlreader": 161, "clazz": 161, "rl": 161, "javaparam": 161, "annotatortransform": 162, "ensur": 162, "_java_obj": 162, "extens": 163, "javawrapp": 163, "extendedjavawrapp": 163, "new_java_arrai": 163, "pylist": 163, "java_class": 163, "todo": 163, "chang": [163, 184, 187], "paramsgetterssett": 165, "getparamvalu": 165, "paramnam": 165, "setparamvalu": 165, "recursiveestim": 166, "tupl": [166, 185, 186, 187], "overrid": 166, "recursivetransform": 166, "cometlogg": [167, 205], "workspac": 167, "project_nam": [167, 205], "comet_mod": [167, 205], "experiment_id": 167, "experiment_kwarg": 167, "logger": [167, 205], "meta": [167, 207], "practition": [167, 205], "reliabl": [167, 205], "streamlin": [167, 205], "lifecycl": [167, 205, 207], "track": [167, 205, 206], "explain": [167, 205, 212, 214], "reproduc": [167, 205, 206], "outputlogpath": [167, 205], "onlin": [167, 187, 205], "reus": [167, 181, 183, 185, 187], "importerror": 167, "output_log_path": [167, 205], "embd": [167, 205], "setshuffleperepoch": [167, 205], "logdir": [167, 205], "interfac": [167, 205, 213], "chart": [167, 205], "comet_ml": [167, 205], "log_pipeline_paramet": [167, 205], "log_visu": [167, 205], "html": [167, 205], "viz": [167, 205], "upload": 167, "colum": [167, 205], "ner_chunk": [167, 205], "sparknlp_displai": [167, 205], "nervisu": [167, 205], "idx": [167, 205], "enumer": [167, 205], "label_col": [167, 205], "document_col": [167, 205], "return_html": [167, 205], "log_metr": [167, 205], "sklearn": [167, 205], "preprocess": [167, 205], "multilabelbinar": [167, 205], "classification_report": [167, 205], "preds_df": [167, 205], "topanda": [167, 205], "mlb": [167, 205], "y_true": [167, 205], "fit_transform": [167, 205], "y_pred": [167, 205], "output_dict": [167, 205], "log_paramet": 167, "log_completed_run": 167, "log_file_path": 167, "complet": [167, 206], "log_asset": 167, "asset_path": 167, "asset": 167, "log_asset_data": 167, "interv": 167, "refresh": 167, "outstand": 167, "disk_loc": 170, "fulli": 170, "light_model": 170, "gather": 170, "langaug": 170, "resourcedownload": 171, "wrongtfvers": [173, 188], "exit": [173, 188], "tensorflowaddonsneed": 173, "tfgraphbuild": [173, 188], "build_param": [173, 188], "generic_classifi": [173, 188], "assertion_dl": [173, 188], "relation_extract": [173, 188], "healthcar": [173, 188], "tfgraph": [173, 188], "tf_graph": [173, 188], "get_model": [173, 188], "nertfgraphbuild": [173, 188], "feat_siz": [173, 188], "n_class": [173, 188], "embeddings_dim": [173, 188], "nchar": [173, 188], "ntag": [173, 188], "model_loc": [173, 188], "medical_ner_graph": [173, 188], "model_filenam": [173, 188], "ner_log": [173, 188], "tfgraphbuilderfactori": [173, 188], "factori": [173, 188], "model_nam": [173, 188], "filenam": [173, 188], "ner_graph": [173, 188], "print_model_param": [173, 188], "tf2contrib": 174, "core_rnn_cel": [174, 184], "fused_rnn_cel": [174, 184], "gru_op": [174, 184], "lstm_op": [174, 184], "rnn_cell": [174, 182, 184], "core": 181, "embeddingwrapp": 181, "inputprojectionwrapp": 181, "outputprojectionwrapp": 181, "embedding_class": 181, "embedding_s": 181, "num_proj": [181, 187], "input_s": [181, 185, 186, 187], "output_s": [181, 185], "fuse": 182, "fusedrnncel": [182, 185], "expand": 182, "recurr": [182, 185, 186, 187], "rnncell": [182, 186, 187], "__call__": 182, "signatur": 182, "fusedrnncelladaptor": 182, "use_dynamic_rnn": 182, "adaptor": 182, "timereversedfusedrnn": 182, "revers": 182, "basicrnncel": 182, "fw_lstm": 182, "bw_lstm": 182, "fw_out": 182, "fw_state": 182, "bw_out": 182, "bw_state": 182, "grublockcel": 183, "num_unit": [183, 185, 187], "cell_siz": 183, "gru_cel": 183, "deprec": 183, "grublockcellv2": 183, "ab": [183, 185, 186, 187], "1406": [183, 187], "1078": [183, 187], "forward": [183, 186], "propag": [183, 187], "mathemat": 183, "equat": [183, 187], "b_ru": 183, "constant_initi": 183, "b_c": 183, "x_h_prev": 183, "h_prev": 183, "r_bar": 183, "u_bar": 183, "w_ru": 183, "h_prevr": 183, "circ": [183, 187], "x_h_prevr": 183, "c_bar": 183, "w_c": [183, 187], "tanh": [183, 187], "h": [183, 187], "temporari": 183, "impl": 183, "input_shap": [183, 187], "lstmblockcel": 185, "forget_bia": [185, 187], "cell_clip": [185, 187], "use_peephol": [185, 187], "dtype": [185, 186, 187], "lstm_cell": 185, "1409": 185, "2329": 185, "forget": [185, 187], "gate": [185, 187], "rnn_cell_impl": [185, 187], "lstmcell": [185, 187], "monolith": 185, "short": [185, 187], "lstmblockwrapp": 185, "housekeep": 185, "_call_cel": 185, "initial_st": 185, "sequence_length": [185, 186], "time_len": 185, "initial_cell_st": 185, "initial_output": 185, "_num_unit": 185, "heterogen": 185, "int32": [185, 186], "int64": [185, 186], "cell_stat": 185, "valueerror": [185, 186, 187], "mismatch": 185, "lstmblockfusedcel": 185, "lstm_fused_cel": 185, "extrem": 185, "stack_bidirectional_rnn": 186, "cells_fw": 186, "cells_bw": 186, "initial_states_fw": 186, "initial_states_bw": 186, "stack": [186, 187], "sever": [186, 215], "backward": 186, "bidirectional_rnn": 186, "intermedi": 186, "1303": 186, "5778": 186, "appropri": 186, "cell_fw": 186, "state_s": [186, 187], "variablescop": 186, "subgraph": 186, "output_state_fw": 186, "output_state_bw": 186, "output_states_fw": 186, "output_states_bw": 186, "typeerror": 186, "cell_bw": 186, "stack_bidirectional_dynamic_rnn": 186, "parallel_iter": 186, "time_major": 186, "swap_memori": 186, "max_tim": 186, "major": 186, "emit": 186, "transpar": 186, "produc": [186, 187, 209], "prop": 186, "cpu": 186, "layers_output": 186, "coupledinputforgetgatelstmcel": 187, "proj_clip": 187, "num_unit_shard": 187, "num_proj_shard": 187, "state_is_tupl": 187, "math_op": 187, "layer_norm": 187, "norm_gain": 187, "norm_shift": 187, "peephol": 187, "pdf": 187, "semanticscholar": 187, "1154": 187, "0131eae85b2e11d53df7f1360eeb6476e7f4": 187, "felix": 187, "ger": 187, "jurgen": 187, "schmidhub": 187, "fred": 187, "cummin": 187, "iet": 187, "850": 187, "855": 187, "1999": 187, "pub": 187, "archiv": 187, "43905": 187, "hasim": 187, "sak": 187, "andrew": 187, "senior": 187, "francois": 187, "beaufai": 187, "interspeech": 187, "2014": 187, "coupl": 187, "1503": 187, "04069": 187, "greff": 187, "odyssei": 187, "peep": 187, "hole": 187, "1607": 187, "06450": 187, "jimmi": 187, "lei": 187, "ba": 187, "jami": 187, "ryan": 187, "kiro": 187, "geoffrei": 187, "hinton": 187, "nonlinear": 187, "2d": 187, "c_state": 187, "m_state": 187, "output_dim": 187, "cannot": 187, "timefreqlstmcel": 187, "feature_s": 187, "frequency_skip": 187, "tara": 187, "sainath": 187, "bo": 187, "li": 187, "lvcsr": 187, "2016": 187, "clip": 187, "gridlstmcel": 187, "share_time_frequency_weight": 187, "num_frequency_block": 187, "start_freqindex_list": 187, "end_freqindex_list": 187, "couple_input_forget_g": 187, "grid": 187, "nal": 187, "kalchbrenn": 187, "ivo": 187, "danihelka": 187, "alex": 187, "proc": 187, "iclr": 187, "1507": 187, "01526": 187, "shared_weight": 187, "_state_is_tupl": 187, "bidirectionalgridlstmcel": 187, "backward_slice_offset": 187, "gridlstm": 187, "attentioncellwrapp": 187, "attn_length": 187, "attn_siz": 187, "attn_vec_s": 187, "1601": 187, "06733": 187, "lstma": 187, "highwaywrapp": 187, "couple_carry_transform_g": 187, "carry_bias_init": 187, "highwai": 187, "srivastava": 187, "preprint": 187, "1505": 187, "00387": 187, "layernormbasiclstmcel": 187, "dropout_keep_prob": 187, "dropout_prob_se": 187, "1603": 187, "05118": 187, "stanislau": 187, "semeniuta": 187, "aliaksei": 187, "severyn": 187, "erhardt": 187, "barth": 187, "nascel": 187, "use_bia": 187, "na": 187, "1611": 187, "01578": 187, "barret": 187, "zoph": 187, "quoc": 187, "reinforc": 187, "2017": 187, "ugrnncel": 187, "ugrnn": 187, "compromis": 187, "vanilla": 187, "instantan": 187, "feedforward": 187, "09913": 187, "jasmin": 187, "collin": 187, "jascha": 187, "sohl": 187, "dickstein": 187, "david": 187, "sussillo": 187, "num": 187, "new_output": 187, "ident": 187, "new_stat": 187, "intersectionrnncel": 187, "num_in_proj": 187, "y_activ": 187, "nn_op": 187, "relu": 187, "flow": 187, "subsequ": 187, "deepli": 187, "new_i": 187, "compiledwrapp": 187, "compile_st": 187, "jit": 187, "phasedlstmcel": 187, "leak": 187, "ratio_on": 187, "trainable_ratio_on": 187, "period_init_min": 187, "period_init_max": 187, "1610": 187, "09513v1": 187, "float32": 187, "float64": 187, "features_s": 187, "lstmstatetupl": 187, "timestep": 187, "convlstmcel": 187, "conv_ndim": 187, "output_channel": 187, "kernel_shap": 187, "skip_connect": 187, "conv_lstm_cel": 187, "1506": 187, "04214v1": 187, "conv1dlstmcel": 187, "conv_1d_lstm_cel": 187, "1d": 187, "conv2dlstmcel": 187, "conv_2d_lstm_cel": 187, "conv3dlstmcel": 187, "conv_3d_lstm_cel": 187, "3d": 187, "glstmcell": 187, "number_of_group": 187, "1703": 187, "10722": 187, "kuchaiev": 187, "ginsburg": 187, "trick": 187, "brief": 187, "evenli": 187, "fed": 187, "receiv": [187, 199, 215], "num_input": 187, "known": 187, "divis": 187, "innermost": 187, "incompat": 187, "layernormlstmcel": 187, "srucel": 187, "sru": 187, "cf": 187, "1709": 187, "02755": 187, "character": 187, "simplifi": 187, "consecut": 187, "tradition": 187, "multipli": 187, "matrix": 187, "w_hh": 187, "ensu": 187, "flavor": 187, "h_": 187, "pointwis": 187, "mistak": 187, "argument": 187, "weightnormlstmcel": 187, "norm": 187, "1602": 187, "07868": 187, "tim": 187, "saliman": 187, "diederik": 187, "kingma": 187, "reparameter": 187, "indrnncel": 187, "indrnn": 187, "1803": 187, "04831": 187, "indygrucel": 187, "kernel_initi": 187, "bias_initi": 187, "grucel": 187, "yet": 187, "u_r": 187, "u_z": 187, "diagon": 187, "hadamard": 187, "r_j": 187, "sigmaleft": 187, "mathbf": 187, "w_rmathbf": 187, "_j": 187, "u_rcirc": 187, "_jright": 187, "z_j": 187, "w_zmathbf": 187, "u_zcirc": 187, "tild": 187, "phileft": 187, "denot": 187, "indygru": 187, "oppos": 187, "nunit": 187, "indylstmcel": 187, "indylstm": 187, "basiclstmcel": 187, "u_f": 187, "u_i": 187, "u_o": 187, "u_c": 187, "f_t": 187, "sigma_gleft": 187, "w_f": 187, "x_t": 187, "b_fright": 187, "i_t": 187, "w_i": 187, "b_iright": 187, "o_t": 187, "w_o": 187, "b_oright": 187, "c_t": 187, "c_": 187, "sigma_cleft": 187, "b_cright": 187, "1903": 187, "08023": 187, "ntmcell": 187, "memory_s": 187, "memory_vector_dim": 187, "read_head_num": 187, "write_head_num": 187, "shift_rang": 187, "clip_valu": 187, "ture": 187, "1807": 187, "08518": 187, "collier": 187, "joeran": 187, "beel": 187, "snowkylin": 187, "ntm": 187, "cours": 187, "1410": 187, "5401": 187, "wayn": 187, "minimalrnncel": 187, "glorot_uniform": 187, "ones": 187, "minimalrnn": 187, "1806": 187, "05394v2": 187, "minmin": 187, "jeffrei": 187, "pennington": 187, "samuel": 187, "schoenholz": 187, "isometri": 187, "theori": 187, "icml": 187, "cfncell": 187, "chao": 187, "openreview": 187, "net": 187, "s1dizvclg": 187, "thoma": 187, "jame": 187, "von": 187, "brecht": 187, "cfn": 187, "goe": 187, "contract": 187, "decoupl": 187, "tf_graph_1x": 188, "documentcol": [196, 197], "sentencecol": [196, 197], "tokencol": 196, "conlllabelindex": 196, "conllposindex": 196, "textcol": [196, 197], "labelcol": 196, "docstart": [196, 215], "eu": [196, 215], "np": [196, 215], "reject": [196, 215], "vp": [196, 215], "misc": [196, 215], "boycott": [196, 215], "british": [196, 215], "lamb": [196, 215], "blackburn": 196, "brussel": 196, "1996": 196, "08": 196, "storage_level": 196, "storagelevel": 196, "disk_onli": 196, "lift": 196, "persist": 196, "uposcol": 197, "upo": 197, "xposcol": 197, "xpo": 197, "lemmacol": 197, "sent_id": 197, "sell": 197, "pron": 197, "nom": 197, "plur": 197, "_": 197, "tens": 197, "conj": 197, "cc": 197, "spaceaft": 197, "No": [197, 208], "punct": 197, "conllufil": [197, 215], "conlldataset": [197, 215], "morph": 197, "Into": 197, "googleo": 197, "sconj": 197, "propn": 197, "adp": 197, "wp": 197, "vbd": [197, 199, 215], "ago": [199, 215], "posdf": 199, "61": 199, "56": 199, "67": [199, 200, 215], "nonexecut": 199, "69": 199, "76": 199, "director": 199, "78": 199, "81": 199, "84": 199, "outputposcol": 199, "outputdocumentcol": 199, "outputtextcol": 199, "pubtat": [200, 212], "medic": [200, 215], "medment": [200, 215], "25763772": [200, 215], "dctn4": [200, 215], "t116": [200, 215], "t123": [200, 215], "c4308010": [200, 215], "63": [200, 215], "chronic": [200, 215], "pseudomona": [200, 215], "aeruginosa": [200, 215], "infect": [200, 215], "t047": [200, 215], "c0854135": [200, 215], "82": [200, 215], "cystic": [200, 215], "fibrosi": [200, 215], "c0010674": [200, 215], "120": [200, 215], "pa": [200, 215], "124": [200, 215], "139": [200, 215], "pubtatorfil": 200, "corpus_pubtator_sampl": 200, "pubtatordataset": 200, "doc_id": 200, "finished_token": [200, 210], "finished_po": 200, "finished_n": 200, "finished_token_metadata": 200, "finished_pos_metadata": 200, "finished_label_metadata": 200, "mo": 200, "ispaddedtoken": 200, "pad": 200, "workflow": 205, "dedic": 205, "account": 205, "inspect": 205, "init": 205, "sparknlp_experi": 205, "offline_directori": 205, "later": 205, "nativ": 206, "record": 206, "queri": 206, "registri": 206, "discov": 206, "central": 206, "send": 207, "messag": 207, "mlflow": 207, "clearli": 208, "explain_document_ml": [208, 213, 214], "approx": [208, 213, 214], "mb": [208, 213, 214], "ok": [208, 213, 214], "spearhead": 209, "declar": 209, "accordingli": 209, "extra_loc": 209, "offer": [209, 211, 214], "column_nam": 209, "preced": 209, "interchang": 210, "anoth": 210, "road": 210, "proce": 210, "At": 210, "sens": 214, "constantli": 214, "server": 214, "train_po": 215, "training_conl": 215, "train_corpu": 215, "withcolumnrenam": 215, "trainingpubtatordf": 215, "corpus_pubt": 215}, "objects": {"": [[160, 0, 0, "-", "sparknlp"]], "sparknlp": [[12, 0, 0, "-", "annotation"], [13, 0, 0, "-", "annotation_audio"], [14, 0, 0, "-", "annotation_image"], [82, 0, 0, "-", "annotator"], [142, 0, 0, "-", "base"], [153, 0, 0, "-", "common"], [159, 0, 0, "-", "functions"], [164, 0, 0, "-", "internal"], [168, 0, 0, "-", "logging"], [169, 0, 0, "-", "pretrained"], [160, 3, 1, "", "start"], [198, 0, 0, "-", "training"], [202, 0, 0, "-", "upload_to_hub"], [203, 0, 0, "-", "util"], [160, 3, 1, "", "version"]], "sparknlp.annotation": [[12, 1, 1, "", "Annotation"]], "sparknlp.annotation.Annotation": [[12, 2, 1, "", "arrayType"], [12, 2, 1, "", "copy"], [12, 2, 1, "", "dataType"], [12, 2, 1, "", "fromRow"], [12, 2, 1, "", "toRow"]], "sparknlp.annotation_audio": [[13, 1, 1, "", "AnnotationAudio"]], "sparknlp.annotation_audio.AnnotationAudio": [[13, 2, 1, "", "copy"]], "sparknlp.annotation_image": [[14, 1, 1, "", "AnnotationImage"]], "sparknlp.annotation_image.AnnotationImage": [[14, 2, 1, "", "copy"]], "sparknlp.annotator": [[16, 0, 0, "-", "audio"], [18, 0, 0, "-", "chunker"], [35, 0, 0, "-", "classifier_dl"], [50, 0, 0, "-", "coref"], [52, 0, 0, "-", "cv"], [56, 0, 0, "-", "dependency"], [58, 0, 0, "-", "document_normalizer"], [68, 0, 0, "-", "embeddings"], [80, 0, 0, "-", "er"], [81, 0, 0, "-", "graph_extraction"], [83, 0, 0, "-", "keyword_extraction"], [85, 0, 0, "-", "ld_dl"], [87, 0, 0, "-", "lemmatizer"], [90, 0, 0, "-", "matcher"], [94, 0, 0, "-", "n_gram_generator"], [95, 0, 0, "-", "ner"], [101, 0, 0, "-", "normalizer"], [104, 0, 0, "-", "param"], [105, 0, 0, "-", "pos"], [107, 0, 0, "-", "sentence"], [110, 0, 0, "-", "sentiment"], [114, 0, 0, "-", "seq2seq"], [118, 0, 0, "-", "spell_check"], [121, 0, 0, "-", "stemmer"], [122, 0, 0, "-", "stop_words_cleaner"], [123, 0, 0, "-", "tf_ner_dl_graph_builder"], [125, 0, 0, "-", "token"], [130, 0, 0, "-", "ws"]], "sparknlp.annotator.audio": [[15, 0, 0, "-", "hubert_for_ctc"], [17, 0, 0, "-", "wav2vec2_for_ctc"]], "sparknlp.annotator.audio.hubert_for_ctc": [[15, 1, 1, "", "HubertForCTC"]], "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC": [[15, 2, 1, "", "loadSavedModel"], [15, 2, 1, "", "pretrained"], [15, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[17, 1, 1, "", "Wav2Vec2ForCTC"]], "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[17, 2, 1, "", "loadSavedModel"], [17, 2, 1, "", "pretrained"], [17, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.chunker": [[18, 1, 1, "", "Chunker"]], "sparknlp.annotator.chunker.Chunker": [[18, 2, 1, "", "setRegexParsers"]], "sparknlp.annotator.classifier_dl": [[19, 0, 0, "-", "albert_for_question_answering"], [20, 0, 0, "-", "albert_for_sequence_classification"], [21, 0, 0, "-", "albert_for_token_classification"], [22, 0, 0, "-", "bert_for_question_answering"], [23, 0, 0, "-", "bert_for_sequence_classification"], [24, 0, 0, "-", "bert_for_token_classification"], [25, 0, 0, "-", "camembert_for_question_answering"], [26, 0, 0, "-", "camembert_for_sequence_classification"], [27, 0, 0, "-", "camembert_for_token_classification"], [28, 0, 0, "-", "classifier_dl"], [29, 0, 0, "-", "deberta_for_question_answering"], [30, 0, 0, "-", "deberta_for_sequence_classification"], [31, 0, 0, "-", "deberta_for_token_classification"], [32, 0, 0, "-", "distil_bert_for_question_answering"], [33, 0, 0, "-", "distil_bert_for_sequence_classification"], [34, 0, 0, "-", "distil_bert_for_token_classification"], [36, 0, 0, "-", "longformer_for_question_answering"], [37, 0, 0, "-", "longformer_for_sequence_classification"], [38, 0, 0, "-", "longformer_for_token_classification"], [39, 0, 0, "-", "multi_classifier_dl"], [40, 0, 0, "-", "roberta_for_question_answering"], [41, 0, 0, "-", "roberta_for_sequence_classification"], [42, 0, 0, "-", "roberta_for_token_classification"], [43, 0, 0, "-", "sentiment_dl"], [44, 0, 0, "-", "tapas_for_question_answering"], [45, 0, 0, "-", "xlm_roberta_for_question_answering"], [46, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [47, 0, 0, "-", "xlm_roberta_for_token_classification"], [48, 0, 0, "-", "xlnet_for_sequence_classification"], [49, 0, 0, "-", "xlnet_for_token_classification"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[19, 1, 1, "", "AlbertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[19, 2, 1, "", "loadSavedModel"], [19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setConfigProtoBytes"], [19, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[20, 1, 1, "", "AlbertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[20, 2, 1, "", "getClasses"], [20, 2, 1, "", "loadSavedModel"], [20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setCoalesceSentences"], [20, 2, 1, "", "setConfigProtoBytes"], [20, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[21, 1, 1, "", "AlbertForTokenClassification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[21, 2, 1, "", "getClasses"], [21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[22, 1, 1, "", "BertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[23, 1, 1, "", "BertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[23, 2, 1, "", "getClasses"], [23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setCoalesceSentences"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[24, 1, 1, "", "BertForTokenClassification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[24, 2, 1, "", "getClasses"], [24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[25, 1, 1, "", "CamemBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering": [[25, 2, 1, "", "loadSavedModel"], [25, 2, 1, "", "pretrained"], [25, 2, 1, "", "setConfigProtoBytes"], [25, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[26, 1, 1, "", "CamemBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification": [[26, 2, 1, "", "getClasses"], [26, 2, 1, "", "loadSavedModel"], [26, 2, 1, "", "pretrained"], [26, 2, 1, "", "setCoalesceSentences"], [26, 2, 1, "", "setConfigProtoBytes"], [26, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[27, 1, 1, "", "CamemBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[27, 2, 1, "", "getClasses"], [27, 2, 1, "", "loadSavedModel"], [27, 2, 1, "", "pretrained"], [27, 2, 1, "", "setConfigProtoBytes"], [27, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[28, 1, 1, "", "ClassifierDLApproach"], [28, 1, 1, "", "ClassifierDLModel"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[28, 2, 1, "", "setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[28, 2, 1, "", "pretrained"], [28, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[29, 1, 1, "", "DeBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[29, 2, 1, "", "loadSavedModel"], [29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[30, 1, 1, "", "DeBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[30, 2, 1, "", "getClasses"], [30, 2, 1, "", "loadSavedModel"], [30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setCoalesceSentences"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[31, 1, 1, "", "DeBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[31, 2, 1, "", "getClasses"], [31, 2, 1, "", "loadSavedModel"], [31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[32, 1, 1, "", "DistilBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[32, 2, 1, "", "loadSavedModel"], [32, 2, 1, "", "pretrained"], [32, 2, 1, "", "setConfigProtoBytes"], [32, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[33, 1, 1, "", "DistilBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[33, 2, 1, "", "getClasses"], [33, 2, 1, "", "loadSavedModel"], [33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setCoalesceSentences"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[34, 1, 1, "", "DistilBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[34, 2, 1, "", "getClasses"], [34, 2, 1, "", "loadSavedModel"], [34, 2, 1, "", "pretrained"], [34, 2, 1, "", "setConfigProtoBytes"], [34, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[36, 1, 1, "", "LongformerForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[36, 2, 1, "", "loadSavedModel"], [36, 2, 1, "", "pretrained"], [36, 2, 1, "", "setConfigProtoBytes"], [36, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[37, 1, 1, "", "LongformerForSequenceClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[37, 2, 1, "", "getClasses"], [37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"], [37, 2, 1, "", "setCoalesceSentences"], [37, 2, 1, "", "setConfigProtoBytes"], [37, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[38, 1, 1, "", "LongformerForTokenClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[38, 2, 1, "", "getClasses"], [38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[39, 1, 1, "", "MultiClassifierDLApproach"], [39, 1, 1, "", "MultiClassifierDLModel"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[39, 2, 1, "", "setThreshold"], [39, 2, 1, "", "setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setThreshold"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[40, 1, 1, "", "RoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[40, 2, 1, "", "loadSavedModel"], [40, 2, 1, "", "pretrained"], [40, 2, 1, "", "setConfigProtoBytes"], [40, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[41, 1, 1, "", "RoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[41, 2, 1, "", "getClasses"], [41, 2, 1, "", "loadSavedModel"], [41, 2, 1, "", "pretrained"], [41, 2, 1, "", "setCoalesceSentences"], [41, 2, 1, "", "setConfigProtoBytes"], [41, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[42, 1, 1, "", "RoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[42, 2, 1, "", "getClasses"], [42, 2, 1, "", "loadSavedModel"], [42, 2, 1, "", "pretrained"], [42, 2, 1, "", "setConfigProtoBytes"], [42, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[43, 1, 1, "", "SentimentDLApproach"], [43, 1, 1, "", "SentimentDLModel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[43, 2, 1, "", "setDropout"], [43, 2, 1, "", "setThreshold"], [43, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[43, 2, 1, "", "pretrained"], [43, 2, 1, "", "setConfigProtoBytes"], [43, 2, 1, "", "setThreshold"], [43, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[44, 1, 1, "", "TapasForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[45, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[45, 2, 1, "", "loadSavedModel"], [45, 2, 1, "", "pretrained"], [45, 2, 1, "", "setConfigProtoBytes"], [45, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[46, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[46, 2, 1, "", "getClasses"], [46, 2, 1, "", "loadSavedModel"], [46, 2, 1, "", "pretrained"], [46, 2, 1, "", "setCoalesceSentences"], [46, 2, 1, "", "setConfigProtoBytes"], [46, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[47, 1, 1, "", "XlmRoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[47, 2, 1, "", "getClasses"], [47, 2, 1, "", "loadSavedModel"], [47, 2, 1, "", "pretrained"], [47, 2, 1, "", "setConfigProtoBytes"], [47, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[48, 1, 1, "", "XlnetForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[48, 2, 1, "", "getClasses"], [48, 2, 1, "", "loadSavedModel"], [48, 2, 1, "", "pretrained"], [48, 2, 1, "", "setCoalesceSentences"], [48, 2, 1, "", "setConfigProtoBytes"], [48, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[49, 1, 1, "", "XlnetForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[49, 2, 1, "", "getClasses"], [49, 2, 1, "", "loadSavedModel"], [49, 2, 1, "", "pretrained"], [49, 2, 1, "", "setConfigProtoBytes"], [49, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.coref": [[51, 0, 0, "-", "spanbert_coref"]], "sparknlp.annotator.coref.spanbert_coref": [[51, 1, 1, "", "SpanBertCorefModel"]], "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[51, 2, 1, "", "loadSavedModel"], [51, 2, 1, "", "pretrained"], [51, 2, 1, "", "setConfigProtoBytes"], [51, 2, 1, "", "setMaxSegmentLength"], [51, 2, 1, "", "setMaxSentenceLength"], [51, 2, 1, "", "setTextGenre"]], "sparknlp.annotator.cv": [[53, 0, 0, "-", "swin_for_image_classification"], [54, 0, 0, "-", "vit_for_image_classification"]], "sparknlp.annotator.cv.swin_for_image_classification": [[53, 1, 1, "", "SwinForImageClassification"]], "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification": [[53, 2, 1, "", "getClasses"], [53, 2, 1, "", "loadSavedModel"], [53, 2, 1, "", "pretrained"], [53, 2, 1, "", "setConfigProtoBytes"], [53, 2, 1, "", "setDoRescale"], [53, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.vit_for_image_classification": [[54, 1, 1, "", "ViTForImageClassification"]], "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[54, 2, 1, "", "getClasses"], [54, 2, 1, "", "loadSavedModel"], [54, 2, 1, "", "pretrained"], [54, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.dependency": [[55, 0, 0, "-", "dependency_parser"], [57, 0, 0, "-", "typed_dependency_parser"]], "sparknlp.annotator.dependency.dependency_parser": [[55, 1, 1, "", "DependencyParserApproach"], [55, 1, 1, "", "DependencyParserModel"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[55, 2, 1, "", "setConllU"], [55, 2, 1, "", "setDependencyTreeBank"], [55, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[55, 2, 1, "", "pretrained"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[57, 1, 1, "", "TypedDependencyParserApproach"], [57, 1, 1, "", "TypedDependencyParserModel"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[57, 2, 1, "", "setConll2009"], [57, 2, 1, "", "setConllU"], [57, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[57, 2, 1, "", "pretrained"]], "sparknlp.annotator.document_normalizer": [[58, 1, 1, "", "DocumentNormalizer"]], "sparknlp.annotator.document_normalizer.DocumentNormalizer": [[58, 2, 1, "", "setAction"], [58, 2, 1, "", "setEncoding"], [58, 2, 1, "", "setLowercase"], [58, 2, 1, "", "setPatterns"], [58, 2, 1, "", "setPolicy"], [58, 2, 1, "", "setReplacement"]], "sparknlp.annotator.embeddings": [[59, 0, 0, "-", "albert_embeddings"], [60, 0, 0, "-", "bert_embeddings"], [61, 0, 0, "-", "bert_sentence_embeddings"], [62, 0, 0, "-", "camembert_embeddings"], [63, 0, 0, "-", "chunk_embeddings"], [64, 0, 0, "-", "deberta_embeddings"], [65, 0, 0, "-", "distil_bert_embeddings"], [66, 0, 0, "-", "doc2vec"], [67, 0, 0, "-", "elmo_embeddings"], [69, 0, 0, "-", "longformer_embeddings"], [70, 0, 0, "-", "roberta_embeddings"], [71, 0, 0, "-", "roberta_sentence_embeddings"], [72, 0, 0, "-", "sentence_embeddings"], [73, 0, 0, "-", "universal_sentence_encoder"], [74, 0, 0, "-", "word2vec"], [75, 0, 0, "-", "word_embeddings"], [76, 0, 0, "-", "xlm_roberta_embeddings"], [77, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [78, 0, 0, "-", "xlnet_embeddings"]], "sparknlp.annotator.embeddings.albert_embeddings": [[59, 1, 1, "", "AlbertEmbeddings"]], "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[59, 2, 1, "", "loadSavedModel"], [59, 2, 1, "", "pretrained"], [59, 2, 1, "", "setConfigProtoBytes"], [59, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[60, 1, 1, "", "BertEmbeddings"]], "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[60, 2, 1, "", "loadSavedModel"], [60, 2, 1, "", "pretrained"], [60, 2, 1, "", "setConfigProtoBytes"], [60, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[61, 1, 1, "", "BertSentenceEmbeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[61, 2, 1, "", "loadSavedModel"], [61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setConfigProtoBytes"], [61, 2, 1, "", "setIsLong"], [61, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[62, 1, 1, "", "CamemBertEmbeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[62, 2, 1, "", "loadSavedModel"], [62, 2, 1, "", "pretrained"], [62, 2, 1, "", "setConfigProtoBytes"], [62, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[63, 1, 1, "", "ChunkEmbeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[63, 2, 1, "", "setPoolingStrategy"], [63, 2, 1, "", "setSkipOOV"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[64, 1, 1, "", "DeBertaEmbeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[64, 2, 1, "", "loadSavedModel"], [64, 2, 1, "", "pretrained"], [64, 2, 1, "", "setConfigProtoBytes"], [64, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[65, 1, 1, "", "DistilBertEmbeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[65, 2, 1, "", "loadSavedModel"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setConfigProtoBytes"], [65, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.doc2vec": [[66, 1, 1, "", "Doc2VecApproach"], [66, 1, 1, "", "Doc2VecModel"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[66, 2, 1, "", "setMaxIter"], [66, 2, 1, "", "setMaxSentenceLength"], [66, 2, 1, "", "setMinCount"], [66, 2, 1, "", "setNumPartitions"], [66, 2, 1, "", "setSeed"], [66, 2, 1, "", "setStepSize"], [66, 2, 1, "", "setVectorSize"], [66, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[66, 2, 1, "", "pretrained"], [66, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[67, 1, 1, "", "ElmoEmbeddings"]], "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[67, 2, 1, "", "loadSavedModel"], [67, 2, 1, "", "pretrained"], [67, 2, 1, "", "setBatchSize"], [67, 2, 1, "", "setConfigProtoBytes"], [67, 2, 1, "", "setPoolingLayer"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[69, 1, 1, "", "LongformerEmbeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[69, 2, 1, "", "loadSavedModel"], [69, 2, 1, "", "pretrained"], [69, 2, 1, "", "setConfigProtoBytes"], [69, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[70, 1, 1, "", "RoBertaEmbeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[70, 2, 1, "", "loadSavedModel"], [70, 2, 1, "", "pretrained"], [70, 2, 1, "", "setConfigProtoBytes"], [70, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[71, 1, 1, "", "RoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[71, 2, 1, "", "loadSavedModel"], [71, 2, 1, "", "pretrained"], [71, 2, 1, "", "setConfigProtoBytes"], [71, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[72, 1, 1, "", "SentenceEmbeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[72, 2, 1, "", "setPoolingStrategy"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[73, 1, 1, "", "UniversalSentenceEncoder"]], "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[73, 2, 1, "", "loadSavedModel"], [73, 2, 1, "", "pretrained"], [73, 2, 1, "", "setConfigProtoBytes"], [73, 2, 1, "", "setLoadSP"]], "sparknlp.annotator.embeddings.word2vec": [[74, 1, 1, "", "Word2VecApproach"], [74, 1, 1, "", "Word2VecModel"]], "sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[74, 2, 1, "", "setMaxIter"], [74, 2, 1, "", "setMaxSentenceLength"], [74, 2, 1, "", "setMinCount"], [74, 2, 1, "", "setNumPartitions"], [74, 2, 1, "", "setSeed"], [74, 2, 1, "", "setStepSize"], [74, 2, 1, "", "setVectorSize"], [74, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[74, 2, 1, "", "pretrained"], [74, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[75, 1, 1, "", "WordEmbeddings"], [75, 1, 1, "", "WordEmbeddingsModel"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[75, 2, 1, "", "setReadCacheSize"], [75, 2, 1, "", "setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[75, 2, 1, "", "loadStorage"], [75, 2, 1, "", "overallCoverage"], [75, 2, 1, "", "pretrained"], [75, 2, 1, "", "setReadCacheSize"], [75, 2, 1, "", "withCoverageColumn"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[76, 1, 1, "", "XlmRoBertaEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[76, 2, 1, "", "loadSavedModel"], [76, 2, 1, "", "pretrained"], [76, 2, 1, "", "setConfigProtoBytes"], [76, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[77, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[77, 2, 1, "", "loadSavedModel"], [77, 2, 1, "", "pretrained"], [77, 2, 1, "", "setConfigProtoBytes"], [77, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[78, 1, 1, "", "XlnetEmbeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[78, 2, 1, "", "loadSavedModel"], [78, 2, 1, "", "pretrained"], [78, 2, 1, "", "setConfigProtoBytes"], [78, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.er": [[79, 0, 0, "-", "entity_ruler"]], "sparknlp.annotator.er.entity_ruler": [[79, 1, 1, "", "EntityRulerApproach"], [79, 1, 1, "", "EntityRulerModel"]], "sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[79, 2, 1, "", "setAlphabetResource"], [79, 2, 1, "", "setEnablePatternRegex"], [79, 2, 1, "", "setPatternsResource"], [79, 2, 1, "", "setSentenceMatch"], [79, 2, 1, "", "setUseStorage"]], "sparknlp.annotator.graph_extraction": [[81, 1, 1, "", "GraphExtraction"]], "sparknlp.annotator.graph_extraction.GraphExtraction": [[81, 2, 1, "", "setDelimiter"], [81, 2, 1, "", "setDependencyParserModel"], [81, 2, 1, "", "setEntityTypes"], [81, 2, 1, "", "setExplodeEntities"], [81, 2, 1, "", "setIncludeEdges"], [81, 2, 1, "", "setMaxSentenceSize"], [81, 2, 1, "", "setMergeEntities"], [81, 2, 1, "", "setMergeEntitiesIOBFormat"], [81, 2, 1, "", "setMinSentenceSize"], [81, 2, 1, "", "setPosModel"], [81, 2, 1, "", "setRelationshipTypes"], [81, 2, 1, "", "setRootTokens"], [81, 2, 1, "", "setTypedDependencyParserModel"]], "sparknlp.annotator.keyword_extraction": [[84, 0, 0, "-", "yake_keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[84, 1, 1, "", "YakeKeywordExtraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[84, 2, 1, "", "getStopWords"], [84, 2, 1, "", "loadDefaultStopWords"], [84, 2, 1, "", "setMaxNGrams"], [84, 2, 1, "", "setMinNGrams"], [84, 2, 1, "", "setNKeywords"], [84, 2, 1, "", "setStopWords"], [84, 2, 1, "", "setThreshold"], [84, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.ld_dl": [[86, 0, 0, "-", "language_detector_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[86, 1, 1, "", "LanguageDetectorDL"]], "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[86, 2, 1, "", "pretrained"], [86, 2, 1, "", "setCoalesceSentences"], [86, 2, 1, "", "setConfigProtoBytes"], [86, 2, 1, "", "setThreshold"], [86, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.lemmatizer": [[87, 1, 1, "", "Lemmatizer"], [87, 1, 1, "", "LemmatizerModel"]], "sparknlp.annotator.lemmatizer.Lemmatizer": [[87, 2, 1, "", "setDictionary"], [87, 2, 1, "", "setFormCol"], [87, 2, 1, "", "setLemmaCol"]], "sparknlp.annotator.lemmatizer.LemmatizerModel": [[87, 2, 1, "", "pretrained"]], "sparknlp.annotator.matcher": [[88, 0, 0, "-", "big_text_matcher"], [89, 0, 0, "-", "date_matcher"], [91, 0, 0, "-", "multi_date_matcher"], [92, 0, 0, "-", "regex_matcher"], [93, 0, 0, "-", "text_matcher"]], "sparknlp.annotator.matcher.big_text_matcher": [[88, 1, 1, "", "BigTextMatcher"], [88, 1, 1, "", "BigTextMatcherModel"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[88, 2, 1, "", "setCaseSensitive"], [88, 2, 1, "", "setEntities"], [88, 2, 1, "", "setMergeOverlapping"], [88, 2, 1, "", "setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[88, 2, 1, "", "loadStorage"], [88, 2, 1, "", "pretrained"], [88, 2, 1, "", "setCaseSensitive"], [88, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.date_matcher": [[89, 1, 1, "", "DateMatcher"], [89, 1, 1, "", "DateMatcherUtils"]], "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[89, 2, 1, "", "setAnchorDateDay"], [89, 2, 1, "", "setAnchorDateMonth"], [89, 2, 1, "", "setAnchorDateYear"], [89, 2, 1, "", "setDefaultDayWhenMissing"], [89, 2, 1, "", "setInputFormats"], [89, 2, 1, "", "setOutputFormat"], [89, 2, 1, "", "setReadMonthFirst"]], "sparknlp.annotator.matcher.multi_date_matcher": [[91, 1, 1, "", "MultiDateMatcher"]], "sparknlp.annotator.matcher.regex_matcher": [[92, 1, 1, "", "RegexMatcher"], [92, 1, 1, "", "RegexMatcherModel"]], "sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[92, 2, 1, "", "setDelimiter"], [92, 2, 1, "", "setExternalRules"], [92, 2, 1, "", "setRules"], [92, 2, 1, "", "setStrategy"]], "sparknlp.annotator.matcher.text_matcher": [[93, 1, 1, "", "TextMatcher"], [93, 1, 1, "", "TextMatcherModel"]], "sparknlp.annotator.matcher.text_matcher.TextMatcher": [[93, 2, 1, "", "setBuildFromTokens"], [93, 2, 1, "", "setCaseSensitive"], [93, 2, 1, "", "setEntities"], [93, 2, 1, "", "setEntityValue"], [93, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[93, 2, 1, "", "pretrained"], [93, 2, 1, "", "setBuildFromTokens"], [93, 2, 1, "", "setEntityValue"], [93, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.n_gram_generator": [[94, 1, 1, "", "NGramGenerator"]], "sparknlp.annotator.n_gram_generator.NGramGenerator": [[94, 2, 1, "", "setDelimiter"], [94, 2, 1, "", "setEnableCumulative"], [94, 2, 1, "", "setN"]], "sparknlp.annotator.ner": [[96, 0, 0, "-", "ner_approach"], [97, 0, 0, "-", "ner_converter"], [98, 0, 0, "-", "ner_crf"], [99, 0, 0, "-", "ner_dl"], [100, 0, 0, "-", "ner_overwriter"]], "sparknlp.annotator.ner.ner_approach": [[96, 1, 1, "", "NerApproach"]], "sparknlp.annotator.ner.ner_approach.NerApproach": [[96, 2, 1, "", "getLabelColumn"], [96, 2, 1, "", "setEntities"], [96, 2, 1, "", "setLabelColumn"], [96, 2, 1, "", "setMaxEpochs"], [96, 2, 1, "", "setMinEpochs"], [96, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.ner.ner_converter": [[97, 1, 1, "", "NerConverter"]], "sparknlp.annotator.ner.ner_converter.NerConverter": [[97, 2, 1, "", "setPreservePosition"], [97, 2, 1, "", "setWhiteList"]], "sparknlp.annotator.ner.ner_crf": [[98, 1, 1, "", "NerCrfApproach"], [98, 1, 1, "", "NerCrfModel"]], "sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[98, 2, 1, "", "setC0"], [98, 2, 1, "", "setExternalFeatures"], [98, 2, 1, "", "setIncludeConfidence"], [98, 2, 1, "", "setL2"], [98, 2, 1, "", "setLossEps"], [98, 2, 1, "", "setMinW"], [98, 2, 1, "", "setVerbose"]], "sparknlp.annotator.ner.ner_crf.NerCrfModel": [[98, 2, 1, "", "pretrained"], [98, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_dl": [[99, 1, 1, "", "NerDLApproach"], [99, 1, 1, "", "NerDLModel"]], "sparknlp.annotator.ner.ner_dl.NerDLApproach": [[99, 2, 1, "", "setBatchSize"], [99, 2, 1, "", "setBestModelMetric"], [99, 2, 1, "", "setConfigProtoBytes"], [99, 2, 1, "", "setDropout"], [99, 2, 1, "", "setEnableMemoryOptimizer"], [99, 2, 1, "", "setGraphFolder"], [99, 2, 1, "", "setIncludeAllConfidenceScores"], [99, 2, 1, "", "setIncludeConfidence"], [99, 2, 1, "", "setLr"], [99, 2, 1, "", "setPo"], [99, 2, 1, "", "setUseBestModel"], [99, 2, 1, "", "setUseContrib"]], "sparknlp.annotator.ner.ner_dl.NerDLModel": [[99, 2, 1, "", "pretrained"], [99, 2, 1, "", "setConfigProtoBytes"], [99, 2, 1, "", "setIncludeAllConfidenceScores"], [99, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_overwriter": [[100, 1, 1, "", "NerOverwriter"]], "sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[100, 2, 1, "", "setNerWords"], [100, 2, 1, "", "setNewNerEntity"], [100, 2, 1, "", "setReplaceEntities"]], "sparknlp.annotator.normalizer": [[101, 1, 1, "", "Normalizer"], [101, 1, 1, "", "NormalizerModel"]], "sparknlp.annotator.normalizer.Normalizer": [[101, 2, 1, "", "setCleanupPatterns"], [101, 2, 1, "", "setLowercase"], [101, 2, 1, "", "setMaxLength"], [101, 2, 1, "", "setMinLength"], [101, 2, 1, "", "setSlangDictionary"]], "sparknlp.annotator.param": [[102, 0, 0, "-", "classifier_encoder"], [103, 0, 0, "-", "evaluation_dl_params"]], "sparknlp.annotator.param.classifier_encoder": [[102, 1, 1, "", "ClassifierEncoder"]], "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[102, 2, 1, "", "setBatchSize"], [102, 2, 1, "", "setConfigProtoBytes"], [102, 2, 1, "", "setLabelColumn"], [102, 2, 1, "", "setLr"], [102, 2, 1, "", "setMaxEpochs"], [102, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.param.evaluation_dl_params": [[103, 1, 1, "", "EvaluationDLParams"]], "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[103, 2, 1, "", "setEnableOutputLogs"], [103, 2, 1, "", "setEvaluationLogExtended"], [103, 2, 1, "", "setOutputLogsPath"], [103, 2, 1, "", "setTestDataset"], [103, 2, 1, "", "setValidationSplit"], [103, 2, 1, "", "setVerbose"]], "sparknlp.annotator.pos": [[106, 0, 0, "-", "perceptron"]], "sparknlp.annotator.pos.perceptron": [[106, 1, 1, "", "PerceptronApproach"], [106, 1, 1, "", "PerceptronModel"]], "sparknlp.annotator.pos.perceptron.PerceptronApproach": [[106, 2, 1, "", "getNIterations"], [106, 2, 1, "", "setIterations"], [106, 2, 1, "", "setPosColumn"]], "sparknlp.annotator.pos.perceptron.PerceptronModel": [[106, 2, 1, "", "pretrained"]], "sparknlp.annotator.sentence": [[108, 0, 0, "-", "sentence_detector"], [109, 0, 0, "-", "sentence_detector_dl"]], "sparknlp.annotator.sentence.sentence_detector": [[108, 1, 1, "", "SentenceDetector"], [108, 1, 1, "", "SentenceDetectorParams"]], "sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[108, 2, 1, "", "setCustomBounds"], [108, 2, 1, "", "setCustomBoundsStrategy"], [108, 2, 1, "", "setDetectLists"], [108, 2, 1, "", "setExplodeSentences"], [108, 2, 1, "", "setMaxLength"], [108, 2, 1, "", "setMinLength"], [108, 2, 1, "", "setSplitLength"], [108, 2, 1, "", "setUseAbbreviations"], [108, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[109, 1, 1, "", "SentenceDetectorDLApproach"], [109, 1, 1, "", "SentenceDetectorDLModel"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[109, 2, 1, "", "setEpochsNumber"], [109, 2, 1, "", "setExplodeSentences"], [109, 2, 1, "", "setImpossiblePenultimates"], [109, 2, 1, "", "setModel"], [109, 2, 1, "", "setOutputLogsPath"], [109, 2, 1, "", "setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[109, 2, 1, "", "pretrained"], [109, 2, 1, "", "setCustomBounds"], [109, 2, 1, "", "setExplodeSentences"], [109, 2, 1, "", "setImpossiblePenultimates"], [109, 2, 1, "", "setMaxLength"], [109, 2, 1, "", "setMinLength"], [109, 2, 1, "", "setModel"], [109, 2, 1, "", "setSplitLength"], [109, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentiment": [[111, 0, 0, "-", "sentiment_detector"], [112, 0, 0, "-", "vivekn_sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[111, 1, 1, "", "SentimentDetector"], [111, 1, 1, "", "SentimentDetectorModel"]], "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[111, 2, 1, "", "setDictionary"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[112, 1, 1, "", "ViveknSentimentApproach"], [112, 1, 1, "", "ViveknSentimentModel"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[112, 2, 1, "", "setPruneCorpus"], [112, 2, 1, "", "setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[112, 2, 1, "", "pretrained"]], "sparknlp.annotator.seq2seq": [[113, 0, 0, "-", "gpt2_transformer"], [115, 0, 0, "-", "marian_transformer"], [116, 0, 0, "-", "t5_transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[113, 1, 1, "", "GPT2Transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[113, 2, 1, "", "loadSavedModel"], [113, 2, 1, "", "pretrained"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setDoSample"], [113, 2, 1, "", "setIgnoreTokenIds"], [113, 2, 1, "", "setMaxOutputLength"], [113, 2, 1, "", "setMinOutputLength"], [113, 2, 1, "", "setNoRepeatNgramSize"], [113, 2, 1, "", "setRepetitionPenalty"], [113, 2, 1, "", "setTask"], [113, 2, 1, "", "setTemperature"], [113, 2, 1, "", "setTopK"], [113, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.marian_transformer": [[115, 1, 1, "", "MarianTransformer"]], "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[115, 2, 1, "", "loadSavedModel"], [115, 2, 1, "", "pretrained"], [115, 2, 1, "", "setConfigProtoBytes"], [115, 2, 1, "", "setIgnoreTokenIds"], [115, 2, 1, "", "setLangId"], [115, 2, 1, "", "setMaxInputLength"], [115, 2, 1, "", "setMaxOutputLength"]], "sparknlp.annotator.seq2seq.t5_transformer": [[116, 1, 1, "", "T5Transformer"]], "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[116, 2, 1, "", "loadSavedModel"], [116, 2, 1, "", "pretrained"], [116, 2, 1, "", "setConfigProtoBytes"], [116, 2, 1, "", "setDoSample"], [116, 2, 1, "", "setIgnoreTokenIds"], [116, 2, 1, "", "setMaxOutputLength"], [116, 2, 1, "", "setMinOutputLength"], [116, 2, 1, "", "setNoRepeatNgramSize"], [116, 2, 1, "", "setRepetitionPenalty"], [116, 2, 1, "", "setTask"], [116, 2, 1, "", "setTemperature"], [116, 2, 1, "", "setTopK"], [116, 2, 1, "", "setTopP"]], "sparknlp.annotator.spell_check": [[117, 0, 0, "-", "context_spell_checker"], [119, 0, 0, "-", "norvig_sweeting"], [120, 0, 0, "-", "symmetric_delete"]], "sparknlp.annotator.spell_check.context_spell_checker": [[117, 1, 1, "", "ContextSpellCheckerApproach"], [117, 1, 1, "", "ContextSpellCheckerModel"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[117, 2, 1, "", "addRegexClass"], [117, 2, 1, "", "addVocabClass"], [117, 2, 1, "", "setBatchSize"], [117, 2, 1, "", "setCaseStrategy"], [117, 2, 1, "", "setClassCount"], [117, 2, 1, "", "setCompoundCount"], [117, 2, 1, "", "setConfigProtoBytes"], [117, 2, 1, "", "setEpochs"], [117, 2, 1, "", "setErrorThreshold"], [117, 2, 1, "", "setFinalRate"], [117, 2, 1, "", "setInitialRate"], [117, 2, 1, "", "setLanguageModelClasses"], [117, 2, 1, "", "setMaxCandidates"], [117, 2, 1, "", "setMaxWindowLen"], [117, 2, 1, "", "setMinCount"], [117, 2, 1, "", "setTradeoff"], [117, 2, 1, "", "setValidationFraction"], [117, 2, 1, "", "setWeightedDistPath"], [117, 2, 1, "", "setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[117, 2, 1, "", "getWordClasses"], [117, 2, 1, "", "pretrained"], [117, 2, 1, "", "setCaseStrategy"], [117, 2, 1, "", "setCompareLowcase"], [117, 2, 1, "", "setConfigProtoBytes"], [117, 2, 1, "", "setCorrectSymbols"], [117, 2, 1, "", "setErrorThreshold"], [117, 2, 1, "", "setGamma"], [117, 2, 1, "", "setMaxCandidates"], [117, 2, 1, "", "setMaxWindowLen"], [117, 2, 1, "", "setTradeoff"], [117, 2, 1, "", "setWeights"], [117, 2, 1, "", "setWordMaxDistance"], [117, 2, 1, "", "updateRegexClass"], [117, 2, 1, "", "updateVocabClass"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[119, 1, 1, "", "NorvigSweetingApproach"], [119, 1, 1, "", "NorvigSweetingModel"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[119, 2, 1, "", "setCaseSensitive"], [119, 2, 1, "", "setDictionary"], [119, 2, 1, "", "setDoubleVariants"], [119, 2, 1, "", "setFrequencyPriority"], [119, 2, 1, "", "setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[119, 2, 1, "", "pretrained"]], "sparknlp.annotator.spell_check.symmetric_delete": [[120, 1, 1, "", "SymmetricDeleteApproach"], [120, 1, 1, "", "SymmetricDeleteModel"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[120, 2, 1, "", "setDeletesThreshold"], [120, 2, 1, "", "setDictionary"], [120, 2, 1, "", "setFrequencyThreshold"], [120, 2, 1, "", "setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[120, 2, 1, "", "pretrained"]], "sparknlp.annotator.stemmer": [[121, 1, 1, "", "Stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[122, 1, 1, "", "StopWordsCleaner"]], "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[122, 2, 1, "", "loadDefaultStopWords"], [122, 2, 1, "", "pretrained"], [122, 2, 1, "", "setCaseSensitive"], [122, 2, 1, "", "setLocale"], [122, 2, 1, "", "setStopWords"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[123, 1, 1, "", "TFNerDLGraphBuilder"], [123, 1, 1, "", "TFNerDLGraphBuilderModel"]], "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[123, 2, 1, "", "getGraphFile"], [123, 2, 1, "", "getGraphFolder"], [123, 2, 1, "", "getHiddenUnitsNumber"], [123, 2, 1, "", "getInputCols"], [123, 2, 1, "", "getLabelColumn"], [123, 2, 1, "", "setGraphFile"], [123, 2, 1, "", "setGraphFolder"], [123, 2, 1, "", "setHiddenUnitsNumber"], [123, 2, 1, "", "setInputCols"], [123, 2, 1, "", "setLabelColumn"]], "sparknlp.annotator.token": [[124, 0, 0, "-", "chunk_tokenizer"], [126, 0, 0, "-", "recursive_tokenizer"], [127, 0, 0, "-", "regex_tokenizer"], [128, 0, 0, "-", "token2_chunk"], [129, 0, 0, "-", "tokenizer"]], "sparknlp.annotator.token.chunk_tokenizer": [[124, 1, 1, "", "ChunkTokenizer"], [124, 1, 1, "", "ChunkTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer": [[126, 1, 1, "", "RecursiveTokenizer"], [126, 1, 1, "", "RecursiveTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[126, 2, 1, "", "setInfixes"], [126, 2, 1, "", "setPrefixes"], [126, 2, 1, "", "setSuffixes"], [126, 2, 1, "", "setWhitelist"]], "sparknlp.annotator.token.regex_tokenizer": [[127, 1, 1, "", "RegexTokenizer"]], "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[127, 2, 1, "", "setMaxLength"], [127, 2, 1, "", "setMinLength"], [127, 2, 1, "", "setPattern"], [127, 2, 1, "", "setPositionalMask"], [127, 2, 1, "", "setPreservePosition"], [127, 2, 1, "", "setToLowercase"], [127, 2, 1, "", "setTrimWhitespace"]], "sparknlp.annotator.token.token2_chunk": [[128, 1, 1, "", "Token2Chunk"]], "sparknlp.annotator.token.tokenizer": [[129, 1, 1, "", "Tokenizer"], [129, 1, 1, "", "TokenizerModel"]], "sparknlp.annotator.token.tokenizer.Tokenizer": [[129, 2, 1, "", "addContextChars"], [129, 2, 1, "", "addException"], [129, 2, 1, "", "addInfixPattern"], [129, 2, 1, "", "addSplitChars"], [129, 2, 1, "", "getCaseSensitiveExceptions"], [129, 2, 1, "", "getContextChars"], [129, 2, 1, "", "getExceptions"], [129, 2, 1, "", "getInfixPatterns"], [129, 2, 1, "", "getPrefixPattern"], [129, 2, 1, "", "getSplitChars"], [129, 2, 1, "", "getSuffixPattern"], [129, 2, 1, "", "setCaseSensitiveExceptions"], [129, 2, 1, "", "setContextChars"], [129, 2, 1, "", "setExceptions"], [129, 2, 1, "", "setExceptionsPath"], [129, 2, 1, "", "setInfixPatterns"], [129, 2, 1, "", "setMaxLength"], [129, 2, 1, "", "setMinLength"], [129, 2, 1, "", "setPrefixPattern"], [129, 2, 1, "", "setSplitChars"], [129, 2, 1, "", "setSplitPattern"], [129, 2, 1, "", "setSuffixPattern"], [129, 2, 1, "", "setTargetPattern"]], "sparknlp.annotator.token.tokenizer.TokenizerModel": [[129, 2, 1, "", "addSplitChars"], [129, 2, 1, "", "pretrained"], [129, 2, 1, "", "setSplitChars"], [129, 2, 1, "", "setSplitPattern"]], "sparknlp.annotator.ws": [[131, 0, 0, "-", "word_segmenter"]], "sparknlp.annotator.ws.word_segmenter": [[131, 1, 1, "", "WordSegmenterApproach"], [131, 1, 1, "", "WordSegmenterModel"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[131, 2, 1, "", "getAmbiguityThreshold"], [131, 2, 1, "", "getFrequencyThreshold"], [131, 2, 1, "", "getNIterations"], [131, 2, 1, "", "setAmbiguityThreshold"], [131, 2, 1, "", "setEnableRegexTokenizer"], [131, 2, 1, "", "setFrequencyThreshold"], [131, 2, 1, "", "setNIterations"], [131, 2, 1, "", "setPattern"], [131, 2, 1, "", "setPosColumn"], [131, 2, 1, "", "setToLowercase"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[131, 2, 1, "", "pretrained"], [131, 2, 1, "", "setEnableRegexTokenizer"], [131, 2, 1, "", "setPattern"], [131, 2, 1, "", "setToLowercase"]], "sparknlp.base": [[132, 0, 0, "-", "audio_assembler"], [133, 0, 0, "-", "chunk2_doc"], [134, 0, 0, "-", "doc2_chunk"], [135, 0, 0, "-", "document_assembler"], [136, 0, 0, "-", "embeddings_finisher"], [137, 0, 0, "-", "finisher"], [138, 0, 0, "-", "graph_finisher"], [139, 0, 0, "-", "has_recursive_fit"], [140, 0, 0, "-", "has_recursive_transform"], [141, 0, 0, "-", "image_assembler"], [143, 0, 0, "-", "light_pipeline"], [144, 0, 0, "-", "multi_document_assembler"], [145, 0, 0, "-", "recursive_pipeline"], [146, 0, 0, "-", "table_assembler"], [147, 0, 0, "-", "token_assembler"]], "sparknlp.base.audio_assembler": [[132, 1, 1, "", "AudioAssembler"]], "sparknlp.base.audio_assembler.AudioAssembler": [[132, 2, 1, "", "getOutputCol"], [132, 2, 1, "", "setInputCol"], [132, 2, 1, "", "setOutputCol"]], "sparknlp.base.chunk2_doc": [[133, 1, 1, "", "Chunk2Doc"]], "sparknlp.base.doc2_chunk": [[134, 1, 1, "", "Doc2Chunk"]], "sparknlp.base.doc2_chunk.Doc2Chunk": [[134, 2, 1, "", "setChunkCol"], [134, 2, 1, "", "setFailOnMissing"], [134, 2, 1, "", "setIsArray"], [134, 2, 1, "", "setLowerCase"], [134, 2, 1, "", "setStartCol"], [134, 2, 1, "", "setStartColByTokenIndex"]], "sparknlp.base.document_assembler": [[135, 1, 1, "", "DocumentAssembler"]], "sparknlp.base.document_assembler.DocumentAssembler": [[135, 2, 1, "", "getOutputCol"], [135, 2, 1, "", "setCleanupMode"], [135, 2, 1, "", "setIdCol"], [135, 2, 1, "", "setInputCol"], [135, 2, 1, "", "setMetadataCol"], [135, 2, 1, "", "setOutputCol"]], "sparknlp.base.embeddings_finisher": [[136, 1, 1, "", "EmbeddingsFinisher"]], "sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[136, 2, 1, "", "getInputCols"], [136, 2, 1, "", "getOutputCols"], [136, 2, 1, "", "setCleanAnnotations"], [136, 2, 1, "", "setInputCols"], [136, 2, 1, "", "setOutputAsVector"], [136, 2, 1, "", "setOutputCols"]], "sparknlp.base.finisher": [[137, 1, 1, "", "Finisher"]], "sparknlp.base.finisher.Finisher": [[137, 2, 1, "", "getInputCols"], [137, 2, 1, "", "getOutputCols"], [137, 2, 1, "", "setAnnotationSplitSymbol"], [137, 2, 1, "", "setCleanAnnotations"], [137, 2, 1, "", "setIncludeMetadata"], [137, 2, 1, "", "setInputCols"], [137, 2, 1, "", "setOutputAsArray"], [137, 2, 1, "", "setOutputCols"], [137, 2, 1, "", "setParseEmbeddingsVectors"], [137, 2, 1, "", "setValueSplitSymbol"]], "sparknlp.base.graph_finisher": [[138, 1, 1, "", "GraphFinisher"]], "sparknlp.base.graph_finisher.GraphFinisher": [[138, 2, 1, "", "setCleanAnnotations"], [138, 2, 1, "", "setInputCol"], [138, 2, 1, "", "setOutputAsArray"], [138, 2, 1, "", "setOutputCol"]], "sparknlp.base.has_recursive_fit": [[139, 1, 1, "", "HasRecursiveFit"]], "sparknlp.base.has_recursive_transform": [[140, 1, 1, "", "HasRecursiveTransform"]], "sparknlp.base.image_assembler": [[141, 1, 1, "", "ImageAssembler"]], "sparknlp.base.image_assembler.ImageAssembler": [[141, 2, 1, "", "getOutputCol"], [141, 2, 1, "", "setInputCol"], [141, 2, 1, "", "setOutputCol"]], "sparknlp.base.light_pipeline": [[143, 1, 1, "", "LightPipeline"]], "sparknlp.base.light_pipeline.LightPipeline": [[143, 2, 1, "", "annotate"], [143, 2, 1, "", "fullAnnotate"], [143, 2, 1, "", "fullAnnotateImage"], [143, 2, 1, "", "getIgnoreUnsupported"], [143, 2, 1, "", "setIgnoreUnsupported"], [143, 2, 1, "", "transform"]], "sparknlp.base.multi_document_assembler": [[144, 1, 1, "", "MultiDocumentAssembler"]], "sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[144, 2, 1, "", "getOutputCols"], [144, 2, 1, "", "setCleanupMode"], [144, 2, 1, "", "setIdCol"], [144, 2, 1, "", "setInputCols"], [144, 2, 1, "", "setMetadataCol"], [144, 2, 1, "", "setOutputCols"]], "sparknlp.base.recursive_pipeline": [[145, 1, 1, "", "RecursivePipeline"], [145, 1, 1, "", "RecursivePipelineModel"]], "sparknlp.base.table_assembler": [[146, 1, 1, "", "TableAssembler"]], "sparknlp.base.table_assembler.TableAssembler": [[146, 2, 1, "", "setCsvDelimiter"], [146, 2, 1, "", "setEscapeCsvDelimiter"], [146, 2, 1, "", "setInputFormat"]], "sparknlp.base.token_assembler": [[147, 1, 1, "", "TokenAssembler"]], "sparknlp.base.token_assembler.TokenAssembler": [[147, 2, 1, "", "setPreservePosition"]], "sparknlp.common": [[148, 0, 0, "-", "annotator_approach"], [149, 0, 0, "-", "annotator_model"], [150, 0, 0, "-", "annotator_properties"], [151, 0, 0, "-", "annotator_type"], [152, 0, 0, "-", "coverage_result"], [154, 0, 0, "-", "properties"], [155, 0, 0, "-", "read_as"], [156, 0, 0, "-", "recursive_annotator_approach"], [157, 0, 0, "-", "storage"], [158, 0, 0, "-", "utils"]], "sparknlp.common.annotator_approach": [[148, 1, 1, "", "AnnotatorApproach"]], "sparknlp.common.annotator_model": [[149, 1, 1, "", "AnnotatorModel"]], "sparknlp.common.annotator_properties": [[150, 1, 1, "", "AnnotatorProperties"]], "sparknlp.common.annotator_properties.AnnotatorProperties": [[150, 2, 1, "", "getInputCols"], [150, 2, 1, "", "getLazyAnnotator"], [150, 2, 1, "", "getOutputCol"], [150, 2, 1, "", "setInputCols"], [150, 2, 1, "", "setLazyAnnotator"], [150, 2, 1, "", "setOutputCol"]], "sparknlp.common.properties": [[154, 1, 1, "", "HasEmbeddingsProperties"]], "sparknlp.common.properties.HasEmbeddingsProperties": [[154, 2, 1, "", "getDimension"], [154, 2, 1, "", "setDimension"]], "sparknlp.common.read_as": [[155, 1, 1, "", "ReadAs"]], "sparknlp.common.recursive_annotator_approach": [[156, 1, 1, "", "RecursiveAnnotatorApproach"]], "sparknlp.common.utils": [[158, 3, 1, "", "ExternalResource"]], "sparknlp.functions": [[159, 3, 1, "", "explode_annotations_col"], [159, 3, 1, "", "filter_by_annotations_col"], [159, 3, 1, "", "map_annotations"], [159, 3, 1, "", "map_annotations_array"], [159, 3, 1, "", "map_annotations_col"], [159, 3, 1, "", "map_annotations_cols"], [159, 3, 1, "", "map_annotations_strict"]], "sparknlp.internal": [[161, 0, 0, "-", "annotator_java_ml"], [162, 0, 0, "-", "annotator_transformer"], [163, 0, 0, "-", "extended_java_wrapper"], [165, 0, 0, "-", "params_getters_setters"], [166, 0, 0, "-", "recursive"]], "sparknlp.internal.annotator_java_ml": [[161, 1, 1, "", "AnnotatorJavaMLReadable"], [161, 1, 1, "", "AnnotatorJavaMLReader"]], "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[161, 2, 1, "", "read"]], "sparknlp.internal.annotator_transformer": [[162, 1, 1, "", "AnnotatorTransformer"]], "sparknlp.internal.extended_java_wrapper": [[163, 1, 1, "", "ExtendedJavaWrapper"]], "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[163, 2, 1, "", "new_java_array"]], "sparknlp.internal.params_getters_setters": [[165, 1, 1, "", "ParamsGettersSetters"]], "sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[165, 2, 1, "", "getParamValue"], [165, 2, 1, "", "setParamValue"]], "sparknlp.internal.recursive": [[166, 1, 1, "", "RecursiveEstimator"], [166, 1, 1, "", "RecursiveTransformer"]], "sparknlp.internal.recursive.RecursiveEstimator": [[166, 2, 1, "", "fit"]], "sparknlp.logging": [[167, 0, 0, "-", "comet"]], "sparknlp.logging.comet": [[167, 1, 1, "", "CometLogger"]], "sparknlp.logging.comet.CometLogger": [[167, 2, 1, "", "end"], [167, 2, 1, "", "log_asset"], [167, 2, 1, "", "log_asset_data"], [167, 2, 1, "", "log_completed_run"], [167, 2, 1, "", "log_metrics"], [167, 2, 1, "", "log_parameters"], [167, 2, 1, "", "log_pipeline_parameters"], [167, 2, 1, "", "log_visualization"], [167, 2, 1, "", "monitor"]], "sparknlp.pretrained": [[170, 0, 0, "-", "pretrained_pipeline"], [171, 0, 0, "-", "resource_downloader"], [172, 0, 0, "-", "utils"]], "sparknlp.pretrained.pretrained_pipeline": [[170, 1, 1, "", "PretrainedPipeline"]], "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[170, 2, 1, "", "annotate"], [170, 2, 1, "", "fullAnnotate"], [170, 2, 1, "", "fullAnnotateImage"], [170, 2, 1, "", "transform"]], "sparknlp.training": [[174, 0, 0, "-", "_tf_graph_builders"], [189, 0, 0, "-", "_tf_graph_builders_1x"], [196, 0, 0, "-", "conll"], [197, 0, 0, "-", "conllu"], [199, 0, 0, "-", "pos"], [200, 0, 0, "-", "pub_tator"], [201, 0, 0, "-", "tfgraphs"]], "sparknlp.training._tf_graph_builders": [[173, 0, 0, "-", "graph_builders"], [177, 0, 0, "-", "ner_dl"], [184, 0, 0, "-", "tf2contrib"]], "sparknlp.training._tf_graph_builders.graph_builders": [[173, 1, 1, "", "NerTFGraphBuilder"], [173, 1, 1, "", "TFGraphBuilder"], [173, 1, 1, "", "TFGraphBuilderFactory"], [173, 4, 1, "", "TensorflowAddonsNeeded"], [173, 4, 1, "", "WrongTFVersion"]], "sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory": [[173, 2, 1, "", "build"], [173, 2, 1, "", "get_models"], [173, 2, 1, "", "print_model_params"]], "sparknlp.training._tf_graph_builders.ner_dl": [[175, 0, 0, "-", "create_graph"], [176, 0, 0, "-", "dataset_encoder"], [178, 0, 0, "-", "ner_model"], [179, 0, 0, "-", "ner_model_saver"], [180, 0, 0, "-", "sentence_grouper"]], "sparknlp.training._tf_graph_builders.tf2contrib": [[181, 0, 0, "-", "core_rnn_cell"], [182, 0, 0, "-", "fused_rnn_cell"], [183, 0, 0, "-", "gru_ops"], [185, 0, 0, "-", "lstm_ops"], [186, 0, 0, "-", "rnn"], [187, 0, 0, "-", "rnn_cell"]], "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[181, 1, 1, "", "EmbeddingWrapper"], [181, 1, 1, "", "InputProjectionWrapper"], [181, 1, 1, "", "OutputProjectionWrapper"]], "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper": [[181, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper": [[181, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper": [[181, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[182, 1, 1, "", "FusedRNNCell"], [182, 1, 1, "", "FusedRNNCellAdaptor"], [182, 1, 1, "", "TimeReversedFusedRNN"]], "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[183, 1, 1, "", "GRUBlockCell"], [183, 1, 1, "", "GRUBlockCellV2"]], "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell": [[183, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2": [[183, 2, 1, "", "build"]], "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[185, 1, 1, "", "LSTMBlockCell"], [185, 1, 1, "", "LSTMBlockFusedCell"], [185, 1, 1, "", "LSTMBlockWrapper"]], "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell": [[185, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper": [[185, 2, 1, "", "call"], [185, 2, 1, "", "num_units"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[186, 3, 1, "", "stack_bidirectional_dynamic_rnn"], [186, 3, 1, "", "stack_bidirectional_rnn"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[187, 1, 1, "", "AttentionCellWrapper"], [187, 1, 1, "", "BidirectionalGridLSTMCell"], [187, 1, 1, "", "CFNCell"], [187, 1, 1, "", "CompiledWrapper"], [187, 1, 1, "", "Conv1DLSTMCell"], [187, 1, 1, "", "Conv2DLSTMCell"], [187, 1, 1, "", "Conv3DLSTMCell"], [187, 1, 1, "", "ConvLSTMCell"], [187, 1, 1, "", "CoupledInputForgetGateLSTMCell"], [187, 1, 1, "", "GLSTMCell"], [187, 1, 1, "", "GridLSTMCell"], [187, 1, 1, "", "HighwayWrapper"], [187, 1, 1, "", "IndRNNCell"], [187, 1, 1, "", "IndyGRUCell"], [187, 1, 1, "", "IndyLSTMCell"], [187, 1, 1, "", "IntersectionRNNCell"], [187, 1, 1, "", "LayerNormBasicLSTMCell"], [187, 1, 1, "", "LayerNormLSTMCell"], [187, 1, 1, "", "MinimalRNNCell"], [187, 1, 1, "", "NASCell"], [187, 1, 1, "", "NTMCell"], [187, 1, 1, "", "PhasedLSTMCell"], [187, 1, 1, "", "SRUCell"], [187, 1, 1, "", "TimeFreqLSTMCell"], [187, 1, 1, "", "UGRNNCell"], [187, 1, 1, "", "WeightNormLSTMCell"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell": [[187, 2, 1, "", "call"]], "sparknlp.training._tf_graph_builders_1x": [[188, 0, 0, "-", "graph_builders"], [192, 0, 0, "-", "ner_dl"]], "sparknlp.training._tf_graph_builders_1x.graph_builders": [[188, 1, 1, "", "NerTFGraphBuilder"], [188, 1, 1, "", "TFGraphBuilder"], [188, 1, 1, "", "TFGraphBuilderFactory"], [188, 4, 1, "", "WrongTFVersion"]], "sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory": [[188, 2, 1, "", "build"], [188, 2, 1, "", "get_models"], [188, 2, 1, "", "print_model_params"]], "sparknlp.training._tf_graph_builders_1x.ner_dl": [[190, 0, 0, "-", "create_graph"], [191, 0, 0, "-", "dataset_encoder"], [193, 0, 0, "-", "ner_model"], [194, 0, 0, "-", "ner_model_saver"], [195, 0, 0, "-", "sentence_grouper"]], "sparknlp.training.conll": [[196, 1, 1, "", "CoNLL"]], "sparknlp.training.conll.CoNLL": [[196, 2, 1, "", "readDataset"]], "sparknlp.training.conllu": [[197, 1, 1, "", "CoNLLU"]], "sparknlp.training.conllu.CoNLLU": [[197, 2, 1, "", "readDataset"]], "sparknlp.training.pos": [[199, 1, 1, "", "POS"]], "sparknlp.training.pos.POS": [[199, 2, 1, "", "readDataset"]], "sparknlp.training.pub_tator": [[200, 1, 1, "", "PubTator"]], "sparknlp.training.pub_tator.PubTator": [[200, 2, 1, "", "readDataset"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "exception", "Python exception"]}, "titleterms": {"api": [1, 204], "refer": [1, 204], "get": [10, 210], "start": 10, "spark": [10, 11, 205, 210, 214], "nlp": [10, 11, 205, 214], "cheat": 10, "sheet": 10, "requir": 10, "instal": [10, 205], "us": [10, 205, 214], "conda": 10, "virtualenv": 10, "session": 10, "from": 10, "python": 10, "document": 11, "content": [11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 154, 155, 156, 158, 159, 160, 161, 162, 163, 165, 166, 167, 170, 173, 181, 182, 183, 185, 186, 187, 188, 196, 197, 199, 200], "sparknlp": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203], "annot": [12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 208, 209, 210], "modul": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 154, 155, 156, 158, 159, 161, 162, 163, 165, 166, 167, 170, 173, 181, 182, 183, 185, 186, 187, 188, 196, 197, 199, 200, 204], "class": [12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 154, 155, 156, 161, 162, 163, 165, 166, 167, 170, 173, 181, 182, 183, 185, 187, 188, 196, 197, 199, 200], "annotation_audio": 13, "annotation_imag": 14, "audio": [15, 16, 17], "hubert_for_ctc": 15, "submodul": [16, 35, 50, 52, 56, 68, 80, 82, 83, 85, 90, 95, 105, 107, 110, 114, 118, 125, 130, 142, 153, 160, 164, 168, 169, 184, 198], "wav2vec2_for_ctc": 17, "chunker": 18, "classifier_dl": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], "albert_for_question_answ": 19, "albert_for_sequence_classif": 20, "albert_for_token_classif": 21, "bert_for_question_answ": 22, "bert_for_sequence_classif": 23, "bert_for_token_classif": 24, "camembert_for_question_answ": 25, "camembert_for_sequence_classif": 26, "camembert_for_token_classif": 27, "deberta_for_question_answ": 29, "deberta_for_sequence_classif": 30, "deberta_for_token_classif": 31, "distil_bert_for_question_answ": 32, "distil_bert_for_sequence_classif": 33, "distil_bert_for_token_classif": 34, "longformer_for_question_answ": 36, "longformer_for_sequence_classif": 37, "longformer_for_token_classif": 38, "multi_classifier_dl": 39, "roberta_for_question_answ": 40, "roberta_for_sequence_classif": 41, "roberta_for_token_classif": 42, "sentiment_dl": 43, "tapas_for_question_answ": 44, "xlm_roberta_for_question_answ": 45, "xlm_roberta_for_sequence_classif": 46, "xlm_roberta_for_token_classif": 47, "xlnet_for_sequence_classif": 48, "xlnet_for_token_classif": 49, "coref": [50, 51], "spanbert_coref": 51, "cv": [52, 53, 54], "swin_for_image_classif": 53, "vit_for_image_classif": 54, "depend": [55, 56, 57], "dependency_pars": 55, "typed_dependency_pars": 57, "document_norm": 58, "embed": [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "albert_embed": 59, "bert_embed": 60, "bert_sentence_embed": 61, "camembert_embed": 62, "chunk_embed": 63, "deberta_embed": 64, "distil_bert_embed": 65, "doc2vec": 66, "elmo_embed": 67, "longformer_embed": 69, "roberta_embed": 70, "roberta_sentence_embed": 71, "sentence_embed": 72, "universal_sentence_encod": 73, "word2vec": 74, "word_embed": 75, "xlm_roberta_embed": 76, "xlm_roberta_sentence_embed": 77, "xlnet_embed": 78, "er": [79, 80], "entity_rul": 79, "graph_extract": 81, "subpackag": [82, 160, 174], "keyword_extract": [83, 84], "yake_keyword_extract": 84, "ld_dl": [85, 86], "language_detector_dl": 86, "lemmat": 87, "matcher": [88, 89, 90, 91, 92, 93], "big_text_match": 88, "date_match": 89, "multi_date_match": 91, "regex_match": 92, "text_match": 93, "n_gram_gener": 94, "ner": [95, 96, 97, 98, 99, 100], "ner_approach": 96, "ner_convert": 97, "ner_crf": 98, "ner_dl": [99, 175, 176, 177, 178, 179, 180, 190, 191, 192, 193, 194, 195], "ner_overwrit": 100, "normal": 101, "param": [102, 103, 104], "classifier_encod": 102, "evaluation_dl_param": 103, "po": [105, 106, 199, 215], "perceptron": 106, "sentenc": [107, 108, 109, 210], "sentence_detector": 108, "sentence_detector_dl": 109, "sentiment": [110, 111, 112], "sentiment_detector": 111, "vivekn_senti": 112, "seq2seq": [113, 114, 115, 116], "gpt2_transform": 113, "marian_transform": 115, "t5_transform": 116, "spell_check": [117, 118, 119, 120], "context_spell_check": 117, "norvig_sweet": 119, "symmetric_delet": 120, "stemmer": 121, "stop_words_clean": 122, "tf_ner_dl_graph_build": 123, "token": [124, 125, 126, 127, 128, 129, 210], "chunk_token": 124, "recursive_token": 126, "regex_token": 127, "token2_chunk": 128, "w": [130, 131], "word_segment": 131, "base": [132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147], "audio_assembl": 132, "chunk2_doc": 133, "doc2_chunk": 134, "document_assembl": 135, "embeddings_finish": 136, "finish": [137, 210], "graph_finish": 138, "has_recursive_fit": 139, "has_recursive_transform": 140, "image_assembl": 141, "light_pipelin": 143, "multi_document_assembl": 144, "recursive_pipelin": 145, "table_assembl": 146, "token_assembl": 147, "common": [148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 209], "annotator_approach": 148, "annotator_model": 149, "annotator_properti": 150, "annotator_typ": 151, "coverage_result": 152, "properti": 154, "read_a": 155, "recursive_annotator_approach": 156, "storag": 157, "util": [158, 172, 203], "function": [158, 159, 160, 186, 209, 211], "packag": 160, "intern": [161, 162, 163, 164, 165, 166], "annotator_java_ml": 161, "annotator_transform": 162, "extended_java_wrapp": 163, "params_getters_sett": 165, "recurs": 166, "log": [167, 168, 205, 207], "comet": [167, 205], "pretrain": [169, 170, 171, 172, 209, 213, 214], "pretrained_pipelin": 170, "resource_download": 171, "train": [173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 215], "_tf_graph_build": [173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187], "graph_build": [173, 188], "create_graph": [175, 190], "dataset_encod": [176, 191], "ner_model": [178, 193], "ner_model_sav": [179, 194], "sentence_group": [180, 195], "tf2contrib": [181, 182, 183, 184, 185, 186, 187], "core_rnn_cel": 181, "fused_rnn_cel": 182, "gru_op": 183, "lstm_op": 185, "rnn": 186, "rnn_cell": 187, "_tf_graph_builders_1x": [188, 189, 190, 191, 192, 193, 194, 195], "conll": [196, 215], "conllu": [197, 215], "pub_tat": 200, "tfgraph": 201, "upload_to_hub": 202, "A": 205, "meta": 205, "machin": [205, 206], "learn": [205, 206], "platform": [205, 206], "pipelin": [205, 210, 213, 214], "paramet": 205, "evalu": 205, "metric": 205, "visual": 205, "run": 205, "an": 205, "offlin": 205, "experi": 205, "mlflow": 206, "lifecycl": 206, "third": 207, "parti": 207, "project": 207, "approach": 209, "model": 209, "note": 209, "avail": [209, 214], "set": 210, "up": 210, "your": 210, "own": 210, "type": 210, "necessari": 210, "import": 210, "construct": 210, "documentassembl": 210, "data": 210, "detect": 210, "out": 210, "put": 210, "all": 210, "togeth": 210, "ml": [210, 214], "helper": 211, "user": 212, "guid": 212, "light": 213, "convert": 213, "pipelinemodel": 213, "download": 214, "As": 214, "lightpipelin": 214, "load": 215, "dataset": 215, "spell": 215, "checker": 215, "pubtat": 215}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"API Reference": [[1, "api-reference"], [204, "api-reference"]], "Getting Started": [[10, "getting-started"]], "Spark NLP Cheat Sheet": [[10, "spark-nlp-cheat-sheet"]], "Requirements": [[10, "requirements"]], "Installation": [[10, "installation"], [205, "installation"]], "Using Conda": [[10, "using-conda"]], "Using Virtualenv": [[10, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[10, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[11, "spark-nlp-documentation"]], "Content": [[11, "content"]], "sparknlp.annotation": [[12, "module-sparknlp.annotation"]], "Module Contents": [[12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [51, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [76, "module-contents"], [77, "module-contents"], [78, "module-contents"], [79, "module-contents"], [81, "module-contents"], [84, "module-contents"], [86, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [100, "module-contents"], [101, "module-contents"], [102, "module-contents"], [103, "module-contents"], [106, "module-contents"], [108, "module-contents"], [109, "module-contents"], [111, "module-contents"], [112, "module-contents"], [113, "module-contents"], [115, "module-contents"], [116, "module-contents"], [117, "module-contents"], [119, "module-contents"], [120, "module-contents"], [121, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [143, "module-contents"], [144, "module-contents"], [145, "module-contents"], [146, "module-contents"], [147, "module-contents"], [148, "module-contents"], [149, "module-contents"], [150, "module-contents"], [154, "module-contents"], [155, "module-contents"], [156, "module-contents"], [158, "module-contents"], [159, "module-contents"], [161, "module-contents"], [162, "module-contents"], [163, "module-contents"], [165, "module-contents"], [166, "module-contents"], [167, "module-contents"], [170, "module-contents"], [173, "module-contents"], [181, "module-contents"], [182, "module-contents"], [183, "module-contents"], [185, "module-contents"], [186, "module-contents"], [187, "module-contents"], [188, "module-contents"], [196, "module-contents"], [197, "module-contents"], [199, "module-contents"], [200, "module-contents"]], "Classes": [[12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [44, "classes"], [45, "classes"], [46, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [51, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [75, "classes"], [76, "classes"], [77, "classes"], [78, "classes"], [79, "classes"], [81, "classes"], [84, "classes"], [86, "classes"], [87, "classes"], [88, "classes"], [89, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [99, "classes"], [100, "classes"], [101, "classes"], [102, "classes"], [103, "classes"], [106, "classes"], [108, "classes"], [109, "classes"], [111, "classes"], [112, "classes"], [113, "classes"], [115, "classes"], [116, "classes"], [117, "classes"], [119, "classes"], [120, "classes"], [121, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [143, "classes"], [144, "classes"], [145, "classes"], [146, "classes"], [147, "classes"], [148, "classes"], [149, "classes"], [150, "classes"], [154, "classes"], [155, "classes"], [156, "classes"], [161, "classes"], [162, "classes"], [163, "classes"], [165, "classes"], [166, "classes"], [167, "classes"], [170, "classes"], [173, "classes"], [181, "classes"], [182, "classes"], [183, "classes"], [185, "classes"], [187, "classes"], [188, "classes"], [196, "classes"], [197, "classes"], [199, "classes"], [200, "classes"]], "sparknlp.annotation_audio": [[13, "module-sparknlp.annotation_audio"]], "sparknlp.annotation_image": [[14, "module-sparknlp.annotation_image"]], "sparknlp.annotator.audio.hubert_for_ctc": [[15, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[16, "module-sparknlp.annotator.audio"]], "Submodules": [[16, "submodules"], [35, "submodules"], [50, "submodules"], [52, "submodules"], [56, "submodules"], [68, "submodules"], [80, "submodules"], [82, "submodules"], [83, "submodules"], [85, "submodules"], [90, "submodules"], [95, "submodules"], [105, "submodules"], [107, "submodules"], [110, "submodules"], [114, "submodules"], [118, "submodules"], [125, "submodules"], [130, "submodules"], [142, "submodules"], [153, "submodules"], [160, "submodules"], [164, "submodules"], [168, "submodules"], [169, "submodules"], [184, "submodules"], [198, "submodules"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[17, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "sparknlp.annotator.chunker": [[18, "module-sparknlp.annotator.chunker"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[19, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[20, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[21, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[22, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[23, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[24, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[25, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[26, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[27, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[28, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[29, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[30, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[31, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[32, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[33, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[34, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[35, "module-sparknlp.annotator.classifier_dl"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[36, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[37, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[38, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[39, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[40, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[41, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[42, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[43, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[44, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[45, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[46, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[47, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[48, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[49, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[50, "module-sparknlp.annotator.coref"]], "sparknlp.annotator.coref.spanbert_coref": [[51, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv": [[52, "module-sparknlp.annotator.cv"]], "sparknlp.annotator.cv.swin_for_image_classification": [[53, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "sparknlp.annotator.cv.vit_for_image_classification": [[54, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "sparknlp.annotator.dependency.dependency_parser": [[55, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[56, "module-sparknlp.annotator.dependency"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[57, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "sparknlp.annotator.document_normalizer": [[58, "module-sparknlp.annotator.document_normalizer"]], "sparknlp.annotator.embeddings.albert_embeddings": [[59, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "sparknlp.annotator.embeddings.bert_embeddings": [[60, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[61, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[62, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[63, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[64, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[65, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "sparknlp.annotator.embeddings.doc2vec": [[66, "module-sparknlp.annotator.embeddings.doc2vec"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[67, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[68, "module-sparknlp.annotator.embeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[69, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[70, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[71, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[72, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[73, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "sparknlp.annotator.embeddings.word2vec": [[74, "module-sparknlp.annotator.embeddings.word2vec"]], "sparknlp.annotator.embeddings.word_embeddings": [[75, "module-sparknlp.annotator.embeddings.word_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[76, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[77, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[78, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "sparknlp.annotator.er.entity_ruler": [[79, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[80, "module-sparknlp.annotator.er"]], "sparknlp.annotator.graph_extraction": [[81, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[82, "module-sparknlp.annotator"]], "Subpackages": [[82, "subpackages"], [160, "subpackages"], [174, "subpackages"]], "sparknlp.annotator.keyword_extraction": [[83, "module-sparknlp.annotator.keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[84, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[85, "module-sparknlp.annotator.ld_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[86, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "sparknlp.annotator.lemmatizer": [[87, "module-sparknlp.annotator.lemmatizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[88, "module-sparknlp.annotator.matcher.big_text_matcher"]], "sparknlp.annotator.matcher.date_matcher": [[89, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[90, "module-sparknlp.annotator.matcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[91, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "sparknlp.annotator.matcher.regex_matcher": [[92, "module-sparknlp.annotator.matcher.regex_matcher"]], "sparknlp.annotator.matcher.text_matcher": [[93, "module-sparknlp.annotator.matcher.text_matcher"]], "sparknlp.annotator.n_gram_generator": [[94, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[95, "module-sparknlp.annotator.ner"]], "sparknlp.annotator.ner.ner_approach": [[96, "module-sparknlp.annotator.ner.ner_approach"]], "sparknlp.annotator.ner.ner_converter": [[97, "module-sparknlp.annotator.ner.ner_converter"]], "sparknlp.annotator.ner.ner_crf": [[98, "module-sparknlp.annotator.ner.ner_crf"]], "sparknlp.annotator.ner.ner_dl": [[99, "module-sparknlp.annotator.ner.ner_dl"]], "sparknlp.annotator.ner.ner_overwriter": [[100, "module-sparknlp.annotator.ner.ner_overwriter"]], "sparknlp.annotator.normalizer": [[101, "module-sparknlp.annotator.normalizer"]], "sparknlp.annotator.param.classifier_encoder": [[102, "module-sparknlp.annotator.param.classifier_encoder"]], "sparknlp.annotator.param.evaluation_dl_params": [[103, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[104, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[105, "module-sparknlp.annotator.pos"]], "sparknlp.annotator.pos.perceptron": [[106, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[107, "module-sparknlp.annotator.sentence"]], "sparknlp.annotator.sentence.sentence_detector": [[108, "module-sparknlp.annotator.sentence.sentence_detector"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[109, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[110, "module-sparknlp.annotator.sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[111, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[112, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[113, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[114, "module-sparknlp.annotator.seq2seq"]], "sparknlp.annotator.seq2seq.marian_transformer": [[115, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "sparknlp.annotator.seq2seq.t5_transformer": [[116, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "sparknlp.annotator.spell_check.context_spell_checker": [[117, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "sparknlp.annotator.spell_check": [[118, "module-sparknlp.annotator.spell_check"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[119, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "sparknlp.annotator.spell_check.symmetric_delete": [[120, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "sparknlp.annotator.stemmer": [[121, "module-sparknlp.annotator.stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[122, "module-sparknlp.annotator.stop_words_cleaner"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[123, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "sparknlp.annotator.token.chunk_tokenizer": [[124, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[125, "module-sparknlp.annotator.token"]], "sparknlp.annotator.token.recursive_tokenizer": [[126, "module-sparknlp.annotator.token.recursive_tokenizer"]], "sparknlp.annotator.token.regex_tokenizer": [[127, "module-sparknlp.annotator.token.regex_tokenizer"]], "sparknlp.annotator.token.token2_chunk": [[128, "module-sparknlp.annotator.token.token2_chunk"]], "sparknlp.annotator.token.tokenizer": [[129, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[130, "module-sparknlp.annotator.ws"]], "sparknlp.annotator.ws.word_segmenter": [[131, "module-sparknlp.annotator.ws.word_segmenter"]], "sparknlp.base.audio_assembler": [[132, "module-sparknlp.base.audio_assembler"]], "sparknlp.base.chunk2_doc": [[133, "module-sparknlp.base.chunk2_doc"]], "sparknlp.base.doc2_chunk": [[134, "module-sparknlp.base.doc2_chunk"]], "sparknlp.base.document_assembler": [[135, "module-sparknlp.base.document_assembler"]], "sparknlp.base.embeddings_finisher": [[136, "module-sparknlp.base.embeddings_finisher"]], "sparknlp.base.finisher": [[137, "module-sparknlp.base.finisher"]], "sparknlp.base.graph_finisher": [[138, "module-sparknlp.base.graph_finisher"]], "sparknlp.base.has_recursive_fit": [[139, "module-sparknlp.base.has_recursive_fit"]], "sparknlp.base.has_recursive_transform": [[140, "module-sparknlp.base.has_recursive_transform"]], "sparknlp.base.image_assembler": [[141, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[142, "module-sparknlp.base"]], "sparknlp.base.light_pipeline": [[143, "module-sparknlp.base.light_pipeline"]], "sparknlp.base.multi_document_assembler": [[144, "module-sparknlp.base.multi_document_assembler"]], "sparknlp.base.recursive_pipeline": [[145, "module-sparknlp.base.recursive_pipeline"]], "sparknlp.base.table_assembler": [[146, "module-sparknlp.base.table_assembler"]], "sparknlp.base.token_assembler": [[147, "module-sparknlp.base.token_assembler"]], "sparknlp.common.annotator_approach": [[148, "module-sparknlp.common.annotator_approach"]], "sparknlp.common.annotator_model": [[149, "module-sparknlp.common.annotator_model"]], "sparknlp.common.annotator_properties": [[150, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[151, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[152, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[153, "module-sparknlp.common"]], "sparknlp.common.properties": [[154, "module-sparknlp.common.properties"]], "sparknlp.common.read_as": [[155, "module-sparknlp.common.read_as"]], "sparknlp.common.recursive_annotator_approach": [[156, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[157, "module-sparknlp.common.storage"]], "sparknlp.common.utils": [[158, "module-sparknlp.common.utils"]], "Functions": [[158, "functions"], [159, "functions"], [160, "functions"], [186, "functions"]], "sparknlp.functions": [[159, "module-sparknlp.functions"]], "sparknlp": [[160, "module-sparknlp"]], "Package Contents": [[160, "package-contents"]], "sparknlp.internal.annotator_java_ml": [[161, "module-sparknlp.internal.annotator_java_ml"]], "sparknlp.internal.annotator_transformer": [[162, "module-sparknlp.internal.annotator_transformer"]], "sparknlp.internal.extended_java_wrapper": [[163, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[164, "module-sparknlp.internal"]], "sparknlp.internal.params_getters_setters": [[165, "module-sparknlp.internal.params_getters_setters"]], "sparknlp.internal.recursive": [[166, "module-sparknlp.internal.recursive"]], "sparknlp.logging.comet": [[167, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[168, "module-sparknlp.logging"]], "sparknlp.pretrained": [[169, "module-sparknlp.pretrained"]], "sparknlp.pretrained.pretrained_pipeline": [[170, "module-sparknlp.pretrained.pretrained_pipeline"]], "sparknlp.pretrained.resource_downloader": [[171, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[172, "module-sparknlp.pretrained.utils"]], "sparknlp.training._tf_graph_builders.graph_builders": [[173, "module-sparknlp.training._tf_graph_builders.graph_builders"]], "sparknlp.training._tf_graph_builders": [[174, "module-sparknlp.training._tf_graph_builders"]], "sparknlp.training._tf_graph_builders.ner_dl.create_graph": [[175, "module-sparknlp.training._tf_graph_builders.ner_dl.create_graph"]], "sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder": [[176, "module-sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"]], "sparknlp.training._tf_graph_builders.ner_dl": [[177, "module-sparknlp.training._tf_graph_builders.ner_dl"]], "sparknlp.training._tf_graph_builders.ner_dl.ner_model": [[178, "module-sparknlp.training._tf_graph_builders.ner_dl.ner_model"]], "sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver": [[179, "module-sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"]], "sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper": [[180, "module-sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"]], "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[181, "module-sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"]], "sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[182, "module-sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"]], "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[183, "module-sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"]], "sparknlp.training._tf_graph_builders.tf2contrib": [[184, "module-sparknlp.training._tf_graph_builders.tf2contrib"]], "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[185, "module-sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[186, "module-sparknlp.training._tf_graph_builders.tf2contrib.rnn"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[187, "module-sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"]], "sparknlp.training._tf_graph_builders_1x.graph_builders": [[188, "module-sparknlp.training._tf_graph_builders_1x.graph_builders"]], "sparknlp.training._tf_graph_builders_1x": [[189, "module-sparknlp.training._tf_graph_builders_1x"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph": [[190, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder": [[191, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"]], "sparknlp.training._tf_graph_builders_1x.ner_dl": [[192, "module-sparknlp.training._tf_graph_builders_1x.ner_dl"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model": [[193, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver": [[194, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper": [[195, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"]], "sparknlp.training.conll": [[196, "module-sparknlp.training.conll"]], "sparknlp.training.conllu": [[197, "module-sparknlp.training.conllu"]], "sparknlp.training": [[198, "module-sparknlp.training"]], "sparknlp.training.pos": [[199, "module-sparknlp.training.pos"]], "sparknlp.training.pub_tator": [[200, "module-sparknlp.training.pub_tator"]], "sparknlp.training.tfgraphs": [[201, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[202, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[203, "module-sparknlp.util"]], "Modules": [[204, "modules"]], "Comet - A meta machine learning platform": [[205, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[205, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[205, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[205, "logging-evaluation-metrics"]], "Logging Visualizations": [[205, "logging-visualizations"]], "Running An Offline Experiment": [[205, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[206, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[207, "third-party-projects"]], "Logging": [[207, "logging"]], "Annotation": [[208, "annotation"]], "Annotators": [[209, "annotators"]], "Annotator Approaches": [[209, "annotator-approaches"]], "Annotator Models": [[209, "annotator-models"]], "Note": [[209, "note"]], "Pretrained Models": [[209, "pretrained-models"]], "Common Functions": [[209, "common-functions"]], "Available Annotators": [[209, "available-annotators"]], "Setting up your own pipeline": [[210, "setting-up-your-own-pipeline"]], "Annotator types": [[210, "annotator-types"]], "Necessary imports": [[210, "necessary-imports"]], "Constructing the Pipeline": [[210, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[210, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[210, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[210, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[210, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[211, "helper-functions"]], "User Guide": [[212, "user-guide"]], "Light Pipelines": [[213, "light-pipelines"]], "Converting PipelineModels": [[213, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[213, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[214, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[214, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[214, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[214, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[214, "available-pipelines"]], "Loading datasets for training": [[215, "loading-datasets-for-training"]], "POS Dataset": [[215, "pos-dataset"]], "CoNLL Dataset": [[215, "conll-dataset"]], "CoNLLU Dataset": [[215, "conllu-dataset"]], "Spell Checkers Dataset": [[215, "spell-checkers-dataset"]], "PubTator Dataset": [[215, "pubtator-dataset"]]}, "indexentries": {"annotation (class in sparknlp.annotation)": [[12, "sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[12, "sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[12, "sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[12, "sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[12, "sparknlp.annotation.Annotation.fromRow"]], "module": [[12, "module-sparknlp.annotation"], [13, "module-sparknlp.annotation_audio"], [14, "module-sparknlp.annotation_image"], [15, "module-sparknlp.annotator.audio.hubert_for_ctc"], [16, "module-sparknlp.annotator.audio"], [17, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"], [18, "module-sparknlp.annotator.chunker"], [19, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"], [20, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [21, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"], [22, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"], [23, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [24, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"], [25, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"], [26, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"], [27, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [28, "module-sparknlp.annotator.classifier_dl.classifier_dl"], [29, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [30, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [31, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [32, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [33, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [34, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [35, "module-sparknlp.annotator.classifier_dl"], [36, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [37, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [38, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [39, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"], [40, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [41, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [42, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [43, "module-sparknlp.annotator.classifier_dl.sentiment_dl"], [44, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [45, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [46, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [47, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [48, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [49, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [50, "module-sparknlp.annotator.coref"], [51, "module-sparknlp.annotator.coref.spanbert_coref"], [52, "module-sparknlp.annotator.cv"], [53, "module-sparknlp.annotator.cv.swin_for_image_classification"], [54, "module-sparknlp.annotator.cv.vit_for_image_classification"], [55, "module-sparknlp.annotator.dependency.dependency_parser"], [56, "module-sparknlp.annotator.dependency"], [57, "module-sparknlp.annotator.dependency.typed_dependency_parser"], [58, "module-sparknlp.annotator.document_normalizer"], [59, "module-sparknlp.annotator.embeddings.albert_embeddings"], [60, "module-sparknlp.annotator.embeddings.bert_embeddings"], [61, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"], [62, "module-sparknlp.annotator.embeddings.camembert_embeddings"], [63, "module-sparknlp.annotator.embeddings.chunk_embeddings"], [64, "module-sparknlp.annotator.embeddings.deberta_embeddings"], [65, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"], [66, "module-sparknlp.annotator.embeddings.doc2vec"], [67, "module-sparknlp.annotator.embeddings.elmo_embeddings"], [68, "module-sparknlp.annotator.embeddings"], [69, "module-sparknlp.annotator.embeddings.longformer_embeddings"], [70, "module-sparknlp.annotator.embeddings.roberta_embeddings"], [71, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [72, "module-sparknlp.annotator.embeddings.sentence_embeddings"], [73, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"], [74, "module-sparknlp.annotator.embeddings.word2vec"], [75, "module-sparknlp.annotator.embeddings.word_embeddings"], [76, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [77, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [78, "module-sparknlp.annotator.embeddings.xlnet_embeddings"], [79, "module-sparknlp.annotator.er.entity_ruler"], [80, "module-sparknlp.annotator.er"], [81, "module-sparknlp.annotator.graph_extraction"], [82, "module-sparknlp.annotator"], [83, "module-sparknlp.annotator.keyword_extraction"], [84, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [85, "module-sparknlp.annotator.ld_dl"], [86, "module-sparknlp.annotator.ld_dl.language_detector_dl"], [87, "module-sparknlp.annotator.lemmatizer"], [88, "module-sparknlp.annotator.matcher.big_text_matcher"], [89, "module-sparknlp.annotator.matcher.date_matcher"], [90, "module-sparknlp.annotator.matcher"], [91, "module-sparknlp.annotator.matcher.multi_date_matcher"], [92, "module-sparknlp.annotator.matcher.regex_matcher"], [93, "module-sparknlp.annotator.matcher.text_matcher"], [94, "module-sparknlp.annotator.n_gram_generator"], [95, "module-sparknlp.annotator.ner"], [96, "module-sparknlp.annotator.ner.ner_approach"], [97, "module-sparknlp.annotator.ner.ner_converter"], [98, "module-sparknlp.annotator.ner.ner_crf"], [99, "module-sparknlp.annotator.ner.ner_dl"], [100, "module-sparknlp.annotator.ner.ner_overwriter"], [101, "module-sparknlp.annotator.normalizer"], [102, "module-sparknlp.annotator.param.classifier_encoder"], [103, "module-sparknlp.annotator.param.evaluation_dl_params"], [104, "module-sparknlp.annotator.param"], [105, "module-sparknlp.annotator.pos"], [106, "module-sparknlp.annotator.pos.perceptron"], [107, "module-sparknlp.annotator.sentence"], [108, "module-sparknlp.annotator.sentence.sentence_detector"], [109, "module-sparknlp.annotator.sentence.sentence_detector_dl"], [110, "module-sparknlp.annotator.sentiment"], [111, "module-sparknlp.annotator.sentiment.sentiment_detector"], [112, "module-sparknlp.annotator.sentiment.vivekn_sentiment"], [113, "module-sparknlp.annotator.seq2seq.gpt2_transformer"], [114, "module-sparknlp.annotator.seq2seq"], [115, "module-sparknlp.annotator.seq2seq.marian_transformer"], [116, "module-sparknlp.annotator.seq2seq.t5_transformer"], [117, "module-sparknlp.annotator.spell_check.context_spell_checker"], [118, "module-sparknlp.annotator.spell_check"], [119, "module-sparknlp.annotator.spell_check.norvig_sweeting"], [120, "module-sparknlp.annotator.spell_check.symmetric_delete"], [121, "module-sparknlp.annotator.stemmer"], [122, "module-sparknlp.annotator.stop_words_cleaner"], [123, "module-sparknlp.annotator.tf_ner_dl_graph_builder"], [124, "module-sparknlp.annotator.token.chunk_tokenizer"], [125, "module-sparknlp.annotator.token"], [126, "module-sparknlp.annotator.token.recursive_tokenizer"], [127, "module-sparknlp.annotator.token.regex_tokenizer"], [128, "module-sparknlp.annotator.token.token2_chunk"], [129, "module-sparknlp.annotator.token.tokenizer"], [130, "module-sparknlp.annotator.ws"], [131, "module-sparknlp.annotator.ws.word_segmenter"], [132, "module-sparknlp.base.audio_assembler"], [133, "module-sparknlp.base.chunk2_doc"], [134, "module-sparknlp.base.doc2_chunk"], [135, "module-sparknlp.base.document_assembler"], [136, "module-sparknlp.base.embeddings_finisher"], [137, "module-sparknlp.base.finisher"], [138, "module-sparknlp.base.graph_finisher"], [139, "module-sparknlp.base.has_recursive_fit"], [140, "module-sparknlp.base.has_recursive_transform"], [141, "module-sparknlp.base.image_assembler"], [142, "module-sparknlp.base"], [143, "module-sparknlp.base.light_pipeline"], [144, "module-sparknlp.base.multi_document_assembler"], [145, "module-sparknlp.base.recursive_pipeline"], [146, "module-sparknlp.base.table_assembler"], [147, "module-sparknlp.base.token_assembler"], [148, "module-sparknlp.common.annotator_approach"], [149, "module-sparknlp.common.annotator_model"], [150, "module-sparknlp.common.annotator_properties"], [151, "module-sparknlp.common.annotator_type"], [152, "module-sparknlp.common.coverage_result"], [153, "module-sparknlp.common"], [154, "module-sparknlp.common.properties"], [155, "module-sparknlp.common.read_as"], [156, "module-sparknlp.common.recursive_annotator_approach"], [157, "module-sparknlp.common.storage"], [158, "module-sparknlp.common.utils"], [159, "module-sparknlp.functions"], [160, "module-sparknlp"], [161, "module-sparknlp.internal.annotator_java_ml"], [162, "module-sparknlp.internal.annotator_transformer"], [163, "module-sparknlp.internal.extended_java_wrapper"], [164, "module-sparknlp.internal"], [165, "module-sparknlp.internal.params_getters_setters"], [166, "module-sparknlp.internal.recursive"], [167, "module-sparknlp.logging.comet"], [168, "module-sparknlp.logging"], [169, "module-sparknlp.pretrained"], [170, "module-sparknlp.pretrained.pretrained_pipeline"], [171, "module-sparknlp.pretrained.resource_downloader"], [172, "module-sparknlp.pretrained.utils"], [173, "module-sparknlp.training._tf_graph_builders.graph_builders"], [174, "module-sparknlp.training._tf_graph_builders"], [175, "module-sparknlp.training._tf_graph_builders.ner_dl.create_graph"], [176, "module-sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"], [177, "module-sparknlp.training._tf_graph_builders.ner_dl"], [178, "module-sparknlp.training._tf_graph_builders.ner_dl.ner_model"], [179, "module-sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"], [180, "module-sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"], [181, "module-sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"], [182, "module-sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"], [183, "module-sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"], [184, "module-sparknlp.training._tf_graph_builders.tf2contrib"], [185, "module-sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"], [186, "module-sparknlp.training._tf_graph_builders.tf2contrib.rnn"], [187, "module-sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"], [188, "module-sparknlp.training._tf_graph_builders_1x.graph_builders"], [189, "module-sparknlp.training._tf_graph_builders_1x"], [190, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"], [191, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"], [192, "module-sparknlp.training._tf_graph_builders_1x.ner_dl"], [193, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"], [194, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"], [195, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"], [196, "module-sparknlp.training.conll"], [197, "module-sparknlp.training.conllu"], [198, "module-sparknlp.training"], [199, "module-sparknlp.training.pos"], [200, "module-sparknlp.training.pub_tator"], [201, "module-sparknlp.training.tfgraphs"], [202, "module-sparknlp.upload_to_hub"], [203, "module-sparknlp.util"]], "sparknlp.annotation": [[12, "module-sparknlp.annotation"]], "torow() (annotation static method)": [[12, "sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in sparknlp.annotation_audio)": [[13, "sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[13, "sparknlp.annotation_audio.AnnotationAudio.copy"]], "sparknlp.annotation_audio": [[13, "module-sparknlp.annotation_audio"]], "annotationimage (class in sparknlp.annotation_image)": [[14, "sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[14, "sparknlp.annotation_image.AnnotationImage.copy"]], "sparknlp.annotation_image": [[14, "module-sparknlp.annotation_image"]], "hubertforctc (class in sparknlp.annotator.audio.hubert_for_ctc)": [[15, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC"]], "loadsavedmodel() (hubertforctc static method)": [[15, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.loadSavedModel"]], "pretrained() (hubertforctc static method)": [[15, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.pretrained"]], "setconfigprotobytes() (hubertforctc method)": [[15, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.hubert_for_ctc": [[15, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[16, "module-sparknlp.annotator.audio"]], "wav2vec2forctc (class in sparknlp.annotator.audio.wav2vec2_for_ctc)": [[17, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[17, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[17, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "setconfigprotobytes() (wav2vec2forctc method)": [[17, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[17, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "chunker (class in sparknlp.annotator.chunker)": [[18, "sparknlp.annotator.chunker.Chunker"]], "setregexparsers() (chunker method)": [[18, "sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "sparknlp.annotator.chunker": [[18, "module-sparknlp.annotator.chunker"]], "albertforquestionanswering (class in sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[19, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[19, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[19, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (albertforquestionanswering method)": [[19, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[19, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[19, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "albertforsequenceclassification (class in sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "setcoalescesentences() (albertforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[20, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "albertfortokenclassification (class in sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[21, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[21, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[21, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[21, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "setconfigprotobytes() (albertfortokenclassification method)": [[21, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[21, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[21, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "bertforquestionanswering (class in sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[22, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[22, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[22, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (bertforquestionanswering method)": [[22, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[22, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[22, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "bertforsequenceclassification (class in sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "setcoalescesentences() (bertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[23, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "bertfortokenclassification (class in sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[24, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[24, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[24, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[24, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "setconfigprotobytes() (bertfortokenclassification method)": [[24, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[24, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[24, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "camembertforquestionanswering (class in sparknlp.annotator.classifier_dl.camembert_for_question_answering)": [[25, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering"]], "loadsavedmodel() (camembertforquestionanswering static method)": [[25, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.loadSavedModel"]], "pretrained() (camembertforquestionanswering static method)": [[25, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (camembertforquestionanswering method)": [[25, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforquestionanswering method)": [[25, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[25, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "camembertforsequenceclassification (class in sparknlp.annotator.classifier_dl.camembert_for_sequence_classification)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification"]], "getclasses() (camembertforsequenceclassification method)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.getClasses"]], "loadsavedmodel() (camembertforsequenceclassification static method)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.loadSavedModel"]], "pretrained() (camembertforsequenceclassification static method)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.pretrained"]], "setcoalescesentences() (camembertforsequenceclassification method)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (camembertforsequenceclassification method)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforsequenceclassification method)": [[26, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[26, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "camembertfortokenclassification (class in sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[27, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[27, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[27, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[27, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[27, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[27, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[27, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "classifierdlapproach (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[28, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[28, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[28, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "setconfigprotobytes() (classifierdlmodel method)": [[28, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[28, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[28, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "debertaforquestionanswering (class in sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[29, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[29, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[29, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[29, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[29, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[29, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "debertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[30, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[30, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "debertafortokenclassification (class in sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[31, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[31, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[31, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[31, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (debertafortokenclassification method)": [[31, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[31, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[31, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "distilbertforquestionanswering (class in sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[32, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[32, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[32, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[32, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[32, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[32, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "distilbertforsequenceclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[33, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "distilbertfortokenclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[34, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[34, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[34, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[34, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[34, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[34, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[34, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[35, "module-sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[36, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[36, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[36, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[36, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[36, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[36, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "longformerforsequenceclassification (class in sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[37, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "longformerfortokenclassification (class in sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[38, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[38, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[38, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[38, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[38, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[38, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[38, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "multiclassifierdlapproach (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[39, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[39, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "robertaforquestionanswering (class in sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[40, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[40, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[40, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[40, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[40, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[40, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "robertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[41, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[41, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "robertafortokenclassification (class in sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[42, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[42, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[42, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[42, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (robertafortokenclassification method)": [[42, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[42, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[42, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sentimentdlapproach (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "setconfigprotobytes() (sentimentdlmodel method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[43, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[43, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "tapasforquestionanswering (class in sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[44, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[44, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[44, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[44, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[45, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[45, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[45, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[45, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[45, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[45, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "xlmrobertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[46, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[46, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "xlmrobertafortokenclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[47, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[47, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[47, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[47, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[47, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[47, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[47, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "xlnetforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[48, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[48, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "xlnetfortokenclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[49, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[49, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[49, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[49, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[49, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[49, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[49, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[50, "module-sparknlp.annotator.coref"]], "spanbertcorefmodel (class in sparknlp.annotator.coref.spanbert_coref)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[51, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "sparknlp.annotator.coref.spanbert_coref": [[51, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv": [[52, "module-sparknlp.annotator.cv"]], "swinforimageclassification (class in sparknlp.annotator.cv.swin_for_image_classification)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification"]], "getclasses() (swinforimageclassification method)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.getClasses"]], "loadsavedmodel() (swinforimageclassification static method)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.loadSavedModel"]], "pretrained() (swinforimageclassification static method)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.pretrained"]], "setconfigprotobytes() (swinforimageclassification method)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setConfigProtoBytes"]], "setdorescale() (swinforimageclassification method)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setDoRescale"]], "setrescalefactor() (swinforimageclassification method)": [[53, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[53, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "vitforimageclassification (class in sparknlp.annotator.cv.vit_for_image_classification)": [[54, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[54, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[54, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[54, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "setconfigprotobytes() (vitforimageclassification method)": [[54, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "sparknlp.annotator.cv.vit_for_image_classification": [[54, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "dependencyparserapproach (class in sparknlp.annotator.dependency.dependency_parser)": [[55, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in sparknlp.annotator.dependency.dependency_parser)": [[55, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[55, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "setconllu() (dependencyparserapproach method)": [[55, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[55, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[55, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser": [[55, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[56, "module-sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[57, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[57, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[57, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "setconll2009() (typeddependencyparserapproach method)": [[57, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[57, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[57, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[57, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "documentnormalizer (class in sparknlp.annotator.document_normalizer)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "setaction() (documentnormalizer method)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[58, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "sparknlp.annotator.document_normalizer": [[58, "module-sparknlp.annotator.document_normalizer"]], "albertembeddings (class in sparknlp.annotator.embeddings.albert_embeddings)": [[59, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[59, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[59, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "setconfigprotobytes() (albertembeddings method)": [[59, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[59, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.albert_embeddings": [[59, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "bertembeddings (class in sparknlp.annotator.embeddings.bert_embeddings)": [[60, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[60, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[60, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "setconfigprotobytes() (bertembeddings method)": [[60, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[60, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[60, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "bertsentenceembeddings (class in sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[61, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[61, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[61, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[61, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[61, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[61, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[61, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "camembertembeddings (class in sparknlp.annotator.embeddings.camembert_embeddings)": [[62, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[62, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[62, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "setconfigprotobytes() (camembertembeddings method)": [[62, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[62, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[62, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "chunkembeddings (class in sparknlp.annotator.embeddings.chunk_embeddings)": [[63, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[63, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[63, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[63, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "debertaembeddings (class in sparknlp.annotator.embeddings.deberta_embeddings)": [[64, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[64, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[64, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "setconfigprotobytes() (debertaembeddings method)": [[64, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[64, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[64, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "distilbertembeddings (class in sparknlp.annotator.embeddings.distil_bert_embeddings)": [[65, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[65, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[65, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "setconfigprotobytes() (distilbertembeddings method)": [[65, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[65, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[65, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "doc2vecapproach (class in sparknlp.annotator.embeddings.doc2vec)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in sparknlp.annotator.embeddings.doc2vec)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "setmaxiter() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[66, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec": [[66, "module-sparknlp.annotator.embeddings.doc2vec"]], "elmoembeddings (class in sparknlp.annotator.embeddings.elmo_embeddings)": [[67, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[67, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[67, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "setbatchsize() (elmoembeddings method)": [[67, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[67, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[67, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[67, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[68, "module-sparknlp.annotator.embeddings"]], "longformerembeddings (class in sparknlp.annotator.embeddings.longformer_embeddings)": [[69, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[69, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[69, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "setconfigprotobytes() (longformerembeddings method)": [[69, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[69, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[69, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "robertaembeddings (class in sparknlp.annotator.embeddings.roberta_embeddings)": [[70, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[70, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[70, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (robertaembeddings method)": [[70, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[70, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[70, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "robertasentenceembeddings (class in sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[71, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[71, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[71, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[71, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[71, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[71, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sentenceembeddings (class in sparknlp.annotator.embeddings.sentence_embeddings)": [[72, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[72, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[72, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "universalsentenceencoder (class in sparknlp.annotator.embeddings.universal_sentence_encoder)": [[73, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[73, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[73, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "setconfigprotobytes() (universalsentenceencoder method)": [[73, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[73, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[73, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "word2vecapproach (class in sparknlp.annotator.embeddings.word2vec)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in sparknlp.annotator.embeddings.word2vec)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "setmaxiter() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[74, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.word2vec": [[74, "module-sparknlp.annotator.embeddings.word2vec"]], "wordembeddings (class in sparknlp.annotator.embeddings.word_embeddings)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in sparknlp.annotator.embeddings.word_embeddings)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "setreadcachesize() (wordembeddings method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[75, "module-sparknlp.annotator.embeddings.word_embeddings"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[75, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[76, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[76, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[76, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[76, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[76, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[76, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "xlmrobertasentenceembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[77, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[77, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[77, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[77, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[77, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[77, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "xlnetembeddings (class in sparknlp.annotator.embeddings.xlnet_embeddings)": [[78, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[78, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[78, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "setconfigprotobytes() (xlnetembeddings method)": [[78, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[78, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[78, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "entityrulerapproach (class in sparknlp.annotator.er.entity_ruler)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in sparknlp.annotator.er.entity_ruler)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "setalphabetresource() (entityrulerapproach method)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setenablepatternregex() (entityrulerapproach method)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setEnablePatternRegex"]], "setpatternsresource() (entityrulerapproach method)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[79, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "sparknlp.annotator.er.entity_ruler": [[79, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[80, "module-sparknlp.annotator.er"]], "graphextraction (class in sparknlp.annotator.graph_extraction)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction"]], "setdelimiter() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[81, "sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "sparknlp.annotator.graph_extraction": [[81, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[82, "module-sparknlp.annotator"]], "sparknlp.annotator.keyword_extraction": [[83, "module-sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "setmaxngrams() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[84, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[84, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[85, "module-sparknlp.annotator.ld_dl"]], "languagedetectordl (class in sparknlp.annotator.ld_dl.language_detector_dl)": [[86, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[86, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "setcoalescesentences() (languagedetectordl method)": [[86, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[86, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[86, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[86, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[86, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "lemmatizer (class in sparknlp.annotator.lemmatizer)": [[87, "sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in sparknlp.annotator.lemmatizer)": [[87, "sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[87, "sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "setdictionary() (lemmatizer method)": [[87, "sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[87, "sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[87, "sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "sparknlp.annotator.lemmatizer": [[87, "module-sparknlp.annotator.lemmatizer"]], "bigtextmatcher (class in sparknlp.annotator.matcher.big_text_matcher)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in sparknlp.annotator.matcher.big_text_matcher)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "setcasesensitive() (bigtextmatcher method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[88, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[88, "module-sparknlp.annotator.matcher.big_text_matcher"]], "datematcher (class in sparknlp.annotator.matcher.date_matcher)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in sparknlp.annotator.matcher.date_matcher)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "setanchordateday() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[89, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "sparknlp.annotator.matcher.date_matcher": [[89, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[90, "module-sparknlp.annotator.matcher"]], "multidatematcher (class in sparknlp.annotator.matcher.multi_date_matcher)": [[91, "sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[91, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in sparknlp.annotator.matcher.regex_matcher)": [[92, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in sparknlp.annotator.matcher.regex_matcher)": [[92, "sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "setdelimiter() (regexmatcher method)": [[92, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setDelimiter"]], "setexternalrules() (regexmatcher method)": [[92, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setrules() (regexmatcher method)": [[92, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setRules"]], "setstrategy() (regexmatcher method)": [[92, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "sparknlp.annotator.matcher.regex_matcher": [[92, "module-sparknlp.annotator.matcher.regex_matcher"]], "textmatcher (class in sparknlp.annotator.matcher.text_matcher)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in sparknlp.annotator.matcher.text_matcher)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "setbuildfromtokens() (textmatcher method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[93, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher": [[93, "module-sparknlp.annotator.matcher.text_matcher"]], "ngramgenerator (class in sparknlp.annotator.n_gram_generator)": [[94, "sparknlp.annotator.n_gram_generator.NGramGenerator"]], "setdelimiter() (ngramgenerator method)": [[94, "sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[94, "sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[94, "sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "sparknlp.annotator.n_gram_generator": [[94, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[95, "module-sparknlp.annotator.ner"]], "nerapproach (class in sparknlp.annotator.ner.ner_approach)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "setentities() (nerapproach method)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[96, "sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "sparknlp.annotator.ner.ner_approach": [[96, "module-sparknlp.annotator.ner.ner_approach"]], "nerconverter (class in sparknlp.annotator.ner.ner_converter)": [[97, "sparknlp.annotator.ner.ner_converter.NerConverter"]], "setpreserveposition() (nerconverter method)": [[97, "sparknlp.annotator.ner.ner_converter.NerConverter.setPreservePosition"]], "setwhitelist() (nerconverter method)": [[97, "sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "sparknlp.annotator.ner.ner_converter": [[97, "module-sparknlp.annotator.ner.ner_converter"]], "nercrfapproach (class in sparknlp.annotator.ner.ner_crf)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in sparknlp.annotator.ner.ner_crf)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "setc0() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[98, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "sparknlp.annotator.ner.ner_crf": [[98, "module-sparknlp.annotator.ner.ner_crf"]], "nerdlapproach (class in sparknlp.annotator.ner.ner_dl)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in sparknlp.annotator.ner.ner_dl)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "setbatchsize() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[99, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "sparknlp.annotator.ner.ner_dl": [[99, "module-sparknlp.annotator.ner.ner_dl"]], "neroverwriter (class in sparknlp.annotator.ner.ner_overwriter)": [[100, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "setnerwords() (neroverwriter method)": [[100, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[100, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[100, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "sparknlp.annotator.ner.ner_overwriter": [[100, "module-sparknlp.annotator.ner.ner_overwriter"]], "normalizer (class in sparknlp.annotator.normalizer)": [[101, "sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in sparknlp.annotator.normalizer)": [[101, "sparknlp.annotator.normalizer.NormalizerModel"]], "setcleanuppatterns() (normalizer method)": [[101, "sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[101, "sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[101, "sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[101, "sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[101, "sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "sparknlp.annotator.normalizer": [[101, "module-sparknlp.annotator.normalizer"]], "classifierencoder (class in sparknlp.annotator.param.classifier_encoder)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "setbatchsize() (classifierencoder method)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[102, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "sparknlp.annotator.param.classifier_encoder": [[102, "module-sparknlp.annotator.param.classifier_encoder"]], "evaluationdlparams (class in sparknlp.annotator.param.evaluation_dl_params)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "setenableoutputlogs() (evaluationdlparams method)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[103, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "sparknlp.annotator.param.evaluation_dl_params": [[103, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[104, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[105, "module-sparknlp.annotator.pos"]], "perceptronapproach (class in sparknlp.annotator.pos.perceptron)": [[106, "sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in sparknlp.annotator.pos.perceptron)": [[106, "sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[106, "sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[106, "sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "setiterations() (perceptronapproach method)": [[106, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[106, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "sparknlp.annotator.pos.perceptron": [[106, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[107, "module-sparknlp.annotator.sentence"]], "sentencedetector (class in sparknlp.annotator.sentence.sentence_detector)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in sparknlp.annotator.sentence.sentence_detector)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "setcustombounds() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[108, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector": [[108, "module-sparknlp.annotator.sentence.sentence_detector"]], "sentencedetectordlapproach (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "setcustombounds() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[109, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[109, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[110, "module-sparknlp.annotator.sentiment"]], "sentimentdetector (class in sparknlp.annotator.sentiment.sentiment_detector)": [[111, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in sparknlp.annotator.sentiment.sentiment_detector)": [[111, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "setdictionary() (sentimentdetector method)": [[111, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "sparknlp.annotator.sentiment.sentiment_detector": [[111, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "viveknsentimentapproach (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[112, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[112, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[112, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "setprunecorpus() (viveknsentimentapproach method)": [[112, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[112, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[112, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "gpt2transformer (class in sparknlp.annotator.seq2seq.gpt2_transformer)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "setconfigprotobytes() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[113, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[113, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[114, "module-sparknlp.annotator.seq2seq"]], "mariantransformer (class in sparknlp.annotator.seq2seq.marian_transformer)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "setconfigprotobytes() (mariantransformer method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[115, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "sparknlp.annotator.seq2seq.marian_transformer": [[115, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "t5transformer (class in sparknlp.annotator.seq2seq.t5_transformer)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "setconfigprotobytes() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[116, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "sparknlp.annotator.seq2seq.t5_transformer": [[116, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "contextspellcheckerapproach (class in sparknlp.annotator.spell_check.context_spell_checker)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in sparknlp.annotator.spell_check.context_spell_checker)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "setbatchsize() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setcomparelowcase() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setinitialrate() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker": [[117, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "updateregexclass() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[117, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "sparknlp.annotator.spell_check": [[118, "module-sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "setcasesensitive() (norvigsweetingapproach method)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[119, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[119, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "symmetricdeleteapproach (class in sparknlp.annotator.spell_check.symmetric_delete)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in sparknlp.annotator.spell_check.symmetric_delete)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[120, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete": [[120, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "stemmer (class in sparknlp.annotator.stemmer)": [[121, "sparknlp.annotator.stemmer.Stemmer"]], "sparknlp.annotator.stemmer": [[121, "module-sparknlp.annotator.stemmer"]], "stopwordscleaner (class in sparknlp.annotator.stop_words_cleaner)": [[122, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[122, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[122, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "setcasesensitive() (stopwordscleaner method)": [[122, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[122, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[122, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "sparknlp.annotator.stop_words_cleaner": [[122, "module-sparknlp.annotator.stop_words_cleaner"]], "tfnerdlgraphbuilder (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[123, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[123, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "chunktokenizer (class in sparknlp.annotator.token.chunk_tokenizer)": [[124, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in sparknlp.annotator.token.chunk_tokenizer)": [[124, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "sparknlp.annotator.token.chunk_tokenizer": [[124, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[125, "module-sparknlp.annotator.token"]], "recursivetokenizer (class in sparknlp.annotator.token.recursive_tokenizer)": [[126, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in sparknlp.annotator.token.recursive_tokenizer)": [[126, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "setinfixes() (recursivetokenizer method)": [[126, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[126, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[126, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[126, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "sparknlp.annotator.token.recursive_tokenizer": [[126, "module-sparknlp.annotator.token.recursive_tokenizer"]], "regextokenizer (class in sparknlp.annotator.token.regex_tokenizer)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "setmaxlength() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[127, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "sparknlp.annotator.token.regex_tokenizer": [[127, "module-sparknlp.annotator.token.regex_tokenizer"]], "token2chunk (class in sparknlp.annotator.token.token2_chunk)": [[128, "sparknlp.annotator.token.token2_chunk.Token2Chunk"]], "sparknlp.annotator.token.token2_chunk": [[128, "module-sparknlp.annotator.token.token2_chunk"]], "tokenizer (class in sparknlp.annotator.token.tokenizer)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in sparknlp.annotator.token.tokenizer)": [[129, "sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[129, "sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[129, "sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "setcasesensitiveexceptions() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[129, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[129, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[129, "sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "sparknlp.annotator.token.tokenizer": [[129, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[130, "module-sparknlp.annotator.ws"]], "wordsegmenterapproach (class in sparknlp.annotator.ws.word_segmenter)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in sparknlp.annotator.ws.word_segmenter)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setenableregextokenizer() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setEnableRegexTokenizer"]], "setenableregextokenizer() (wordsegmentermodel method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setEnableRegexTokenizer"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setpattern() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPattern"]], "setpattern() (wordsegmentermodel method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setPattern"]], "setposcolumn() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "settolowercase() (wordsegmenterapproach method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setToLowercase"]], "settolowercase() (wordsegmentermodel method)": [[131, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setToLowercase"]], "sparknlp.annotator.ws.word_segmenter": [[131, "module-sparknlp.annotator.ws.word_segmenter"]], "audioassembler (class in sparknlp.base.audio_assembler)": [[132, "sparknlp.base.audio_assembler.AudioAssembler"]], "getoutputcol() (audioassembler method)": [[132, "sparknlp.base.audio_assembler.AudioAssembler.getOutputCol"]], "setinputcol() (audioassembler method)": [[132, "sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[132, "sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "sparknlp.base.audio_assembler": [[132, "module-sparknlp.base.audio_assembler"]], "chunk2doc (class in sparknlp.base.chunk2_doc)": [[133, "sparknlp.base.chunk2_doc.Chunk2Doc"]], "sparknlp.base.chunk2_doc": [[133, "module-sparknlp.base.chunk2_doc"]], "doc2chunk (class in sparknlp.base.doc2_chunk)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk"]], "setchunkcol() (doc2chunk method)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[134, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "sparknlp.base.doc2_chunk": [[134, "module-sparknlp.base.doc2_chunk"]], "documentassembler (class in sparknlp.base.document_assembler)": [[135, "sparknlp.base.document_assembler.DocumentAssembler"]], "getoutputcol() (documentassembler method)": [[135, "sparknlp.base.document_assembler.DocumentAssembler.getOutputCol"]], "setcleanupmode() (documentassembler method)": [[135, "sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[135, "sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[135, "sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[135, "sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[135, "sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "sparknlp.base.document_assembler": [[135, "module-sparknlp.base.document_assembler"]], "embeddingsfinisher (class in sparknlp.base.embeddings_finisher)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "getinputcols() (embeddingsfinisher method)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getInputCols"]], "getoutputcols() (embeddingsfinisher method)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getOutputCols"]], "setcleanannotations() (embeddingsfinisher method)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[136, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "sparknlp.base.embeddings_finisher": [[136, "module-sparknlp.base.embeddings_finisher"]], "finisher (class in sparknlp.base.finisher)": [[137, "sparknlp.base.finisher.Finisher"]], "getinputcols() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.getInputCols"]], "getoutputcols() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.getOutputCols"]], "setannotationsplitsymbol() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[137, "sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "sparknlp.base.finisher": [[137, "module-sparknlp.base.finisher"]], "graphfinisher (class in sparknlp.base.graph_finisher)": [[138, "sparknlp.base.graph_finisher.GraphFinisher"]], "setcleanannotations() (graphfinisher method)": [[138, "sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[138, "sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[138, "sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[138, "sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "sparknlp.base.graph_finisher": [[138, "module-sparknlp.base.graph_finisher"]], "hasrecursivefit (class in sparknlp.base.has_recursive_fit)": [[139, "sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "sparknlp.base.has_recursive_fit": [[139, "module-sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in sparknlp.base.has_recursive_transform)": [[140, "sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "sparknlp.base.has_recursive_transform": [[140, "module-sparknlp.base.has_recursive_transform"]], "imageassembler (class in sparknlp.base.image_assembler)": [[141, "sparknlp.base.image_assembler.ImageAssembler"]], "getoutputcol() (imageassembler method)": [[141, "sparknlp.base.image_assembler.ImageAssembler.getOutputCol"]], "setinputcol() (imageassembler method)": [[141, "sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[141, "sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "sparknlp.base.image_assembler": [[141, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[142, "module-sparknlp.base"]], "lightpipeline (class in sparknlp.base.light_pipeline)": [[143, "sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[143, "sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[143, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[143, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[143, "sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "setignoreunsupported() (lightpipeline method)": [[143, "sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "sparknlp.base.light_pipeline": [[143, "module-sparknlp.base.light_pipeline"]], "transform() (lightpipeline method)": [[143, "sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in sparknlp.base.multi_document_assembler)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "getoutputcols() (multidocumentassembler method)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.getOutputCols"]], "setcleanupmode() (multidocumentassembler method)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[144, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "sparknlp.base.multi_document_assembler": [[144, "module-sparknlp.base.multi_document_assembler"]], "recursivepipeline (class in sparknlp.base.recursive_pipeline)": [[145, "sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in sparknlp.base.recursive_pipeline)": [[145, "sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "sparknlp.base.recursive_pipeline": [[145, "module-sparknlp.base.recursive_pipeline"]], "tableassembler (class in sparknlp.base.table_assembler)": [[146, "sparknlp.base.table_assembler.TableAssembler"]], "setcsvdelimiter() (tableassembler method)": [[146, "sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[146, "sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[146, "sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "sparknlp.base.table_assembler": [[146, "module-sparknlp.base.table_assembler"]], "tokenassembler (class in sparknlp.base.token_assembler)": [[147, "sparknlp.base.token_assembler.TokenAssembler"]], "setpreserveposition() (tokenassembler method)": [[147, "sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "sparknlp.base.token_assembler": [[147, "module-sparknlp.base.token_assembler"]], "annotatorapproach (class in sparknlp.common.annotator_approach)": [[148, "sparknlp.common.annotator_approach.AnnotatorApproach"]], "sparknlp.common.annotator_approach": [[148, "module-sparknlp.common.annotator_approach"]], "annotatormodel (class in sparknlp.common.annotator_model)": [[149, "sparknlp.common.annotator_model.AnnotatorModel"]], "sparknlp.common.annotator_model": [[149, "module-sparknlp.common.annotator_model"]], "annotatorproperties (class in sparknlp.common.annotator_properties)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "setinputcols() (annotatorproperties method)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[150, "sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "sparknlp.common.annotator_properties": [[150, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[151, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[152, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[153, "module-sparknlp.common"]], "hasembeddingsproperties (class in sparknlp.common.properties)": [[154, "sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[154, "sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "setdimension() (hasembeddingsproperties method)": [[154, "sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "sparknlp.common.properties": [[154, "module-sparknlp.common.properties"]], "readas (class in sparknlp.common.read_as)": [[155, "sparknlp.common.read_as.ReadAs"]], "sparknlp.common.read_as": [[155, "module-sparknlp.common.read_as"]], "recursiveannotatorapproach (class in sparknlp.common.recursive_annotator_approach)": [[156, "sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "sparknlp.common.recursive_annotator_approach": [[156, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[157, "module-sparknlp.common.storage"]], "externalresource() (in module sparknlp.common.utils)": [[158, "sparknlp.common.utils.ExternalResource"]], "sparknlp.common.utils": [[158, "module-sparknlp.common.utils"]], "explode_annotations_col() (in module sparknlp.functions)": [[159, "sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module sparknlp.functions)": [[159, "sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module sparknlp.functions)": [[159, "sparknlp.functions.map_annotations"]], "map_annotations_array() (in module sparknlp.functions)": [[159, "sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module sparknlp.functions)": [[159, "sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module sparknlp.functions)": [[159, "sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module sparknlp.functions)": [[159, "sparknlp.functions.map_annotations_strict"]], "sparknlp.functions": [[159, "module-sparknlp.functions"]], "sparknlp": [[160, "module-sparknlp"]], "start() (in module sparknlp)": [[160, "sparknlp.start"]], "version() (in module sparknlp)": [[160, "sparknlp.version"]], "annotatorjavamlreadable (class in sparknlp.internal.annotator_java_ml)": [[161, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in sparknlp.internal.annotator_java_ml)": [[161, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "read() (annotatorjavamlreadable class method)": [[161, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "sparknlp.internal.annotator_java_ml": [[161, "module-sparknlp.internal.annotator_java_ml"]], "annotatortransformer (class in sparknlp.internal.annotator_transformer)": [[162, "sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "sparknlp.internal.annotator_transformer": [[162, "module-sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in sparknlp.internal.extended_java_wrapper)": [[163, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[163, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "sparknlp.internal.extended_java_wrapper": [[163, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[164, "module-sparknlp.internal"]], "paramsgetterssetters (class in sparknlp.internal.params_getters_setters)": [[165, "sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[165, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "setparamvalue() (paramsgetterssetters method)": [[165, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "sparknlp.internal.params_getters_setters": [[165, "module-sparknlp.internal.params_getters_setters"]], "recursiveestimator (class in sparknlp.internal.recursive)": [[166, "sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in sparknlp.internal.recursive)": [[166, "sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[166, "sparknlp.internal.recursive.RecursiveEstimator.fit"]], "sparknlp.internal.recursive": [[166, "module-sparknlp.internal.recursive"]], "cometlogger (class in sparknlp.logging.comet)": [[167, "sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[167, "sparknlp.logging.comet.CometLogger.monitor"]], "sparknlp.logging.comet": [[167, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[168, "module-sparknlp.logging"]], "sparknlp.pretrained": [[169, "module-sparknlp.pretrained"]], "pretrainedpipeline (class in sparknlp.pretrained.pretrained_pipeline)": [[170, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[170, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[170, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "fullannotateimage() (pretrainedpipeline method)": [[170, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotateImage"]], "sparknlp.pretrained.pretrained_pipeline": [[170, "module-sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[170, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "sparknlp.pretrained.resource_downloader": [[171, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[172, "module-sparknlp.pretrained.utils"]], "nertfgraphbuilder (class in sparknlp.training._tf_graph_builders.graph_builders)": [[173, "sparknlp.training._tf_graph_builders.graph_builders.NerTFGraphBuilder"]], "tfgraphbuilder (class in sparknlp.training._tf_graph_builders.graph_builders)": [[173, "sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilder"]], "tfgraphbuilderfactory (class in sparknlp.training._tf_graph_builders.graph_builders)": [[173, "sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory"]], "tensorflowaddonsneeded": [[173, "sparknlp.training._tf_graph_builders.graph_builders.TensorflowAddonsNeeded"]], "wrongtfversion": [[173, "sparknlp.training._tf_graph_builders.graph_builders.WrongTFVersion"], [188, "sparknlp.training._tf_graph_builders_1x.graph_builders.WrongTFVersion"]], "build() (tfgraphbuilderfactory static method)": [[173, "sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.build"], [188, "sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.build"]], "get_models() (tfgraphbuilderfactory static method)": [[173, "sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.get_models"], [188, "sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.get_models"]], "print_model_params() (tfgraphbuilderfactory static method)": [[173, "sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.print_model_params"], [188, "sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.print_model_params"]], "sparknlp.training._tf_graph_builders.graph_builders": [[173, "module-sparknlp.training._tf_graph_builders.graph_builders"]], "sparknlp.training._tf_graph_builders": [[174, "module-sparknlp.training._tf_graph_builders"]], "sparknlp.training._tf_graph_builders.ner_dl.create_graph": [[175, "module-sparknlp.training._tf_graph_builders.ner_dl.create_graph"]], "sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder": [[176, "module-sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"]], "sparknlp.training._tf_graph_builders.ner_dl": [[177, "module-sparknlp.training._tf_graph_builders.ner_dl"]], "sparknlp.training._tf_graph_builders.ner_dl.ner_model": [[178, "module-sparknlp.training._tf_graph_builders.ner_dl.ner_model"]], "sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver": [[179, "module-sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"]], "sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper": [[180, "module-sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"]], "embeddingwrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[181, "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper"]], "inputprojectionwrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[181, "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper"]], "outputprojectionwrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[181, "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper"]], "call() (embeddingwrapper method)": [[181, "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.call"]], "call() (inputprojectionwrapper method)": [[181, "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.call"]], "call() (outputprojectionwrapper method)": [[181, "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.call"]], "sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[181, "module-sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"]], "fusedrnncell (class in sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[182, "sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.FusedRNNCell"]], "fusedrnncelladaptor (class in sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[182, "sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.FusedRNNCellAdaptor"]], "timereversedfusedrnn (class in sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[182, "sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.TimeReversedFusedRNN"]], "sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[182, "module-sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"]], "grublockcell (class in sparknlp.training._tf_graph_builders.tf2contrib.gru_ops)": [[183, "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell"]], "grublockcellv2 (class in sparknlp.training._tf_graph_builders.tf2contrib.gru_ops)": [[183, "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2"]], "build() (grublockcellv2 method)": [[183, "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2.build"]], "call() (grublockcell method)": [[183, "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell.call"]], "sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[183, "module-sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"]], "sparknlp.training._tf_graph_builders.tf2contrib": [[184, "module-sparknlp.training._tf_graph_builders.tf2contrib"]], "lstmblockcell (class in sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[185, "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell"]], "lstmblockfusedcell (class in sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[185, "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockFusedCell"]], "lstmblockwrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[185, "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper"]], "call() (lstmblockcell method)": [[185, "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell.call"]], "call() (lstmblockwrapper method)": [[185, "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper.call"]], "num_units() (lstmblockwrapper method)": [[185, "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper.num_units"]], "sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[185, "module-sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[186, "module-sparknlp.training._tf_graph_builders.tf2contrib.rnn"]], "stack_bidirectional_dynamic_rnn() (in module sparknlp.training._tf_graph_builders.tf2contrib.rnn)": [[186, "sparknlp.training._tf_graph_builders.tf2contrib.rnn.stack_bidirectional_dynamic_rnn"]], "stack_bidirectional_rnn() (in module sparknlp.training._tf_graph_builders.tf2contrib.rnn)": [[186, "sparknlp.training._tf_graph_builders.tf2contrib.rnn.stack_bidirectional_rnn"]], "attentioncellwrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper"]], "bidirectionalgridlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell"]], "cfncell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell"]], "compiledwrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CompiledWrapper"]], "conv1dlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv1DLSTMCell"]], "conv2dlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv2DLSTMCell"]], "conv3dlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv3DLSTMCell"]], "convlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.ConvLSTMCell"]], "coupledinputforgetgatelstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell"]], "glstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell"]], "gridlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell"]], "highwaywrapper (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.HighwayWrapper"]], "indrnncell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell"]], "indygrucell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell"]], "indylstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell"]], "intersectionrnncell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell"]], "layernormbasiclstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell"]], "layernormlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell"]], "minimalrnncell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell"]], "nascell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell"]], "ntmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NTMCell"]], "phasedlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell"]], "srucell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell"]], "timefreqlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell"]], "ugrnncell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell"]], "weightnormlstmcell (class in sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell"]], "call() (attentioncellwrapper method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper.call"]], "call() (bidirectionalgridlstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell.call"]], "call() (cfncell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell.call"]], "call() (coupledinputforgetgatelstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell.call"]], "call() (glstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell.call"]], "call() (gridlstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell.call"]], "call() (indrnncell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell.call"]], "call() (indygrucell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell.call"]], "call() (indylstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell.call"]], "call() (intersectionrnncell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell.call"]], "call() (layernormbasiclstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell.call"]], "call() (layernormlstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell.call"]], "call() (minimalrnncell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell.call"]], "call() (nascell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell.call"]], "call() (phasedlstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell.call"]], "call() (srucell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell.call"]], "call() (timefreqlstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell.call"]], "call() (ugrnncell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell.call"]], "call() (weightnormlstmcell method)": [[187, "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell.call"]], "sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[187, "module-sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"]], "nertfgraphbuilder (class in sparknlp.training._tf_graph_builders_1x.graph_builders)": [[188, "sparknlp.training._tf_graph_builders_1x.graph_builders.NerTFGraphBuilder"]], "tfgraphbuilder (class in sparknlp.training._tf_graph_builders_1x.graph_builders)": [[188, "sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilder"]], "tfgraphbuilderfactory (class in sparknlp.training._tf_graph_builders_1x.graph_builders)": [[188, "sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory"]], "sparknlp.training._tf_graph_builders_1x.graph_builders": [[188, "module-sparknlp.training._tf_graph_builders_1x.graph_builders"]], "sparknlp.training._tf_graph_builders_1x": [[189, "module-sparknlp.training._tf_graph_builders_1x"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph": [[190, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder": [[191, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"]], "sparknlp.training._tf_graph_builders_1x.ner_dl": [[192, "module-sparknlp.training._tf_graph_builders_1x.ner_dl"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model": [[193, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver": [[194, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"]], "sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper": [[195, "module-sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"]], "conll (class in sparknlp.training.conll)": [[196, "sparknlp.training.conll.CoNLL"]], "readdataset() (conll method)": [[196, "sparknlp.training.conll.CoNLL.readDataset"]], "sparknlp.training.conll": [[196, "module-sparknlp.training.conll"]], "conllu (class in sparknlp.training.conllu)": [[197, "sparknlp.training.conllu.CoNLLU"]], "readdataset() (conllu method)": [[197, "sparknlp.training.conllu.CoNLLU.readDataset"]], "sparknlp.training.conllu": [[197, "module-sparknlp.training.conllu"]], "sparknlp.training": [[198, "module-sparknlp.training"]], "pos (class in sparknlp.training.pos)": [[199, "sparknlp.training.pos.POS"]], "readdataset() (pos method)": [[199, "sparknlp.training.pos.POS.readDataset"]], "sparknlp.training.pos": [[199, "module-sparknlp.training.pos"]], "pubtator (class in sparknlp.training.pub_tator)": [[200, "sparknlp.training.pub_tator.PubTator"]], "readdataset() (pubtator method)": [[200, "sparknlp.training.pub_tator.PubTator.readDataset"]], "sparknlp.training.pub_tator": [[200, "module-sparknlp.training.pub_tator"]], "sparknlp.training.tfgraphs": [[201, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[202, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[203, "module-sparknlp.util"]]}})