Search.setIndex({"docnames": ["_templates/_autoapi/base/base", "_templates/_autoapi/index", "_templates/_autoapi/python/attribute", "_templates/_autoapi/python/class", "_templates/_autoapi/python/data", "_templates/_autoapi/python/exception", "_templates/_autoapi/python/function", "_templates/_autoapi/python/method", "_templates/_autoapi/python/module", "_templates/_autoapi/python/package", "getting_started/index", "index", "reference/autosummary/python/sparknlp/annotation/index", "reference/autosummary/python/sparknlp/annotation_audio/index", "reference/autosummary/python/sparknlp/annotation_image/index", "reference/autosummary/python/sparknlp/annotator/audio/index", "reference/autosummary/python/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/python/sparknlp/annotator/chunker/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/coref/index", "reference/autosummary/python/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/python/sparknlp/annotator/cv/index", "reference/autosummary/python/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/python/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/python/sparknlp/annotator/dependency/index", "reference/autosummary/python/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/python/sparknlp/annotator/document_normalizer/index", "reference/autosummary/python/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/python/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/python/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/python/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/python/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/python/sparknlp/annotator/er/index", "reference/autosummary/python/sparknlp/annotator/graph_extraction/index", "reference/autosummary/python/sparknlp/annotator/index", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/python/sparknlp/annotator/ld_dl/index", "reference/autosummary/python/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/python/sparknlp/annotator/lemmatizer/index", "reference/autosummary/python/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/python/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/python/sparknlp/annotator/ner/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/python/sparknlp/annotator/normalizer/index", "reference/autosummary/python/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/python/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/python/sparknlp/annotator/param/index", "reference/autosummary/python/sparknlp/annotator/pos/index", "reference/autosummary/python/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/python/sparknlp/annotator/sentence/index", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/python/sparknlp/annotator/sentiment/index", "reference/autosummary/python/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/python/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/python/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/python/sparknlp/annotator/spell_check/index", "reference/autosummary/python/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/python/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/python/sparknlp/annotator/stemmer/index", "reference/autosummary/python/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/python/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/python/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/python/sparknlp/annotator/token/index", "reference/autosummary/python/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/python/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/python/sparknlp/annotator/token/token2_chunk/index", "reference/autosummary/python/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/python/sparknlp/annotator/ws/index", "reference/autosummary/python/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/python/sparknlp/base/audio_assembler/index", "reference/autosummary/python/sparknlp/base/chunk2_doc/index", "reference/autosummary/python/sparknlp/base/doc2_chunk/index", "reference/autosummary/python/sparknlp/base/document_assembler/index", "reference/autosummary/python/sparknlp/base/embeddings_finisher/index", "reference/autosummary/python/sparknlp/base/finisher/index", "reference/autosummary/python/sparknlp/base/graph_finisher/index", "reference/autosummary/python/sparknlp/base/has_recursive_fit/index", "reference/autosummary/python/sparknlp/base/has_recursive_transform/index", "reference/autosummary/python/sparknlp/base/image_assembler/index", "reference/autosummary/python/sparknlp/base/index", "reference/autosummary/python/sparknlp/base/light_pipeline/index", "reference/autosummary/python/sparknlp/base/multi_document_assembler/index", "reference/autosummary/python/sparknlp/base/recursive_pipeline/index", "reference/autosummary/python/sparknlp/base/table_assembler/index", "reference/autosummary/python/sparknlp/base/token_assembler/index", "reference/autosummary/python/sparknlp/common/annotator_approach/index", "reference/autosummary/python/sparknlp/common/annotator_model/index", "reference/autosummary/python/sparknlp/common/annotator_properties/index", "reference/autosummary/python/sparknlp/common/annotator_type/index", "reference/autosummary/python/sparknlp/common/coverage_result/index", "reference/autosummary/python/sparknlp/common/index", "reference/autosummary/python/sparknlp/common/properties/index", "reference/autosummary/python/sparknlp/common/read_as/index", "reference/autosummary/python/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/python/sparknlp/common/storage/index", "reference/autosummary/python/sparknlp/common/utils/index", "reference/autosummary/python/sparknlp/functions/index", "reference/autosummary/python/sparknlp/index", "reference/autosummary/python/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/python/sparknlp/internal/annotator_transformer/index", "reference/autosummary/python/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/python/sparknlp/internal/index", "reference/autosummary/python/sparknlp/internal/params_getters_setters/index", "reference/autosummary/python/sparknlp/internal/recursive/index", "reference/autosummary/python/sparknlp/logging/comet/index", "reference/autosummary/python/sparknlp/logging/index", "reference/autosummary/python/sparknlp/pretrained/index", "reference/autosummary/python/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/python/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/python/sparknlp/pretrained/utils/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/graph_builders/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/create_graph/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/dataset_encoder/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model_saver/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/sentence_grouper/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/core_rnn_cell/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/fused_rnn_cell/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/gru_ops/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/lstm_ops/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn_cell/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/graph_builders/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/create_graph/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/dataset_encoder/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model_saver/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/sentence_grouper/index", "reference/autosummary/python/sparknlp/training/conll/index", "reference/autosummary/python/sparknlp/training/conllu/index", "reference/autosummary/python/sparknlp/training/index", "reference/autosummary/python/sparknlp/training/pos/index", "reference/autosummary/python/sparknlp/training/pub_tator/index", "reference/autosummary/python/sparknlp/training/tfgraphs/index", "reference/autosummary/python/sparknlp/upload_to_hub/index", "reference/autosummary/python/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["_templates/_autoapi/base/base.rst", "_templates/_autoapi/index.rst", "_templates/_autoapi/python/attribute.rst", "_templates/_autoapi/python/class.rst", "_templates/_autoapi/python/data.rst", "_templates/_autoapi/python/exception.rst", "_templates/_autoapi/python/function.rst", "_templates/_autoapi/python/method.rst", "_templates/_autoapi/python/module.rst", "_templates/_autoapi/python/package.rst", "getting_started/index.rst", "index.rst", "reference/autosummary/python/sparknlp/annotation/index.rst", "reference/autosummary/python/sparknlp/annotation_audio/index.rst", "reference/autosummary/python/sparknlp/annotation_image/index.rst", "reference/autosummary/python/sparknlp/annotator/audio/index.rst", "reference/autosummary/python/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/python/sparknlp/annotator/chunker/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/coref/index.rst", "reference/autosummary/python/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/python/sparknlp/annotator/cv/index.rst", "reference/autosummary/python/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/python/sparknlp/annotator/dependency/index.rst", "reference/autosummary/python/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/python/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/python/sparknlp/annotator/er/index.rst", "reference/autosummary/python/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/python/sparknlp/annotator/index.rst", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/python/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/python/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/python/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/python/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/python/sparknlp/annotator/param/index.rst", "reference/autosummary/python/sparknlp/annotator/pos/index.rst", "reference/autosummary/python/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/python/sparknlp/annotator/sentence/index.rst", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/python/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/python/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/python/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/python/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/python/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/python/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/token/index.rst", "reference/autosummary/python/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/token/token2_chunk/index.rst", "reference/autosummary/python/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/ws/index.rst", "reference/autosummary/python/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/python/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/python/sparknlp/base/chunk2_doc/index.rst", "reference/autosummary/python/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/python/sparknlp/base/document_assembler/index.rst", "reference/autosummary/python/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/python/sparknlp/base/finisher/index.rst", "reference/autosummary/python/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/python/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/python/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/python/sparknlp/base/image_assembler/index.rst", "reference/autosummary/python/sparknlp/base/index.rst", "reference/autosummary/python/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/python/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/python/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/python/sparknlp/base/table_assembler/index.rst", "reference/autosummary/python/sparknlp/base/token_assembler/index.rst", "reference/autosummary/python/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/python/sparknlp/common/annotator_model/index.rst", "reference/autosummary/python/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/python/sparknlp/common/annotator_type/index.rst", "reference/autosummary/python/sparknlp/common/coverage_result/index.rst", "reference/autosummary/python/sparknlp/common/index.rst", "reference/autosummary/python/sparknlp/common/properties/index.rst", "reference/autosummary/python/sparknlp/common/read_as/index.rst", "reference/autosummary/python/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/python/sparknlp/common/storage/index.rst", "reference/autosummary/python/sparknlp/common/utils/index.rst", "reference/autosummary/python/sparknlp/functions/index.rst", "reference/autosummary/python/sparknlp/index.rst", "reference/autosummary/python/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/python/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/python/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/python/sparknlp/internal/index.rst", "reference/autosummary/python/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/python/sparknlp/internal/recursive/index.rst", "reference/autosummary/python/sparknlp/logging/comet/index.rst", "reference/autosummary/python/sparknlp/logging/index.rst", "reference/autosummary/python/sparknlp/pretrained/index.rst", "reference/autosummary/python/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/python/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/python/sparknlp/pretrained/utils/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/graph_builders/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/create_graph/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/dataset_encoder/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model_saver/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/sentence_grouper/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/core_rnn_cell/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/fused_rnn_cell/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/gru_ops/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/lstm_ops/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn_cell/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/graph_builders/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/create_graph/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/dataset_encoder/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model_saver/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/sentence_grouper/index.rst", "reference/autosummary/python/sparknlp/training/conll/index.rst", "reference/autosummary/python/sparknlp/training/conllu/index.rst", "reference/autosummary/python/sparknlp/training/index.rst", "reference/autosummary/python/sparknlp/training/pos/index.rst", "reference/autosummary/python/sparknlp/training/pub_tator/index.rst", "reference/autosummary/python/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/python/sparknlp/upload_to_hub/index.rst", "reference/autosummary/python/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["&lt;no title&gt;", "API Reference", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_type</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.create_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.rnn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], "thi": [1, 10, 11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 123, 124, 125, 127, 128, 131, 132, 134, 137, 139, 140, 141, 142, 143, 145, 146, 150, 156, 157, 161, 162, 163, 166, 169, 177, 178, 179, 180, 181, 182, 183, 184, 195, 200, 201, 204, 205, 206, 208, 209, 210], "page": [1, 11, 54, 109, 166, 200, 208, 210], "list": [1, 3, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 80, 82, 85, 88, 92, 93, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 118, 122, 125, 132, 133, 139, 140, 146, 155, 162, 163, 166, 181, 182, 200, 205], "an": [1, 12, 16, 17, 25, 36, 40, 41, 50, 51, 54, 58, 60, 63, 65, 74, 75, 80, 82, 84, 85, 87, 88, 89, 90, 94, 95, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 120, 125, 127, 130, 131, 132, 133, 134, 139, 140, 143, 146, 150, 154, 155, 157, 161, 162, 163, 177, 178, 181, 182, 183, 192, 193, 195, 196, 200, 202, 204, 205, 206, 208, 209], "overview": [1, 200, 208], "all": [1, 8, 10, 12, 13, 14, 19, 22, 27, 30, 34, 38, 41, 43, 45, 54, 55, 56, 57, 58, 68, 71, 74, 75, 78, 82, 85, 95, 97, 109, 112, 113, 118, 123, 127, 132, 134, 163, 169, 180, 183, 184, 200, 205, 210], "spark": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 149, 151, 155, 156, 158, 159, 160, 163, 166, 169, 184, 192, 193, 195, 196, 200, 202, 203, 204, 205, 207, 208, 209, 211], "nlp": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 129, 130, 131, 132, 133, 137, 138, 139, 140, 141, 142, 143, 149, 156, 160, 163, 166, 169, 184, 192, 193, 195, 196, 200, 202, 203, 204, 205, 206, 207, 208, 209, 211], "modul": [1, 8, 9, 11, 32, 52, 64, 76, 78, 79, 81, 86, 91, 100, 101, 103, 106, 110, 114, 121, 126, 138, 149, 160, 165, 180, 194], "class": [1, 3, 5, 8, 78, 149, 153, 160, 167, 194, 200, 201, 209, 211], "function": [1, 6, 8, 11, 63, 71, 112, 132, 180, 200, 208], "method": [1, 3, 7, 25, 36, 40, 55, 61, 62, 70, 74, 80, 95, 169, 181, 184, 200], "extend": [2, 5, 9, 16, 17, 25, 36, 40, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 68, 69, 71, 72, 74, 80, 82, 83, 85, 87, 88, 89, 90, 94, 95, 97, 99, 102, 104, 105, 107, 108, 111, 112, 113, 115, 117, 118, 122, 125, 127, 129, 130, 131, 132, 133, 140, 143, 166], "python": [2, 5, 9, 11], "data": [2, 8, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 137, 139, 140, 141, 142, 143, 155, 163, 166, 181, 182, 183, 192, 193, 194, 195, 196, 202, 204, 205, 209, 210, 211], "rst": [2, 5, 8, 9], "obj": [3, 4, 6, 7, 8, 193], "displai": [3, 4, 6, 7, 8, 25, 36, 40, 99, 109, 163, 201], "py": [3, 4, 6, 7, 144, 145, 152, 158, 162], "type": [3, 4, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 155, 157, 166, 181, 182, 183, 195, 204, 205, 208], "short_nam": [3, 6, 7, 8], "arg": [3, 6, 7, 141, 159, 181, 182, 183], "endif": [3, 4, 6, 7, 8], "return_annot": [3, 6, 7], "overload": [3, 6, 7], "length": [3, 7, 8, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 74, 90, 97, 104, 105, 109, 111, 112, 113, 123, 125, 181, 182], "endfor": [3, 6, 7, 8], "base": [3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 144, 145, 146, 149, 152, 156, 158, 162, 163, 169, 179, 181, 183, 184, 201, 205, 206, 209], "show": [3, 4, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 155, 192, 193, 195, 196, 201, 204, 205, 206, 210], "inherit": [3, 145, 162], "autoapi_opt": [3, 8], "link_obj": 3, "loop": [3, 178], "last": [3, 12, 85, 87, 120, 209], "diagram": 3, "object": [3, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 117, 118, 127, 151, 158, 159, 163, 178, 204, 205], "autoapi": [3, 8], "full_nam": 3, "part": [3, 17, 58, 80, 83, 101, 102, 117, 127, 130, 183, 195, 211], "privat": [3, 66, 67, 157], "member": [3, 102, 166], "docstr": [3, 4, 6, 7, 8], "indent": [3, 4, 6, 7, 8], "set": [3, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 145, 146, 150, 154, 156, 161, 162, 163, 183, 192, 201, 205, 208, 209], "visible_class": [3, 8], "selectattr": [3, 8], "els": [3, 4, 6, 7, 8, 107], "rejectattr": [3, 8], "klass": [3, 8], "render": [3, 8], "visible_attribut": [3, 8], "attribut": [3, 8, 163], "visible_method": 3, "name": [4, 8, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 89, 91, 92, 94, 95, 98, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 146, 155, 161, 163, 166, 169, 179, 181, 183, 184, 192, 195, 201, 205], "valu": [4, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 80, 82, 83, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 108, 109, 111, 112, 113, 115, 118, 119, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 150, 151, 161, 163, 181, 182, 201, 211], "i": [4, 6, 7, 8, 10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 154, 155, 156, 162, 163, 178, 179, 180, 181, 182, 183, 192, 195, 196, 201, 202, 204, 205, 206, 208, 209, 210, 211], "none": [4, 6, 7, 8, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 140, 142, 145, 162, 163, 166, 177, 179, 181, 182, 183, 206], "annot": [4, 11, 13, 14, 128, 129, 130, 131, 132, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 154, 155, 156, 157, 158, 160, 162, 163, 166, 168, 169, 184, 195, 201, 202, 207, 208, 209, 210, 211], "string": [4, 12, 25, 36, 40, 48, 51, 54, 75, 88, 90, 96, 97, 105, 112, 116, 118, 122, 130, 131, 133, 137, 139, 140, 183, 209], "splitlin": 4, "count": [4, 41, 113], "multilin": 4, "width": [4, 14, 137], "8": [4, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 51, 53, 54, 55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74, 85, 90, 95, 96, 99, 109, 113, 124, 183, 192], "truncat": [4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 71, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 133, 134, 140, 142, 143, 155, 195, 204, 205, 206], "100": [4, 25, 36, 41, 50, 62, 70, 72, 80, 105, 142], "sphinx_vers": [6, 7], "properti": [6, 7, 55, 135, 136, 146, 149, 156, 181, 182], "method_typ": 7, "orphan": 8, "nest": [8, 182], "pars": [8, 17, 51, 52, 53, 58, 75, 83, 85, 87, 113, 115, 116, 139, 142, 166, 195], "block": [8, 179, 181], "subpackag": 8, "visible_subpackag": 8, "toctre": 8, "titlesonli": 8, "maxdepth": 8, "index": [8, 12, 80, 84, 123, 156, 192], "endblock": 8, "submodul": 8, "visible_submodul": 8, "content": [8, 204, 210], "visible_children": 8, "children": 8, "elif": 8, "equalto": 8, "packag": [8, 10, 55, 60, 163, 202, 203], "import": [8, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 137, 139, 140, 141, 142, 143, 155, 163, 166, 169, 184, 192, 193, 195, 196, 201, 204, 205, 208, 209, 210, 211], "titl": [8, 196, 211], "visible_funct": 8, "summari": [8, 109, 112], "scope": [8, 108, 181, 182, 183], "id": [8, 36, 54, 72, 75, 109, 111, 112, 129, 130, 131, 133, 140, 143, 163, 183], "obj_item": 8, "0": [8, 10, 16, 17, 25, 36, 40, 48, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 82, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 109, 112, 113, 116, 119, 124, 125, 127, 129, 131, 132, 133, 139, 140, 142, 143, 146, 150, 155, 156, 159, 161, 162, 163, 166, 169, 179, 181, 183, 184, 193, 195, 196, 201, 204, 205, 210, 211], "can": [10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 88, 93, 94, 95, 96, 102, 104, 105, 107, 109, 111, 112, 113, 115, 116, 118, 124, 127, 131, 132, 140, 141, 142, 154, 163, 166, 182, 192, 193, 195, 201, 203, 205, 206, 208, 209, 210, 211], "quick": [10, 201, 206], "refer": [10, 11, 48, 50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 80, 104, 105, 108, 109, 111, 112, 113, 115, 116, 130, 131, 140, 205, 207, 208], "how": [10, 11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 53, 55, 56, 58, 59, 60, 61, 63, 65, 66, 68, 72, 74, 75, 77, 82, 83, 84, 88, 89, 93, 94, 95, 97, 99, 104, 107, 115, 116, 123, 125, 127, 131, 134, 140, 151, 154, 156, 192, 193, 201, 205, 210], "up": [10, 11, 25, 36, 62, 65, 68, 70, 80, 109, 112, 156, 201, 205, 208, 209], "your": [10, 11, 25, 36, 40, 51, 61, 62, 66, 68, 70, 83, 84, 88, 89, 94, 95, 97, 102, 107, 108, 113, 115, 120, 122, 127, 132, 177, 203, 205, 208, 209, 211], "environ": [10, 202], "pypi": 10, "pip": 10, "anaconda": 10, "c": [10, 58, 62, 70, 80, 111, 179, 183], "johnsnowlab": [10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 142, 156], "load": [10, 11, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 80, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 137, 166, 205, 208], "shell": 10, "com": [10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 142, 156, 183], "nlp_2": [10, 156], "12": [10, 55, 72, 73, 74, 80, 85, 87, 93, 102, 113, 124, 139, 155, 156, 166, 169, 184, 195, 204], "pyspark": [10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 137, 139, 140, 142, 143, 155, 156, 159, 162, 163, 166, 192, 193, 195, 196, 205, 206], "submit": [10, 163, 183, 201], "extern": [10, 80, 83, 88, 89, 95, 119, 141, 154, 192, 193, 195, 196], "jar": [10, 156], "after": [10, 51, 53, 62, 66, 67, 70, 85, 87, 93, 122, 143, 163, 183, 204, 205], "compil": 10, "build": [10, 60, 61, 66, 67, 77, 80, 84, 109, 163, 169, 179, 183, 184, 201], "sbt": 10, "assembli": 10, "built": [10, 25, 36, 140, 183], "top": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 55, 80, 109, 112, 140], "apach": [10, 140, 156], "x": [10, 36, 155, 179, 180, 183, 192, 211], "For": [10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 129, 130, 131, 132, 133, 140, 143, 163, 166, 178, 183, 196, 201, 202, 204, 205, 206, 207, 208, 209], "you": [10, 51, 53, 59, 61, 66, 68, 77, 85, 96, 132, 134, 139, 163, 169, 184, 195, 201, 203, 205, 206, 209, 210, 211], "need": [10, 16, 17, 51, 53, 61, 66, 71, 75, 77, 80, 85, 88, 94, 95, 97, 99, 102, 105, 108, 109, 113, 115, 116, 123, 125, 128, 137, 139, 163, 177, 182, 183, 192, 193, 195, 201, 203, 205, 206, 209, 211], "java": [10, 82, 144, 145, 152, 158, 159, 162], "ar": [10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 53, 55, 56, 58, 60, 61, 63, 65, 66, 69, 71, 72, 73, 74, 75, 77, 80, 82, 83, 85, 88, 90, 93, 95, 96, 97, 102, 104, 105, 108, 109, 111, 112, 113, 117, 119, 127, 129, 132, 139, 141, 142, 151, 155, 163, 178, 179, 180, 182, 183, 196, 201, 202, 203, 204, 205, 206, 209, 210, 211], "6": [10, 25, 40, 56, 57, 60, 63, 80, 84, 89, 90, 96, 102, 115, 124, 169, 183, 184, 193, 205], "7": [10, 40, 56, 57, 60, 85, 87, 102, 109, 129, 133, 195, 204], "It": [10, 25, 36, 40, 41, 54, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 75, 80, 90, 108, 111, 113, 115, 116, 122, 133, 139, 181, 183, 204, 209], "recommend": [10, 63, 74, 107, 108, 109, 111, 112], "have": [10, 25, 36, 40, 55, 58, 61, 66, 67, 71, 80, 88, 90, 94, 95, 96, 102, 104, 105, 109, 116, 124, 143, 158, 182, 183, 205, 206, 209], "basic": [10, 80, 104, 181, 183, 204], "knowledg": [10, 61, 80, 134], "framework": [10, 16, 111, 112], "work": [10, 61, 65, 82, 112, 120, 204, 206, 210], "befor": [10, 54, 71, 85, 87, 112, 115, 123, 127, 145, 162, 183, 201], "pleas": [10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 56, 57, 58, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 82, 83, 84, 85, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 127, 131, 140, 141, 202, 203, 207, 210], "document": [10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 139, 140, 142, 143, 163, 166, 192, 193, 195, 201, 205, 206, 208, 209, 210], "first": [10, 12, 60, 62, 63, 70, 72, 73, 80, 88, 94, 95, 96, 104, 112, 113, 118, 123, 132, 143, 182, 183, 201, 205, 206, 210], "let": [10, 61, 122, 205], "": [10, 11, 18, 21, 26, 29, 33, 37, 42, 54, 55, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 75, 80, 88, 95, 97, 108, 109, 111, 112, 113, 115, 116, 122, 123, 125, 127, 128, 133, 139, 144, 145, 152, 155, 158, 162, 163, 183, 201, 204, 205, 206, 209], "make": [10, 54, 58, 65, 72, 73, 80, 105, 108, 115, 207, 211], "sure": [10, 108], "version": [10, 54, 61, 98, 99, 119, 146, 150, 156, 161, 162, 166, 169, 205], "oracl": 10, "openjdk": 10, "0_292": 10, "creat": [10, 12, 13, 14, 25, 36, 40, 56, 57, 62, 66, 70, 71, 77, 95, 99, 102, 120, 127, 139, 141, 155, 169, 181, 182, 184, 192, 193, 195, 196, 205, 206, 209, 211], "new": [10, 12, 13, 14, 40, 48, 55, 56, 57, 60, 63, 65, 71, 74, 96, 98, 99, 109, 112, 113, 119, 129, 133, 146, 150, 161, 162, 183, 204, 205], "manag": [10, 80, 202], "depend": [10, 12, 48, 58, 68, 74, 75, 77, 78, 80, 82, 95, 111, 113, 156, 182, 183], "Then": [10, 25, 36, 94, 95, 143, 163, 205], "we": [10, 16, 25, 36, 50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 80, 94, 95, 97, 105, 109, 111, 112, 113, 115, 125, 139, 155, 181, 183, 201, 204, 205, 206, 209, 210, 211], "sparknlp": [10, 201, 204, 205, 206, 207, 209, 210, 211], "n": [10, 73, 80, 90, 93, 94, 95, 104, 105, 109, 112, 122, 139, 142, 155, 166, 183], "y": [10, 36, 183], "activ": [10, 19, 22, 30, 34, 38, 43, 45, 80, 177, 183], "jupyt": [10, 163, 201], "now": [10, 58, 105, 139, 206], "should": [10, 12, 13, 14, 17, 25, 36, 40, 62, 70, 72, 80, 82, 89, 90, 94, 95, 99, 104, 105, 111, 113, 123, 139, 145, 146, 158, 162, 166, 181, 183, 192, 193], "readi": [10, 25, 166, 205], "notebook": [10, 163, 201], "run": [10, 61, 80, 163, 177, 181, 182, 183, 202, 210], "also": [10, 25, 36, 40, 50, 54, 55, 63, 65, 71, 72, 73, 75, 77, 80, 85, 88, 93, 94, 95, 98, 99, 105, 108, 118, 139, 142, 146, 150, 161, 183, 201, 205, 206, 207, 208], "python3": 10, "sourc": [10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 166, 169, 177, 178, 179, 180, 181, 182, 183, 184, 192, 193, 195, 196, 202], "bin": 10, "A": [10, 16, 40, 48, 55, 66, 67, 71, 75, 80, 83, 84, 88, 89, 90, 97, 107, 109, 111, 112, 115, 116, 123, 125, 163, 178, 181, 182, 183, 195, 203, 205, 211], "retriev": [10, 71, 83, 115, 116, 117, 163, 166, 201, 205, 206], "If": [10, 19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 68, 71, 75, 82, 85, 87, 93, 94, 95, 97, 99, 104, 105, 109, 112, 113, 119, 156, 162, 163, 169, 181, 182, 183, 184, 201, 203, 205], "manual": [10, 204], "sparksess": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 84, 109, 111, 112, 156, 192, 193, 195, 196], "becaus": [10, 107, 145, 162, 182], "other": [10, 36, 58, 68, 69, 77, 80, 97, 107, 109, 112, 120, 122, 129, 132, 133, 140, 205], "configur": [10, 68, 125, 156, 169, 184], "includ": [10, 54, 56, 57, 62, 63, 70, 72, 73, 74, 77, 80, 85, 93, 94, 95, 109, 112, 113, 133, 163, 180, 196, 202, 204, 205, 206, 211], "them": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 56, 58, 60, 61, 65, 66, 72, 74, 75, 77, 80, 85, 88, 105, 113, 118, 127, 141, 143, 205, 206], "builder": [10, 119, 156], "appnam": [10, 156], "master": [10, 156], "local": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 80, 109, 111, 112, 118, 139, 156, 166, 209], "config": [10, 156, 202], "driver": [10, 156], "memori": [10, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 55, 63, 71, 156, 181, 182, 183], "16g": [10, 156], "maxresults": [10, 156], "kryoseri": [10, 156], "buffer": [10, 57, 71, 156], "max": [10, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74, 80, 116, 156], "2000m": [10, 156], "getorcr": [10, 156], "main": [11, 75, 125, 204, 208, 211], "github": [11, 60, 66, 111, 166], "issu": 11, "workshop": [11, 17, 25, 36, 40, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 68, 69, 71, 72, 74, 80, 82, 83, 85, 87, 88, 89, 90, 94, 95, 97, 102, 104, 105, 107, 108, 111, 112, 113, 115, 117, 118, 122, 125, 127, 129, 130, 131, 132, 133, 140, 143, 163, 183, 201, 208], "model": [11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 122, 125, 127, 145, 156, 162, 163, 166, 169, 182, 183, 184, 201, 202, 204, 208, 210, 211], "hub": [11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 82, 83, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 118, 127], "welcom": [11, 16], "contain": [11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 141, 142, 143, 144, 145, 146, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 161, 162, 163, 164, 166, 167, 168, 181, 182, 183, 192, 193, 195, 196, 199, 201, 204, 205], "inform": [11, 51, 53, 71, 72, 80, 85, 93, 113, 131, 140, 182, 183, 196, 201, 202, 203, 204, 205, 211], "us": [11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 99, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 118, 119, 123, 124, 125, 127, 129, 130, 131, 132, 133, 139, 140, 141, 142, 143, 155, 156, 163, 166, 177, 178, 179, 181, 182, 183, 192, 193, 195, 196, 202, 203, 204, 205, 206, 208], "librari": [11, 50, 82, 130, 131, 132, 140, 143, 210], "exampl": [11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 141, 142, 143, 155, 163, 166, 169, 178, 183, 184, 192, 193, 195, 196, 201, 204, 205, 206, 208, 209, 210, 211], "get": [11, 25, 36, 80, 92, 102, 113, 119, 125, 127, 139, 146, 150, 161, 201, 205, 210, 211], "start": [11, 18, 21, 26, 29, 33, 37, 42, 65, 77, 80, 94, 95, 105, 130, 156, 163, 177, 181, 201, 204, 206, 209, 210], "cheat": 11, "sheet": [11, 54], "requir": [11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 53, 55, 57, 60, 63, 69, 72, 73, 80, 95, 97, 108, 113, 124, 127, 130, 132, 143, 181, 182, 183, 204, 205, 206], "instal": [11, 163, 203], "session": [11, 156, 192, 193, 195, 196], "from": [11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 98, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 141, 142, 143, 145, 155, 156, 159, 162, 163, 166, 169, 177, 179, 181, 182, 183, 184, 192, 193, 195, 196, 201, 204, 205, 206, 209, 210, 211], "user": [11, 93, 94, 125, 141, 156, 163, 201], "guid": [11, 202], "own": [11, 25, 36, 40, 51, 62, 70, 83, 84, 88, 89, 94, 95, 97, 102, 107, 108, 113, 115, 120, 122, 127, 183, 208, 209, 211], "pipelin": [11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 137, 139, 140, 141, 142, 143, 156, 162, 163, 165, 166, 168, 202, 204, 205, 208], "pretrain": [11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 82, 83, 84, 85, 88, 89, 94, 95, 96, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 129, 132, 133, 139, 155, 156, 163, 201, 204, 208], "dataset": [11, 25, 36, 40, 51, 53, 58, 62, 65, 66, 67, 70, 71, 80, 82, 94, 95, 99, 105, 109, 113, 127, 162, 166, 192, 193, 195, 196, 208], "train": [11, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 69, 70, 72, 73, 74, 80, 82, 83, 84, 88, 89, 92, 94, 95, 97, 98, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 120, 122, 127, 130, 139, 156, 163, 166, 201, 205, 206, 208, 209], "light": [11, 61, 74, 80, 139, 208, 210], "helper": [11, 102, 127, 134, 155, 181, 182, 195, 196, 208, 211], "third": [11, 104, 118, 164], "parti": [11, 164], "project": [11, 80, 111, 163, 177, 183, 202], "log": [11, 25, 36, 40, 95, 99, 105, 109, 156], "api": [11, 201, 205, 208], "format": [12, 13, 14, 50, 51, 53, 75, 77, 83, 84, 85, 87, 88, 89, 94, 95, 97, 99, 107, 112, 115, 116, 125, 128, 131, 133, 134, 137, 140, 142, 182, 192, 193, 195, 196, 202, 211], "annotatortyp": [12, 13, 14, 59, 90, 130, 131, 137, 140, 204], "begin": [12, 48, 93, 109, 122, 125, 130, 131, 140, 155, 181, 182, 183, 204], "end": [12, 18, 21, 26, 29, 33, 37, 42, 48, 95, 105, 122, 125, 131, 140, 155, 163, 182, 192, 201, 204, 206], "result": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 155, 156, 163, 166, 183, 192, 193, 201, 202, 204, 205, 206, 209, 210], "metadata": [12, 13, 14, 41, 48, 80, 89, 94, 95, 102, 131, 133, 137, 139, 140, 155, 163, 204, 206], "embed": [12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 77, 78, 94, 95, 96, 131, 132, 133, 139, 140, 150, 155, 156, 162, 166, 169, 177, 184, 204], "repres": [12, 13, 14, 51, 53, 55, 60, 74, 75, 77, 84, 89, 90, 125, 163, 166, 178, 183, 205], "output": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 155, 156, 163, 177, 181, 182, 183, 195, 201, 204, 205, 206], "detail": [12, 13, 14, 72, 73, 80, 109, 112, 183], "paramet": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 150, 154, 155, 156, 161, 162, 163, 166, 169, 182, 184, 192, 193, 195, 196], "annotator_typ": [12, 13, 14], "str": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 154, 155, 156, 161, 163, 166, 169, 184, 192, 193, 195, 196], "The": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 123, 125, 127, 131, 133, 139, 140, 142, 155, 156, 163, 166, 169, 179, 180, 181, 182, 183, 184, 192, 193, 195, 196, 201, 204, 205, 206, 208, 209, 211], "possibl": [12, 13, 14, 59, 61, 72, 73, 75, 104, 113, 116, 131, 140, 151, 163, 201], "token": [12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 80, 83, 84, 89, 90, 92, 93, 94, 95, 96, 97, 99, 102, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 127, 129, 130, 132, 139, 141, 143, 156, 166, 169, 184, 192, 196, 205, 209, 210], "wordpiec": 12, "word_embed": [12, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 72, 74, 78, 94, 95, 99], "sentence_embed": [12, 25, 36, 40, 57, 62, 64, 67, 69, 73, 78, 163, 201, 205], "categori": [12, 19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 50, 163, 201, 205], "date": [12, 85, 87, 88], "entiti": [12, 20, 23, 24, 28, 31, 35, 39, 44, 46, 48, 58, 75, 76, 77, 84, 89, 91, 92, 93, 94, 95, 96, 120, 124, 129, 133, 139, 166], "sentiment": [12, 25, 36, 40, 63, 74, 78, 112, 156, 205, 206], "po": [12, 17, 19, 22, 27, 30, 34, 38, 43, 45, 51, 53, 77, 78, 94, 95, 122, 127, 139, 155, 156, 166, 192, 194, 204, 208, 209, 210], "chunk": [12, 17, 18, 21, 26, 29, 33, 37, 42, 59, 62, 70, 75, 80, 84, 88, 89, 90, 93, 120, 124, 129, 130, 133, 155, 163, 196, 201, 211], "named_ent": [12, 20, 23, 24, 28, 31, 35, 39, 44, 46, 77, 93, 94, 95, 96, 99, 139, 166], "negex": 12, "labeled_depend": [12, 53], "languag": [12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 80, 81, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 130, 140, 143, 205], "keyword": [12, 79, 80, 107, 183], "dummi": [12, 54], "int": [12, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 77, 80, 82, 85, 90, 92, 94, 95, 97, 98, 99, 102, 104, 105, 108, 109, 111, 112, 113, 116, 119, 123, 125, 127, 150, 156, 163, 183, 192], "charact": [12, 54, 63, 65, 75, 82, 88, 90, 97, 104, 105, 113, 115, 116, 123, 125, 127, 133], "under": [12, 61, 74, 80, 156], "dict": [12, 13, 14, 51, 53, 75, 83, 84, 88, 89, 94, 96, 97, 99, 107, 113, 115, 116, 125, 139, 154, 162, 163, 166, 169, 184], "associ": [12, 13, 14, 36, 69, 75, 88, 93, 163], "vector": [12, 36, 56, 57, 59, 60, 62, 63, 69, 70, 71, 132, 133, 140, 181, 182, 183, 204], "where": [12, 36, 60, 63, 75, 80, 83, 84, 88, 89, 90, 102, 105, 107, 109, 112, 115, 116, 127, 130, 169, 182, 183, 184, 195], "applic": [12, 50, 80, 163, 164, 201, 203], "copi": [12, 13, 14], "differ": [12, 13, 14, 51, 53, 63, 66, 67, 72, 74, 80, 85, 104, 105, 113, 125, 139, 163, 169, 179, 183, 184, 209], "return": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 80, 82, 83, 84, 89, 90, 92, 94, 95, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 117, 118, 122, 125, 127, 130, 139, 154, 155, 156, 157, 162, 166, 169, 181, 182, 183, 184, 192, 193, 195, 196], "newli": [12, 13, 14], "static": [12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 169, 183, 184, 205], "datatyp": [12, 155], "structtyp": 12, "schema": [12, 93, 163, 201], "look": [12, 95, 115, 204], "like": [12, 18, 21, 25, 26, 29, 33, 37, 42, 48, 54, 55, 59, 61, 65, 68, 74, 77, 80, 88, 93, 105, 108, 109, 113, 125, 127, 163, 201, 203, 204], "struct": [12, 131, 137, 140], "containsnul": [12, 36, 128, 131, 137, 140], "true": [12, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 50, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 82, 84, 85, 87, 89, 93, 95, 97, 104, 105, 113, 115, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 140, 142, 163, 169, 178, 182, 183, 184, 192, 193, 196, 201, 205, 206], "nullabl": [12, 36, 128, 131, 137, 140], "fals": [12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 139, 140, 142, 143, 155, 156, 163, 166, 178, 181, 182, 183, 192, 193, 195, 201, 204, 205, 206, 211], "integ": [12, 131, 137, 140], "map": [12, 17, 36, 71, 75, 98, 99, 102, 113, 131, 137, 140, 146, 150, 155, 161, 162, 183, 204], "kei": [12, 51, 53, 66, 67, 72, 73, 83, 131, 137, 139, 140, 163, 166, 201], "valuecontainsnul": [12, 131, 137, 140], "arrai": [12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 72, 73, 74, 82, 83, 90, 95, 98, 102, 104, 105, 109, 111, 112, 113, 120, 122, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 155, 206, 209], "element": [12, 36, 90, 128, 131, 137, 140, 181, 182], "float": [12, 13, 16, 25, 36, 40, 82, 94, 95, 98, 99, 105, 109, 112, 113, 127, 128, 131, 132, 139, 140], "sql": [12, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 84, 109, 111, 112, 139, 155, 162, 166, 192, 193, 195, 196], "arraytyp": [12, 130, 155], "fromrow": 12, "row": [12, 41, 71, 104, 105, 108, 131, 140, 142, 155, 192], "column": [12, 25, 36, 40, 54, 71, 83, 92, 94, 95, 98, 99, 102, 108, 119, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 143, 146, 155, 166, 183, 192, 195, 205], "torow": 12, "transform": [12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 139, 140, 142, 143, 155, 158, 162, 163, 166, 201, 204, 205, 206, 209, 210, 211], "annotationaudio": 13, "audio": [13, 128, 163], "alreadi": [13, 77, 80, 94, 95, 96, 124, 125, 139, 166, 183, 209], "process": [13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 70, 72, 73, 74, 77, 80, 82, 93, 94, 95, 99, 105, 109, 112, 128, 129, 130, 131, 132, 133, 137, 140, 141, 143, 163, 183, 201, 204, 205, 206, 207], "file": [13, 16, 25, 36, 40, 51, 53, 54, 69, 71, 75, 83, 84, 88, 89, 94, 95, 97, 99, 105, 107, 113, 115, 116, 119, 125, 128, 142, 151, 156, 163, 169, 180, 184, 192, 193, 195, 196, 201, 211], "byte": [13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 98, 109, 111, 112, 113, 163], "annotationimag": [14, 139, 166], "origin": [14, 55, 62, 65, 66, 70, 93, 105, 137, 180, 183], "height": [14, 137], "nchannel": [14, 137], "mode": [14, 25, 36, 40, 95, 99, 115, 131, 137, 140, 163], "imag": [14, 50, 137, 139, 166], "uri": 14, "pixel": 14, "number": [14, 25, 36, 40, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 90, 92, 94, 95, 98, 102, 104, 105, 109, 112, 113, 119, 127, 181, 182, 183, 192, 193], "color": 14, "channel": [14, 113], "opencv": 14, "wav2vec2_for_ctc": 15, "concern": [16, 19, 50, 55], "wav2vec2forctc": 16, "classnam": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 142, 144, 145, 152, 158], "java_model": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 136, 142, 145, 162], "wav2vec2": 16, "head": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 55, 74, 93, 94, 95, 139, 155, 166], "connectionist": 16, "tempor": [16, 182], "classif": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 69, 108, 112, 205], "ctc": 16, "wa": [16, 19, 20, 22, 23, 25, 27, 28, 30, 31, 34, 35, 38, 39, 40, 43, 44, 45, 46, 54, 58, 60, 61, 65, 66, 67, 71, 72, 73, 80, 108, 109, 113, 166, 183, 205, 206], "propos": [16, 55, 58, 60, 61, 66, 67, 72, 73, 74], "wav2vec": 16, "self": [16, 55, 65, 111, 181, 183], "supervis": [16, 55, 63, 69, 80, 109], "learn": [16, 25, 36, 40, 55, 61, 62, 63, 66, 67, 69, 70, 72, 73, 74, 80, 94, 95, 98, 105, 109, 112, 113, 163, 183, 203], "speech": [16, 17, 58, 101, 102, 127, 195, 211], "represent": [16, 55, 56, 57, 61, 62, 63, 70, 71, 72, 73, 74, 93, 112, 140, 142, 154], "alexei": 16, "baevski": 16, "henri": 16, "zhou": 16, "abdelrahman": 16, "moham": 16, "michael": [16, 120], "auli": 16, "take": [16, 41, 58, 77, 89, 98, 99, 115, 118, 125, 141, 146, 150, 161, 182, 192, 204, 205, 209, 210], "transcrib": 16, "text": [16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 140, 142, 143, 151, 154, 155, 163, 192, 193, 195, 196, 201, 204, 205, 206, 210, 211], "provid": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 82, 83, 84, 85, 87, 88, 89, 94, 95, 97, 98, 99, 102, 105, 107, 109, 111, 112, 113, 115, 116, 127, 139, 146, 150, 155, 157, 161, 166, 181, 182, 183, 206], "pre": [16, 25, 36, 40, 50, 56, 57, 60, 61, 63, 69, 95, 99, 112, 129, 130, 131, 133, 140, 143, 193, 205], "note": [16, 25, 36, 40, 55, 61, 63, 66, 68, 71, 72, 74, 80, 95, 109, 111, 112, 139, 156, 177, 210], "current": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 80, 84, 85, 87, 105, 109, 111, 112, 119, 139, 142, 146, 156, 183, 204, 205, 206], "support": [16, 25, 36, 55, 65, 80, 95, 97, 105, 118, 142, 156, 202], "appl": [16, 57, 67, 73], "silicon": 16, "processor": 16, "m1": [16, 156], "due": [16, 19, 22, 27, 30, 34, 38, 43, 45, 55, 65], "instruct": 16, "xla": [16, 183], "companion": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 118, 127, 159], "speechtotext": 16, "setinputcol": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 146, 163, 169, 184, 201, 205, 206], "audio_assembl": [16, 138, 156], "setoutputcol": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 146, 163, 169, 184, 201, 205, 206], "default": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 125, 127, 130, 131, 132, 133, 134, 139, 140, 142, 154, 155, 156, 163, 166, 181, 182, 183, 192, 193, 195, 196, 205], "asr_wav2vec2_base_960h": 16, "avail": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 78, 80, 82, 83, 85, 88, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 118, 127, 158, 166, 169, 180, 184, 201, 208], "see": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 129, 130, 131, 132, 133, 134, 140, 143, 163, 166, 183, 196, 201, 202, 203, 208, 210, 211], "To": [16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 55, 56, 58, 60, 61, 65, 66, 72, 74, 75, 80, 85, 88, 102, 104, 109, 112, 127, 134, 139, 141, 163, 183, 201, 209], "which": [16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 70, 72, 74, 77, 80, 85, 87, 88, 95, 97, 104, 105, 107, 109, 111, 112, 115, 123, 127, 132, 139, 155, 178, 182, 183, 192, 193, 205, 206], "compat": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 56, 58, 60, 61, 65, 66, 72, 74, 95, 132, 178, 181], "5669": [16, 50, 58], "more": [16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 54, 58, 61, 63, 68, 72, 73, 77, 80, 90, 93, 105, 109, 112, 115, 123, 125, 129, 130, 131, 132, 133, 140, 143, 163, 166, 177, 178, 181, 182, 196, 201, 202, 203, 205, 208, 211], "wav2vec2forctctestspec": 16, "input": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 155, 162, 166, 177, 178, 179, 181, 182, 183, 192, 193, 195, 196, 205, 206, 209, 211], "batchsiz": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 95, 111, 113], "size": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 77, 80, 95, 98, 109, 111, 112, 113, 115, 181, 182, 183, 204, 209, 210], "each": [16, 25, 36, 40, 60, 62, 68, 70, 71, 75, 77, 80, 83, 84, 85, 88, 89, 90, 92, 94, 95, 97, 99, 102, 104, 105, 107, 113, 115, 116, 123, 125, 131, 140, 155, 162, 181, 182, 183, 195, 206], "batch": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 95, 98, 111, 113, 177, 182, 183], "ml": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 137, 139, 140, 141, 142, 143, 163, 201, 205, 209], "audioassembl": [16, 128], "audio_cont": [16, 128], "setstag": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 130, 132, 142, 143, 205, 206], "processedaudiofloat": 16, "createdatafram": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 140, 142, 143, 155, 163, 201, 204, 205, 206, 210], "rawfloat": 16, "todf": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 137, 140, 142, 143, 155, 204, 205, 206, 210], "fit": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 130, 132, 139, 141, 142, 143, 162, 163, 182, 201, 205, 206, 209], "select": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 59, 61, 71, 77, 80, 82, 94, 95, 108, 109, 112, 113, 115, 116, 122, 127, 128, 131, 133, 134, 137, 140, 142, 143, 155, 163, 201, 206], "mister": 16, "quilter": 16, "THE": [16, 54], "apostl": 16, "OF": [16, 55], "midl": 16, "clase": 16, "AND": 16, "glad": 16, "TO": [16, 192, 211], "hi": [16, 105], "gospel": 16, "setconfigprotobyt": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 98, 109, 111, 112, 113], "b": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 84, 89, 93, 94, 95, 96, 98, 104, 109, 111, 112, 113, 139, 155, 166, 183, 192, 196, 211], "configproto": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 98, 109, 111, 112, 113], "tensorflow": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 80, 82, 95, 98, 109, 111, 112, 113, 169, 180, 182, 184], "serial": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 82, 95, 98, 109, 111, 112, 113, 156], "loadsavedmodel": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 109, 111, 112], "folder": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 95, 99, 105, 109, 111, 112, 116, 119, 192], "spark_sess": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 109, 111, 112], "save": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 95, 99, 105, 109, 111, 112, 156, 163, 169, 184, 201, 205], "restor": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127], "lang": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 166], "en": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 74, 77, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 166, 193, 211], "remote_loc": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 166], "download": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 82, 83, 84, 89, 94, 95, 96, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 156, 166, 204, 205, 208, 209], "option": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 80, 82, 83, 84, 88, 89, 94, 95, 97, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 128, 131, 135, 136, 139, 140, 154, 155, 156, 162, 163, 166, 182, 183, 192, 193, 195, 196, 205], "remot": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 166], "address": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127], "resourc": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 82, 83, 84, 88, 89, 94, 95, 97, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 125, 127, 141, 151, 154, 165, 192, 193, 195, 196, 205, 211], "Will": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127], "repositori": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 166, 202], "otherwis": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 130, 163, 183], "match": [17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 70, 72, 73, 74, 75, 84, 85, 86, 87, 88, 89, 97, 102, 104, 109, 125, 127, 130, 181, 182, 204], "pattern": [17, 54, 75, 85, 88, 97, 115, 116, 123, 125, 127, 183], "tag": [17, 25, 36, 40, 54, 58, 92, 93, 94, 95, 96, 101, 102, 127, 155, 163, 192, 195, 196, 211], "order": [17, 74, 75, 80, 115, 116, 139, 143, 155, 181, 183, 205, 206, 209, 211], "meaning": [17, 117], "phrase": [17, 58, 62, 70, 84, 89], "extract": [17, 18, 21, 26, 29, 33, 37, 42, 51, 59, 71, 75, 76, 77, 79, 80, 84, 85, 87, 89, 93, 94, 95, 96, 104, 105, 107, 113, 116, 120, 124, 129, 132, 133, 134, 139, 156, 163, 166, 201], "onto": [17, 155, 206], "sentenc": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 102, 108, 111, 113, 118, 120, 123, 124, 127, 129, 131, 133, 139, 140, 142, 143, 156, 166, 169, 184, 192, 193, 195, 196, 205, 209, 210], "regular": [17, 88, 94, 104, 183], "express": [17, 40, 48, 85, 88, 104], "wrap": [17, 144, 145, 152, 158, 162, 183], "angl": 17, "bracket": 17, "easili": [17, 63, 102, 132, 201], "distinguish": 17, "itself": [17, 80, 112, 141, 206], "form": [17, 25, 36, 40, 71, 75, 83, 84, 85, 88, 89, 105, 107, 115, 116, 127, 132, 163, 182, 192, 193, 205], "peter": [17, 65, 83, 97, 102, 105, 115, 117, 192], "piper": [17, 83, 102, 117], "employe": [17, 83, 102, 117], "pick": [17, 83, 102, 117], "peck": [17, 83, 102, 117], "pickl": [17, 83, 102, 117], "pepper": [17, 83, 102, 117], "nnp": [17, 102, 139, 155, 192, 193, 195, 196, 204, 209, 210, 211], "nn": [17, 102, 178, 192, 193, 195, 196, 211], "vbp": [17, 102, 139, 193, 204, 209, 210], "vbg": [17, 102], "IN": [17, 102, 139, 155, 193, 195, 196, 204, 209, 210], "jj": [17, 102, 139, 155, 192, 195, 204, 209, 210, 211], "regexpars": 17, "e": [17, 19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 53, 54, 63, 65, 75, 77, 94, 95, 109, 111, 112, 113, 118, 142, 163, 183, 201], "g": [17, 19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 53, 54, 63, 77, 94, 95, 109, 111, 112, 113, 118, 142, 163, 183, 201], "setregexpars": 17, "when": [17, 50, 54, 55, 77, 85, 87, 90, 95, 109, 113, 115, 118, 122, 127, 129, 139, 183, 192, 205, 206, 209], "defin": [17, 93, 94, 95, 118, 122, 129, 133, 155, 163, 166, 181, 201, 205, 209], "enclos": 17, "treat": 17, "group": [17, 125, 183], "so": [17, 25, 40, 80, 93, 105, 141, 163, 182, 183, 201], "here": [17, 83, 155, 183, 205], "specif": [17, 41, 51, 53, 54, 56, 57, 61, 69, 77, 80, 95, 109, 119, 139, 141, 163, 169, 184, 209], "mean": [17, 36, 72, 80, 82, 85, 87, 109, 111, 112, 123, 132, 139, 183, 205, 206, 209], "noun": [17, 193], "success": [17, 58, 109], "grammar": 17, "parser": [17, 51, 53, 77], "perceptronmodel": [17, 51, 53, 77, 94, 102, 192], "Of": [17, 55, 127], "documentassembl": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 130, 131, 132, 140, 141, 142, 143, 163, 192, 201, 205], "sentencedetector": [17, 25, 41, 48, 51, 53, 57, 59, 67, 69, 73, 77, 80, 83, 88, 90, 94, 95, 96, 102, 104, 105, 118, 120, 141, 143, 192, 205, 206], "postag": 17, "selectexpr": [17, 25, 41, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 83, 84, 85, 87, 88, 89, 90, 93, 96, 97, 102, 104, 105, 107, 111, 117, 118, 120, 123, 124, 125, 129, 130, 132, 133, 155, 192, 193, 195, 204, 205, 210], "explod": [17, 25, 41, 48, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 84, 87, 88, 89, 90, 93, 96, 102, 104, 105, 111, 124, 129, 132, 133, 155, 192, 195, 204, 205, 210], "11": [17, 72, 73, 85, 87, 90, 102], "13": [17, 48, 72, 73, 77, 102, 129, 133], "21": [17, 85, 87, 96, 102], "35": [17, 102], "39": [17, 96, 102, 195], "52": [17, 96, 102, 195], "58": [17, 102], "albertforquestionansw": 18, "classifi": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 80, 132, 205], "dl": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 82, 95, 115, 116], "albert": [18, 19, 20, 55], "span": [18, 21, 26, 29, 33, 37, 42, 112], "question": [18, 21, 26, 29, 33, 37, 41, 42, 51, 53, 56, 57, 63, 66, 67, 74, 102, 109, 112, 139], "answer": [18, 21, 26, 29, 33, 37, 41, 42, 51, 53, 56, 57, 63, 74, 109, 112, 139], "task": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 50, 55, 56, 57, 58, 60, 61, 65, 69, 72, 73, 74, 80, 109, 111, 112, 141, 183], "squad": [18, 21, 26, 29, 33, 37, 42, 55, 56, 57, 60, 66, 67], "linear": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 109, 183], "layer": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 55, 56, 57, 60, 63, 74, 182, 183], "hidden": [18, 20, 21, 23, 24, 26, 28, 29, 31, 33, 35, 37, 39, 42, 44, 46, 55, 63, 74, 119, 183], "state": [18, 20, 21, 23, 24, 25, 26, 28, 29, 31, 33, 35, 36, 37, 39, 40, 42, 44, 46, 50, 55, 56, 57, 58, 63, 65, 66, 67, 74, 80, 95, 109, 112, 140, 177, 181, 182, 183, 202, 205], "comput": [18, 21, 26, 29, 33, 37, 42, 50, 55, 60, 61, 69, 109, 111, 116, 139, 179, 182, 183, 209], "logit": [18, 19, 21, 22, 26, 29, 30, 33, 34, 37, 38, 42, 43, 45], "spanclassifi": [18, 21, 26, 29, 33, 37, 42], "document_quest": [18, 21, 26, 29, 33, 37, 41, 42], "document_context": [18, 21, 26, 29, 33, 37, 42], "albert_base_qa_squad2": 18, "larg": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 55, 60, 61, 63, 72, 73, 74, 80, 82, 84, 89, 95, 109, 183], "allow": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 63, 69, 94, 95, 97, 104, 105, 123, 125, 141, 169, 182, 183, 184], "faster": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 61, 63, 115, 116, 181], "casesensit": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 84, 89, 115, 118], "whether": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 84, 85, 87, 89, 90, 93, 94, 95, 97, 99, 104, 105, 109, 112, 113, 115, 118, 123, 125, 127, 130, 132, 133, 134, 139, 142, 143, 146, 156, 166, 183, 192, 196, 206], "ignor": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 84, 90, 93, 109, 111, 112, 115, 118, 139], "case": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 75, 82, 84, 89, 113, 115, 118, 125, 130, 177, 181, 183, 192, 193, 205], "configprotobyt": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 109, 111, 112, 113], "maxsentencelength": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 74], "128": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 66, 67, 72, 73, 74, 163, 183, 201], "multidocumentassembl": [18, 21, 26, 29, 33, 37, 41, 42, 140], "context": [18, 21, 26, 29, 33, 37, 42, 56, 57, 62, 63, 70, 74, 108, 113, 125], "setcasesensit": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 59, 61, 65, 66, 72, 84, 89, 94, 115, 118, 132, 143], "what": [18, 21, 26, 29, 33, 37, 40, 42, 51, 53, 80, 82, 111, 113, 122, 193, 202], "my": [18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 54, 88, 90, 104, 109, 118, 120, 123, 205], "clara": [18, 21, 26, 29, 33, 37, 42], "live": [18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 109, 163, 201], "berkelei": [18, 21, 26, 29, 33, 37, 42], "setmaxsentencelength": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 74], "albertforsequenceclassif": [19, 27], "sequenc": [19, 22, 27, 30, 34, 38, 43, 45, 50, 65, 109, 110, 111, 112, 113, 118, 177, 178, 181, 182], "regress": [19, 22, 27, 30, 34, 38, 43, 45, 112], "pool": [19, 22, 27, 30, 34, 38, 43, 45, 59, 63, 68], "multi": [19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 55, 69, 72, 73, 80, 82, 111], "sequenceclassifi": [19, 22, 27, 30, 34, 38, 43, 45], "label": [19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 50, 51, 53, 75, 82, 92, 93, 94, 95, 98, 99, 107, 108, 112, 113, 119, 163, 169, 184, 192, 201, 205], "albert_base_sequence_classifier_imdb": 19, "coalescesent": [19, 22, 27, 30, 34, 38, 43, 45, 82], "instead": [19, 22, 27, 30, 34, 38, 43, 45, 57, 80, 82, 85, 87, 112, 132, 133, 139, 177, 179, 209], "per": [19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 72, 73, 82, 85, 90, 92, 93, 94, 95, 139, 155, 166, 182, 183, 192], "inputcol": [19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 68, 82, 128, 131, 132, 133, 134, 137, 140], "averag": [19, 22, 27, 30, 34, 38, 41, 43, 45, 59, 68, 72, 73, 82, 95, 102], "probabl": [19, 22, 27, 30, 34, 38, 43, 45, 80, 109, 112, 115], "calcul": [19, 22, 25, 30, 34, 36, 38, 40, 43, 45, 71, 90, 95, 99, 107, 182, 183], "via": [19, 22, 30, 34, 38, 43, 45, 69, 137, 156, 183], "softmax": [19, 22, 30, 34, 38, 43, 45, 60, 62, 70, 113, 177], "sigmoid": [19, 22, 30, 34, 38, 43, 45, 179], "john": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 48, 57, 67, 73, 75, 77, 96, 97, 105, 134], "lenon": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "born": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 109], "london": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "pari": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "sarah": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "neg": [19, 22, 27, 30, 34, 38, 40, 43, 45, 107, 108, 163, 201], "getclass": [19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 50], "setcoalescesent": [19, 22, 27, 30, 34, 38, 43, 45, 82], "limit": [19, 22, 27, 30, 34, 38, 43, 45, 50, 55, 58, 65, 71, 74, 80, 112, 115], "almost": [19, 22, 27, 30, 34, 38, 43, 45], "bert": [19, 21, 22, 23, 27, 30, 31, 34, 38, 41, 43, 45, 55, 56, 57, 60, 61, 65, 66, 67, 72, 73, 74, 95, 96, 112], "512": [19, 22, 27, 30, 34, 38, 41, 43, 45, 63], "help": [19, 22, 27, 30, 34, 38, 43, 45, 51, 53, 55, 111, 125, 163, 201, 206, 210], "feed": [19, 22, 27, 30, 34, 38, 43, 45, 177], "entir": [19, 22, 27, 30, 34, 38, 43, 45, 111, 178, 181], "bool": [19, 22, 27, 30, 34, 38, 43, 45, 54, 57, 59, 69, 75, 77, 82, 84, 85, 89, 90, 93, 94, 95, 97, 99, 104, 105, 109, 112, 113, 115, 118, 123, 125, 127, 130, 132, 133, 134, 139, 142, 146, 156, 163, 166, 192], "one": [19, 22, 27, 30, 34, 36, 38, 43, 45, 48, 51, 53, 54, 56, 57, 68, 72, 73, 74, 80, 82, 85, 88, 93, 105, 115, 120, 143, 182, 183, 201, 205], "albertfortokenclassif": [20, 55], "recognit": [20, 23, 24, 28, 31, 35, 39, 44, 46, 50, 58, 91, 94, 95, 183], "ner": [20, 23, 24, 28, 31, 35, 39, 44, 46, 72, 73, 77, 78, 120, 139, 155, 156, 163, 166, 169, 184, 201], "token_classifi": [20, 24, 35, 39, 44, 46], "albert_base_token_classifier_conll03": 20, "albertembed": [20, 55], "level": [20, 25, 36, 40, 56, 57, 65, 66, 67, 69, 71, 73, 75, 94, 95, 99, 113, 156, 192], "tokenclassifi": [20, 23, 24, 28, 31, 35, 39, 44, 46], "o": [20, 23, 24, 28, 31, 35, 39, 44, 46, 93, 94, 95, 96, 139, 155, 166, 183, 192, 196, 211], "loc": [20, 23, 24, 28, 31, 35, 39, 44, 46, 77, 93, 94, 95, 129, 133, 139, 155, 166, 192], "bertforquestionansw": [21, 41], "bert_base_cased_qa_squad2": 21, "bertforsequenceclassif": 22, "bert_base_sequence_classifier_imdb": 22, "bertfortokenclassif": 23, "bert_base_token_classifier_conll03": 23, "camembertfortokenclassif": 24, "camembert": [24, 58], "camembert_base_token_classifier_wikin": 24, "georg": 24, "washington": 24, "est": [24, 58, 82, 111], "all\u00e9": 24, "\u00e0": 24, "classifierdl": [25, 205], "classifierdlapproach": [25, 36, 205], "gener": [25, 36, 55, 59, 61, 65, 68, 74, 77, 80, 94, 95, 105, 109, 112, 113, 115, 116, 133, 134, 163, 169, 184, 201, 204, 205, 206], "art": [25, 36, 50, 55, 56, 57, 58, 63, 65, 66, 67, 74, 80, 95, 109, 112, 140], "univers": [25, 51, 53, 69, 111], "encod": [25, 54, 56, 57, 60, 65, 69, 111, 163], "deep": [25, 56, 57, 63, 80, 94, 105, 113, 183], "dnn": 25, "insid": [25, 36, 93, 102, 125, 178, 192], "instanti": [25, 36, 40, 51, 53, 62, 70, 71, 75, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 113, 115, 116, 120, 122, 127, 192, 193], "classifierdlmodel": [25, 36, 205], "test": [25, 36, 40, 50, 51, 53, 56, 57, 69, 71, 83, 84, 88, 89, 94, 95, 99, 102, 109, 115, 116, 120, 127, 192, 193, 195, 196, 205, 211], "monitor": [25, 36, 40, 95, 163, 201], "metric": [25, 36, 40, 95, 116, 163], "done": [25, 36, 40, 66, 67, 94, 95, 206], "settestdataset": [25, 36, 40, 95, 99], "expect": [25, 36, 40, 74, 95, 125, 155, 181], "path": [25, 36, 40, 51, 53, 62, 70, 71, 75, 77, 83, 84, 88, 89, 94, 95, 97, 99, 105, 107, 109, 113, 115, 116, 119, 125, 137, 139, 154, 163, 166, 169, 184, 192, 193, 195, 196, 201], "parquet": [25, 36, 40, 95, 99, 128], "datafram": [25, 36, 40, 50, 71, 95, 99, 102, 127, 139, 151, 155, 162, 163, 166, 192, 193, 195, 196, 201, 205, 209, 211], "ha": [25, 36, 40, 41, 50, 54, 55, 60, 61, 63, 66, 67, 71, 80, 83, 88, 95, 99, 105, 107, 112, 115, 116, 127, 128, 130, 137, 139, 163, 181, 182, 183, 195, 201, 205, 206], "same": [25, 36, 40, 48, 55, 66, 71, 72, 75, 77, 95, 99, 112, 141, 163, 182, 183, 206], "step": [25, 36, 40, 62, 70, 95, 99, 163, 179, 183, 201, 205], "appli": [25, 36, 40, 50, 54, 75, 77, 95, 96, 99, 104, 112, 113, 115, 129, 133, 155, 183, 192], "follow": [25, 36, 40, 48, 54, 63, 65, 71, 80, 85, 87, 88, 93, 95, 97, 104, 124, 142, 178, 179, 201, 203, 206], "universalsentenceencod": [25, 36, 40, 69, 163, 201, 205], "preprocessingpipelin": [25, 36, 40, 95, 99], "randomsplit": [25, 36, 40, 95, 99], "write": [25, 36, 40, 71, 95, 99, 115, 116, 206], "overwrit": [25, 36, 40, 95, 96, 99, 163], "test_data": [25, 36, 40, 95, 99], "setlabelcolumn": [25, 36, 40, 92, 94, 95, 98, 119, 163, 169, 184, 201, 205], "usag": [25, 36, 40, 48, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 69, 71, 72, 74, 75, 80, 82, 83, 85, 87, 88, 89, 94, 95, 97, 102, 104, 105, 107, 108, 111, 112, 113, 115, 117, 118, 122, 125, 127], "64": [25, 36, 40, 55, 95, 98, 169, 184, 205], "dropout": [25, 40, 95, 183], "coeffici": [25, 40, 94, 95], "5": [25, 36, 40, 48, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 80, 82, 85, 87, 90, 93, 95, 102, 109, 127, 132, 139, 155, 163, 166, 183, 193, 195, 196, 201, 204, 205, 211], "enableoutputlog": [25, 36, 40, 95], "stdout": [25, 36, 40, 95, 99], "addit": [25, 36, 40, 51, 53, 56, 57, 75, 94, 95, 99, 104, 109, 125, 163, 183, 204, 205], "evaluationlogextend": [25, 36, 40, 95], "valid": [25, 36, 40, 85, 95, 99, 105, 113, 201], "time": [25, 36, 40, 55, 62, 70, 72, 73, 80, 85, 99, 108, 113, 127, 156, 177, 178, 179, 182, 183, 204, 205, 209, 210], "evalu": [25, 36, 40, 58, 65, 72, 73, 99, 146, 163], "labelcolumn": [25, 36, 40, 94, 95], "lr": [25, 36, 40, 95], "rate": [25, 36, 40, 62, 66, 67, 70, 71, 95, 98, 113], "005": [25, 40, 95, 98], "maxepoch": [25, 36, 40, 94, 95], "maximum": [25, 36, 40, 48, 62, 70, 77, 80, 92, 94, 95, 97, 98, 104, 105, 109, 111, 112, 113, 115, 123, 125], "epoch": [25, 36, 40, 92, 94, 95, 98, 99, 105, 113, 163], "30": [25, 40, 80, 85, 87, 93, 98, 111, 139, 155, 166, 204], "outputlogspath": [25, 36, 40, 95, 105], "randomse": [25, 36, 40, 94, 95], "random": [25, 36, 40, 62, 70, 92, 94, 95, 98, 132], "seed": [25, 36, 40, 62, 70, 92, 94, 95, 98], "shuffl": [25, 36, 92, 98], "testdataset": [25, 36, 40, 95, 163, 201], "statist": [25, 36, 40, 71, 80, 95, 99], "dure": [25, 36, 40, 61, 94, 95, 99, 104, 113, 156, 163, 201], "validationsplit": [25, 36, 40, 95, 105], "choos": [25, 36, 40, 59, 68, 95, 105, 115], "proport": [25, 36, 40, 95, 99, 105], "against": [25, 36, 40, 75, 80, 84, 89, 95, 99, 105, 141], "between": [25, 36, 40, 51, 53, 66, 67, 69, 72, 73, 74, 77, 95, 99, 104, 105, 113, 182, 183], "off": [25, 36, 40, 69, 72, 73, 95, 99, 105, 182], "verbos": [25, 36, 40, 94, 95, 99], "multiclassifierdlapproach": [25, 36, 163, 201], "sentimentdlapproach": [25, 36, 40], "analysi": [25, 36, 40, 63, 74, 106, 107, 112, 129, 148, 183, 206], "accept": [25, 36, 40, 182], "singl": [25, 36, 40, 71, 77, 80, 120, 122, 125, 181, 182, 183, 192], "item": [25, 40, 71, 163, 201], "either": [25, 40, 50, 53, 58, 59, 68, 75, 80, 82, 88, 107, 108, 112, 130, 131, 139, 140, 142, 166, 182, 206], "doubl": [25, 40, 128, 142], "sentenceembed": [25, 36, 40, 68, 71, 132], "In": [25, 36, 40, 50, 58, 60, 61, 65, 71, 74, 75, 80, 82, 83, 84, 88, 89, 104, 105, 107, 109, 112, 115, 116, 127, 163, 169, 178, 183, 195, 201, 205, 206, 210, 211], "csv": [25, 40, 75, 99, 142, 205], "movi": [25, 40, 108, 205], "best": [25, 40, 55, 58, 66, 67, 80, 82, 95, 183, 205], "wach": [25, 205], "ever": [25, 40, 54, 205], "opinion": [25, 40, 205], "win": [25, 40, 205], "award": [25, 40, 205], "terribl": [25, 40, 205], "act": [25, 40, 183, 205], "bad": [25, 40, 107, 163, 201, 205], "realli": [25, 40, 108, 205], "trane": 25, "smallcorpu": [25, 40, 205], "read": [25, 40, 50, 51, 53, 62, 70, 80, 83, 84, 85, 87, 88, 89, 94, 97, 99, 105, 107, 109, 113, 115, 116, 125, 127, 128, 131, 137, 140, 151, 154, 157, 163, 183, 192, 193, 195, 196, 201, 205, 211], "header": [25, 40, 41, 142, 205], "src": [25, 40, 50, 51, 53, 71, 83, 84, 88, 89, 94, 95, 102, 115, 116, 120, 127, 192, 193, 195, 196, 205, 211], "useembed": [25, 36, 40, 69, 205], "docclassifi": [25, 36, 40, 205], "setbatchs": [25, 36, 40, 63, 95, 98, 113, 163, 169, 184, 201, 205], "setmaxepoch": [25, 36, 40, 92, 94, 95, 98, 163, 169, 184, 201, 205], "20": [25, 41, 74, 93, 109, 139, 142, 155, 166, 183, 205], "setlr": [25, 36, 40, 95, 98, 163, 201, 205], "5e": [25, 40, 205], "setdropout": [25, 40, 95, 205], "pipelinemodel": [25, 36, 40, 51, 53, 54, 62, 70, 94, 95, 108, 113, 115, 116, 127, 139, 141, 163, 205, 208], "v": [25, 36, 40, 60, 71, 80, 82, 84, 95, 98, 99, 116, 155, 183], "classifierdl_use_trec6": 25, "trec": 25, "multiclassifierdlmodel": [25, 36], "sentimentdlmodel": [25, 36, 40], "sarcasmdl": [25, 205], "classifierdl_use_sarcasm": [25, 205], "sarcasm": [25, 205], "m": [25, 85, 87, 205], "could": [25, 61, 80, 88, 99, 113, 204, 205, 206], "put": [25, 155, 169, 178, 184, 205], "word": [25, 50, 51, 53, 55, 59, 60, 62, 63, 66, 68, 69, 70, 71, 74, 75, 77, 80, 83, 90, 93, 96, 97, 102, 107, 109, 111, 112, 113, 115, 116, 117, 118, 122, 125, 126, 127, 139, 155, 166, 195, 196, 204, 205], "much": [25, 41, 55, 66, 67, 97, 127, 156, 178, 181, 205], "love": [25, 57, 67, 73, 105, 108, 205], "wake": [25, 205], "am": [25, 85, 87, 109, 120, 205], "mondai": [25, 205], "would": [25, 48, 59, 68, 85, 105, 156, 182, 205], "arrays_zip": [25, 51, 53, 80, 205], "out": [25, 80, 83, 97, 109, 111, 112, 117, 118, 205], "normal": [25, 54, 78, 84, 105, 108, 118, 132, 141, 143, 156, 183, 205, 206], "debertaforquestionansw": 26, "deberta": [26, 27, 28, 60], "deberta_v3_xsmall_qa_squad2": 26, "debertaforsequenceclassif": 27, "v2": [27, 28, 56, 57, 60], "v3": [27, 28], "deberta_v3_xsmall_sequence_classifier_imdb": 27, "deberta_base_sequence_classifier_imdb": 27, "debertafortokenclassif": 28, "deberta_v3_xsmall_token_classifier_conll03": 28, "distilbertforquestionansw": 29, "distilbert": [29, 30, 61], "distilbert_base_cased_qa_squad2": 29, "distilbertforsequenceclassif": 30, "distilbert_base_sequence_classifier_imdb": 30, "distilbertfortokenclassif": 31, "distilbert_base_token_classifier_conll03": 31, "albert_for_sequence_classif": [32, 78], "albert_for_token_classif": [32, 78], "bert_for_sequence_classif": [32, 78], "bert_for_token_classif": [32, 78], "camembert_for_token_classif": [32, 78], "deberta_for_sequence_classif": [32, 78], "deberta_for_token_classif": [32, 78], "distil_bert_for_sequence_classif": [32, 78], "distil_bert_for_token_classif": [32, 78], "longformer_for_sequence_classif": [32, 78], "longformer_for_token_classif": [32, 78], "multi_classifier_dl": [32, 78], "roberta_for_sequence_classif": [32, 78], "roberta_for_token_classif": [32, 78], "sentiment_dl": [32, 78], "xlm_roberta_for_sequence_classif": [32, 78], "xlm_roberta_for_token_classif": [32, 78], "xlnet_for_sequence_classif": [32, 78], "xlnet_for_token_classif": [32, 78], "longformerforquestionansw": 33, "longform": [33, 34, 35, 65], "longformer_base_base_qa_squad2": 33, "longformerforsequenceclassif": 34, "longformer_base_sequence_classifier_imdb": 34, "4096": [34, 55, 65], "longformerfortokenclassif": 35, "xlnet_base_token_classifier_conll03": [35, 46], "longformer_base_token_classifier_conll03": 35, "multiclassifierdl": 36, "bidirect": [36, 56, 57, 63, 74, 182, 183], "gru": [36, 179, 183], "convolut": [36, 50, 183], "machin": [36, 62, 70, 80, 94, 109, 111, 112, 163, 183, 203], "strongli": 36, "relat": [36, 51, 53, 77, 210], "problem": [36, 55, 63, 112, 113], "variant": [36, 65, 69], "multipl": [36, 50, 58, 75, 80, 85, 104, 125, 155, 163, 183, 192], "mai": [36, 130, 177, 181, 183, 204, 205, 206, 209, 210], "assign": [36, 75, 96, 107], "instanc": [36, 98, 99, 146, 150, 156, 157, 161, 182], "multiclass": 36, "categor": 36, "precis": [36, 51, 53], "than": [36, 40, 61, 62, 70, 72, 73, 74, 80, 82, 90, 94, 109, 115, 116, 181, 205], "two": [36, 51, 53, 55, 60, 69, 71, 72, 73, 77, 124, 183, 192, 205], "constraint": 36, "mani": [36, 60, 66, 67, 80, 109, 111, 112, 127, 177], "formal": 36, "find": [36, 51, 53, 66, 67, 69, 75, 77, 83, 85, 109], "binari": [36, 137, 151, 163], "bertsentenceembed": [36, 40, 57, 67, 73], "multiclassifi": [36, 163, 201], "001": [36, 94, 95, 183], "10": [36, 48, 51, 80, 85, 87, 96, 115, 163, 178, 204], "44": [36, 62, 70, 102], "shuffleperepoch": 36, "threshold": [36, 40, 62, 70, 80, 82, 94, 113, 127], "minimum": [36, 40, 62, 70, 77, 80, 82, 92, 94, 95, 97, 104, 105, 109, 112, 115, 116, 123, 125, 192], "ed58abb40640f983": 36, "pn": 36, "newsyou": 36, "toxic": 36, "a1237f726b5f5d89": 36, "dude": 36, "place": [36, 50], "obscen": 36, "insult": 36, "24b0d6c8733c2abe": 36, "thank": [36, 74, 80], "8c4478fb239bcfc0": 36, "gee": 36, "minut": 36, "traindataset": [36, 163, 201], "printschema": [36, 128, 131, 137, 140], "root": [36, 48, 51, 53, 77, 128, 131, 137, 140, 193], "setcleanupmod": [36, 131, 140], "shrink": [36, 131, 140], "1e": [36, 163, 201], "setthreshold": [36, 40, 80, 82, 163, 201], "setvalidationsplit": [36, 99, 105, 169, 184], "setverbos": [36, 94, 95, 99, 169, 184], "multiclassifierdl_use_tox": 36, "comment": [36, 80], "jigsaw": 36, "challeng": [36, 61, 63, 66, 67, 80], "pretti": [36, 80], "good": [36, 58, 61, 69, 108], "stuff": 36, "wtf": 36, "kind": [36, 80, 85, 87], "crap": 36, "robertaforquestionansw": 37, "roberta": [37, 38, 39, 42, 43, 44, 58, 60, 65, 66, 67, 72, 73], "roberta_base_qa_squad2": 37, "robertaforsequenceclassif": 38, "roberta_base_sequence_classifier_imdb": 38, "robertafortokenclassif": 39, "roberta_base_token_classifier_conll03": 39, "sentimentdl": 40, "natur": [40, 50, 55, 56, 57, 58, 60, 61, 62, 69, 70, 74, 82, 109, 112, 130, 140, 143], "affect": [40, 125, 183], "subject": [40, 51, 53], "view": 40, "common": [40, 75, 120, 130, 156, 169, 184, 208], "product": [40, 183], "review": [40, 159], "tweet": 40, "interpret": [40, 75], "posit": [40, 60, 61, 72, 73, 74, 80, 93, 107, 108, 123, 143, 163, 201], "final": [40, 65, 66, 67, 72, 73, 82, 95, 113, 181, 182, 205], "otheriws": [40, 82], "neutral": [40, 82], "thresholdlabel": [40, 82], "score": [40, 56, 57, 72, 73, 80, 82, 94, 95, 107, 108, 109], "less": [40, 61, 82, 90, 94, 115, 178, 182], "watch": [40, 108], "32": [40, 55, 63, 182, 183, 204, 210], "setthresholdlabel": [40, 82], "p": [40, 54, 62, 70, 82, 95, 99, 122, 183], "sentimentdl_use_imdb": 40, "english": [40, 58, 80, 115, 118, 127], "imdb": 40, "sentimentdl_use_twitt": 40, "wow": 40, "video": [40, 80], "awesom": 40, "bruh": 40, "damn": 40, "wast": [40, 108], "tapasforquestionansw": 41, "implement": [41, 62, 70, 72, 105, 113, 135, 136, 144, 145, 152, 158, 162, 177, 178, 179, 181, 183], "tapa": 41, "design": [41, 56, 57, 66, 67, 84, 111, 163, 183, 201], "about": [41, 51, 53, 66, 67, 71, 80, 104, 116, 139, 141, 204, 206, 209, 210], "tabular": [41, 142], "tabl": [41, 142], "tri": 41, "share": [41, 80, 182, 183, 206], "its": [41, 50, 60, 61, 65, 74, 80, 102, 107, 111, 118, 163, 183, 195], "table_qa_tapas_base_finetuned_wtq": 41, "document_assembl": [41, 138, 142, 156], "table_json": 41, "document_t": [41, 142], "sentence_detector": [41, 78, 103], "table_assembl": [41, 138, 156], "tableassembl": [41, 142], "stage": [41, 139, 141, 163, 201, 205, 206, 209], "json_data": 41, "monei": [41, 142], "ag": [41, 142], "donald": [41, 142], "trump": [41, 142], "000": [41, 80, 109, 142], "75": [41, 80, 142], "elon": [41, 142], "musk": [41, 142], "55": [41, 96, 142], "AS": [41, 48], "who": [41, 122, 205], "earn": 41, "thei": [41, 51, 53, 95, 97, 109, 141, 158, 193, 205], "old": [41, 48, 195], "xlmrobertaforquestionansw": 42, "xlm": [42, 43, 44, 72, 73], "xlm_roberta_base_qa_squad2": 42, "xlmrobertaforsequenceclassif": 43, "xlm_roberta_base_sequence_classifier_imdb": 43, "xlmrobertafortokenclassif": 44, "xlm_roberta_base_token_classifier_conll03": 44, "xlnetforsequenceclassif": 45, "xlnet": [45, 46, 74], "xlnet_base_sequence_classifier_imdb": 45, "xlnetfortokenclassif": 46, "spanbert_coref": 47, "spanbertcorefmodel": 48, "corefer": 48, "resolut": 48, "spanbert": 48, "identifi": [48, 71, 80, 84, 88, 123, 125, 163, 206], "given": [48, 75, 80, 109, 112, 113, 115, 116, 118, 162, 163, 177, 181, 183], "told": [48, 87], "mari": [48, 57, 67, 73, 105], "he": [48, 60, 87, 122], "borrow": 48, "book": [48, 54, 109, 113, 193], "her": 48, "link": [48, 166], "fine": [48, 56, 57, 61, 112], "tune": [48, 56, 57, 61, 112], "ontonot": 48, "corefresolut": 48, "spanbert_base_coref": 48, "maxsegmentlength": 48, "segment": [48, 61, 66, 126, 127], "textgenr": 48, "genr": 48, "One": [48, 80, 122, 124], "bc": 48, "broadcast": 48, "convers": 48, "bn": 48, "nw": 48, "wire": 48, "pt": 48, "pivot": 48, "testament": 48, "tc": 48, "telephon": 48, "wb": 48, "web": [48, 54, 58, 109, 163, 201], "setmaxsegmentlength": 48, "settextgenr": 48, "code": [48, 60, 62, 65, 66, 67, 70, 72, 73, 80, 82, 112, 180, 183, 202, 210], "vit_for_image_classif": 49, "vitforimageclassif": 50, "vision": 50, "vit": 50, "altern": [50, 80, 107, 113, 115, 116, 139, 142, 181], "neural": [50, 56, 57, 60, 95, 105, 111, 182, 183], "network": [50, 56, 57, 63, 95, 105, 178, 181, 182, 183], "usual": [50, 143, 178], "imageclassifi": 50, "image_assembl": [50, 138, 156], "image_classifier_vit_base_patch16_224": 50, "huggingfac": [50, 58], "vitimageclassificationtestspec": 50, "paper": [50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 80, 105, 108, 109, 111, 112, 183, 196, 211], "abstract": [50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 80, 109, 111, 112, 119, 178, 181, 196, 211], "while": [50, 55, 61, 71, 80, 99, 109, 163, 182, 201, 206], "architectur": [50, 55, 56, 57, 60, 66, 82, 95, 105, 112, 183], "becom": [50, 55, 61, 80], "de": [50, 58, 80, 82, 111], "facto": [50, 80], "standard": [50, 54, 65, 85, 87, 115, 116, 125], "remain": [50, 54, 55, 61, 80], "attent": [50, 60, 65, 183], "conjunct": 50, "replac": [50, 54, 60, 65, 82, 83, 96, 105, 115, 116, 183, 205], "certain": [50, 113], "compon": [50, 98, 99, 128, 137, 146, 150, 161, 209], "keep": [50, 80, 97, 109, 112], "overal": [50, 71, 74], "structur": [50, 143, 204], "relianc": 50, "cnn": [50, 82, 95, 105, 183], "necessari": [50, 61, 201, 208], "pure": [50, 111], "directli": [50, 139, 163, 177, 201], "patch": 50, "perform": [50, 54, 55, 58, 60, 61, 63, 66, 67, 69, 71, 72, 73, 74, 95, 108, 109, 115, 182, 183], "veri": [50, 58, 63, 72, 73, 74, 109, 111, 112, 139, 182, 204, 206, 209, 210], "well": [50, 51, 53, 69, 72, 73, 80, 142, 183], "amount": [50, 69, 80, 89, 109, 127, 139, 209], "transfer": [50, 61, 69, 72, 73, 109, 112], "mid": 50, "small": [50, 54, 55, 58, 61, 62, 70, 83, 102, 139, 195, 209], "benchmark": [50, 55, 60, 61, 63, 72, 73, 112], "imagenet": 50, "cifar": 50, "vtab": 50, "etc": [50, 59, 132, 143, 201], "attain": 50, "excel": [50, 74], "compar": [50, 55, 60, 61, 63, 74, 80, 105, 112, 113, 163, 201], "substanti": [50, 56, 57], "fewer": [50, 55], "worth": 50, "16x16": 50, "scale": [50, 55, 61, 65, 72, 73, 109, 112, 181, 183], "imagedf": 50, "dropinvalid": 50, "imageassembl": [50, 137], "pipelinedf": 50, "dependencypars": [51, 53, 77], "dependencyparserapproach": [51, 193, 211], "unlabel": [51, 56, 57, 109, 112], "grammat": [51, 53], "dependencyparsermodel": [51, 53, 77], "relationship": [51, 53, 69, 77], "tell": [51, 53, 80, 155], "verb": [51, 53, 193], "modifi": [51, 53, 66, 67, 93, 105, 180], "describ": [51, 53, 77, 80, 111, 182, 183], "wai": [51, 53, 75, 77, 141, 166], "onli": [51, 53, 54, 63, 69, 74, 85, 88, 97, 104, 105, 109, 112, 122, 127, 141, 179, 180, 183, 192], "chosen": [51, 53, 95], "particular": [51, 53, 80], "treebank": 51, "penn": 51, "setdependencytreebank": 51, "conll": [51, 53, 94, 95, 156, 193, 194, 208], "u": [51, 53, 60, 61, 80, 87, 93, 94, 95, 139, 155, 166, 179, 183, 193, 203, 206, 211], "setconllu": [51, 53], "apart": [51, 53, 129, 133], "dependencytreebank": 51, "conllu": [51, 53, 83, 156, 194, 208], "numberofiter": [51, 53], "iter": [51, 53, 55, 62, 70, 102, 127, 163, 182, 201], "converg": [51, 53, 102, 127], "better": [51, 53, 55, 60, 74, 80, 94, 102, 104, 105, 108, 127], "accuraci": [51, 53, 56, 57, 62, 69, 70, 72, 73, 94, 95, 102, 115, 127, 201], "typeddependencyparserapproach": [51, 53], "postagg": [51, 53, 77, 94, 102], "dependency_treebank": 51, "emptydataset": [51, 53], "reli": [51, 53, 74, 80], "tree": [51, 77], "bank": 51, "setnumberofiter": [51, 53], "read_a": [51, 53, 75, 83, 84, 88, 89, 94, 97, 99, 107, 115, 116, 125, 149, 154, 156, 192, 193], "reada": [51, 53, 71, 75, 83, 84, 88, 89, 94, 97, 99, 107, 115, 116, 120, 125, 151, 154, 192, 193], "dep": 51, "dependency_conllu": [51, 77], "perceptron": [51, 78, 101], "featur": [51, 62, 70, 80, 90, 94, 99, 163, 183, 208], "typeddependencyparsermdoel": 51, "union": [51, 53], "worker": [51, 53], "turner": [51, 53], "newal": [51, 53], "sai": [51, 53, 80, 125], "disappoint": [51, 53], "talk": [51, 53], "stricken": [51, 53], "parent": [51, 53], "firm": [51, 53], "feder": [51, 53], "mogul": [51, 53], "col": [51, 53, 75, 84, 93, 96, 129, 133, 155, 204], "dependency_pars": [52, 78], "typed_dependency_pars": [52, 78], "typeddependencypars": [53, 77], "Its": 53, "conll2009": 53, "typeddependencyparsermodel": [53, 77], "beforehand": 53, "2009": 53, "setconll2009": 53, "dependency_typ": [53, 77], "train_smal": 53, "txt": [53, 62, 70, 71, 83, 84, 88, 89, 102, 105, 107, 113, 115, 116, 120, 125, 195, 196, 211], "descript": [53, 68, 80, 85, 115, 122, 151, 169, 184], "typdep": 53, "dependency_typed_conllu": [53, 77], "amod": 53, "flat": [53, 77, 134], "nsubj": [53, 77, 134, 193], "parataxi": 53, "documentnorm": 54, "raw": [54, 109, 122, 125, 204, 206], "scrape": 54, "xml": 54, "remov": [54, 66, 67, 97, 108, 123, 132, 133, 134], "dirti": [54, 97], "regex": [54, 75, 85, 88, 97, 113, 115, 116, 123, 125, 127], "want": [54, 75, 96, 169, 184, 206], "polici": 54, "lower": [54, 55, 80, 113, 130], "action": 54, "clean": [54, 97, 112, 143, 206], "lowercas": [54, 97, 123, 127, 130], "convert": [54, 59, 68, 71, 85, 87, 90, 93, 97, 112, 123, 124, 127, 129, 130, 133, 134, 163, 201, 208], "pretty_al": 54, "utf": 54, "cleanuppattern": [54, 97], "normalizeddocu": 54, "setact": 54, "setpattern": [54, 123, 127], "setreplac": 54, "setpolici": 54, "setlowercas": [54, 97, 130, 143], "div": 54, "theworldsgreatest": 54, "right": [54, 56, 57], "hide": 54, "wide": [54, 56, 57, 60, 61, 72, 73], "toptext": 54, "style": [54, 82, 112], "font": 54, "famili": 54, "sego": 54, "ui": 54, "arial": 54, "san": [54, 80], "serif": 54, "world": [54, 120, 163, 201], "largest": [54, 80, 109], "develop": [54, 80, 111, 160], "site": [54, 80], "h1": 54, "300": 54, "160": 54, "lorem": [54, 84, 89], "ipsum": [54, 84, 89], "simpli": [54, 206], "print": 54, "typeset": 54, "industri": 54, "been": [54, 58, 109, 124, 143], "sinc": [54, 80, 109, 205, 206, 210], "1500": 54, "unknown": [54, 82], "printer": 54, "took": 54, "gallei": 54, "scrambl": 54, "specimen": 54, "surviv": 54, "five": [54, 96], "centuri": 54, "leap": 54, "electron": 54, "essenti": [54, 109], "unchang": 54, "popularis": 54, "1960": 54, "releas": [54, 55, 58, 60, 66, 67, 72, 73, 112, 156], "letraset": 54, "passag": 54, "recent": [54, 56, 57, 60, 66, 67, 80], "desktop": 54, "publish": [54, 66, 67], "softwar": 54, "aldu": 54, "pagemak": 54, "setencod": 54, "lite": 55, "googl": [55, 56, 57, 60, 62, 63, 66, 67, 69, 70, 80, 112, 183, 193], "research": [55, 56, 57, 60, 62, 70, 111, 112, 183], "toyota": 55, "technolog": 55, "institut": 55, "chicago": 55, "These": [55, 66, 67, 74, 80, 94, 109, 166, 203], "offici": [55, 80, 93, 94, 95, 139, 155, 166, 202], "tf": [55, 69, 169, 178, 180, 181, 182, 184], "wrapper": [55, 159, 177, 179, 183], "port": 55, "albert_base_uncas": 55, "albert_bas": 55, "768": [55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74], "emb": 55, "dim": [55, 183], "12m": 55, "albert_large_uncas": 55, "albert_larg": 55, "1024": [55, 63, 65, 74], "24": [55, 74, 84, 89, 93, 113, 139, 155, 166, 204], "16": [55, 74, 96, 195, 204], "18m": 55, "albert_xlarge_uncas": 55, "albert_xlarg": 55, "2048": 55, "60m": 55, "albert_xxlarge_uncas": 55, "albert_xxlarg": 55, "235m": 55, "sentencepiec": [55, 60, 69], "everi": [55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74, 95, 108, 111, 113, 131, 140, 141, 169, 178, 184, 206], "dimens": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 150, 178, 181, 183], "repeat": 55, "footprint": 55, "howev": [55, 68, 74, 80, 97, 182, 204], "cost": [55, 113, 115], "similar": [55, 69, 80, 82, 181, 183], "through": [55, 77, 80, 134, 183, 206], "FOR": 55, "http": [55, 58, 60, 62, 63, 69, 70, 179, 181, 182, 183, 202], "tfhub": [55, 63, 69], "dev": [55, 63, 69], "q": 55, "increas": [55, 71, 80, 109, 115], "often": [55, 66, 67, 74], "improv": [55, 56, 57, 58, 60, 63, 66, 67, 72, 73, 94, 95, 109, 183, 210], "downstream": [55, 58, 60, 63, 65, 74, 109, 112], "some": [55, 57, 72, 80, 95, 105, 109, 141, 163, 204, 205, 209, 210], "point": [55, 56, 57, 104, 105, 131, 140, 192], "further": [55, 80, 94, 95, 129, 143], "harder": 55, "gpu": [55, 109, 111, 112, 156, 182], "tpu": 55, "longer": [55, 62, 65, 70, 82, 182, 210], "present": [55, 63, 65, 66, 67, 69, 72, 73, 77, 99, 105, 111], "reduct": [55, 115], "techniqu": [55, 60, 109, 112], "consumpt": [55, 69, 71], "speed": [55, 94, 111], "devlin": [55, 66, 67], "et": [55, 66, 67, 82, 183], "al": [55, 66, 67, 183], "2019": [55, 58, 60, 66, 67, 72, 73], "comprehens": [55, 109], "empir": [55, 56, 57, 72, 73, 74], "evid": 55, "our": [55, 58, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 80, 105, 109, 112, 155, 166, 210], "lead": [55, 58, 72, 73, 178], "loss": [55, 61, 95, 112, 183, 201], "focus": [55, 80], "inter": 55, "coher": [55, 109], "consist": [55, 60, 65, 88, 102, 108, 127, 142, 181, 183, 195], "As": [55, 56, 57, 61, 80, 182, 183], "establish": 55, "glue": [55, 56, 57, 61, 66, 67, 72, 73], "race": [55, 60, 66, 67], "embeddingsfinish": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 132], "finished_embed": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "setoutputasvector": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 132], "setcleanannot": [55, 60, 61, 63, 65, 66, 68, 69, 71, 72, 74, 132, 133, 134], "80": [55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 88, 132, 143], "1342473030090332": [55, 60], "3855540752410889": [55, 60], "9818322062492371": [55, 60], "784737348556518": [55, 60], "847029983997345": [55, 60], "047153353691101": [55, 60], "1520637571811676": [55, 60], "6245765686035156": [55, 60], "009860038757324219": [55, 60], "13450059294700623": [55, 60], "707749128341675": [55, 60], "2916892766952": [55, 60], "04192575812339783": [55, 60], "5764210224151611": [55, 60], "3196685314178467": [55, 60], "527840495109": [55, 60], "15583214163780212": [55, 60], "1614152491092682": [55, 60], "28423872590065": [55, 60], "135491415858268": [55, 60], "bertembed": [56, 59, 68, 95, 132], "dens": [56, 57], "small_bert_l2_768": 56, "understand": [56, 57, 61, 72, 74, 80, 112, 127, 204], "introduc": [56, 57, 61, 63, 65, 112], "call": [56, 57, 61, 75, 80, 109, 162, 177, 179, 181, 183, 192, 205, 211], "stand": [56, 57], "unlik": [56, 57, 72, 80, 122, 178, 181], "jointli": [56, 57], "condit": [56, 57, 109, 112], "both": [56, 57, 63, 69, 77, 181, 182, 183, 205, 206], "left": [56, 57], "just": [56, 57, 61, 66, 90, 95, 180], "rang": [56, 57, 60, 61, 72, 73], "infer": [56, 57, 58, 61, 74, 182, 183], "without": [56, 57, 72, 73, 80, 109, 127, 183], "modif": [56, 57], "conceptu": [56, 57], "simpl": [56, 57, 75, 109, 183, 206], "power": [56, 57, 112], "obtain": [56, 57, 58, 69], "eleven": [56, 57], "push": [56, 57], "absolut": [56, 57], "multinli": [56, 57], "86": [56, 57, 60], "v1": [56, 57, 178], "f1": [56, 57, 72, 73, 95, 109], "93": [56, 57], "83": [56, 57, 60, 169, 184, 195, 196, 211], "small_bert_l2_128": 56, "3497989177703857": 56, "480538547039032": 56, "3238905668258667": 56, "612930893898010": 56, "1357314586639404": 56, "32984697818756104": 56, "6032363176345825": 56, "6791689395904": 56, "8244884014129639": 56, "27088963985443115": 56, "059438943862915": 56, "9817547798156": 56, "1648050546646118": 56, "4725411534309387": 56, "5938255786895752": 56, "5780693292617": 56, "9125322699546814": 56, "4563939869403839": 56, "3975459933280945": 56, "81611204147338": 56, "sentence_bert_embed": 57, "sent_small_bert_l2_768": 57, "islong": 57, "long": [57, 65, 74, 181, 183], "sent_small_bert_l2_128": 57, "orang": [57, 67, 73], "8951074481010437": [57, 67, 73], "13753940165042877": [57, 67, 73], "3108254075050354": [57, 67, 73], "65693199634552": [57, 67, 73], "6180210709571838": [57, 67, 73], "12179657071828842": [57, 67, 73], "191165953874588": [57, 67, 73], "4497021436691": [57, 67, 73], "822715163230896": [57, 67, 73], "7568016648292542": [57, 67, 73], "1165061742067337": [57, 67, 73], "59048593044281": [57, 67, 73], "setislong": 57, "camembertembed": 58, "tasti": 58, "french": [58, 80, 111, 118], "loui": 58, "martin": 58, "benjamin": 58, "muller": 58, "pedro": 58, "javier": 58, "ortiz": 58, "su\u00e1rez": 58, "yoann": 58, "dupont": 58, "laurent": [58, 183], "romari": 58, "\u00e9ric": 58, "villemont": 58, "la": [58, 111], "clergeri": 58, "djam\u00e9": 58, "seddah": 58, "beno\u00eet": 58, "sagot": 58, "facebook": [58, 60, 72, 73], "138gb": 58, "camembert_bas": 58, "camembertembeddingstestspec": 58, "co": [58, 80], "ubiquit": 58, "despit": 58, "most": [58, 61, 65, 80, 95, 109, 111, 112, 182], "concaten": [58, 127, 177, 182], "practic": [58, 112], "except": [58, 90, 95, 125, 169, 184], "investig": [58, 61, 69], "feasibl": 58, "monolingu": [58, 72, 73], "crawl": [58, 112], "prefer": [58, 77, 134], "wikipedia": [58, 82, 109], "surprisingli": [58, 69], "rel": [58, 60, 72, 85, 87, 94, 113, 204], "4gb": 58, "those": [58, 77, 96, 182, 205, 206], "larger": [58, 61, 66, 67, 109, 111, 112], "130": 58, "gb": 58, "reach": [58, 80, 109], "four": [58, 105, 124], "un": [58, 82], "08442357927560806": 58, "12863239645957947": 58, "03835778683423996": 58, "200479581952": 58, "048462312668561935": 58, "12637358903884888": 58, "27429091930389404": 58, "07516729831": 58, "02690504491329193": 58, "12104076147079468": 58, "012526623904705048": 58, "031543646007": 58, "05877285450696945": 58, "08773420006036758": 58, "06381352990865707": 58, "122621834278": 58, "fr": [58, 82], "chunkembed": [59, 132], "util": [59, 94, 104, 105, 116, 141, 148, 149, 151, 153, 156, 157, 161, 165], "wordembed": [59, 68, 71, 95, 132, 156], "chunker": [59, 78, 156], "ngramgener": [59, 90], "nerconvert": [59, 93, 94, 95, 163, 201], "poolingstrategi": [59, 68], "aggreg": [59, 68], "sum": [59, 63, 68, 183], "skipoov": 59, "discard": 59, "oov": 59, "ngram": [59, 90, 109, 112], "setn": [59, 90], "wordembeddingsmodel": [59, 68, 71, 77, 94, 95, 96, 132], "setpoolingstrategi": [59, 68], "55661": 59, "42829502": 59, "86661": 59, "409785": 59, "06316501": 59, "120775": 59, "0732005": 59, "40674996": 59, "22938299": 59, "50597": 59, "288195": 59, "555655": 59, "465145": 59, "140118": 59, "17417": 59, "095253006": 59, "0530925": 59, "218465": 59, "714395": 59, "79860497": 59, "0129999": 59, "139705": 59, "177955": 59, "1887775": 59, "45545": 59, "20030999": 59, "461557": 59, "07891501": 59, "strategi": [59, 68, 88, 104, 113], "setskipoov": 59, "debertaembed": 60, "decod": [60, 65, 109, 111, 112], "enhanc": [60, 108], "disentangl": 60, "pengcheng": 60, "xiaodong": 60, "liu": [60, 66, 67], "jianfeng": 60, "gao": 60, "weizhu": 60, "chen": [60, 66, 67, 183], "2018": [60, 66, 67, 183], "mask": [60, 72, 73, 74, 123], "half": [60, 80], "deberta_v3_bas": 60, "microsoft": [60, 111], "www": 60, "blog": 60, "surpass": 60, "human": [60, 80], "superglu": 60, "progress": [60, 105, 123], "significantli": [60, 63, 66, 67, 72, 73, 80], "novel": [60, 74, 80], "mechan": [60, 65], "respect": [60, 71, 94, 95, 183, 195], "weight": [60, 63, 80, 94, 96, 113, 181, 183], "among": 60, "matric": [60, 181, 183], "second": [60, 63, 88, 104, 118, 123, 183, 205], "predict": [60, 95, 109, 112, 163, 183, 201], "effici": [60, 62, 69, 70, 111, 177, 178, 181, 182, 204], "achiev": [60, 65, 66, 67, 72, 73, 74, 95, 109, 111, 112, 139, 183, 209], "mnli": 60, "9": [60, 72, 73, 90, 204, 209, 210], "90": 60, "91": 60, "88": 60, "made": [60, 69, 201], "publicli": [60, 72, 73], "distilbertembed": 61, "fast": [61, 108, 111, 139, 183, 209], "cheap": 61, "distil": 61, "40": [61, 96, 111], "uncas": 61, "60": [61, 104], "preserv": [61, 93, 123, 143], "over": [61, 72, 73, 74, 115, 125, 155, 163, 178, 201], "95": 61, "measur": [61, 66, 67, 163], "distilbert_base_cas": 61, "doesn": [61, 66, 183], "t": [61, 66, 83, 97, 105, 107, 125, 129, 133, 182, 183], "token_type_id": [61, 66], "don": [61, 66, 97], "indic": [61, 66, 123, 127], "belong": [61, 66], "separ": [61, 66, 88, 90, 104, 105, 115, 125, 127, 133, 155, 192, 203], "sep_token": [61, 66], "sep": 61, "position_id": 61, "ad": [61, 63, 113, 177], "though": [61, 80], "know": [61, 111, 141], "smaller": [61, 62, 70, 182], "cheaper": 61, "lighter": 61, "preval": 61, "oper": [61, 65, 113, 122, 177, 178, 182, 183, 204], "edg": [61, 77], "constrain": 61, "budget": 61, "purpos": [61, 105], "counterpart": 61, "prior": [61, 65, 113], "leverag": [61, 163, 201], "phase": [61, 183], "reduc": [61, 115, 116, 143, 181, 183], "retain": 61, "97": [61, 85, 87, 127], "capabl": [61, 74, 109], "being": [61, 95, 99, 111, 112, 183], "induct": 61, "bias": [61, 179, 181, 183], "tripl": [61, 77], "combin": [61, 65, 71, 80, 112, 113, 115, 182, 183], "cosin": 61, "distanc": [61, 113, 115, 116], "demonstr": [61, 65, 80, 109, 111], "devic": 61, "proof": 61, "concept": [61, 206], "experi": [61, 74, 163, 202], "studi": [61, 66, 67, 112], "1127224713563919": 61, "1982710212469101": 61, "5360898375511169": 61, "272536993026733": 61, "35534414649009705": 61, "13215228915214539": 61, "40981462597846985": 61, "14036104083061": 61, "328085333108902": 61, "06269335001707077": 61, "017595693469047546": 61, "024373905733": 61, "15617232024669647": 61, "2967822253704071": 61, "22324979305267334": 61, "04568954557180": 61, "45411425828933716": 61, "01173491682857275": 61, "190129816532135": 61, "1178255230188369": 61, "doc2vecapproach": 62, "word2vec": [62, 64, 78], "corpu": [62, 63, 70, 80, 83, 102, 112, 113, 195, 211], "algorithm": [62, 70, 80, 94, 108, 113, 115, 116], "construct": [62, 70, 125, 166, 178, 183, 208], "vocabulari": [62, 70, 109, 112, 113], "skip": [62, 70, 77, 113], "gram": [62, 70, 80, 90, 109, 112], "hierarch": [62, 70], "variabl": [62, 70, 179, 181, 183], "doc2vecmodel": 62, "vectors": [62, 70], "windows": [62, 70, 80], "window": [62, 65, 70, 80, 95, 113], "numpartit": [62, 70], "partit": [62, 70, 192], "mincount": [62, 70, 113], "must": [62, 70, 83, 84, 88, 89, 99, 107, 108, 115, 116, 130, 155, 156, 163, 178, 181, 182, 183, 192], "appear": [62, 70, 113], "ani": [62, 69, 70, 75, 80, 95, 109, 112, 132, 133, 182, 202, 205, 206, 211], "divid": [62, 70], "1000": [62, 70, 77, 94, 183], "stepsiz": [62, 70], "optim": [62, 66, 67, 70, 95, 105], "025": [62, 70], "maxit": [62, 70], "estim": [62, 70, 119, 135, 144, 152, 162, 205], "space": [62, 70, 71, 90, 143, 182, 183], "distribut": [62, 70, 180], "composition": [62, 70], "sherlockholm": [62, 70, 113, 211], "setvectors": [62, 70], "setwindows": [62, 70, 80], "setsteps": [62, 70], "initi": [62, 70, 113, 123, 141, 156, 177, 179, 181, 182, 183, 192, 193, 195, 196, 201], "setnumpartit": [62, 70], "setmaxit": [62, 70], "numiter": [62, 70], "equal": [62, 70, 183], "setse": [62, 70], "setmincount": [62, 70, 113], "doc2vec_gigaword_300": 62, "06222493574023247": [62, 70], "011579325422644615": [62, 70], "009919632226228714": [62, 70], "109361454844": [62, 70], "doc2vec_wiki": 62, "elmoembed": 63, "elmo": 63, "billion": [63, 109], "computation": [63, 66, 67, 74, 109, 111, 112], "expens": [63, 66, 67, 74, 107, 109, 111, 112, 115], "lookup": [63, 71, 74, 84, 115, 116], "acceler": [63, 74, 109, 111, 112, 156, 183], "setpoolinglay": 63, "word_emb": 63, "shape": [63, 181, 182, 183], "batch_siz": [63, 181, 182, 183], "max_length": 63, "lstm_outputs1": 63, "lstm": [63, 95, 181, 183], "lstm_outputs2": 63, "trainabl": [63, 183], "tensor": [63, 181, 182, 183], "poolinglay": 63, "contextu": [63, 113], "complex": [63, 69, 80, 115, 116, 178], "characterist": 63, "syntax": 63, "semant": [63, 69, 127], "vari": 63, "across": [63, 109], "linguist": 63, "polysemi": 63, "intern": [63, 98, 99, 125, 142, 146, 150, 156, 183], "bilm": 63, "exist": [63, 113, 132, 134, 163, 183], "six": [63, 115, 116], "textual": 63, "entail": 63, "expos": 63, "crucial": 63, "mix": [63, 145, 162], "semi": 63, "signal": [63, 183], "662458181381226e": 63, "2541114091873169": 63, "6275503039360046": 63, "5787073969841": 63, "19154725968837738": 63, "22998669743537903": 63, "2894386649131775": 63, "21524395048618": 63, "10400570929050446": 63, "12288510054349899": 63, "07056470215320587": 63, "246389418840": 63, "49932169914245605": 63, "12706467509269714": 63, "30969417095184326": 63, "2643227577209": 63, "8871506452560425": 63, "20039963722229004": 63, "0601330995559692": 63, "0348707810044": 63, "albert_embed": [64, 78], "bert_embed": [64, 78], "bert_sentence_embed": [64, 78], "camembert_embed": [64, 78], "chunk_embed": [64, 78], "deberta_embed": [64, 78], "distil_bert_embed": [64, 78], "doc2vec": [64, 78], "elmo_embed": [64, 78], "longformer_embed": [64, 78], "roberta_embed": [64, 78], "roberta_sentence_embed": [64, 78], "universal_sentence_encod": [64, 78], "xlm_roberta_embed": [64, 78], "xlm_roberta_sentence_embed": [64, 78], "xlnet_embed": [64, 78], "longformerembed": 65, "iz": 65, "beltagi": 65, "matthew": 65, "arman": 65, "cohan": 65, "checkpoint": 65, "mlm": 65, "096": 65, "longformer_base_4096": 65, "unabl": 65, "quadrat": 65, "linearli": 65, "easi": 65, "thousand": 65, "drop": [65, 118], "motiv": 65, "global": 65, "text8": 65, "enwik8": 65, "contrast": [65, 84, 112], "finetun": [65, 74], "varieti": [65, 72, 73, 210], "outperform": [65, 69, 72, 73, 74, 80, 109], "wikihop": 65, "triviaqa": 65, "led": [65, 66, 67, 80], "effect": [65, 104, 112, 178], "arxiv": [65, 179, 181, 182, 183], "summar": [65, 80, 109, 111, 112], "found": [65, 71, 80, 115, 122, 130, 208], "18792399764060974": [65, 66], "14591649174690247": [65, 66], "20547787845134735": [65, 66], "1468472778797": [65, 66], "22845706343650818": [65, 66], "18073144555091858": [65, 66], "09725798666477203": [65, 66], "0417917296290": [65, 66], "07037967443466187": [65, 66], "14801117777824402": [65, 66], "03603338822722435": [65, 66], "17893412709": [65, 66], "08734266459941864": [65, 66], "2486150562763214": [65, 66], "009067727252840996": [65, 66], "24408400058": [65, 66], "22409197688102722": [65, 66], "4312366545200348": [65, 66], "1401449590921402": [65, 66], "356410235166549": [65, 66], "robertaembed": [66, 72], "robustli": [66, 67], "approach": [66, 67, 74, 80, 92, 94, 95, 105, 107, 109, 112, 113, 115, 116, 144, 208], "yinhan": [66, 67], "myle": [66, 67, 72, 73], "ott": [66, 67, 72, 73], "naman": [66, 67, 72, 73], "goyal": [66, 67, 72, 73], "jingfei": [66, 67], "du": [66, 67, 82], "mandar": [66, 67], "joshi": [66, 67], "danqi": [66, 67], "omer": [66, 67], "levi": [66, 67], "mike": [66, 67], "lewi": [66, 67], "luke": [66, 67, 72, 73], "zettlemoy": [66, 67, 72, 73], "veselin": [66, 67, 72, 73], "stoyanov": [66, 67, 72, 73], "hyperparamet": [66, 67], "next": [66, 67, 80, 85, 87, 109, 112, 182], "mini": [66, 67], "roberta_bas": 66, "bpe": 66, "gpt": [66, 109], "scheme": [66, 179], "signific": [66, 67, 72, 73, 80, 83], "gain": [66, 67, 72, 73, 183], "care": [66, 67, 125], "comparison": [66, 67, 69, 118], "choic": [66, 67, 88], "impact": [66, 67], "replic": [66, 67], "carefulli": [66, 67], "undertrain": [66, 67], "exce": [66, 67], "highlight": [66, 67], "previous": [66, 67, 80], "overlook": [66, 67], "rais": [66, 67, 80, 90, 95, 163, 181, 182, 183], "report": [66, 67, 69, 163, 201], "robertasentenceembed": 67, "sent_roberta_bas": 67, "embeddingssent": 68, "22093398869037628": 68, "25130119919776917": 68, "41810303926467896": 68, "380883991718": 68, "high": [69, 72, 73, 111], "dimension": [69, 183], "cluster": [69, 156], "tfhub_us": 69, "loadsp": 69, "op": [69, 179, 180, 181], "lingual": [69, 72, 73, 80, 82, 111], "target": [69, 111, 125, 130, 139, 166], "accur": [69, 108, 115], "divers": [69, 109, 112, 202], "trade": [69, 72, 73, 182], "baselin": [69, 109, 183], "do": [69, 80, 93, 118, 125, 129, 139, 177, 182, 201, 205, 209], "tend": 69, "With": [69, 74, 80], "observ": 69, "minim": [69, 111, 182], "encourag": 69, "weat": 69, "detect": [69, 81, 82, 103, 104, 105], "bia": [69, 181, 183], "freeli": 69, "04616805538535118": 69, "022307956591248512": 69, "044395286589860916": 69, "0016493503": 69, "setloadsp": 69, "word2vecapproach": 70, "word2vecmodel": 70, "word2vec_gigaword_300": 70, "word2vec_wiki": 70, "custom": [71, 94, 95, 104, 105, 125, 163], "dictionari": [71, 80, 83, 88, 94, 96, 97, 107, 115, 116, 163], "setstoragepath": [71, 84], "line": [71, 75, 84, 89, 105, 107, 166, 195], "delimit": [71, 75, 77, 83, 88, 90, 94, 97, 107, 123, 142, 192, 195], "39658191506190343": 71, "630968081620067": 71, "5393722253731201": 71, "8428180123359783": 71, "were": [71, 95, 163, 201], "7535235923631415": 71, "9699218875629833": 71, "10397182122983872": 71, "11833962569383116": 71, "stress": 71, "0492683418305907": 71, "9415954572751959": 71, "47624463167525755": 71, "16790967216778263": 71, "induc": 71, "1535748762292387": 71, "33498936903209897": 71, "9235178224122094": 71, "1158772920395934": 71, "zero": [71, 109, 181, 182], "withcoveragecolumn": 71, "overallcoverag": 71, "writebuffers": 71, "dump": 71, "disk": [71, 205, 206], "storag": [71, 75, 84, 149, 156], "10000": 71, "readcaches": 71, "cach": 71, "higher": [71, 80, 108, 109, 112], "random_embeddings_dim4": 71, "abov": [71, 77, 181, 195], "setstorageref": 71, "glove_4d": 71, "setdimens": [71, 150], "patient": 71, "diagnos": 71, "diabet": 71, "9439099431037903": 71, "4707513153553009": 71, "806300163269043": 71, "16176554560661316": 71, "7966810464859009": 71, "5551124811172485": 71, "8861005902290344": 71, "28284206986427307": 71, "025029370561242104": 71, "35177749395370483": 71, "052506182342767715": 71, "1887107789516449": 71, "08617766946554184": 71, "8399239182472229": 71, "5395117998123169": 71, "7864698767662048": 71, "6599600911140442": 71, "16109347343444824": 71, "6041093468666077": 71, "8913561105728149": 71, "5955275893211365": 71, "01899011991918087": 71, "4397728443145752": 71, "8911281824111938": 71, "9840458631515503": 71, "7599489092826843": 71, "9417727589607239": 71, "8624503016471863": 71, "setwritebuffers": 71, "setreadcaches": 71, "glove_100d": [71, 95], "There": [71, 75, 77, 122, 183, 203, 205, 206, 211], "conveni": 71, "coverag": [71, 148], "add": [71, 85, 87, 104, 109, 112, 113, 125, 181, 183, 205], "stat": 71, "field": [71, 75, 89, 183], "whole": [71, 166, 177], "consid": [71, 77, 80, 113, 115, 116, 118, 122], "570580005645752": 71, "44183000922203064": 71, "7010200023651123": 71, "417129993438720": 71, "542639970779419": 71, "4147599935531616": 71, "0321999788284302": 71, "4024400115013122": 71, "2708599865436554": 71, "04400600120425224": 71, "020260000601410866": 71, "17395000159": 71, "6191999912261963": 71, "14650000631809235": 71, "08592499792575836": 71, "2629800140857": 71, "3397899866104126": 71, "20940999686717987": 71, "46347999572753906": 71, "6479200124740": 71, "embeddings_col": 71, "coverageresult": 71, "coverateresult": 71, "wordsoverallcoverag": 71, "resultdf": 71, "percentag": [71, 113, 127], "output_col": 71, "wordscoverag": 71, "cov_embed": 71, "loadstorag": [71, 84], "storage_ref": [71, 84], "xlmrobertaembed": 72, "unsupervis": [72, 73, 74, 80, 109], "cross": [72, 73, 96], "alexi": [72, 73], "conneau": [72, 73], "kartikai": [72, 73], "khandelw": [72, 73], "vishrav": [72, 73], "chaudhari": [72, 73], "guillaum": [72, 73], "wenzek": [72, 73], "francisco": [72, 73, 80], "guzman": 72, "edouard": [72, 73], "grave": [72, 73, 183], "5tb": [72, 73], "filter": [72, 73, 80, 93, 94, 109, 111, 112, 118, 155], "commoncrawl": [72, 73], "xlm_roberta_bas": 72, "xx": [72, 73, 82, 111], "multilingu": [72, 73, 127], "doe": [72, 80, 93, 139, 141, 182, 183, 206, 209, 210], "abl": [72, 112, 163, 204], "determin": [72, 183], "correct": [72, 113, 115, 116, 127], "hundr": [72, 73], "terabyt": [72, 73], "dub": [72, 73], "r": [72, 73, 80, 179, 183], "mbert": [72, 73], "xnli": [72, 73], "mlqa": [72, 73], "particularli": [72, 73], "low": [72, 73, 113], "swahili": [72, 73], "urdu": [72, 73], "previou": [72, 73, 109, 183, 205], "factor": [72, 73, 74, 112, 113, 183], "capac": [72, 73, 109, 183], "dilut": [72, 73], "sacrif": [72, 73], "ri": [72, 73], "competit": [72, 73, 80], "strong": [72, 73], "05969233065843582": 72, "030789051204919815": 72, "04443822056055069": 72, "09564960747": 72, "038839809596538544": 72, "011712731793522835": 72, "019954433664679527": 72, "0667808502": 72, "03952755779027939": 72, "03455188870429993": 72, "019103847444057465": 72, "04311436787": 72, "09579929709434509": 72, "02494969218969345": 72, "014753809198737144": 72, "10259044915": 72, "004710011184215546": 72, "022148698568344116": 72, "011723337695002556": 72, "013356896": 72, "xlmrobertasentenceembed": 73, "guzm\u00e3": 73, "sent_xlm_roberta_bas": 73, "xlnetembed": 74, "autoregress": 74, "permut": 74, "addition": [74, 95, 102, 131, 140, 166], "emploi": 74, "xl": 74, "backbon": 74, "exhibit": 74, "involv": [74, 105], "sota": 74, "variou": [74, 199], "rank": [74, 113], "xlnet_large_cas": 74, "xlnet_base_cas": 74, "full": [74, 205], "zihangdai": 74, "denois": 74, "autoencod": 74, "corrupt": 74, "neglect": 74, "suffer": 74, "discrep": 74, "pro": 74, "con": 74, "enabl": [74, 75, 95, 115, 156, 180, 183], "maxim": [74, 113], "likelihood": 74, "overcom": 74, "formul": 74, "furthermor": 74, "integr": [74, 80, 111, 163, 183, 201, 203], "idea": [74, 183], "margin": 74, "6287205219268799": 74, "4865287244319916": 74, "186111718416214": 74, "234187275171279": 74, "1967450380325317": 74, "2746637463569641": 74, "9481253027915955": 74, "3431355059146881": 74, "0777631998062134": 74, "092679977416992": 74, "5331977605819702": 74, "11190271377563": 74, "8349916934967041": 74, "45627787709236145": 74, "7890847325325012": 74, "028069257736": 74, "134845569729805": 74, "11672890186309814": 74, "4945235550403595": 74, "66587203741073": 74, "entityrul": 75, "entityrulerapproach": 75, "exact": [75, 84, 89], "definit": [75, 192], "json": [75, 142, 163], "jsonl": 75, "setpatternsresourc": 75, "might": [75, 95, 127, 210], "setenablepatternregex": 75, "rule": [75, 88, 107, 122, 125], "person": [75, 193], "w": [75, 78, 88, 94, 97, 122, 125, 156, 183], "locat": [75, 104, 129, 156, 166, 205], "winterfel": 75, "j": [75, 183], "jon": 75, "snow": [75, 96, 113], "stark": 75, "eddard": 75, "patternsresourc": 75, "enablepatternregex": 75, "usestorag": 75, "rocksdb": 75, "lord": 75, "29": [75, 96, 195], "38": 75, "setusestorag": 75, "setsentencematch": 75, "setalphabetresourc": 75, "alphabet": [75, 97], "plain": [75, 211], "entityrulermodel": 75, "entity_rul": [76, 78], "graphextract": [77, 134], "graph": [77, 95, 111, 119, 134, 169, 184], "nerdlmodel": [77, 93, 94, 95, 96, 163, 201], "store": [77, 98, 99, 142, 146, 150, 161, 166, 183, 202], "node": [77, 183], "relev": [77, 80], "taken": 77, "implicitli": 77, "setmergeent": 77, "automat": [77, 80, 111, 115, 204, 205], "setdependencyparsermodel": 77, "settypeddependencyparsermodel": 77, "setrelationshiptyp": 77, "public": [77, 205], "relationshiptyp": 77, "pair": [77, 163, 181, 183], "entitytyp": 77, "explodeent": 77, "roottoken": 77, "travers": 77, "along": 77, "maxsentences": 77, "minsentences": 77, "below": [77, 210], "mergeent": 77, "merg": [77, 84, 89], "neighbor": 77, "includeedg": 77, "symbol": [77, 113, 127], "posmodel": 77, "coordin": [77, 104], "remoteloc": 77, "graphfinish": [77, 134], "rdf": [77, 134], "nertagg": [77, 94, 95, 96, 169, 184], "morn": [77, 134], "flight": [77, 134], "denver": [77, 134], "18": [77, 85, 87, 90, 93, 96, 139, 155, 166, 204], "path1": 77, "setentitytyp": 77, "setexplodeent": 77, "setroottoken": 77, "setmaxsentences": 77, "setminsentences": 77, "setmergeentitiesiobformat": 77, "iob": [77, 93, 94, 95], "iob2": [77, 93], "setincludeedg": 77, "setdelimit": [77, 88, 90], "setposmodel": 77, "classifier_dl": [78, 156], "er": [78, 156], "keyword_extract": [78, 156], "yake_keyword_extract": [78, 79], "ld_dl": [78, 156], "language_detector_dl": [78, 81], "matcher": [78, 156], "big_text_match": [78, 86], "date_match": [78, 86], "multi_date_match": [78, 86], "regex_match": [78, 86], "text_match": [78, 86], "ner_approach": [78, 91], "ner_convert": [78, 91], "ner_crf": [78, 91], "ner_dl": [78, 91, 169, 184], "ner_overwrit": [78, 91], "param": [78, 94, 145, 146, 150, 156, 161, 162, 169, 184], "sentence_detector_dl": [78, 103, 111], "sentiment_detector": [78, 106], "vivekn_senti": [78, 106], "seq2seq": [78, 156], "gpt2_transform": [78, 110], "marian_transform": [78, 110], "t5_transform": [78, 110], "spell_check": [78, 156], "context_spell_check": [78, 114], "norvig_sweet": [78, 114], "symmetric_delet": [78, 114], "chunk_token": [78, 121], "recursive_token": [78, 121], "regex_token": [78, 121], "token2_chunk": [78, 121], "word_segment": [78, 126], "document_norm": [78, 156], "graph_extract": [78, 156], "lemmat": [78, 107, 118, 141, 143, 156], "n_gram_gener": [78, 156], "stemmer": [78, 118, 156], "stop_words_clean": [78, 156], "yakekeywordextract": 80, "yake": 80, "independ": [80, 115, 116, 122, 183], "domain": [80, 109], "individu": [80, 113], "organ": [80, 111], "grow": 80, "autom": 80, "adequ": 80, "manner": 80, "emerg": [80, 112], "tool": 80, "system": [80, 109, 183], "nor": 80, "thesauri": 80, "neither": 80, "corpora": [80, 84], "upon": 80, "thu": 80, "written": [80, 111], "benefici": 80, "plethora": 80, "situat": [80, 105], "access": 80, "restrict": 80, "therefor": [80, 180, 183, 209], "sent": 80, "boundari": [80, 104, 105, 108, 125], "detector": [80, 85, 107], "section": [80, 131, 140, 201, 203, 209], "tweakabl": 80, "greater": 80, "upper": 80, "bound": [80, 104, 105, 108], "minngram": 80, "maxngram": 80, "occurr": 80, "nkeyword": 80, "stopword": [80, 96, 118], "stop": [80, 94, 118], "campo": 80, "mangaravit": 80, "pasquali": 80, "jatowt": 80, "jorg": 80, "nune": 80, "2020": [80, 85, 87, 105], "scienc": [80, 202], "journal": 80, "elsevi": 80, "vol": 80, "509": 80, "pp": 80, "257": 80, "289": 80, "collect": [80, 163, 201], "turn": [80, 143, 183, 205], "come": 80, "term": [80, 181, 183], "fly": 80, "demand": 80, "abil": [80, 109], "within": [80, 102, 108, 109, 125, 130], "resort": 80, "alwai": [80, 112], "solut": 80, "articl": [80, 113], "rest": [80, 93], "merit": 80, "ten": 80, "experiment": 80, "carri": 80, "twenti": 80, "setcontextchar": [80, 125], "setminngram": 80, "setnkeyword": 80, "acquir": 80, "kaggl": 80, "platform": [80, 163, 203], "host": 80, "transact": 80, "somewhat": 80, "vagu": 80, "cloud": 80, "confer": 80, "week": [80, 85, 87, 120], "announc": [80, 96], "earli": 80, "tomorrow": [80, 85, 87], "phone": 80, "founder": 80, "ceo": 80, "anthoni": 80, "goldbloom": 80, "declin": 80, "deni": 80, "acquisit": 80, "happen": 80, "rumor": 80, "million": [80, 96, 109], "scientist": 80, "ben": 80, "hamner": 80, "2010": 80, "servic": [80, 111], "got": 80, "even": [80, 112], "few": [80, 125, 195, 211], "competitor": 80, "drivendata": 80, "topcod": 80, "hackerrank": 80, "stai": 80, "ahead": 80, "nich": 80, "home": [80, 156], "bui": [80, 193], "commun": 80, "mindshar": 80, "too": [80, 107, 204], "plenti": 80, "bit": [80, 105, 182, 210], "histori": [80, 105, 113], "earlier": 80, "month": [80, 85, 87, 195, 211], "team": [80, 111, 163, 201], "around": 80, "youtub": 80, "That": [80, 122, 163, 201, 206], "had": 80, "technologi": 80, "did": 80, "interest": 80, "kernel": [80, 179], "On": [80, 109, 111], "analyz": [80, 108], "compani": [80, 111], "script": 80, "centric": 80, "job": [80, 130], "board": [80, 102, 195], "unclear": 80, "accord": [80, 113, 192], "crunchbas": 80, "pitchbook": 80, "launch": 80, "investor": 80, "ventur": 80, "sv": 80, "angel": 80, "levchin": 80, "naravik": 80, "chie": 80, "economist": 80, "hal": 80, "varian": 80, "khosla": 80, "yuri": 80, "milner": 80, "resulttupl": 80, "ascend": 80, "orderbi": 80, "32051516486864573": 80, "37786450577630676": 80, "39922830978423146": 80, "40224744669493756": 80, "41584827825302534": 80, "setmaxngram": 80, "setstopword": [80, 96, 118], "getstopword": 80, "loaddefaultstopword": [80, 118], "danish": [80, 118], "dutch": [80, 118], "finnish": [80, 118], "german": [80, 118, 192, 211], "hungarian": [80, 118], "italian": [80, 113, 118], "norwegian": [80, 118], "portugues": [80, 118], "russian": [80, 118], "spanish": [80, 118], "swedish": [80, 118], "turkish": [80, 118], "languagedetectordl": 82, "ld": 82, "identif": 82, "rnn": [82, 170, 177, 178, 180, 181, 183], "tatoeba": 82, "140": 82, "wiki": 82, "languagedetector": 82, "ld_wiki_tatoeba_cnn_21": 82, "open": [82, 125, 130, 131, 132, 140, 143, 202], "advanc": [82, 130, 143], "scala": [82, 144, 145, 152, 158, 162], "program": 82, "biblioth\u00e8qu": 82, "traitement": 82, "pour": 82, "le": [82, 111, 183], "avanc\u00e9": 82, "langag": 82, "naturel": 82, "programm": 82, "ist": 82, "ein": 82, "textverarbeitungsbibliothek": 82, "f\u00fcr": 82, "fortgeschritten": 82, "nat\u00fcrlich": 82, "sprachverarbeitung": 82, "die": 82, "programmiersprachen": 82, "und": 82, "lemma": [83, 107, 139, 166, 193, 206, 209, 210], "predefin": [83, 84, 88, 89, 107], "setdictionari": [83, 107, 115, 116], "lemmatizermodel": 83, "lemmas_smal": [83, 107], "setformcol": 83, "correspend": 83, "formcol": [83, 193], "setlemmacol": 83, "fromlemma": 83, "key_delimit": 83, "value_delimit": 83, "lemma_antbnc": 83, "bigtextmatch": [84, 89], "textmatch": [84, 89, 120], "externalresourc": [84, 89, 154], "mergeoverlap": [84, 89], "overlap": [84, 89], "tokenizermodel": [84, 125], "trie": 84, "dolor": [84, 89], "magna": [84, 89], "aliqua": [84, 89], "sit": [84, 89], "laborum": [84, 89], "hello": [84, 89, 120], "entityextractor": [84, 89, 120], "extractor": [84, 89, 120], "53": [84, 89], "59": [84, 85, 87, 89], "setent": [84, 89, 92, 120], "setmergeoverlap": [84, 89], "settoken": 84, "tokenizer_model": 84, "bigtextmatchermodel": 84, "btm": 84, "textmatchermodel": [84, 89], "searchtri": 84, "datematch": 85, "datematcherutil": 85, "setinputformat": [85, 142], "setoutputformat": [85, 87], "desir": [85, 87], "yyyi": [85, 87], "mm": [85, 87], "dd": [85, 87, 88], "Not": [85, 95, 141], "setreadmonthfirst": 85, "juli": 85, "5th": 85, "2015": [85, 183], "07": 85, "05": 85, "setdefaultdaywhenmiss": 85, "dai": [85, 87, 113], "miss": [85, 87, 130], "setanchordateyear": [85, 87], "anchor": [85, 87], "year": [85, 87, 109, 120, 195], "2021": [85, 87], "setanchordatemonth": [85, 87], "januari": [85, 87], "setanchordatedai": [85, 87], "multidatematch": [85, 87], "1978": [85, 87], "01": [85, 87, 88], "28": [85, 87, 93, 139, 155, 166, 204], "1984": [85, 87], "04": [85, 87], "02": [85, 87], "1980": [85, 87], "79": [85, 87], "31st": [85, 87], "april": [85, 87], "2008": [85, 87], "fri": [85, 87], "nov": [85, 87, 195], "1997": [85, 87], "jan": [85, 87], "sun": [85, 87], "1st": [85, 87], "thursdai": [85, 87], "wednesdai": [85, 87], "todai": [85, 87], "yesterdai": [85, 87], "0600h": [85, 87], "06": [85, 87], "00": [85, 87], "hour": [85, 87], "6pm": [85, 87], "23": [85, 87, 88, 96, 102, 195, 196, 211], "1988": [85, 87], "31": [85, 87, 88, 96, 102, 195], "dateformat": [85, 87], "readmonthfirst": [85, 87], "defaultdaywhenmiss": [85, 87], "anchordateyear": [85, 87], "anchordatemonth": [85, 87], "anchordatedai": [85, 87], "15": 85, "saw": 87, "him": 87, "me": 87, "visit": 87, "57": [87, 96], "65": [87, 96], "regexmatch": 88, "d": [88, 97, 125, 181, 183, 203], "1970": 88, "setrul": 88, "setexternalrul": 88, "match_first": 88, "match_al": 88, "match_complet": 88, "externalrul": 88, "ceremoni": 88, "setstrategi": 88, "71": 88, "short_dat": 88, "regexmatchermodel": 88, "regardless": 89, "entityvalu": 89, "buildfromtoken": 89, "27": [89, 102, 104, 195], "48": 89, "setentityvalu": 89, "setbuildfromtoken": 89, "null": 90, "empti": [90, 130, 182], "enablecumul": 90, "actual": [90, 129, 133, 143, 182], "join": [90, 102, 142, 195], "19": [90, 195], "setenablecumul": 90, "nerapproach": 92, "recogn": [92, 93, 94, 95, 96], "setminepoch": [92, 94], "setrandomse": [92, 95, 98, 169, 184], "getlabelcolumn": [92, 119], "friendli": [93, 111], "whitelist": [93, 122], "setwhitelist": [93, 122], "outsid": 93, "prefix": [93, 122, 125, 163, 201], "preserveposit": [93, 123, 143], "continu": [93, 109, 134, 183, 201], "org": [93, 94, 95, 96, 139, 155, 156, 166, 179, 181, 182, 183, 192, 202, 211], "14": [93, 102, 124, 139, 155, 166, 195], "ekeu": [93, 94, 95, 139, 155, 166], "26": [93, 139, 155, 166], "36": [93, 102, 139, 155, 166, 195], "baghdad": [93, 94, 95, 139, 155, 166], "37": [93, 139, 155, 166], "setpreserveposit": [93, 123, 143], "nercrf": 94, "nercrfapproach": [94, 95], "nercrfmodel": [94, 95], "crf": [94, 95], "2003": [94, 95, 192, 211], "exclud": [94, 95], "setexternalfeatur": 94, "minepoch": [94, 95], "l2": 94, "c0": 94, "decai": [94, 95], "gradient": 94, "2250000": 94, "lossep": 94, "ep": 94, "minw": 94, "includeconfid": [94, 95], "confid": [94, 95], "externalfeatur": 94, "nerdlapproach": [94, 95, 184, 192, 211], "trainingdata": [94, 95, 105, 115, 116, 192], "readdataset": [94, 95, 102, 127, 192, 193, 195, 196, 211], "conll2003": [94, 95, 192, 211], "eng": [94, 95, 192, 211], "setl2": 94, "l2valu": 94, "setc0": 94, "c0valu": 94, "setlossep": 94, "setminw": 94, "setincludeconfid": [94, 95, 169, 184], "verbosevalu": 94, "prerequisit": [94, 95, 96, 205], "nerdl": 95, "char": [95, 97, 105], "bilstm": 95, "tagger": [95, 195, 211], "50": [95, 96, 102, 109, 183], "real": [95, 156, 163, 183, 201], "rage": 95, "graphfold": 95, "usecontrib": 95, "contrib": [95, 178, 180], "cell": [95, 142, 177, 178, 179, 181, 182, 183], "slightli": [95, 105], "includeallconfidencescor": 95, "enablememoryoptim": 95, "slow": 95, "down": [95, 205, 206], "usebestmodel": 95, "bestmodelmetr": 95, "check": [95, 104, 113, 114, 115, 116, 139, 143, 166], "micro": 95, "macro": 95, "setgraphfold": [95, 119, 169, 184], "setusecontrib": 95, "setpo": 95, "setincludeallconfidencescor": 95, "setenablememoryoptim": [95, 169, 184], "setusebestmodel": 95, "setbestmodelmetr": 95, "nermodel": 95, "neroverwrit": 96, "specifi": [96, 105, 181, 183, 192, 193], "setnewresult": 96, "nerword": 96, "overwritten": 96, "newnerent": 96, "lab": 96, "42": [96, 102], "45": [96, 102, 195], "47": [96, 195], "66": 96, "ner_overwritten": 96, "setnerword": 96, "setnewnerent": 96, "cardin": 96, "setreplaceent": 96, "rw": 96, "stem": [97, 117, 139, 166, 209, 210], "henc": [97, 183], "pl": 97, "slangdictionari": 97, "slang": 97, "minlength": [97, 104, 105, 123, 125], "maxlength": [97, 104, 105, 123, 125], "setcleanuppattern": 97, "punctuat": [97, 104], "alphanumer": 97, "letter": [97, 109, 113, 195, 211], "za": 97, "z": [97, 125], "brother": 97, "dont": [97, 108], "setslangdictionari": 97, "setminlength": [97, 104, 105, 123, 125], "setmaxlength": [97, 104, 105, 123, 125], "normalizermodel": 97, "classifierencod": 98, "attach": [98, 99, 146, 150, 161, 163], "evaluationdlparam": 99, "setevaluationlogextend": [99, 169, 184], "setenableoutputlog": [99, 163, 169, 184, 201], "setoutputlogspath": [99, 105, 163, 169, 184, 201], "assum": 99, "perceptronapproach": [102, 195, 211], "datasetpath": 102, "pierr": [102, 195], "vinken": [102, 195], "34": [102, 195], "md": [102, 195], "vb": [102, 192, 195, 211], "41": [102, 104, 195], "43": [102, 104, 195], "dt": [102, 195, 196, 211], "49": [102, 195], "poscol": [102, 127, 192], "niter": [102, 127], "anc": [102, 195, 211], "trainingperceptrondf": 102, "trainedpo": 102, "setposcolumn": [102, 127], "cd": [102, 192, 195], "setiter": 102, "getniter": [102, 127], "pos_anc": 102, "25": [102, 104, 195], "33": 102, "sentencedetectorparam": 104, "ii": 104, "abbrevi": 104, "period": 104, "geo": 104, "1026": 104, "253": 104, "553": 104, "ellipsi": 104, "quotat": 104, "mark": [104, 105, 127, 183], "exclam": 104, "breaker": 104, "explicit": [104, 109], "pragmaticcontentformatt": 104, "custombound": [104, 105], "setcustombound": [104, 105], "usecustomboundsonli": [104, 105], "explodesent": [104, 105, 192, 193], "useabbrevi": 104, "explicitli": [104, 105, 118, 155, 205], "customboundsstrategi": 104, "prepend": [104, 130], "break": 104, "append": [104, 113, 205], "parallel": [104, 105, 139, 182, 192, 209], "splitlength": [104, 105], "forcibli": [104, 105], "split": [104, 105, 120, 122, 123, 127, 177, 183], "99999": [104, 105, 125], "detectlist": 104, "nhow": 104, "setcustomboundsstrategi": 104, "setuseabbrevi": 104, "setdetectlist": 104, "setusecustomboundsonli": [104, 105], "setexplodesent": [104, 105], "setsplitlength": [104, 105], "sentencedetectordl": 105, "sentencedetectordlapproach": 105, "futur": [105, 112], "setmodel": 105, "sentencedetectordlmodel": [105, 111], "modelarchitectur": 105, "impossiblepenultim": 105, "imposs": [105, 127], "penultim": 105, "epochsnumb": 105, "eo": 105, "stefan": 105, "schweter": 105, "sajawel": 105, "ahm": 105, "littl": [105, 210], "cover": [105, 112, 127], "broken": 105, "moder": 105, "lack": 105, "easier": [105, 133, 207, 211], "polit": 105, "successor": 105, "great": 105, "respons": 105, "heritag": 105, "bequeath": 105, "nelson": 105, "mandela": 105, "setepochsnumb": 105, "model_architectur": 105, "validation_split": 105, "epochs_numb": 105, "output_logs_path": 105, "setimpossiblepenultim": 105, "impossible_penultim": 105, "sentencedl": 105, "sentencesdl": 105, "helen": 105, "total": [105, 127], "peopl": 105, "sentimentdetector": 107, "By": [107, 112, 118, 123, 132, 156, 163, 201], "viveknsentimentapproach": [107, 108], "cool": 107, "superb": 107, "uninspir": 107, "sentimentscor": 107, "staff": 107, "restaur": 107, "nice": [107, 163, 201], "avoid": [107, 182, 183], "entri": [107, 131, 140], "sttr": 107, "sentimentdetectormodel": 107, "sda": [107, 108], "pragmat": 107, "viveknsenti": 108, "analys": 108, "inspir": [108, 115, 116, 159], "vivek": 108, "narayanan": 108, "give": 108, "transit": [108, 113], "sentimentcol": 108, "prunecorpu": 108, "unfrequ": 108, "scenario": 108, "naiv": 108, "bay": 108, "vivekn": 108, "setsentimentcol": 108, "train_senti": 108, "result_senti": 108, "finish": [108, 132, 134, 138, 141, 156], "final_senti": 108, "cast": [108, 128], "horribl": 108, "never": [108, 205], "go": [108, 205], "again": [108, 122], "anyon": 108, "protagonist": 108, "music": 108, "setprunecorpu": 108, "frequenc": [108, 113, 115, 116, 127, 183], "viveknsentimentmodel": 108, "sentiment_vivekn": 108, "gpt2transform": 109, "gpt2": 109, "openai": 109, "caus": [109, 125], "goal": 109, "occur": [109, 112], "direct": [109, 182, 183], "10x": 109, "broad": 109, "synthet": 109, "sampl": [109, 112], "unpreced": 109, "qualiti": 109, "prime": 109, "lengthi": 109, "translat": [109, 111, 112], "far": [109, 129, 133], "suggest": 109, "benefit": 109, "suffici": 109, "minoutputlength": [109, 112], "maxoutputlength": [109, 111, 112], "dosampl": [109, 112], "greedi": [109, 112], "temperatur": [109, 112], "topk": [109, 112], "highest": [109, 112, 115], "k": [109, 112, 132, 183], "topp": [109, 112], "cumul": [109, 112], "kept": [109, 112], "repetitionpenalti": [109, 112], "repetit": [109, 112], "penalti": [109, 112, 182], "norepeatngrams": [109, 112], "onc": [109, 112, 178], "ignoretokenid": [109, 112], "especi": [109, 111, 112], "multitask": 109, "learner": 109, "typic": [109, 182], "taskspecif": 109, "webpag": [109, 202], "webtext": 109, "plu": 109, "coqa": 109, "exceed": 109, "127": 109, "shot": 109, "fashion": 109, "5b": 109, "still": [109, 163], "underfit": 109, "reflect": 109, "paragraph": 109, "promis": 109, "toward": 109, "setmaxoutputlength": [109, 111, 112], "leonardo": 109, "man": 109, "1776": 109, "came": 109, "unit": [109, 119, 181, 183], "kingdom": 109, "settask": [109, 112], "setignoretokenid": [109, 111, 112], "setminoutputlength": [109, 112], "setdosampl": [109, 112], "settemperatur": [109, 112], "settopk": [109, 112], "settopp": [109, 112], "setrepetitionpenalti": [109, 112], "ctrl": [109, 112], "control": [109, 111, 112, 113, 183], "setnorepeatngrams": [109, 112], "mariantransform": 111, "marian": 111, "free": [111, 183], "mainli": 111, "academ": 111, "notabl": 111, "edinburgh": 111, "past": 111, "adam": 111, "mickiewicz": 111, "pozna\u0144": 111, "commerci": 111, "contributor": 111, "mariannmt": 111, "engin": [111, 120], "behind": 111, "deploi": [111, 202], "opus_mt_en_fr": 111, "langid": 111, "maxinputlength": 111, "differenti": 111, "dynam": [111, 182, 183], "toolkit": 111, "setmaxinputlength": 111, "capit": [111, 113], "franc": 111, "quell": 111, "capital": 111, "devrait": 111, "savoir": 111, "fran\u00e7ai": 111, "setlangid": 111, "t5transform": 112, "t5": 112, "reconsid": 112, "unifi": 112, "hyper": 112, "t5_small": 112, "explor": 112, "rich": 112, "rise": 112, "methodologi": 112, "landscap": 112, "systemat": 112, "dozen": 112, "insight": 112, "coloss": 112, "facilit": 112, "200": [112, 169, 183, 184], "contextspellcheck": 113, "contextspellcheckerapproach": [113, 115, 116], "noisi": 113, "spell": [113, 114, 115, 116, 139, 143, 208, 209, 210], "candid": [113, 115, 116, 125], "contextspellcheckermodel": [113, 115, 116], "potenti": 113, "error": [113, 183], "three": [113, 124], "thing": [113, 129, 133], "surround": [113, 142], "edit": [113, 115, 116], "subword": 113, "checker": [113, 115, 116, 208], "languagemodelclass": 113, "lm": 113, "wordmaxdist": 113, "maxcandid": 113, "casestrategi": 113, "try": [113, 129], "uppercas": 113, "errorthreshold": 113, "perplex": 113, "nlm": 113, "initialr": 113, "finalr": 113, "validationfract": 113, "datapoint": 113, "min": 113, "vocab": 113, "compoundcount": 113, "compound": 113, "classcount": 113, "special": [113, 157, 206], "tradeoff": 113, "weighteddistpath": 113, "levenshtein": [113, 115, 116], "maxwindowlen": 113, "rememb": 113, "norvigsweetingapproach": [113, 115, 116, 211], "symmetricdeleteapproach": [113, 115, 116, 211], "depth": [113, 182, 183, 208], "explan": [113, 208], "awar": 113, "sherlock": 113, "holm": 113, "spellcheck": [113, 115, 116], "setwordmaxdist": 113, "setepoch": 113, "setlanguagemodelclass": 113, "1650": 113, "addvocabclass": 113, "_name_": 113, "extra": [113, 115, 205], "dist": 113, "setmaxcandid": 113, "setcasestrategi": 113, "seterrorthreshold": 113, "setinitialr": 113, "setfinalr": 113, "setvalidationfract": 113, "fraction": 113, "setcompoundcount": 113, "setclasscount": 113, "settradeoff": 113, "alpha": 113, "setweighteddistpath": 113, "setmaxwindowlen": 113, "userdist": 113, "addregexclass": 113, "spellcheck_dl": 113, "gamma": 113, "influenc": 113, "decis": 113, "correctsymbol": 113, "comparelowcas": 113, "norvigsweetingmodel": [113, 115, 116], "symmetricdeletemodel": [113, 115, 116], "doc": [113, 196, 211], "cold": 113, "dreari": 113, "countri": 113, "white": 113, "smow": 113, "setweight": 113, "setgamma": 113, "getwordclass": 113, "updateregexclass": 113, "updat": [113, 183], "updatevocabclass": 113, "setcorrectsymbol": 113, "setcomparelowcas": 113, "norvigsweet": 115, "norvig": 115, "bayesian": 115, "tokenpattern": 115, "sensit": [115, 118, 125], "doublevari": 115, "search": [115, 183], "shortcircuit": 115, "frequencyprior": 115, "ham": 115, "intersect": [115, 183], "prioriti": [115, 125], "wordsizeignor": 115, "dupslimit": 115, "duplic": 115, "reductlimit": 115, "attempt": 115, "vowelswaplimit": 115, "vowel": 115, "swap": [115, 182], "corrector": 115, "gummi": [115, 116], "gummic": [115, 116], "gummier": [115, 116], "gummiest": [115, 116], "gummifer": [115, 116], "basi": [115, 116], "token_pattern": [115, 116], "setdoublevari": 115, "setshortcircuit": 115, "setfrequencyprior": 115, "symmetr": [115, 116], "delet": [115, 116, 205], "damerau": [115, 116], "magnitud": [115, 116], "transpos": [115, 116, 182], "insert": [115, 116, 205], "spellcheck_norvig": 115, "symspel": [115, 116], "somtim": 115, "wrrite": [115, 116], "wordz": [115, 116], "erong": [115, 116], "sometim": [115, 116, 205], "wrong": [115, 116], "symmetricdelet": 116, "deriv": 116, "teach": 116, "maxeditdist": 116, "frequencythreshold": [116, 127], "deletesthreshold": 116, "patttern": 116, "setmaxeditdist": 116, "setfrequencythreshold": [116, 127], "setdeletesthreshold": 116, "spellcheck_sd": 116, "spmetim": 116, "hard": 117, "employ": 117, "stopwordsclean": [118, 132, 143], "mllib": [118, 202], "stopwordsremov": 118, "cleantoken": [118, 132, 143], "stopwords_en": 118, "jvm": 118, "forth": 118, "setlocal": 118, "tfnerdlgraphbuildermodel": 119, "tfnerdlgraphbuild": 119, "sethiddenunitsnumb": 119, "assertiondlapproach": 119, "medicalnerapproach": [119, 169, 184], "gethiddenunitsnumb": 119, "getinputcol": [119, 146], "srt": 119, "getgraphfold": 119, "setgraphfil": 119, "greaph": 119, "auto": [119, 169, 184], "getgraphfil": 119, "chunktoken": 120, "flatten": 120, "artist": 120, "benezar": 120, "robert": 120, "farendel": 120, "graduat": 120, "luca": 120, "chunktokenizermodel": 120, "recursivetoken": 122, "recurs": [122, 141, 152, 156, 160], "hand": 122, "suffix": [122, 125, 205], "infix": [122, 125], "middl": 122, "she": 122, "qam": 122, "setprefix": 122, "setsuffix": 122, "setinfix": 122, "recursivetokenizermodel": 122, "regextoken": [123, 127, 206], "whitespac": [123, 127, 130], "tolowercas": [123, 127], "positionalmask": 123, "guarante": 123, "increment": 123, "trimwhitespac": 123, "flag": [123, 183], "eventu": 123, "settolowercas": [123, 127], "nthi": 123, "setpositionalmask": 123, "settrimwhitespac": 123, "token2chunk": 124, "17": [124, 195], "tokenizedsent": 125, "non": [125, 127, 169, 183, 184], "rulefactori": 125, "targetpattern": 125, "grab": 125, "prefixpattern": 125, "suffixpattern": 125, "infixpattern": 125, "sub": [125, 183], "won": 125, "exceptionspath": 125, "casesensitiveexcept": 125, "contextchar": 125, "splitpattern": 125, "splitchar": 125, "didn": 125, "jane": 125, "boyfriend": 125, "getinfixpattern": 125, "getsuffixpattern": 125, "getprefixpattern": 125, "getcontextchar": 125, "getsplitchar": 125, "settargetpattern": 125, "setprefixpattern": 125, "setsuffixpattern": 125, "setinfixpattern": 125, "addinfixpattern": 125, "setexcept": 125, "getexcept": 125, "setexceptionspath": 125, "addexcept": 125, "setcasesensitiveexcept": 125, "getcasesensitiveexcept": 125, "addcontextchar": 125, "setsplitpattern": 125, "setsplitchar": 125, "addsplitchar": 125, "piec": 125, "token_rul": 125, "wordsegment": 127, "wordsegmenterapproach": 127, "korean": 127, "japanes": 127, "chines": 127, "correspond": [127, 163, 182], "wordsegmentermodel": 127, "tip": 127, "frame": 127, "least": 127, "frequent": 127, "ambiguitythreshold": 127, "enableregextoken": 127, "chinese_train": 127, "utf8": 127, "\u5341": 127, "ll": 127, "\u56db": 127, "rr": 127, "\u4e0d": 127, "\u662f": 127, "setniter": 127, "trainingdataset": 127, "setambiguitythreshold": 127, "getfrequencythreshold": 127, "getambiguitythreshold": 127, "setenableregextoken": 127, "plit": 127, "words_seg": 127, "wordseg_pku": 127, "zh": 127, "\u7136\u800c": 127, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 127, "\u9019\u6a23": 127, "\u7684": 127, "\u8655\u7406": 127, "\u4e5f": 127, "\u884d\u751f": 127, "\u4e86": 127, "\u4e00\u4e9b": 127, "\u554f\u984c": 127, "prepar": [128, 131, 137, 140], "outputcol": [128, 131, 132, 133, 134, 137, 140], "inferschema": 128, "tmp": [128, 137, 156, 201], "librispeech_asr_dummy_clean_audio_array_parquet": 128, "float_arrai": 128, "chunk2doc": [129, 130], "back": [129, 182], "re": [129, 205], "doc2chunk": [129, 130], "pretrainedpipelin": [129, 133, 139, 155, 166, 204, 209, 210], "york": [129, 133], "jersei": [129, 133], "aren": [129, 133], "amongst": [129, 133], "explain_document_dl": [129, 133, 139, 155, 166], "chunktodoc": 129, "chunkconvert": 129, "explainresult": [129, 133], "22": [129, 133, 192, 204], "chunkcol": 130, "stringtyp": 130, "setisarrai": 130, "startcol": 130, "startcolbytokenindex": 130, "isarrai": 130, "failonmiss": 130, "fail": 130, "chunkassembl": 130, "setchunkcol": 130, "setstartcol": 130, "setstartcolbytokenindex": 130, "setfailonmiss": 130, "disabl": [131, 140], "idcol": [131, 140], "metadatacol": [131, 140], "cleanupmod": [131, 140], "cleanup": [131, 140], "inplac": [131, 140], "inplace_ful": [131, 140], "shrink_ful": [131, 140], "each_ful": [131, 140], "delete_ful": [131, 140], "51": [131, 140, 195], "setidcol": [131, 140], "setmetadatacol": [131, 140], "usabl": 132, "lda": 132, "forest": 132, "featurecol": 132, "cleanannot": [132, 133, 134], "outputasvector": 132, "gloveembed": 132, "finished_sentence_embed": 132, "resultwiths": 132, "1619900017976761": 132, "045552998781204224": 132, "03229299932718277": 132, "685609996318": 132, "42416998744010925": 132, "1378999948501587": 132, "5717899799346924": 132, "5078899860382": 132, "08621499687433243": 132, "15772999823093414": 132, "06067200005054474": 132, "395359992980": 132, "4970499873161316": 132, "7164199948310852": 132, "40119001269340515": 132, "05761000141501": 132, "08170200139284134": 132, "7159299850463867": 132, "20677000284194946": 132, "0295659992843": 132, "valuesplitsymbol": 133, "annotationsplitsymbol": 133, "includemetadata": 133, "outputasarrai": [133, 134], "parseembeddingsvector": 133, "setvaluesplitsymbol": 133, "setannotationsplitsymbol": 133, "setincludemetadata": [133, 206], "setoutputasarrai": [133, 134], "setparseembeddingsvector": 133, "finishedresult": 134, "hasrecursivefit": [135, 136], "java_obj": [135, 159, 162], "py4j": [135, 136, 162], "java_gatewai": [135, 136, 162], "javaobject": [135, 136, 162], "recursivepipelin": [135, 136, 141, 146], "hasrecursivetransform": 136, "chunk2_doc": [138, 156], "doc2_chunk": [138, 156], "embeddings_finish": [138, 156], "graph_finish": [138, 156], "has_recursive_fit": [138, 156], "has_recursive_transform": [138, 156], "light_pipelin": [138, 156], "recursive_pipelin": [138, 156], "token_assembl": [138, 156], "lightpipelin": [139, 166, 209], "parse_embed": [139, 166], "equival": [139, 156, 209], "execut": [139, 183, 205, 209], "hold": [139, 209], "principl": [139, 209], "everyth": [139, 209, 210], "deal": [139, 209], "fullannot": [139, 166], "happi": [139, 204, 206, 209, 210], "prp": [139, 193, 195, 204, 209, 210, 211], "rb": [139, 169, 184, 195, 204, 209, 210, 211], "optional_target": [139, 166], "explain_document_pipelin": [139, 155, 166, 204, 209, 210], "dict_kei": [139, 166], "fullannotateimag": [139, 166], "path_to_imag": [139, 166], "setignoreunsupport": 139, "unsupport": 139, "annotatormodel": [139, 145], "getignoreunsupport": 139, "calculationscol": 140, "text2": 140, "document1": 140, "document2": 140, "kwarg": [141, 183], "decid": 141, "advantag": 141, "behav": 141, "exactli": 141, "intent": 141, "recursivepipelinemodel": 141, "pipeline_model": [141, 163, 201], "intend": 141, "tab": [142, 163, 201], "escap": 142, "quot": 142, "inputformat": 142, "csvdelimit": 142, "defailt": 142, "comma": 142, "escapecsvdelimit": 142, "table_csv": 142, "csv_data": 142, "118": 142, "input_format": 142, "setcsvdelimit": 142, "setescapecsvdelimit": 142, "tokenassembl": 143, "reconstruct": 143, "cleantext": 143, "opensourc": 143, "annotatorapproach": [144, 152, 163], "subclass": [145, 158, 162, 178, 181], "ins": [145, 162], "uid": [145, 162], "annotatorproperti": 146, "getoutputcol": 146, "setlazyannot": 146, "lazili": 146, "getlazyannot": 146, "annotator_approach": [149, 156], "annotator_model": [149, 156], "annotator_properti": [149, 156], "coverage_result": [149, 156], "recursive_annotator_approach": [149, 156], "hasembeddingsproperti": 150, "getdimens": 150, "constant": 151, "recursiveannotatorapproach": 152, "handl": [153, 194], "fo": 154, "assist": 155, "map_annot": 155, "f": [155, 163, 201], "output_typ": 155, "udf": 155, "userdefinedfunct": 155, "def": 155, "nnp_token": 155, "lambda": 155, "alia": 155, "epeu": 155, "map_annotations_arrai": 155, "map_annotations_strict": 155, "map_annotations_col": 155, "output_column": 155, "annotatyon_typ": 155, "chunks_df": 155, "pos_chunk": 155, "vbz": [155, 192, 211], "filter_by_annotations_col": 155, "filter_po": 155, "explode_annotations_col": 155, "annotator_java_ml": [156, 160], "annotator_transform": [156, 160], "extended_java_wrapp": [156, 160], "params_getters_sett": [156, 160], "comet": [156, 164, 203], "pretrained_pipelin": [156, 165], "resource_download": [156, 165], "pub_tat": [156, 194], "annotation_audio": 156, "annotation_imag": 156, "aarch64": 156, "cache_fold": 156, "log_fold": 156, "cluster_tmp_dir": 156, "real_time_output": 156, "output_level": 156, "correctli": 156, "maco": 156, "linux": 156, "alloc": 156, "directori": [156, 201], "cache_pretrain": 156, "temporarili": 156, "unpack": 156, "hadoop": 156, "dir": 156, "s3": 156, "hdf": 156, "dbf": 156, "annotator_log": 156, "annotatorjavamlread": 157, "mixin": 157, "javamlread": 157, "classmethod": 157, "mlreader": 157, "clazz": 157, "rl": 157, "javaparam": 157, "annotatortransform": 158, "ensur": 158, "_java_obj": 158, "extens": 159, "javawrapp": 159, "extendedjavawrapp": 159, "new_java_arrai": 159, "pylist": 159, "java_class": 159, "todo": 159, "chang": [159, 180, 183], "paramsgetterssett": 161, "getparamvalu": 161, "paramnam": 161, "setparamvalu": 161, "recursiveestim": 162, "tupl": [162, 181, 182, 183], "overrid": 162, "recursivetransform": 162, "cometlogg": [163, 201], "workspac": 163, "project_nam": [163, 201], "comet_mod": [163, 201], "experiment_id": 163, "experiment_kwarg": 163, "logger": [163, 201], "meta": [163, 203], "ai": [163, 201], "practition": [163, 201], "reliabl": [163, 201], "streamlin": [163, 201], "lifecycl": [163, 201, 203], "track": [163, 201, 202], "explain": [163, 201, 208, 210], "reproduc": [163, 201, 202], "outputlogpath": [163, 201], "offlin": 163, "onlin": [163, 183, 201], "reus": [163, 177, 179, 181, 183], "importerror": 163, "output_log_path": [163, 201], "embd": [163, 201], "setshuffleperepoch": [163, 201], "logdir": [163, 201], "interfac": [163, 201, 209], "chart": [163, 201], "comet_ml": [163, 201], "log_pipeline_paramet": [163, 201], "log_visu": [163, 201], "html": [163, 201], "viz": [163, 201], "upload": 163, "visual": 163, "colum": [163, 201], "ner_chunk": [163, 201], "sparknlp_displai": [163, 201], "nervisu": [163, 201], "idx": [163, 201], "enumer": [163, 201], "label_col": [163, 201], "document_col": [163, 201], "return_html": [163, 201], "log_metr": [163, 201], "sklearn": [163, 201], "preprocess": [163, 201], "multilabelbinar": [163, 201], "classification_report": [163, 201], "preds_df": [163, 201], "topanda": [163, 201], "mlb": [163, 201], "y_true": [163, 201], "fit_transform": [163, 201], "y_pred": [163, 201], "output_dict": [163, 201], "log_paramet": 163, "log_completed_run": 163, "log_file_path": 163, "complet": [163, 202], "log_asset": 163, "asset_path": 163, "asset": 163, "log_asset_data": 163, "interv": 163, "refresh": 163, "outstand": 163, "disk_loc": 166, "fulli": 166, "light_model": 166, "gather": 166, "langaug": 166, "resourcedownload": 167, "wrongtfvers": [169, 184], "exit": [169, 184], "tensorflowaddonsneed": 169, "tfgraphbuild": [169, 184], "build_param": [169, 184], "generic_classifi": [169, 184], "assertion_dl": [169, 184], "relation_extract": [169, 184], "healthcar": [169, 184], "tfgraph": [169, 184], "tf_graph": [169, 184], "get_model": [169, 184], "nertfgraphbuild": [169, 184], "feat_siz": [169, 184], "n_class": [169, 184], "embeddings_dim": [169, 184], "nchar": [169, 184], "ntag": [169, 184], "model_loc": [169, 184], "medical_ner_graph": [169, 184], "model_filenam": [169, 184], "ner_log": [169, 184], "tfgraphbuilderfactori": [169, 184], "factori": [169, 184], "model_nam": [169, 184], "filenam": [169, 184], "ner_graph": [169, 184], "print_model_param": [169, 184], "tf2contrib": 170, "core_rnn_cel": [170, 180], "fused_rnn_cel": [170, 180], "gru_op": [170, 180], "lstm_op": [170, 180], "rnn_cell": [170, 178, 180], "core": 177, "embeddingwrapp": 177, "inputprojectionwrapp": 177, "outputprojectionwrapp": 177, "embedding_class": 177, "embedding_s": 177, "num_proj": [177, 183], "input_s": [177, 181, 182, 183], "output_s": [177, 181], "fuse": 178, "fusedrnncel": [178, 181], "expand": 178, "recurr": [178, 181, 182, 183], "rnncell": [178, 182, 183], "flexibl": 178, "__call__": 178, "signatur": 178, "fusedrnncelladaptor": 178, "use_dynamic_rnn": 178, "adaptor": 178, "timereversedfusedrnn": 178, "revers": 178, "basicrnncel": 178, "fw_lstm": 178, "bw_lstm": 178, "fw_out": 178, "fw_state": 178, "bw_out": 178, "bw_state": 178, "grublockcel": 179, "num_unit": [179, 181, 183], "cell_siz": 179, "gru_cel": 179, "deprec": 179, "grublockcellv2": 179, "ab": [179, 181, 182, 183], "1406": [179, 183], "1078": [179, 183], "forward": [179, 182], "propag": [179, 183], "mathemat": 179, "equat": [179, 183], "b_ru": 179, "constant_initi": 179, "b_c": 179, "x_h_prev": 179, "h_prev": 179, "r_bar": 179, "u_bar": 179, "w_ru": 179, "h_prevr": 179, "circ": [179, 183], "x_h_prevr": 179, "c_bar": 179, "w_c": [179, 183], "tanh": [179, 183], "h": [179, 183], "temporari": 179, "impl": 179, "input_shap": [179, 183], "lstmblockcel": 181, "forget_bia": [181, 183], "cell_clip": [181, 183], "use_peephol": [181, 183], "dtype": [181, 182, 183], "lstm_cell": 181, "1409": 181, "2329": 181, "forget": [181, 183], "gate": [181, 183], "rnn_cell_impl": [181, 183], "lstmcell": [181, 183], "monolith": 181, "short": [181, 183], "lstmblockwrapp": 181, "housekeep": 181, "_call_cel": 181, "initial_st": 181, "sequence_length": [181, 182], "time_len": 181, "initial_cell_st": 181, "initial_output": 181, "_num_unit": 181, "heterogen": 181, "int32": [181, 182], "int64": [181, 182], "cell_stat": 181, "valueerror": [181, 182, 183], "mismatch": 181, "lstmblockfusedcel": 181, "lstm_fused_cel": 181, "extrem": 181, "stack_bidirectional_rnn": 182, "cells_fw": 182, "cells_bw": 182, "initial_states_fw": 182, "initial_states_bw": 182, "stack": [182, 183], "sever": [182, 211], "backward": 182, "bidirectional_rnn": 182, "intermedi": 182, "1303": 182, "5778": 182, "appropri": 182, "cell_fw": 182, "state_s": [182, 183], "variablescop": 182, "subgraph": 182, "output_state_fw": 182, "output_state_bw": 182, "output_states_fw": 182, "output_states_bw": 182, "typeerror": 182, "cell_bw": 182, "stack_bidirectional_dynamic_rnn": 182, "parallel_iter": 182, "time_major": 182, "swap_memori": 182, "max_tim": 182, "major": 182, "emit": 182, "transpar": 182, "produc": [182, 183, 205], "prop": 182, "cpu": 182, "layers_output": 182, "coupledinputforgetgatelstmcel": 183, "proj_clip": 183, "num_unit_shard": 183, "num_proj_shard": 183, "state_is_tupl": 183, "math_op": 183, "layer_norm": 183, "norm_gain": 183, "norm_shift": 183, "peephol": 183, "pdf": 183, "semanticscholar": 183, "1154": 183, "0131eae85b2e11d53df7f1360eeb6476e7f4": 183, "felix": 183, "ger": 183, "jurgen": 183, "schmidhub": 183, "fred": 183, "cummin": 183, "iet": 183, "850": 183, "855": 183, "1999": 183, "pub": 183, "archiv": 183, "43905": 183, "hasim": 183, "sak": 183, "andrew": 183, "senior": 183, "francois": 183, "beaufai": 183, "acoust": 183, "interspeech": 183, "2014": 183, "coupl": 183, "1503": 183, "04069": 183, "greff": 183, "odyssei": 183, "peep": 183, "hole": 183, "connect": 183, "1607": 183, "06450": 183, "jimmi": 183, "lei": 183, "ba": 183, "jami": 183, "ryan": 183, "kiro": 183, "geoffrei": 183, "hinton": 183, "nonlinear": 183, "2d": 183, "c_state": 183, "m_state": 183, "output_dim": 183, "cannot": 183, "timefreqlstmcel": 183, "feature_s": 183, "frequency_skip": 183, "tara": 183, "sainath": 183, "bo": 183, "li": 183, "lvcsr": 183, "2016": 183, "clip": 183, "gridlstmcel": 183, "share_time_frequency_weight": 183, "num_frequency_block": 183, "start_freqindex_list": 183, "end_freqindex_list": 183, "couple_input_forget_g": 183, "grid": 183, "nal": 183, "kalchbrenn": 183, "ivo": 183, "danihelka": 183, "alex": 183, "proc": 183, "iclr": 183, "1507": 183, "01526": 183, "shared_weight": 183, "_state_is_tupl": 183, "bidirectionalgridlstmcel": 183, "backward_slice_offset": 183, "gridlstm": 183, "attentioncellwrapp": 183, "attn_length": 183, "attn_siz": 183, "attn_vec_s": 183, "1601": 183, "06733": 183, "lstma": 183, "highwaywrapp": 183, "couple_carry_transform_g": 183, "carry_bias_init": 183, "highwai": 183, "srivastava": 183, "preprint": 183, "1505": 183, "00387": 183, "layernormbasiclstmcel": 183, "dropout_keep_prob": 183, "dropout_prob_se": 183, "1603": 183, "05118": 183, "stanislau": 183, "semeniuta": 183, "aliaksei": 183, "severyn": 183, "erhardt": 183, "barth": 183, "nascel": 183, "use_bia": 183, "na": 183, "1611": 183, "01578": 183, "barret": 183, "zoph": 183, "quoc": 183, "reinforc": 183, "2017": 183, "ugrnncel": 183, "ugrnn": 183, "compromis": 183, "vanilla": 183, "instantan": 183, "feedforward": 183, "09913": 183, "jasmin": 183, "collin": 183, "jascha": 183, "sohl": 183, "dickstein": 183, "david": 183, "sussillo": 183, "num": 183, "new_output": 183, "ident": 183, "new_stat": 183, "intersectionrnncel": 183, "num_in_proj": 183, "y_activ": 183, "nn_op": 183, "relu": 183, "flow": 183, "subsequ": 183, "deepli": 183, "new_i": 183, "compiledwrapp": 183, "compile_st": 183, "jit": 183, "phasedlstmcel": 183, "leak": 183, "ratio_on": 183, "trainable_ratio_on": 183, "period_init_min": 183, "period_init_max": 183, "1610": 183, "09513v1": 183, "float32": 183, "float64": 183, "features_s": 183, "lstmstatetupl": 183, "timestep": 183, "convlstmcel": 183, "conv_ndim": 183, "output_channel": 183, "kernel_shap": 183, "skip_connect": 183, "conv_lstm_cel": 183, "1506": 183, "04214v1": 183, "conv1dlstmcel": 183, "conv_1d_lstm_cel": 183, "1d": 183, "conv2dlstmcel": 183, "conv_2d_lstm_cel": 183, "conv3dlstmcel": 183, "conv_3d_lstm_cel": 183, "3d": 183, "glstmcell": 183, "number_of_group": 183, "1703": 183, "10722": 183, "kuchaiev": 183, "ginsburg": 183, "trick": 183, "brief": 183, "evenli": 183, "fed": 183, "receiv": [183, 195, 211], "num_input": 183, "known": 183, "divis": 183, "innermost": 183, "incompat": 183, "layernormlstmcel": 183, "srucel": 183, "sru": 183, "cf": 183, "1709": 183, "02755": 183, "variat": 183, "character": 183, "simplifi": 183, "consecut": 183, "tradition": 183, "multipli": 183, "matrix": 183, "w_hh": 183, "ensu": 183, "flavor": 183, "h_": 183, "pointwis": 183, "boolean": 183, "mistak": 183, "argument": 183, "weightnormlstmcel": 183, "norm": 183, "adapt": 183, "1602": 183, "07868": 183, "tim": 183, "saliman": 183, "diederik": 183, "kingma": 183, "reparameter": 183, "indrnncel": 183, "indrnn": 183, "1803": 183, "04831": 183, "indygrucel": 183, "kernel_initi": 183, "bias_initi": 183, "grucel": 183, "yet": 183, "u_r": 183, "u_z": 183, "diagon": 183, "hadamard": 183, "r_j": 183, "sigmaleft": 183, "mathbf": 183, "w_rmathbf": 183, "_j": 183, "u_rcirc": 183, "_jright": 183, "z_j": 183, "w_zmathbf": 183, "u_zcirc": 183, "tild": 183, "phileft": 183, "denot": 183, "indygru": 183, "oppos": 183, "nunit": 183, "indylstmcel": 183, "indylstm": 183, "basiclstmcel": 183, "u_f": 183, "u_i": 183, "u_o": 183, "u_c": 183, "f_t": 183, "sigma_gleft": 183, "w_f": 183, "x_t": 183, "b_fright": 183, "i_t": 183, "w_i": 183, "b_iright": 183, "o_t": 183, "w_o": 183, "b_oright": 183, "c_t": 183, "c_": 183, "sigma_cleft": 183, "b_cright": 183, "1903": 183, "08023": 183, "ntmcell": 183, "memory_s": 183, "memory_vector_dim": 183, "read_head_num": 183, "write_head_num": 183, "shift_rang": 183, "clip_valu": 183, "ture": 183, "1807": 183, "08518": 183, "collier": 183, "joeran": 183, "beel": 183, "snowkylin": 183, "ntm": 183, "cours": 183, "1410": 183, "5401": 183, "wayn": 183, "minimalrnncel": 183, "glorot_uniform": 183, "ones": 183, "minimalrnn": 183, "1806": 183, "05394v2": 183, "minmin": 183, "jeffrei": 183, "pennington": 183, "samuel": 183, "schoenholz": 183, "isometri": 183, "theori": 183, "icml": 183, "cfncell": 183, "chao": 183, "openreview": 183, "net": 183, "s1dizvclg": 183, "thoma": 183, "jame": 183, "von": 183, "brecht": 183, "cfn": 183, "goe": 183, "contract": 183, "decoupl": 183, "tf_graph_1x": 184, "documentcol": [192, 193], "sentencecol": [192, 193], "tokencol": 192, "conlllabelindex": 192, "conllposindex": 192, "textcol": [192, 193], "labelcol": 192, "docstart": [192, 211], "eu": [192, 211], "np": [192, 211], "reject": [192, 211], "vp": [192, 211], "misc": [192, 211], "boycott": [192, 211], "british": [192, 211], "lamb": [192, 211], "blackburn": 192, "brussel": 192, "1996": 192, "08": 192, "storage_level": 192, "storagelevel": 192, "disk_onli": 192, "lift": 192, "persist": 192, "uposcol": 193, "upo": 193, "xposcol": 193, "xpo": 193, "lemmacol": 193, "sent_id": 193, "sell": 193, "pron": 193, "nom": 193, "plur": 193, "_": 193, "tens": 193, "conj": 193, "cc": 193, "spaceaft": 193, "No": [193, 204], "punct": 193, "conllufil": [193, 211], "conlldataset": [193, 211], "morph": 193, "Into": 193, "googleo": 193, "sconj": 193, "propn": 193, "adp": 193, "wp": 193, "vbd": [193, 195, 211], "ago": [195, 211], "posdf": 195, "61": 195, "56": 195, "67": [195, 196, 211], "nonexecut": 195, "69": 195, "76": 195, "director": 195, "78": 195, "81": 195, "84": 195, "outputposcol": 195, "outputdocumentcol": 195, "outputtextcol": 195, "pubtat": [196, 208], "medic": [196, 211], "medment": [196, 211], "25763772": [196, 211], "dctn4": [196, 211], "t116": [196, 211], "t123": [196, 211], "c4308010": [196, 211], "63": [196, 211], "chronic": [196, 211], "pseudomona": [196, 211], "aeruginosa": [196, 211], "infect": [196, 211], "t047": [196, 211], "c0854135": [196, 211], "82": [196, 211], "cystic": [196, 211], "fibrosi": [196, 211], "c0010674": [196, 211], "120": [196, 211], "pa": [196, 211], "124": [196, 211], "139": [196, 211], "pubtatorfil": 196, "corpus_pubtator_sampl": 196, "pubtatordataset": 196, "doc_id": 196, "finished_token": [196, 206], "finished_po": 196, "finished_n": 196, "finished_token_metadata": 196, "finished_pos_metadata": 196, "finished_label_metadata": 196, "mo": 196, "ispaddedtoken": 196, "pad": 196, "workflow": 201, "dedic": 201, "account": 201, "inspect": 201, "init": 201, "sparknlp_experi": 201, "offline_directori": 201, "later": 201, "nativ": 202, "record": 202, "queri": 202, "serv": 202, "registri": 202, "discov": 202, "central": 202, "send": 203, "messag": 203, "mlflow": 203, "clearli": 204, "explain_document_ml": [204, 209, 210], "approx": [204, 209, 210], "mb": [204, 209, 210], "ok": [204, 209, 210], "spearhead": 205, "declar": 205, "accordingli": 205, "extra_loc": 205, "bring": 205, "offer": [205, 207, 210], "column_nam": 205, "preced": 205, "interchang": 206, "anoth": 206, "road": 206, "proce": 206, "At": 206, "sens": 210, "constantli": 210, "server": 210, "train_po": 211, "training_conl": 211, "train_corpu": 211, "withcolumnrenam": 211, "trainingpubtatordf": 211, "corpus_pubt": 211}, "objects": {"python": [[156, 0, 0, "-", "sparknlp"]], "python.sparknlp": [[12, 0, 0, "-", "annotation"], [13, 0, 0, "-", "annotation_audio"], [14, 0, 0, "-", "annotation_image"], [78, 0, 0, "-", "annotator"], [138, 0, 0, "-", "base"], [149, 0, 0, "-", "common"], [155, 0, 0, "-", "functions"], [160, 0, 0, "-", "internal"], [164, 0, 0, "-", "logging"], [165, 0, 0, "-", "pretrained"], [156, 3, 1, "", "start"], [194, 0, 0, "-", "training"], [198, 0, 0, "-", "upload_to_hub"], [199, 0, 0, "-", "util"], [156, 3, 1, "", "version"]], "python.sparknlp.annotation": [[12, 1, 1, "", "Annotation"]], "python.sparknlp.annotation.Annotation": [[12, 2, 1, "", "arrayType"], [12, 2, 1, "", "copy"], [12, 2, 1, "", "dataType"], [12, 2, 1, "", "fromRow"], [12, 2, 1, "", "toRow"]], "python.sparknlp.annotation_audio": [[13, 1, 1, "", "AnnotationAudio"]], "python.sparknlp.annotation_audio.AnnotationAudio": [[13, 2, 1, "", "copy"]], "python.sparknlp.annotation_image": [[14, 1, 1, "", "AnnotationImage"]], "python.sparknlp.annotation_image.AnnotationImage": [[14, 2, 1, "", "copy"]], "python.sparknlp.annotator": [[15, 0, 0, "-", "audio"], [17, 0, 0, "-", "chunker"], [32, 0, 0, "-", "classifier_dl"], [47, 0, 0, "-", "coref"], [49, 0, 0, "-", "cv"], [52, 0, 0, "-", "dependency"], [54, 0, 0, "-", "document_normalizer"], [64, 0, 0, "-", "embeddings"], [76, 0, 0, "-", "er"], [77, 0, 0, "-", "graph_extraction"], [79, 0, 0, "-", "keyword_extraction"], [81, 0, 0, "-", "ld_dl"], [83, 0, 0, "-", "lemmatizer"], [86, 0, 0, "-", "matcher"], [90, 0, 0, "-", "n_gram_generator"], [91, 0, 0, "-", "ner"], [97, 0, 0, "-", "normalizer"], [100, 0, 0, "-", "param"], [101, 0, 0, "-", "pos"], [103, 0, 0, "-", "sentence"], [106, 0, 0, "-", "sentiment"], [110, 0, 0, "-", "seq2seq"], [114, 0, 0, "-", "spell_check"], [117, 0, 0, "-", "stemmer"], [118, 0, 0, "-", "stop_words_cleaner"], [119, 0, 0, "-", "tf_ner_dl_graph_builder"], [121, 0, 0, "-", "token"], [126, 0, 0, "-", "ws"]], "python.sparknlp.annotator.audio": [[16, 0, 0, "-", "wav2vec2_for_ctc"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc": [[16, 1, 1, "", "Wav2Vec2ForCTC"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[16, 2, 1, "", "loadSavedModel"], [16, 2, 1, "", "pretrained"], [16, 2, 1, "", "setConfigProtoBytes"]], "python.sparknlp.annotator.chunker": [[17, 1, 1, "", "Chunker"]], "python.sparknlp.annotator.chunker.Chunker": [[17, 2, 1, "", "setRegexParsers"]], "python.sparknlp.annotator.classifier_dl": [[18, 0, 0, "-", "albert_for_question_answering"], [19, 0, 0, "-", "albert_for_sequence_classification"], [20, 0, 0, "-", "albert_for_token_classification"], [21, 0, 0, "-", "bert_for_question_answering"], [22, 0, 0, "-", "bert_for_sequence_classification"], [23, 0, 0, "-", "bert_for_token_classification"], [24, 0, 0, "-", "camembert_for_token_classification"], [25, 0, 0, "-", "classifier_dl"], [26, 0, 0, "-", "deberta_for_question_answering"], [27, 0, 0, "-", "deberta_for_sequence_classification"], [28, 0, 0, "-", "deberta_for_token_classification"], [29, 0, 0, "-", "distil_bert_for_question_answering"], [30, 0, 0, "-", "distil_bert_for_sequence_classification"], [31, 0, 0, "-", "distil_bert_for_token_classification"], [33, 0, 0, "-", "longformer_for_question_answering"], [34, 0, 0, "-", "longformer_for_sequence_classification"], [35, 0, 0, "-", "longformer_for_token_classification"], [36, 0, 0, "-", "multi_classifier_dl"], [37, 0, 0, "-", "roberta_for_question_answering"], [38, 0, 0, "-", "roberta_for_sequence_classification"], [39, 0, 0, "-", "roberta_for_token_classification"], [40, 0, 0, "-", "sentiment_dl"], [41, 0, 0, "-", "tapas_for_question_answering"], [42, 0, 0, "-", "xlm_roberta_for_question_answering"], [43, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [44, 0, 0, "-", "xlm_roberta_for_token_classification"], [45, 0, 0, "-", "xlnet_for_sequence_classification"], [46, 0, 0, "-", "xlnet_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering": [[18, 1, 1, "", "AlbertForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[18, 2, 1, "", "loadSavedModel"], [18, 2, 1, "", "pretrained"], [18, 2, 1, "", "setConfigProtoBytes"], [18, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[19, 1, 1, "", "AlbertForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[19, 2, 1, "", "getClasses"], [19, 2, 1, "", "loadSavedModel"], [19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setCoalesceSentences"], [19, 2, 1, "", "setConfigProtoBytes"], [19, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification": [[20, 1, 1, "", "AlbertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[20, 2, 1, "", "getClasses"], [20, 2, 1, "", "loadSavedModel"], [20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setConfigProtoBytes"], [20, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering": [[21, 1, 1, "", "BertForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[22, 1, 1, "", "BertForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[22, 2, 1, "", "getClasses"], [22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setCoalesceSentences"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification": [[23, 1, 1, "", "BertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[23, 2, 1, "", "getClasses"], [23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[24, 1, 1, "", "CamemBertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[24, 2, 1, "", "getClasses"], [24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.classifier_dl": [[25, 1, 1, "", "ClassifierDLApproach"], [25, 1, 1, "", "ClassifierDLModel"]], "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[25, 2, 1, "", "setDropout"]], "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[25, 2, 1, "", "pretrained"], [25, 2, 1, "", "setConfigProtoBytes"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[26, 1, 1, "", "DeBertaForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[26, 2, 1, "", "loadSavedModel"], [26, 2, 1, "", "pretrained"], [26, 2, 1, "", "setConfigProtoBytes"], [26, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[27, 1, 1, "", "DeBertaForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[27, 2, 1, "", "getClasses"], [27, 2, 1, "", "loadSavedModel"], [27, 2, 1, "", "pretrained"], [27, 2, 1, "", "setCoalesceSentences"], [27, 2, 1, "", "setConfigProtoBytes"], [27, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[28, 1, 1, "", "DeBertaForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[28, 2, 1, "", "getClasses"], [28, 2, 1, "", "loadSavedModel"], [28, 2, 1, "", "pretrained"], [28, 2, 1, "", "setConfigProtoBytes"], [28, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[29, 1, 1, "", "DistilBertForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[29, 2, 1, "", "loadSavedModel"], [29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[30, 1, 1, "", "DistilBertForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[30, 2, 1, "", "getClasses"], [30, 2, 1, "", "loadSavedModel"], [30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setCoalesceSentences"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[31, 1, 1, "", "DistilBertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[31, 2, 1, "", "getClasses"], [31, 2, 1, "", "loadSavedModel"], [31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[33, 1, 1, "", "LongformerForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[33, 2, 1, "", "loadSavedModel"], [33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[34, 1, 1, "", "LongformerForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[34, 2, 1, "", "getClasses"], [34, 2, 1, "", "loadSavedModel"], [34, 2, 1, "", "pretrained"], [34, 2, 1, "", "setCoalesceSentences"], [34, 2, 1, "", "setConfigProtoBytes"], [34, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[35, 1, 1, "", "LongformerForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[35, 2, 1, "", "getClasses"], [35, 2, 1, "", "loadSavedModel"], [35, 2, 1, "", "pretrained"], [35, 2, 1, "", "setConfigProtoBytes"], [35, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl": [[36, 1, 1, "", "MultiClassifierDLApproach"], [36, 1, 1, "", "MultiClassifierDLModel"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[36, 2, 1, "", "setThreshold"], [36, 2, 1, "", "setVerbose"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[36, 2, 1, "", "pretrained"], [36, 2, 1, "", "setConfigProtoBytes"], [36, 2, 1, "", "setThreshold"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[37, 1, 1, "", "RoBertaForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"], [37, 2, 1, "", "setConfigProtoBytes"], [37, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[38, 1, 1, "", "RoBertaForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[38, 2, 1, "", "getClasses"], [38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setCoalesceSentences"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[39, 1, 1, "", "RoBertaForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[39, 2, 1, "", "getClasses"], [39, 2, 1, "", "loadSavedModel"], [39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl": [[40, 1, 1, "", "SentimentDLApproach"], [40, 1, 1, "", "SentimentDLModel"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[40, 2, 1, "", "setDropout"], [40, 2, 1, "", "setThreshold"], [40, 2, 1, "", "setThresholdLabel"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[40, 2, 1, "", "pretrained"], [40, 2, 1, "", "setConfigProtoBytes"], [40, 2, 1, "", "setThreshold"], [40, 2, 1, "", "setThresholdLabel"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[41, 1, 1, "", "TapasForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[41, 2, 1, "", "loadSavedModel"], [41, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[42, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[42, 2, 1, "", "loadSavedModel"], [42, 2, 1, "", "pretrained"], [42, 2, 1, "", "setConfigProtoBytes"], [42, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[43, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[43, 2, 1, "", "getClasses"], [43, 2, 1, "", "loadSavedModel"], [43, 2, 1, "", "pretrained"], [43, 2, 1, "", "setCoalesceSentences"], [43, 2, 1, "", "setConfigProtoBytes"], [43, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[44, 1, 1, "", "XlmRoBertaForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[44, 2, 1, "", "getClasses"], [44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"], [44, 2, 1, "", "setConfigProtoBytes"], [44, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[45, 1, 1, "", "XlnetForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[45, 2, 1, "", "getClasses"], [45, 2, 1, "", "loadSavedModel"], [45, 2, 1, "", "pretrained"], [45, 2, 1, "", "setCoalesceSentences"], [45, 2, 1, "", "setConfigProtoBytes"], [45, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[46, 1, 1, "", "XlnetForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[46, 2, 1, "", "getClasses"], [46, 2, 1, "", "loadSavedModel"], [46, 2, 1, "", "pretrained"], [46, 2, 1, "", "setConfigProtoBytes"], [46, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.coref": [[48, 0, 0, "-", "spanbert_coref"]], "python.sparknlp.annotator.coref.spanbert_coref": [[48, 1, 1, "", "SpanBertCorefModel"]], "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[48, 2, 1, "", "loadSavedModel"], [48, 2, 1, "", "pretrained"], [48, 2, 1, "", "setConfigProtoBytes"], [48, 2, 1, "", "setMaxSegmentLength"], [48, 2, 1, "", "setMaxSentenceLength"], [48, 2, 1, "", "setTextGenre"]], "python.sparknlp.annotator.cv": [[50, 0, 0, "-", "vit_for_image_classification"]], "python.sparknlp.annotator.cv.vit_for_image_classification": [[50, 1, 1, "", "ViTForImageClassification"]], "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[50, 2, 1, "", "getClasses"], [50, 2, 1, "", "loadSavedModel"], [50, 2, 1, "", "pretrained"], [50, 2, 1, "", "setConfigProtoBytes"]], "python.sparknlp.annotator.dependency": [[51, 0, 0, "-", "dependency_parser"], [53, 0, 0, "-", "typed_dependency_parser"]], "python.sparknlp.annotator.dependency.dependency_parser": [[51, 1, 1, "", "DependencyParserApproach"], [51, 1, 1, "", "DependencyParserModel"]], "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[51, 2, 1, "", "setConllU"], [51, 2, 1, "", "setDependencyTreeBank"], [51, 2, 1, "", "setNumberOfIterations"]], "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[51, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.dependency.typed_dependency_parser": [[53, 1, 1, "", "TypedDependencyParserApproach"], [53, 1, 1, "", "TypedDependencyParserModel"]], "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[53, 2, 1, "", "setConll2009"], [53, 2, 1, "", "setConllU"], [53, 2, 1, "", "setNumberOfIterations"]], "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[53, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.document_normalizer": [[54, 1, 1, "", "DocumentNormalizer"]], "python.sparknlp.annotator.document_normalizer.DocumentNormalizer": [[54, 2, 1, "", "setAction"], [54, 2, 1, "", "setEncoding"], [54, 2, 1, "", "setLowercase"], [54, 2, 1, "", "setPatterns"], [54, 2, 1, "", "setPolicy"], [54, 2, 1, "", "setReplacement"]], "python.sparknlp.annotator.embeddings": [[55, 0, 0, "-", "albert_embeddings"], [56, 0, 0, "-", "bert_embeddings"], [57, 0, 0, "-", "bert_sentence_embeddings"], [58, 0, 0, "-", "camembert_embeddings"], [59, 0, 0, "-", "chunk_embeddings"], [60, 0, 0, "-", "deberta_embeddings"], [61, 0, 0, "-", "distil_bert_embeddings"], [62, 0, 0, "-", "doc2vec"], [63, 0, 0, "-", "elmo_embeddings"], [65, 0, 0, "-", "longformer_embeddings"], [66, 0, 0, "-", "roberta_embeddings"], [67, 0, 0, "-", "roberta_sentence_embeddings"], [68, 0, 0, "-", "sentence_embeddings"], [69, 0, 0, "-", "universal_sentence_encoder"], [70, 0, 0, "-", "word2vec"], [71, 0, 0, "-", "word_embeddings"], [72, 0, 0, "-", "xlm_roberta_embeddings"], [73, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [74, 0, 0, "-", "xlnet_embeddings"]], "python.sparknlp.annotator.embeddings.albert_embeddings": [[55, 1, 1, "", "AlbertEmbeddings"]], "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[55, 2, 1, "", "loadSavedModel"], [55, 2, 1, "", "pretrained"], [55, 2, 1, "", "setConfigProtoBytes"], [55, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.bert_embeddings": [[56, 1, 1, "", "BertEmbeddings"]], "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[56, 2, 1, "", "loadSavedModel"], [56, 2, 1, "", "pretrained"], [56, 2, 1, "", "setConfigProtoBytes"], [56, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings": [[57, 1, 1, "", "BertSentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[57, 2, 1, "", "loadSavedModel"], [57, 2, 1, "", "pretrained"], [57, 2, 1, "", "setConfigProtoBytes"], [57, 2, 1, "", "setIsLong"], [57, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.camembert_embeddings": [[58, 1, 1, "", "CamemBertEmbeddings"]], "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[58, 2, 1, "", "loadSavedModel"], [58, 2, 1, "", "pretrained"], [58, 2, 1, "", "setConfigProtoBytes"], [58, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.chunk_embeddings": [[59, 1, 1, "", "ChunkEmbeddings"]], "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[59, 2, 1, "", "setPoolingStrategy"], [59, 2, 1, "", "setSkipOOV"]], "python.sparknlp.annotator.embeddings.deberta_embeddings": [[60, 1, 1, "", "DeBertaEmbeddings"]], "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[60, 2, 1, "", "loadSavedModel"], [60, 2, 1, "", "pretrained"], [60, 2, 1, "", "setConfigProtoBytes"], [60, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings": [[61, 1, 1, "", "DistilBertEmbeddings"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[61, 2, 1, "", "loadSavedModel"], [61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setConfigProtoBytes"], [61, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.doc2vec": [[62, 1, 1, "", "Doc2VecApproach"], [62, 1, 1, "", "Doc2VecModel"]], "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[62, 2, 1, "", "setMaxIter"], [62, 2, 1, "", "setMaxSentenceLength"], [62, 2, 1, "", "setMinCount"], [62, 2, 1, "", "setNumPartitions"], [62, 2, 1, "", "setSeed"], [62, 2, 1, "", "setStepSize"], [62, 2, 1, "", "setVectorSize"], [62, 2, 1, "", "setWindowSize"]], "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[62, 2, 1, "", "pretrained"], [62, 2, 1, "", "setVectorSize"]], "python.sparknlp.annotator.embeddings.elmo_embeddings": [[63, 1, 1, "", "ElmoEmbeddings"]], "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[63, 2, 1, "", "loadSavedModel"], [63, 2, 1, "", "pretrained"], [63, 2, 1, "", "setBatchSize"], [63, 2, 1, "", "setConfigProtoBytes"], [63, 2, 1, "", "setPoolingLayer"]], "python.sparknlp.annotator.embeddings.longformer_embeddings": [[65, 1, 1, "", "LongformerEmbeddings"]], "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[65, 2, 1, "", "loadSavedModel"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setConfigProtoBytes"], [65, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.roberta_embeddings": [[66, 1, 1, "", "RoBertaEmbeddings"]], "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[66, 2, 1, "", "loadSavedModel"], [66, 2, 1, "", "pretrained"], [66, 2, 1, "", "setConfigProtoBytes"], [66, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[67, 1, 1, "", "RoBertaSentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[67, 2, 1, "", "loadSavedModel"], [67, 2, 1, "", "pretrained"], [67, 2, 1, "", "setConfigProtoBytes"], [67, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.sentence_embeddings": [[68, 1, 1, "", "SentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[68, 2, 1, "", "setPoolingStrategy"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder": [[69, 1, 1, "", "UniversalSentenceEncoder"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[69, 2, 1, "", "loadSavedModel"], [69, 2, 1, "", "pretrained"], [69, 2, 1, "", "setConfigProtoBytes"], [69, 2, 1, "", "setLoadSP"]], "python.sparknlp.annotator.embeddings.word2vec": [[70, 1, 1, "", "Word2VecApproach"], [70, 1, 1, "", "Word2VecModel"]], "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[70, 2, 1, "", "setMaxIter"], [70, 2, 1, "", "setMaxSentenceLength"], [70, 2, 1, "", "setMinCount"], [70, 2, 1, "", "setNumPartitions"], [70, 2, 1, "", "setSeed"], [70, 2, 1, "", "setStepSize"], [70, 2, 1, "", "setVectorSize"], [70, 2, 1, "", "setWindowSize"]], "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[70, 2, 1, "", "pretrained"], [70, 2, 1, "", "setVectorSize"]], "python.sparknlp.annotator.embeddings.word_embeddings": [[71, 1, 1, "", "WordEmbeddings"], [71, 1, 1, "", "WordEmbeddingsModel"]], "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[71, 2, 1, "", "setReadCacheSize"], [71, 2, 1, "", "setWriteBufferSize"]], "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[71, 2, 1, "", "loadStorage"], [71, 2, 1, "", "overallCoverage"], [71, 2, 1, "", "pretrained"], [71, 2, 1, "", "setReadCacheSize"], [71, 2, 1, "", "withCoverageColumn"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[72, 1, 1, "", "XlmRoBertaEmbeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[72, 2, 1, "", "loadSavedModel"], [72, 2, 1, "", "pretrained"], [72, 2, 1, "", "setConfigProtoBytes"], [72, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[73, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[73, 2, 1, "", "loadSavedModel"], [73, 2, 1, "", "pretrained"], [73, 2, 1, "", "setConfigProtoBytes"], [73, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings": [[74, 1, 1, "", "XlnetEmbeddings"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[74, 2, 1, "", "loadSavedModel"], [74, 2, 1, "", "pretrained"], [74, 2, 1, "", "setConfigProtoBytes"], [74, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.er": [[75, 0, 0, "-", "entity_ruler"]], "python.sparknlp.annotator.er.entity_ruler": [[75, 1, 1, "", "EntityRulerApproach"], [75, 1, 1, "", "EntityRulerModel"]], "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[75, 2, 1, "", "setAlphabetResource"], [75, 2, 1, "", "setEnablePatternRegex"], [75, 2, 1, "", "setPatternsResource"], [75, 2, 1, "", "setSentenceMatch"], [75, 2, 1, "", "setUseStorage"]], "python.sparknlp.annotator.graph_extraction": [[77, 1, 1, "", "GraphExtraction"]], "python.sparknlp.annotator.graph_extraction.GraphExtraction": [[77, 2, 1, "", "setDelimiter"], [77, 2, 1, "", "setDependencyParserModel"], [77, 2, 1, "", "setEntityTypes"], [77, 2, 1, "", "setExplodeEntities"], [77, 2, 1, "", "setIncludeEdges"], [77, 2, 1, "", "setMaxSentenceSize"], [77, 2, 1, "", "setMergeEntities"], [77, 2, 1, "", "setMergeEntitiesIOBFormat"], [77, 2, 1, "", "setMinSentenceSize"], [77, 2, 1, "", "setPosModel"], [77, 2, 1, "", "setRelationshipTypes"], [77, 2, 1, "", "setRootTokens"], [77, 2, 1, "", "setTypedDependencyParserModel"]], "python.sparknlp.annotator.keyword_extraction": [[80, 0, 0, "-", "yake_keyword_extraction"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[80, 1, 1, "", "YakeKeywordExtraction"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[80, 2, 1, "", "getStopWords"], [80, 2, 1, "", "loadDefaultStopWords"], [80, 2, 1, "", "setMaxNGrams"], [80, 2, 1, "", "setMinNGrams"], [80, 2, 1, "", "setNKeywords"], [80, 2, 1, "", "setStopWords"], [80, 2, 1, "", "setThreshold"], [80, 2, 1, "", "setWindowSize"]], "python.sparknlp.annotator.ld_dl": [[82, 0, 0, "-", "language_detector_dl"]], "python.sparknlp.annotator.ld_dl.language_detector_dl": [[82, 1, 1, "", "LanguageDetectorDL"]], "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[82, 2, 1, "", "pretrained"], [82, 2, 1, "", "setCoalesceSentences"], [82, 2, 1, "", "setConfigProtoBytes"], [82, 2, 1, "", "setThreshold"], [82, 2, 1, "", "setThresholdLabel"]], "python.sparknlp.annotator.lemmatizer": [[83, 1, 1, "", "Lemmatizer"], [83, 1, 1, "", "LemmatizerModel"]], "python.sparknlp.annotator.lemmatizer.Lemmatizer": [[83, 2, 1, "", "setDictionary"], [83, 2, 1, "", "setFormCol"], [83, 2, 1, "", "setLemmaCol"]], "python.sparknlp.annotator.lemmatizer.LemmatizerModel": [[83, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.matcher": [[84, 0, 0, "-", "big_text_matcher"], [85, 0, 0, "-", "date_matcher"], [87, 0, 0, "-", "multi_date_matcher"], [88, 0, 0, "-", "regex_matcher"], [89, 0, 0, "-", "text_matcher"]], "python.sparknlp.annotator.matcher.big_text_matcher": [[84, 1, 1, "", "BigTextMatcher"], [84, 1, 1, "", "BigTextMatcherModel"]], "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[84, 2, 1, "", "setCaseSensitive"], [84, 2, 1, "", "setEntities"], [84, 2, 1, "", "setMergeOverlapping"], [84, 2, 1, "", "setTokenizer"]], "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[84, 2, 1, "", "loadStorage"], [84, 2, 1, "", "pretrained"], [84, 2, 1, "", "setCaseSensitive"], [84, 2, 1, "", "setMergeOverlapping"]], "python.sparknlp.annotator.matcher.date_matcher": [[85, 1, 1, "", "DateMatcher"], [85, 1, 1, "", "DateMatcherUtils"]], "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[85, 2, 1, "", "setAnchorDateDay"], [85, 2, 1, "", "setAnchorDateMonth"], [85, 2, 1, "", "setAnchorDateYear"], [85, 2, 1, "", "setDefaultDayWhenMissing"], [85, 2, 1, "", "setInputFormats"], [85, 2, 1, "", "setOutputFormat"], [85, 2, 1, "", "setReadMonthFirst"]], "python.sparknlp.annotator.matcher.multi_date_matcher": [[87, 1, 1, "", "MultiDateMatcher"]], "python.sparknlp.annotator.matcher.regex_matcher": [[88, 1, 1, "", "RegexMatcher"], [88, 1, 1, "", "RegexMatcherModel"]], "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[88, 2, 1, "", "setDelimiter"], [88, 2, 1, "", "setExternalRules"], [88, 2, 1, "", "setRules"], [88, 2, 1, "", "setStrategy"]], "python.sparknlp.annotator.matcher.text_matcher": [[89, 1, 1, "", "TextMatcher"], [89, 1, 1, "", "TextMatcherModel"]], "python.sparknlp.annotator.matcher.text_matcher.TextMatcher": [[89, 2, 1, "", "setBuildFromTokens"], [89, 2, 1, "", "setCaseSensitive"], [89, 2, 1, "", "setEntities"], [89, 2, 1, "", "setEntityValue"], [89, 2, 1, "", "setMergeOverlapping"]], "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[89, 2, 1, "", "pretrained"], [89, 2, 1, "", "setBuildFromTokens"], [89, 2, 1, "", "setEntityValue"], [89, 2, 1, "", "setMergeOverlapping"]], "python.sparknlp.annotator.n_gram_generator": [[90, 1, 1, "", "NGramGenerator"]], "python.sparknlp.annotator.n_gram_generator.NGramGenerator": [[90, 2, 1, "", "setDelimiter"], [90, 2, 1, "", "setEnableCumulative"], [90, 2, 1, "", "setN"]], "python.sparknlp.annotator.ner": [[92, 0, 0, "-", "ner_approach"], [93, 0, 0, "-", "ner_converter"], [94, 0, 0, "-", "ner_crf"], [95, 0, 0, "-", "ner_dl"], [96, 0, 0, "-", "ner_overwriter"]], "python.sparknlp.annotator.ner.ner_approach": [[92, 1, 1, "", "NerApproach"]], "python.sparknlp.annotator.ner.ner_approach.NerApproach": [[92, 2, 1, "", "getLabelColumn"], [92, 2, 1, "", "setEntities"], [92, 2, 1, "", "setLabelColumn"], [92, 2, 1, "", "setMaxEpochs"], [92, 2, 1, "", "setMinEpochs"], [92, 2, 1, "", "setRandomSeed"]], "python.sparknlp.annotator.ner.ner_converter": [[93, 1, 1, "", "NerConverter"]], "python.sparknlp.annotator.ner.ner_converter.NerConverter": [[93, 2, 1, "", "setPreservePosition"], [93, 2, 1, "", "setWhiteList"]], "python.sparknlp.annotator.ner.ner_crf": [[94, 1, 1, "", "NerCrfApproach"], [94, 1, 1, "", "NerCrfModel"]], "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[94, 2, 1, "", "setC0"], [94, 2, 1, "", "setExternalFeatures"], [94, 2, 1, "", "setIncludeConfidence"], [94, 2, 1, "", "setL2"], [94, 2, 1, "", "setLossEps"], [94, 2, 1, "", "setMinW"], [94, 2, 1, "", "setVerbose"]], "python.sparknlp.annotator.ner.ner_crf.NerCrfModel": [[94, 2, 1, "", "pretrained"], [94, 2, 1, "", "setIncludeConfidence"]], "python.sparknlp.annotator.ner.ner_dl": [[95, 1, 1, "", "NerDLApproach"], [95, 1, 1, "", "NerDLModel"]], "python.sparknlp.annotator.ner.ner_dl.NerDLApproach": [[95, 2, 1, "", "setBatchSize"], [95, 2, 1, "", "setBestModelMetric"], [95, 2, 1, "", "setConfigProtoBytes"], [95, 2, 1, "", "setDropout"], [95, 2, 1, "", "setEnableMemoryOptimizer"], [95, 2, 1, "", "setGraphFolder"], [95, 2, 1, "", "setIncludeAllConfidenceScores"], [95, 2, 1, "", "setIncludeConfidence"], [95, 2, 1, "", "setLr"], [95, 2, 1, "", "setPo"], [95, 2, 1, "", "setUseBestModel"], [95, 2, 1, "", "setUseContrib"]], "python.sparknlp.annotator.ner.ner_dl.NerDLModel": [[95, 2, 1, "", "pretrained"], [95, 2, 1, "", "setConfigProtoBytes"], [95, 2, 1, "", "setIncludeAllConfidenceScores"], [95, 2, 1, "", "setIncludeConfidence"]], "python.sparknlp.annotator.ner.ner_overwriter": [[96, 1, 1, "", "NerOverwriter"]], "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[96, 2, 1, "", "setNerWords"], [96, 2, 1, "", "setNewNerEntity"], [96, 2, 1, "", "setReplaceEntities"]], "python.sparknlp.annotator.normalizer": [[97, 1, 1, "", "Normalizer"], [97, 1, 1, "", "NormalizerModel"]], "python.sparknlp.annotator.normalizer.Normalizer": [[97, 2, 1, "", "setCleanupPatterns"], [97, 2, 1, "", "setLowercase"], [97, 2, 1, "", "setMaxLength"], [97, 2, 1, "", "setMinLength"], [97, 2, 1, "", "setSlangDictionary"]], "python.sparknlp.annotator.param": [[98, 0, 0, "-", "classifier_encoder"], [99, 0, 0, "-", "evaluation_dl_params"]], "python.sparknlp.annotator.param.classifier_encoder": [[98, 1, 1, "", "ClassifierEncoder"]], "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[98, 2, 1, "", "setBatchSize"], [98, 2, 1, "", "setConfigProtoBytes"], [98, 2, 1, "", "setLabelColumn"], [98, 2, 1, "", "setLr"], [98, 2, 1, "", "setMaxEpochs"], [98, 2, 1, "", "setRandomSeed"]], "python.sparknlp.annotator.param.evaluation_dl_params": [[99, 1, 1, "", "EvaluationDLParams"]], "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[99, 2, 1, "", "setEnableOutputLogs"], [99, 2, 1, "", "setEvaluationLogExtended"], [99, 2, 1, "", "setOutputLogsPath"], [99, 2, 1, "", "setTestDataset"], [99, 2, 1, "", "setValidationSplit"], [99, 2, 1, "", "setVerbose"]], "python.sparknlp.annotator.pos": [[102, 0, 0, "-", "perceptron"]], "python.sparknlp.annotator.pos.perceptron": [[102, 1, 1, "", "PerceptronApproach"], [102, 1, 1, "", "PerceptronModel"]], "python.sparknlp.annotator.pos.perceptron.PerceptronApproach": [[102, 2, 1, "", "getNIterations"], [102, 2, 1, "", "setIterations"], [102, 2, 1, "", "setPosColumn"]], "python.sparknlp.annotator.pos.perceptron.PerceptronModel": [[102, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.sentence": [[104, 0, 0, "-", "sentence_detector"], [105, 0, 0, "-", "sentence_detector_dl"]], "python.sparknlp.annotator.sentence.sentence_detector": [[104, 1, 1, "", "SentenceDetector"], [104, 1, 1, "", "SentenceDetectorParams"]], "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[104, 2, 1, "", "setCustomBounds"], [104, 2, 1, "", "setCustomBoundsStrategy"], [104, 2, 1, "", "setDetectLists"], [104, 2, 1, "", "setExplodeSentences"], [104, 2, 1, "", "setMaxLength"], [104, 2, 1, "", "setMinLength"], [104, 2, 1, "", "setSplitLength"], [104, 2, 1, "", "setUseAbbreviations"], [104, 2, 1, "", "setUseCustomBoundsOnly"]], "python.sparknlp.annotator.sentence.sentence_detector_dl": [[105, 1, 1, "", "SentenceDetectorDLApproach"], [105, 1, 1, "", "SentenceDetectorDLModel"]], "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[105, 2, 1, "", "setEpochsNumber"], [105, 2, 1, "", "setExplodeSentences"], [105, 2, 1, "", "setImpossiblePenultimates"], [105, 2, 1, "", "setModel"], [105, 2, 1, "", "setOutputLogsPath"], [105, 2, 1, "", "setValidationSplit"]], "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[105, 2, 1, "", "pretrained"], [105, 2, 1, "", "setCustomBounds"], [105, 2, 1, "", "setExplodeSentences"], [105, 2, 1, "", "setImpossiblePenultimates"], [105, 2, 1, "", "setMaxLength"], [105, 2, 1, "", "setMinLength"], [105, 2, 1, "", "setModel"], [105, 2, 1, "", "setSplitLength"], [105, 2, 1, "", "setUseCustomBoundsOnly"]], "python.sparknlp.annotator.sentiment": [[107, 0, 0, "-", "sentiment_detector"], [108, 0, 0, "-", "vivekn_sentiment"]], "python.sparknlp.annotator.sentiment.sentiment_detector": [[107, 1, 1, "", "SentimentDetector"], [107, 1, 1, "", "SentimentDetectorModel"]], "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[107, 2, 1, "", "setDictionary"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment": [[108, 1, 1, "", "ViveknSentimentApproach"], [108, 1, 1, "", "ViveknSentimentModel"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[108, 2, 1, "", "setPruneCorpus"], [108, 2, 1, "", "setSentimentCol"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[108, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.seq2seq": [[109, 0, 0, "-", "gpt2_transformer"], [111, 0, 0, "-", "marian_transformer"], [112, 0, 0, "-", "t5_transformer"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer": [[109, 1, 1, "", "GPT2Transformer"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[109, 2, 1, "", "loadSavedModel"], [109, 2, 1, "", "pretrained"], [109, 2, 1, "", "setConfigProtoBytes"], [109, 2, 1, "", "setDoSample"], [109, 2, 1, "", "setIgnoreTokenIds"], [109, 2, 1, "", "setMaxOutputLength"], [109, 2, 1, "", "setMinOutputLength"], [109, 2, 1, "", "setNoRepeatNgramSize"], [109, 2, 1, "", "setRepetitionPenalty"], [109, 2, 1, "", "setTask"], [109, 2, 1, "", "setTemperature"], [109, 2, 1, "", "setTopK"], [109, 2, 1, "", "setTopP"]], "python.sparknlp.annotator.seq2seq.marian_transformer": [[111, 1, 1, "", "MarianTransformer"]], "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[111, 2, 1, "", "loadSavedModel"], [111, 2, 1, "", "pretrained"], [111, 2, 1, "", "setConfigProtoBytes"], [111, 2, 1, "", "setIgnoreTokenIds"], [111, 2, 1, "", "setLangId"], [111, 2, 1, "", "setMaxInputLength"], [111, 2, 1, "", "setMaxOutputLength"]], "python.sparknlp.annotator.seq2seq.t5_transformer": [[112, 1, 1, "", "T5Transformer"]], "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[112, 2, 1, "", "loadSavedModel"], [112, 2, 1, "", "pretrained"], [112, 2, 1, "", "setConfigProtoBytes"], [112, 2, 1, "", "setDoSample"], [112, 2, 1, "", "setIgnoreTokenIds"], [112, 2, 1, "", "setMaxOutputLength"], [112, 2, 1, "", "setMinOutputLength"], [112, 2, 1, "", "setNoRepeatNgramSize"], [112, 2, 1, "", "setRepetitionPenalty"], [112, 2, 1, "", "setTask"], [112, 2, 1, "", "setTemperature"], [112, 2, 1, "", "setTopK"], [112, 2, 1, "", "setTopP"]], "python.sparknlp.annotator.spell_check": [[113, 0, 0, "-", "context_spell_checker"], [115, 0, 0, "-", "norvig_sweeting"], [116, 0, 0, "-", "symmetric_delete"]], "python.sparknlp.annotator.spell_check.context_spell_checker": [[113, 1, 1, "", "ContextSpellCheckerApproach"], [113, 1, 1, "", "ContextSpellCheckerModel"]], "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[113, 2, 1, "", "addRegexClass"], [113, 2, 1, "", "addVocabClass"], [113, 2, 1, "", "setBatchSize"], [113, 2, 1, "", "setCaseStrategy"], [113, 2, 1, "", "setClassCount"], [113, 2, 1, "", "setCompoundCount"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setEpochs"], [113, 2, 1, "", "setErrorThreshold"], [113, 2, 1, "", "setFinalRate"], [113, 2, 1, "", "setInitialRate"], [113, 2, 1, "", "setLanguageModelClasses"], [113, 2, 1, "", "setMaxCandidates"], [113, 2, 1, "", "setMaxWindowLen"], [113, 2, 1, "", "setMinCount"], [113, 2, 1, "", "setTradeoff"], [113, 2, 1, "", "setValidationFraction"], [113, 2, 1, "id0", "setWeightedDistPath"], [113, 2, 1, "", "setWordMaxDistance"]], "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[113, 2, 1, "", "getWordClasses"], [113, 2, 1, "", "pretrained"], [113, 2, 1, "", "setCaseStrategy"], [113, 2, 1, "", "setCompareLowcase"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setCorrectSymbols"], [113, 2, 1, "", "setErrorThreshold"], [113, 2, 1, "", "setGamma"], [113, 2, 1, "", "setMaxCandidates"], [113, 2, 1, "", "setMaxWindowLen"], [113, 2, 1, "", "setTradeoff"], [113, 2, 1, "", "setWeights"], [113, 2, 1, "", "setWordMaxDistance"], [113, 2, 1, "", "updateRegexClass"], [113, 2, 1, "", "updateVocabClass"]], "python.sparknlp.annotator.spell_check.norvig_sweeting": [[115, 1, 1, "", "NorvigSweetingApproach"], [115, 1, 1, "", "NorvigSweetingModel"]], "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[115, 2, 1, "", "setCaseSensitive"], [115, 2, 1, "", "setDictionary"], [115, 2, 1, "", "setDoubleVariants"], [115, 2, 1, "", "setFrequencyPriority"], [115, 2, 1, "", "setShortCircuit"]], "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[115, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.spell_check.symmetric_delete": [[116, 1, 1, "", "SymmetricDeleteApproach"], [116, 1, 1, "", "SymmetricDeleteModel"]], "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[116, 2, 1, "", "setDeletesThreshold"], [116, 2, 1, "", "setDictionary"], [116, 2, 1, "", "setFrequencyThreshold"], [116, 2, 1, "", "setMaxEditDistance"]], "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[116, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.stemmer": [[117, 1, 1, "", "Stemmer"]], "python.sparknlp.annotator.stop_words_cleaner": [[118, 1, 1, "", "StopWordsCleaner"]], "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[118, 2, 1, "", "loadDefaultStopWords"], [118, 2, 1, "", "pretrained"], [118, 2, 1, "", "setCaseSensitive"], [118, 2, 1, "", "setLocale"], [118, 2, 1, "", "setStopWords"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder": [[119, 1, 1, "", "TFNerDLGraphBuilder"], [119, 1, 1, "", "TFNerDLGraphBuilderModel"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[119, 2, 1, "", "getGraphFile"], [119, 2, 1, "", "getGraphFolder"], [119, 2, 1, "", "getHiddenUnitsNumber"], [119, 2, 1, "", "getInputCols"], [119, 2, 1, "", "getLabelColumn"], [119, 2, 1, "", "setGraphFile"], [119, 2, 1, "", "setGraphFolder"], [119, 2, 1, "", "setHiddenUnitsNumber"], [119, 2, 1, "", "setInputCols"], [119, 2, 1, "", "setLabelColumn"]], "python.sparknlp.annotator.token": [[120, 0, 0, "-", "chunk_tokenizer"], [122, 0, 0, "-", "recursive_tokenizer"], [123, 0, 0, "-", "regex_tokenizer"], [124, 0, 0, "-", "token2_chunk"], [125, 0, 0, "-", "tokenizer"]], "python.sparknlp.annotator.token.chunk_tokenizer": [[120, 1, 1, "", "ChunkTokenizer"], [120, 1, 1, "", "ChunkTokenizerModel"]], "python.sparknlp.annotator.token.recursive_tokenizer": [[122, 1, 1, "", "RecursiveTokenizer"], [122, 1, 1, "", "RecursiveTokenizerModel"]], "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[122, 2, 1, "", "setInfixes"], [122, 2, 1, "", "setPrefixes"], [122, 2, 1, "", "setSuffixes"], [122, 2, 1, "", "setWhitelist"]], "python.sparknlp.annotator.token.regex_tokenizer": [[123, 1, 1, "", "RegexTokenizer"]], "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[123, 2, 1, "", "setMaxLength"], [123, 2, 1, "", "setMinLength"], [123, 2, 1, "", "setPattern"], [123, 2, 1, "", "setPositionalMask"], [123, 2, 1, "", "setPreservePosition"], [123, 2, 1, "", "setToLowercase"], [123, 2, 1, "", "setTrimWhitespace"]], "python.sparknlp.annotator.token.token2_chunk": [[124, 1, 1, "", "Token2Chunk"]], "python.sparknlp.annotator.token.tokenizer": [[125, 1, 1, "", "Tokenizer"], [125, 1, 1, "", "TokenizerModel"]], "python.sparknlp.annotator.token.tokenizer.Tokenizer": [[125, 2, 1, "", "addContextChars"], [125, 2, 1, "", "addException"], [125, 2, 1, "", "addInfixPattern"], [125, 2, 1, "", "addSplitChars"], [125, 2, 1, "", "getCaseSensitiveExceptions"], [125, 2, 1, "", "getContextChars"], [125, 2, 1, "", "getExceptions"], [125, 2, 1, "", "getInfixPatterns"], [125, 2, 1, "", "getPrefixPattern"], [125, 2, 1, "", "getSplitChars"], [125, 2, 1, "", "getSuffixPattern"], [125, 2, 1, "", "setCaseSensitiveExceptions"], [125, 2, 1, "", "setContextChars"], [125, 2, 1, "", "setExceptions"], [125, 2, 1, "", "setExceptionsPath"], [125, 2, 1, "", "setInfixPatterns"], [125, 2, 1, "", "setMaxLength"], [125, 2, 1, "", "setMinLength"], [125, 2, 1, "", "setPrefixPattern"], [125, 2, 1, "", "setSplitChars"], [125, 2, 1, "", "setSplitPattern"], [125, 2, 1, "", "setSuffixPattern"], [125, 2, 1, "", "setTargetPattern"]], "python.sparknlp.annotator.token.tokenizer.TokenizerModel": [[125, 2, 1, "", "addSplitChars"], [125, 2, 1, "", "pretrained"], [125, 2, 1, "", "setSplitChars"], [125, 2, 1, "", "setSplitPattern"]], "python.sparknlp.annotator.ws": [[127, 0, 0, "-", "word_segmenter"]], "python.sparknlp.annotator.ws.word_segmenter": [[127, 1, 1, "", "WordSegmenterApproach"], [127, 1, 1, "", "WordSegmenterModel"]], "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[127, 2, 1, "", "getAmbiguityThreshold"], [127, 2, 1, "", "getFrequencyThreshold"], [127, 2, 1, "", "getNIterations"], [127, 2, 1, "", "setAmbiguityThreshold"], [127, 2, 1, "", "setEnableRegexTokenizer"], [127, 2, 1, "", "setFrequencyThreshold"], [127, 2, 1, "", "setNIterations"], [127, 2, 1, "", "setPattern"], [127, 2, 1, "", "setPosColumn"], [127, 2, 1, "", "setToLowercase"]], "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[127, 2, 1, "", "pretrained"], [127, 2, 1, "", "setEnableRegexTokenizer"], [127, 2, 1, "", "setPattern"], [127, 2, 1, "", "setToLowercase"]], "python.sparknlp.base": [[128, 0, 0, "-", "audio_assembler"], [129, 0, 0, "-", "chunk2_doc"], [130, 0, 0, "-", "doc2_chunk"], [131, 0, 0, "-", "document_assembler"], [132, 0, 0, "-", "embeddings_finisher"], [133, 0, 0, "-", "finisher"], [134, 0, 0, "-", "graph_finisher"], [135, 0, 0, "-", "has_recursive_fit"], [136, 0, 0, "-", "has_recursive_transform"], [137, 0, 0, "-", "image_assembler"], [139, 0, 0, "-", "light_pipeline"], [140, 0, 0, "-", "multi_document_assembler"], [141, 0, 0, "-", "recursive_pipeline"], [142, 0, 0, "-", "table_assembler"], [143, 0, 0, "-", "token_assembler"]], "python.sparknlp.base.audio_assembler": [[128, 1, 1, "", "AudioAssembler"]], "python.sparknlp.base.audio_assembler.AudioAssembler": [[128, 2, 1, "", "setInputCol"], [128, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.chunk2_doc": [[129, 1, 1, "", "Chunk2Doc"]], "python.sparknlp.base.doc2_chunk": [[130, 1, 1, "", "Doc2Chunk"]], "python.sparknlp.base.doc2_chunk.Doc2Chunk": [[130, 2, 1, "", "setChunkCol"], [130, 2, 1, "", "setFailOnMissing"], [130, 2, 1, "", "setIsArray"], [130, 2, 1, "", "setLowerCase"], [130, 2, 1, "", "setStartCol"], [130, 2, 1, "", "setStartColByTokenIndex"]], "python.sparknlp.base.document_assembler": [[131, 1, 1, "", "DocumentAssembler"]], "python.sparknlp.base.document_assembler.DocumentAssembler": [[131, 2, 1, "", "setCleanupMode"], [131, 2, 1, "", "setIdCol"], [131, 2, 1, "", "setInputCol"], [131, 2, 1, "", "setMetadataCol"], [131, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.embeddings_finisher": [[132, 1, 1, "", "EmbeddingsFinisher"]], "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[132, 2, 1, "", "setCleanAnnotations"], [132, 2, 1, "", "setInputCols"], [132, 2, 1, "", "setOutputAsVector"], [132, 2, 1, "", "setOutputCols"]], "python.sparknlp.base.finisher": [[133, 1, 1, "", "Finisher"]], "python.sparknlp.base.finisher.Finisher": [[133, 2, 1, "", "setAnnotationSplitSymbol"], [133, 2, 1, "", "setCleanAnnotations"], [133, 2, 1, "", "setIncludeMetadata"], [133, 2, 1, "", "setInputCols"], [133, 2, 1, "", "setOutputAsArray"], [133, 2, 1, "", "setOutputCols"], [133, 2, 1, "", "setParseEmbeddingsVectors"], [133, 2, 1, "", "setValueSplitSymbol"]], "python.sparknlp.base.graph_finisher": [[134, 1, 1, "", "GraphFinisher"]], "python.sparknlp.base.graph_finisher.GraphFinisher": [[134, 2, 1, "", "setCleanAnnotations"], [134, 2, 1, "", "setInputCol"], [134, 2, 1, "", "setOutputAsArray"], [134, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.has_recursive_fit": [[135, 1, 1, "", "HasRecursiveFit"]], "python.sparknlp.base.has_recursive_transform": [[136, 1, 1, "", "HasRecursiveTransform"]], "python.sparknlp.base.image_assembler": [[137, 1, 1, "", "ImageAssembler"]], "python.sparknlp.base.image_assembler.ImageAssembler": [[137, 2, 1, "", "setInputCol"], [137, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.light_pipeline": [[139, 1, 1, "", "LightPipeline"]], "python.sparknlp.base.light_pipeline.LightPipeline": [[139, 2, 1, "", "annotate"], [139, 2, 1, "", "fullAnnotate"], [139, 2, 1, "", "fullAnnotateImage"], [139, 2, 1, "", "getIgnoreUnsupported"], [139, 2, 1, "", "setIgnoreUnsupported"], [139, 2, 1, "", "transform"]], "python.sparknlp.base.multi_document_assembler": [[140, 1, 1, "", "MultiDocumentAssembler"]], "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[140, 2, 1, "", "setCleanupMode"], [140, 2, 1, "", "setIdCol"], [140, 2, 1, "", "setInputCols"], [140, 2, 1, "", "setMetadataCol"], [140, 2, 1, "", "setOutputCols"]], "python.sparknlp.base.recursive_pipeline": [[141, 1, 1, "", "RecursivePipeline"], [141, 1, 1, "", "RecursivePipelineModel"]], "python.sparknlp.base.table_assembler": [[142, 1, 1, "", "TableAssembler"]], "python.sparknlp.base.table_assembler.TableAssembler": [[142, 2, 1, "", "setCsvDelimiter"], [142, 2, 1, "", "setEscapeCsvDelimiter"], [142, 2, 1, "", "setInputFormat"]], "python.sparknlp.base.token_assembler": [[143, 1, 1, "", "TokenAssembler"]], "python.sparknlp.base.token_assembler.TokenAssembler": [[143, 2, 1, "", "setPreservePosition"]], "python.sparknlp.common": [[144, 0, 0, "-", "annotator_approach"], [145, 0, 0, "-", "annotator_model"], [146, 0, 0, "-", "annotator_properties"], [147, 0, 0, "-", "annotator_type"], [148, 0, 0, "-", "coverage_result"], [150, 0, 0, "-", "properties"], [151, 0, 0, "-", "read_as"], [152, 0, 0, "-", "recursive_annotator_approach"], [153, 0, 0, "-", "storage"], [154, 0, 0, "-", "utils"]], "python.sparknlp.common.annotator_approach": [[144, 1, 1, "", "AnnotatorApproach"]], "python.sparknlp.common.annotator_model": [[145, 1, 1, "", "AnnotatorModel"]], "python.sparknlp.common.annotator_properties": [[146, 1, 1, "", "AnnotatorProperties"]], "python.sparknlp.common.annotator_properties.AnnotatorProperties": [[146, 2, 1, "", "getInputCols"], [146, 2, 1, "", "getLazyAnnotator"], [146, 2, 1, "", "getOutputCol"], [146, 2, 1, "", "setInputCols"], [146, 2, 1, "", "setLazyAnnotator"], [146, 2, 1, "", "setOutputCol"]], "python.sparknlp.common.properties": [[150, 1, 1, "", "HasEmbeddingsProperties"]], "python.sparknlp.common.properties.HasEmbeddingsProperties": [[150, 2, 1, "", "getDimension"], [150, 2, 1, "", "setDimension"]], "python.sparknlp.common.read_as": [[151, 1, 1, "", "ReadAs"]], "python.sparknlp.common.recursive_annotator_approach": [[152, 1, 1, "", "RecursiveAnnotatorApproach"]], "python.sparknlp.common.utils": [[154, 3, 1, "", "ExternalResource"]], "python.sparknlp.functions": [[155, 3, 1, "", "explode_annotations_col"], [155, 3, 1, "", "filter_by_annotations_col"], [155, 3, 1, "", "map_annotations"], [155, 3, 1, "", "map_annotations_array"], [155, 3, 1, "", "map_annotations_col"], [155, 3, 1, "", "map_annotations_cols"], [155, 3, 1, "", "map_annotations_strict"]], "python.sparknlp.internal": [[157, 0, 0, "-", "annotator_java_ml"], [158, 0, 0, "-", "annotator_transformer"], [159, 0, 0, "-", "extended_java_wrapper"], [161, 0, 0, "-", "params_getters_setters"], [162, 0, 0, "-", "recursive"]], "python.sparknlp.internal.annotator_java_ml": [[157, 1, 1, "", "AnnotatorJavaMLReadable"], [157, 1, 1, "", "AnnotatorJavaMLReader"]], "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[157, 2, 1, "", "read"]], "python.sparknlp.internal.annotator_transformer": [[158, 1, 1, "", "AnnotatorTransformer"]], "python.sparknlp.internal.extended_java_wrapper": [[159, 1, 1, "", "ExtendedJavaWrapper"]], "python.sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[159, 2, 1, "", "new_java_array"]], "python.sparknlp.internal.params_getters_setters": [[161, 1, 1, "", "ParamsGettersSetters"]], "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[161, 2, 1, "", "getParamValue"], [161, 2, 1, "", "setParamValue"]], "python.sparknlp.internal.recursive": [[162, 1, 1, "", "RecursiveEstimator"], [162, 1, 1, "", "RecursiveTransformer"]], "python.sparknlp.internal.recursive.RecursiveEstimator": [[162, 2, 1, "", "fit"]], "python.sparknlp.logging": [[163, 0, 0, "-", "comet"]], "python.sparknlp.logging.comet": [[163, 1, 1, "", "CometLogger"]], "python.sparknlp.logging.comet.CometLogger": [[163, 2, 1, "", "end"], [163, 2, 1, "", "log_asset"], [163, 2, 1, "", "log_asset_data"], [163, 2, 1, "", "log_completed_run"], [163, 2, 1, "", "log_metrics"], [163, 2, 1, "", "log_parameters"], [163, 2, 1, "", "log_pipeline_parameters"], [163, 2, 1, "", "log_visualization"], [163, 2, 1, "", "monitor"]], "python.sparknlp.pretrained": [[166, 0, 0, "-", "pretrained_pipeline"], [167, 0, 0, "-", "resource_downloader"], [168, 0, 0, "-", "utils"]], "python.sparknlp.pretrained.pretrained_pipeline": [[166, 1, 1, "", "PretrainedPipeline"]], "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[166, 2, 1, "", "annotate"], [166, 2, 1, "", "fullAnnotate"], [166, 2, 1, "", "fullAnnotateImage"], [166, 2, 1, "", "transform"]], "python.sparknlp.training": [[170, 0, 0, "-", "_tf_graph_builders"], [185, 0, 0, "-", "_tf_graph_builders_1x"], [192, 0, 0, "-", "conll"], [193, 0, 0, "-", "conllu"], [195, 0, 0, "-", "pos"], [196, 0, 0, "-", "pub_tator"], [197, 0, 0, "-", "tfgraphs"]], "python.sparknlp.training._tf_graph_builders": [[169, 0, 0, "-", "graph_builders"], [173, 0, 0, "-", "ner_dl"], [180, 0, 0, "-", "tf2contrib"]], "python.sparknlp.training._tf_graph_builders.graph_builders": [[169, 1, 1, "", "NerTFGraphBuilder"], [169, 1, 1, "", "TFGraphBuilder"], [169, 1, 1, "", "TFGraphBuilderFactory"], [169, 4, 1, "", "TensorflowAddonsNeeded"], [169, 4, 1, "", "WrongTFVersion"]], "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory": [[169, 2, 1, "", "build"], [169, 2, 1, "", "get_models"], [169, 2, 1, "", "print_model_params"]], "python.sparknlp.training._tf_graph_builders.ner_dl": [[171, 0, 0, "-", "create_graph"], [172, 0, 0, "-", "dataset_encoder"], [174, 0, 0, "-", "ner_model"], [175, 0, 0, "-", "ner_model_saver"], [176, 0, 0, "-", "sentence_grouper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib": [[177, 0, 0, "-", "core_rnn_cell"], [178, 0, 0, "-", "fused_rnn_cell"], [179, 0, 0, "-", "gru_ops"], [181, 0, 0, "-", "lstm_ops"], [182, 0, 0, "-", "rnn"], [183, 0, 0, "-", "rnn_cell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[177, 1, 1, "", "EmbeddingWrapper"], [177, 1, 1, "", "InputProjectionWrapper"], [177, 1, 1, "", "OutputProjectionWrapper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper": [[177, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper": [[177, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper": [[177, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[178, 1, 1, "", "FusedRNNCell"], [178, 1, 1, "", "FusedRNNCellAdaptor"], [178, 1, 1, "", "TimeReversedFusedRNN"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[179, 1, 1, "", "GRUBlockCell"], [179, 1, 1, "", "GRUBlockCellV2"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell": [[179, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2": [[179, 2, 1, "", "build"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[181, 1, 1, "", "LSTMBlockCell"], [181, 1, 1, "", "LSTMBlockFusedCell"], [181, 1, 1, "", "LSTMBlockWrapper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell": [[181, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper": [[181, 2, 1, "", "call"], [181, 2, 1, "", "num_units"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[182, 3, 1, "", "stack_bidirectional_dynamic_rnn"], [182, 3, 1, "", "stack_bidirectional_rnn"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[183, 1, 1, "", "AttentionCellWrapper"], [183, 1, 1, "", "BidirectionalGridLSTMCell"], [183, 1, 1, "", "CFNCell"], [183, 1, 1, "", "CompiledWrapper"], [183, 1, 1, "", "Conv1DLSTMCell"], [183, 1, 1, "", "Conv2DLSTMCell"], [183, 1, 1, "", "Conv3DLSTMCell"], [183, 1, 1, "", "ConvLSTMCell"], [183, 1, 1, "", "CoupledInputForgetGateLSTMCell"], [183, 1, 1, "", "GLSTMCell"], [183, 1, 1, "", "GridLSTMCell"], [183, 1, 1, "", "HighwayWrapper"], [183, 1, 1, "", "IndRNNCell"], [183, 1, 1, "", "IndyGRUCell"], [183, 1, 1, "", "IndyLSTMCell"], [183, 1, 1, "", "IntersectionRNNCell"], [183, 1, 1, "", "LayerNormBasicLSTMCell"], [183, 1, 1, "", "LayerNormLSTMCell"], [183, 1, 1, "", "MinimalRNNCell"], [183, 1, 1, "", "NASCell"], [183, 1, 1, "", "NTMCell"], [183, 1, 1, "", "PhasedLSTMCell"], [183, 1, 1, "", "SRUCell"], [183, 1, 1, "", "TimeFreqLSTMCell"], [183, 1, 1, "", "UGRNNCell"], [183, 1, 1, "", "WeightNormLSTMCell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell": [[183, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders_1x": [[184, 0, 0, "-", "graph_builders"], [188, 0, 0, "-", "ner_dl"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders": [[184, 1, 1, "", "NerTFGraphBuilder"], [184, 1, 1, "", "TFGraphBuilder"], [184, 1, 1, "", "TFGraphBuilderFactory"], [184, 4, 1, "", "WrongTFVersion"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory": [[184, 2, 1, "", "build"], [184, 2, 1, "", "get_models"], [184, 2, 1, "", "print_model_params"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl": [[186, 0, 0, "-", "create_graph"], [187, 0, 0, "-", "dataset_encoder"], [189, 0, 0, "-", "ner_model"], [190, 0, 0, "-", "ner_model_saver"], [191, 0, 0, "-", "sentence_grouper"]], "python.sparknlp.training.conll": [[192, 1, 1, "", "CoNLL"]], "python.sparknlp.training.conll.CoNLL": [[192, 2, 1, "", "readDataset"]], "python.sparknlp.training.conllu": [[193, 1, 1, "", "CoNLLU"]], "python.sparknlp.training.conllu.CoNLLU": [[193, 2, 1, "", "readDataset"]], "python.sparknlp.training.pos": [[195, 1, 1, "", "POS"]], "python.sparknlp.training.pos.POS": [[195, 2, 1, "", "readDataset"]], "python.sparknlp.training.pub_tator": [[196, 1, 1, "", "PubTator"]], "python.sparknlp.training.pub_tator.PubTator": [[196, 2, 1, "", "readDataset"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "exception", "Python exception"]}, "titleterms": {"api": [1, 200], "refer": [1, 200], "get": [10, 206], "start": 10, "spark": [10, 11, 201, 206, 210], "nlp": [10, 11, 201, 210], "cheat": 10, "sheet": 10, "requir": 10, "instal": [10, 201], "us": [10, 201, 210], "conda": 10, "virtualenv": 10, "session": 10, "from": 10, "python": [10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], "document": 11, "content": [11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 154, 155, 156, 157, 158, 159, 161, 162, 163, 166, 169, 177, 178, 179, 181, 182, 183, 184, 192, 193, 195, 196], "sparknlp": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], "annot": [12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 204, 205, 206], "modul": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 154, 155, 157, 158, 159, 161, 162, 163, 166, 169, 177, 178, 179, 181, 182, 183, 184, 192, 193, 195, 196, 200], "class": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 150, 151, 152, 157, 158, 159, 161, 162, 163, 166, 169, 177, 178, 179, 181, 183, 184, 192, 193, 195, 196], "annotation_audio": 13, "annotation_imag": 14, "audio": [15, 16], "submodul": [15, 32, 47, 49, 52, 64, 76, 78, 79, 81, 86, 91, 101, 103, 106, 110, 114, 121, 126, 138, 149, 156, 160, 164, 165, 180, 194], "wav2vec2_for_ctc": 16, "chunker": 17, "classifier_dl": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "albert_for_question_answ": 18, "albert_for_sequence_classif": 19, "albert_for_token_classif": 20, "bert_for_question_answ": 21, "bert_for_sequence_classif": 22, "bert_for_token_classif": 23, "camembert_for_token_classif": 24, "deberta_for_question_answ": 26, "deberta_for_sequence_classif": 27, "deberta_for_token_classif": 28, "distil_bert_for_question_answ": 29, "distil_bert_for_sequence_classif": 30, "distil_bert_for_token_classif": 31, "longformer_for_question_answ": 33, "longformer_for_sequence_classif": 34, "longformer_for_token_classif": 35, "multi_classifier_dl": 36, "roberta_for_question_answ": 37, "roberta_for_sequence_classif": 38, "roberta_for_token_classif": 39, "sentiment_dl": 40, "tapas_for_question_answ": 41, "xlm_roberta_for_question_answ": 42, "xlm_roberta_for_sequence_classif": 43, "xlm_roberta_for_token_classif": 44, "xlnet_for_sequence_classif": 45, "xlnet_for_token_classif": 46, "coref": [47, 48], "spanbert_coref": 48, "cv": [49, 50], "vit_for_image_classif": 50, "depend": [51, 52, 53], "dependency_pars": 51, "typed_dependency_pars": 53, "document_norm": 54, "embed": [55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "albert_embed": 55, "bert_embed": 56, "bert_sentence_embed": 57, "camembert_embed": 58, "chunk_embed": 59, "deberta_embed": 60, "distil_bert_embed": 61, "doc2vec": 62, "elmo_embed": 63, "longformer_embed": 65, "roberta_embed": 66, "roberta_sentence_embed": 67, "sentence_embed": 68, "universal_sentence_encod": 69, "word2vec": 70, "word_embed": 71, "xlm_roberta_embed": 72, "xlm_roberta_sentence_embed": 73, "xlnet_embed": 74, "er": [75, 76], "entity_rul": 75, "graph_extract": 77, "subpackag": [78, 156, 170], "keyword_extract": [79, 80], "yake_keyword_extract": 80, "ld_dl": [81, 82], "language_detector_dl": 82, "lemmat": 83, "matcher": [84, 85, 86, 87, 88, 89], "big_text_match": 84, "date_match": 85, "multi_date_match": 87, "regex_match": 88, "text_match": 89, "n_gram_gener": 90, "ner": [91, 92, 93, 94, 95, 96], "ner_approach": 92, "ner_convert": 93, "ner_crf": 94, "ner_dl": [95, 171, 172, 173, 174, 175, 176, 186, 187, 188, 189, 190, 191], "ner_overwrit": 96, "normal": 97, "param": [98, 99, 100], "classifier_encod": 98, "evaluation_dl_param": 99, "po": [101, 102, 195, 211], "perceptron": 102, "sentenc": [103, 104, 105, 206], "sentence_detector": 104, "sentence_detector_dl": 105, "sentiment": [106, 107, 108], "sentiment_detector": 107, "vivekn_senti": 108, "seq2seq": [109, 110, 111, 112], "gpt2_transform": 109, "marian_transform": 111, "t5_transform": 112, "spell_check": [113, 114, 115, 116], "context_spell_check": 113, "norvig_sweet": 115, "symmetric_delet": 116, "stemmer": 117, "stop_words_clean": 118, "tf_ner_dl_graph_build": 119, "token": [120, 121, 122, 123, 124, 125, 206], "chunk_token": 120, "recursive_token": 122, "regex_token": 123, "token2_chunk": 124, "w": [126, 127], "word_segment": 127, "base": [128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], "audio_assembl": 128, "chunk2_doc": 129, "doc2_chunk": 130, "document_assembl": 131, "embeddings_finish": 132, "finish": [133, 206], "graph_finish": 134, "has_recursive_fit": 135, "has_recursive_transform": 136, "image_assembl": 137, "light_pipelin": 139, "multi_document_assembl": 140, "recursive_pipelin": 141, "table_assembl": 142, "token_assembl": 143, "common": [144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 205], "annotator_approach": 144, "annotator_model": 145, "annotator_properti": 146, "annotator_typ": 147, "coverage_result": 148, "properti": 150, "read_a": 151, "recursive_annotator_approach": 152, "storag": 153, "util": [154, 168, 199], "function": [154, 155, 156, 182, 205, 207], "packag": 156, "intern": [157, 158, 159, 160, 161, 162], "annotator_java_ml": 157, "annotator_transform": 158, "extended_java_wrapp": 159, "params_getters_sett": 161, "recurs": 162, "log": [163, 164, 201, 203], "comet": [163, 201], "pretrain": [165, 166, 167, 168, 205, 209, 210], "pretrained_pipelin": 166, "resource_download": 167, "train": [169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 211], "_tf_graph_build": [169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183], "graph_build": [169, 184], "create_graph": [171, 186], "dataset_encod": [172, 187], "ner_model": [174, 189], "ner_model_sav": [175, 190], "sentence_group": [176, 191], "tf2contrib": [177, 178, 179, 180, 181, 182, 183], "core_rnn_cel": 177, "fused_rnn_cel": 178, "gru_op": 179, "lstm_op": 181, "rnn": 182, "rnn_cell": 183, "_tf_graph_builders_1x": [184, 185, 186, 187, 188, 189, 190, 191], "conll": [192, 211], "conllu": [193, 211], "pub_tat": 196, "tfgraph": 197, "upload_to_hub": 198, "A": 201, "meta": 201, "machin": [201, 202], "learn": [201, 202], "platform": [201, 202], "pipelin": [201, 206, 209, 210], "paramet": 201, "evalu": 201, "metric": 201, "visual": 201, "run": 201, "an": 201, "offlin": 201, "experi": 201, "mlflow": 202, "lifecycl": 202, "third": 203, "parti": 203, "project": 203, "approach": 205, "model": 205, "note": 205, "avail": [205, 210], "set": 206, "up": 206, "your": 206, "own": 206, "type": 206, "necessari": 206, "import": 206, "construct": 206, "documentassembl": 206, "data": 206, "detect": 206, "out": 206, "put": 206, "all": 206, "togeth": 206, "ml": [206, 210], "helper": 207, "user": 208, "guid": 208, "light": 209, "convert": 209, "pipelinemodel": 209, "download": 210, "As": 210, "lightpipelin": 210, "load": 211, "dataset": 211, "spell": 211, "checker": 211, "pubtat": 211}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"API Reference": [[1, "api-reference"], [200, "api-reference"]], "Getting Started": [[10, "getting-started"]], "Spark NLP Cheat Sheet": [[10, "spark-nlp-cheat-sheet"]], "Requirements": [[10, "requirements"]], "Installation": [[10, "installation"], [201, "installation"]], "Using Conda": [[10, "using-conda"]], "Using Virtualenv": [[10, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[10, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[11, "spark-nlp-documentation"]], "Content": [[11, "content"]], "python.sparknlp.annotation": [[12, "module-python.sparknlp.annotation"]], "Module Contents": [[12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [48, "module-contents"], [50, "module-contents"], [51, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [77, "module-contents"], [80, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [85, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [102, "module-contents"], [104, "module-contents"], [105, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [111, "module-contents"], [112, "module-contents"], [113, "module-contents"], [115, "module-contents"], [116, "module-contents"], [117, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [145, "module-contents"], [146, "module-contents"], [150, "module-contents"], [151, "module-contents"], [152, "module-contents"], [154, "module-contents"], [155, "module-contents"], [157, "module-contents"], [158, "module-contents"], [159, "module-contents"], [161, "module-contents"], [162, "module-contents"], [163, "module-contents"], [166, "module-contents"], [169, "module-contents"], [177, "module-contents"], [178, "module-contents"], [179, "module-contents"], [181, "module-contents"], [182, "module-contents"], [183, "module-contents"], [184, "module-contents"], [192, "module-contents"], [193, "module-contents"], [195, "module-contents"], [196, "module-contents"]], "Classes": [[12, "classes"], [13, "classes"], [14, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [44, "classes"], [45, "classes"], [46, "classes"], [48, "classes"], [50, "classes"], [51, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [75, "classes"], [77, "classes"], [80, "classes"], [82, "classes"], [83, "classes"], [84, "classes"], [85, "classes"], [87, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [95, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [99, "classes"], [102, "classes"], [104, "classes"], [105, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [111, "classes"], [112, "classes"], [113, "classes"], [115, "classes"], [116, "classes"], [117, "classes"], [118, "classes"], [119, "classes"], [120, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [145, "classes"], [146, "classes"], [150, "classes"], [151, "classes"], [152, "classes"], [157, "classes"], [158, "classes"], [159, "classes"], [161, "classes"], [162, "classes"], [163, "classes"], [166, "classes"], [169, "classes"], [177, "classes"], [178, "classes"], [179, "classes"], [181, "classes"], [183, "classes"], [184, "classes"], [192, "classes"], [193, "classes"], [195, "classes"], [196, "classes"]], "python.sparknlp.annotation_audio": [[13, "module-python.sparknlp.annotation_audio"]], "python.sparknlp.annotation_image": [[14, "module-python.sparknlp.annotation_image"]], "python.sparknlp.annotator.audio": [[15, "module-python.sparknlp.annotator.audio"]], "Submodules": [[15, "submodules"], [32, "submodules"], [47, "submodules"], [49, "submodules"], [52, "submodules"], [64, "submodules"], [76, "submodules"], [78, "submodules"], [79, "submodules"], [81, "submodules"], [86, "submodules"], [91, "submodules"], [101, "submodules"], [103, "submodules"], [106, "submodules"], [110, "submodules"], [114, "submodules"], [121, "submodules"], [126, "submodules"], [138, "submodules"], [149, "submodules"], [156, "submodules"], [160, "submodules"], [164, "submodules"], [165, "submodules"], [180, "submodules"], [194, "submodules"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc": [[16, "module-python.sparknlp.annotator.audio.wav2vec2_for_ctc"]], "python.sparknlp.annotator.chunker": [[17, "module-python.sparknlp.annotator.chunker"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering": [[18, "module-python.sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[19, "module-python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification": [[20, "module-python.sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering": [[21, "module-python.sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[22, "module-python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification": [[23, "module-python.sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[24, "module-python.sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.classifier_dl": [[25, "module-python.sparknlp.annotator.classifier_dl.classifier_dl"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[26, "module-python.sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[27, "module-python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[28, "module-python.sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[29, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[30, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[31, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl": [[32, "module-python.sparknlp.annotator.classifier_dl"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[33, "module-python.sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[34, "module-python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[35, "module-python.sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl": [[36, "module-python.sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[37, "module-python.sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[38, "module-python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[39, "module-python.sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl": [[40, "module-python.sparknlp.annotator.classifier_dl.sentiment_dl"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[41, "module-python.sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[42, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[43, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[44, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[45, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[46, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "python.sparknlp.annotator.coref": [[47, "module-python.sparknlp.annotator.coref"]], "python.sparknlp.annotator.coref.spanbert_coref": [[48, "module-python.sparknlp.annotator.coref.spanbert_coref"]], "python.sparknlp.annotator.cv": [[49, "module-python.sparknlp.annotator.cv"]], "python.sparknlp.annotator.cv.vit_for_image_classification": [[50, "module-python.sparknlp.annotator.cv.vit_for_image_classification"]], "python.sparknlp.annotator.dependency.dependency_parser": [[51, "module-python.sparknlp.annotator.dependency.dependency_parser"]], "python.sparknlp.annotator.dependency": [[52, "module-python.sparknlp.annotator.dependency"]], "python.sparknlp.annotator.dependency.typed_dependency_parser": [[53, "module-python.sparknlp.annotator.dependency.typed_dependency_parser"]], "python.sparknlp.annotator.document_normalizer": [[54, "module-python.sparknlp.annotator.document_normalizer"]], "python.sparknlp.annotator.embeddings.albert_embeddings": [[55, "module-python.sparknlp.annotator.embeddings.albert_embeddings"]], "python.sparknlp.annotator.embeddings.bert_embeddings": [[56, "module-python.sparknlp.annotator.embeddings.bert_embeddings"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings": [[57, "module-python.sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "python.sparknlp.annotator.embeddings.camembert_embeddings": [[58, "module-python.sparknlp.annotator.embeddings.camembert_embeddings"]], "python.sparknlp.annotator.embeddings.chunk_embeddings": [[59, "module-python.sparknlp.annotator.embeddings.chunk_embeddings"]], "python.sparknlp.annotator.embeddings.deberta_embeddings": [[60, "module-python.sparknlp.annotator.embeddings.deberta_embeddings"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings": [[61, "module-python.sparknlp.annotator.embeddings.distil_bert_embeddings"]], "python.sparknlp.annotator.embeddings.doc2vec": [[62, "module-python.sparknlp.annotator.embeddings.doc2vec"]], "python.sparknlp.annotator.embeddings.elmo_embeddings": [[63, "module-python.sparknlp.annotator.embeddings.elmo_embeddings"]], "python.sparknlp.annotator.embeddings": [[64, "module-python.sparknlp.annotator.embeddings"]], "python.sparknlp.annotator.embeddings.longformer_embeddings": [[65, "module-python.sparknlp.annotator.embeddings.longformer_embeddings"]], "python.sparknlp.annotator.embeddings.roberta_embeddings": [[66, "module-python.sparknlp.annotator.embeddings.roberta_embeddings"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[67, "module-python.sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "python.sparknlp.annotator.embeddings.sentence_embeddings": [[68, "module-python.sparknlp.annotator.embeddings.sentence_embeddings"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder": [[69, "module-python.sparknlp.annotator.embeddings.universal_sentence_encoder"]], "python.sparknlp.annotator.embeddings.word2vec": [[70, "module-python.sparknlp.annotator.embeddings.word2vec"]], "python.sparknlp.annotator.embeddings.word_embeddings": [[71, "module-python.sparknlp.annotator.embeddings.word_embeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[72, "module-python.sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[73, "module-python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings": [[74, "module-python.sparknlp.annotator.embeddings.xlnet_embeddings"]], "python.sparknlp.annotator.er.entity_ruler": [[75, "module-python.sparknlp.annotator.er.entity_ruler"]], "python.sparknlp.annotator.er": [[76, "module-python.sparknlp.annotator.er"]], "python.sparknlp.annotator.graph_extraction": [[77, "module-python.sparknlp.annotator.graph_extraction"]], "python.sparknlp.annotator": [[78, "module-python.sparknlp.annotator"]], "Subpackages": [[78, "subpackages"], [156, "subpackages"], [170, "subpackages"]], "python.sparknlp.annotator.keyword_extraction": [[79, "module-python.sparknlp.annotator.keyword_extraction"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[80, "module-python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "python.sparknlp.annotator.ld_dl": [[81, "module-python.sparknlp.annotator.ld_dl"]], "python.sparknlp.annotator.ld_dl.language_detector_dl": [[82, "module-python.sparknlp.annotator.ld_dl.language_detector_dl"]], "python.sparknlp.annotator.lemmatizer": [[83, "module-python.sparknlp.annotator.lemmatizer"]], "python.sparknlp.annotator.matcher.big_text_matcher": [[84, "module-python.sparknlp.annotator.matcher.big_text_matcher"]], "python.sparknlp.annotator.matcher.date_matcher": [[85, "module-python.sparknlp.annotator.matcher.date_matcher"]], "python.sparknlp.annotator.matcher": [[86, "module-python.sparknlp.annotator.matcher"]], "python.sparknlp.annotator.matcher.multi_date_matcher": [[87, "module-python.sparknlp.annotator.matcher.multi_date_matcher"]], "python.sparknlp.annotator.matcher.regex_matcher": [[88, "module-python.sparknlp.annotator.matcher.regex_matcher"]], "python.sparknlp.annotator.matcher.text_matcher": [[89, "module-python.sparknlp.annotator.matcher.text_matcher"]], "python.sparknlp.annotator.n_gram_generator": [[90, "module-python.sparknlp.annotator.n_gram_generator"]], "python.sparknlp.annotator.ner": [[91, "module-python.sparknlp.annotator.ner"]], "python.sparknlp.annotator.ner.ner_approach": [[92, "module-python.sparknlp.annotator.ner.ner_approach"]], "python.sparknlp.annotator.ner.ner_converter": [[93, "module-python.sparknlp.annotator.ner.ner_converter"]], "python.sparknlp.annotator.ner.ner_crf": [[94, "module-python.sparknlp.annotator.ner.ner_crf"]], "python.sparknlp.annotator.ner.ner_dl": [[95, "module-python.sparknlp.annotator.ner.ner_dl"]], "python.sparknlp.annotator.ner.ner_overwriter": [[96, "module-python.sparknlp.annotator.ner.ner_overwriter"]], "python.sparknlp.annotator.normalizer": [[97, "module-python.sparknlp.annotator.normalizer"]], "python.sparknlp.annotator.param.classifier_encoder": [[98, "module-python.sparknlp.annotator.param.classifier_encoder"]], "python.sparknlp.annotator.param.evaluation_dl_params": [[99, "module-python.sparknlp.annotator.param.evaluation_dl_params"]], "python.sparknlp.annotator.param": [[100, "module-python.sparknlp.annotator.param"]], "python.sparknlp.annotator.pos": [[101, "module-python.sparknlp.annotator.pos"]], "python.sparknlp.annotator.pos.perceptron": [[102, "module-python.sparknlp.annotator.pos.perceptron"]], "python.sparknlp.annotator.sentence": [[103, "module-python.sparknlp.annotator.sentence"]], "python.sparknlp.annotator.sentence.sentence_detector": [[104, "module-python.sparknlp.annotator.sentence.sentence_detector"]], "python.sparknlp.annotator.sentence.sentence_detector_dl": [[105, "module-python.sparknlp.annotator.sentence.sentence_detector_dl"]], "python.sparknlp.annotator.sentiment": [[106, "module-python.sparknlp.annotator.sentiment"]], "python.sparknlp.annotator.sentiment.sentiment_detector": [[107, "module-python.sparknlp.annotator.sentiment.sentiment_detector"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment": [[108, "module-python.sparknlp.annotator.sentiment.vivekn_sentiment"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer": [[109, "module-python.sparknlp.annotator.seq2seq.gpt2_transformer"]], "python.sparknlp.annotator.seq2seq": [[110, "module-python.sparknlp.annotator.seq2seq"]], "python.sparknlp.annotator.seq2seq.marian_transformer": [[111, "module-python.sparknlp.annotator.seq2seq.marian_transformer"]], "python.sparknlp.annotator.seq2seq.t5_transformer": [[112, "module-python.sparknlp.annotator.seq2seq.t5_transformer"]], "python.sparknlp.annotator.spell_check.context_spell_checker": [[113, "module-python.sparknlp.annotator.spell_check.context_spell_checker"]], "python.sparknlp.annotator.spell_check": [[114, "module-python.sparknlp.annotator.spell_check"]], "python.sparknlp.annotator.spell_check.norvig_sweeting": [[115, "module-python.sparknlp.annotator.spell_check.norvig_sweeting"]], "python.sparknlp.annotator.spell_check.symmetric_delete": [[116, "module-python.sparknlp.annotator.spell_check.symmetric_delete"]], "python.sparknlp.annotator.stemmer": [[117, "module-python.sparknlp.annotator.stemmer"]], "python.sparknlp.annotator.stop_words_cleaner": [[118, "module-python.sparknlp.annotator.stop_words_cleaner"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder": [[119, "module-python.sparknlp.annotator.tf_ner_dl_graph_builder"]], "python.sparknlp.annotator.token.chunk_tokenizer": [[120, "module-python.sparknlp.annotator.token.chunk_tokenizer"]], "python.sparknlp.annotator.token": [[121, "module-python.sparknlp.annotator.token"]], "python.sparknlp.annotator.token.recursive_tokenizer": [[122, "module-python.sparknlp.annotator.token.recursive_tokenizer"]], "python.sparknlp.annotator.token.regex_tokenizer": [[123, "module-python.sparknlp.annotator.token.regex_tokenizer"]], "python.sparknlp.annotator.token.token2_chunk": [[124, "module-python.sparknlp.annotator.token.token2_chunk"]], "python.sparknlp.annotator.token.tokenizer": [[125, "module-python.sparknlp.annotator.token.tokenizer"]], "python.sparknlp.annotator.ws": [[126, "module-python.sparknlp.annotator.ws"]], "python.sparknlp.annotator.ws.word_segmenter": [[127, "module-python.sparknlp.annotator.ws.word_segmenter"]], "python.sparknlp.base.audio_assembler": [[128, "module-python.sparknlp.base.audio_assembler"]], "python.sparknlp.base.chunk2_doc": [[129, "module-python.sparknlp.base.chunk2_doc"]], "python.sparknlp.base.doc2_chunk": [[130, "module-python.sparknlp.base.doc2_chunk"]], "python.sparknlp.base.document_assembler": [[131, "module-python.sparknlp.base.document_assembler"]], "python.sparknlp.base.embeddings_finisher": [[132, "module-python.sparknlp.base.embeddings_finisher"]], "python.sparknlp.base.finisher": [[133, "module-python.sparknlp.base.finisher"]], "python.sparknlp.base.graph_finisher": [[134, "module-python.sparknlp.base.graph_finisher"]], "python.sparknlp.base.has_recursive_fit": [[135, "module-python.sparknlp.base.has_recursive_fit"]], "python.sparknlp.base.has_recursive_transform": [[136, "module-python.sparknlp.base.has_recursive_transform"]], "python.sparknlp.base.image_assembler": [[137, "module-python.sparknlp.base.image_assembler"]], "python.sparknlp.base": [[138, "module-python.sparknlp.base"]], "python.sparknlp.base.light_pipeline": [[139, "module-python.sparknlp.base.light_pipeline"]], "python.sparknlp.base.multi_document_assembler": [[140, "module-python.sparknlp.base.multi_document_assembler"]], "python.sparknlp.base.recursive_pipeline": [[141, "module-python.sparknlp.base.recursive_pipeline"]], "python.sparknlp.base.table_assembler": [[142, "module-python.sparknlp.base.table_assembler"]], "python.sparknlp.base.token_assembler": [[143, "module-python.sparknlp.base.token_assembler"]], "python.sparknlp.common.annotator_approach": [[144, "module-python.sparknlp.common.annotator_approach"]], "python.sparknlp.common.annotator_model": [[145, "module-python.sparknlp.common.annotator_model"]], "python.sparknlp.common.annotator_properties": [[146, "module-python.sparknlp.common.annotator_properties"]], "python.sparknlp.common.annotator_type": [[147, "module-python.sparknlp.common.annotator_type"]], "python.sparknlp.common.coverage_result": [[148, "module-python.sparknlp.common.coverage_result"]], "python.sparknlp.common": [[149, "module-python.sparknlp.common"]], "python.sparknlp.common.properties": [[150, "module-python.sparknlp.common.properties"]], "python.sparknlp.common.read_as": [[151, "module-python.sparknlp.common.read_as"]], "python.sparknlp.common.recursive_annotator_approach": [[152, "module-python.sparknlp.common.recursive_annotator_approach"]], "python.sparknlp.common.storage": [[153, "module-python.sparknlp.common.storage"]], "python.sparknlp.common.utils": [[154, "module-python.sparknlp.common.utils"]], "Functions": [[154, "functions"], [155, "functions"], [156, "functions"], [182, "functions"]], "python.sparknlp.functions": [[155, "module-python.sparknlp.functions"]], "python.sparknlp": [[156, "module-python.sparknlp"]], "Package Contents": [[156, "package-contents"]], "python.sparknlp.internal.annotator_java_ml": [[157, "module-python.sparknlp.internal.annotator_java_ml"]], "python.sparknlp.internal.annotator_transformer": [[158, "module-python.sparknlp.internal.annotator_transformer"]], "python.sparknlp.internal.extended_java_wrapper": [[159, "module-python.sparknlp.internal.extended_java_wrapper"]], "python.sparknlp.internal": [[160, "module-python.sparknlp.internal"]], "python.sparknlp.internal.params_getters_setters": [[161, "module-python.sparknlp.internal.params_getters_setters"]], "python.sparknlp.internal.recursive": [[162, "module-python.sparknlp.internal.recursive"]], "python.sparknlp.logging.comet": [[163, "module-python.sparknlp.logging.comet"]], "python.sparknlp.logging": [[164, "module-python.sparknlp.logging"]], "python.sparknlp.pretrained": [[165, "module-python.sparknlp.pretrained"]], "python.sparknlp.pretrained.pretrained_pipeline": [[166, "module-python.sparknlp.pretrained.pretrained_pipeline"]], "python.sparknlp.pretrained.resource_downloader": [[167, "module-python.sparknlp.pretrained.resource_downloader"]], "python.sparknlp.pretrained.utils": [[168, "module-python.sparknlp.pretrained.utils"]], "python.sparknlp.training._tf_graph_builders.graph_builders": [[169, "module-python.sparknlp.training._tf_graph_builders.graph_builders"]], "python.sparknlp.training._tf_graph_builders": [[170, "module-python.sparknlp.training._tf_graph_builders"]], "python.sparknlp.training._tf_graph_builders.ner_dl.create_graph": [[171, "module-python.sparknlp.training._tf_graph_builders.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder": [[172, "module-python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders.ner_dl": [[173, "module-python.sparknlp.training._tf_graph_builders.ner_dl"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model": [[174, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver": [[175, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper": [[176, "module-python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[177, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[178, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[179, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib": [[180, "module-python.sparknlp.training._tf_graph_builders.tf2contrib"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[181, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[182, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[183, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders": [[184, "module-python.sparknlp.training._tf_graph_builders_1x.graph_builders"]], "python.sparknlp.training._tf_graph_builders_1x": [[185, "module-python.sparknlp.training._tf_graph_builders_1x"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph": [[186, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder": [[187, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl": [[188, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model": [[189, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver": [[190, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper": [[191, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"]], "python.sparknlp.training.conll": [[192, "module-python.sparknlp.training.conll"]], "python.sparknlp.training.conllu": [[193, "module-python.sparknlp.training.conllu"]], "python.sparknlp.training": [[194, "module-python.sparknlp.training"]], "python.sparknlp.training.pos": [[195, "module-python.sparknlp.training.pos"]], "python.sparknlp.training.pub_tator": [[196, "module-python.sparknlp.training.pub_tator"]], "python.sparknlp.training.tfgraphs": [[197, "module-python.sparknlp.training.tfgraphs"]], "python.sparknlp.upload_to_hub": [[198, "module-python.sparknlp.upload_to_hub"]], "python.sparknlp.util": [[199, "module-python.sparknlp.util"]], "Modules": [[200, "modules"]], "Comet - A meta machine learning platform": [[201, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[201, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[201, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[201, "logging-evaluation-metrics"]], "Logging Visualizations": [[201, "logging-visualizations"]], "Running An Offline Experiment": [[201, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[202, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[203, "third-party-projects"]], "Logging": [[203, "logging"]], "Annotation": [[204, "annotation"]], "Annotators": [[205, "annotators"]], "Annotator Approaches": [[205, "annotator-approaches"]], "Annotator Models": [[205, "annotator-models"]], "Note": [[205, "note"]], "Pretrained Models": [[205, "pretrained-models"]], "Common Functions": [[205, "common-functions"]], "Available Annotators": [[205, "available-annotators"]], "Setting up your own pipeline": [[206, "setting-up-your-own-pipeline"]], "Annotator types": [[206, "annotator-types"]], "Necessary imports": [[206, "necessary-imports"]], "Constructing the Pipeline": [[206, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[206, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[206, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[206, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[206, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[207, "helper-functions"]], "User Guide": [[208, "user-guide"]], "Light Pipelines": [[209, "light-pipelines"]], "Converting PipelineModels": [[209, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[209, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[210, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[210, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[210, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[210, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[210, "available-pipelines"]], "Loading datasets for training": [[211, "loading-datasets-for-training"]], "POS Dataset": [[211, "pos-dataset"]], "CoNLL Dataset": [[211, "conll-dataset"]], "CoNLLU Dataset": [[211, "conllu-dataset"]], "Spell Checkers Dataset": [[211, "spell-checkers-dataset"]], "PubTator Dataset": [[211, "pubtator-dataset"]]}, "indexentries": {"annotation (class in python.sparknlp.annotation)": [[12, "python.sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[12, "python.sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.fromRow"]], "module": [[12, "module-python.sparknlp.annotation"], [13, "module-python.sparknlp.annotation_audio"], [14, "module-python.sparknlp.annotation_image"], [15, "module-python.sparknlp.annotator.audio"], [16, "module-python.sparknlp.annotator.audio.wav2vec2_for_ctc"], [17, "module-python.sparknlp.annotator.chunker"], [18, "module-python.sparknlp.annotator.classifier_dl.albert_for_question_answering"], [19, "module-python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [20, "module-python.sparknlp.annotator.classifier_dl.albert_for_token_classification"], [21, "module-python.sparknlp.annotator.classifier_dl.bert_for_question_answering"], [22, "module-python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [23, "module-python.sparknlp.annotator.classifier_dl.bert_for_token_classification"], [24, "module-python.sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [25, "module-python.sparknlp.annotator.classifier_dl.classifier_dl"], [26, "module-python.sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [27, "module-python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [28, "module-python.sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [29, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [30, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [31, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [32, "module-python.sparknlp.annotator.classifier_dl"], [33, "module-python.sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [34, "module-python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [35, "module-python.sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [36, "module-python.sparknlp.annotator.classifier_dl.multi_classifier_dl"], [37, "module-python.sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [38, "module-python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [39, "module-python.sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [40, "module-python.sparknlp.annotator.classifier_dl.sentiment_dl"], [41, "module-python.sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [42, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [43, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [44, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [45, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [46, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [47, "module-python.sparknlp.annotator.coref"], [48, "module-python.sparknlp.annotator.coref.spanbert_coref"], [49, "module-python.sparknlp.annotator.cv"], [50, "module-python.sparknlp.annotator.cv.vit_for_image_classification"], [51, "module-python.sparknlp.annotator.dependency.dependency_parser"], [52, "module-python.sparknlp.annotator.dependency"], [53, "module-python.sparknlp.annotator.dependency.typed_dependency_parser"], [54, "module-python.sparknlp.annotator.document_normalizer"], [55, "module-python.sparknlp.annotator.embeddings.albert_embeddings"], [56, "module-python.sparknlp.annotator.embeddings.bert_embeddings"], [57, "module-python.sparknlp.annotator.embeddings.bert_sentence_embeddings"], [58, "module-python.sparknlp.annotator.embeddings.camembert_embeddings"], [59, "module-python.sparknlp.annotator.embeddings.chunk_embeddings"], [60, "module-python.sparknlp.annotator.embeddings.deberta_embeddings"], [61, "module-python.sparknlp.annotator.embeddings.distil_bert_embeddings"], [62, "module-python.sparknlp.annotator.embeddings.doc2vec"], [63, "module-python.sparknlp.annotator.embeddings.elmo_embeddings"], [64, "module-python.sparknlp.annotator.embeddings"], [65, "module-python.sparknlp.annotator.embeddings.longformer_embeddings"], [66, "module-python.sparknlp.annotator.embeddings.roberta_embeddings"], [67, "module-python.sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [68, "module-python.sparknlp.annotator.embeddings.sentence_embeddings"], [69, "module-python.sparknlp.annotator.embeddings.universal_sentence_encoder"], [70, "module-python.sparknlp.annotator.embeddings.word2vec"], [71, "module-python.sparknlp.annotator.embeddings.word_embeddings"], [72, "module-python.sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [73, "module-python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [74, "module-python.sparknlp.annotator.embeddings.xlnet_embeddings"], [75, "module-python.sparknlp.annotator.er.entity_ruler"], [76, "module-python.sparknlp.annotator.er"], [77, "module-python.sparknlp.annotator.graph_extraction"], [78, "module-python.sparknlp.annotator"], [79, "module-python.sparknlp.annotator.keyword_extraction"], [80, "module-python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [81, "module-python.sparknlp.annotator.ld_dl"], [82, "module-python.sparknlp.annotator.ld_dl.language_detector_dl"], [83, "module-python.sparknlp.annotator.lemmatizer"], [84, "module-python.sparknlp.annotator.matcher.big_text_matcher"], [85, "module-python.sparknlp.annotator.matcher.date_matcher"], [86, "module-python.sparknlp.annotator.matcher"], [87, "module-python.sparknlp.annotator.matcher.multi_date_matcher"], [88, "module-python.sparknlp.annotator.matcher.regex_matcher"], [89, "module-python.sparknlp.annotator.matcher.text_matcher"], [90, "module-python.sparknlp.annotator.n_gram_generator"], [91, "module-python.sparknlp.annotator.ner"], [92, "module-python.sparknlp.annotator.ner.ner_approach"], [93, "module-python.sparknlp.annotator.ner.ner_converter"], [94, "module-python.sparknlp.annotator.ner.ner_crf"], [95, "module-python.sparknlp.annotator.ner.ner_dl"], [96, "module-python.sparknlp.annotator.ner.ner_overwriter"], [97, "module-python.sparknlp.annotator.normalizer"], [98, "module-python.sparknlp.annotator.param.classifier_encoder"], [99, "module-python.sparknlp.annotator.param.evaluation_dl_params"], [100, "module-python.sparknlp.annotator.param"], [101, "module-python.sparknlp.annotator.pos"], [102, "module-python.sparknlp.annotator.pos.perceptron"], [103, "module-python.sparknlp.annotator.sentence"], [104, "module-python.sparknlp.annotator.sentence.sentence_detector"], [105, "module-python.sparknlp.annotator.sentence.sentence_detector_dl"], [106, "module-python.sparknlp.annotator.sentiment"], [107, "module-python.sparknlp.annotator.sentiment.sentiment_detector"], [108, "module-python.sparknlp.annotator.sentiment.vivekn_sentiment"], [109, "module-python.sparknlp.annotator.seq2seq.gpt2_transformer"], [110, "module-python.sparknlp.annotator.seq2seq"], [111, "module-python.sparknlp.annotator.seq2seq.marian_transformer"], [112, "module-python.sparknlp.annotator.seq2seq.t5_transformer"], [113, "module-python.sparknlp.annotator.spell_check.context_spell_checker"], [114, "module-python.sparknlp.annotator.spell_check"], [115, "module-python.sparknlp.annotator.spell_check.norvig_sweeting"], [116, "module-python.sparknlp.annotator.spell_check.symmetric_delete"], [117, "module-python.sparknlp.annotator.stemmer"], [118, "module-python.sparknlp.annotator.stop_words_cleaner"], [119, "module-python.sparknlp.annotator.tf_ner_dl_graph_builder"], [120, "module-python.sparknlp.annotator.token.chunk_tokenizer"], [121, "module-python.sparknlp.annotator.token"], [122, "module-python.sparknlp.annotator.token.recursive_tokenizer"], [123, "module-python.sparknlp.annotator.token.regex_tokenizer"], [124, "module-python.sparknlp.annotator.token.token2_chunk"], [125, "module-python.sparknlp.annotator.token.tokenizer"], [126, "module-python.sparknlp.annotator.ws"], [127, "module-python.sparknlp.annotator.ws.word_segmenter"], [128, "module-python.sparknlp.base.audio_assembler"], [129, "module-python.sparknlp.base.chunk2_doc"], [130, "module-python.sparknlp.base.doc2_chunk"], [131, "module-python.sparknlp.base.document_assembler"], [132, "module-python.sparknlp.base.embeddings_finisher"], [133, "module-python.sparknlp.base.finisher"], [134, "module-python.sparknlp.base.graph_finisher"], [135, "module-python.sparknlp.base.has_recursive_fit"], [136, "module-python.sparknlp.base.has_recursive_transform"], [137, "module-python.sparknlp.base.image_assembler"], [138, "module-python.sparknlp.base"], [139, "module-python.sparknlp.base.light_pipeline"], [140, "module-python.sparknlp.base.multi_document_assembler"], [141, "module-python.sparknlp.base.recursive_pipeline"], [142, "module-python.sparknlp.base.table_assembler"], [143, "module-python.sparknlp.base.token_assembler"], [144, "module-python.sparknlp.common.annotator_approach"], [145, "module-python.sparknlp.common.annotator_model"], [146, "module-python.sparknlp.common.annotator_properties"], [147, "module-python.sparknlp.common.annotator_type"], [148, "module-python.sparknlp.common.coverage_result"], [149, "module-python.sparknlp.common"], [150, "module-python.sparknlp.common.properties"], [151, "module-python.sparknlp.common.read_as"], [152, "module-python.sparknlp.common.recursive_annotator_approach"], [153, "module-python.sparknlp.common.storage"], [154, "module-python.sparknlp.common.utils"], [155, "module-python.sparknlp.functions"], [156, "module-python.sparknlp"], [157, "module-python.sparknlp.internal.annotator_java_ml"], [158, "module-python.sparknlp.internal.annotator_transformer"], [159, "module-python.sparknlp.internal.extended_java_wrapper"], [160, "module-python.sparknlp.internal"], [161, "module-python.sparknlp.internal.params_getters_setters"], [162, "module-python.sparknlp.internal.recursive"], [163, "module-python.sparknlp.logging.comet"], [164, "module-python.sparknlp.logging"], [165, "module-python.sparknlp.pretrained"], [166, "module-python.sparknlp.pretrained.pretrained_pipeline"], [167, "module-python.sparknlp.pretrained.resource_downloader"], [168, "module-python.sparknlp.pretrained.utils"], [169, "module-python.sparknlp.training._tf_graph_builders.graph_builders"], [170, "module-python.sparknlp.training._tf_graph_builders"], [171, "module-python.sparknlp.training._tf_graph_builders.ner_dl.create_graph"], [172, "module-python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"], [173, "module-python.sparknlp.training._tf_graph_builders.ner_dl"], [174, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model"], [175, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"], [176, "module-python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"], [177, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"], [178, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"], [179, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"], [180, "module-python.sparknlp.training._tf_graph_builders.tf2contrib"], [181, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"], [182, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn"], [183, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"], [184, "module-python.sparknlp.training._tf_graph_builders_1x.graph_builders"], [185, "module-python.sparknlp.training._tf_graph_builders_1x"], [186, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"], [187, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"], [188, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl"], [189, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"], [190, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"], [191, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"], [192, "module-python.sparknlp.training.conll"], [193, "module-python.sparknlp.training.conllu"], [194, "module-python.sparknlp.training"], [195, "module-python.sparknlp.training.pos"], [196, "module-python.sparknlp.training.pub_tator"], [197, "module-python.sparknlp.training.tfgraphs"], [198, "module-python.sparknlp.upload_to_hub"], [199, "module-python.sparknlp.util"]], "python.sparknlp.annotation": [[12, "module-python.sparknlp.annotation"]], "torow() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in python.sparknlp.annotation_audio)": [[13, "python.sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[13, "python.sparknlp.annotation_audio.AnnotationAudio.copy"]], "python.sparknlp.annotation_audio": [[13, "module-python.sparknlp.annotation_audio"]], "annotationimage (class in python.sparknlp.annotation_image)": [[14, "python.sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[14, "python.sparknlp.annotation_image.AnnotationImage.copy"]], "python.sparknlp.annotation_image": [[14, "module-python.sparknlp.annotation_image"]], "python.sparknlp.annotator.audio": [[15, "module-python.sparknlp.annotator.audio"]], "wav2vec2forctc (class in python.sparknlp.annotator.audio.wav2vec2_for_ctc)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc": [[16, "module-python.sparknlp.annotator.audio.wav2vec2_for_ctc"]], "setconfigprotobytes() (wav2vec2forctc method)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "chunker (class in python.sparknlp.annotator.chunker)": [[17, "python.sparknlp.annotator.chunker.Chunker"]], "python.sparknlp.annotator.chunker": [[17, "module-python.sparknlp.annotator.chunker"]], "setregexparsers() (chunker method)": [[17, "python.sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "albertforquestionanswering (class in python.sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering": [[18, "module-python.sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "setconfigprotobytes() (albertforquestionanswering method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "albertforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[19, "module-python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "setcoalescesentences() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "albertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification": [[20, "module-python.sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "setconfigprotobytes() (albertfortokenclassification method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "bertforquestionanswering (class in python.sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering": [[21, "module-python.sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "setconfigprotobytes() (bertforquestionanswering method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "bertforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[22, "module-python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "setcoalescesentences() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "bertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification": [[23, "module-python.sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "setconfigprotobytes() (bertfortokenclassification method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "camembertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[24, "module-python.sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "classifierdlapproach (class in python.sparknlp.annotator.classifier_dl.classifier_dl)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in python.sparknlp.annotator.classifier_dl.classifier_dl)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "python.sparknlp.annotator.classifier_dl.classifier_dl": [[25, "module-python.sparknlp.annotator.classifier_dl.classifier_dl"]], "setconfigprotobytes() (classifierdlmodel method)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "debertaforquestionanswering (class in python.sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[26, "module-python.sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "debertaforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[27, "module-python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "debertafortokenclassification (class in python.sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[28, "module-python.sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "setconfigprotobytes() (debertafortokenclassification method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "distilbertforquestionanswering (class in python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[29, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "distilbertforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[30, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "distilbertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[31, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl": [[32, "module-python.sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in python.sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[33, "module-python.sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "longformerforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[34, "module-python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "longformerfortokenclassification (class in python.sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[35, "module-python.sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "multiclassifierdlapproach (class in python.sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in python.sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl": [[36, "module-python.sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "robertaforquestionanswering (class in python.sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[37, "module-python.sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "robertaforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[38, "module-python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "robertafortokenclassification (class in python.sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[39, "module-python.sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "setconfigprotobytes() (robertafortokenclassification method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sentimentdlapproach (class in python.sparknlp.annotator.classifier_dl.sentiment_dl)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in python.sparknlp.annotator.classifier_dl.sentiment_dl)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl": [[40, "module-python.sparknlp.annotator.classifier_dl.sentiment_dl"]], "setconfigprotobytes() (sentimentdlmodel method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "tapasforquestionanswering (class in python.sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[41, "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[41, "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[41, "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[41, "module-python.sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[42, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "xlmrobertaforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[43, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "xlmrobertafortokenclassification (class in python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[44, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "xlnetforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[45, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "xlnetfortokenclassification (class in python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[46, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "python.sparknlp.annotator.coref": [[47, "module-python.sparknlp.annotator.coref"]], "spanbertcorefmodel (class in python.sparknlp.annotator.coref.spanbert_coref)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "python.sparknlp.annotator.coref.spanbert_coref": [[48, "module-python.sparknlp.annotator.coref.spanbert_coref"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "python.sparknlp.annotator.cv": [[49, "module-python.sparknlp.annotator.cv"]], "vitforimageclassification (class in python.sparknlp.annotator.cv.vit_for_image_classification)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "python.sparknlp.annotator.cv.vit_for_image_classification": [[50, "module-python.sparknlp.annotator.cv.vit_for_image_classification"]], "setconfigprotobytes() (vitforimageclassification method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "dependencyparserapproach (class in python.sparknlp.annotator.dependency.dependency_parser)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in python.sparknlp.annotator.dependency.dependency_parser)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "python.sparknlp.annotator.dependency.dependency_parser": [[51, "module-python.sparknlp.annotator.dependency.dependency_parser"]], "setconllu() (dependencyparserapproach method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "python.sparknlp.annotator.dependency": [[52, "module-python.sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in python.sparknlp.annotator.dependency.typed_dependency_parser)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in python.sparknlp.annotator.dependency.typed_dependency_parser)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "python.sparknlp.annotator.dependency.typed_dependency_parser": [[53, "module-python.sparknlp.annotator.dependency.typed_dependency_parser"]], "setconll2009() (typeddependencyparserapproach method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "documentnormalizer (class in python.sparknlp.annotator.document_normalizer)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "python.sparknlp.annotator.document_normalizer": [[54, "module-python.sparknlp.annotator.document_normalizer"]], "setaction() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "albertembeddings (class in python.sparknlp.annotator.embeddings.albert_embeddings)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.albert_embeddings": [[55, "module-python.sparknlp.annotator.embeddings.albert_embeddings"]], "setconfigprotobytes() (albertembeddings method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "bertembeddings (class in python.sparknlp.annotator.embeddings.bert_embeddings)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.bert_embeddings": [[56, "module-python.sparknlp.annotator.embeddings.bert_embeddings"]], "setconfigprotobytes() (bertembeddings method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "bertsentenceembeddings (class in python.sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings": [[57, "module-python.sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "camembertembeddings (class in python.sparknlp.annotator.embeddings.camembert_embeddings)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.camembert_embeddings": [[58, "module-python.sparknlp.annotator.embeddings.camembert_embeddings"]], "setconfigprotobytes() (camembertembeddings method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "chunkembeddings (class in python.sparknlp.annotator.embeddings.chunk_embeddings)": [[59, "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "python.sparknlp.annotator.embeddings.chunk_embeddings": [[59, "module-python.sparknlp.annotator.embeddings.chunk_embeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[59, "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[59, "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "debertaembeddings (class in python.sparknlp.annotator.embeddings.deberta_embeddings)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.deberta_embeddings": [[60, "module-python.sparknlp.annotator.embeddings.deberta_embeddings"]], "setconfigprotobytes() (debertaembeddings method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "distilbertembeddings (class in python.sparknlp.annotator.embeddings.distil_bert_embeddings)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings": [[61, "module-python.sparknlp.annotator.embeddings.distil_bert_embeddings"]], "setconfigprotobytes() (distilbertembeddings method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "doc2vecapproach (class in python.sparknlp.annotator.embeddings.doc2vec)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in python.sparknlp.annotator.embeddings.doc2vec)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "python.sparknlp.annotator.embeddings.doc2vec": [[62, "module-python.sparknlp.annotator.embeddings.doc2vec"]], "setmaxiter() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "elmoembeddings (class in python.sparknlp.annotator.embeddings.elmo_embeddings)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.elmo_embeddings": [[63, "module-python.sparknlp.annotator.embeddings.elmo_embeddings"]], "setbatchsize() (elmoembeddings method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "python.sparknlp.annotator.embeddings": [[64, "module-python.sparknlp.annotator.embeddings"]], "longformerembeddings (class in python.sparknlp.annotator.embeddings.longformer_embeddings)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.longformer_embeddings": [[65, "module-python.sparknlp.annotator.embeddings.longformer_embeddings"]], "setconfigprotobytes() (longformerembeddings method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "robertaembeddings (class in python.sparknlp.annotator.embeddings.roberta_embeddings)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.roberta_embeddings": [[66, "module-python.sparknlp.annotator.embeddings.roberta_embeddings"]], "setconfigprotobytes() (robertaembeddings method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "robertasentenceembeddings (class in python.sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[67, "module-python.sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sentenceembeddings (class in python.sparknlp.annotator.embeddings.sentence_embeddings)": [[68, "python.sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.sentence_embeddings": [[68, "module-python.sparknlp.annotator.embeddings.sentence_embeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[68, "python.sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "universalsentenceencoder (class in python.sparknlp.annotator.embeddings.universal_sentence_encoder)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder": [[69, "module-python.sparknlp.annotator.embeddings.universal_sentence_encoder"]], "setconfigprotobytes() (universalsentenceencoder method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "word2vecapproach (class in python.sparknlp.annotator.embeddings.word2vec)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in python.sparknlp.annotator.embeddings.word2vec)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "python.sparknlp.annotator.embeddings.word2vec": [[70, "module-python.sparknlp.annotator.embeddings.word2vec"]], "setmaxiter() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "wordembeddings (class in python.sparknlp.annotator.embeddings.word_embeddings)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in python.sparknlp.annotator.embeddings.word_embeddings)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "python.sparknlp.annotator.embeddings.word_embeddings": [[71, "module-python.sparknlp.annotator.embeddings.word_embeddings"]], "setreadcachesize() (wordembeddings method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in python.sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[72, "module-python.sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "xlmrobertasentenceembeddings (class in python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[73, "module-python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "xlnetembeddings (class in python.sparknlp.annotator.embeddings.xlnet_embeddings)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings": [[74, "module-python.sparknlp.annotator.embeddings.xlnet_embeddings"]], "setconfigprotobytes() (xlnetembeddings method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "entityrulerapproach (class in python.sparknlp.annotator.er.entity_ruler)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in python.sparknlp.annotator.er.entity_ruler)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "python.sparknlp.annotator.er.entity_ruler": [[75, "module-python.sparknlp.annotator.er.entity_ruler"]], "setalphabetresource() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setenablepatternregex() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setEnablePatternRegex"]], "setpatternsresource() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "python.sparknlp.annotator.er": [[76, "module-python.sparknlp.annotator.er"]], "graphextraction (class in python.sparknlp.annotator.graph_extraction)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction"]], "python.sparknlp.annotator.graph_extraction": [[77, "module-python.sparknlp.annotator.graph_extraction"]], "setdelimiter() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "python.sparknlp.annotator": [[78, "module-python.sparknlp.annotator"]], "python.sparknlp.annotator.keyword_extraction": [[79, "module-python.sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[80, "module-python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "setmaxngrams() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "python.sparknlp.annotator.ld_dl": [[81, "module-python.sparknlp.annotator.ld_dl"]], "languagedetectordl (class in python.sparknlp.annotator.ld_dl.language_detector_dl)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "python.sparknlp.annotator.ld_dl.language_detector_dl": [[82, "module-python.sparknlp.annotator.ld_dl.language_detector_dl"]], "setcoalescesentences() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "lemmatizer (class in python.sparknlp.annotator.lemmatizer)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in python.sparknlp.annotator.lemmatizer)": [[83, "python.sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[83, "python.sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "python.sparknlp.annotator.lemmatizer": [[83, "module-python.sparknlp.annotator.lemmatizer"]], "setdictionary() (lemmatizer method)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "bigtextmatcher (class in python.sparknlp.annotator.matcher.big_text_matcher)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in python.sparknlp.annotator.matcher.big_text_matcher)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "python.sparknlp.annotator.matcher.big_text_matcher": [[84, "module-python.sparknlp.annotator.matcher.big_text_matcher"]], "setcasesensitive() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "datematcher (class in python.sparknlp.annotator.matcher.date_matcher)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in python.sparknlp.annotator.matcher.date_matcher)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "python.sparknlp.annotator.matcher.date_matcher": [[85, "module-python.sparknlp.annotator.matcher.date_matcher"]], "setanchordateday() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "python.sparknlp.annotator.matcher": [[86, "module-python.sparknlp.annotator.matcher"]], "multidatematcher (class in python.sparknlp.annotator.matcher.multi_date_matcher)": [[87, "python.sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "python.sparknlp.annotator.matcher.multi_date_matcher": [[87, "module-python.sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in python.sparknlp.annotator.matcher.regex_matcher)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in python.sparknlp.annotator.matcher.regex_matcher)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "python.sparknlp.annotator.matcher.regex_matcher": [[88, "module-python.sparknlp.annotator.matcher.regex_matcher"]], "setdelimiter() (regexmatcher method)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setDelimiter"]], "setexternalrules() (regexmatcher method)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setrules() (regexmatcher method)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setRules"]], "setstrategy() (regexmatcher method)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "textmatcher (class in python.sparknlp.annotator.matcher.text_matcher)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in python.sparknlp.annotator.matcher.text_matcher)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "python.sparknlp.annotator.matcher.text_matcher": [[89, "module-python.sparknlp.annotator.matcher.text_matcher"]], "setbuildfromtokens() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "ngramgenerator (class in python.sparknlp.annotator.n_gram_generator)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator"]], "python.sparknlp.annotator.n_gram_generator": [[90, "module-python.sparknlp.annotator.n_gram_generator"]], "setdelimiter() (ngramgenerator method)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "python.sparknlp.annotator.ner": [[91, "module-python.sparknlp.annotator.ner"]], "nerapproach (class in python.sparknlp.annotator.ner.ner_approach)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "python.sparknlp.annotator.ner.ner_approach": [[92, "module-python.sparknlp.annotator.ner.ner_approach"]], "setentities() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "nerconverter (class in python.sparknlp.annotator.ner.ner_converter)": [[93, "python.sparknlp.annotator.ner.ner_converter.NerConverter"]], "python.sparknlp.annotator.ner.ner_converter": [[93, "module-python.sparknlp.annotator.ner.ner_converter"]], "setpreserveposition() (nerconverter method)": [[93, "python.sparknlp.annotator.ner.ner_converter.NerConverter.setPreservePosition"]], "setwhitelist() (nerconverter method)": [[93, "python.sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "nercrfapproach (class in python.sparknlp.annotator.ner.ner_crf)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in python.sparknlp.annotator.ner.ner_crf)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "python.sparknlp.annotator.ner.ner_crf": [[94, "module-python.sparknlp.annotator.ner.ner_crf"]], "setc0() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "nerdlapproach (class in python.sparknlp.annotator.ner.ner_dl)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in python.sparknlp.annotator.ner.ner_dl)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "python.sparknlp.annotator.ner.ner_dl": [[95, "module-python.sparknlp.annotator.ner.ner_dl"]], "setbatchsize() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "neroverwriter (class in python.sparknlp.annotator.ner.ner_overwriter)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "python.sparknlp.annotator.ner.ner_overwriter": [[96, "module-python.sparknlp.annotator.ner.ner_overwriter"]], "setnerwords() (neroverwriter method)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "normalizer (class in python.sparknlp.annotator.normalizer)": [[97, "python.sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in python.sparknlp.annotator.normalizer)": [[97, "python.sparknlp.annotator.normalizer.NormalizerModel"]], "python.sparknlp.annotator.normalizer": [[97, "module-python.sparknlp.annotator.normalizer"]], "setcleanuppatterns() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "classifierencoder (class in python.sparknlp.annotator.param.classifier_encoder)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "python.sparknlp.annotator.param.classifier_encoder": [[98, "module-python.sparknlp.annotator.param.classifier_encoder"]], "setbatchsize() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "evaluationdlparams (class in python.sparknlp.annotator.param.evaluation_dl_params)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "python.sparknlp.annotator.param.evaluation_dl_params": [[99, "module-python.sparknlp.annotator.param.evaluation_dl_params"]], "setenableoutputlogs() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "python.sparknlp.annotator.param": [[100, "module-python.sparknlp.annotator.param"]], "python.sparknlp.annotator.pos": [[101, "module-python.sparknlp.annotator.pos"]], "perceptronapproach (class in python.sparknlp.annotator.pos.perceptron)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in python.sparknlp.annotator.pos.perceptron)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "python.sparknlp.annotator.pos.perceptron": [[102, "module-python.sparknlp.annotator.pos.perceptron"]], "setiterations() (perceptronapproach method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "python.sparknlp.annotator.sentence": [[103, "module-python.sparknlp.annotator.sentence"]], "sentencedetector (class in python.sparknlp.annotator.sentence.sentence_detector)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in python.sparknlp.annotator.sentence.sentence_detector)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "python.sparknlp.annotator.sentence.sentence_detector": [[104, "module-python.sparknlp.annotator.sentence.sentence_detector"]], "setcustombounds() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sentencedetectordlapproach (class in python.sparknlp.annotator.sentence.sentence_detector_dl)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in python.sparknlp.annotator.sentence.sentence_detector_dl)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "python.sparknlp.annotator.sentence.sentence_detector_dl": [[105, "module-python.sparknlp.annotator.sentence.sentence_detector_dl"]], "setcustombounds() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "python.sparknlp.annotator.sentiment": [[106, "module-python.sparknlp.annotator.sentiment"]], "sentimentdetector (class in python.sparknlp.annotator.sentiment.sentiment_detector)": [[107, "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in python.sparknlp.annotator.sentiment.sentiment_detector)": [[107, "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "python.sparknlp.annotator.sentiment.sentiment_detector": [[107, "module-python.sparknlp.annotator.sentiment.sentiment_detector"]], "setdictionary() (sentimentdetector method)": [[107, "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "viveknsentimentapproach (class in python.sparknlp.annotator.sentiment.vivekn_sentiment)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in python.sparknlp.annotator.sentiment.vivekn_sentiment)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment": [[108, "module-python.sparknlp.annotator.sentiment.vivekn_sentiment"]], "setprunecorpus() (viveknsentimentapproach method)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "gpt2transformer (class in python.sparknlp.annotator.seq2seq.gpt2_transformer)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer": [[109, "module-python.sparknlp.annotator.seq2seq.gpt2_transformer"]], "setconfigprotobytes() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "python.sparknlp.annotator.seq2seq": [[110, "module-python.sparknlp.annotator.seq2seq"]], "mariantransformer (class in python.sparknlp.annotator.seq2seq.marian_transformer)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "python.sparknlp.annotator.seq2seq.marian_transformer": [[111, "module-python.sparknlp.annotator.seq2seq.marian_transformer"]], "setconfigprotobytes() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "t5transformer (class in python.sparknlp.annotator.seq2seq.t5_transformer)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "python.sparknlp.annotator.seq2seq.t5_transformer": [[112, "module-python.sparknlp.annotator.seq2seq.t5_transformer"]], "setconfigprotobytes() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "contextspellcheckerapproach (class in python.sparknlp.annotator.spell_check.context_spell_checker)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in python.sparknlp.annotator.spell_check.context_spell_checker)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "python.sparknlp.annotator.spell_check.context_spell_checker": [[113, "module-python.sparknlp.annotator.spell_check.context_spell_checker"]], "setbatchsize() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setcomparelowcase() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setinitialrate() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[113, "id0"], [113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "updateregexclass() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "python.sparknlp.annotator.spell_check": [[114, "module-python.sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in python.sparknlp.annotator.spell_check.norvig_sweeting)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in python.sparknlp.annotator.spell_check.norvig_sweeting)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "python.sparknlp.annotator.spell_check.norvig_sweeting": [[115, "module-python.sparknlp.annotator.spell_check.norvig_sweeting"]], "setcasesensitive() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "symmetricdeleteapproach (class in python.sparknlp.annotator.spell_check.symmetric_delete)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in python.sparknlp.annotator.spell_check.symmetric_delete)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "python.sparknlp.annotator.spell_check.symmetric_delete": [[116, "module-python.sparknlp.annotator.spell_check.symmetric_delete"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "stemmer (class in python.sparknlp.annotator.stemmer)": [[117, "python.sparknlp.annotator.stemmer.Stemmer"]], "python.sparknlp.annotator.stemmer": [[117, "module-python.sparknlp.annotator.stemmer"]], "stopwordscleaner (class in python.sparknlp.annotator.stop_words_cleaner)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "python.sparknlp.annotator.stop_words_cleaner": [[118, "module-python.sparknlp.annotator.stop_words_cleaner"]], "setcasesensitive() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "tfnerdlgraphbuilder (class in python.sparknlp.annotator.tf_ner_dl_graph_builder)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in python.sparknlp.annotator.tf_ner_dl_graph_builder)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder": [[119, "module-python.sparknlp.annotator.tf_ner_dl_graph_builder"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "chunktokenizer (class in python.sparknlp.annotator.token.chunk_tokenizer)": [[120, "python.sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in python.sparknlp.annotator.token.chunk_tokenizer)": [[120, "python.sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "python.sparknlp.annotator.token.chunk_tokenizer": [[120, "module-python.sparknlp.annotator.token.chunk_tokenizer"]], "python.sparknlp.annotator.token": [[121, "module-python.sparknlp.annotator.token"]], "recursivetokenizer (class in python.sparknlp.annotator.token.recursive_tokenizer)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in python.sparknlp.annotator.token.recursive_tokenizer)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "python.sparknlp.annotator.token.recursive_tokenizer": [[122, "module-python.sparknlp.annotator.token.recursive_tokenizer"]], "setinfixes() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "regextokenizer (class in python.sparknlp.annotator.token.regex_tokenizer)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "python.sparknlp.annotator.token.regex_tokenizer": [[123, "module-python.sparknlp.annotator.token.regex_tokenizer"]], "setmaxlength() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "token2chunk (class in python.sparknlp.annotator.token.token2_chunk)": [[124, "python.sparknlp.annotator.token.token2_chunk.Token2Chunk"]], "python.sparknlp.annotator.token.token2_chunk": [[124, "module-python.sparknlp.annotator.token.token2_chunk"]], "tokenizer (class in python.sparknlp.annotator.token.tokenizer)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in python.sparknlp.annotator.token.tokenizer)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "python.sparknlp.annotator.token.tokenizer": [[125, "module-python.sparknlp.annotator.token.tokenizer"]], "setcasesensitiveexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "python.sparknlp.annotator.ws": [[126, "module-python.sparknlp.annotator.ws"]], "wordsegmenterapproach (class in python.sparknlp.annotator.ws.word_segmenter)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in python.sparknlp.annotator.ws.word_segmenter)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "python.sparknlp.annotator.ws.word_segmenter": [[127, "module-python.sparknlp.annotator.ws.word_segmenter"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setenableregextokenizer() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setEnableRegexTokenizer"]], "setenableregextokenizer() (wordsegmentermodel method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setEnableRegexTokenizer"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setpattern() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPattern"]], "setpattern() (wordsegmentermodel method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setPattern"]], "setposcolumn() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "settolowercase() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setToLowercase"]], "settolowercase() (wordsegmentermodel method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setToLowercase"]], "audioassembler (class in python.sparknlp.base.audio_assembler)": [[128, "python.sparknlp.base.audio_assembler.AudioAssembler"]], "python.sparknlp.base.audio_assembler": [[128, "module-python.sparknlp.base.audio_assembler"]], "setinputcol() (audioassembler method)": [[128, "python.sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[128, "python.sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "chunk2doc (class in python.sparknlp.base.chunk2_doc)": [[129, "python.sparknlp.base.chunk2_doc.Chunk2Doc"]], "python.sparknlp.base.chunk2_doc": [[129, "module-python.sparknlp.base.chunk2_doc"]], "doc2chunk (class in python.sparknlp.base.doc2_chunk)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk"]], "python.sparknlp.base.doc2_chunk": [[130, "module-python.sparknlp.base.doc2_chunk"]], "setchunkcol() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "documentassembler (class in python.sparknlp.base.document_assembler)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler"]], "python.sparknlp.base.document_assembler": [[131, "module-python.sparknlp.base.document_assembler"]], "setcleanupmode() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "embeddingsfinisher (class in python.sparknlp.base.embeddings_finisher)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "python.sparknlp.base.embeddings_finisher": [[132, "module-python.sparknlp.base.embeddings_finisher"]], "setcleanannotations() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "finisher (class in python.sparknlp.base.finisher)": [[133, "python.sparknlp.base.finisher.Finisher"]], "python.sparknlp.base.finisher": [[133, "module-python.sparknlp.base.finisher"]], "setannotationsplitsymbol() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "graphfinisher (class in python.sparknlp.base.graph_finisher)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher"]], "python.sparknlp.base.graph_finisher": [[134, "module-python.sparknlp.base.graph_finisher"]], "setcleanannotations() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "hasrecursivefit (class in python.sparknlp.base.has_recursive_fit)": [[135, "python.sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "python.sparknlp.base.has_recursive_fit": [[135, "module-python.sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in python.sparknlp.base.has_recursive_transform)": [[136, "python.sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "python.sparknlp.base.has_recursive_transform": [[136, "module-python.sparknlp.base.has_recursive_transform"]], "imageassembler (class in python.sparknlp.base.image_assembler)": [[137, "python.sparknlp.base.image_assembler.ImageAssembler"]], "python.sparknlp.base.image_assembler": [[137, "module-python.sparknlp.base.image_assembler"]], "setinputcol() (imageassembler method)": [[137, "python.sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[137, "python.sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "python.sparknlp.base": [[138, "module-python.sparknlp.base"]], "lightpipeline (class in python.sparknlp.base.light_pipeline)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "python.sparknlp.base.light_pipeline": [[139, "module-python.sparknlp.base.light_pipeline"]], "setignoreunsupported() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "transform() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in python.sparknlp.base.multi_document_assembler)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "python.sparknlp.base.multi_document_assembler": [[140, "module-python.sparknlp.base.multi_document_assembler"]], "setcleanupmode() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "recursivepipeline (class in python.sparknlp.base.recursive_pipeline)": [[141, "python.sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in python.sparknlp.base.recursive_pipeline)": [[141, "python.sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "python.sparknlp.base.recursive_pipeline": [[141, "module-python.sparknlp.base.recursive_pipeline"]], "tableassembler (class in python.sparknlp.base.table_assembler)": [[142, "python.sparknlp.base.table_assembler.TableAssembler"]], "python.sparknlp.base.table_assembler": [[142, "module-python.sparknlp.base.table_assembler"]], "setcsvdelimiter() (tableassembler method)": [[142, "python.sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[142, "python.sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[142, "python.sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "tokenassembler (class in python.sparknlp.base.token_assembler)": [[143, "python.sparknlp.base.token_assembler.TokenAssembler"]], "python.sparknlp.base.token_assembler": [[143, "module-python.sparknlp.base.token_assembler"]], "setpreserveposition() (tokenassembler method)": [[143, "python.sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "annotatorapproach (class in python.sparknlp.common.annotator_approach)": [[144, "python.sparknlp.common.annotator_approach.AnnotatorApproach"]], "python.sparknlp.common.annotator_approach": [[144, "module-python.sparknlp.common.annotator_approach"]], "annotatormodel (class in python.sparknlp.common.annotator_model)": [[145, "python.sparknlp.common.annotator_model.AnnotatorModel"]], "python.sparknlp.common.annotator_model": [[145, "module-python.sparknlp.common.annotator_model"]], "annotatorproperties (class in python.sparknlp.common.annotator_properties)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "python.sparknlp.common.annotator_properties": [[146, "module-python.sparknlp.common.annotator_properties"]], "setinputcols() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "python.sparknlp.common.annotator_type": [[147, "module-python.sparknlp.common.annotator_type"]], "python.sparknlp.common.coverage_result": [[148, "module-python.sparknlp.common.coverage_result"]], "python.sparknlp.common": [[149, "module-python.sparknlp.common"]], "hasembeddingsproperties (class in python.sparknlp.common.properties)": [[150, "python.sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[150, "python.sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "python.sparknlp.common.properties": [[150, "module-python.sparknlp.common.properties"]], "setdimension() (hasembeddingsproperties method)": [[150, "python.sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "readas (class in python.sparknlp.common.read_as)": [[151, "python.sparknlp.common.read_as.ReadAs"]], "python.sparknlp.common.read_as": [[151, "module-python.sparknlp.common.read_as"]], "recursiveannotatorapproach (class in python.sparknlp.common.recursive_annotator_approach)": [[152, "python.sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "python.sparknlp.common.recursive_annotator_approach": [[152, "module-python.sparknlp.common.recursive_annotator_approach"]], "python.sparknlp.common.storage": [[153, "module-python.sparknlp.common.storage"]], "externalresource() (in module python.sparknlp.common.utils)": [[154, "python.sparknlp.common.utils.ExternalResource"]], "python.sparknlp.common.utils": [[154, "module-python.sparknlp.common.utils"]], "explode_annotations_col() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.map_annotations"]], "map_annotations_array() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module python.sparknlp.functions)": [[155, "python.sparknlp.functions.map_annotations_strict"]], "python.sparknlp.functions": [[155, "module-python.sparknlp.functions"]], "python.sparknlp": [[156, "module-python.sparknlp"]], "start() (in module python.sparknlp)": [[156, "python.sparknlp.start"]], "version() (in module python.sparknlp)": [[156, "python.sparknlp.version"]], "annotatorjavamlreadable (class in python.sparknlp.internal.annotator_java_ml)": [[157, "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in python.sparknlp.internal.annotator_java_ml)": [[157, "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "python.sparknlp.internal.annotator_java_ml": [[157, "module-python.sparknlp.internal.annotator_java_ml"]], "read() (annotatorjavamlreadable class method)": [[157, "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "annotatortransformer (class in python.sparknlp.internal.annotator_transformer)": [[158, "python.sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "python.sparknlp.internal.annotator_transformer": [[158, "module-python.sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in python.sparknlp.internal.extended_java_wrapper)": [[159, "python.sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[159, "python.sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "python.sparknlp.internal.extended_java_wrapper": [[159, "module-python.sparknlp.internal.extended_java_wrapper"]], "python.sparknlp.internal": [[160, "module-python.sparknlp.internal"]], "paramsgetterssetters (class in python.sparknlp.internal.params_getters_setters)": [[161, "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[161, "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "python.sparknlp.internal.params_getters_setters": [[161, "module-python.sparknlp.internal.params_getters_setters"]], "setparamvalue() (paramsgetterssetters method)": [[161, "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "recursiveestimator (class in python.sparknlp.internal.recursive)": [[162, "python.sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in python.sparknlp.internal.recursive)": [[162, "python.sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[162, "python.sparknlp.internal.recursive.RecursiveEstimator.fit"]], "python.sparknlp.internal.recursive": [[162, "module-python.sparknlp.internal.recursive"]], "cometlogger (class in python.sparknlp.logging.comet)": [[163, "python.sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[163, "python.sparknlp.logging.comet.CometLogger.monitor"]], "python.sparknlp.logging.comet": [[163, "module-python.sparknlp.logging.comet"]], "python.sparknlp.logging": [[164, "module-python.sparknlp.logging"]], "python.sparknlp.pretrained": [[165, "module-python.sparknlp.pretrained"]], "pretrainedpipeline (class in python.sparknlp.pretrained.pretrained_pipeline)": [[166, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[166, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[166, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "fullannotateimage() (pretrainedpipeline method)": [[166, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotateImage"]], "python.sparknlp.pretrained.pretrained_pipeline": [[166, "module-python.sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[166, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "python.sparknlp.pretrained.resource_downloader": [[167, "module-python.sparknlp.pretrained.resource_downloader"]], "python.sparknlp.pretrained.utils": [[168, "module-python.sparknlp.pretrained.utils"]], "nertfgraphbuilder (class in python.sparknlp.training._tf_graph_builders.graph_builders)": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.NerTFGraphBuilder"]], "tfgraphbuilder (class in python.sparknlp.training._tf_graph_builders.graph_builders)": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilder"]], "tfgraphbuilderfactory (class in python.sparknlp.training._tf_graph_builders.graph_builders)": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory"]], "tensorflowaddonsneeded": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.TensorflowAddonsNeeded"]], "wrongtfversion": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.WrongTFVersion"], [184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.WrongTFVersion"]], "build() (tfgraphbuilderfactory static method)": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.build"], [184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.build"]], "get_models() (tfgraphbuilderfactory static method)": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.get_models"], [184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.get_models"]], "print_model_params() (tfgraphbuilderfactory static method)": [[169, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.print_model_params"], [184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.print_model_params"]], "python.sparknlp.training._tf_graph_builders.graph_builders": [[169, "module-python.sparknlp.training._tf_graph_builders.graph_builders"]], "python.sparknlp.training._tf_graph_builders": [[170, "module-python.sparknlp.training._tf_graph_builders"]], "python.sparknlp.training._tf_graph_builders.ner_dl.create_graph": [[171, "module-python.sparknlp.training._tf_graph_builders.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder": [[172, "module-python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders.ner_dl": [[173, "module-python.sparknlp.training._tf_graph_builders.ner_dl"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model": [[174, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver": [[175, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper": [[176, "module-python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"]], "embeddingwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper"]], "inputprojectionwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper"]], "outputprojectionwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper"]], "call() (embeddingwrapper method)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.call"]], "call() (inputprojectionwrapper method)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.call"]], "call() (outputprojectionwrapper method)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[177, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"]], "fusedrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.FusedRNNCell"]], "fusedrnncelladaptor (class in python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.FusedRNNCellAdaptor"]], "timereversedfusedrnn (class in python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.TimeReversedFusedRNN"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[178, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"]], "grublockcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops)": [[179, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell"]], "grublockcellv2 (class in python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops)": [[179, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2"]], "build() (grublockcellv2 method)": [[179, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2.build"]], "call() (grublockcell method)": [[179, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell.call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[179, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib": [[180, "module-python.sparknlp.training._tf_graph_builders.tf2contrib"]], "lstmblockcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell"]], "lstmblockfusedcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockFusedCell"]], "lstmblockwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper"]], "call() (lstmblockcell method)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell.call"]], "call() (lstmblockwrapper method)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper.call"]], "num_units() (lstmblockwrapper method)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper.num_units"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[181, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[182, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn"]], "stack_bidirectional_dynamic_rnn() (in module python.sparknlp.training._tf_graph_builders.tf2contrib.rnn)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn.stack_bidirectional_dynamic_rnn"]], "stack_bidirectional_rnn() (in module python.sparknlp.training._tf_graph_builders.tf2contrib.rnn)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn.stack_bidirectional_rnn"]], "attentioncellwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper"]], "bidirectionalgridlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell"]], "cfncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell"]], "compiledwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CompiledWrapper"]], "conv1dlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv1DLSTMCell"]], "conv2dlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv2DLSTMCell"]], "conv3dlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv3DLSTMCell"]], "convlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.ConvLSTMCell"]], "coupledinputforgetgatelstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell"]], "glstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell"]], "gridlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell"]], "highwaywrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.HighwayWrapper"]], "indrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell"]], "indygrucell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell"]], "indylstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell"]], "intersectionrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell"]], "layernormbasiclstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell"]], "layernormlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell"]], "minimalrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell"]], "nascell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell"]], "ntmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NTMCell"]], "phasedlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell"]], "srucell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell"]], "timefreqlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell"]], "ugrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell"]], "weightnormlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell"]], "call() (attentioncellwrapper method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper.call"]], "call() (bidirectionalgridlstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell.call"]], "call() (cfncell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell.call"]], "call() (coupledinputforgetgatelstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell.call"]], "call() (glstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell.call"]], "call() (gridlstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell.call"]], "call() (indrnncell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell.call"]], "call() (indygrucell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell.call"]], "call() (indylstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell.call"]], "call() (intersectionrnncell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell.call"]], "call() (layernormbasiclstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell.call"]], "call() (layernormlstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell.call"]], "call() (minimalrnncell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell.call"]], "call() (nascell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell.call"]], "call() (phasedlstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell.call"]], "call() (srucell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell.call"]], "call() (timefreqlstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell.call"]], "call() (ugrnncell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell.call"]], "call() (weightnormlstmcell method)": [[183, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell.call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[183, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"]], "nertfgraphbuilder (class in python.sparknlp.training._tf_graph_builders_1x.graph_builders)": [[184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.NerTFGraphBuilder"]], "tfgraphbuilder (class in python.sparknlp.training._tf_graph_builders_1x.graph_builders)": [[184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilder"]], "tfgraphbuilderfactory (class in python.sparknlp.training._tf_graph_builders_1x.graph_builders)": [[184, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders": [[184, "module-python.sparknlp.training._tf_graph_builders_1x.graph_builders"]], "python.sparknlp.training._tf_graph_builders_1x": [[185, "module-python.sparknlp.training._tf_graph_builders_1x"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph": [[186, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder": [[187, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl": [[188, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model": [[189, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver": [[190, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper": [[191, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"]], "conll (class in python.sparknlp.training.conll)": [[192, "python.sparknlp.training.conll.CoNLL"]], "python.sparknlp.training.conll": [[192, "module-python.sparknlp.training.conll"]], "readdataset() (conll method)": [[192, "python.sparknlp.training.conll.CoNLL.readDataset"]], "conllu (class in python.sparknlp.training.conllu)": [[193, "python.sparknlp.training.conllu.CoNLLU"]], "python.sparknlp.training.conllu": [[193, "module-python.sparknlp.training.conllu"]], "readdataset() (conllu method)": [[193, "python.sparknlp.training.conllu.CoNLLU.readDataset"]], "python.sparknlp.training": [[194, "module-python.sparknlp.training"]], "pos (class in python.sparknlp.training.pos)": [[195, "python.sparknlp.training.pos.POS"]], "python.sparknlp.training.pos": [[195, "module-python.sparknlp.training.pos"]], "readdataset() (pos method)": [[195, "python.sparknlp.training.pos.POS.readDataset"]], "pubtator (class in python.sparknlp.training.pub_tator)": [[196, "python.sparknlp.training.pub_tator.PubTator"]], "python.sparknlp.training.pub_tator": [[196, "module-python.sparknlp.training.pub_tator"]], "readdataset() (pubtator method)": [[196, "python.sparknlp.training.pub_tator.PubTator.readDataset"]], "python.sparknlp.training.tfgraphs": [[197, "module-python.sparknlp.training.tfgraphs"]], "python.sparknlp.upload_to_hub": [[198, "module-python.sparknlp.upload_to_hub"]], "python.sparknlp.util": [[199, "module-python.sparknlp.util"]]}})