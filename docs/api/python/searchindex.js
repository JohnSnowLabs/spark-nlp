Search.setIndex({"docnames": ["getting_started/index", "index", "reference/autosummary/sparknlp/annotation/index", "reference/autosummary/sparknlp/annotation_audio/index", "reference/autosummary/sparknlp/annotation_image/index", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index", "reference/autosummary/sparknlp/annotator/audio/index", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/sparknlp/annotator/chunk2_doc/index", "reference/autosummary/sparknlp/annotator/chunker/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/sparknlp/annotator/coref/index", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/sparknlp/annotator/cv/index", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/sparknlp/annotator/date2_chunk/index", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/sparknlp/annotator/dependency/index", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/sparknlp/annotator/document_normalizer/index", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/sparknlp/annotator/er/index", "reference/autosummary/sparknlp/annotator/graph_extraction/index", "reference/autosummary/sparknlp/annotator/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/sparknlp/annotator/ld_dl/index", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/sparknlp/annotator/lemmatizer/index", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/index", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/sparknlp/annotator/ner/index", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index", "reference/autosummary/sparknlp/annotator/normalizer/index", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/sparknlp/annotator/param/index", "reference/autosummary/sparknlp/annotator/pos/index", "reference/autosummary/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/sparknlp/annotator/sentence/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/sparknlp/annotator/sentiment/index", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/index", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/sparknlp/annotator/spell_check/index", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/sparknlp/annotator/stemmer/index", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/index", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/sparknlp/annotator/ws/index", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/sparknlp/base/audio_assembler/index", "reference/autosummary/sparknlp/base/doc2_chunk/index", "reference/autosummary/sparknlp/base/document_assembler/index", "reference/autosummary/sparknlp/base/embeddings_finisher/index", "reference/autosummary/sparknlp/base/finisher/index", "reference/autosummary/sparknlp/base/graph_finisher/index", "reference/autosummary/sparknlp/base/has_recursive_fit/index", "reference/autosummary/sparknlp/base/has_recursive_transform/index", "reference/autosummary/sparknlp/base/image_assembler/index", "reference/autosummary/sparknlp/base/index", "reference/autosummary/sparknlp/base/light_pipeline/index", "reference/autosummary/sparknlp/base/multi_document_assembler/index", "reference/autosummary/sparknlp/base/recursive_pipeline/index", "reference/autosummary/sparknlp/base/table_assembler/index", "reference/autosummary/sparknlp/base/token2_chunk/index", "reference/autosummary/sparknlp/base/token_assembler/index", "reference/autosummary/sparknlp/common/annotator_approach/index", "reference/autosummary/sparknlp/common/annotator_model/index", "reference/autosummary/sparknlp/common/annotator_properties/index", "reference/autosummary/sparknlp/common/annotator_type/index", "reference/autosummary/sparknlp/common/coverage_result/index", "reference/autosummary/sparknlp/common/index", "reference/autosummary/sparknlp/common/properties/index", "reference/autosummary/sparknlp/common/read_as/index", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/sparknlp/common/storage/index", "reference/autosummary/sparknlp/common/utils/index", "reference/autosummary/sparknlp/functions/index", "reference/autosummary/sparknlp/index", "reference/autosummary/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/sparknlp/internal/annotator_transformer/index", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/sparknlp/internal/index", "reference/autosummary/sparknlp/internal/params_getters_setters/index", "reference/autosummary/sparknlp/internal/recursive/index", "reference/autosummary/sparknlp/logging/comet/index", "reference/autosummary/sparknlp/logging/index", "reference/autosummary/sparknlp/pretrained/index", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/sparknlp/pretrained/utils/index", "reference/autosummary/sparknlp/training/conll/index", "reference/autosummary/sparknlp/training/conllu/index", "reference/autosummary/sparknlp/training/index", "reference/autosummary/sparknlp/training/pos/index", "reference/autosummary/sparknlp/training/pub_tator/index", "reference/autosummary/sparknlp/training/spacy_to_annotation/index", "reference/autosummary/sparknlp/training/tfgraphs/index", "reference/autosummary/sparknlp/upload_to_hub/index", "reference/autosummary/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["getting_started/index.rst", "index.rst", "reference/autosummary/sparknlp/annotation/index.rst", "reference/autosummary/sparknlp/annotation_audio/index.rst", "reference/autosummary/sparknlp/annotation_image/index.rst", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/audio/index.rst", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/chunk2_doc/index.rst", "reference/autosummary/sparknlp/annotator/chunker/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/coref/index.rst", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/sparknlp/annotator/cv/index.rst", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/date2_chunk/index.rst", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/dependency/index.rst", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/sparknlp/annotator/er/index.rst", "reference/autosummary/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/sparknlp/annotator/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/sparknlp/annotator/ner/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.rst", "reference/autosummary/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/sparknlp/annotator/param/index.rst", "reference/autosummary/sparknlp/annotator/pos/index.rst", "reference/autosummary/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/sparknlp/annotator/sentence/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/index.rst", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/ws/index.rst", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/sparknlp/base/document_assembler/index.rst", "reference/autosummary/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/sparknlp/base/finisher/index.rst", "reference/autosummary/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/sparknlp/base/image_assembler/index.rst", "reference/autosummary/sparknlp/base/index.rst", "reference/autosummary/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/sparknlp/base/table_assembler/index.rst", "reference/autosummary/sparknlp/base/token2_chunk/index.rst", "reference/autosummary/sparknlp/base/token_assembler/index.rst", "reference/autosummary/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/sparknlp/common/annotator_model/index.rst", "reference/autosummary/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/sparknlp/common/annotator_type/index.rst", "reference/autosummary/sparknlp/common/coverage_result/index.rst", "reference/autosummary/sparknlp/common/index.rst", "reference/autosummary/sparknlp/common/properties/index.rst", "reference/autosummary/sparknlp/common/read_as/index.rst", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/sparknlp/common/storage/index.rst", "reference/autosummary/sparknlp/common/utils/index.rst", "reference/autosummary/sparknlp/functions/index.rst", "reference/autosummary/sparknlp/index.rst", "reference/autosummary/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/sparknlp/internal/index.rst", "reference/autosummary/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/sparknlp/internal/recursive/index.rst", "reference/autosummary/sparknlp/logging/comet/index.rst", "reference/autosummary/sparknlp/logging/index.rst", "reference/autosummary/sparknlp/pretrained/index.rst", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/sparknlp/pretrained/utils/index.rst", "reference/autosummary/sparknlp/training/conll/index.rst", "reference/autosummary/sparknlp/training/conllu/index.rst", "reference/autosummary/sparknlp/training/index.rst", "reference/autosummary/sparknlp/training/pos/index.rst", "reference/autosummary/sparknlp/training/pub_tator/index.rst", "reference/autosummary/sparknlp/training/spacy_to_annotation/index.rst", "reference/autosummary/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/sparknlp/upload_to_hub/index.rst", "reference/autosummary/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.hubert_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.swin_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.date2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.zero_shot_ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_type</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.spacy_to_annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185], "thi": [0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 51, 52, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 79, 80, 81, 84, 85, 86, 89, 90, 91, 92, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 123, 124, 126, 127, 129, 132, 134, 135, 136, 137, 138, 139, 141, 142, 146, 152, 153, 157, 158, 159, 162, 163, 168, 170, 174, 175, 178, 179, 180, 182, 183, 184], "can": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 84, 89, 90, 91, 92, 93, 99, 101, 102, 104, 106, 108, 109, 110, 112, 113, 115, 123, 126, 127, 135, 136, 137, 138, 150, 159, 162, 163, 165, 166, 168, 175, 177, 179, 180, 182, 183, 184, 185], "quick": [0, 175, 180], "refer": [0, 1, 5, 42, 44, 45, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 68, 69, 70, 76, 93, 101, 102, 105, 106, 108, 109, 110, 112, 113, 123, 125, 126, 135, 179, 181, 182], "how": [0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 47, 49, 51, 52, 54, 55, 56, 57, 59, 61, 62, 64, 68, 70, 71, 73, 78, 79, 80, 84, 85, 89, 90, 91, 94, 96, 101, 104, 112, 113, 120, 121, 123, 126, 129, 135, 147, 150, 152, 165, 166, 170, 175, 179, 184], "set": [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 141, 142, 146, 150, 152, 157, 158, 159, 163, 165, 175, 179, 182, 183], "up": [0, 1, 5, 19, 30, 58, 61, 64, 66, 76, 106, 109, 152, 175, 179, 182, 183], "your": [0, 1, 19, 30, 34, 47, 57, 58, 62, 64, 66, 79, 80, 84, 85, 90, 91, 94, 99, 104, 105, 110, 112, 117, 119, 123, 127, 177, 179, 182, 183, 185], "environ": [0, 176], "pypi": 0, "pip": 0, "anaconda": 0, "c": [0, 54, 58, 66, 76, 108, 123], "johnsnowlab": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 84, 85, 90, 91, 93, 94, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 121, 123, 127, 128, 137, 152], "load": [0, 1, 3, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 76, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 132, 162, 163, 170, 179, 182], "shell": 0, "packag": [0, 51, 56, 159, 176, 177], "com": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 84, 85, 90, 91, 93, 94, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 121, 123, 137, 152], "nlp_2": [0, 152], "12": [0, 51, 68, 69, 70, 76, 81, 83, 89, 99, 110, 134, 138, 151, 152, 162, 168, 170, 178], "pyspark": [0, 2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 132, 134, 135, 137, 138, 139, 151, 152, 155, 158, 159, 162, 165, 166, 168, 169, 179, 180], "submit": [0, 159, 175], "extern": [0, 76, 79, 84, 85, 91, 110, 116, 136, 150, 165, 166, 168, 169], "jar": [0, 152], "after": [0, 46, 47, 49, 58, 62, 63, 66, 81, 83, 89, 119, 139, 159, 178, 179], "compil": 0, "build": [0, 56, 57, 62, 63, 73, 76, 80, 106, 159, 175], "sbt": 0, "assembli": 0, "i": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 150, 151, 152, 158, 159, 163, 165, 168, 169, 170, 175, 176, 178, 179, 180, 182, 183, 184, 185], "built": [0, 19, 30, 135], "top": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 44, 51, 76, 106, 109, 135], "apach": [0, 135, 152], "x": [0, 30, 151, 165, 185], "For": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 121, 123, 126, 127, 128, 135, 139, 159, 162, 169, 175, 176, 178, 179, 180, 181, 182, 183], "you": [0, 47, 49, 55, 57, 62, 64, 73, 81, 92, 127, 129, 134, 159, 163, 168, 170, 175, 177, 179, 180, 183, 184, 185], "need": [0, 5, 7, 9, 47, 49, 57, 62, 67, 71, 73, 76, 81, 84, 90, 91, 94, 96, 99, 102, 105, 106, 110, 112, 113, 120, 121, 124, 132, 134, 159, 163, 165, 166, 168, 175, 177, 179, 180, 183, 185], "java": [0, 78, 140, 141, 148, 154, 155, 158, 163], "8": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 47, 49, 50, 51, 52, 53, 54, 56, 57, 61, 62, 63, 68, 69, 70, 81, 86, 91, 92, 96, 106, 110, 123, 138, 165, 170], "1": [0, 5, 8, 9, 11, 14, 17, 19, 21, 24, 28, 30, 32, 34, 37, 39, 42, 44, 46, 47, 49, 51, 52, 53, 56, 58, 59, 63, 66, 67, 68, 69, 70, 76, 80, 81, 83, 84, 85, 86, 89, 90, 91, 93, 95, 96, 101, 102, 105, 106, 108, 109, 110, 116, 120, 123, 127, 128, 142, 146, 152, 157, 158, 159, 162, 163, 165, 166, 169, 170, 175, 178, 179, 183, 184], "0": [0, 5, 7, 8, 9, 19, 30, 34, 42, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 78, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 106, 109, 110, 113, 116, 121, 123, 126, 127, 128, 134, 135, 137, 138, 139, 142, 146, 151, 152, 155, 157, 158, 159, 162, 163, 166, 168, 169, 170, 175, 178, 179, 184, 185], "ar": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 47, 49, 51, 52, 54, 56, 57, 59, 61, 62, 65, 67, 68, 69, 70, 71, 73, 76, 78, 79, 81, 84, 86, 89, 91, 92, 93, 94, 99, 101, 102, 105, 106, 108, 109, 110, 114, 116, 123, 127, 134, 136, 137, 147, 151, 159, 163, 169, 170, 175, 176, 177, 178, 179, 180, 183, 184, 185], "6": [0, 19, 34, 44, 52, 53, 56, 59, 76, 80, 85, 86, 92, 99, 112, 138, 166, 170, 179], "7": [0, 8, 34, 44, 52, 53, 56, 81, 83, 99, 106, 128, 168, 170, 178], "It": [0, 11, 14, 19, 21, 24, 28, 30, 32, 34, 35, 37, 39, 44, 50, 52, 53, 54, 56, 57, 58, 61, 62, 63, 66, 68, 69, 71, 76, 86, 105, 108, 110, 112, 113, 119, 128, 134, 163, 178, 183], "recommend": [0, 59, 70, 104, 105, 106, 108, 109], "have": [0, 5, 19, 30, 34, 51, 54, 57, 62, 63, 67, 76, 84, 86, 90, 91, 92, 99, 101, 102, 106, 113, 138, 139, 154, 179, 180, 183], "basic": [0, 44, 76, 101, 178], "knowledg": [0, 57, 76, 129], "framework": [0, 7, 108, 109], "work": [0, 57, 61, 78, 109, 117, 178, 180, 184], "befor": [0, 50, 67, 81, 83, 109, 112, 120, 123, 141, 158, 175], "pleas": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 52, 53, 54, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 78, 79, 80, 81, 84, 85, 90, 91, 94, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 123, 126, 135, 136, 176, 177, 181, 184], "document": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 128, 129, 134, 135, 137, 138, 139, 159, 162, 165, 166, 168, 170, 175, 179, 180, 182, 183, 184], "first": [0, 2, 56, 58, 59, 66, 68, 69, 76, 84, 90, 91, 92, 101, 109, 110, 115, 120, 127, 139, 175, 179, 180, 184], "let": [0, 57, 119, 179], "": [0, 1, 10, 13, 16, 20, 23, 27, 31, 36, 50, 51, 54, 56, 57, 58, 61, 62, 63, 66, 68, 69, 71, 76, 84, 91, 94, 105, 106, 108, 109, 110, 112, 113, 119, 120, 121, 123, 124, 128, 134, 140, 141, 148, 151, 154, 158, 159, 175, 178, 179, 180, 183], "make": [0, 44, 50, 54, 61, 68, 69, 76, 102, 105, 112, 181, 185], "sure": [0, 105], "version": [0, 50, 57, 95, 96, 116, 142, 146, 152, 157, 158, 162, 163, 179, 184], "oracl": 0, "openjdk": 0, "0_292": 0, "creat": [0, 2, 3, 4, 19, 30, 34, 52, 53, 58, 62, 66, 67, 73, 91, 96, 99, 117, 123, 134, 136, 151, 165, 166, 168, 169, 179, 180, 183, 185], "new": [0, 2, 3, 4, 8, 34, 42, 44, 46, 51, 52, 53, 56, 59, 61, 67, 70, 92, 93, 95, 96, 106, 109, 110, 116, 128, 142, 146, 157, 158, 178, 179], "manag": [0, 76, 163, 176], "all": [0, 2, 3, 4, 11, 14, 17, 21, 24, 28, 32, 35, 37, 39, 44, 50, 51, 52, 53, 54, 64, 67, 70, 71, 74, 78, 81, 91, 94, 106, 109, 110, 115, 120, 123, 127, 129, 159, 163, 174, 179, 184], "depend": [0, 2, 42, 54, 64, 70, 71, 73, 74, 76, 78, 91, 108, 110, 123, 152], "Then": [0, 19, 30, 90, 91, 139, 159, 179], "we": [0, 5, 7, 19, 30, 44, 45, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 68, 69, 70, 76, 90, 91, 94, 102, 106, 108, 109, 110, 112, 121, 134, 151, 175, 178, 179, 180, 183, 184, 185], "sparknlp": [0, 175, 178, 179, 180, 181, 183, 184, 185], "n": [0, 69, 76, 86, 89, 90, 91, 101, 102, 106, 109, 119, 134, 137, 151, 162], "y": [0, 30], "activ": [0, 11, 14, 17, 24, 28, 32, 37, 39, 76], "jupyt": [0, 159, 175], "now": [0, 54, 102, 134, 180], "should": [0, 2, 3, 4, 9, 19, 30, 34, 58, 66, 68, 76, 78, 85, 86, 90, 91, 96, 101, 102, 108, 110, 120, 134, 141, 142, 154, 158, 162, 165, 166], "readi": [0, 19, 162, 179], "notebook": [0, 159, 175], "run": [0, 57, 76, 159, 163, 176, 184], "also": [0, 19, 30, 34, 44, 45, 50, 51, 59, 61, 67, 68, 69, 71, 73, 76, 81, 84, 89, 90, 91, 95, 96, 102, 105, 115, 134, 137, 142, 146, 157, 175, 179, 180, 181, 182, 184], "python3": 0, "sourc": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169, 170, 176], "bin": 0, "A": [0, 5, 7, 34, 42, 51, 62, 63, 67, 71, 76, 79, 80, 84, 85, 86, 93, 94, 104, 106, 108, 109, 112, 113, 120, 121, 159, 168, 177, 179, 185], "retriev": [0, 67, 79, 112, 113, 114, 159, 162, 175, 179, 180], "import": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 132, 134, 135, 136, 137, 138, 139, 151, 159, 162, 165, 166, 168, 169, 170, 175, 178, 179, 182, 183, 184, 185], "If": [0, 11, 14, 17, 19, 21, 24, 28, 30, 32, 34, 37, 39, 64, 67, 71, 78, 81, 83, 89, 90, 91, 94, 96, 101, 102, 106, 109, 110, 116, 152, 158, 159, 163, 175, 177, 179], "manual": [0, 178], "sparksess": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 67, 68, 69, 70, 80, 106, 108, 109, 152, 165, 166, 168, 169], "becaus": [0, 104, 141, 158], "other": [0, 5, 8, 30, 54, 64, 65, 73, 76, 94, 104, 106, 109, 110, 117, 119, 127, 128, 179], "configur": [0, 64, 121, 152], "includ": [0, 44, 50, 52, 53, 58, 59, 66, 68, 69, 70, 73, 76, 81, 89, 90, 91, 106, 109, 110, 128, 159, 169, 176, 178, 179, 180, 185], "them": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 44, 45, 51, 52, 54, 56, 57, 61, 62, 68, 70, 71, 73, 76, 81, 84, 102, 110, 115, 123, 136, 139, 179, 180], "builder": [0, 116, 152], "appnam": [0, 152], "master": [0, 152], "local": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 76, 106, 108, 109, 115, 134, 152, 162, 183], "config": [0, 152, 176], "driver": [0, 152], "memori": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 51, 59, 67, 152], "16g": [0, 152], "maxresults": [0, 152], "kryoseri": [0, 152], "buffer": [0, 53, 67, 152], "max": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 51, 52, 53, 54, 56, 57, 61, 62, 63, 68, 69, 70, 76, 113, 152], "2000m": [0, 152], "getorcr": [0, 152], "main": [1, 71, 121, 178, 182, 185], "page": [1, 50, 106, 162, 174, 182, 184], "github": [1, 56, 62, 108, 162], "issu": [1, 123], "workshop": [1, 182], "model": [1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 84, 85, 90, 91, 93, 94, 96, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 117, 119, 121, 123, 141, 152, 158, 159, 162, 163, 175, 176, 178, 182, 184, 185], "hub": [1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 78, 79, 90, 91, 99, 102, 106, 108, 109, 110, 112, 113, 115, 123], "welcom": [1, 5, 7], "python": [1, 78], "contain": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 144, 146, 147, 148, 149, 150, 151, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 168, 169, 173, 175, 178, 179], "inform": [1, 47, 49, 67, 68, 76, 81, 89, 110, 126, 135, 169, 175, 176, 177, 178, 179, 185], "us": [1, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 93, 96, 99, 101, 102, 105, 106, 108, 109, 110, 112, 113, 115, 116, 120, 121, 123, 125, 126, 127, 128, 134, 135, 136, 137, 138, 139, 151, 152, 159, 162, 163, 165, 166, 168, 169, 176, 177, 178, 179, 180, 182], "librari": [1, 44, 45, 78, 125, 126, 127, 135, 139, 184], "exampl": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 136, 137, 138, 139, 151, 159, 162, 163, 165, 166, 168, 169, 170, 175, 178, 179, 180, 182, 183, 184, 185], "get": [1, 19, 30, 76, 88, 99, 110, 116, 121, 123, 124, 126, 127, 128, 132, 134, 135, 142, 146, 157, 175, 179, 184, 185], "start": [1, 5, 10, 13, 16, 20, 23, 27, 31, 36, 61, 73, 76, 90, 91, 102, 125, 152, 159, 175, 178, 180, 183, 184], "cheat": 1, "sheet": [1, 50], "requir": [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 45, 46, 47, 49, 51, 53, 56, 59, 65, 68, 69, 76, 91, 94, 105, 110, 123, 125, 127, 138, 139, 178, 179, 180], "instal": [1, 159, 177], "session": [1, 152, 165, 166, 168, 169], "from": [1, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 95, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 136, 137, 138, 139, 141, 151, 152, 155, 158, 159, 162, 165, 166, 168, 169, 170, 175, 178, 179, 180, 183, 184, 185], "user": [1, 89, 90, 121, 136, 152, 159, 175], "guid": [1, 176], "annot": [1, 3, 4, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 158, 159, 162, 163, 164, 168, 170, 175, 176, 181, 182, 183, 184, 185], "own": [1, 19, 30, 34, 47, 58, 66, 79, 80, 84, 85, 90, 91, 94, 99, 104, 105, 110, 112, 117, 119, 123, 182, 183, 185], "pipelin": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 132, 134, 135, 136, 137, 138, 139, 152, 158, 159, 161, 162, 163, 164, 176, 178, 179, 182], "pretrain": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 78, 79, 80, 81, 84, 85, 90, 91, 92, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 127, 128, 134, 151, 152, 159, 175, 178, 182], "dataset": [1, 19, 30, 34, 47, 49, 54, 58, 61, 62, 63, 66, 67, 76, 78, 90, 91, 96, 102, 106, 110, 123, 158, 162, 165, 166, 168, 169, 182], "train": [1, 5, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 62, 63, 65, 66, 68, 69, 70, 76, 78, 79, 80, 84, 85, 88, 90, 91, 94, 95, 96, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 117, 119, 123, 125, 134, 152, 159, 162, 175, 179, 180, 182, 183], "light": [1, 5, 57, 70, 76, 134, 182, 184], "helper": [1, 99, 123, 129, 151, 168, 169, 170, 182, 185], "function": [1, 59, 67, 109, 127, 163, 174, 182], "third": [1, 101, 115, 160, 165], "parti": [1, 160], "project": [1, 76, 108, 159, 176], "log": [1, 19, 30, 34, 91, 96, 102, 106, 152], "api": [1, 175, 179, 182], "modul": [1, 26, 48, 60, 72, 74, 75, 77, 82, 87, 97, 98, 100, 103, 107, 111, 118, 122, 133, 145, 156, 161, 167], "data": [2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 132, 134, 135, 136, 137, 138, 139, 151, 159, 162, 165, 166, 167, 168, 169, 176, 178, 179, 183, 184, 185], "format": [2, 3, 4, 44, 45, 47, 49, 71, 73, 79, 80, 81, 83, 84, 85, 90, 91, 94, 96, 104, 109, 112, 113, 121, 123, 124, 126, 128, 129, 132, 135, 137, 165, 166, 168, 169, 170, 176, 185], "annotatortyp": [2, 3, 4, 55, 86, 125, 126, 132, 135, 178], "begin": [2, 42, 89, 106, 119, 121, 125, 126, 135, 151, 178], "end": [2, 10, 13, 16, 20, 23, 27, 31, 36, 42, 91, 102, 119, 121, 123, 126, 135, 151, 159, 165, 175, 178, 180], "result": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 151, 152, 159, 162, 165, 166, 170, 175, 176, 178, 179, 180, 183, 184], "metadata": [2, 3, 4, 35, 42, 76, 85, 90, 91, 93, 99, 126, 128, 132, 134, 135, 151, 159, 163, 178, 180], "embed": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 73, 74, 90, 91, 92, 126, 127, 128, 134, 135, 146, 151, 152, 158, 162, 178], "repres": [2, 3, 4, 47, 49, 51, 56, 70, 71, 73, 80, 85, 86, 121, 159, 162, 179], "output": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 142, 151, 152, 159, 168, 175, 178, 179, 180], "spark": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 139, 145, 147, 151, 152, 154, 155, 156, 159, 162, 163, 165, 166, 168, 169, 170, 174, 176, 177, 178, 179, 181, 182, 183, 185], "nlp": [2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 78, 79, 80, 84, 85, 90, 91, 92, 93, 94, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 121, 123, 125, 126, 127, 128, 132, 133, 134, 135, 136, 137, 139, 145, 152, 156, 159, 162, 163, 165, 166, 168, 169, 174, 176, 177, 178, 179, 180, 181, 182, 183, 185], "detail": [2, 3, 4, 68, 69, 76, 93, 106, 109], "paramet": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 142, 146, 150, 151, 152, 157, 158, 159, 162, 163, 165, 166, 168, 169], "annotator_typ": [2, 3, 4], "str": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 142, 150, 151, 152, 157, 159, 162, 163, 165, 166, 168, 169], "The": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 120, 121, 123, 126, 128, 134, 135, 137, 151, 152, 159, 162, 163, 165, 166, 168, 169, 170, 175, 178, 179, 180, 182, 183, 185], "type": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 151, 153, 162, 168, 178, 179, 182], "possibl": [2, 3, 4, 55, 57, 68, 69, 71, 101, 110, 113, 126, 135, 147, 159, 175], "valu": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 71, 73, 76, 78, 79, 81, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 105, 106, 108, 109, 110, 112, 115, 116, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 142, 146, 147, 157, 159, 175, 185], "token": [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 79, 80, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 99, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 123, 125, 127, 134, 136, 138, 139, 152, 162, 165, 169, 170, 179, 183, 184], "wordpiec": 2, "word_embed": [2, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 64, 66, 68, 70, 74, 90, 91, 96], "sentence_embed": [2, 19, 30, 34, 53, 58, 60, 63, 65, 69, 74, 159, 175, 179], "categori": [2, 11, 14, 17, 19, 21, 24, 28, 30, 32, 34, 37, 39, 44, 45, 159, 175, 179], "date": [2, 46, 81, 83, 84], "entiti": [2, 8, 12, 15, 18, 22, 25, 29, 33, 38, 40, 42, 44, 54, 71, 72, 73, 80, 85, 87, 88, 89, 90, 91, 92, 93, 117, 128, 134, 138, 162], "sentiment": [2, 19, 30, 34, 59, 70, 74, 109, 152, 179, 180], "po": [2, 9, 11, 14, 17, 21, 24, 28, 32, 37, 39, 47, 49, 73, 74, 90, 91, 119, 123, 134, 151, 152, 162, 165, 167, 178, 182, 183, 184], "chunk": [2, 8, 9, 10, 13, 16, 20, 23, 27, 31, 35, 36, 46, 55, 58, 66, 71, 76, 80, 84, 85, 86, 89, 117, 125, 128, 138, 151, 159, 169, 175, 185], "named_ent": [2, 12, 15, 18, 22, 25, 29, 33, 38, 40, 73, 89, 90, 91, 92, 93, 96, 134, 162], "negex": 2, "labeled_depend": [2, 49], "languag": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 125, 135, 139, 163, 179], "keyword": [2, 75, 76, 104], "dummi": [2, 50], "int": [2, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 67, 68, 69, 70, 73, 76, 78, 81, 86, 88, 90, 91, 94, 95, 96, 99, 101, 102, 105, 106, 108, 109, 110, 113, 116, 120, 121, 123, 146, 152, 159, 165], "index": [2, 76, 80, 120, 152, 165], "charact": [2, 50, 59, 61, 71, 78, 84, 86, 94, 101, 102, 110, 112, 113, 120, 121, 123, 128], "under": [2, 57, 70, 76, 152], "last": [2, 81, 83, 117, 170, 183], "string": [2, 19, 30, 34, 42, 47, 50, 71, 84, 86, 92, 94, 102, 109, 113, 115, 119, 125, 126, 128, 132, 134, 135, 183], "dict": [2, 3, 4, 47, 49, 71, 79, 80, 84, 85, 90, 92, 93, 94, 96, 104, 110, 112, 113, 121, 134, 150, 152, 158, 159, 162], "associ": [2, 3, 4, 30, 65, 71, 84, 89, 159], "list": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 50, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 71, 73, 76, 78, 81, 84, 88, 89, 91, 92, 93, 94, 95, 101, 102, 106, 108, 109, 110, 115, 119, 121, 127, 128, 134, 135, 142, 151, 158, 159, 162, 163, 170, 174, 179], "vector": [2, 30, 52, 53, 55, 56, 58, 59, 65, 66, 67, 127, 128, 178], "where": [2, 30, 56, 59, 71, 76, 79, 80, 84, 85, 86, 99, 102, 104, 106, 109, 112, 113, 123, 125, 168], "applic": [2, 45, 76, 159, 160, 175, 177], "copi": [2, 3, 4], "differ": [2, 3, 4, 44, 47, 49, 59, 62, 63, 68, 70, 76, 81, 101, 102, 110, 121, 123, 134, 159, 183], "return": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 78, 79, 80, 85, 86, 88, 90, 91, 93, 99, 101, 102, 105, 106, 108, 109, 110, 112, 113, 114, 115, 119, 121, 123, 125, 134, 150, 151, 152, 153, 158, 162, 163, 165, 166, 168, 169], "newli": [2, 3, 4], "static": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 163, 179], "datatyp": [2, 151], "structtyp": 2, "schema": [2, 89, 159, 175], "look": [2, 91, 112, 178], "like": [2, 5, 10, 13, 16, 19, 20, 23, 27, 31, 36, 42, 50, 51, 55, 57, 61, 64, 70, 73, 76, 84, 89, 102, 105, 106, 110, 121, 123, 159, 175, 177, 178], "struct": [2, 126, 132, 135], "containsnul": [2, 30, 124, 126, 132, 135], "true": [2, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 44, 45, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 78, 80, 81, 83, 85, 89, 91, 94, 101, 102, 110, 112, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 159, 165, 166, 169, 170, 175, 179, 180], "nullabl": [2, 30, 124, 126, 132, 135], "fals": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 128, 129, 134, 135, 137, 138, 139, 151, 152, 159, 162, 165, 166, 168, 170, 175, 178, 179, 180, 185], "integ": [2, 126, 132, 135], "map": [2, 9, 30, 67, 71, 95, 96, 99, 110, 126, 132, 135, 142, 146, 151, 157, 158, 178], "kei": [2, 5, 47, 49, 62, 63, 68, 69, 79, 93, 126, 132, 134, 135, 159, 162, 175], "valuecontainsnul": [2, 126, 132, 135], "arrai": [2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 64, 65, 68, 69, 70, 78, 79, 86, 91, 95, 99, 101, 102, 106, 108, 109, 110, 117, 119, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 151, 180, 183], "element": [2, 30, 86, 124, 126, 132, 135], "float": [2, 3, 5, 7, 19, 30, 34, 78, 90, 91, 93, 95, 96, 102, 106, 109, 110, 123, 124, 126, 127, 134, 135], "sql": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 67, 68, 69, 70, 80, 106, 108, 109, 134, 151, 158, 162, 165, 166, 168, 169], "arraytyp": [2, 125, 151], "fromrow": 2, "row": [2, 35, 67, 101, 102, 105, 126, 135, 137, 151, 165], "column": [2, 8, 19, 30, 34, 50, 67, 79, 88, 90, 91, 95, 96, 99, 105, 116, 121, 123, 124, 125, 126, 127, 128, 129, 132, 135, 139, 142, 151, 162, 165, 168, 179], "torow": 2, "transform": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 137, 138, 139, 151, 154, 158, 159, 162, 175, 178, 179, 180, 183, 184, 185], "an": [2, 5, 7, 9, 19, 30, 34, 35, 44, 45, 47, 50, 54, 56, 59, 61, 70, 71, 76, 78, 80, 81, 83, 84, 85, 86, 90, 91, 93, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 117, 121, 123, 125, 126, 127, 128, 129, 134, 135, 139, 142, 146, 150, 151, 153, 157, 158, 159, 165, 166, 168, 169, 174, 176, 178, 179, 180, 182, 183], "annotationaudio": 3, "audio": [3, 124, 159], "alreadi": [3, 73, 76, 90, 91, 92, 121, 134, 138, 162, 183], "process": [3, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 66, 68, 69, 70, 73, 76, 78, 89, 90, 91, 96, 102, 106, 109, 123, 124, 125, 126, 127, 128, 132, 135, 136, 139, 159, 175, 178, 179, 180, 181], "file": [3, 5, 7, 19, 30, 34, 47, 49, 50, 65, 67, 71, 79, 80, 84, 85, 90, 91, 94, 96, 102, 104, 110, 112, 113, 116, 121, 124, 137, 147, 152, 159, 165, 166, 168, 169, 175, 185], "byte": [3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 78, 91, 95, 106, 108, 109, 110, 159], "annotationimag": [4, 134, 162], "origin": [4, 44, 45, 51, 58, 61, 62, 66, 89, 102, 132], "height": [4, 132], "width": [4, 132], "nchannel": [4, 132], "mode": [4, 19, 30, 34, 91, 96, 112, 126, 132, 135, 159], "imag": [4, 44, 45, 132, 134, 162], "uri": 4, "pixel": [4, 44], "number": [4, 19, 30, 34, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 86, 88, 90, 91, 95, 99, 101, 102, 106, 109, 110, 116, 123, 165, 166], "color": 4, "channel": [4, 110], "opencv": 4, "concern": [5, 7, 11, 44, 45, 46, 51], "hubertforctc": 5, "classnam": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 84, 85, 90, 91, 93, 94, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 121, 123, 137, 140, 141, 148, 154], "java_model": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 84, 85, 90, 91, 93, 94, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 119, 121, 123, 131, 137, 141, 158], "none": [5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 84, 85, 90, 91, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 121, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 141, 152, 158, 159, 162, 163, 180], "hubert": 5, "head": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 42, 51, 70, 89, 90, 91, 134, 151, 162, 179], "connectionist": [5, 7], "tempor": [5, 7], "classif": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 44, 45, 51, 65, 105, 109, 179], "ctc": [5, 7], "wa": [5, 7, 11, 12, 14, 15, 19, 21, 22, 24, 25, 28, 29, 32, 33, 34, 37, 38, 39, 40, 44, 50, 54, 56, 57, 61, 62, 63, 67, 68, 69, 76, 105, 106, 110, 162, 179, 180], "propos": [5, 7, 44, 51, 54, 56, 57, 62, 63, 68, 69, 70], "self": [5, 7, 44, 51, 61, 108], "supervis": [5, 7, 51, 59, 65, 76, 106], "speech": [5, 7, 9, 54, 98, 99, 123, 168, 185], "represent": [5, 7, 44, 51, 52, 53, 57, 58, 59, 66, 67, 68, 69, 70, 89, 109, 137, 150], "learn": [5, 7, 19, 30, 34, 51, 57, 58, 59, 62, 63, 65, 66, 68, 69, 70, 76, 90, 91, 95, 102, 106, 109, 110, 159, 177], "mask": [5, 44, 56, 68, 69, 70, 120], "predict": [5, 44, 56, 91, 106, 109, 159, 175], "hidden": [5, 10, 12, 13, 15, 16, 18, 20, 22, 23, 25, 27, 29, 31, 33, 36, 38, 40, 51, 59, 70, 116], "unit": [5, 106, 116], "wei": [5, 44], "ning": 5, "hsu": 5, "benjamin": [5, 54], "bolt": 5, "yao": 5, "hung": 5, "tsai": 5, "kushal": 5, "lakhotia": 5, "ruslan": 5, "salakhutdinov": 5, "abdelrahman": [5, 7], "moham": [5, 7], "take": [5, 7, 35, 54, 73, 85, 95, 96, 112, 115, 121, 136, 142, 146, 157, 165, 178, 179, 183, 184], "transcrib": [5, 7], "text": [5, 7, 8, 9, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 125, 126, 127, 128, 129, 135, 137, 138, 139, 147, 150, 151, 159, 165, 166, 168, 169, 175, 178, 179, 180, 184, 185], "provid": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 78, 79, 80, 81, 83, 84, 85, 90, 91, 94, 95, 96, 99, 102, 104, 106, 108, 109, 110, 112, 113, 123, 134, 142, 146, 151, 153, 157, 162, 180], "pre": [5, 7, 19, 30, 34, 45, 52, 53, 56, 57, 59, 65, 91, 96, 109, 126, 128, 135, 139, 166, 179], "note": [5, 7, 19, 30, 34, 51, 57, 59, 62, 64, 67, 68, 70, 76, 91, 106, 108, 109, 134, 152, 184], "current": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 67, 68, 69, 70, 76, 80, 81, 83, 102, 106, 108, 109, 116, 134, 137, 142, 152, 178, 179, 180], "support": [5, 7, 19, 30, 51, 61, 76, 91, 94, 102, 115, 137, 152, 176], "appl": [5, 7, 53, 63, 69, 152], "silicon": [5, 7, 152], "processor": [5, 7], "m1": [5, 7], "due": [5, 7, 11, 14, 17, 21, 24, 28, 32, 37, 39, 51, 61], "instruct": [5, 7], "xla": [5, 7], "companion": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 90, 91, 93, 99, 102, 106, 108, 109, 110, 112, 113, 115, 123, 155], "object": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 90, 91, 93, 99, 102, 106, 108, 109, 110, 112, 113, 114, 115, 123, 147, 154, 155, 159, 178, 179], "speechtotext": [5, 7], "setinputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 138, 139, 142, 159, 175, 179, 180], "audio_assembl": [5, 7, 133, 152], "setoutputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 138, 139, 142, 159, 175, 179, 180], "default": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 116, 119, 120, 121, 123, 125, 126, 127, 128, 129, 134, 135, 137, 150, 151, 152, 159, 162, 163, 165, 166, 168, 169, 179], "asr_hubert_large_ls960": 5, "name": [5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 85, 87, 88, 90, 91, 93, 95, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 116, 117, 121, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 139, 142, 151, 157, 159, 162, 163, 165, 168, 175, 179], "avail": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 74, 76, 78, 79, 81, 84, 90, 91, 99, 102, 106, 108, 109, 110, 112, 113, 115, 123, 154, 162, 163, 175, 182], "see": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 121, 123, 126, 127, 128, 129, 135, 139, 159, 162, 169, 175, 176, 177, 182, 184, 185], "To": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 44, 45, 51, 52, 54, 56, 57, 61, 62, 68, 70, 71, 76, 81, 84, 99, 101, 106, 109, 123, 129, 134, 136, 159, 175, 183], "which": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 64, 65, 66, 68, 70, 73, 76, 81, 83, 84, 91, 93, 94, 101, 102, 104, 106, 108, 109, 112, 120, 123, 127, 134, 151, 163, 165, 166, 179, 180], "compat": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 44, 45, 51, 52, 54, 56, 57, 61, 62, 68, 70, 91, 127, 163], "5669": [5, 7, 44, 45, 54], "more": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 50, 54, 57, 59, 64, 68, 69, 73, 76, 86, 89, 93, 102, 106, 109, 112, 120, 121, 126, 127, 128, 135, 139, 159, 162, 169, 175, 176, 177, 179, 182, 185], "extend": [5, 7, 9, 19, 30, 34, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 64, 65, 67, 68, 70, 76, 78, 79, 81, 83, 84, 85, 86, 90, 91, 93, 94, 96, 99, 101, 102, 104, 105, 108, 109, 110, 112, 114, 115, 119, 121, 123, 126, 127, 128, 135, 139, 162], "hubertforctctestspec": 5, "paper": [5, 44, 45, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 68, 69, 70, 76, 102, 105, 106, 108, 109, 123, 169, 185], "abstract": [5, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 76, 106, 108, 109, 116, 169, 185], "approach": [5, 44, 62, 63, 70, 76, 88, 90, 91, 93, 102, 104, 106, 109, 110, 112, 113, 140, 182], "challeng": [5, 30, 44, 57, 59, 62, 63, 76], "three": [5, 110, 138], "uniqu": 5, "problem": [5, 30, 51, 59, 109, 110, 123], "multipl": [5, 30, 45, 54, 71, 76, 81, 101, 121, 151, 159, 165], "sound": 5, "each": [5, 7, 19, 30, 34, 56, 58, 64, 66, 67, 71, 73, 76, 79, 80, 81, 84, 85, 86, 88, 90, 91, 93, 94, 96, 99, 101, 102, 104, 110, 112, 113, 120, 121, 123, 126, 135, 151, 158, 168, 180], "input": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 142, 151, 158, 162, 165, 166, 168, 169, 179, 180, 183, 185], "utter": 5, "lexicon": 5, "dure": [5, 19, 30, 34, 57, 90, 91, 96, 101, 110, 152, 159, 175], "phase": [5, 57], "variabl": [5, 58, 66], "length": [5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 66, 68, 69, 70, 86, 94, 101, 102, 106, 108, 109, 110, 120, 121], "explicit": [5, 101, 106], "segment": [5, 42, 44, 57, 62, 122, 123], "deal": [5, 134, 183], "bert": [5, 11, 13, 14, 15, 17, 21, 24, 25, 28, 32, 35, 37, 39, 51, 52, 53, 56, 57, 61, 62, 63, 68, 69, 70, 91, 92, 93, 109], "util": [5, 55, 90, 93, 101, 102, 113, 136, 144, 145, 147, 149, 152, 153, 157, 161], "offlin": [5, 159], "cluster": [5, 65, 152], "step": [5, 19, 30, 34, 58, 66, 91, 96, 159, 175, 179], "align": 5, "target": [5, 65, 108, 121, 125, 134, 162], "label": [5, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 44, 45, 47, 49, 71, 78, 88, 89, 90, 91, 93, 95, 96, 104, 105, 109, 110, 116, 123, 159, 165, 175, 179], "loss": [5, 51, 57, 91, 109, 175], "ingredi": 5, "our": [5, 51, 54, 57, 58, 59, 61, 62, 63, 65, 66, 68, 69, 76, 102, 106, 109, 151, 162, 184], "appli": [5, 8, 19, 30, 34, 45, 50, 71, 73, 91, 92, 96, 101, 109, 110, 112, 128, 151, 165], "over": [5, 57, 68, 69, 70, 112, 121, 151, 159, 175], "region": 5, "onli": [5, 47, 49, 50, 59, 65, 70, 81, 84, 94, 101, 102, 106, 109, 119, 123, 136, 165], "forc": 5, "combin": [5, 57, 61, 67, 76, 109, 110, 112, 123], "acoust": 5, "continu": [5, 89, 106, 129, 175], "reli": [5, 47, 49, 70, 76], "primarili": 5, "consist": [5, 51, 56, 61, 84, 99, 105, 123, 137, 168], "unsupervis": [5, 68, 69, 70, 76, 106], "rather": 5, "than": [5, 30, 34, 57, 58, 66, 68, 69, 70, 76, 78, 86, 90, 106, 112, 113, 179], "intrins": 5, "qualiti": [5, 44, 106], "assign": [5, 30, 71, 92, 104], "simpl": [5, 52, 53, 71, 106, 180], "k": [5, 106, 109, 127], "mean": [5, 9, 30, 68, 76, 78, 81, 83, 106, 108, 109, 120, 127, 134, 179, 180, 183], "teacher": 5, "100": [5, 19, 30, 35, 45, 58, 66, 68, 76, 102, 137], "two": [5, 30, 44, 47, 49, 51, 56, 65, 67, 68, 69, 73, 138, 165, 179], "iter": [5, 47, 49, 51, 58, 66, 99, 123, 159, 175], "either": [5, 19, 34, 45, 49, 54, 55, 64, 71, 76, 78, 84, 104, 105, 109, 123, 125, 126, 134, 135, 137, 162, 180], "match": [5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 66, 68, 69, 70, 71, 80, 81, 82, 83, 84, 85, 94, 99, 101, 106, 121, 123, 125, 178], "improv": [5, 51, 52, 53, 54, 56, 59, 62, 63, 68, 69, 90, 91, 106, 184], "upon": [5, 76], "state": [5, 10, 12, 13, 15, 16, 18, 19, 20, 22, 23, 25, 27, 29, 30, 31, 33, 34, 36, 38, 40, 44, 45, 51, 52, 53, 54, 59, 61, 62, 63, 70, 76, 91, 106, 109, 135, 176, 179], "art": [5, 19, 30, 44, 45, 51, 52, 53, 54, 59, 61, 62, 63, 70, 76, 91, 106, 109, 135], "wav2vec": [5, 7], "perform": [5, 44, 45, 50, 51, 54, 56, 57, 59, 62, 63, 65, 67, 68, 69, 70, 91, 105, 106, 112], "librispeech": 5, "960h": 5, "libri": 5, "60": [5, 57, 101], "000h": 5, "benchmark": [5, 45, 51, 56, 57, 59, 68, 69, 109], "10min": 5, "1h": 5, "10h": 5, "100h": 5, "fine": [5, 42, 52, 53, 57, 93, 109, 170], "tune": [5, 42, 52, 53, 57, 93, 109], "subset": 5, "1b": 5, "show": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 138, 139, 151, 163, 165, 166, 168, 169, 170, 175, 178, 179, 180, 184], "19": [5, 46, 86, 168, 170], "13": [5, 8, 9, 42, 68, 69, 73, 99, 128, 170], "rel": [5, 54, 56, 68, 81, 83, 90, 110, 178], "wer": 5, "reduct": [5, 51, 112], "dev": [5, 44, 51, 59, 65], "test": [5, 19, 30, 34, 44, 45, 47, 49, 52, 53, 65, 67, 79, 80, 84, 85, 90, 91, 96, 99, 106, 112, 113, 117, 123, 165, 166, 168, 169, 170, 179, 185], "evalu": [5, 19, 30, 34, 54, 61, 68, 69, 96, 142, 159], "batchsiz": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 68, 69, 70, 91, 108, 110], "size": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 66, 67, 68, 69, 70, 73, 76, 91, 95, 106, 108, 109, 110, 112, 178, 183, 184], "batch": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 68, 69, 70, 91, 95, 108, 110], "base": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 140, 141, 142, 145, 148, 152, 154, 158, 159, 175, 179, 180, 183], "ml": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 124, 125, 126, 127, 132, 134, 135, 136, 137, 138, 139, 159, 175, 179, 183], "audioassembl": [5, 7, 124], "audio_cont": [5, 7, 124], "setstag": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 127, 137, 138, 139, 179, 180], "processedaudiofloat": [5, 7], "createdatafram": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 128, 135, 137, 138, 139, 151, 159, 175, 178, 179, 180, 184], "rawfloat": [5, 7], "todf": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 128, 132, 135, 137, 138, 139, 151, 178, 179, 180, 184], "fit": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 125, 127, 134, 136, 137, 138, 139, 158, 159, 175, 179, 180, 183], "select": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 46, 55, 57, 67, 73, 76, 78, 90, 91, 93, 105, 106, 109, 110, 112, 113, 119, 123, 124, 126, 128, 129, 132, 135, 137, 139, 151, 159, 175, 180], "truncat": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 67, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 128, 129, 135, 137, 138, 139, 151, 168, 178, 179, 180], "mister": [5, 7], "quilter": [5, 7], "THE": [5, 7, 50], "apostl": [5, 7], "OF": [5, 7, 51], "midl": [5, 7], "clase": [5, 7], "AND": [5, 7], "glad": [5, 7], "TO": [5, 7, 165, 185], "hi": [5, 7, 93, 102], "gospel": [5, 7], "setconfigprotobyt": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 78, 91, 95, 106, 108, 109, 110], "b": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 78, 80, 85, 89, 90, 91, 92, 93, 95, 101, 106, 108, 109, 110, 123, 134, 151, 162, 165, 169, 185], "configproto": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 78, 91, 95, 106, 108, 109, 110], "tensorflow": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 76, 78, 91, 95, 106, 108, 109, 110], "serial": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 71, 78, 91, 95, 106, 108, 109, 110, 152], "loadsavedmodel": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 106, 108, 109], "folder": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 91, 96, 102, 106, 108, 109, 110, 113, 116, 163, 165], "spark_sess": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 106, 108, 109], "save": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 91, 96, 102, 106, 108, 109, 152, 159, 175, 179], "restor": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123], "lang": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 73, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 162, 163, 179, 184], "en": [5, 7, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 70, 73, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 162, 163, 166, 179, 184, 185], "remote_loc": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 162, 163], "download": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 73, 78, 79, 80, 85, 90, 91, 92, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 152, 162, 163, 178, 179, 182, 183], "option": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 76, 78, 79, 80, 84, 85, 90, 91, 93, 94, 96, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 124, 126, 130, 131, 134, 135, 150, 151, 152, 158, 159, 162, 163, 165, 166, 168, 169, 179], "remot": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 162, 163], "address": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123], "resourc": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 78, 79, 80, 84, 85, 90, 91, 93, 94, 96, 99, 102, 104, 105, 106, 108, 109, 110, 112, 113, 115, 117, 121, 123, 136, 147, 150, 161, 163, 165, 166, 168, 169, 170, 179, 185], "Will": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 101, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123], "repositori": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 162, 176], "otherwis": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 47, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 78, 79, 80, 85, 90, 91, 93, 99, 102, 105, 106, 108, 109, 110, 112, 113, 115, 121, 123, 125, 159], "hubert_for_ctc": 6, "wav2vec2_for_ctc": 6, "wav2vec2forctc": 7, "wav2vec2": 7, "alexei": 7, "baevski": 7, "henri": 7, "zhou": 7, "michael": [7, 117], "auli": 7, "asr_wav2vec2_base_960h": 7, "wav2vec2forctctestspec": 7, "chunk2doc": [8, 125], "convert": [8, 46, 50, 55, 64, 67, 81, 83, 86, 89, 94, 109, 120, 123, 125, 128, 129, 138, 159, 175, 182], "back": 8, "when": [8, 9, 11, 14, 21, 24, 28, 32, 37, 39, 45, 50, 51, 73, 81, 83, 86, 91, 106, 110, 112, 115, 119, 123, 134, 165, 179, 180, 183], "try": [8, 110, 165], "re": [8, 179], "do": [8, 65, 76, 89, 115, 121, 134, 175, 179, 183], "further": [8, 51, 76, 90, 91, 139], "analysi": [8, 19, 30, 34, 59, 70, 103, 104, 109, 144, 180], "doc2chunk": [8, 125], "pretrainedpipelin": [8, 128, 134, 151, 162, 178, 183, 184], "locat": [8, 71, 101, 152, 162, 179], "extract": [8, 9, 10, 13, 16, 20, 23, 27, 31, 36, 47, 55, 67, 71, 72, 73, 75, 76, 80, 81, 83, 85, 89, 90, 91, 92, 101, 102, 104, 110, 113, 117, 127, 128, 129, 134, 138, 152, 159, 162, 175], "york": [8, 93, 128], "jersei": [8, 128], "aren": [8, 128], "t": [8, 57, 62, 79, 94, 102, 104, 121, 128], "far": [8, 106, 128], "apart": [8, 47, 49, 128], "actual": [8, 86, 128, 139], "id": [8, 30, 50, 68, 71, 106, 108, 109, 110, 125, 126, 128, 135, 139, 159, 165], "defin": [8, 9, 89, 90, 91, 110, 115, 119, 128, 151, 159, 162, 175, 179, 183], "amongst": [8, 128], "thing": [8, 110, 128], "explain_document_dl": [8, 128, 134, 151, 162], "chunktodoc": 8, "chunkconvert": 8, "explainresult": [8, 128], "selectexpr": [8, 9, 19, 35, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 79, 80, 81, 83, 84, 85, 86, 89, 92, 93, 94, 99, 101, 102, 104, 108, 114, 115, 117, 120, 121, 125, 127, 128, 138, 151, 165, 166, 168, 178, 179, 184], "explod": [8, 9, 19, 35, 42, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 80, 83, 84, 85, 86, 89, 92, 93, 99, 101, 102, 108, 127, 128, 138, 151, 165, 168, 178, 179, 184], "col": [8, 47, 49, 71, 80, 89, 92, 128, 151, 178], "loc": [8, 12, 15, 18, 22, 25, 29, 33, 38, 40, 73, 89, 90, 91, 128, 134, 151, 162, 165], "sentenc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 78, 79, 80, 81, 83, 84, 85, 86, 89, 90, 91, 92, 93, 99, 105, 108, 110, 115, 117, 120, 123, 126, 128, 134, 135, 137, 138, 139, 152, 162, 165, 166, 168, 169, 170, 179, 183, 184], "22": [8, 128, 165, 178], "pattern": [9, 50, 71, 81, 84, 94, 112, 113, 120, 121, 123], "part": [9, 54, 76, 79, 98, 99, 114, 123, 125, 168, 185], "tag": [9, 19, 30, 34, 50, 54, 88, 89, 90, 91, 92, 98, 99, 123, 151, 159, 165, 168, 169, 185], "order": [9, 70, 71, 76, 112, 113, 134, 139, 151, 179, 180, 183, 185], "meaning": [9, 114], "phrase": [9, 54, 58, 66, 80, 85], "onto": [9, 151, 180], "pars": [9, 47, 48, 49, 54, 71, 79, 81, 83, 110, 112, 113, 134, 137, 162, 165, 168], "regular": [9, 84, 90, 101], "express": [9, 34, 42, 81, 84, 101], "wrap": [9, 140, 141, 148, 154, 158], "angl": 9, "bracket": 9, "easili": [9, 59, 99, 127, 175], "distinguish": 9, "itself": [9, 76, 109, 123, 136, 180], "form": [9, 19, 30, 34, 67, 71, 79, 80, 81, 84, 85, 102, 104, 112, 113, 123, 127, 159, 165, 166, 179], "peter": [9, 61, 79, 94, 99, 102, 112, 114, 165], "piper": [9, 79, 99, 114], "employe": [9, 79, 99, 114], "pick": [9, 79, 99, 114], "peck": [9, 79, 99, 114], "pickl": [9, 79, 99, 114], "pepper": [9, 79, 99, 114], "nnp": [9, 99, 134, 151, 165, 166, 168, 169, 178, 183, 184, 185], "nn": [9, 99, 165, 166, 168, 169, 185], "vbp": [9, 99, 134, 166, 178, 183, 184], "vbg": [9, 99], "IN": [9, 99, 134, 151, 166, 168, 169, 178, 183, 184], "jj": [9, 99, 134, 151, 165, 168, 178, 183, 184, 185], "regexpars": 9, "e": [9, 11, 12, 14, 15, 17, 18, 21, 22, 24, 25, 28, 29, 32, 33, 37, 38, 39, 40, 49, 50, 59, 61, 71, 73, 90, 91, 106, 108, 109, 110, 115, 137, 159, 175], "g": [9, 11, 12, 14, 15, 17, 18, 21, 22, 24, 25, 28, 29, 32, 33, 37, 38, 39, 40, 49, 50, 59, 73, 90, 91, 106, 108, 109, 110, 115, 137, 159, 175], "setregexpars": 9, "enclos": 9, "treat": [9, 110, 123], "group": [9, 121], "so": [9, 19, 34, 76, 89, 102, 136, 159, 175], "here": [9, 79, 151, 179], "specif": [9, 35, 47, 49, 50, 52, 53, 57, 65, 73, 76, 91, 106, 116, 134, 136, 159, 183], "noun": [9, 166], "success": [9, 54, 106], "grammar": 9, "parser": [9, 47, 49, 73], "perceptronmodel": [9, 47, 49, 73, 90, 99, 165], "Of": [9, 51, 123], "documentassembl": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 90, 91, 92, 93, 94, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 117, 119, 120, 121, 123, 125, 126, 127, 135, 136, 137, 138, 139, 159, 165, 175, 179], "sentencedetector": [9, 19, 35, 42, 47, 49, 53, 55, 63, 65, 69, 73, 76, 79, 84, 86, 90, 91, 92, 93, 99, 101, 102, 115, 117, 136, 139, 165, 179, 180], "postag": 9, "11": [9, 46, 68, 69, 81, 83, 86, 99, 170], "21": [9, 81, 83, 92, 99, 170], "35": [9, 99, 170], "39": [9, 92, 99, 168, 170], "52": [9, 92, 99, 168], "58": [9, 44, 99], "albertforquestionansw": 10, "classifi": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 76, 127, 179], "dl": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 78, 91, 93, 112, 113], "albert": [10, 11, 12, 51], "span": [10, 13, 16, 20, 23, 27, 31, 36, 109], "question": [10, 13, 16, 20, 23, 27, 31, 35, 36, 47, 49, 52, 53, 59, 62, 63, 70, 93, 99, 106, 109, 134], "answer": [10, 13, 16, 20, 23, 27, 31, 35, 36, 47, 49, 52, 53, 59, 70, 93, 106, 109, 134], "task": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 44, 45, 51, 52, 53, 54, 56, 57, 61, 65, 68, 69, 70, 76, 93, 106, 108, 109, 136], "squad": [10, 13, 16, 20, 23, 27, 31, 36, 51, 52, 53, 56, 62, 63], "linear": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 44, 106], "layer": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 51, 52, 53, 56, 59, 70], "comput": [10, 13, 16, 20, 23, 27, 31, 36, 44, 45, 51, 56, 57, 65, 106, 108, 113, 123, 134, 183], "logit": [10, 11, 13, 14, 16, 17, 20, 23, 24, 27, 28, 31, 32, 36, 37, 39], "spanclassifi": [10, 13, 16, 20, 23, 27, 31, 36], "document_quest": [10, 13, 16, 20, 23, 27, 31, 35, 36], "document_context": [10, 13, 16, 20, 23, 27, 31, 36], "albert_base_qa_squad2": 10, "larg": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 44, 45, 51, 56, 57, 59, 68, 69, 70, 76, 78, 80, 85, 91, 106], "allow": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 44, 59, 65, 90, 91, 94, 101, 102, 120, 121, 136], "faster": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 57, 59, 112, 113], "casesensit": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 68, 69, 70, 80, 85, 112, 115], "whether": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 71, 73, 80, 81, 83, 85, 86, 89, 90, 91, 94, 96, 101, 102, 106, 109, 110, 112, 115, 120, 121, 123, 125, 127, 128, 129, 134, 137, 139, 142, 152, 162, 165, 169, 180], "ignor": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 68, 69, 70, 80, 86, 89, 106, 108, 109, 112, 115, 134], "case": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 49, 50, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 68, 69, 70, 71, 78, 80, 85, 110, 112, 115, 121, 125, 165, 166, 179], "configprotobyt": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 45, 51, 52, 53, 54, 56, 57, 59, 61, 62, 63, 65, 68, 69, 70, 78, 91, 106, 108, 109, 110], "maxsentencelength": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 66, 68, 69, 70], "128": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 51, 52, 53, 54, 56, 57, 62, 63, 68, 69, 70, 159, 175], "multidocumentassembl": [10, 13, 16, 20, 23, 27, 31, 35, 36, 135], "context": [10, 13, 16, 20, 23, 27, 31, 36, 52, 53, 58, 59, 66, 70, 105, 110, 121], "setcasesensit": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 55, 57, 61, 62, 68, 80, 85, 90, 112, 115, 127, 139], "what": [10, 13, 16, 20, 23, 27, 31, 34, 36, 47, 49, 76, 78, 93, 108, 110, 119, 166, 176], "my": [10, 12, 13, 15, 16, 19, 20, 22, 23, 25, 27, 29, 31, 33, 34, 36, 38, 40, 50, 84, 86, 93, 101, 106, 115, 117, 120, 179], "clara": [10, 13, 16, 20, 23, 27, 31, 36, 93], "live": [10, 12, 13, 15, 16, 20, 22, 23, 25, 27, 29, 31, 33, 36, 38, 40, 93, 106, 159, 175], "berkelei": [10, 13, 16, 20, 23, 27, 31, 36], "setmaxsentencelength": [10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 42, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 66, 68, 69, 70], "albertforsequenceclassif": [11, 21], "sequenc": [11, 14, 17, 21, 24, 28, 32, 37, 39, 45, 61, 106, 107, 108, 109, 110, 115], "regress": [11, 14, 17, 21, 24, 28, 32, 37, 39, 109], "pool": [11, 14, 17, 21, 24, 28, 32, 37, 39, 55, 59, 64], "multi": [11, 14, 17, 19, 21, 24, 28, 30, 32, 34, 37, 39, 51, 65, 68, 69, 76, 78, 108], "sequenceclassifi": [11, 14, 17, 21, 24, 28, 32, 37, 39], "albert_base_sequence_classifier_imdb": 11, "coalescesent": [11, 14, 17, 21, 24, 28, 32, 37, 39, 78], "instead": [11, 14, 17, 21, 24, 28, 32, 37, 39, 53, 76, 78, 81, 83, 109, 127, 128, 134, 183], "per": [11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 68, 69, 78, 81, 86, 88, 89, 90, 91, 123, 134, 151, 162, 165], "inputcol": [11, 14, 17, 19, 21, 24, 28, 30, 32, 34, 37, 39, 64, 78, 124, 126, 127, 128, 129, 132, 135], "averag": [11, 14, 17, 21, 24, 28, 32, 35, 37, 39, 55, 64, 68, 69, 78, 91, 99], "probabl": [11, 14, 17, 21, 24, 28, 32, 37, 39, 76, 106, 109, 112], "calcul": [11, 14, 17, 19, 24, 28, 30, 32, 34, 37, 39, 67, 86, 91, 96, 104], "via": [11, 14, 17, 24, 28, 32, 37, 39, 65, 132, 152], "softmax": [11, 14, 17, 24, 28, 32, 37, 39, 56, 58, 66, 110], "sigmoid": [11, 14, 17, 24, 28, 32, 37, 39], "love": [11, 14, 19, 21, 24, 28, 32, 37, 39, 53, 63, 69, 102, 105, 179], "movi": [11, 14, 19, 21, 24, 28, 32, 34, 37, 39, 105, 179], "child": [11, 14, 21, 24, 28, 32, 37, 39], "pretti": [11, 14, 21, 24, 28, 30, 32, 37, 39, 76], "bore": [11, 14, 21, 24, 28, 32, 37, 39], "neg": [11, 14, 17, 21, 24, 28, 32, 34, 37, 39, 104, 105, 159, 175], "getclass": [11, 12, 14, 15, 17, 18, 21, 22, 24, 25, 28, 29, 32, 33, 37, 38, 39, 40, 44, 45, 93], "setcoalescesent": [11, 14, 17, 21, 24, 28, 32, 37, 39, 78], "limit": [11, 14, 17, 21, 24, 28, 32, 37, 39, 44, 45, 51, 54, 61, 67, 70, 76, 109, 112], "almost": [11, 14, 17, 21, 24, 28, 32, 37, 39], "512": [11, 14, 17, 21, 24, 28, 32, 35, 37, 39, 59], "help": [11, 14, 17, 21, 24, 28, 32, 37, 39, 47, 49, 51, 108, 121, 159, 175, 180, 184], "feed": [11, 14, 17, 21, 24, 28, 32, 37, 39], "entir": [11, 14, 17, 21, 24, 28, 32, 37, 39, 108], "bool": [11, 14, 17, 21, 24, 28, 32, 37, 39, 50, 53, 55, 65, 71, 73, 78, 80, 81, 85, 86, 89, 90, 91, 94, 96, 101, 102, 106, 109, 110, 112, 115, 120, 121, 123, 125, 127, 128, 129, 134, 137, 142, 152, 159, 162, 165], "one": [11, 14, 17, 21, 24, 28, 30, 32, 37, 39, 42, 47, 49, 50, 52, 53, 64, 68, 69, 70, 76, 78, 81, 84, 89, 102, 112, 117, 139, 175, 179], "albertfortokenclassif": [12, 51], "recognit": [12, 15, 18, 22, 25, 29, 33, 38, 40, 45, 54, 87, 90, 91, 93], "ner": [12, 15, 18, 22, 25, 29, 33, 38, 40, 68, 69, 73, 74, 117, 134, 151, 152, 159, 162, 175], "token_classifi": [12, 18, 29, 33, 38, 40], "albert_base_token_classifier_conll03": 12, "albertembed": [12, 51], "level": [12, 19, 30, 34, 52, 53, 61, 62, 63, 65, 67, 69, 71, 90, 91, 96, 110, 152, 165], "tokenclassifi": [12, 15, 18, 22, 25, 29, 33, 38, 40], "john": [12, 15, 22, 25, 29, 33, 38, 40, 42, 53, 63, 69, 71, 73, 92, 94, 102, 129, 170], "lenon": [12, 15, 22, 25, 29, 33, 38, 40], "born": [12, 15, 22, 25, 29, 33, 38, 40, 106], "london": [12, 15, 22, 25, 29, 33, 38, 40], "pari": [12, 15, 22, 25, 29, 33, 38, 40, 93], "sarah": [12, 15, 22, 25, 29, 33, 38, 40], "o": [12, 15, 18, 22, 25, 29, 33, 38, 40, 89, 90, 91, 92, 134, 151, 162, 165, 169, 185], "bertforquestionansw": [13, 35], "bert_base_cased_qa_squad2": 13, "bertforsequenceclassif": 14, "bert_base_sequence_classifier_imdb": 14, "bertfortokenclassif": 15, "bert_base_token_classifier_conll03": 15, "camembertforquestionansw": 16, "camembert": [16, 17, 18, 54], "camembert_base_qa_fquad": 16, "fr": [16, 17, 54, 78], "camembertforsequenceclassif": 17, "sequence_classifi": 17, "camembert_base_sequence_classifier_allocin": 17, "j": [17, 71], "ai": [17, 159, 175], "ador\u00e9": 17, "ce": 17, "film": 17, "lorsqu": 17, "\u00e9tai": 17, "enfant": 17, "je": 17, "d\u00e9test": 17, "\u00e7a": 17, "camembertfortokenclassif": 18, "camembert_base_token_classifier_wikin": 18, "georg": 18, "washington": 18, "est": [18, 54, 78, 108], "all\u00e9": 18, "\u00e0": 18, "classifierdl": [19, 179], "classifierdlapproach": [19, 30, 179], "gener": [19, 30, 44, 51, 55, 57, 61, 64, 70, 73, 76, 90, 91, 93, 102, 106, 109, 110, 112, 113, 128, 129, 159, 175, 178, 179, 180], "univers": [19, 47, 49, 65, 108], "encod": [19, 50, 52, 53, 56, 61, 65, 93, 108, 159], "deep": [19, 52, 53, 59, 76, 90, 102, 110], "dnn": 19, "insid": [19, 30, 89, 99, 121, 165], "instanti": [19, 30, 34, 47, 49, 58, 66, 67, 71, 79, 80, 84, 85, 90, 91, 94, 99, 102, 104, 105, 110, 112, 113, 117, 119, 123, 165, 166], "classifierdlmodel": [19, 30, 179], "monitor": [19, 30, 34, 91, 159, 175], "metric": [19, 30, 34, 91, 113, 159], "done": [19, 30, 34, 62, 63, 90, 91, 180], "settestdataset": [19, 30, 34, 91, 96], "method": [19, 30, 34, 51, 57, 58, 66, 70, 76, 91, 163, 174], "expect": [19, 30, 34, 70, 91, 121, 151], "path": [19, 30, 34, 47, 49, 58, 66, 67, 71, 73, 79, 80, 84, 85, 90, 91, 93, 94, 96, 102, 104, 106, 110, 112, 113, 116, 121, 132, 134, 150, 159, 162, 165, 166, 168, 169, 175], "parquet": [19, 30, 34, 91, 96, 124], "datafram": [19, 30, 34, 45, 67, 91, 96, 99, 123, 134, 147, 151, 158, 159, 162, 165, 166, 168, 169, 175, 179, 183, 185], "ha": [19, 30, 34, 35, 44, 45, 50, 51, 56, 57, 59, 62, 63, 67, 76, 79, 84, 91, 96, 102, 104, 109, 112, 113, 123, 124, 125, 132, 134, 159, 163, 168, 175, 179, 180], "same": [19, 30, 34, 42, 51, 62, 67, 68, 71, 73, 91, 96, 109, 136, 159, 180], "follow": [19, 30, 34, 42, 46, 50, 59, 61, 67, 76, 81, 83, 84, 89, 91, 94, 101, 137, 138, 175, 177, 180], "universalsentenceencod": [19, 30, 34, 65, 159, 175, 179], "preprocessingpipelin": [19, 30, 34, 91, 96], "randomsplit": [19, 30, 34, 91, 96], "write": [19, 30, 34, 67, 91, 96, 112, 113, 180], "overwrit": [19, 30, 34, 91, 92, 96, 159], "test_data": [19, 30, 34, 91, 96], "setlabelcolumn": [19, 30, 34, 88, 90, 91, 95, 116, 159, 175, 179], "usag": [19, 30, 34, 42, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 65, 67, 68, 70, 71, 76, 78, 79, 81, 83, 84, 85, 90, 91, 94, 99, 101, 102, 104, 105, 108, 109, 110, 112, 114, 115, 119, 121, 123], "64": [19, 30, 34, 51, 91, 95, 179], "dropout": [19, 34, 91], "coeffici": [19, 34, 90, 91], "5": [19, 30, 34, 42, 44, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 78, 81, 83, 86, 89, 91, 99, 106, 123, 127, 134, 151, 159, 162, 166, 168, 169, 170, 175, 178, 179, 185], "enableoutputlog": [19, 30, 34, 91], "stdout": [19, 30, 34, 91, 96], "addit": [19, 30, 34, 47, 49, 52, 53, 71, 90, 91, 96, 101, 106, 121, 159, 178, 179], "evaluationlogextend": [19, 30, 34, 91], "valid": [19, 30, 34, 81, 91, 96, 102, 110, 175], "displai": [19, 30, 34, 96, 106, 159, 175], "time": [19, 30, 34, 51, 58, 66, 68, 69, 76, 81, 96, 105, 110, 123, 152, 178, 179, 183, 184], "labelcolumn": [19, 30, 34, 90, 91], "lr": [19, 30, 34, 91, 123], "rate": [19, 30, 34, 58, 62, 63, 66, 67, 91, 95, 110], "005": [19, 34, 91, 95], "maxepoch": [19, 30, 34, 90, 91], "maximum": [19, 30, 34, 42, 58, 66, 73, 76, 88, 90, 91, 94, 95, 101, 102, 106, 108, 109, 110, 112, 120, 121], "epoch": [19, 30, 34, 88, 90, 91, 95, 96, 102, 110, 159], "30": [19, 34, 76, 81, 83, 89, 95, 108, 134, 151, 162, 170, 178], "outputlogspath": [19, 30, 34, 91, 102], "randomse": [19, 30, 34, 90, 91], "random": [19, 30, 34, 58, 66, 88, 90, 91, 95, 127], "seed": [19, 30, 34, 58, 66, 88, 90, 91, 95], "shuffl": [19, 30, 88, 95], "testdataset": [19, 30, 34, 91, 159, 175], "statist": [19, 30, 34, 67, 76, 91, 96], "validationsplit": [19, 30, 34, 91, 102], "choos": [19, 30, 34, 55, 64, 91, 102, 112], "proport": [19, 30, 34, 91, 96, 102], "against": [19, 30, 34, 71, 76, 80, 85, 91, 96, 102, 136], "between": [19, 30, 34, 44, 47, 49, 62, 63, 65, 68, 69, 70, 73, 91, 96, 101, 102, 110], "off": [19, 30, 34, 65, 68, 69, 91, 96, 102], "verbos": [19, 30, 34, 90, 91, 96], "multiclassifierdlapproach": [19, 30, 159, 175], "sentimentdlapproach": [19, 30, 34], "accept": [19, 30, 34], "singl": [19, 30, 34, 67, 73, 76, 117, 119, 121, 165], "item": [19, 34, 67, 159, 165, 175], "doubl": [19, 34, 124, 137], "sentenceembed": [19, 30, 34, 64, 67, 127], "In": [19, 30, 34, 45, 54, 56, 57, 61, 67, 70, 71, 76, 78, 79, 80, 84, 85, 101, 102, 104, 106, 109, 112, 113, 123, 159, 168, 175, 179, 180, 184, 185], "csv": [19, 34, 71, 96, 137, 179], "best": [19, 34, 51, 54, 62, 63, 76, 78, 91, 179], "wach": [19, 179], "ever": [19, 34, 50, 179], "opinion": [19, 34, 179], "win": [19, 34, 179], "award": [19, 34, 179], "terribl": [19, 34, 179], "act": [19, 34, 179], "bad": [19, 34, 104, 159, 175, 179], "realli": [19, 34, 105, 179], "trane": 19, "smallcorpu": [19, 34, 179], "read": [19, 34, 44, 45, 47, 49, 58, 66, 76, 79, 80, 81, 83, 84, 85, 90, 93, 94, 96, 102, 104, 106, 110, 112, 113, 121, 123, 124, 126, 132, 135, 147, 150, 152, 153, 159, 163, 165, 166, 168, 169, 175, 179, 185], "header": [19, 34, 35, 137, 179], "src": [19, 34, 44, 45, 47, 49, 67, 79, 80, 84, 85, 90, 91, 99, 112, 113, 117, 123, 165, 166, 168, 169, 170, 179, 185], "useembed": [19, 30, 34, 65, 179], "docclassifi": [19, 30, 34, 179], "setbatchs": [19, 30, 34, 59, 91, 95, 110, 159, 175, 179], "setmaxepoch": [19, 30, 34, 88, 90, 91, 95, 159, 175, 179], "20": [19, 35, 70, 89, 106, 134, 137, 151, 162, 179], "setlr": [19, 30, 34, 91, 95, 159, 175, 179], "5e": [19, 34, 179], "setdropout": [19, 34, 91, 179], "pipelinemodel": [19, 30, 34, 47, 49, 50, 58, 66, 90, 91, 105, 110, 112, 113, 123, 134, 136, 159, 163, 179, 182], "v": [19, 30, 34, 56, 67, 76, 78, 80, 91, 95, 96, 113, 151], "classifierdl_use_trec6": [19, 179], "trec": 19, "multiclassifierdlmodel": [19, 30], "sentimentdlmodel": [19, 30, 34], "sarcasmdl": [19, 179], "classifierdl_use_sarcasm": [19, 179], "sarcasm": [19, 179], "m": [19, 81, 83, 170, 179], "could": [19, 57, 76, 84, 96, 110, 178, 179, 180], "put": [19, 151, 179], "word": [19, 44, 45, 47, 49, 51, 55, 56, 58, 59, 62, 64, 65, 66, 67, 70, 71, 73, 76, 79, 86, 89, 92, 93, 94, 99, 104, 106, 108, 109, 110, 112, 113, 114, 115, 119, 121, 122, 123, 134, 151, 162, 168, 169, 178, 179], "much": [19, 35, 51, 62, 63, 94, 123, 152, 179], "wake": [19, 179], "am": [19, 81, 83, 106, 117, 179], "mondai": [19, 179], "would": [19, 42, 55, 64, 81, 102, 152, 179], "arrays_zip": [19, 47, 49, 76, 179], "out": [19, 76, 79, 94, 106, 108, 109, 114, 115, 179], "normal": [19, 50, 74, 80, 102, 105, 115, 127, 136, 139, 152, 179, 180], "debertaforquestionansw": 20, "deberta": [20, 21, 22, 56], "deberta_v3_xsmall_qa_squad2": 20, "debertaforsequenceclassif": 21, "v2": [21, 22, 52, 53, 56], "v3": [21, 22], "deberta_v3_xsmall_sequence_classifier_imdb": 21, "deberta_base_sequence_classifier_imdb": 21, "debertafortokenclassif": 22, "deberta_v3_xsmall_token_classifier_conll03": 22, "distilbertforquestionansw": 23, "distilbert": [23, 24, 57], "distilbert_base_cased_qa_squad2": 23, "distilbertforsequenceclassif": 24, "distilbert_base_sequence_classifier_imdb": 24, "distilbertfortokenclassif": 25, "distilbert_base_token_classifier_conll03": 25, "albert_for_sequence_classif": [26, 74], "albert_for_token_classif": [26, 74], "bert_for_sequence_classif": [26, 74], "bert_for_token_classif": [26, 74], "camembert_for_sequence_classif": [26, 74], "camembert_for_token_classif": [26, 74], "deberta_for_sequence_classif": [26, 74], "deberta_for_token_classif": [26, 74], "distil_bert_for_sequence_classif": [26, 74], "distil_bert_for_token_classif": [26, 74], "longformer_for_sequence_classif": [26, 74], "longformer_for_token_classif": [26, 74], "multi_classifier_dl": [26, 74], "roberta_for_sequence_classif": [26, 74], "roberta_for_token_classif": [26, 74], "sentiment_dl": [26, 74], "xlm_roberta_for_sequence_classif": [26, 74], "xlm_roberta_for_token_classif": [26, 74], "xlnet_for_sequence_classif": [26, 74], "xlnet_for_token_classif": [26, 74], "longformerforquestionansw": 27, "longform": [27, 28, 29, 61], "longformer_base_base_qa_squad2": 27, "longformerforsequenceclassif": 28, "longformer_base_sequence_classifier_imdb": 28, "4096": [28, 51, 61], "longformerfortokenclassif": 29, "xlnet_base_token_classifier_conll03": [29, 40], "longformer_base_token_classifier_conll03": 29, "multiclassifierdl": 30, "bidirect": [30, 52, 53, 59, 70], "gru": 30, "convolut": [30, 45], "machin": [30, 58, 66, 76, 90, 106, 108, 109, 159, 177], "strongli": 30, "relat": [30, 47, 49, 73, 184], "variant": [30, 46, 61, 65], "mai": [30, 125, 178, 179, 180, 183, 184], "instanc": [30, 93, 95, 96, 142, 146, 152, 153, 157], "multiclass": 30, "categor": [30, 163], "precis": [30, 47, 49], "constraint": 30, "mani": [30, 56, 62, 63, 76, 106, 108, 109, 123], "formal": 30, "find": [30, 47, 49, 62, 63, 65, 71, 73, 79, 81, 106], "binari": [30, 132, 147, 159], "bertsentenceembed": [30, 34, 53, 63, 69], "multiclassifi": [30, 159, 175], "001": [30, 90, 91], "10": [30, 42, 47, 76, 81, 83, 92, 112, 159, 170, 178], "44": [30, 58, 66, 99], "shuffleperepoch": 30, "threshold": [30, 34, 58, 66, 76, 78, 90, 93, 110, 123], "minimum": [30, 34, 58, 66, 73, 76, 78, 88, 90, 91, 94, 101, 102, 106, 109, 112, 113, 120, 121, 165], "ed58abb40640f983": 30, "pn": 30, "newsyou": 30, "toxic": 30, "a1237f726b5f5d89": 30, "dude": 30, "place": [30, 45], "obscen": 30, "insult": 30, "24b0d6c8733c2abe": 30, "thank": [30, 70, 76, 170], "8c4478fb239bcfc0": 30, "gee": 30, "minut": 30, "traindataset": [30, 159, 175], "printschema": [30, 124, 126, 132, 135], "root": [30, 42, 47, 49, 73, 124, 126, 132, 135, 166], "setcleanupmod": [30, 126, 135], "shrink": [30, 126, 135], "1e": [30, 159, 175], "setthreshold": [30, 34, 76, 78, 159, 175], "setvalidationsplit": [30, 96, 102], "setverbos": [30, 90, 91, 96], "multiclassifierdl_use_tox": 30, "comment": [30, 76], "jigsaw": 30, "good": [30, 54, 57, 65, 105], "stuff": 30, "wtf": 30, "kind": [30, 76, 81, 83], "crap": 30, "robertaforquestionansw": [31, 93], "roberta": [31, 32, 33, 36, 37, 38, 54, 56, 61, 62, 63, 68, 69, 93], "roberta_base_qa_squad2": [31, 93], "robertaforsequenceclassif": 32, "roberta_base_sequence_classifier_imdb": 32, "robertafortokenclassif": 33, "roberta_base_token_classifier_conll03": 33, "sentimentdl": 34, "natur": [34, 45, 51, 52, 53, 54, 56, 57, 58, 65, 66, 70, 78, 106, 109, 125, 135, 139], "affect": [34, 121], "subject": [34, 47, 49], "view": 34, "common": [34, 71, 117, 125, 152, 182], "product": 34, "review": [34, 155], "tweet": 34, "interpret": [34, 71], "posit": [34, 56, 57, 68, 69, 70, 76, 89, 104, 105, 120, 123, 139, 159, 175], "final": [34, 61, 62, 63, 68, 69, 78, 91, 110, 179], "otheriws": [34, 78], "neutral": [34, 78], "thresholdlabel": [34, 78], "score": [34, 52, 53, 68, 69, 76, 78, 90, 91, 93, 104, 105, 106], "less": [34, 57, 78, 86, 90, 112], "watch": [34, 105], "32": [34, 51, 59, 170, 178, 184], "setthresholdlabel": [34, 78], "p": [34, 50, 58, 66, 78, 91, 96, 119], "sentimentdl_use_imdb": 34, "english": [34, 54, 76, 112, 115, 123, 163], "imdb": 34, "sentimentdl_use_twitt": 34, "wow": 34, "video": [34, 76], "awesom": 34, "bruh": 34, "damn": 34, "wast": [34, 105], "tapasforquestionansw": 35, "implement": [35, 58, 66, 68, 93, 102, 110, 130, 131, 140, 141, 148, 154, 158], "tapa": 35, "design": [35, 44, 46, 52, 53, 62, 63, 80, 108, 159, 175], "about": [35, 47, 49, 62, 63, 67, 76, 93, 101, 113, 134, 136, 178, 180, 183, 184], "tabular": [35, 137], "tabl": [35, 137], "tri": 35, "share": [35, 76, 180], "its": [35, 45, 56, 57, 61, 70, 76, 99, 104, 108, 115, 159, 168], "table_qa_tapas_base_finetuned_wtq": 35, "document_assembl": [35, 93, 133, 137, 152], "table_json": 35, "document_t": [35, 137], "sentence_detector": [35, 74, 93, 100], "table_assembl": [35, 133, 152], "tableassembl": [35, 137], "stage": [35, 134, 136, 159, 175, 179, 180, 183], "json_data": 35, "monei": [35, 137], "ag": [35, 137], "donald": [35, 137], "trump": [35, 137], "000": [35, 76, 106, 123, 137], "75": [35, 76, 137], "elon": [35, 137], "musk": [35, 137], "55": [35, 92, 137, 170], "AS": [35, 42, 93], "who": [35, 119, 179], "earn": 35, "thei": [35, 47, 49, 91, 94, 106, 136, 154, 166, 179], "count": [35, 110], "old": [35, 42, 168], "xlmrobertaforquestionansw": 36, "xlm": [36, 37, 38, 68, 69], "xlm_roberta_base_qa_squad2": 36, "xlmrobertaforsequenceclassif": 37, "xlm_roberta_base_sequence_classifier_imdb": 37, "xlmrobertafortokenclassif": 38, "xlm_roberta_base_token_classifier_conll03": 38, "xlnetforsequenceclassif": 39, "xlnet": [39, 40, 70], "xlnet_base_sequence_classifier_imdb": 39, "xlnetfortokenclassif": 40, "spanbert_coref": 41, "spanbertcorefmodel": 42, "corefer": 42, "resolut": [42, 44], "spanbert": 42, "identifi": [42, 67, 76, 80, 84, 120, 121, 159, 180], "given": [42, 71, 76, 93, 106, 109, 110, 112, 113, 115, 158, 159], "told": [42, 83], "mari": [42, 53, 63, 69, 102], "he": [42, 56, 83, 119, 170], "borrow": 42, "book": [42, 50, 106, 110, 166], "her": [42, 93], "link": [42, 162], "ontonot": 42, "corefresolut": 42, "spanbert_base_coref": 42, "maxsegmentlength": 42, "textgenr": 42, "genr": 42, "One": [42, 76, 119, 138], "bc": 42, "broadcast": 42, "convers": 42, "bn": 42, "nw": 42, "wire": 42, "pt": 42, "pivot": 42, "testament": 42, "tc": 42, "telephon": 42, "wb": 42, "web": [42, 50, 54, 106, 159, 175], "setmaxsegmentlength": 42, "settextgenr": 42, "code": [42, 56, 58, 61, 62, 63, 66, 68, 69, 76, 78, 109, 176, 184], "swin_for_image_classif": 43, "vit_for_image_classif": 43, "swinforimageclassif": 44, "swinimageclassif": 44, "swin": 44, "hierarch": [44, 58, 66], "vision": [44, 45], "shift": 44, "window": [44, 58, 61, 66, 76, 91, 110], "ze": 44, "liu": [44, 56, 62, 63], "yutong": 44, "lin": 44, "yue": 44, "cao": 44, "han": 44, "hu": 44, "yixuan": 44, "zheng": 44, "zhang": 44, "stephen": 44, "bain": 44, "guo": 44, "whose": 44, "scheme": [44, 62], "bring": [44, 179], "greater": [44, 76], "effici": [44, 56, 58, 65, 66, 108, 178], "attent": [44, 45, 56, 61], "non": [44, 121, 123], "overlap": [44, 80, 85], "while": [44, 45, 51, 57, 67, 76, 96, 106, 159, 175, 180], "cross": [44, 68, 69, 92], "connect": 44, "imageclassifi": [44, 45], "image_assembl": [44, 45, 133, 152], "image_classifier_swin_base_patch4_window7_224": 44, "huggingfac": [44, 45, 54], "swinforimageclassificationtest": 44, "present": [44, 51, 59, 61, 62, 63, 65, 68, 69, 73, 96, 102, 108], "call": [44, 52, 53, 57, 71, 76, 106, 158, 163, 165, 179, 185], "capabl": [44, 57, 70, 106], "serv": [44, 176], "purpos": [44, 57, 102], "backbon": [44, 70], "adapt": 44, "aris": 44, "domain": [44, 76, 106], "variat": 44, "scale": [44, 45, 51, 57, 61, 68, 69, 106, 109], "visual": [44, 159], "high": [44, 65, 68, 69, 108], "compar": [44, 45, 51, 56, 57, 59, 70, 76, 102, 109, 110, 159, 175], "architectur": [44, 45, 51, 52, 53, 56, 62, 78, 91, 102, 109], "flexibl": 44, "variou": [44, 70, 173], "complex": [44, 59, 65, 76, 112, 113], "respect": [44, 56, 67, 90, 91, 168], "These": [44, 51, 62, 63, 70, 76, 90, 106, 162, 177], "broad": [44, 106], "rang": [44, 52, 53, 56, 57, 68, 69], "87": 44, "accuraci": [44, 47, 49, 52, 53, 58, 65, 66, 68, 69, 90, 91, 99, 112, 123, 175], "imagenet": [44, 45], "1k": 44, "dens": [44, 52, 53], "detect": [44, 65, 77, 78, 100, 101, 102], "box": 44, "ap": 44, "51": [44, 126, 135, 168], "coco": 44, "semant": [44, 59, 65, 123], "53": [44, 80, 85], "miou": 44, "ade20k": 44, "val": 44, "Its": [44, 49, 93], "surpass": [44, 56], "previou": [44, 68, 69, 106, 179], "margin": [44, 70], "demonstr": [44, 57, 61, 76, 106, 108], "potenti": [44, 110], "prove": 44, "benefici": [44, 76], "mlp": 44, "imagedf": [44, 45], "dropinvalid": [44, 45], "imageassembl": [44, 45, 132], "pipelinedf": [44, 45], "revers": [44, 45], "split": [44, 45, 101, 102, 117, 119, 120, 123], "image_nam": [44, 45], "palac": [44, 45], "jpeg": [44, 45], "egyptian_cat": [44, 45], "tabbi": 44, "cat": [44, 45], "hippopotamu": [44, 45], "hippo": [44, 45], "river": [44, 45], "hors": [44, 45], "amphibiu": [44, 45], "hen": [44, 45], "ostrich": [44, 45], "struthio": [44, 45], "camelu": [44, 45], "junco": [44, 45], "snowbird": [44, 45], "bluetick": [44, 45], "jpg": [44, 45], "chihuahua": [44, 45], "tractor": [44, 45], "ox": [44, 45], "setdorescal": 44, "rescal": 44, "rescalefactor": 44, "boolean": 44, "setrescalefactor": 44, "factor": [44, 68, 69, 70, 109, 110], "255": 44, "vitforimageclassif": 45, "vit": 45, "altern": [45, 76, 104, 110, 112, 113, 134, 137, 179, 184], "neural": [45, 52, 53, 56, 91, 102, 108], "network": [45, 52, 53, 59, 91, 102], "usual": [45, 139, 163], "image_classifier_vit_base_patch16_224": 45, "vitimageclassificationtestspec": 45, "becom": [45, 51, 57, 76], "de": [45, 54, 76, 78, 108], "facto": [45, 76], "standard": [45, 50, 61, 81, 83, 112, 113, 121], "remain": [45, 50, 51, 57, 76], "conjunct": 45, "replac": [45, 50, 56, 61, 78, 79, 92, 102, 112, 113, 179], "certain": [45, 110], "compon": [45, 95, 96, 124, 132, 142, 146, 157, 183], "keep": [45, 76, 94, 106, 109], "overal": [45, 67, 70], "structur": [45, 93, 139, 178], "relianc": 45, "cnn": [45, 78, 91, 102], "necessari": [45, 57, 175, 182], "pure": [45, 108], "directli": [45, 134, 159, 163, 175], "patch": 45, "veri": [45, 54, 59, 68, 69, 70, 106, 108, 109, 134, 178, 180, 183, 184], "well": [45, 47, 49, 65, 68, 69, 76, 137], "amount": [45, 65, 76, 85, 106, 123, 134, 183], "transfer": [45, 57, 65, 68, 69, 106, 109], "mid": 45, "small": [45, 50, 51, 54, 57, 58, 66, 79, 99, 134, 168, 183], "cifar": 45, "vtab": 45, "etc": [45, 55, 127, 139, 175], "attain": 45, "excel": [45, 70], "substanti": [45, 52, 53], "fewer": [45, 51], "worth": 45, "16x16": 45, "egyptian": 45, "date2chunk": 46, "datematch": [46, 81], "multidatematch": [46, 81, 83], "date_chunk": 46, "omicron": 46, "covid": 46, "world": [46, 50, 117, 159, 170, 175], "health": 46, "organ": [46, 76, 108], "nov": [46, 81, 83, 168], "26": [46, 89, 134, 151, 162, 170], "2021": [46, 81, 83], "118": [46, 137], "121": 46, "01": [46, 81, 83, 84], "dependencypars": [47, 49, 73], "dependencyparserapproach": [47, 166, 185], "unlabel": [47, 52, 53, 106, 109], "grammat": [47, 49], "dependencyparsermodel": [47, 49, 73], "relationship": [47, 49, 65, 73], "tell": [47, 49, 76, 151], "verb": [47, 49, 166], "modifi": [47, 49, 62, 63, 89, 102], "describ": [47, 49, 73, 76, 108], "wai": [47, 49, 71, 73, 136, 162], "chosen": [47, 49, 91], "particular": [47, 49, 76, 163, 179], "treebank": 47, "penn": 47, "setdependencytreebank": 47, "conll": [47, 49, 90, 91, 152, 166, 167, 182], "u": [47, 49, 56, 57, 76, 83, 89, 90, 91, 134, 151, 162, 166, 177, 180, 185], "setconllu": [47, 49], "dependencytreebank": 47, "conllu": [47, 49, 79, 152, 167, 182], "numberofiter": [47, 49], "converg": [47, 49, 99, 123], "better": [47, 49, 51, 56, 70, 76, 90, 99, 101, 102, 105, 123], "typeddependencyparserapproach": [47, 49], "postagg": [47, 49, 73, 90, 99], "dependency_treebank": 47, "emptydataset": [47, 49], "tree": [47, 73], "bank": 47, "setnumberofiter": [47, 49], "read_a": [47, 49, 71, 79, 80, 84, 85, 90, 94, 96, 104, 112, 113, 121, 145, 150, 152, 165, 166], "reada": [47, 49, 67, 71, 79, 80, 84, 85, 90, 94, 96, 104, 112, 113, 117, 121, 147, 150, 165, 166], "dep": 47, "dependency_conllu": [47, 73], "perceptron": [47, 74, 98], "featur": [47, 58, 66, 76, 86, 90, 96, 159, 182], "typeddependencyparsermdoel": 47, "union": [47, 49], "worker": [47, 49], "turner": [47, 49], "newal": [47, 49], "sai": [47, 49, 76, 121], "disappoint": [47, 49], "talk": [47, 49], "stricken": [47, 49], "parent": [47, 49], "firm": [47, 49], "feder": [47, 49], "mogul": [47, 49], "dependency_pars": [48, 74, 163, 184], "typed_dependency_pars": [48, 74], "typeddependencypars": [49, 73], "conll2009": 49, "typeddependencyparsermodel": [49, 73], "beforehand": 49, "2009": 49, "setconll2009": 49, "dependency_typ": [49, 73], "train_smal": 49, "txt": [49, 58, 66, 67, 79, 80, 84, 85, 99, 102, 104, 110, 112, 113, 117, 121, 168, 169, 185], "descript": [49, 64, 76, 81, 112, 119, 147], "typdep": 49, "dependency_typed_conllu": [49, 73], "amod": 49, "flat": [49, 73, 129], "nsubj": [49, 73, 129, 166], "parataxi": 49, "documentnorm": 50, "raw": [50, 106, 119, 121, 123, 178, 180], "scrape": 50, "xml": 50, "remov": [50, 62, 63, 94, 105, 120, 127, 128, 129], "dirti": [50, 94], "regex": [50, 71, 81, 84, 94, 110, 112, 113, 120, 121, 123], "want": [50, 71, 92, 163, 180], "polici": 50, "lower": [50, 51, 76, 110, 125], "__": [50, 127, 128], "action": 50, "clean": [50, 94, 109, 139, 180], "lowercas": [50, 94, 120, 123, 125], "pretty_al": 50, "utf": 50, "cleanuppattern": [50, 94], "normalizeddocu": 50, "setact": 50, "setpattern": [50, 120, 123], "setreplac": 50, "setpolici": 50, "setlowercas": [50, 94, 125, 139], "div": 50, "theworldsgreatest": 50, "right": [50, 52, 53, 123], "hide": 50, "wide": [50, 52, 53, 56, 57, 68, 69], "toptext": 50, "style": [50, 78, 109], "font": 50, "famili": 50, "sego": 50, "ui": 50, "arial": 50, "san": [50, 76], "serif": 50, "largest": [50, 76, 106], "develop": [50, 76, 108, 156], "site": [50, 76], "h1": 50, "300": 50, "160": 50, "lorem": [50, 80, 85], "ipsum": [50, 80, 85], "simpli": [50, 180], "print": [50, 152, 163], "typeset": 50, "industri": 50, "been": [50, 54, 106, 138, 139, 163], "sinc": [50, 76, 106, 179, 180, 184], "1500": 50, "unknown": [50, 78], "printer": 50, "took": 50, "gallei": 50, "scrambl": 50, "specimen": 50, "surviv": 50, "five": [50, 92], "centuri": [50, 123], "leap": 50, "electron": 50, "essenti": [50, 106], "unchang": 50, "popularis": 50, "1960": 50, "releas": [50, 51, 54, 56, 62, 63, 68, 69, 109, 152], "letraset": 50, "passag": 50, "recent": [50, 52, 53, 56, 62, 63, 76], "desktop": 50, "publish": [50, 62, 63], "softwar": 50, "aldu": 50, "pagemak": 50, "setencod": 50, "lite": 51, "googl": [51, 52, 53, 56, 58, 59, 62, 63, 65, 66, 76, 109, 166], "research": [51, 52, 53, 56, 58, 66, 108, 109], "toyota": 51, "technolog": 51, "institut": 51, "chicago": 51, "offici": [51, 76, 89, 90, 91, 134, 151, 162, 176], "tf": [51, 65], "wrapper": [51, 155], "port": 51, "properti": [51, 130, 131, 142, 145, 152], "albert_base_uncas": 51, "albert_bas": 51, "768": [51, 52, 53, 54, 56, 57, 61, 62, 63, 68, 69, 70], "emb": 51, "dim": 51, "12m": 51, "albert_large_uncas": 51, "albert_larg": 51, "1024": [51, 59, 61, 70], "24": [51, 70, 80, 85, 89, 110, 134, 151, 162, 178], "16": [51, 70, 92, 168, 178], "18m": 51, "albert_xlarge_uncas": 51, "albert_xlarg": 51, "2048": 51, "60m": 51, "albert_xxlarge_uncas": 51, "albert_xxlarg": 51, "235m": 51, "sentencepiec": [51, 56, 65], "everi": [51, 52, 53, 54, 56, 57, 61, 62, 63, 68, 69, 70, 91, 105, 108, 110, 126, 135, 136, 180], "dimens": [51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 146], "repeat": 51, "footprint": 51, "howev": [51, 64, 70, 76, 94, 163, 178], "cost": [51, 110, 112], "similar": [51, 65, 76, 78], "through": [51, 73, 76, 129, 180], "FOR": 51, "http": [51, 54, 56, 58, 59, 65, 66, 123, 176], "tfhub": [51, 59, 65], "q": 51, "increas": [51, 67, 76, 106, 112], "often": [51, 62, 63, 70], "downstream": [51, 54, 56, 59, 61, 70, 106, 109], "some": [51, 53, 68, 76, 91, 102, 106, 136, 159, 170, 178, 179, 183, 184], "point": [51, 52, 53, 101, 102, 126, 135, 165], "harder": 51, "gpu": [51, 106, 108, 109, 152], "tpu": 51, "longer": [51, 58, 61, 66, 78, 184], "techniqu": [51, 56, 106, 109], "consumpt": [51, 65, 67], "speed": [51, 90, 108], "devlin": [51, 62, 63], "et": [51, 62, 63, 78], "al": [51, 62, 63], "2019": [51, 54, 56, 62, 63, 68, 69], "comprehens": [51, 106], "empir": [51, 52, 53, 68, 69, 70], "evid": 51, "lead": [51, 54, 68, 69], "focus": [51, 76], "inter": 51, "coher": [51, 106], "As": [51, 52, 53, 57, 76], "establish": 51, "glue": [51, 52, 53, 57, 62, 63, 68, 69], "race": [51, 56, 62, 63], "embeddingsfinish": [51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 127], "finished_embed": [51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "setoutputasvector": [51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 127], "setcleanannot": [51, 56, 57, 59, 61, 62, 64, 65, 67, 68, 70, 127, 128, 129], "80": [51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 84, 127, 139], "1342473030090332": [51, 56], "3855540752410889": [51, 56], "9818322062492371": [51, 56], "784737348556518": [51, 56], "847029983997345": [51, 56], "047153353691101": [51, 56], "1520637571811676": [51, 56], "6245765686035156": [51, 56], "009860038757324219": [51, 56], "13450059294700623": [51, 56], "707749128341675": [51, 56], "2916892766952": [51, 56], "04192575812339783": [51, 56], "5764210224151611": [51, 56], "3196685314178467": [51, 56], "527840495109": [51, 56], "15583214163780212": [51, 56], "1614152491092682": [51, 56], "28423872590065": [51, 56], "135491415858268": [51, 56], "bertembed": [52, 55, 64, 91, 127], "small_bert_l2_768": 52, "understand": [52, 53, 57, 68, 70, 76, 109, 123, 178], "introduc": [52, 53, 57, 59, 61, 109], "stand": [52, 53], "unlik": [52, 53, 68, 76, 119], "jointli": [52, 53], "condit": [52, 53, 106, 109], "both": [52, 53, 59, 65, 73, 179, 180], "left": [52, 53, 123], "just": [52, 53, 57, 62, 86, 91], "infer": [52, 53, 54, 57, 70], "without": [52, 53, 68, 69, 76, 106, 123], "modif": [52, 53], "conceptu": [52, 53], "power": [52, 53, 109], "obtain": [52, 53, 54, 65], "eleven": [52, 53], "push": [52, 53], "absolut": [52, 53], "multinli": [52, 53], "86": [52, 53, 56], "v1": [52, 53], "f1": [52, 53, 68, 69, 91, 106], "93": [52, 53], "83": [52, 53, 56, 168, 169, 185], "small_bert_l2_128": 52, "3497989177703857": 52, "480538547039032": 52, "3238905668258667": 52, "612930893898010": 52, "1357314586639404": 52, "32984697818756104": 52, "6032363176345825": 52, "6791689395904": 52, "8244884014129639": 52, "27088963985443115": 52, "059438943862915": 52, "9817547798156": 52, "1648050546646118": 52, "4725411534309387": 52, "5938255786895752": 52, "5780693292617": 52, "9125322699546814": 52, "4563939869403839": 52, "3975459933280945": 52, "81611204147338": 52, "sentence_bert_embed": 53, "sent_small_bert_l2_768": 53, "islong": 53, "long": [53, 61, 70], "sent_small_bert_l2_128": 53, "orang": [53, 63, 69], "8951074481010437": [53, 63, 69], "13753940165042877": [53, 63, 69], "3108254075050354": [53, 63, 69], "65693199634552": [53, 63, 69], "6180210709571838": [53, 63, 69], "12179657071828842": [53, 63, 69], "191165953874588": [53, 63, 69], "4497021436691": [53, 63, 69], "822715163230896": [53, 63, 69], "7568016648292542": [53, 63, 69], "1165061742067337": [53, 63, 69], "59048593044281": [53, 63, 69], "setislong": 53, "camembertembed": 54, "tasti": 54, "french": [54, 76, 108, 115], "loui": 54, "martin": 54, "muller": 54, "pedro": 54, "javier": 54, "ortiz": 54, "su\u00e1rez": 54, "yoann": 54, "dupont": 54, "laurent": 54, "romari": 54, "\u00e9ric": 54, "villemont": 54, "la": [54, 108], "clergeri": 54, "djam\u00e9": 54, "seddah": 54, "beno\u00eet": 54, "sagot": 54, "facebook": [54, 56, 68, 69], "138gb": 54, "camembert_bas": 54, "camembertembeddingstestspec": 54, "co": [54, 76], "ubiquit": 54, "despit": 54, "most": [54, 57, 61, 76, 91, 106, 108, 109], "concaten": [54, 123], "practic": [54, 109], "except": [54, 86, 91, 121], "investig": [54, 57, 65], "feasibl": 54, "monolingu": [54, 68, 69], "crawl": [54, 109], "prefer": [54, 73, 129], "wikipedia": [54, 78, 106], "surprisingli": [54, 65], "4gb": 54, "those": [54, 73, 92, 179, 180], "larger": [54, 57, 62, 63, 106, 108, 109], "130": 54, "gb": 54, "reach": [54, 76, 106, 123], "four": [54, 102, 123, 138], "un": [54, 78], "08442357927560806": 54, "12863239645957947": 54, "03835778683423996": 54, "200479581952": 54, "048462312668561935": 54, "12637358903884888": 54, "27429091930389404": 54, "07516729831": 54, "02690504491329193": 54, "12104076147079468": 54, "012526623904705048": 54, "031543646007": 54, "05877285450696945": 54, "08773420006036758": 54, "06381352990865707": 54, "122621834278": 54, "chunkembed": [55, 127], "wordembed": [55, 64, 67, 91, 127, 152], "chunker": [55, 74, 152], "ngramgener": [55, 86], "nerconvert": [55, 89, 90, 91, 159, 175], "poolingstrategi": [55, 64], "aggreg": [55, 64], "sum": [55, 59, 64], "skipoov": 55, "discard": [55, 93], "oov": 55, "ngram": [55, 86, 106, 109], "setn": [55, 86], "wordembeddingsmodel": [55, 64, 67, 73, 90, 91, 92, 127], "setpoolingstrategi": [55, 64], "55661": 55, "42829502": 55, "86661": 55, "409785": 55, "06316501": 55, "120775": 55, "0732005": 55, "40674996": 55, "22938299": 55, "50597": 55, "288195": 55, "555655": 55, "465145": 55, "140118": 55, "17417": 55, "095253006": 55, "0530925": 55, "218465": 55, "714395": 55, "79860497": 55, "0129999": 55, "139705": 55, "177955": 55, "1887775": 55, "45545": 55, "20030999": 55, "461557": 55, "07891501": 55, "strategi": [55, 64, 84, 101, 110], "setskipoov": 55, "debertaembed": 56, "decod": [56, 61, 106, 108, 109], "enhanc": [56, 105], "disentangl": 56, "pengcheng": 56, "xiaodong": 56, "jianfeng": 56, "gao": 56, "weizhu": 56, "chen": [56, 62, 63], "2018": [56, 62, 63], "half": [56, 76], "deberta_v3_bas": 56, "microsoft": [56, 108], "www": 56, "blog": 56, "human": [56, 76], "superglu": 56, "progress": [56, 102, 120], "significantli": [56, 59, 62, 63, 68, 69, 76], "novel": [56, 70, 76], "mechan": [56, 61], "weight": [56, 59, 76, 90, 92, 110], "among": 56, "matric": 56, "second": [56, 59, 84, 101, 115, 120, 179], "achiev": [56, 61, 62, 63, 68, 69, 70, 91, 106, 108, 109, 134, 183], "mnli": 56, "9": [56, 68, 69, 86, 178, 183, 184], "90": 56, "91": 56, "88": 56, "made": [56, 65, 175], "publicli": [56, 68, 69], "distilbertembed": 57, "fast": [57, 105, 108, 134, 183], "cheap": 57, "distil": 57, "40": [57, 92, 108], "uncas": 57, "preserv": [57, 89, 120, 139], "95": 57, "measur": [57, 62, 63, 159], "distilbert_base_cas": 57, "doesn": [57, 62], "token_type_id": [57, 62], "don": [57, 62, 94], "indic": [57, 62, 120, 123], "belong": [57, 62], "separ": [57, 62, 84, 86, 101, 102, 112, 121, 123, 128, 151, 165, 177], "sep_token": [57, 62], "sep": 57, "position_id": 57, "ad": [57, 59, 110], "though": [57, 76], "know": [57, 108, 136], "smaller": [57, 58, 66], "cheaper": 57, "lighter": 57, "preval": 57, "oper": [57, 61, 110, 119, 178], "edg": [57, 73], "constrain": 57, "budget": 57, "counterpart": 57, "prior": [57, 61, 110], "leverag": [57, 159, 175], "reduc": [57, 112, 113, 139], "retain": 57, "97": [57, 81, 83, 123], "being": [57, 91, 96, 108, 109], "induct": 57, "bias": 57, "tripl": [57, 73], "cosin": 57, "distanc": [57, 110, 112, 113], "devic": 57, "proof": 57, "concept": [57, 180], "experi": [57, 70, 159, 176], "studi": [57, 62, 63, 109], "1127224713563919": 57, "1982710212469101": 57, "5360898375511169": 57, "272536993026733": 57, "35534414649009705": 57, "13215228915214539": 57, "40981462597846985": 57, "14036104083061": 57, "328085333108902": 57, "06269335001707077": 57, "017595693469047546": 57, "024373905733": 57, "15617232024669647": 57, "2967822253704071": 57, "22324979305267334": 57, "04568954557180": 57, "45411425828933716": 57, "01173491682857275": 57, "190129816532135": 57, "1178255230188369": 57, "doc2vecapproach": 58, "word2vec": [58, 60, 74], "corpu": [58, 59, 66, 76, 79, 99, 109, 110, 168, 185], "algorithm": [58, 66, 76, 90, 105, 110, 112, 113], "construct": [58, 66, 121, 162, 182], "vocabulari": [58, 66, 106, 109, 110], "skip": [58, 66, 73, 110], "gram": [58, 66, 76, 86, 106, 109], "doc2vecmodel": 58, "vectors": [58, 66], "windows": [58, 66, 76], "numpartit": [58, 66], "partit": [58, 66, 165], "mincount": [58, 66, 110], "must": [58, 66, 79, 80, 84, 85, 96, 104, 105, 112, 113, 125, 151, 152, 159, 165], "appear": [58, 66, 110], "ani": [58, 65, 66, 71, 76, 91, 106, 109, 110, 127, 128, 163, 176, 179, 180, 185], "divid": [58, 66], "1000": [58, 66, 73, 90], "stepsiz": [58, 66], "optim": [58, 62, 63, 66, 91, 93, 102], "025": [58, 66], "maxit": [58, 66], "estim": [58, 66, 116, 130, 140, 148, 158, 179], "space": [58, 66, 67, 86, 139], "distribut": [58, 66], "composition": [58, 66], "sherlockholm": [58, 66, 110, 185], "setvectors": [58, 66], "setwindows": [58, 66, 76], "setsteps": [58, 66], "initi": [58, 66, 110, 120, 136, 152, 165, 166, 168, 169, 175], "setnumpartit": [58, 66], "setmaxit": [58, 66], "numiter": [58, 66], "equal": [58, 66], "setse": [58, 66], "setmincount": [58, 66, 110], "doc2vec_gigaword_300": 58, "06222493574023247": [58, 66], "011579325422644615": [58, 66], "009919632226228714": [58, 66], "109361454844": [58, 66], "doc2vec_wiki": 58, "elmoembed": 59, "elmo": 59, "billion": [59, 106], "computation": [59, 62, 63, 70, 106, 108, 109], "expens": [59, 62, 63, 70, 104, 106, 108, 109, 112], "lookup": [59, 67, 70, 80, 112, 113], "acceler": [59, 70, 106, 108, 109, 152], "setpoolinglay": 59, "word_emb": 59, "shape": 59, "batch_siz": 59, "max_length": 59, "lstm_outputs1": 59, "lstm": [59, 91], "lstm_outputs2": 59, "trainabl": 59, "tensor": 59, "poolinglay": 59, "contextu": [59, 110], "characterist": 59, "syntax": 59, "vari": 59, "across": [59, 106], "linguist": [59, 123], "polysemi": 59, "intern": [59, 95, 96, 110, 121, 123, 137, 142, 146, 152], "bilm": 59, "exist": [59, 110, 127, 129, 159], "six": [59, 112, 113], "textual": 59, "entail": 59, "expos": 59, "crucial": 59, "mix": [59, 141, 158], "semi": 59, "signal": 59, "662458181381226e": 59, "2541114091873169": 59, "6275503039360046": 59, "5787073969841": 59, "19154725968837738": 59, "22998669743537903": 59, "2894386649131775": 59, "21524395048618": 59, "10400570929050446": 59, "12288510054349899": 59, "07056470215320587": 59, "246389418840": 59, "49932169914245605": 59, "12706467509269714": 59, "30969417095184326": 59, "2643227577209": 59, "8871506452560425": 59, "20039963722229004": 59, "0601330995559692": 59, "0348707810044": 59, "albert_embed": [60, 74], "bert_embed": [60, 74], "bert_sentence_embed": [60, 74], "camembert_embed": [60, 74], "chunk_embed": [60, 74], "deberta_embed": [60, 74], "distil_bert_embed": [60, 74], "doc2vec": [60, 74], "elmo_embed": [60, 74], "longformer_embed": [60, 74], "roberta_embed": [60, 74], "roberta_sentence_embed": [60, 74], "universal_sentence_encod": [60, 74], "xlm_roberta_embed": [60, 74], "xlm_roberta_sentence_embed": [60, 74], "xlnet_embed": [60, 74], "longformerembed": 61, "iz": 61, "beltagi": 61, "matthew": 61, "arman": 61, "cohan": 61, "checkpoint": 61, "mlm": 61, "096": 61, "longformer_base_4096": 61, "unabl": 61, "quadrat": 61, "linearli": 61, "easi": 61, "thousand": 61, "drop": [61, 115], "motiv": 61, "global": 61, "text8": 61, "enwik8": 61, "contrast": [61, 80, 109], "finetun": [61, 70], "varieti": [61, 68, 69, 184], "outperform": [61, 65, 68, 69, 70, 76, 106], "wikihop": 61, "triviaqa": 61, "led": [61, 62, 63, 76], "effect": [61, 101, 109], "arxiv": 61, "summar": [61, 76, 106, 108, 109], "found": [61, 67, 76, 112, 119, 125, 165, 182], "18792399764060974": [61, 62], "14591649174690247": [61, 62], "20547787845134735": [61, 62], "1468472778797": [61, 62], "22845706343650818": [61, 62], "18073144555091858": [61, 62], "09725798666477203": [61, 62], "0417917296290": [61, 62], "07037967443466187": [61, 62], "14801117777824402": [61, 62], "03603338822722435": [61, 62], "17893412709": [61, 62], "08734266459941864": [61, 62], "2486150562763214": [61, 62], "009067727252840996": [61, 62], "24408400058": [61, 62], "22409197688102722": [61, 62], "4312366545200348": [61, 62], "1401449590921402": [61, 62], "356410235166549": [61, 62], "robertaembed": [62, 68], "robustli": [62, 63, 93], "yinhan": [62, 63], "myle": [62, 63, 68, 69], "ott": [62, 63, 68, 69], "naman": [62, 63, 68, 69], "goyal": [62, 63, 68, 69], "jingfei": [62, 63], "du": [62, 63, 78], "mandar": [62, 63], "joshi": [62, 63], "danqi": [62, 63], "omer": [62, 63], "levi": [62, 63], "mike": [62, 63], "lewi": [62, 63], "luke": [62, 63, 68, 69], "zettlemoy": [62, 63, 68, 69], "veselin": [62, 63, 68, 69], "stoyanov": [62, 63, 68, 69], "hyperparamet": [62, 63], "next": [62, 63, 76, 81, 83, 106, 109], "mini": [62, 63], "roberta_bas": 62, "bpe": 62, "gpt": [62, 106], "signific": [62, 63, 68, 69, 76, 79], "gain": [62, 63, 68, 69], "care": [62, 63, 121], "comparison": [62, 63, 65, 115], "privat": [62, 63, 153], "choic": [62, 63, 84], "impact": [62, 63], "replic": [62, 63], "carefulli": [62, 63], "undertrain": [62, 63], "exce": [62, 63], "highlight": [62, 63], "previous": [62, 63, 76], "overlook": [62, 63], "rais": [62, 63, 76, 86, 91, 159], "report": [62, 63, 65, 159, 175], "robertasentenceembed": 63, "sent_roberta_bas": 63, "embeddingssent": 64, "22093398869037628": 64, "25130119919776917": 64, "41810303926467896": 64, "380883991718": 64, "dimension": 65, "tfhub_us": 65, "loadsp": 65, "op": 65, "lingual": [65, 68, 69, 76, 78, 108], "accur": [65, 105, 112], "divers": [65, 106, 109, 176], "trade": [65, 68, 69], "baselin": [65, 106], "tend": 65, "With": [65, 70, 76], "observ": 65, "minim": [65, 93, 108], "encourag": 65, "weat": 65, "bia": 65, "freeli": 65, "04616805538535118": 65, "022307956591248512": 65, "044395286589860916": 65, "0016493503": 65, "setloadsp": 65, "word2vecapproach": 66, "word2vecmodel": 66, "word2vec_gigaword_300": 66, "word2vec_wiki": 66, "custom": [67, 90, 91, 101, 102, 121, 152, 159], "dictionari": [67, 76, 79, 84, 90, 92, 93, 94, 104, 112, 113, 159], "setstoragepath": [67, 80], "line": [67, 71, 80, 85, 102, 104, 110, 162, 165, 168], "delimit": [67, 71, 73, 79, 84, 86, 90, 94, 104, 120, 137, 165, 168], "39658191506190343": 67, "630968081620067": 67, "5393722253731201": 67, "8428180123359783": 67, "were": [67, 91, 159, 175], "7535235923631415": 67, "9699218875629833": 67, "10397182122983872": 67, "11833962569383116": 67, "stress": 67, "0492683418305907": 67, "9415954572751959": 67, "47624463167525755": 67, "16790967216778263": 67, "induc": 67, "1535748762292387": 67, "33498936903209897": 67, "9235178224122094": 67, "1158772920395934": 67, "zero": [67, 93, 106], "withcoveragecolumn": 67, "overallcoverag": 67, "writebuffers": 67, "dump": 67, "disk": [67, 179, 180], "storag": [67, 71, 80, 145, 152], "10000": 67, "readcaches": 67, "cach": [67, 163], "higher": [67, 76, 105, 106, 109], "random_embeddings_dim4": 67, "abov": [67, 73, 168], "setstorageref": 67, "glove_4d": 67, "setdimens": [67, 146], "patient": 67, "diagnos": 67, "diabet": 67, "9439099431037903": 67, "4707513153553009": 67, "806300163269043": 67, "16176554560661316": 67, "7966810464859009": 67, "5551124811172485": 67, "8861005902290344": 67, "28284206986427307": 67, "025029370561242104": 67, "35177749395370483": 67, "052506182342767715": 67, "1887107789516449": 67, "08617766946554184": 67, "8399239182472229": 67, "5395117998123169": 67, "7864698767662048": 67, "6599600911140442": 67, "16109347343444824": 67, "6041093468666077": 67, "8913561105728149": 67, "5955275893211365": 67, "01899011991918087": 67, "4397728443145752": 67, "8911281824111938": 67, "9840458631515503": 67, "7599489092826843": 67, "9417727589607239": 67, "8624503016471863": 67, "setwritebuffers": 67, "setreadcaches": 67, "glove_100d": [67, 91], "There": [67, 71, 73, 119, 177, 179, 180, 185], "conveni": 67, "coverag": [67, 144], "add": [67, 81, 83, 101, 106, 109, 110, 121, 179], "stat": 67, "field": [67, 71, 85], "whole": [67, 162], "consid": [67, 73, 76, 110, 112, 113, 115, 119, 163], "570580005645752": 67, "44183000922203064": 67, "7010200023651123": 67, "417129993438720": 67, "542639970779419": 67, "4147599935531616": 67, "0321999788284302": 67, "4024400115013122": 67, "2708599865436554": 67, "04400600120425224": 67, "020260000601410866": 67, "17395000159": 67, "6191999912261963": 67, "14650000631809235": 67, "08592499792575836": 67, "2629800140857": 67, "3397899866104126": 67, "20940999686717987": 67, "46347999572753906": 67, "6479200124740": 67, "embeddings_col": 67, "coverageresult": 67, "coverateresult": 67, "wordsoverallcoverag": 67, "resultdf": 67, "percentag": [67, 110, 123], "output_col": 67, "wordscoverag": 67, "cov_embed": 67, "loadstorag": [67, 80], "storage_ref": [67, 80], "xlmrobertaembed": 68, "alexi": [68, 69], "conneau": [68, 69], "kartikai": [68, 69], "khandelw": [68, 69], "vishrav": [68, 69], "chaudhari": [68, 69], "guillaum": [68, 69], "wenzek": [68, 69], "francisco": [68, 69, 76], "guzman": 68, "edouard": [68, 69], "grave": [68, 69], "5tb": [68, 69], "filter": [68, 69, 76, 89, 90, 106, 108, 109, 115, 151, 163], "commoncrawl": [68, 69], "xlm_roberta_bas": 68, "xx": [68, 69, 78, 108], "multilingu": [68, 69, 123], "doe": [68, 76, 89, 134, 136, 163, 180, 183, 184], "abl": [68, 109, 159, 178], "determin": 68, "correct": [68, 110, 112, 113, 123], "hundr": [68, 69], "terabyt": [68, 69], "dub": [68, 69], "r": [68, 69, 76], "mbert": [68, 69], "xnli": [68, 69], "mlqa": [68, 69], "particularli": [68, 69], "low": [68, 69, 110], "swahili": [68, 69], "urdu": [68, 69], "capac": [68, 69, 106], "dilut": [68, 69], "sacrif": [68, 69], "ri": [68, 69], "competit": [68, 69, 76], "strong": [68, 69], "05969233065843582": 68, "030789051204919815": 68, "04443822056055069": 68, "09564960747": 68, "038839809596538544": 68, "011712731793522835": 68, "019954433664679527": 68, "0667808502": 68, "03952755779027939": 68, "03455188870429993": 68, "019103847444057465": 68, "04311436787": 68, "09579929709434509": 68, "02494969218969345": 68, "014753809198737144": 68, "10259044915": 68, "004710011184215546": 68, "022148698568344116": 68, "011723337695002556": 68, "013356896": 68, "xlmrobertasentenceembed": 69, "guzm\u00e3": 69, "sent_xlm_roberta_bas": 69, "xlnetembed": 70, "autoregress": 70, "permut": 70, "addition": [70, 91, 99, 126, 135, 162], "emploi": 70, "xl": 70, "exhibit": 70, "involv": [70, 102], "sota": 70, "rank": [70, 110], "xlnet_large_cas": 70, "xlnet_base_cas": 70, "full": [70, 179], "zihangdai": 70, "denois": 70, "autoencod": 70, "corrupt": 70, "neglect": 70, "suffer": 70, "discrep": 70, "pro": 70, "con": 70, "enabl": [70, 71, 91, 112, 152], "maxim": [70, 110], "likelihood": 70, "overcom": 70, "formul": 70, "furthermor": 70, "integr": [70, 76, 108, 159, 175, 177], "idea": 70, "6287205219268799": 70, "4865287244319916": 70, "186111718416214": 70, "234187275171279": 70, "1967450380325317": 70, "2746637463569641": 70, "9481253027915955": 70, "3431355059146881": 70, "0777631998062134": 70, "092679977416992": 70, "5331977605819702": 70, "11190271377563": 70, "8349916934967041": 70, "45627787709236145": 70, "7890847325325012": 70, "028069257736": 70, "134845569729805": 70, "11672890186309814": 70, "4945235550403595": 70, "66587203741073": 70, "entityrul": 71, "entityrulerapproach": 71, "exact": [71, 80, 85], "definit": [71, 93, 165], "json": [71, 137, 159, 170], "jsonl": 71, "setpatternsresourc": 71, "might": [71, 91, 123, 184], "setenablepatternregex": 71, "rule": [71, 84, 104, 119, 121], "person": [71, 166], "w": [71, 74, 84, 90, 94, 119, 121, 152], "winterfel": 71, "jon": 71, "snow": [71, 92, 110], "stark": 71, "eddard": 71, "patternsresourc": 71, "enablepatternregex": 71, "usestorag": 71, "rocksdb": 71, "lord": 71, "29": [71, 92, 123, 168, 170], "38": [71, 170], "setusestorag": 71, "setsentencematch": 71, "setalphabetresourc": 71, "alphabet": [71, 94], "plain": [71, 185], "entityrulermodel": 71, "entity_rul": [72, 74], "graphextract": [73, 129], "graph": [73, 91, 108, 110, 116, 129], "nerdlmodel": [73, 89, 90, 91, 92, 159, 163, 175], "store": [73, 95, 96, 137, 142, 146, 157, 162, 170, 176], "node": 73, "relev": [73, 76], "taken": 73, "implicitli": 73, "setmergeent": 73, "automat": [73, 76, 93, 108, 112, 178, 179], "setdependencyparsermodel": 73, "settypeddependencyparsermodel": 73, "setrelationshiptyp": 73, "public": [73, 163, 179], "relationshiptyp": 73, "pair": [73, 159], "entitytyp": 73, "explodeent": 73, "roottoken": 73, "travers": 73, "along": 73, "maxsentences": 73, "minsentences": 73, "below": [73, 184], "mergeent": 73, "merg": [73, 80, 85], "neighbor": 73, "includeedg": 73, "symbol": [73, 110, 123], "posmodel": 73, "coordin": [73, 101], "remoteloc": 73, "graphfinish": [73, 129], "rdf": [73, 129], "nertagg": [73, 90, 91, 92], "morn": [73, 129], "flight": [73, 129], "denver": [73, 129], "18": [73, 81, 83, 86, 89, 92, 134, 151, 162, 178], "path1": 73, "setentitytyp": 73, "setexplodeent": 73, "setroottoken": 73, "setmaxsentences": 73, "setminsentences": 73, "setmergeentitiesiobformat": 73, "iob": [73, 89, 90, 91], "iob2": [73, 89], "setincludeedg": 73, "setdelimit": [73, 84, 86], "setposmodel": 73, "class": [74, 145, 149, 156, 167, 174, 175, 183, 185], "classifier_dl": [74, 152], "er": [74, 152], "keyword_extract": [74, 152], "yake_keyword_extract": [74, 75], "ld_dl": [74, 152], "language_detector_dl": [74, 77], "matcher": [74, 152], "big_text_match": [74, 82], "date_match": [74, 82], "multi_date_match": [74, 82], "regex_match": [74, 82], "text_match": [74, 82], "ner_approach": [74, 87], "ner_convert": [74, 87], "ner_crf": [74, 87], "ner_dl": [74, 87], "ner_overwrit": [74, 87], "param": [74, 90, 141, 142, 146, 152, 157, 158], "sentence_detector_dl": [74, 100, 108], "sentiment_detector": [74, 103], "vivekn_senti": [74, 103], "seq2seq": [74, 152], "gpt2_transform": [74, 107], "marian_transform": [74, 107], "t5_transform": [74, 107], "spell_check": [74, 152], "context_spell_check": [74, 111], "norvig_sweet": [74, 111], "symmetric_delet": [74, 111], "chunk_token": [74, 118], "recursive_token": [74, 118], "regex_token": [74, 118], "word_segment": [74, 122], "chunk2_doc": [74, 152], "date2_chunk": [74, 152], "document_norm": [74, 152], "graph_extract": [74, 152], "lemmat": [74, 104, 115, 136, 139, 152], "n_gram_gener": [74, 152], "stemmer": [74, 115, 152], "stop_words_clean": [74, 152], "yakekeywordextract": 76, "yake": 76, "independ": [76, 112, 113, 119], "individu": [76, 110], "grow": 76, "autom": 76, "adequ": 76, "manner": 76, "emerg": [76, 109], "tool": 76, "system": [76, 106], "nor": 76, "thesauri": 76, "neither": 76, "corpora": [76, 80], "thu": 76, "written": [76, 108], "plethora": 76, "situat": [76, 102], "access": 76, "restrict": 76, "therefor": [76, 183], "sent": 76, "boundari": [76, 101, 102, 105, 121, 123], "detector": [76, 81, 104], "section": [76, 126, 135, 175, 177, 183], "tweakabl": 76, "upper": 76, "bound": [76, 101, 102, 105], "minngram": 76, "maxngram": 76, "occurr": 76, "nkeyword": 76, "stopword": [76, 92, 115], "stop": [76, 90, 115], "campo": 76, "mangaravit": 76, "pasquali": 76, "jatowt": 76, "jorg": 76, "nune": 76, "2020": [76, 81, 83, 102], "scienc": [76, 176], "journal": [76, 123], "elsevi": 76, "vol": 76, "509": 76, "pp": [76, 123], "257": 76, "289": 76, "collect": [76, 159, 175], "turn": [76, 139, 179], "come": 76, "term": 76, "fly": 76, "demand": 76, "abil": [76, 106], "within": [76, 99, 105, 106, 121, 125], "resort": 76, "alwai": [76, 109], "solut": 76, "articl": [76, 110], "rest": [76, 89], "merit": 76, "ten": 76, "experiment": 76, "carri": 76, "twenti": 76, "setcontextchar": [76, 121], "setminngram": 76, "setnkeyword": 76, "acquir": 76, "kaggl": 76, "platform": [76, 159, 177], "host": 76, "transact": 76, "somewhat": 76, "vagu": 76, "cloud": 76, "confer": 76, "week": [76, 81, 83, 117], "announc": [76, 92], "earli": 76, "tomorrow": [76, 81, 83], "phone": 76, "founder": 76, "ceo": 76, "anthoni": 76, "goldbloom": 76, "declin": 76, "deni": 76, "acquisit": 76, "happen": 76, "rumor": 76, "million": [76, 92, 106], "scientist": 76, "ben": 76, "hamner": 76, "2010": 76, "servic": [76, 108], "got": 76, "even": [76, 109], "few": [76, 121, 168, 185], "competitor": 76, "drivendata": 76, "topcod": 76, "hackerrank": 76, "stai": 76, "ahead": 76, "nich": 76, "home": [76, 152], "bui": [76, 166], "commun": 76, "mindshar": 76, "too": [76, 104, 178], "plenti": 76, "bit": [76, 102, 184], "histori": [76, 102, 110], "earlier": 76, "month": [76, 81, 83, 168, 185], "team": [76, 108, 159, 175], "around": 76, "youtub": 76, "That": [76, 119, 159, 175, 180], "had": 76, "technologi": 76, "did": 76, "interest": 76, "kernel": 76, "On": [76, 106, 108], "analyz": [76, 105], "compani": [76, 108], "script": 76, "centric": 76, "job": [76, 125], "board": [76, 99, 168], "unclear": 76, "accord": [76, 110, 165], "crunchbas": 76, "pitchbook": 76, "launch": 76, "investor": 76, "ventur": 76, "sv": 76, "angel": 76, "levchin": 76, "naravik": 76, "chie": 76, "economist": 76, "hal": 76, "varian": 76, "khosla": 76, "yuri": 76, "milner": 76, "resulttupl": 76, "ascend": 76, "orderbi": 76, "32051516486864573": 76, "37786450577630676": 76, "39922830978423146": 76, "40224744669493756": 76, "41584827825302534": 76, "setmaxngram": 76, "setstopword": [76, 92, 115], "getstopword": 76, "loaddefaultstopword": [76, 115], "danish": [76, 115], "dutch": [76, 115], "finnish": [76, 115], "german": [76, 115, 165, 185], "hungarian": [76, 115], "italian": [76, 110, 115], "norwegian": [76, 115], "portugues": [76, 115], "russian": [76, 115], "spanish": [76, 115], "swedish": [76, 115], "turkish": [76, 115], "languagedetectordl": 78, "ld": 78, "identif": 78, "rnn": 78, "tatoeba": 78, "140": 78, "wiki": 78, "languagedetector": 78, "ld_wiki_tatoeba_cnn_21": 78, "open": [78, 121, 125, 126, 127, 135, 139, 176], "advanc": [78, 125, 139], "scala": [78, 140, 141, 148, 154, 158], "program": 78, "biblioth\u00e8qu": 78, "traitement": 78, "pour": 78, "le": [78, 108], "avanc\u00e9": 78, "langag": 78, "naturel": 78, "programm": 78, "ist": 78, "ein": 78, "textverarbeitungsbibliothek": 78, "f\u00fcr": 78, "fortgeschritten": 78, "nat\u00fcrlich": 78, "sprachverarbeitung": 78, "die": 78, "programmiersprachen": 78, "und": 78, "lemma": [79, 104, 134, 162, 166, 180, 183, 184], "predefin": [79, 80, 84, 85, 104], "setdictionari": [79, 104, 112, 113], "lemmatizermodel": 79, "lemmas_smal": [79, 104], "setformcol": 79, "correspend": 79, "formcol": [79, 166], "setlemmacol": 79, "fromlemma": 79, "key_delimit": 79, "value_delimit": 79, "lemma_antbnc": 79, "bigtextmatch": [80, 85], "textmatch": [80, 85, 117], "externalresourc": [80, 85, 150], "mergeoverlap": [80, 85], "tokenizermodel": [80, 121], "trie": 80, "dolor": [80, 85], "magna": [80, 85], "aliqua": [80, 85], "sit": [80, 85], "laborum": [80, 85], "hello": [80, 85, 117, 170], "entityextractor": [80, 85, 117], "extractor": [80, 85, 117], "59": [80, 81, 83, 85], "setent": [80, 85, 88, 117], "setmergeoverlap": [80, 85], "settoken": 80, "tokenizer_model": 80, "bigtextmatchermodel": 80, "btm": 80, "textmatchermodel": [80, 85], "searchtri": 80, "datematcherutil": 81, "setinputformat": [81, 137], "setoutputformat": [81, 83], "desir": [81, 83], "yyyi": [81, 83], "mm": [81, 83, 123], "dd": [81, 83, 84], "Not": [81, 91, 136], "setreadmonthfirst": 81, "juli": 81, "5th": 81, "2015": 81, "07": 81, "05": 81, "setdefaultdaywhenmiss": 81, "dai": [81, 83, 110], "miss": [81, 83, 125], "setanchordateyear": [81, 83], "anchor": [81, 83], "year": [81, 83, 106, 117, 168], "setanchordatemonth": [81, 83], "januari": [81, 83], "setanchordatedai": [81, 83], "1978": [81, 83], "28": [81, 83, 89, 134, 151, 162, 170, 178], "1984": [81, 83], "04": [81, 83], "02": [81, 83], "1980": [81, 83], "79": [81, 83], "31st": [81, 83], "april": [81, 83], "2008": [81, 83], "fri": [81, 83], "1997": [81, 83], "jan": [81, 83], "sun": [81, 83], "1st": [81, 83], "thursdai": [81, 83], "wednesdai": [81, 83], "todai": [81, 83, 170], "yesterdai": [81, 83], "0600h": [81, 83], "06": [81, 83], "00": [81, 83], "hour": [81, 83], "6pm": [81, 83], "23": [81, 83, 84, 92, 99, 168, 169, 170, 185], "1988": [81, 83], "31": [81, 83, 84, 92, 99, 168], "dateformat": [81, 83], "readmonthfirst": [81, 83], "defaultdaywhenmiss": [81, 83], "anchordateyear": [81, 83], "anchordatemonth": [81, 83], "anchordatedai": [81, 83], "15": [81, 170], "saw": 83, "him": 83, "me": 83, "visit": 83, "57": [83, 92], "65": [83, 92], "regexmatch": 84, "d": [84, 94, 121, 177], "1970": 84, "setrul": 84, "setexternalrul": 84, "match_first": 84, "match_al": 84, "match_complet": 84, "externalrul": 84, "ceremoni": 84, "setstrategi": 84, "71": 84, "short_dat": 84, "regexmatchermodel": 84, "regardless": 85, "entityvalu": 85, "buildfromtoken": 85, "27": [85, 99, 101, 168], "48": [85, 123, 170], "setentityvalu": 85, "setbuildfromtoken": 85, "null": 86, "empti": [86, 125], "enablecumul": 86, "join": [86, 99, 137, 168], "setenablecumul": 86, "nerapproach": 88, "recogn": [88, 89, 90, 91, 92, 93, 110], "setminepoch": [88, 90], "setrandomse": [88, 91, 95], "getlabelcolumn": [88, 116], "friendli": [89, 108], "whitelist": [89, 119], "setwhitelist": [89, 119], "outsid": 89, "prefix": [89, 119, 121, 159, 175], "preserveposit": [89, 120, 139], "org": [89, 90, 91, 92, 123, 134, 151, 152, 162, 165, 176, 185], "14": [89, 99, 134, 138, 151, 162, 168], "ekeu": [89, 90, 91, 134, 151, 162], "36": [89, 99, 134, 151, 162, 168, 170], "baghdad": [89, 90, 91, 134, 151, 162], "37": [89, 134, 151, 162], "setpreserveposit": [89, 120, 139], "nercrf": 90, "nercrfapproach": [90, 91], "nercrfmodel": [90, 91], "crf": [90, 91], "2003": [90, 91, 123, 165, 185], "exclud": [90, 91], "setexternalfeatur": 90, "minepoch": [90, 91], "l2": 90, "c0": 90, "decai": [90, 91], "gradient": 90, "2250000": 90, "lossep": 90, "ep": 90, "minw": 90, "includeconfid": [90, 91], "confid": [90, 91, 93], "externalfeatur": 90, "nerdlapproach": [90, 91, 165, 185], "trainingdata": [90, 91, 102, 112, 113, 165], "readdataset": [90, 91, 99, 123, 165, 166, 168, 169, 170, 185], "conll2003": [90, 91, 165, 185], "eng": [90, 91, 165, 185], "setl2": 90, "l2valu": 90, "setc0": 90, "c0valu": 90, "setlossep": 90, "setminw": 90, "setincludeconfid": [90, 91], "verbosevalu": 90, "prerequisit": [90, 91, 92, 179], "nerdl": 91, "char": [91, 94, 102], "bilstm": 91, "tagger": [91, 168, 185], "50": [91, 92, 99, 106, 170], "real": [91, 152, 159, 175], "rage": 91, "graphfold": [91, 110], "usecontrib": 91, "contrib": 91, "cell": [91, 137], "slightli": [91, 102], "includeallconfidencescor": 91, "enablememoryoptim": 91, "slow": 91, "down": [91, 179, 180], "usebestmodel": 91, "bestmodelmetr": 91, "check": [91, 101, 110, 111, 112, 113, 134, 139, 162, 179, 184], "micro": 91, "macro": 91, "setgraphfold": [91, 110, 116], "setusecontrib": 91, "setpo": 91, "setincludeallconfidencescor": 91, "setenablememoryoptim": 91, "setusebestmodel": 91, "setbestmodelmetr": 91, "nermodel": 91, "neroverwrit": 92, "specifi": [92, 93, 102, 165, 166], "setnewresult": 92, "nerword": 92, "overwritten": 92, "newnerent": 92, "lab": 92, "42": [92, 99], "45": [92, 99, 168, 170], "47": [92, 168, 170], "66": 92, "ner_overwritten": 92, "setnerword": 92, "setnewnerent": 92, "cardin": 92, "setreplaceent": 92, "rw": 92, "zeroshotnermodel": 93, "shot": [93, 106], "zeroshotn": 93, "zer_shot_n": 93, "entitydefinit": 93, "citi": 93, "town": 93, "predictionthreshold": 93, "01f": 93, "ignoreent": 93, "zero_shot_n": 93, "setentitydefinit": 93, "hellen": 93, "5328949": 93, "9360068": 93, "83294415": 93, "45366877": 93, "setpredictionthreshold": 93, "zero_shot_ner_roberta": 93, "shortcut": 93, "stem": [94, 114, 134, 162, 183, 184], "henc": 94, "pl": 94, "slangdictionari": 94, "slang": 94, "minlength": [94, 101, 102, 120, 121], "maxlength": [94, 101, 102, 120, 121], "setcleanuppattern": 94, "punctuat": [94, 101], "alphanumer": 94, "letter": [94, 106, 110, 168, 185], "za": 94, "z": [94, 121], "brother": 94, "dont": [94, 105], "setslangdictionari": 94, "setminlength": [94, 101, 102, 120, 121], "setmaxlength": [94, 101, 102, 120, 121], "normalizermodel": 94, "classifierencod": 95, "attach": [95, 96, 142, 146, 157, 159], "evaluationdlparam": 96, "setevaluationlogextend": 96, "setenableoutputlog": [96, 159, 175], "setoutputlogspath": [96, 102, 159, 175], "assum": 96, "perceptronapproach": [99, 168, 185], "member": [99, 162], "datasetpath": 99, "pierr": [99, 168], "vinken": [99, 168], "34": [99, 168, 170], "md": [99, 168], "vb": [99, 165, 168, 185], "41": [99, 101, 168, 170], "43": [99, 101, 168, 170], "dt": [99, 168, 169, 185], "49": [99, 168], "poscol": [99, 123, 165], "niter": [99, 123], "anc": [99, 168, 185], "trainingperceptrondf": 99, "trainedpo": 99, "setposcolumn": [99, 123], "cd": [99, 165, 168], "setiter": 99, "getniter": [99, 123], "pos_anc": 99, "25": [99, 101, 168, 170], "33": [99, 170], "sentencedetectorparam": 101, "ii": 101, "abbrevi": 101, "period": 101, "geo": 101, "1026": 101, "253": 101, "553": 101, "ellipsi": 101, "quotat": 101, "mark": [101, 102, 123], "exclam": 101, "breaker": 101, "pragmaticcontentformatt": 101, "custombound": [101, 102], "setcustombound": [101, 102], "usecustomboundsonli": [101, 102], "explodesent": [101, 102, 165, 166], "useabbrevi": 101, "explicitli": [101, 102, 115, 151, 179], "customboundsstrategi": 101, "prepend": [101, 125], "break": 101, "append": [101, 110, 179], "parallel": [101, 102, 134, 165, 183], "splitlength": [101, 102], "forcibli": [101, 102], "99999": [101, 102, 121], "detectlist": 101, "nhow": 101, "setcustomboundsstrategi": 101, "setuseabbrevi": 101, "setdetectlist": 101, "setusecustomboundsonli": [101, 102], "setexplodesent": [101, 102], "setsplitlength": [101, 102], "sentencedetectordl": 102, "sentencedetectordlapproach": 102, "futur": [102, 109], "setmodel": 102, "sentencedetectordlmodel": [102, 108], "modelarchitectur": 102, "impossiblepenultim": 102, "imposs": [102, 123], "penultim": 102, "epochsnumb": 102, "eo": 102, "stefan": 102, "schweter": 102, "sajawel": 102, "ahm": 102, "littl": [102, 184], "cover": [102, 109, 123], "broken": 102, "moder": 102, "lack": 102, "easier": [102, 128, 181, 185], "polit": 102, "successor": 102, "great": 102, "respons": 102, "heritag": 102, "bequeath": 102, "nelson": 102, "mandela": 102, "setepochsnumb": 102, "model_architectur": 102, "validation_split": 102, "epochs_numb": 102, "output_logs_path": 102, "setimpossiblepenultim": 102, "impossible_penultim": 102, "sentencedl": 102, "sentencesdl": 102, "helen": 102, "total": [102, 123], "peopl": 102, "sentimentdetector": 104, "By": [104, 109, 115, 120, 127, 152, 159, 175], "els": 104, "viveknsentimentapproach": [104, 105], "cool": 104, "superb": 104, "uninspir": 104, "sentimentscor": 104, "staff": 104, "restaur": 104, "nice": [104, 159, 175], "avoid": 104, "entri": [104, 126, 135, 163], "sttr": 104, "sentimentdetectormodel": 104, "sda": [104, 105], "pragmat": 104, "viveknsenti": 105, "analys": 105, "inspir": [105, 112, 113, 155], "vivek": 105, "narayanan": 105, "give": 105, "transit": [105, 110], "sentimentcol": 105, "prunecorpu": 105, "unfrequ": 105, "scenario": 105, "scope": 105, "naiv": 105, "bay": 105, "vivekn": 105, "setsentimentcol": 105, "train_senti": 105, "result_senti": 105, "finish": [105, 127, 129, 133, 136, 152], "final_senti": 105, "cast": [105, 124], "horribl": 105, "never": [105, 179], "go": [105, 179], "again": [105, 119], "anyon": 105, "protagonist": 105, "music": 105, "setprunecorpu": 105, "frequenc": [105, 110, 112, 113, 123], "viveknsentimentmodel": 105, "sentiment_vivekn": 105, "gpt2transform": 106, "gpt2": 106, "openai": 106, "caus": [106, 121], "goal": [106, 123], "occur": [106, 109], "direct": 106, "10x": 106, "synthet": 106, "sampl": [106, 109], "unpreced": 106, "prime": 106, "lengthi": 106, "translat": [106, 108, 109, 123], "suggest": 106, "benefit": 106, "suffici": 106, "minoutputlength": [106, 109], "maxoutputlength": [106, 108, 109], "dosampl": [106, 109], "greedi": [106, 109], "temperatur": [106, 109], "topk": [106, 109], "highest": [106, 109, 112], "topp": [106, 109], "cumul": [106, 109], "kept": [106, 109], "repetitionpenalti": [106, 109], "repetit": [106, 109], "penalti": [106, 109], "norepeatngrams": [106, 109], "onc": [106, 109], "ignoretokenid": [106, 109], "especi": [106, 108, 109], "multitask": 106, "learner": 106, "typic": 106, "taskspecif": 106, "webpag": [106, 176], "webtext": 106, "plu": 106, "coqa": 106, "exceed": 106, "127": 106, "fashion": 106, "5b": 106, "still": [106, 159], "underfit": 106, "reflect": 106, "paragraph": [106, 110], "promis": 106, "toward": 106, "setmaxoutputlength": [106, 108, 109], "leonardo": 106, "summari": [106, 109], "man": 106, "1776": 106, "came": 106, "kingdom": 106, "settask": [106, 109], "setignoretokenid": [106, 108, 109], "setminoutputlength": [106, 109], "setdosampl": [106, 109], "settemperatur": [106, 109], "settopk": [106, 109], "settopp": [106, 109], "setrepetitionpenalti": [106, 109], "ctrl": [106, 109], "control": [106, 108, 109, 110], "setnorepeatngrams": [106, 109], "mariantransform": 108, "marian": 108, "free": 108, "mainli": 108, "academ": 108, "notabl": 108, "edinburgh": 108, "past": 108, "adam": 108, "mickiewicz": 108, "pozna\u0144": 108, "commerci": 108, "contributor": 108, "mariannmt": 108, "engin": [108, 117], "behind": 108, "deploi": [108, 176], "opus_mt_en_fr": 108, "langid": 108, "maxinputlength": 108, "differenti": 108, "dynam": 108, "toolkit": 108, "setmaxinputlength": 108, "capit": [108, 110], "franc": 108, "quell": 108, "capital": 108, "devrait": 108, "savoir": 108, "fran\u00e7ai": 108, "setlangid": 108, "t5transform": 109, "t5": 109, "reconsid": 109, "unifi": 109, "hyper": 109, "t5_small": 109, "explor": 109, "rich": 109, "rise": 109, "methodologi": 109, "landscap": 109, "systemat": 109, "dozen": 109, "insight": 109, "coloss": 109, "facilit": 109, "200": 109, "contextspellcheck": 110, "contextspellcheckerapproach": [110, 112, 113], "noisi": 110, "spell": [110, 111, 112, 113, 134, 139, 182, 183, 184], "candid": [110, 112, 113, 121], "contextspellcheckermodel": [110, 112, 113], "error": 110, "surround": [110, 137], "edit": [110, 112, 113], "subword": 110, "checker": [110, 112, 113, 182], "languagemodelclass": 110, "lm": 110, "wordmaxdist": 110, "maxcandid": 110, "casestrategi": 110, "uppercas": 110, "errorthreshold": 110, "perplex": 110, "nlm": 110, "initialr": 110, "finalr": 110, "validationfract": 110, "datapoint": 110, "min": 110, "vocab": 110, "compoundcount": 110, "compound": 110, "classcount": 110, "special": [110, 123, 153, 180], "tradeoff": 110, "weighteddistpath": 110, "levenshtein": [110, 112, 113], "maxwindowlen": 110, "rememb": 110, "maxsentlen": 110, "norvigsweetingapproach": [110, 112, 113, 185], "symmetricdeleteapproach": [110, 112, 113, 185], "depth": [110, 182], "explan": [110, 182], "awar": 110, "sherlock": 110, "holm": 110, "spellcheck": [110, 112, 113], "setwordmaxdist": 110, "setepoch": 110, "setlanguagemodelclass": 110, "1650": 110, "addvocabclass": 110, "_name_": 110, "extra": [110, 112, 179], "dist": 110, "setmaxcandid": 110, "setcasestrategi": 110, "seterrorthreshold": 110, "setinitialr": 110, "setfinalr": 110, "setvalidationfract": 110, "fraction": 110, "setcompoundcount": 110, "setclasscount": 110, "settradeoff": 110, "alpha": 110, "setweighteddistpath": 110, "setmaxwindowlen": 110, "setmaxsentlen": 110, "sentlen": 110, "userdist": 110, "addregexclass": 110, "spellcheck_dl": 110, "gamma": 110, "influenc": 110, "decis": 110, "correctsymbol": 110, "comparelowcas": 110, "vocabfreq": 110, "idsvocab": 110, "vocabid": 110, "usenewlin": 110, "newlin": 110, "norvigsweetingmodel": [110, 112, 113], "symmetricdeletemodel": [110, 112, 113], "doc": [110, 169, 185], "cold": 110, "dreari": 110, "countri": 110, "white": 110, "smow": 110, "setweight": 110, "setgamma": 110, "setvocabfreq": 110, "setidsvocab": 110, "setvocabid": 110, "setclass": 110, "getwordclass": 110, "updateregexclass": 110, "updat": 110, "updatevocabclass": 110, "setcorrectsymbol": 110, "setcomparelowcas": 110, "norvigsweet": 112, "norvig": 112, "bayesian": 112, "tokenpattern": 112, "sensit": [112, 115, 121], "doublevari": 112, "search": 112, "shortcircuit": 112, "frequencyprior": 112, "ham": 112, "intersect": 112, "prioriti": [112, 121], "wordsizeignor": 112, "dupslimit": 112, "duplic": 112, "reductlimit": 112, "attempt": 112, "vowelswaplimit": 112, "vowel": 112, "swap": 112, "corrector": 112, "gummi": [112, 113], "gummic": [112, 113], "gummier": [112, 113], "gummiest": [112, 113], "gummifer": [112, 113], "basi": [112, 113], "token_pattern": [112, 113], "setdoublevari": 112, "setshortcircuit": 112, "setfrequencyprior": 112, "symmetr": [112, 113], "delet": [112, 113, 179], "damerau": [112, 113], "magnitud": [112, 113], "transpos": [112, 113], "insert": [112, 113, 179], "spellcheck_norvig": 112, "symspel": [112, 113], "somtim": 112, "wrrite": [112, 113], "wordz": [112, 113], "erong": [112, 113], "sometim": [112, 113, 179], "wrong": [112, 113], "symmetricdelet": 113, "deriv": 113, "teach": 113, "maxeditdist": 113, "frequencythreshold": [113, 123], "deletesthreshold": 113, "patttern": 113, "setmaxeditdist": 113, "setfrequencythreshold": [113, 123], "setdeletesthreshold": 113, "spellcheck_sd": 113, "spmetim": 113, "hard": 114, "employ": 114, "stopwordsclean": [115, 127, 139], "mllib": [115, 176], "stopwordsremov": 115, "cleantoken": [115, 127, 139], "stopwords_en": 115, "jvm": [115, 152], "forth": 115, "setlocal": 115, "tfnerdlgraphbuildermodel": 116, "tfnerdlgraphbuild": 116, "sethiddenunitsnumb": 116, "assertiondlapproach": 116, "medicalnerapproach": 116, "gethiddenunitsnumb": 116, "getinputcol": [116, 127, 128, 142], "srt": 116, "getgraphfold": 116, "setgraphfil": 116, "greaph": 116, "auto": 116, "getgraphfil": 116, "chunktoken": 117, "flatten": 117, "artist": 117, "benezar": 117, "robert": 117, "farendel": 117, "graduat": 117, "luca": 117, "chunktokenizermodel": 117, "recursivetoken": 119, "recurs": [119, 136, 148, 152, 156], "hand": 119, "suffix": [119, 121, 179], "infix": [119, 121], "middl": [119, 123], "she": 119, "qam": 119, "setprefix": 119, "setsuffix": 119, "setinfix": 119, "recursivetokenizermodel": 119, "regextoken": [120, 123, 180], "whitespac": [120, 123, 125], "tolowercas": [120, 123], "positionalmask": 120, "guarante": 120, "increment": 120, "trimwhitespac": 120, "flag": 120, "eventu": 120, "settolowercas": [120, 123], "nthi": 120, "setpositionalmask": 120, "settrimwhitespac": 120, "tokenizedsent": 121, "rulefactori": 121, "targetpattern": 121, "grab": 121, "prefixpattern": 121, "suffixpattern": 121, "infixpattern": 121, "sub": 121, "won": 121, "exceptionspath": 121, "casesensitiveexcept": 121, "contextchar": 121, "splitpattern": 121, "splitchar": 121, "didn": 121, "jane": 121, "boyfriend": 121, "getinfixpattern": 121, "getsuffixpattern": 121, "getprefixpattern": 121, "getcontextchar": 121, "getsplitchar": 121, "settargetpattern": 121, "setprefixpattern": 121, "setsuffixpattern": 121, "setinfixpattern": 121, "addinfixpattern": 121, "setexcept": 121, "getexcept": 121, "setexceptionspath": 121, "addexcept": 121, "setcasesensitiveexcept": 121, "getcasesensitiveexcept": 121, "addcontextchar": 121, "setsplitpattern": 121, "setsplitchar": 121, "addsplitchar": 121, "piec": 121, "token_rul": 121, "wordsegment": 123, "wordsegmenterapproach": 123, "korean": 123, "japanes": 123, "chines": 123, "correspond": [123, 159], "ll": 123, "rr": 123, "likewis": 123, "side": 123, "themselv": 123, "\u4e0a\u6d77": 123, "\u8ba1\u5212": 123, "\u5230": 123, "\u672c": 123, "\u4e16\u7eaa": 123, "\u672b": 123, "\u5b9e\u73b0": 123, "\u4eba\u5747": 123, "\u56fd\u5185": 123, "\u751f\u4ea7": 123, "\u603b\u503c": 123, "\u4e94\u5343": 123, "\u7f8e\u5143": 123, "\u4e0a": 123, "\u6d77": 123, "\u8ba1": 123, "\u5212": 123, "\u4e16": 123, "\u7eaa": 123, "\u5b9e": 123, "\u73b0": 123, "\u4eba": 123, "\u5747": 123, "\u56fd": 123, "\u5185": 123, "\u751f": 123, "\u4ea7": 123, "\u603b": 123, "ll\u503c": 123, "\u4e94": 123, "\u5343": 123, "\u7f8e": 123, "\u5143": 123, "shanghai": 123, "plan": 123, "dollar": 123, "capita": 123, "gdp": 123, "wordsegmentermodel": 123, "tip": 123, "frame": 123, "least": 123, "frequent": 123, "ambiguitythreshold": 123, "enableregextoken": 123, "xue": 123, "nianwen": 123, "volum": 123, "februari": 123, "aclweb": 123, "aclanthologi": 123, "o03": 123, "4002": 123, "chinese_train": 123, "utf8": 123, "\u5341": 123, "\u56db": 123, "\u4e0d": 123, "\u662f": 123, "setniter": 123, "trainingdataset": 123, "setambiguitythreshold": 123, "getfrequencythreshold": 123, "getambiguitythreshold": 123, "setenableregextoken": 123, "plit": 123, "words_seg": 123, "wordseg_pku": 123, "zh": 123, "\u7136\u800c": 123, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 123, "\u9019\u6a23": 123, "\u7684": 123, "\u8655\u7406": 123, "\u4e5f": 123, "\u884d\u751f": 123, "\u4e86": 123, "\u4e00\u4e9b": 123, "\u554f\u984c": 123, "prepar": [124, 126, 132, 135], "outputcol": [124, 126, 127, 128, 129, 132, 135], "inferschema": 124, "tmp": [124, 132, 152, 175], "librispeech_asr_dummy_clean_audio_array_parquet": 124, "float_arrai": 124, "getoutputcol": [124, 126, 127, 128, 132, 135, 142], "chunkcol": 125, "stringtyp": 125, "setisarrai": 125, "startcol": 125, "startcolbytokenindex": 125, "isarrai": 125, "failonmiss": 125, "fail": 125, "chunkassembl": 125, "setchunkcol": 125, "setstartcol": 125, "setstartcolbytokenindex": 125, "setfailonmiss": 125, "disabl": [126, 135], "idcol": [126, 135], "metadatacol": [126, 135], "cleanupmod": [126, 135], "cleanup": [126, 135], "inplac": [126, 135], "inplace_ful": [126, 135], "shrink_ful": [126, 135], "each_ful": [126, 135], "delete_ful": [126, 135], "setidcol": [126, 135], "setmetadatacol": [126, 135], "usabl": 127, "lda": 127, "forest": 127, "featurecol": 127, "cleanannot": [127, 128, 129], "outputasvector": 127, "gloveembed": 127, "finished_sentence_embed": 127, "resultwiths": 127, "1619900017976761": 127, "045552998781204224": 127, "03229299932718277": 127, "685609996318": 127, "42416998744010925": 127, "1378999948501587": 127, "5717899799346924": 127, "5078899860382": 127, "08621499687433243": 127, "15772999823093414": 127, "06067200005054474": 127, "395359992980": 127, "4970499873161316": 127, "7164199948310852": 127, "40119001269340515": 127, "05761000141501": 127, "08170200139284134": 127, "7159299850463867": 127, "20677000284194946": 127, "0295659992843": 127, "valuesplitsymbol": 128, "annotationsplitsymbol": 128, "includemetadata": 128, "outputasarrai": [128, 129], "parseembeddingsvector": 128, "setvaluesplitsymbol": 128, "setannotationsplitsymbol": 128, "setincludemetadata": [128, 180], "setoutputasarrai": [128, 129], "setparseembeddingsvector": 128, "finishedresult": 129, "hasrecursivefit": [130, 131], "java_obj": [130, 155, 158], "py4j": [130, 131, 158], "java_gatewai": [130, 131, 158], "javaobject": [130, 131, 158], "recursivepipelin": [130, 131, 136, 142], "hasrecursivetransform": 131, "doc2_chunk": [133, 152], "embeddings_finish": [133, 152], "graph_finish": [133, 152], "has_recursive_fit": [133, 152], "has_recursive_transform": [133, 152], "light_pipelin": [133, 152], "recursive_pipelin": [133, 152], "token2_chunk": [133, 152], "token_assembl": [133, 152], "lightpipelin": [134, 162, 183], "parse_embed": [134, 162], "equival": [134, 152, 183], "execut": [134, 179, 183], "hold": [134, 183], "principl": [134, 183], "everyth": [134, 183, 184], "fullannot": [134, 162], "happi": [134, 178, 180, 183, 184], "prp": [134, 166, 168, 178, 183, 184, 185], "rb": [134, 168, 178, 183, 184, 185], "optional_target": [134, 162], "explain_document_pipelin": [134, 151, 162, 178, 183, 184], "dict_kei": [134, 162], "fullannotateimag": [134, 162], "path_to_imag": [134, 162], "setignoreunsupport": 134, "unsupport": 134, "annotatormodel": [134, 141, 163], "getignoreunsupport": 134, "text2": 135, "document1": 135, "document2": 135, "arg": [136, 155], "kwarg": 136, "decid": 136, "advantag": 136, "behav": 136, "exactli": 136, "intent": 136, "recursivepipelinemodel": 136, "pipeline_model": [136, 159, 175], "intend": 136, "tab": [137, 159, 175], "escap": 137, "quot": 137, "inputformat": 137, "csvdelimit": 137, "defailt": 137, "comma": 137, "escapecsvdelimit": 137, "table_csv": 137, "csv_data": 137, "input_format": 137, "setcsvdelimit": 137, "setescapecsvdelimit": 137, "token2chunk": 138, "17": [138, 168, 170], "tokenassembl": 139, "reconstruct": 139, "cleantext": 139, "opensourc": 139, "annotatorapproach": [140, 148, 159], "py": [140, 141, 148, 154, 158], "subclass": [141, 154, 158], "inherit": [141, 158], "ins": [141, 158], "uid": [141, 158], "annotatorproperti": 142, "setlazyannot": 142, "lazili": 142, "getlazyannot": 142, "annotator_approach": [145, 152], "annotator_model": [145, 152], "annotator_properti": [145, 152], "coverage_result": [145, 152], "recursive_annotator_approach": [145, 152], "hasembeddingsproperti": 146, "getdimens": 146, "constant": 147, "recursiveannotatorapproach": 148, "handl": [149, 167], "fo": 150, "assist": 151, "map_annot": 151, "f": [151, 159, 175], "output_typ": 151, "udf": 151, "userdefinedfunct": 151, "def": 151, "nnp_token": 151, "lambda": 151, "alia": 151, "epeu": 151, "map_annotations_arrai": 151, "map_annotations_strict": 151, "map_annotations_col": 151, "output_column": 151, "annotatyon_typ": 151, "chunks_df": 151, "pos_chunk": 151, "vbz": [151, 165, 185], "filter_by_annotations_col": 151, "filter_po": 151, "explode_annotations_col": 151, "annotator_java_ml": [152, 156], "annotator_transform": [152, 156], "extended_java_wrapp": [152, 156], "params_getters_sett": [152, 156], "comet": [152, 160, 177], "pretrained_pipelin": [152, 161], "resource_download": [152, 161], "pub_tat": [152, 167], "annotation_audio": 152, "annotation_imag": 152, "apple_silicon": 152, "aarch64": 152, "cache_fold": 152, "log_fold": 152, "cluster_tmp_dir": 152, "real_time_output": 152, "output_level": 152, "correctli": 152, "maco": 152, "linux": 152, "alloc": 152, "directori": [152, 163, 175], "cache_pretrain": 152, "temporarili": 152, "unpack": 152, "hadoop": 152, "dir": 152, "s3": 152, "hdf": 152, "dbf": 152, "annotator_log": 152, "annotatorjavamlread": 153, "mixin": 153, "javamlread": 153, "classmethod": 153, "mlreader": 153, "clazz": 153, "rl": 153, "javaparam": 153, "annotatortransform": 154, "ensur": 154, "_java_obj": 154, "extens": 155, "javawrapp": 155, "extendedjavawrapp": 155, "new_java_arrai": 155, "pylist": 155, "java_class": 155, "todo": 155, "chang": 155, "paramsgetterssett": 157, "getparamvalu": 157, "paramnam": 157, "setparamvalu": 157, "recursiveestim": 158, "tupl": 158, "overrid": 158, "recursivetransform": 158, "cometlogg": [159, 175], "workspac": 159, "project_nam": [159, 175], "comet_mod": [159, 175], "experiment_id": 159, "experiment_kwarg": 159, "logger": [159, 175], "meta": [159, 177], "practition": [159, 175], "reliabl": [159, 175], "streamlin": [159, 175], "lifecycl": [159, 175, 177], "track": [159, 175, 176], "explain": [159, 175, 182, 184], "reproduc": [159, 175, 176], "outputlogpath": [159, 175], "onlin": [159, 175], "reus": 159, "importerror": 159, "output_log_path": [159, 175], "embd": [159, 175], "setshuffleperepoch": [159, 175], "logdir": [159, 175], "interfac": [159, 175, 183], "chart": [159, 175], "attribut": 159, "comet_ml": [159, 175], "log_pipeline_paramet": [159, 175], "log_visu": [159, 175], "html": [159, 175], "viz": [159, 175], "upload": 159, "colum": [159, 175], "ner_chunk": [159, 175], "sparknlp_displai": [159, 175], "nervisu": [159, 175], "idx": [159, 175], "enumer": [159, 175], "label_col": [159, 175], "document_col": [159, 175], "return_html": [159, 175], "log_metr": [159, 175], "sklearn": [159, 175], "preprocess": [159, 175], "multilabelbinar": [159, 175], "classification_report": [159, 175], "preds_df": [159, 175], "topanda": [159, 175], "mlb": [159, 175], "y_true": [159, 175], "fit_transform": [159, 175], "y_pred": [159, 175], "output_dict": [159, 175], "log_paramet": 159, "log_completed_run": 159, "log_file_path": 159, "complet": [159, 176, 179], "log_asset": 159, "asset_path": 159, "asset": 159, "log_asset_data": 159, "interv": 159, "refresh": 159, "outstand": 159, "disk_loc": 162, "fulli": 162, "light_model": 162, "gather": 162, "langaug": 162, "resourcedownload": [163, 179, 184], "showpublicmodel": [163, 179], "onto_100": 163, "onto_300": 163, "ner_dl_bert": 163, "similarli": 163, "showpublicpipelin": [163, 184], "check_spel": [163, 184], "match_datetim": [163, 184], "downloadmodel": 163, "reader": 163, "j_dwn": 163, "pythonresourcedownload": 163, "downloadmodeldirectli": 163, "downloadpipelin": 163, "clearcach": 163, "clear": 163, "argument": 163, "filer": 163, "showuncategorizedresourc": 163, "yet": 163, "showavailableannot": 163, "documentcol": [165, 166], "sentencecol": [165, 166], "tokencol": 165, "conlllabelindex": 165, "conllposindex": 165, "conlldocidcol": 165, "doc_id": [165, 169], "textcol": [165, 166], "labelcol": 165, "includedocid": 165, "docstart": [165, 185], "eu": [165, 185], "np": [165, 185], "reject": [165, 185], "vp": [165, 185], "misc": [165, 185], "boycott": [165, 185], "british": [165, 185], "lamb": [165, 185], "blackburn": 165, "brussel": 165, "1996": 165, "08": 165, "storage_level": 165, "storagelevel": 165, "disk_onli": 165, "lift": 165, "persist": 165, "uposcol": 166, "upo": 166, "xposcol": 166, "xpo": 166, "lemmacol": 166, "sent_id": 166, "sell": 166, "pron": 166, "nom": 166, "plur": 166, "_": 166, "tens": 166, "conj": 166, "cc": 166, "obj": 166, "spaceaft": 166, "No": [166, 178], "punct": 166, "conllufil": [166, 185], "conlldataset": [166, 185], "morph": 166, "Into": 166, "googleo": 166, "sconj": 166, "propn": 166, "adp": 166, "wp": 166, "vbd": [166, 168, 185], "ago": [168, 185], "receiv": [168, 185], "posdf": 168, "61": 168, "56": 168, "67": [168, 169, 185], "nonexecut": 168, "69": 168, "76": 168, "director": 168, "78": 168, "81": 168, "84": 168, "outputposcol": 168, "outputdocumentcol": 168, "outputtextcol": 168, "pubtat": [169, 182], "medic": [169, 185], "titl": [169, 185], "medment": [169, 185], "25763772": [169, 185], "dctn4": [169, 185], "t116": [169, 185], "t123": [169, 185], "c4308010": [169, 185], "63": [169, 185], "chronic": [169, 185], "pseudomona": [169, 185], "aeruginosa": [169, 185], "infect": [169, 185], "t047": [169, 185], "c0854135": [169, 185], "82": [169, 185], "cystic": [169, 185], "fibrosi": [169, 185], "c0010674": [169, 185], "120": [169, 185], "pa": [169, 185], "124": [169, 185], "139": [169, 185], "pubtatorfil": 169, "corpus_pubtator_sampl": 169, "pubtatordataset": 169, "finished_token": [169, 180], "finished_po": 169, "finished_n": 169, "finished_token_metadata": 169, "finished_pos_metadata": 169, "finished_label_metadata": 169, "mo": 169, "ispaddedtoken": 169, "pad": 169, "spacytoannot": 170, "token_spac": 170, "sentence_end": 170, "spaci": 170, "multi_doc_token": 170, "went": 170, "night": 170, "bought": 170, "bread": 170, "54": 170, "46": 170, "overview": [174, 182], "workflow": 175, "dedic": 175, "account": 175, "inspect": 175, "init": 175, "sparknlp_experi": 175, "offline_directori": 175, "later": 175, "nativ": 176, "record": 176, "queri": 176, "registri": 176, "discov": 176, "central": 176, "send": 177, "messag": 177, "mlflow": 177, "content": [178, 184], "clearli": 178, "explain_document_ml": [178, 183, 184], "approx": [178, 183, 184], "mb": [178, 183, 184], "ok": [178, 183, 184], "spearhead": 179, "produc": 179, "declar": 179, "accordingli": 179, "extra_loc": 179, "offer": [179, 181, 184], "classifierdl_use_trec50": 179, "classifierdl_use_spam": 179, "column_nam": 179, "preced": 179, "interchang": 180, "anoth": 180, "road": 180, "proce": 180, "At": 180, "sens": 184, "constantli": 184, "server": 184, "sever": 185, "train_po": 185, "training_conl": 185, "train_corpu": 185, "withcolumnrenam": 185, "trainingpubtatordf": 185, "corpus_pubt": 185}, "objects": {"": [[152, 0, 0, "-", "sparknlp"]], "sparknlp": [[2, 0, 0, "-", "annotation"], [3, 0, 0, "-", "annotation_audio"], [4, 0, 0, "-", "annotation_image"], [74, 0, 0, "-", "annotator"], [133, 0, 0, "-", "base"], [145, 0, 0, "-", "common"], [151, 0, 0, "-", "functions"], [156, 0, 0, "-", "internal"], [160, 0, 0, "-", "logging"], [161, 0, 0, "-", "pretrained"], [152, 3, 1, "", "start"], [167, 0, 0, "-", "training"], [172, 0, 0, "-", "upload_to_hub"], [173, 0, 0, "-", "util"], [152, 3, 1, "", "version"]], "sparknlp.annotation": [[2, 1, 1, "", "Annotation"]], "sparknlp.annotation.Annotation": [[2, 2, 1, "", "arrayType"], [2, 2, 1, "", "copy"], [2, 2, 1, "", "dataType"], [2, 2, 1, "", "fromRow"], [2, 2, 1, "", "toRow"]], "sparknlp.annotation_audio": [[3, 1, 1, "", "AnnotationAudio"]], "sparknlp.annotation_audio.AnnotationAudio": [[3, 2, 1, "", "copy"]], "sparknlp.annotation_image": [[4, 1, 1, "", "AnnotationImage"]], "sparknlp.annotation_image.AnnotationImage": [[4, 2, 1, "", "copy"]], "sparknlp.annotator": [[6, 0, 0, "-", "audio"], [8, 0, 0, "-", "chunk2_doc"], [9, 0, 0, "-", "chunker"], [26, 0, 0, "-", "classifier_dl"], [41, 0, 0, "-", "coref"], [43, 0, 0, "-", "cv"], [46, 0, 0, "-", "date2_chunk"], [48, 0, 0, "-", "dependency"], [50, 0, 0, "-", "document_normalizer"], [60, 0, 0, "-", "embeddings"], [72, 0, 0, "-", "er"], [73, 0, 0, "-", "graph_extraction"], [75, 0, 0, "-", "keyword_extraction"], [77, 0, 0, "-", "ld_dl"], [79, 0, 0, "-", "lemmatizer"], [82, 0, 0, "-", "matcher"], [86, 0, 0, "-", "n_gram_generator"], [87, 0, 0, "-", "ner"], [94, 0, 0, "-", "normalizer"], [97, 0, 0, "-", "param"], [98, 0, 0, "-", "pos"], [100, 0, 0, "-", "sentence"], [103, 0, 0, "-", "sentiment"], [107, 0, 0, "-", "seq2seq"], [111, 0, 0, "-", "spell_check"], [114, 0, 0, "-", "stemmer"], [115, 0, 0, "-", "stop_words_cleaner"], [116, 0, 0, "-", "tf_ner_dl_graph_builder"], [118, 0, 0, "-", "token"], [122, 0, 0, "-", "ws"]], "sparknlp.annotator.audio": [[5, 0, 0, "-", "hubert_for_ctc"], [7, 0, 0, "-", "wav2vec2_for_ctc"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, 1, 1, "", "HubertForCTC"]], "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC": [[5, 2, 1, "", "loadSavedModel"], [5, 2, 1, "", "pretrained"], [5, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, 1, 1, "", "Wav2Vec2ForCTC"]], "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[7, 2, 1, "", "loadSavedModel"], [7, 2, 1, "", "pretrained"], [7, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.chunk2_doc": [[8, 1, 1, "", "Chunk2Doc"]], "sparknlp.annotator.chunker": [[9, 1, 1, "", "Chunker"]], "sparknlp.annotator.chunker.Chunker": [[9, 2, 1, "", "setRegexParsers"]], "sparknlp.annotator.classifier_dl": [[10, 0, 0, "-", "albert_for_question_answering"], [11, 0, 0, "-", "albert_for_sequence_classification"], [12, 0, 0, "-", "albert_for_token_classification"], [13, 0, 0, "-", "bert_for_question_answering"], [14, 0, 0, "-", "bert_for_sequence_classification"], [15, 0, 0, "-", "bert_for_token_classification"], [16, 0, 0, "-", "camembert_for_question_answering"], [17, 0, 0, "-", "camembert_for_sequence_classification"], [18, 0, 0, "-", "camembert_for_token_classification"], [19, 0, 0, "-", "classifier_dl"], [20, 0, 0, "-", "deberta_for_question_answering"], [21, 0, 0, "-", "deberta_for_sequence_classification"], [22, 0, 0, "-", "deberta_for_token_classification"], [23, 0, 0, "-", "distil_bert_for_question_answering"], [24, 0, 0, "-", "distil_bert_for_sequence_classification"], [25, 0, 0, "-", "distil_bert_for_token_classification"], [27, 0, 0, "-", "longformer_for_question_answering"], [28, 0, 0, "-", "longformer_for_sequence_classification"], [29, 0, 0, "-", "longformer_for_token_classification"], [30, 0, 0, "-", "multi_classifier_dl"], [31, 0, 0, "-", "roberta_for_question_answering"], [32, 0, 0, "-", "roberta_for_sequence_classification"], [33, 0, 0, "-", "roberta_for_token_classification"], [34, 0, 0, "-", "sentiment_dl"], [35, 0, 0, "-", "tapas_for_question_answering"], [36, 0, 0, "-", "xlm_roberta_for_question_answering"], [37, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [38, 0, 0, "-", "xlm_roberta_for_token_classification"], [39, 0, 0, "-", "xlnet_for_sequence_classification"], [40, 0, 0, "-", "xlnet_for_token_classification"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, 1, 1, "", "AlbertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[10, 2, 1, "", "loadSavedModel"], [10, 2, 1, "", "pretrained"], [10, 2, 1, "", "setConfigProtoBytes"], [10, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, 1, 1, "", "AlbertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[11, 2, 1, "", "getClasses"], [11, 2, 1, "", "loadSavedModel"], [11, 2, 1, "", "pretrained"], [11, 2, 1, "", "setCoalesceSentences"], [11, 2, 1, "", "setConfigProtoBytes"], [11, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, 1, 1, "", "AlbertForTokenClassification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[12, 2, 1, "", "getClasses"], [12, 2, 1, "", "loadSavedModel"], [12, 2, 1, "", "pretrained"], [12, 2, 1, "", "setConfigProtoBytes"], [12, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, 1, 1, "", "BertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[13, 2, 1, "", "loadSavedModel"], [13, 2, 1, "", "pretrained"], [13, 2, 1, "", "setConfigProtoBytes"], [13, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, 1, 1, "", "BertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[14, 2, 1, "", "getClasses"], [14, 2, 1, "", "loadSavedModel"], [14, 2, 1, "", "pretrained"], [14, 2, 1, "", "setCoalesceSentences"], [14, 2, 1, "", "setConfigProtoBytes"], [14, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, 1, 1, "", "BertForTokenClassification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[15, 2, 1, "", "getClasses"], [15, 2, 1, "", "loadSavedModel"], [15, 2, 1, "", "pretrained"], [15, 2, 1, "", "setConfigProtoBytes"], [15, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[16, 1, 1, "", "CamemBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering": [[16, 2, 1, "", "loadSavedModel"], [16, 2, 1, "", "pretrained"], [16, 2, 1, "", "setConfigProtoBytes"], [16, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[17, 1, 1, "", "CamemBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification": [[17, 2, 1, "", "getClasses"], [17, 2, 1, "", "loadSavedModel"], [17, 2, 1, "", "pretrained"], [17, 2, 1, "", "setCoalesceSentences"], [17, 2, 1, "", "setConfigProtoBytes"], [17, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[18, 1, 1, "", "CamemBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[18, 2, 1, "", "getClasses"], [18, 2, 1, "", "loadSavedModel"], [18, 2, 1, "", "pretrained"], [18, 2, 1, "", "setConfigProtoBytes"], [18, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[19, 1, 1, "", "ClassifierDLApproach"], [19, 1, 1, "", "ClassifierDLModel"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[19, 2, 1, "", "setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[20, 1, 1, "", "DeBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[20, 2, 1, "", "loadSavedModel"], [20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setConfigProtoBytes"], [20, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[21, 1, 1, "", "DeBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[21, 2, 1, "", "getClasses"], [21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setCoalesceSentences"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[22, 1, 1, "", "DeBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[22, 2, 1, "", "getClasses"], [22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[23, 1, 1, "", "DistilBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[24, 1, 1, "", "DistilBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[24, 2, 1, "", "getClasses"], [24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setCoalesceSentences"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[25, 1, 1, "", "DistilBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[25, 2, 1, "", "getClasses"], [25, 2, 1, "", "loadSavedModel"], [25, 2, 1, "", "pretrained"], [25, 2, 1, "", "setConfigProtoBytes"], [25, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[27, 1, 1, "", "LongformerForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[27, 2, 1, "", "loadSavedModel"], [27, 2, 1, "", "pretrained"], [27, 2, 1, "", "setConfigProtoBytes"], [27, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[28, 1, 1, "", "LongformerForSequenceClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[28, 2, 1, "", "getClasses"], [28, 2, 1, "", "loadSavedModel"], [28, 2, 1, "", "pretrained"], [28, 2, 1, "", "setCoalesceSentences"], [28, 2, 1, "", "setConfigProtoBytes"], [28, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[29, 1, 1, "", "LongformerForTokenClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[29, 2, 1, "", "getClasses"], [29, 2, 1, "", "loadSavedModel"], [29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[30, 1, 1, "", "MultiClassifierDLApproach"], [30, 1, 1, "", "MultiClassifierDLModel"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[30, 2, 1, "", "setThreshold"], [30, 2, 1, "", "setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setThreshold"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[31, 1, 1, "", "RoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[31, 2, 1, "", "loadSavedModel"], [31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[32, 1, 1, "", "RoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[32, 2, 1, "", "getClasses"], [32, 2, 1, "", "loadSavedModel"], [32, 2, 1, "", "pretrained"], [32, 2, 1, "", "setCoalesceSentences"], [32, 2, 1, "", "setConfigProtoBytes"], [32, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[33, 1, 1, "", "RoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[33, 2, 1, "", "getClasses"], [33, 2, 1, "", "loadSavedModel"], [33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[34, 1, 1, "", "SentimentDLApproach"], [34, 1, 1, "", "SentimentDLModel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[34, 2, 1, "", "setDropout"], [34, 2, 1, "", "setThreshold"], [34, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[34, 2, 1, "", "pretrained"], [34, 2, 1, "", "setConfigProtoBytes"], [34, 2, 1, "", "setThreshold"], [34, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[35, 1, 1, "", "TapasForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[35, 2, 1, "", "loadSavedModel"], [35, 2, 1, "", "pretrained"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[36, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[36, 2, 1, "", "loadSavedModel"], [36, 2, 1, "", "pretrained"], [36, 2, 1, "", "setConfigProtoBytes"], [36, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[37, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[37, 2, 1, "", "getClasses"], [37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"], [37, 2, 1, "", "setCoalesceSentences"], [37, 2, 1, "", "setConfigProtoBytes"], [37, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[38, 1, 1, "", "XlmRoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[38, 2, 1, "", "getClasses"], [38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[39, 1, 1, "", "XlnetForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[39, 2, 1, "", "getClasses"], [39, 2, 1, "", "loadSavedModel"], [39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setCoalesceSentences"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[40, 1, 1, "", "XlnetForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[40, 2, 1, "", "getClasses"], [40, 2, 1, "", "loadSavedModel"], [40, 2, 1, "", "pretrained"], [40, 2, 1, "", "setConfigProtoBytes"], [40, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.coref": [[42, 0, 0, "-", "spanbert_coref"]], "sparknlp.annotator.coref.spanbert_coref": [[42, 1, 1, "", "SpanBertCorefModel"]], "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[42, 2, 1, "", "loadSavedModel"], [42, 2, 1, "", "pretrained"], [42, 2, 1, "", "setConfigProtoBytes"], [42, 2, 1, "", "setMaxSegmentLength"], [42, 2, 1, "", "setMaxSentenceLength"], [42, 2, 1, "", "setTextGenre"]], "sparknlp.annotator.cv": [[44, 0, 0, "-", "swin_for_image_classification"], [45, 0, 0, "-", "vit_for_image_classification"]], "sparknlp.annotator.cv.swin_for_image_classification": [[44, 1, 1, "", "SwinForImageClassification"]], "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification": [[44, 2, 1, "", "getClasses"], [44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"], [44, 2, 1, "", "setConfigProtoBytes"], [44, 2, 1, "", "setDoRescale"], [44, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.vit_for_image_classification": [[45, 1, 1, "", "ViTForImageClassification"]], "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[45, 2, 1, "", "getClasses"], [45, 2, 1, "", "loadSavedModel"], [45, 2, 1, "", "pretrained"], [45, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.date2_chunk": [[46, 1, 1, "", "Date2Chunk"]], "sparknlp.annotator.dependency": [[47, 0, 0, "-", "dependency_parser"], [49, 0, 0, "-", "typed_dependency_parser"]], "sparknlp.annotator.dependency.dependency_parser": [[47, 1, 1, "", "DependencyParserApproach"], [47, 1, 1, "", "DependencyParserModel"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[47, 2, 1, "", "setConllU"], [47, 2, 1, "", "setDependencyTreeBank"], [47, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[47, 2, 1, "", "pretrained"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[49, 1, 1, "", "TypedDependencyParserApproach"], [49, 1, 1, "", "TypedDependencyParserModel"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[49, 2, 1, "", "setConll2009"], [49, 2, 1, "", "setConllU"], [49, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[49, 2, 1, "", "pretrained"]], "sparknlp.annotator.document_normalizer": [[50, 1, 1, "", "DocumentNormalizer"]], "sparknlp.annotator.document_normalizer.DocumentNormalizer": [[50, 2, 1, "", "setAction"], [50, 2, 1, "", "setEncoding"], [50, 2, 1, "", "setLowercase"], [50, 2, 1, "", "setPatterns"], [50, 2, 1, "", "setPolicy"], [50, 2, 1, "", "setReplacement"]], "sparknlp.annotator.embeddings": [[51, 0, 0, "-", "albert_embeddings"], [52, 0, 0, "-", "bert_embeddings"], [53, 0, 0, "-", "bert_sentence_embeddings"], [54, 0, 0, "-", "camembert_embeddings"], [55, 0, 0, "-", "chunk_embeddings"], [56, 0, 0, "-", "deberta_embeddings"], [57, 0, 0, "-", "distil_bert_embeddings"], [58, 0, 0, "-", "doc2vec"], [59, 0, 0, "-", "elmo_embeddings"], [61, 0, 0, "-", "longformer_embeddings"], [62, 0, 0, "-", "roberta_embeddings"], [63, 0, 0, "-", "roberta_sentence_embeddings"], [64, 0, 0, "-", "sentence_embeddings"], [65, 0, 0, "-", "universal_sentence_encoder"], [66, 0, 0, "-", "word2vec"], [67, 0, 0, "-", "word_embeddings"], [68, 0, 0, "-", "xlm_roberta_embeddings"], [69, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [70, 0, 0, "-", "xlnet_embeddings"]], "sparknlp.annotator.embeddings.albert_embeddings": [[51, 1, 1, "", "AlbertEmbeddings"]], "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[51, 2, 1, "", "loadSavedModel"], [51, 2, 1, "", "pretrained"], [51, 2, 1, "", "setConfigProtoBytes"], [51, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[52, 1, 1, "", "BertEmbeddings"]], "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[52, 2, 1, "", "loadSavedModel"], [52, 2, 1, "", "pretrained"], [52, 2, 1, "", "setConfigProtoBytes"], [52, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[53, 1, 1, "", "BertSentenceEmbeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[53, 2, 1, "", "loadSavedModel"], [53, 2, 1, "", "pretrained"], [53, 2, 1, "", "setConfigProtoBytes"], [53, 2, 1, "", "setIsLong"], [53, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[54, 1, 1, "", "CamemBertEmbeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[54, 2, 1, "", "loadSavedModel"], [54, 2, 1, "", "pretrained"], [54, 2, 1, "", "setConfigProtoBytes"], [54, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[55, 1, 1, "", "ChunkEmbeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[55, 2, 1, "", "setPoolingStrategy"], [55, 2, 1, "", "setSkipOOV"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[56, 1, 1, "", "DeBertaEmbeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[56, 2, 1, "", "loadSavedModel"], [56, 2, 1, "", "pretrained"], [56, 2, 1, "", "setConfigProtoBytes"], [56, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[57, 1, 1, "", "DistilBertEmbeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[57, 2, 1, "", "loadSavedModel"], [57, 2, 1, "", "pretrained"], [57, 2, 1, "", "setConfigProtoBytes"], [57, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.doc2vec": [[58, 1, 1, "", "Doc2VecApproach"], [58, 1, 1, "", "Doc2VecModel"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[58, 2, 1, "", "setMaxIter"], [58, 2, 1, "", "setMaxSentenceLength"], [58, 2, 1, "", "setMinCount"], [58, 2, 1, "", "setNumPartitions"], [58, 2, 1, "", "setSeed"], [58, 2, 1, "", "setStepSize"], [58, 2, 1, "", "setVectorSize"], [58, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[58, 2, 1, "", "pretrained"], [58, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[59, 1, 1, "", "ElmoEmbeddings"]], "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[59, 2, 1, "", "loadSavedModel"], [59, 2, 1, "", "pretrained"], [59, 2, 1, "", "setBatchSize"], [59, 2, 1, "", "setConfigProtoBytes"], [59, 2, 1, "", "setPoolingLayer"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[61, 1, 1, "", "LongformerEmbeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[61, 2, 1, "", "loadSavedModel"], [61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setConfigProtoBytes"], [61, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[62, 1, 1, "", "RoBertaEmbeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[62, 2, 1, "", "loadSavedModel"], [62, 2, 1, "", "pretrained"], [62, 2, 1, "", "setConfigProtoBytes"], [62, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[63, 1, 1, "", "RoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[63, 2, 1, "", "loadSavedModel"], [63, 2, 1, "", "pretrained"], [63, 2, 1, "", "setConfigProtoBytes"], [63, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[64, 1, 1, "", "SentenceEmbeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[64, 2, 1, "", "setPoolingStrategy"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[65, 1, 1, "", "UniversalSentenceEncoder"]], "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[65, 2, 1, "", "loadSavedModel"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setConfigProtoBytes"], [65, 2, 1, "", "setLoadSP"]], "sparknlp.annotator.embeddings.word2vec": [[66, 1, 1, "", "Word2VecApproach"], [66, 1, 1, "", "Word2VecModel"]], "sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[66, 2, 1, "", "setMaxIter"], [66, 2, 1, "", "setMaxSentenceLength"], [66, 2, 1, "", "setMinCount"], [66, 2, 1, "", "setNumPartitions"], [66, 2, 1, "", "setSeed"], [66, 2, 1, "", "setStepSize"], [66, 2, 1, "", "setVectorSize"], [66, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[66, 2, 1, "", "pretrained"], [66, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[67, 1, 1, "", "WordEmbeddings"], [67, 1, 1, "", "WordEmbeddingsModel"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[67, 2, 1, "", "setReadCacheSize"], [67, 2, 1, "", "setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[67, 2, 1, "", "loadStorage"], [67, 2, 1, "", "overallCoverage"], [67, 2, 1, "", "pretrained"], [67, 2, 1, "", "setReadCacheSize"], [67, 2, 1, "", "withCoverageColumn"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[68, 1, 1, "", "XlmRoBertaEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[68, 2, 1, "", "loadSavedModel"], [68, 2, 1, "", "pretrained"], [68, 2, 1, "", "setConfigProtoBytes"], [68, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[69, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[69, 2, 1, "", "loadSavedModel"], [69, 2, 1, "", "pretrained"], [69, 2, 1, "", "setConfigProtoBytes"], [69, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[70, 1, 1, "", "XlnetEmbeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[70, 2, 1, "", "loadSavedModel"], [70, 2, 1, "", "pretrained"], [70, 2, 1, "", "setConfigProtoBytes"], [70, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.er": [[71, 0, 0, "-", "entity_ruler"]], "sparknlp.annotator.er.entity_ruler": [[71, 1, 1, "", "EntityRulerApproach"], [71, 1, 1, "", "EntityRulerModel"]], "sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[71, 2, 1, "", "setAlphabetResource"], [71, 2, 1, "", "setEnablePatternRegex"], [71, 2, 1, "", "setPatternsResource"], [71, 2, 1, "", "setSentenceMatch"], [71, 2, 1, "", "setUseStorage"]], "sparknlp.annotator.graph_extraction": [[73, 1, 1, "", "GraphExtraction"]], "sparknlp.annotator.graph_extraction.GraphExtraction": [[73, 2, 1, "", "setDelimiter"], [73, 2, 1, "", "setDependencyParserModel"], [73, 2, 1, "", "setEntityTypes"], [73, 2, 1, "", "setExplodeEntities"], [73, 2, 1, "", "setIncludeEdges"], [73, 2, 1, "", "setMaxSentenceSize"], [73, 2, 1, "", "setMergeEntities"], [73, 2, 1, "", "setMergeEntitiesIOBFormat"], [73, 2, 1, "", "setMinSentenceSize"], [73, 2, 1, "", "setPosModel"], [73, 2, 1, "", "setRelationshipTypes"], [73, 2, 1, "", "setRootTokens"], [73, 2, 1, "", "setTypedDependencyParserModel"]], "sparknlp.annotator.keyword_extraction": [[76, 0, 0, "-", "yake_keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[76, 1, 1, "", "YakeKeywordExtraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[76, 2, 1, "", "getStopWords"], [76, 2, 1, "", "loadDefaultStopWords"], [76, 2, 1, "", "setMaxNGrams"], [76, 2, 1, "", "setMinNGrams"], [76, 2, 1, "", "setNKeywords"], [76, 2, 1, "", "setStopWords"], [76, 2, 1, "", "setThreshold"], [76, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.ld_dl": [[78, 0, 0, "-", "language_detector_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[78, 1, 1, "", "LanguageDetectorDL"]], "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[78, 2, 1, "", "pretrained"], [78, 2, 1, "", "setCoalesceSentences"], [78, 2, 1, "", "setConfigProtoBytes"], [78, 2, 1, "", "setThreshold"], [78, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.lemmatizer": [[79, 1, 1, "", "Lemmatizer"], [79, 1, 1, "", "LemmatizerModel"]], "sparknlp.annotator.lemmatizer.Lemmatizer": [[79, 2, 1, "", "setDictionary"], [79, 2, 1, "", "setFormCol"], [79, 2, 1, "", "setLemmaCol"]], "sparknlp.annotator.lemmatizer.LemmatizerModel": [[79, 2, 1, "", "pretrained"]], "sparknlp.annotator.matcher": [[80, 0, 0, "-", "big_text_matcher"], [81, 0, 0, "-", "date_matcher"], [83, 0, 0, "-", "multi_date_matcher"], [84, 0, 0, "-", "regex_matcher"], [85, 0, 0, "-", "text_matcher"]], "sparknlp.annotator.matcher.big_text_matcher": [[80, 1, 1, "", "BigTextMatcher"], [80, 1, 1, "", "BigTextMatcherModel"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[80, 2, 1, "", "setCaseSensitive"], [80, 2, 1, "", "setEntities"], [80, 2, 1, "", "setMergeOverlapping"], [80, 2, 1, "", "setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[80, 2, 1, "", "loadStorage"], [80, 2, 1, "", "pretrained"], [80, 2, 1, "", "setCaseSensitive"], [80, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.date_matcher": [[81, 1, 1, "", "DateMatcher"], [81, 1, 1, "", "DateMatcherUtils"]], "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[81, 2, 1, "", "setAnchorDateDay"], [81, 2, 1, "", "setAnchorDateMonth"], [81, 2, 1, "", "setAnchorDateYear"], [81, 2, 1, "", "setDefaultDayWhenMissing"], [81, 2, 1, "", "setInputFormats"], [81, 2, 1, "", "setOutputFormat"], [81, 2, 1, "", "setReadMonthFirst"]], "sparknlp.annotator.matcher.multi_date_matcher": [[83, 1, 1, "", "MultiDateMatcher"]], "sparknlp.annotator.matcher.regex_matcher": [[84, 1, 1, "", "RegexMatcher"], [84, 1, 1, "", "RegexMatcherModel"]], "sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[84, 2, 1, "", "setDelimiter"], [84, 2, 1, "", "setExternalRules"], [84, 2, 1, "", "setRules"], [84, 2, 1, "", "setStrategy"]], "sparknlp.annotator.matcher.text_matcher": [[85, 1, 1, "", "TextMatcher"], [85, 1, 1, "", "TextMatcherModel"]], "sparknlp.annotator.matcher.text_matcher.TextMatcher": [[85, 2, 1, "", "setBuildFromTokens"], [85, 2, 1, "", "setCaseSensitive"], [85, 2, 1, "", "setEntities"], [85, 2, 1, "", "setEntityValue"], [85, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[85, 2, 1, "", "pretrained"], [85, 2, 1, "", "setBuildFromTokens"], [85, 2, 1, "", "setEntityValue"], [85, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.n_gram_generator": [[86, 1, 1, "", "NGramGenerator"]], "sparknlp.annotator.n_gram_generator.NGramGenerator": [[86, 2, 1, "", "setDelimiter"], [86, 2, 1, "", "setEnableCumulative"], [86, 2, 1, "", "setN"]], "sparknlp.annotator.ner": [[88, 0, 0, "-", "ner_approach"], [89, 0, 0, "-", "ner_converter"], [90, 0, 0, "-", "ner_crf"], [91, 0, 0, "-", "ner_dl"], [92, 0, 0, "-", "ner_overwriter"], [93, 0, 0, "-", "zero_shot_ner_model"]], "sparknlp.annotator.ner.ner_approach": [[88, 1, 1, "", "NerApproach"]], "sparknlp.annotator.ner.ner_approach.NerApproach": [[88, 2, 1, "", "getLabelColumn"], [88, 2, 1, "", "setEntities"], [88, 2, 1, "", "setLabelColumn"], [88, 2, 1, "", "setMaxEpochs"], [88, 2, 1, "", "setMinEpochs"], [88, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.ner.ner_converter": [[89, 1, 1, "", "NerConverter"]], "sparknlp.annotator.ner.ner_converter.NerConverter": [[89, 2, 1, "", "setPreservePosition"], [89, 2, 1, "", "setWhiteList"]], "sparknlp.annotator.ner.ner_crf": [[90, 1, 1, "", "NerCrfApproach"], [90, 1, 1, "", "NerCrfModel"]], "sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[90, 2, 1, "", "setC0"], [90, 2, 1, "", "setExternalFeatures"], [90, 2, 1, "", "setIncludeConfidence"], [90, 2, 1, "", "setL2"], [90, 2, 1, "", "setLossEps"], [90, 2, 1, "", "setMinW"], [90, 2, 1, "", "setVerbose"]], "sparknlp.annotator.ner.ner_crf.NerCrfModel": [[90, 2, 1, "", "pretrained"], [90, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_dl": [[91, 1, 1, "", "NerDLApproach"], [91, 1, 1, "", "NerDLModel"]], "sparknlp.annotator.ner.ner_dl.NerDLApproach": [[91, 2, 1, "", "setBatchSize"], [91, 2, 1, "", "setBestModelMetric"], [91, 2, 1, "", "setConfigProtoBytes"], [91, 2, 1, "", "setDropout"], [91, 2, 1, "", "setEnableMemoryOptimizer"], [91, 2, 1, "", "setGraphFolder"], [91, 2, 1, "", "setIncludeAllConfidenceScores"], [91, 2, 1, "", "setIncludeConfidence"], [91, 2, 1, "", "setLr"], [91, 2, 1, "", "setPo"], [91, 2, 1, "", "setUseBestModel"], [91, 2, 1, "", "setUseContrib"]], "sparknlp.annotator.ner.ner_dl.NerDLModel": [[91, 2, 1, "", "pretrained"], [91, 2, 1, "", "setConfigProtoBytes"], [91, 2, 1, "", "setIncludeAllConfidenceScores"], [91, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_overwriter": [[92, 1, 1, "", "NerOverwriter"]], "sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[92, 2, 1, "", "setNerWords"], [92, 2, 1, "", "setNewNerEntity"], [92, 2, 1, "", "setReplaceEntities"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[93, 1, 1, "", "ZeroShotNerModel"]], "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel": [[93, 2, 1, "", "getClasses"], [93, 2, 1, "", "load"], [93, 2, 1, "", "pretrained"], [93, 2, 1, "", "setEntityDefinitions"], [93, 2, 1, "", "setPredictionThreshold"]], "sparknlp.annotator.normalizer": [[94, 1, 1, "", "Normalizer"], [94, 1, 1, "", "NormalizerModel"]], "sparknlp.annotator.normalizer.Normalizer": [[94, 2, 1, "", "setCleanupPatterns"], [94, 2, 1, "", "setLowercase"], [94, 2, 1, "", "setMaxLength"], [94, 2, 1, "", "setMinLength"], [94, 2, 1, "", "setSlangDictionary"]], "sparknlp.annotator.param": [[95, 0, 0, "-", "classifier_encoder"], [96, 0, 0, "-", "evaluation_dl_params"]], "sparknlp.annotator.param.classifier_encoder": [[95, 1, 1, "", "ClassifierEncoder"]], "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[95, 2, 1, "", "setBatchSize"], [95, 2, 1, "", "setConfigProtoBytes"], [95, 2, 1, "", "setLabelColumn"], [95, 2, 1, "", "setLr"], [95, 2, 1, "", "setMaxEpochs"], [95, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.param.evaluation_dl_params": [[96, 1, 1, "", "EvaluationDLParams"]], "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[96, 2, 1, "", "setEnableOutputLogs"], [96, 2, 1, "", "setEvaluationLogExtended"], [96, 2, 1, "", "setOutputLogsPath"], [96, 2, 1, "", "setTestDataset"], [96, 2, 1, "", "setValidationSplit"], [96, 2, 1, "", "setVerbose"]], "sparknlp.annotator.pos": [[99, 0, 0, "-", "perceptron"]], "sparknlp.annotator.pos.perceptron": [[99, 1, 1, "", "PerceptronApproach"], [99, 1, 1, "", "PerceptronModel"]], "sparknlp.annotator.pos.perceptron.PerceptronApproach": [[99, 2, 1, "", "getNIterations"], [99, 2, 1, "", "setIterations"], [99, 2, 1, "", "setPosColumn"]], "sparknlp.annotator.pos.perceptron.PerceptronModel": [[99, 2, 1, "", "pretrained"]], "sparknlp.annotator.sentence": [[101, 0, 0, "-", "sentence_detector"], [102, 0, 0, "-", "sentence_detector_dl"]], "sparknlp.annotator.sentence.sentence_detector": [[101, 1, 1, "", "SentenceDetector"], [101, 1, 1, "", "SentenceDetectorParams"]], "sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[101, 2, 1, "", "setCustomBounds"], [101, 2, 1, "", "setCustomBoundsStrategy"], [101, 2, 1, "", "setDetectLists"], [101, 2, 1, "", "setExplodeSentences"], [101, 2, 1, "", "setMaxLength"], [101, 2, 1, "", "setMinLength"], [101, 2, 1, "", "setSplitLength"], [101, 2, 1, "", "setUseAbbreviations"], [101, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[102, 1, 1, "", "SentenceDetectorDLApproach"], [102, 1, 1, "", "SentenceDetectorDLModel"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[102, 2, 1, "", "setEpochsNumber"], [102, 2, 1, "", "setExplodeSentences"], [102, 2, 1, "", "setImpossiblePenultimates"], [102, 2, 1, "", "setModel"], [102, 2, 1, "", "setOutputLogsPath"], [102, 2, 1, "", "setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[102, 2, 1, "", "pretrained"], [102, 2, 1, "", "setCustomBounds"], [102, 2, 1, "", "setExplodeSentences"], [102, 2, 1, "", "setImpossiblePenultimates"], [102, 2, 1, "", "setMaxLength"], [102, 2, 1, "", "setMinLength"], [102, 2, 1, "", "setModel"], [102, 2, 1, "", "setSplitLength"], [102, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentiment": [[104, 0, 0, "-", "sentiment_detector"], [105, 0, 0, "-", "vivekn_sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[104, 1, 1, "", "SentimentDetector"], [104, 1, 1, "", "SentimentDetectorModel"]], "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[104, 2, 1, "", "setDictionary"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[105, 1, 1, "", "ViveknSentimentApproach"], [105, 1, 1, "", "ViveknSentimentModel"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[105, 2, 1, "", "setPruneCorpus"], [105, 2, 1, "", "setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[105, 2, 1, "", "pretrained"]], "sparknlp.annotator.seq2seq": [[106, 0, 0, "-", "gpt2_transformer"], [108, 0, 0, "-", "marian_transformer"], [109, 0, 0, "-", "t5_transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[106, 1, 1, "", "GPT2Transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[106, 2, 1, "", "loadSavedModel"], [106, 2, 1, "", "pretrained"], [106, 2, 1, "", "setConfigProtoBytes"], [106, 2, 1, "", "setDoSample"], [106, 2, 1, "", "setIgnoreTokenIds"], [106, 2, 1, "", "setMaxOutputLength"], [106, 2, 1, "", "setMinOutputLength"], [106, 2, 1, "", "setNoRepeatNgramSize"], [106, 2, 1, "", "setRepetitionPenalty"], [106, 2, 1, "", "setTask"], [106, 2, 1, "", "setTemperature"], [106, 2, 1, "", "setTopK"], [106, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.marian_transformer": [[108, 1, 1, "", "MarianTransformer"]], "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[108, 2, 1, "", "loadSavedModel"], [108, 2, 1, "", "pretrained"], [108, 2, 1, "", "setConfigProtoBytes"], [108, 2, 1, "", "setIgnoreTokenIds"], [108, 2, 1, "", "setLangId"], [108, 2, 1, "", "setMaxInputLength"], [108, 2, 1, "", "setMaxOutputLength"]], "sparknlp.annotator.seq2seq.t5_transformer": [[109, 1, 1, "", "T5Transformer"]], "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[109, 2, 1, "", "loadSavedModel"], [109, 2, 1, "", "pretrained"], [109, 2, 1, "", "setConfigProtoBytes"], [109, 2, 1, "", "setDoSample"], [109, 2, 1, "", "setIgnoreTokenIds"], [109, 2, 1, "", "setMaxOutputLength"], [109, 2, 1, "", "setMinOutputLength"], [109, 2, 1, "", "setNoRepeatNgramSize"], [109, 2, 1, "", "setRepetitionPenalty"], [109, 2, 1, "", "setTask"], [109, 2, 1, "", "setTemperature"], [109, 2, 1, "", "setTopK"], [109, 2, 1, "", "setTopP"]], "sparknlp.annotator.spell_check": [[110, 0, 0, "-", "context_spell_checker"], [112, 0, 0, "-", "norvig_sweeting"], [113, 0, 0, "-", "symmetric_delete"]], "sparknlp.annotator.spell_check.context_spell_checker": [[110, 1, 1, "", "ContextSpellCheckerApproach"], [110, 1, 1, "", "ContextSpellCheckerModel"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[110, 2, 1, "", "addRegexClass"], [110, 2, 1, "", "addVocabClass"], [110, 2, 1, "", "setBatchSize"], [110, 2, 1, "", "setCaseStrategy"], [110, 2, 1, "", "setClassCount"], [110, 2, 1, "", "setCompoundCount"], [110, 2, 1, "", "setConfigProtoBytes"], [110, 2, 1, "", "setEpochs"], [110, 2, 1, "", "setErrorThreshold"], [110, 2, 1, "", "setFinalRate"], [110, 2, 1, "", "setGraphFolder"], [110, 2, 1, "", "setInitialRate"], [110, 2, 1, "", "setLanguageModelClasses"], [110, 2, 1, "", "setMaxCandidates"], [110, 2, 1, "", "setMaxSentLen"], [110, 2, 1, "", "setMaxWindowLen"], [110, 2, 1, "", "setMinCount"], [110, 2, 1, "", "setTradeoff"], [110, 2, 1, "", "setValidationFraction"], [110, 2, 1, "", "setWeightedDistPath"], [110, 2, 1, "", "setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[110, 2, 1, "", "getWordClasses"], [110, 2, 1, "", "pretrained"], [110, 2, 1, "", "setCaseStrategy"], [110, 2, 1, "", "setClasses"], [110, 2, 1, "", "setCompareLowcase"], [110, 2, 1, "", "setConfigProtoBytes"], [110, 2, 1, "", "setCorrectSymbols"], [110, 2, 1, "", "setErrorThreshold"], [110, 2, 1, "", "setGamma"], [110, 2, 1, "", "setIdsVocab"], [110, 2, 1, "", "setMaxCandidates"], [110, 2, 1, "", "setMaxWindowLen"], [110, 2, 1, "", "setTradeoff"], [110, 2, 1, "", "setVocabFreq"], [110, 2, 1, "", "setVocabIds"], [110, 2, 1, "", "setWeights"], [110, 2, 1, "", "setWordMaxDistance"], [110, 2, 1, "", "updateRegexClass"], [110, 2, 1, "", "updateVocabClass"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[112, 1, 1, "", "NorvigSweetingApproach"], [112, 1, 1, "", "NorvigSweetingModel"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[112, 2, 1, "", "setCaseSensitive"], [112, 2, 1, "", "setDictionary"], [112, 2, 1, "", "setDoubleVariants"], [112, 2, 1, "", "setFrequencyPriority"], [112, 2, 1, "", "setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[112, 2, 1, "", "pretrained"]], "sparknlp.annotator.spell_check.symmetric_delete": [[113, 1, 1, "", "SymmetricDeleteApproach"], [113, 1, 1, "", "SymmetricDeleteModel"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[113, 2, 1, "", "setDeletesThreshold"], [113, 2, 1, "", "setDictionary"], [113, 2, 1, "", "setFrequencyThreshold"], [113, 2, 1, "", "setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[113, 2, 1, "", "pretrained"]], "sparknlp.annotator.stemmer": [[114, 1, 1, "", "Stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[115, 1, 1, "", "StopWordsCleaner"]], "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[115, 2, 1, "", "loadDefaultStopWords"], [115, 2, 1, "", "pretrained"], [115, 2, 1, "", "setCaseSensitive"], [115, 2, 1, "", "setLocale"], [115, 2, 1, "", "setStopWords"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[116, 1, 1, "", "TFNerDLGraphBuilder"], [116, 1, 1, "", "TFNerDLGraphBuilderModel"]], "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[116, 2, 1, "", "getGraphFile"], [116, 2, 1, "", "getGraphFolder"], [116, 2, 1, "", "getHiddenUnitsNumber"], [116, 2, 1, "", "getInputCols"], [116, 2, 1, "", "getLabelColumn"], [116, 2, 1, "", "setGraphFile"], [116, 2, 1, "", "setGraphFolder"], [116, 2, 1, "", "setHiddenUnitsNumber"], [116, 2, 1, "", "setInputCols"], [116, 2, 1, "", "setLabelColumn"]], "sparknlp.annotator.token": [[117, 0, 0, "-", "chunk_tokenizer"], [119, 0, 0, "-", "recursive_tokenizer"], [120, 0, 0, "-", "regex_tokenizer"], [121, 0, 0, "-", "tokenizer"]], "sparknlp.annotator.token.chunk_tokenizer": [[117, 1, 1, "", "ChunkTokenizer"], [117, 1, 1, "", "ChunkTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer": [[119, 1, 1, "", "RecursiveTokenizer"], [119, 1, 1, "", "RecursiveTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[119, 2, 1, "", "setInfixes"], [119, 2, 1, "", "setPrefixes"], [119, 2, 1, "", "setSuffixes"], [119, 2, 1, "", "setWhitelist"]], "sparknlp.annotator.token.regex_tokenizer": [[120, 1, 1, "", "RegexTokenizer"]], "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[120, 2, 1, "", "setMaxLength"], [120, 2, 1, "", "setMinLength"], [120, 2, 1, "", "setPattern"], [120, 2, 1, "", "setPositionalMask"], [120, 2, 1, "", "setPreservePosition"], [120, 2, 1, "", "setToLowercase"], [120, 2, 1, "", "setTrimWhitespace"]], "sparknlp.annotator.token.tokenizer": [[121, 1, 1, "", "Tokenizer"], [121, 1, 1, "", "TokenizerModel"]], "sparknlp.annotator.token.tokenizer.Tokenizer": [[121, 2, 1, "", "addContextChars"], [121, 2, 1, "", "addException"], [121, 2, 1, "", "addInfixPattern"], [121, 2, 1, "", "addSplitChars"], [121, 2, 1, "", "getCaseSensitiveExceptions"], [121, 2, 1, "", "getContextChars"], [121, 2, 1, "", "getExceptions"], [121, 2, 1, "", "getInfixPatterns"], [121, 2, 1, "", "getPrefixPattern"], [121, 2, 1, "", "getSplitChars"], [121, 2, 1, "", "getSuffixPattern"], [121, 2, 1, "", "setCaseSensitiveExceptions"], [121, 2, 1, "", "setContextChars"], [121, 2, 1, "", "setExceptions"], [121, 2, 1, "", "setExceptionsPath"], [121, 2, 1, "", "setInfixPatterns"], [121, 2, 1, "", "setMaxLength"], [121, 2, 1, "", "setMinLength"], [121, 2, 1, "", "setPrefixPattern"], [121, 2, 1, "", "setSplitChars"], [121, 2, 1, "", "setSplitPattern"], [121, 2, 1, "", "setSuffixPattern"], [121, 2, 1, "", "setTargetPattern"]], "sparknlp.annotator.token.tokenizer.TokenizerModel": [[121, 2, 1, "", "addSplitChars"], [121, 2, 1, "", "pretrained"], [121, 2, 1, "", "setSplitChars"], [121, 2, 1, "", "setSplitPattern"]], "sparknlp.annotator.ws": [[123, 0, 0, "-", "word_segmenter"]], "sparknlp.annotator.ws.word_segmenter": [[123, 1, 1, "", "WordSegmenterApproach"], [123, 1, 1, "", "WordSegmenterModel"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[123, 2, 1, "", "getAmbiguityThreshold"], [123, 2, 1, "", "getFrequencyThreshold"], [123, 2, 1, "", "getNIterations"], [123, 2, 1, "", "setAmbiguityThreshold"], [123, 2, 1, "", "setEnableRegexTokenizer"], [123, 2, 1, "", "setFrequencyThreshold"], [123, 2, 1, "", "setNIterations"], [123, 2, 1, "", "setPattern"], [123, 2, 1, "", "setPosColumn"], [123, 2, 1, "", "setToLowercase"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[123, 2, 1, "", "pretrained"], [123, 2, 1, "", "setEnableRegexTokenizer"], [123, 2, 1, "", "setPattern"], [123, 2, 1, "", "setToLowercase"]], "sparknlp.base": [[124, 0, 0, "-", "audio_assembler"], [125, 0, 0, "-", "doc2_chunk"], [126, 0, 0, "-", "document_assembler"], [127, 0, 0, "-", "embeddings_finisher"], [128, 0, 0, "-", "finisher"], [129, 0, 0, "-", "graph_finisher"], [130, 0, 0, "-", "has_recursive_fit"], [131, 0, 0, "-", "has_recursive_transform"], [132, 0, 0, "-", "image_assembler"], [134, 0, 0, "-", "light_pipeline"], [135, 0, 0, "-", "multi_document_assembler"], [136, 0, 0, "-", "recursive_pipeline"], [137, 0, 0, "-", "table_assembler"], [138, 0, 0, "-", "token2_chunk"], [139, 0, 0, "-", "token_assembler"]], "sparknlp.base.audio_assembler": [[124, 1, 1, "", "AudioAssembler"]], "sparknlp.base.audio_assembler.AudioAssembler": [[124, 2, 1, "", "getOutputCol"], [124, 2, 1, "", "setInputCol"], [124, 2, 1, "", "setOutputCol"]], "sparknlp.base.doc2_chunk": [[125, 1, 1, "", "Doc2Chunk"]], "sparknlp.base.doc2_chunk.Doc2Chunk": [[125, 2, 1, "", "setChunkCol"], [125, 2, 1, "", "setFailOnMissing"], [125, 2, 1, "", "setIsArray"], [125, 2, 1, "", "setLowerCase"], [125, 2, 1, "", "setStartCol"], [125, 2, 1, "", "setStartColByTokenIndex"]], "sparknlp.base.document_assembler": [[126, 1, 1, "", "DocumentAssembler"]], "sparknlp.base.document_assembler.DocumentAssembler": [[126, 2, 1, "", "getOutputCol"], [126, 2, 1, "", "setCleanupMode"], [126, 2, 1, "", "setIdCol"], [126, 2, 1, "", "setInputCol"], [126, 2, 1, "", "setMetadataCol"], [126, 2, 1, "", "setOutputCol"]], "sparknlp.base.embeddings_finisher": [[127, 1, 1, "", "EmbeddingsFinisher"]], "sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[127, 2, 1, "", "getInputCols"], [127, 2, 1, "", "getOutputCols"], [127, 2, 1, "", "setCleanAnnotations"], [127, 2, 1, "", "setInputCols"], [127, 2, 1, "", "setOutputAsVector"], [127, 2, 1, "", "setOutputCols"]], "sparknlp.base.finisher": [[128, 1, 1, "", "Finisher"]], "sparknlp.base.finisher.Finisher": [[128, 2, 1, "", "getInputCols"], [128, 2, 1, "", "getOutputCols"], [128, 2, 1, "", "setAnnotationSplitSymbol"], [128, 2, 1, "", "setCleanAnnotations"], [128, 2, 1, "", "setIncludeMetadata"], [128, 2, 1, "", "setInputCols"], [128, 2, 1, "", "setOutputAsArray"], [128, 2, 1, "", "setOutputCols"], [128, 2, 1, "", "setParseEmbeddingsVectors"], [128, 2, 1, "", "setValueSplitSymbol"]], "sparknlp.base.graph_finisher": [[129, 1, 1, "", "GraphFinisher"]], "sparknlp.base.graph_finisher.GraphFinisher": [[129, 2, 1, "", "setCleanAnnotations"], [129, 2, 1, "", "setInputCol"], [129, 2, 1, "", "setOutputAsArray"], [129, 2, 1, "", "setOutputCol"]], "sparknlp.base.has_recursive_fit": [[130, 1, 1, "", "HasRecursiveFit"]], "sparknlp.base.has_recursive_transform": [[131, 1, 1, "", "HasRecursiveTransform"]], "sparknlp.base.image_assembler": [[132, 1, 1, "", "ImageAssembler"]], "sparknlp.base.image_assembler.ImageAssembler": [[132, 2, 1, "", "getOutputCol"], [132, 2, 1, "", "setInputCol"], [132, 2, 1, "", "setOutputCol"]], "sparknlp.base.light_pipeline": [[134, 1, 1, "", "LightPipeline"]], "sparknlp.base.light_pipeline.LightPipeline": [[134, 2, 1, "", "annotate"], [134, 2, 1, "", "fullAnnotate"], [134, 2, 1, "", "fullAnnotateImage"], [134, 2, 1, "", "getIgnoreUnsupported"], [134, 2, 1, "", "setIgnoreUnsupported"], [134, 2, 1, "", "transform"]], "sparknlp.base.multi_document_assembler": [[135, 1, 1, "", "MultiDocumentAssembler"]], "sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[135, 2, 1, "", "getOutputCols"], [135, 2, 1, "", "setCleanupMode"], [135, 2, 1, "", "setIdCol"], [135, 2, 1, "", "setInputCols"], [135, 2, 1, "", "setMetadataCol"], [135, 2, 1, "", "setOutputCols"]], "sparknlp.base.recursive_pipeline": [[136, 1, 1, "", "RecursivePipeline"], [136, 1, 1, "", "RecursivePipelineModel"]], "sparknlp.base.table_assembler": [[137, 1, 1, "", "TableAssembler"]], "sparknlp.base.table_assembler.TableAssembler": [[137, 2, 1, "", "setCsvDelimiter"], [137, 2, 1, "", "setEscapeCsvDelimiter"], [137, 2, 1, "", "setInputFormat"]], "sparknlp.base.token2_chunk": [[138, 1, 1, "", "Token2Chunk"]], "sparknlp.base.token_assembler": [[139, 1, 1, "", "TokenAssembler"]], "sparknlp.base.token_assembler.TokenAssembler": [[139, 2, 1, "", "setPreservePosition"]], "sparknlp.common": [[140, 0, 0, "-", "annotator_approach"], [141, 0, 0, "-", "annotator_model"], [142, 0, 0, "-", "annotator_properties"], [143, 0, 0, "-", "annotator_type"], [144, 0, 0, "-", "coverage_result"], [146, 0, 0, "-", "properties"], [147, 0, 0, "-", "read_as"], [148, 0, 0, "-", "recursive_annotator_approach"], [149, 0, 0, "-", "storage"], [150, 0, 0, "-", "utils"]], "sparknlp.common.annotator_approach": [[140, 1, 1, "", "AnnotatorApproach"]], "sparknlp.common.annotator_model": [[141, 1, 1, "", "AnnotatorModel"]], "sparknlp.common.annotator_properties": [[142, 1, 1, "", "AnnotatorProperties"]], "sparknlp.common.annotator_properties.AnnotatorProperties": [[142, 2, 1, "", "getInputCols"], [142, 2, 1, "", "getLazyAnnotator"], [142, 2, 1, "", "getOutputCol"], [142, 2, 1, "", "setInputCols"], [142, 2, 1, "", "setLazyAnnotator"], [142, 2, 1, "", "setOutputCol"]], "sparknlp.common.properties": [[146, 1, 1, "", "HasEmbeddingsProperties"]], "sparknlp.common.properties.HasEmbeddingsProperties": [[146, 2, 1, "", "getDimension"], [146, 2, 1, "", "setDimension"]], "sparknlp.common.read_as": [[147, 1, 1, "", "ReadAs"]], "sparknlp.common.recursive_annotator_approach": [[148, 1, 1, "", "RecursiveAnnotatorApproach"]], "sparknlp.common.utils": [[150, 3, 1, "", "ExternalResource"]], "sparknlp.functions": [[151, 3, 1, "", "explode_annotations_col"], [151, 3, 1, "", "filter_by_annotations_col"], [151, 3, 1, "", "map_annotations"], [151, 3, 1, "", "map_annotations_array"], [151, 3, 1, "", "map_annotations_col"], [151, 3, 1, "", "map_annotations_cols"], [151, 3, 1, "", "map_annotations_strict"]], "sparknlp.internal": [[153, 0, 0, "-", "annotator_java_ml"], [154, 0, 0, "-", "annotator_transformer"], [155, 0, 0, "-", "extended_java_wrapper"], [157, 0, 0, "-", "params_getters_setters"], [158, 0, 0, "-", "recursive"]], "sparknlp.internal.annotator_java_ml": [[153, 1, 1, "", "AnnotatorJavaMLReadable"], [153, 1, 1, "", "AnnotatorJavaMLReader"]], "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[153, 2, 1, "", "read"]], "sparknlp.internal.annotator_transformer": [[154, 1, 1, "", "AnnotatorTransformer"]], "sparknlp.internal.extended_java_wrapper": [[155, 1, 1, "", "ExtendedJavaWrapper"]], "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[155, 2, 1, "", "new_java_array"]], "sparknlp.internal.params_getters_setters": [[157, 1, 1, "", "ParamsGettersSetters"]], "sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[157, 2, 1, "", "getParamValue"], [157, 2, 1, "", "setParamValue"]], "sparknlp.internal.recursive": [[158, 1, 1, "", "RecursiveEstimator"], [158, 1, 1, "", "RecursiveTransformer"]], "sparknlp.internal.recursive.RecursiveEstimator": [[158, 2, 1, "", "fit"]], "sparknlp.logging": [[159, 0, 0, "-", "comet"]], "sparknlp.logging.comet": [[159, 1, 1, "", "CometLogger"]], "sparknlp.logging.comet.CometLogger": [[159, 2, 1, "", "end"], [159, 2, 1, "", "log_asset"], [159, 2, 1, "", "log_asset_data"], [159, 2, 1, "", "log_completed_run"], [159, 2, 1, "", "log_metrics"], [159, 2, 1, "", "log_parameters"], [159, 2, 1, "", "log_pipeline_parameters"], [159, 2, 1, "", "log_visualization"], [159, 2, 1, "", "monitor"]], "sparknlp.pretrained": [[162, 0, 0, "-", "pretrained_pipeline"], [163, 0, 0, "-", "resource_downloader"], [164, 0, 0, "-", "utils"]], "sparknlp.pretrained.pretrained_pipeline": [[162, 1, 1, "", "PretrainedPipeline"]], "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[162, 2, 1, "", "annotate"], [162, 2, 1, "", "fullAnnotate"], [162, 2, 1, "", "fullAnnotateImage"], [162, 2, 1, "", "transform"]], "sparknlp.pretrained.resource_downloader": [[163, 1, 1, "", "ResourceDownloader"]], "sparknlp.pretrained.resource_downloader.ResourceDownloader": [[163, 2, 1, "", "clearCache"], [163, 2, 1, "", "downloadModel"], [163, 2, 1, "", "downloadModelDirectly"], [163, 2, 1, "", "downloadPipeline"], [163, 2, 1, "", "showAvailableAnnotators"], [163, 2, 1, "", "showPublicModels"], [163, 2, 1, "", "showPublicPipelines"], [163, 2, 1, "", "showUnCategorizedResources"]], "sparknlp.training": [[165, 0, 0, "-", "conll"], [166, 0, 0, "-", "conllu"], [168, 0, 0, "-", "pos"], [169, 0, 0, "-", "pub_tator"], [170, 0, 0, "-", "spacy_to_annotation"], [171, 0, 0, "-", "tfgraphs"]], "sparknlp.training.conll": [[165, 1, 1, "", "CoNLL"]], "sparknlp.training.conll.CoNLL": [[165, 2, 1, "", "readDataset"]], "sparknlp.training.conllu": [[166, 1, 1, "", "CoNLLU"]], "sparknlp.training.conllu.CoNLLU": [[166, 2, 1, "", "readDataset"]], "sparknlp.training.pos": [[168, 1, 1, "", "POS"]], "sparknlp.training.pos.POS": [[168, 2, 1, "", "readDataset"]], "sparknlp.training.pub_tator": [[169, 1, 1, "", "PubTator"]], "sparknlp.training.pub_tator.PubTator": [[169, 2, 1, "", "readDataset"]], "sparknlp.training.spacy_to_annotation": [[170, 1, 1, "", "SpacyToAnnotation"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"get": [0, 180], "start": 0, "spark": [0, 1, 175, 180, 184], "nlp": [0, 1, 175, 184], "cheat": 0, "sheet": 0, "requir": 0, "instal": [0, 175], "us": [0, 175, 184], "conda": 0, "virtualenv": 0, "session": 0, "from": 0, "python": 0, "document": 1, "content": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169, 170], "sparknlp": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173], "annot": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 178, 179, 180], "modul": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169, 170, 174], "class": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 102, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169, 170], "annotation_audio": 3, "annotation_imag": 4, "audio": [5, 6, 7], "hubert_for_ctc": 5, "submodul": [6, 26, 41, 43, 48, 60, 72, 74, 75, 77, 82, 87, 98, 100, 103, 107, 111, 118, 122, 133, 145, 152, 156, 160, 161, 167], "wav2vec2_for_ctc": 7, "chunk2_doc": 8, "chunker": 9, "classifier_dl": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "albert_for_question_answ": 10, "albert_for_sequence_classif": 11, "albert_for_token_classif": 12, "bert_for_question_answ": 13, "bert_for_sequence_classif": 14, "bert_for_token_classif": 15, "camembert_for_question_answ": 16, "camembert_for_sequence_classif": 17, "camembert_for_token_classif": 18, "deberta_for_question_answ": 20, "deberta_for_sequence_classif": 21, "deberta_for_token_classif": 22, "distil_bert_for_question_answ": 23, "distil_bert_for_sequence_classif": 24, "distil_bert_for_token_classif": 25, "longformer_for_question_answ": 27, "longformer_for_sequence_classif": 28, "longformer_for_token_classif": 29, "multi_classifier_dl": 30, "roberta_for_question_answ": 31, "roberta_for_sequence_classif": 32, "roberta_for_token_classif": 33, "sentiment_dl": 34, "tapas_for_question_answ": 35, "xlm_roberta_for_question_answ": 36, "xlm_roberta_for_sequence_classif": 37, "xlm_roberta_for_token_classif": 38, "xlnet_for_sequence_classif": 39, "xlnet_for_token_classif": 40, "coref": [41, 42], "spanbert_coref": 42, "cv": [43, 44, 45], "swin_for_image_classif": 44, "vit_for_image_classif": 45, "date2_chunk": 46, "depend": [47, 48, 49], "dependency_pars": 47, "typed_dependency_pars": 49, "document_norm": 50, "embed": [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70], "albert_embed": 51, "bert_embed": 52, "bert_sentence_embed": 53, "camembert_embed": 54, "chunk_embed": 55, "deberta_embed": 56, "distil_bert_embed": 57, "doc2vec": 58, "elmo_embed": 59, "longformer_embed": 61, "roberta_embed": 62, "roberta_sentence_embed": 63, "sentence_embed": 64, "universal_sentence_encod": 65, "word2vec": 66, "word_embed": 67, "xlm_roberta_embed": 68, "xlm_roberta_sentence_embed": 69, "xlnet_embed": 70, "er": [71, 72], "entity_rul": 71, "graph_extract": 73, "subpackag": [74, 152], "keyword_extract": [75, 76], "yake_keyword_extract": 76, "ld_dl": [77, 78], "language_detector_dl": 78, "lemmat": 79, "matcher": [80, 81, 82, 83, 84, 85], "big_text_match": 80, "date_match": 81, "multi_date_match": 83, "regex_match": 84, "text_match": 85, "n_gram_gener": 86, "ner": [87, 88, 89, 90, 91, 92, 93], "ner_approach": 88, "ner_convert": 89, "ner_crf": 90, "ner_dl": 91, "ner_overwrit": 92, "zero_shot_ner_model": 93, "normal": 94, "param": [95, 96, 97], "classifier_encod": 95, "evaluation_dl_param": 96, "po": [98, 99, 168, 185], "perceptron": 99, "sentenc": [100, 101, 102, 180], "sentence_detector": 101, "sentence_detector_dl": 102, "sentiment": [103, 104, 105], "sentiment_detector": 104, "vivekn_senti": 105, "seq2seq": [106, 107, 108, 109], "gpt2_transform": 106, "marian_transform": 108, "t5_transform": 109, "spell_check": [110, 111, 112, 113], "context_spell_check": 110, "norvig_sweet": 112, "symmetric_delet": 113, "stemmer": 114, "stop_words_clean": 115, "tf_ner_dl_graph_build": 116, "token": [117, 118, 119, 120, 121, 180], "chunk_token": 117, "recursive_token": 119, "regex_token": 120, "w": [122, 123], "word_segment": 123, "base": [124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139], "audio_assembl": 124, "doc2_chunk": 125, "document_assembl": 126, "embeddings_finish": 127, "finish": [128, 180], "graph_finish": 129, "has_recursive_fit": 130, "has_recursive_transform": 131, "image_assembl": 132, "light_pipelin": 134, "multi_document_assembl": 135, "recursive_pipelin": 136, "table_assembl": 137, "token2_chunk": 138, "token_assembl": 139, "common": [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 179], "annotator_approach": 140, "annotator_model": 141, "annotator_properti": 142, "annotator_typ": 143, "coverage_result": 144, "properti": 146, "read_a": 147, "recursive_annotator_approach": 148, "storag": 149, "util": [150, 164, 173], "function": [150, 151, 152, 179, 181], "packag": 152, "intern": [153, 154, 155, 156, 157, 158], "annotator_java_ml": 153, "annotator_transform": 154, "extended_java_wrapp": 155, "params_getters_sett": 157, "recurs": 158, "log": [159, 160, 175, 177], "comet": [159, 175], "pretrain": [161, 162, 163, 164, 179, 183, 184], "pretrained_pipelin": 162, "resource_download": 163, "train": [165, 166, 167, 168, 169, 170, 171, 185], "conll": [165, 185], "conllu": [166, 185], "pub_tat": 169, "spacy_to_annot": 170, "tfgraph": 171, "upload_to_hub": 172, "api": 174, "refer": 174, "A": 175, "meta": 175, "machin": [175, 176], "learn": [175, 176], "platform": [175, 176], "pipelin": [175, 180, 183, 184], "paramet": 175, "evalu": 175, "metric": 175, "visual": 175, "run": 175, "an": 175, "offlin": 175, "experi": 175, "mlflow": 176, "lifecycl": 176, "third": 177, "parti": 177, "project": 177, "approach": 179, "model": 179, "note": 179, "avail": [179, 184], "set": 180, "up": 180, "your": 180, "own": 180, "type": 180, "necessari": 180, "import": 180, "construct": 180, "documentassembl": 180, "data": 180, "detect": 180, "out": 180, "put": 180, "all": 180, "togeth": 180, "ml": [180, 184], "helper": 181, "user": 182, "guid": 182, "light": 183, "convert": 183, "pipelinemodel": 183, "download": 184, "As": 184, "lightpipelin": 184, "load": 185, "dataset": 185, "spell": 185, "checker": 185, "pubtat": 185}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Getting Started": [[0, "getting-started"]], "Spark NLP Cheat Sheet": [[0, "spark-nlp-cheat-sheet"]], "Requirements": [[0, "requirements"]], "Installation": [[0, "installation"], [175, "installation"]], "Using Conda": [[0, "using-conda"]], "Using Virtualenv": [[0, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[0, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[1, "spark-nlp-documentation"]], "Content": [[1, "content"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "Module Contents": [[2, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [8, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [42, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [47, "module-contents"], [49, "module-contents"], [50, "module-contents"], [51, "module-contents"], [52, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [73, "module-contents"], [76, "module-contents"], [78, "module-contents"], [79, "module-contents"], [80, "module-contents"], [81, "module-contents"], [83, "module-contents"], [84, "module-contents"], [85, "module-contents"], [86, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [96, "module-contents"], [99, "module-contents"], [101, "module-contents"], [102, "module-contents"], [104, "module-contents"], [105, "module-contents"], [106, "module-contents"], [108, "module-contents"], [109, "module-contents"], [110, "module-contents"], [112, "module-contents"], [113, "module-contents"], [114, "module-contents"], [115, "module-contents"], [116, "module-contents"], [117, "module-contents"], [119, "module-contents"], [120, "module-contents"], [121, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [146, "module-contents"], [147, "module-contents"], [148, "module-contents"], [150, "module-contents"], [151, "module-contents"], [153, "module-contents"], [154, "module-contents"], [155, "module-contents"], [157, "module-contents"], [158, "module-contents"], [159, "module-contents"], [162, "module-contents"], [163, "module-contents"], [165, "module-contents"], [166, "module-contents"], [168, "module-contents"], [169, "module-contents"], [170, "module-contents"]], "Classes": [[2, "classes"], [3, "classes"], [4, "classes"], [5, "classes"], [7, "classes"], [8, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [42, "classes"], [44, "classes"], [45, "classes"], [46, "classes"], [47, "classes"], [49, "classes"], [50, "classes"], [51, "classes"], [52, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [73, "classes"], [76, "classes"], [78, "classes"], [79, "classes"], [80, "classes"], [81, "classes"], [83, "classes"], [84, "classes"], [85, "classes"], [86, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [95, "classes"], [96, "classes"], [99, "classes"], [101, "classes"], [102, "classes"], [104, "classes"], [105, "classes"], [106, "classes"], [108, "classes"], [109, "classes"], [110, "classes"], [112, "classes"], [113, "classes"], [114, "classes"], [115, "classes"], [116, "classes"], [117, "classes"], [119, "classes"], [120, "classes"], [121, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [146, "classes"], [147, "classes"], [148, "classes"], [153, "classes"], [154, "classes"], [155, "classes"], [157, "classes"], [158, "classes"], [159, "classes"], [162, "classes"], [163, "classes"], [165, "classes"], [166, "classes"], [168, "classes"], [169, "classes"], [170, "classes"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "Submodules": [[6, "submodules"], [26, "submodules"], [41, "submodules"], [43, "submodules"], [48, "submodules"], [60, "submodules"], [72, "submodules"], [74, "submodules"], [75, "submodules"], [77, "submodules"], [82, "submodules"], [87, "submodules"], [98, "submodules"], [100, "submodules"], [103, "submodules"], [107, "submodules"], [111, "submodules"], [118, "submodules"], [122, "submodules"], [133, "submodules"], [145, "submodules"], [152, "submodules"], [156, "submodules"], [160, "submodules"], [161, "submodules"], [167, "submodules"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "sparknlp.annotator.chunk2_doc": [[8, "module-sparknlp.annotator.chunk2_doc"]], "sparknlp.annotator.chunker": [[9, "module-sparknlp.annotator.chunker"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[16, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[18, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[19, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[20, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[22, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[23, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[26, "module-sparknlp.annotator.classifier_dl"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[27, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[28, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[29, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[30, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[31, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[32, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[33, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[34, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[35, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[36, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[40, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[41, "module-sparknlp.annotator.coref"]], "sparknlp.annotator.coref.spanbert_coref": [[42, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv": [[43, "module-sparknlp.annotator.cv"]], "sparknlp.annotator.cv.swin_for_image_classification": [[44, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "sparknlp.annotator.cv.vit_for_image_classification": [[45, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "sparknlp.annotator.date2_chunk": [[46, "module-sparknlp.annotator.date2_chunk"]], "sparknlp.annotator.dependency.dependency_parser": [[47, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[48, "module-sparknlp.annotator.dependency"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[49, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "sparknlp.annotator.document_normalizer": [[50, "module-sparknlp.annotator.document_normalizer"]], "sparknlp.annotator.embeddings.albert_embeddings": [[51, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "sparknlp.annotator.embeddings.bert_embeddings": [[52, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[53, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[54, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[55, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[56, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[57, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "sparknlp.annotator.embeddings.doc2vec": [[58, "module-sparknlp.annotator.embeddings.doc2vec"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[59, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[60, "module-sparknlp.annotator.embeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[61, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[62, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[63, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[64, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[65, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "sparknlp.annotator.embeddings.word2vec": [[66, "module-sparknlp.annotator.embeddings.word2vec"]], "sparknlp.annotator.embeddings.word_embeddings": [[67, "module-sparknlp.annotator.embeddings.word_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[68, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[69, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[70, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "sparknlp.annotator.er.entity_ruler": [[71, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[72, "module-sparknlp.annotator.er"]], "sparknlp.annotator.graph_extraction": [[73, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[74, "module-sparknlp.annotator"]], "Subpackages": [[74, "subpackages"], [152, "subpackages"]], "sparknlp.annotator.keyword_extraction": [[75, "module-sparknlp.annotator.keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[76, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[77, "module-sparknlp.annotator.ld_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[78, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "sparknlp.annotator.lemmatizer": [[79, "module-sparknlp.annotator.lemmatizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[80, "module-sparknlp.annotator.matcher.big_text_matcher"]], "sparknlp.annotator.matcher.date_matcher": [[81, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[82, "module-sparknlp.annotator.matcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[83, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "sparknlp.annotator.matcher.regex_matcher": [[84, "module-sparknlp.annotator.matcher.regex_matcher"]], "sparknlp.annotator.matcher.text_matcher": [[85, "module-sparknlp.annotator.matcher.text_matcher"]], "sparknlp.annotator.n_gram_generator": [[86, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[87, "module-sparknlp.annotator.ner"]], "sparknlp.annotator.ner.ner_approach": [[88, "module-sparknlp.annotator.ner.ner_approach"]], "sparknlp.annotator.ner.ner_converter": [[89, "module-sparknlp.annotator.ner.ner_converter"]], "sparknlp.annotator.ner.ner_crf": [[90, "module-sparknlp.annotator.ner.ner_crf"]], "sparknlp.annotator.ner.ner_dl": [[91, "module-sparknlp.annotator.ner.ner_dl"]], "sparknlp.annotator.ner.ner_overwriter": [[92, "module-sparknlp.annotator.ner.ner_overwriter"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[93, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "sparknlp.annotator.normalizer": [[94, "module-sparknlp.annotator.normalizer"]], "sparknlp.annotator.param.classifier_encoder": [[95, "module-sparknlp.annotator.param.classifier_encoder"]], "sparknlp.annotator.param.evaluation_dl_params": [[96, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[97, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[98, "module-sparknlp.annotator.pos"]], "sparknlp.annotator.pos.perceptron": [[99, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[100, "module-sparknlp.annotator.sentence"]], "sparknlp.annotator.sentence.sentence_detector": [[101, "module-sparknlp.annotator.sentence.sentence_detector"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[102, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[103, "module-sparknlp.annotator.sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[104, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[105, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[106, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[107, "module-sparknlp.annotator.seq2seq"]], "sparknlp.annotator.seq2seq.marian_transformer": [[108, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "sparknlp.annotator.seq2seq.t5_transformer": [[109, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "sparknlp.annotator.spell_check.context_spell_checker": [[110, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "sparknlp.annotator.spell_check": [[111, "module-sparknlp.annotator.spell_check"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[112, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "sparknlp.annotator.spell_check.symmetric_delete": [[113, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "sparknlp.annotator.stemmer": [[114, "module-sparknlp.annotator.stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[115, "module-sparknlp.annotator.stop_words_cleaner"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[116, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "sparknlp.annotator.token.chunk_tokenizer": [[117, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[118, "module-sparknlp.annotator.token"]], "sparknlp.annotator.token.recursive_tokenizer": [[119, "module-sparknlp.annotator.token.recursive_tokenizer"]], "sparknlp.annotator.token.regex_tokenizer": [[120, "module-sparknlp.annotator.token.regex_tokenizer"]], "sparknlp.annotator.token.tokenizer": [[121, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[122, "module-sparknlp.annotator.ws"]], "sparknlp.annotator.ws.word_segmenter": [[123, "module-sparknlp.annotator.ws.word_segmenter"]], "sparknlp.base.audio_assembler": [[124, "module-sparknlp.base.audio_assembler"]], "sparknlp.base.doc2_chunk": [[125, "module-sparknlp.base.doc2_chunk"]], "sparknlp.base.document_assembler": [[126, "module-sparknlp.base.document_assembler"]], "sparknlp.base.embeddings_finisher": [[127, "module-sparknlp.base.embeddings_finisher"]], "sparknlp.base.finisher": [[128, "module-sparknlp.base.finisher"]], "sparknlp.base.graph_finisher": [[129, "module-sparknlp.base.graph_finisher"]], "sparknlp.base.has_recursive_fit": [[130, "module-sparknlp.base.has_recursive_fit"]], "sparknlp.base.has_recursive_transform": [[131, "module-sparknlp.base.has_recursive_transform"]], "sparknlp.base.image_assembler": [[132, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[133, "module-sparknlp.base"]], "sparknlp.base.light_pipeline": [[134, "module-sparknlp.base.light_pipeline"]], "sparknlp.base.multi_document_assembler": [[135, "module-sparknlp.base.multi_document_assembler"]], "sparknlp.base.recursive_pipeline": [[136, "module-sparknlp.base.recursive_pipeline"]], "sparknlp.base.table_assembler": [[137, "module-sparknlp.base.table_assembler"]], "sparknlp.base.token2_chunk": [[138, "module-sparknlp.base.token2_chunk"]], "sparknlp.base.token_assembler": [[139, "module-sparknlp.base.token_assembler"]], "sparknlp.common.annotator_approach": [[140, "module-sparknlp.common.annotator_approach"]], "sparknlp.common.annotator_model": [[141, "module-sparknlp.common.annotator_model"]], "sparknlp.common.annotator_properties": [[142, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[143, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[144, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[145, "module-sparknlp.common"]], "sparknlp.common.properties": [[146, "module-sparknlp.common.properties"]], "sparknlp.common.read_as": [[147, "module-sparknlp.common.read_as"]], "sparknlp.common.recursive_annotator_approach": [[148, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[149, "module-sparknlp.common.storage"]], "sparknlp.common.utils": [[150, "module-sparknlp.common.utils"]], "Functions": [[150, "functions"], [151, "functions"], [152, "functions"]], "sparknlp.functions": [[151, "module-sparknlp.functions"]], "sparknlp": [[152, "module-sparknlp"]], "Package Contents": [[152, "package-contents"]], "sparknlp.internal.annotator_java_ml": [[153, "module-sparknlp.internal.annotator_java_ml"]], "sparknlp.internal.annotator_transformer": [[154, "module-sparknlp.internal.annotator_transformer"]], "sparknlp.internal.extended_java_wrapper": [[155, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[156, "module-sparknlp.internal"]], "sparknlp.internal.params_getters_setters": [[157, "module-sparknlp.internal.params_getters_setters"]], "sparknlp.internal.recursive": [[158, "module-sparknlp.internal.recursive"]], "sparknlp.logging.comet": [[159, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[160, "module-sparknlp.logging"]], "sparknlp.pretrained": [[161, "module-sparknlp.pretrained"]], "sparknlp.pretrained.pretrained_pipeline": [[162, "module-sparknlp.pretrained.pretrained_pipeline"]], "sparknlp.pretrained.resource_downloader": [[163, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[164, "module-sparknlp.pretrained.utils"]], "sparknlp.training.conll": [[165, "module-sparknlp.training.conll"]], "sparknlp.training.conllu": [[166, "module-sparknlp.training.conllu"]], "sparknlp.training": [[167, "module-sparknlp.training"]], "sparknlp.training.pos": [[168, "module-sparknlp.training.pos"]], "sparknlp.training.pub_tator": [[169, "module-sparknlp.training.pub_tator"]], "sparknlp.training.spacy_to_annotation": [[170, "module-sparknlp.training.spacy_to_annotation"]], "sparknlp.training.tfgraphs": [[171, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[172, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[173, "module-sparknlp.util"]], "API Reference": [[174, "api-reference"]], "Modules": [[174, "modules"]], "Comet - A meta machine learning platform": [[175, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[175, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[175, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[175, "logging-evaluation-metrics"]], "Logging Visualizations": [[175, "logging-visualizations"]], "Running An Offline Experiment": [[175, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[176, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[177, "third-party-projects"]], "Logging": [[177, "logging"]], "Annotation": [[178, "annotation"]], "Annotators": [[179, "annotators"]], "Annotator Approaches": [[179, "annotator-approaches"]], "Annotator Models": [[179, "annotator-models"]], "Note": [[179, "note"]], "Pretrained Models": [[179, "pretrained-models"]], "Common Functions": [[179, "common-functions"]], "Available Annotators": [[179, "available-annotators"]], "Setting up your own pipeline": [[180, "setting-up-your-own-pipeline"]], "Annotator types": [[180, "annotator-types"]], "Necessary imports": [[180, "necessary-imports"]], "Constructing the Pipeline": [[180, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[180, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[180, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[180, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[180, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[181, "helper-functions"]], "User Guide": [[182, "user-guide"]], "Light Pipelines": [[183, "light-pipelines"]], "Converting PipelineModels": [[183, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[183, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[184, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[184, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[184, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[184, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[184, "available-pipelines"]], "Loading datasets for training": [[185, "loading-datasets-for-training"]], "POS Dataset": [[185, "pos-dataset"]], "CoNLL Dataset": [[185, "conll-dataset"]], "CoNLLU Dataset": [[185, "conllu-dataset"]], "Spell Checkers Dataset": [[185, "spell-checkers-dataset"]], "PubTator Dataset": [[185, "pubtator-dataset"]]}, "indexentries": {"annotation (class in sparknlp.annotation)": [[2, "sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[2, "sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.fromRow"]], "module": [[2, "module-sparknlp.annotation"], [3, "module-sparknlp.annotation_audio"], [4, "module-sparknlp.annotation_image"], [5, "module-sparknlp.annotator.audio.hubert_for_ctc"], [6, "module-sparknlp.annotator.audio"], [7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"], [8, "module-sparknlp.annotator.chunk2_doc"], [9, "module-sparknlp.annotator.chunker"], [10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"], [11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"], [13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"], [14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"], [16, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"], [17, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"], [18, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [19, "module-sparknlp.annotator.classifier_dl.classifier_dl"], [20, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [21, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [22, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [23, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [26, "module-sparknlp.annotator.classifier_dl"], [27, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [28, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [29, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [30, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"], [31, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [32, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [33, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [34, "module-sparknlp.annotator.classifier_dl.sentiment_dl"], [35, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [36, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [39, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [40, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [41, "module-sparknlp.annotator.coref"], [42, "module-sparknlp.annotator.coref.spanbert_coref"], [43, "module-sparknlp.annotator.cv"], [44, "module-sparknlp.annotator.cv.swin_for_image_classification"], [45, "module-sparknlp.annotator.cv.vit_for_image_classification"], [46, "module-sparknlp.annotator.date2_chunk"], [47, "module-sparknlp.annotator.dependency.dependency_parser"], [48, "module-sparknlp.annotator.dependency"], [49, "module-sparknlp.annotator.dependency.typed_dependency_parser"], [50, "module-sparknlp.annotator.document_normalizer"], [51, "module-sparknlp.annotator.embeddings.albert_embeddings"], [52, "module-sparknlp.annotator.embeddings.bert_embeddings"], [53, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"], [54, "module-sparknlp.annotator.embeddings.camembert_embeddings"], [55, "module-sparknlp.annotator.embeddings.chunk_embeddings"], [56, "module-sparknlp.annotator.embeddings.deberta_embeddings"], [57, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"], [58, "module-sparknlp.annotator.embeddings.doc2vec"], [59, "module-sparknlp.annotator.embeddings.elmo_embeddings"], [60, "module-sparknlp.annotator.embeddings"], [61, "module-sparknlp.annotator.embeddings.longformer_embeddings"], [62, "module-sparknlp.annotator.embeddings.roberta_embeddings"], [63, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [64, "module-sparknlp.annotator.embeddings.sentence_embeddings"], [65, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"], [66, "module-sparknlp.annotator.embeddings.word2vec"], [67, "module-sparknlp.annotator.embeddings.word_embeddings"], [68, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [69, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [70, "module-sparknlp.annotator.embeddings.xlnet_embeddings"], [71, "module-sparknlp.annotator.er.entity_ruler"], [72, "module-sparknlp.annotator.er"], [73, "module-sparknlp.annotator.graph_extraction"], [74, "module-sparknlp.annotator"], [75, "module-sparknlp.annotator.keyword_extraction"], [76, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [77, "module-sparknlp.annotator.ld_dl"], [78, "module-sparknlp.annotator.ld_dl.language_detector_dl"], [79, "module-sparknlp.annotator.lemmatizer"], [80, "module-sparknlp.annotator.matcher.big_text_matcher"], [81, "module-sparknlp.annotator.matcher.date_matcher"], [82, "module-sparknlp.annotator.matcher"], [83, "module-sparknlp.annotator.matcher.multi_date_matcher"], [84, "module-sparknlp.annotator.matcher.regex_matcher"], [85, "module-sparknlp.annotator.matcher.text_matcher"], [86, "module-sparknlp.annotator.n_gram_generator"], [87, "module-sparknlp.annotator.ner"], [88, "module-sparknlp.annotator.ner.ner_approach"], [89, "module-sparknlp.annotator.ner.ner_converter"], [90, "module-sparknlp.annotator.ner.ner_crf"], [91, "module-sparknlp.annotator.ner.ner_dl"], [92, "module-sparknlp.annotator.ner.ner_overwriter"], [93, "module-sparknlp.annotator.ner.zero_shot_ner_model"], [94, "module-sparknlp.annotator.normalizer"], [95, "module-sparknlp.annotator.param.classifier_encoder"], [96, "module-sparknlp.annotator.param.evaluation_dl_params"], [97, "module-sparknlp.annotator.param"], [98, "module-sparknlp.annotator.pos"], [99, "module-sparknlp.annotator.pos.perceptron"], [100, "module-sparknlp.annotator.sentence"], [101, "module-sparknlp.annotator.sentence.sentence_detector"], [102, "module-sparknlp.annotator.sentence.sentence_detector_dl"], [103, "module-sparknlp.annotator.sentiment"], [104, "module-sparknlp.annotator.sentiment.sentiment_detector"], [105, "module-sparknlp.annotator.sentiment.vivekn_sentiment"], [106, "module-sparknlp.annotator.seq2seq.gpt2_transformer"], [107, "module-sparknlp.annotator.seq2seq"], [108, "module-sparknlp.annotator.seq2seq.marian_transformer"], [109, "module-sparknlp.annotator.seq2seq.t5_transformer"], [110, "module-sparknlp.annotator.spell_check.context_spell_checker"], [111, "module-sparknlp.annotator.spell_check"], [112, "module-sparknlp.annotator.spell_check.norvig_sweeting"], [113, "module-sparknlp.annotator.spell_check.symmetric_delete"], [114, "module-sparknlp.annotator.stemmer"], [115, "module-sparknlp.annotator.stop_words_cleaner"], [116, "module-sparknlp.annotator.tf_ner_dl_graph_builder"], [117, "module-sparknlp.annotator.token.chunk_tokenizer"], [118, "module-sparknlp.annotator.token"], [119, "module-sparknlp.annotator.token.recursive_tokenizer"], [120, "module-sparknlp.annotator.token.regex_tokenizer"], [121, "module-sparknlp.annotator.token.tokenizer"], [122, "module-sparknlp.annotator.ws"], [123, "module-sparknlp.annotator.ws.word_segmenter"], [124, "module-sparknlp.base.audio_assembler"], [125, "module-sparknlp.base.doc2_chunk"], [126, "module-sparknlp.base.document_assembler"], [127, "module-sparknlp.base.embeddings_finisher"], [128, "module-sparknlp.base.finisher"], [129, "module-sparknlp.base.graph_finisher"], [130, "module-sparknlp.base.has_recursive_fit"], [131, "module-sparknlp.base.has_recursive_transform"], [132, "module-sparknlp.base.image_assembler"], [133, "module-sparknlp.base"], [134, "module-sparknlp.base.light_pipeline"], [135, "module-sparknlp.base.multi_document_assembler"], [136, "module-sparknlp.base.recursive_pipeline"], [137, "module-sparknlp.base.table_assembler"], [138, "module-sparknlp.base.token2_chunk"], [139, "module-sparknlp.base.token_assembler"], [140, "module-sparknlp.common.annotator_approach"], [141, "module-sparknlp.common.annotator_model"], [142, "module-sparknlp.common.annotator_properties"], [143, "module-sparknlp.common.annotator_type"], [144, "module-sparknlp.common.coverage_result"], [145, "module-sparknlp.common"], [146, "module-sparknlp.common.properties"], [147, "module-sparknlp.common.read_as"], [148, "module-sparknlp.common.recursive_annotator_approach"], [149, "module-sparknlp.common.storage"], [150, "module-sparknlp.common.utils"], [151, "module-sparknlp.functions"], [152, "module-sparknlp"], [153, "module-sparknlp.internal.annotator_java_ml"], [154, "module-sparknlp.internal.annotator_transformer"], [155, "module-sparknlp.internal.extended_java_wrapper"], [156, "module-sparknlp.internal"], [157, "module-sparknlp.internal.params_getters_setters"], [158, "module-sparknlp.internal.recursive"], [159, "module-sparknlp.logging.comet"], [160, "module-sparknlp.logging"], [161, "module-sparknlp.pretrained"], [162, "module-sparknlp.pretrained.pretrained_pipeline"], [163, "module-sparknlp.pretrained.resource_downloader"], [164, "module-sparknlp.pretrained.utils"], [165, "module-sparknlp.training.conll"], [166, "module-sparknlp.training.conllu"], [167, "module-sparknlp.training"], [168, "module-sparknlp.training.pos"], [169, "module-sparknlp.training.pub_tator"], [170, "module-sparknlp.training.spacy_to_annotation"], [171, "module-sparknlp.training.tfgraphs"], [172, "module-sparknlp.upload_to_hub"], [173, "module-sparknlp.util"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "torow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in sparknlp.annotation_audio)": [[3, "sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[3, "sparknlp.annotation_audio.AnnotationAudio.copy"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "annotationimage (class in sparknlp.annotation_image)": [[4, "sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[4, "sparknlp.annotation_image.AnnotationImage.copy"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "hubertforctc (class in sparknlp.annotator.audio.hubert_for_ctc)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC"]], "loadsavedmodel() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.loadSavedModel"]], "pretrained() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.pretrained"]], "setconfigprotobytes() (hubertforctc method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "wav2vec2forctc (class in sparknlp.annotator.audio.wav2vec2_for_ctc)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "setconfigprotobytes() (wav2vec2forctc method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "chunk2doc (class in sparknlp.annotator.chunk2_doc)": [[8, "sparknlp.annotator.chunk2_doc.Chunk2Doc"]], "sparknlp.annotator.chunk2_doc": [[8, "module-sparknlp.annotator.chunk2_doc"]], "chunker (class in sparknlp.annotator.chunker)": [[9, "sparknlp.annotator.chunker.Chunker"]], "setregexparsers() (chunker method)": [[9, "sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "sparknlp.annotator.chunker": [[9, "module-sparknlp.annotator.chunker"]], "albertforquestionanswering (class in sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (albertforquestionanswering method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "albertforsequenceclassification (class in sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "setcoalescesentences() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "albertfortokenclassification (class in sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "setconfigprotobytes() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "bertforquestionanswering (class in sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (bertforquestionanswering method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "bertforsequenceclassification (class in sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "setcoalescesentences() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "bertfortokenclassification (class in sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "setconfigprotobytes() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "camembertforquestionanswering (class in sparknlp.annotator.classifier_dl.camembert_for_question_answering)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering"]], "loadsavedmodel() (camembertforquestionanswering static method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.loadSavedModel"]], "pretrained() (camembertforquestionanswering static method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (camembertforquestionanswering method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforquestionanswering method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[16, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "camembertforsequenceclassification (class in sparknlp.annotator.classifier_dl.camembert_for_sequence_classification)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification"]], "getclasses() (camembertforsequenceclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.getClasses"]], "loadsavedmodel() (camembertforsequenceclassification static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.loadSavedModel"]], "pretrained() (camembertforsequenceclassification static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.pretrained"]], "setcoalescesentences() (camembertforsequenceclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (camembertforsequenceclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforsequenceclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "camembertfortokenclassification (class in sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[18, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "classifierdlapproach (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[19, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[19, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[19, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "setconfigprotobytes() (classifierdlmodel method)": [[19, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[19, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[19, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "debertaforquestionanswering (class in sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[20, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "debertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "debertafortokenclassification (class in sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (debertafortokenclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[22, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "distilbertforquestionanswering (class in sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[23, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "distilbertforsequenceclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "distilbertfortokenclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[26, "module-sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[27, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "longformerforsequenceclassification (class in sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[28, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "longformerfortokenclassification (class in sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[29, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "multiclassifierdlapproach (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[30, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[30, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "robertaforquestionanswering (class in sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[31, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "robertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[32, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "robertafortokenclassification (class in sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (robertafortokenclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[33, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sentimentdlapproach (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "setconfigprotobytes() (sentimentdlmodel method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[34, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[34, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "tapasforquestionanswering (class in sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[35, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[35, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[35, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[35, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[36, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "xlmrobertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "xlmrobertafortokenclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "xlnetforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "xlnetfortokenclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[40, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[41, "module-sparknlp.annotator.coref"]], "spanbertcorefmodel (class in sparknlp.annotator.coref.spanbert_coref)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[42, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "sparknlp.annotator.coref.spanbert_coref": [[42, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv": [[43, "module-sparknlp.annotator.cv"]], "swinforimageclassification (class in sparknlp.annotator.cv.swin_for_image_classification)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification"]], "getclasses() (swinforimageclassification method)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.getClasses"]], "loadsavedmodel() (swinforimageclassification static method)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.loadSavedModel"]], "pretrained() (swinforimageclassification static method)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.pretrained"]], "setconfigprotobytes() (swinforimageclassification method)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setConfigProtoBytes"]], "setdorescale() (swinforimageclassification method)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setDoRescale"]], "setrescalefactor() (swinforimageclassification method)": [[44, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[44, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "vitforimageclassification (class in sparknlp.annotator.cv.vit_for_image_classification)": [[45, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[45, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[45, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[45, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "setconfigprotobytes() (vitforimageclassification method)": [[45, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "sparknlp.annotator.cv.vit_for_image_classification": [[45, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "date2chunk (class in sparknlp.annotator.date2_chunk)": [[46, "sparknlp.annotator.date2_chunk.Date2Chunk"]], "sparknlp.annotator.date2_chunk": [[46, "module-sparknlp.annotator.date2_chunk"]], "dependencyparserapproach (class in sparknlp.annotator.dependency.dependency_parser)": [[47, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in sparknlp.annotator.dependency.dependency_parser)": [[47, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[47, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "setconllu() (dependencyparserapproach method)": [[47, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[47, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[47, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser": [[47, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[48, "module-sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[49, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[49, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[49, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "setconll2009() (typeddependencyparserapproach method)": [[49, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[49, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[49, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[49, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "documentnormalizer (class in sparknlp.annotator.document_normalizer)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "setaction() (documentnormalizer method)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[50, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "sparknlp.annotator.document_normalizer": [[50, "module-sparknlp.annotator.document_normalizer"]], "albertembeddings (class in sparknlp.annotator.embeddings.albert_embeddings)": [[51, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[51, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[51, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "setconfigprotobytes() (albertembeddings method)": [[51, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[51, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.albert_embeddings": [[51, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "bertembeddings (class in sparknlp.annotator.embeddings.bert_embeddings)": [[52, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[52, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[52, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "setconfigprotobytes() (bertembeddings method)": [[52, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[52, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[52, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "bertsentenceembeddings (class in sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[53, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[53, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[53, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[53, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[53, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[53, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[53, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "camembertembeddings (class in sparknlp.annotator.embeddings.camembert_embeddings)": [[54, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[54, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[54, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "setconfigprotobytes() (camembertembeddings method)": [[54, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[54, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[54, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "chunkembeddings (class in sparknlp.annotator.embeddings.chunk_embeddings)": [[55, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[55, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[55, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[55, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "debertaembeddings (class in sparknlp.annotator.embeddings.deberta_embeddings)": [[56, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[56, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[56, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "setconfigprotobytes() (debertaembeddings method)": [[56, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[56, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[56, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "distilbertembeddings (class in sparknlp.annotator.embeddings.distil_bert_embeddings)": [[57, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[57, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[57, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "setconfigprotobytes() (distilbertembeddings method)": [[57, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[57, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[57, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "doc2vecapproach (class in sparknlp.annotator.embeddings.doc2vec)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in sparknlp.annotator.embeddings.doc2vec)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "setmaxiter() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[58, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec": [[58, "module-sparknlp.annotator.embeddings.doc2vec"]], "elmoembeddings (class in sparknlp.annotator.embeddings.elmo_embeddings)": [[59, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[59, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[59, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "setbatchsize() (elmoembeddings method)": [[59, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[59, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[59, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[59, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[60, "module-sparknlp.annotator.embeddings"]], "longformerembeddings (class in sparknlp.annotator.embeddings.longformer_embeddings)": [[61, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[61, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[61, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "setconfigprotobytes() (longformerembeddings method)": [[61, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[61, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[61, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "robertaembeddings (class in sparknlp.annotator.embeddings.roberta_embeddings)": [[62, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[62, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[62, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (robertaembeddings method)": [[62, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[62, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[62, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "robertasentenceembeddings (class in sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[63, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[63, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[63, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[63, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[63, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[63, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sentenceembeddings (class in sparknlp.annotator.embeddings.sentence_embeddings)": [[64, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[64, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[64, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "universalsentenceencoder (class in sparknlp.annotator.embeddings.universal_sentence_encoder)": [[65, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[65, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[65, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "setconfigprotobytes() (universalsentenceencoder method)": [[65, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[65, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[65, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "word2vecapproach (class in sparknlp.annotator.embeddings.word2vec)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in sparknlp.annotator.embeddings.word2vec)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "setmaxiter() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[66, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.word2vec": [[66, "module-sparknlp.annotator.embeddings.word2vec"]], "wordembeddings (class in sparknlp.annotator.embeddings.word_embeddings)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in sparknlp.annotator.embeddings.word_embeddings)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "setreadcachesize() (wordembeddings method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[67, "module-sparknlp.annotator.embeddings.word_embeddings"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[67, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[68, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[68, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[68, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[68, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[68, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[68, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "xlmrobertasentenceembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[69, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[69, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[69, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[69, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[69, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[69, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "xlnetembeddings (class in sparknlp.annotator.embeddings.xlnet_embeddings)": [[70, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[70, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[70, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "setconfigprotobytes() (xlnetembeddings method)": [[70, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[70, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[70, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "entityrulerapproach (class in sparknlp.annotator.er.entity_ruler)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in sparknlp.annotator.er.entity_ruler)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "setalphabetresource() (entityrulerapproach method)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setenablepatternregex() (entityrulerapproach method)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setEnablePatternRegex"]], "setpatternsresource() (entityrulerapproach method)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[71, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "sparknlp.annotator.er.entity_ruler": [[71, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[72, "module-sparknlp.annotator.er"]], "graphextraction (class in sparknlp.annotator.graph_extraction)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction"]], "setdelimiter() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[73, "sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "sparknlp.annotator.graph_extraction": [[73, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[74, "module-sparknlp.annotator"]], "sparknlp.annotator.keyword_extraction": [[75, "module-sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "setmaxngrams() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[76, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[76, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[77, "module-sparknlp.annotator.ld_dl"]], "languagedetectordl (class in sparknlp.annotator.ld_dl.language_detector_dl)": [[78, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[78, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "setcoalescesentences() (languagedetectordl method)": [[78, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[78, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[78, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[78, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[78, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "lemmatizer (class in sparknlp.annotator.lemmatizer)": [[79, "sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in sparknlp.annotator.lemmatizer)": [[79, "sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[79, "sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "setdictionary() (lemmatizer method)": [[79, "sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[79, "sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[79, "sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "sparknlp.annotator.lemmatizer": [[79, "module-sparknlp.annotator.lemmatizer"]], "bigtextmatcher (class in sparknlp.annotator.matcher.big_text_matcher)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in sparknlp.annotator.matcher.big_text_matcher)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "setcasesensitive() (bigtextmatcher method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[80, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[80, "module-sparknlp.annotator.matcher.big_text_matcher"]], "datematcher (class in sparknlp.annotator.matcher.date_matcher)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in sparknlp.annotator.matcher.date_matcher)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "setanchordateday() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[81, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "sparknlp.annotator.matcher.date_matcher": [[81, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[82, "module-sparknlp.annotator.matcher"]], "multidatematcher (class in sparknlp.annotator.matcher.multi_date_matcher)": [[83, "sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[83, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in sparknlp.annotator.matcher.regex_matcher)": [[84, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in sparknlp.annotator.matcher.regex_matcher)": [[84, "sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "setdelimiter() (regexmatcher method)": [[84, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setDelimiter"]], "setexternalrules() (regexmatcher method)": [[84, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setrules() (regexmatcher method)": [[84, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setRules"]], "setstrategy() (regexmatcher method)": [[84, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "sparknlp.annotator.matcher.regex_matcher": [[84, "module-sparknlp.annotator.matcher.regex_matcher"]], "textmatcher (class in sparknlp.annotator.matcher.text_matcher)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in sparknlp.annotator.matcher.text_matcher)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "setbuildfromtokens() (textmatcher method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[85, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher": [[85, "module-sparknlp.annotator.matcher.text_matcher"]], "ngramgenerator (class in sparknlp.annotator.n_gram_generator)": [[86, "sparknlp.annotator.n_gram_generator.NGramGenerator"]], "setdelimiter() (ngramgenerator method)": [[86, "sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[86, "sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[86, "sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "sparknlp.annotator.n_gram_generator": [[86, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[87, "module-sparknlp.annotator.ner"]], "nerapproach (class in sparknlp.annotator.ner.ner_approach)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "setentities() (nerapproach method)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[88, "sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "sparknlp.annotator.ner.ner_approach": [[88, "module-sparknlp.annotator.ner.ner_approach"]], "nerconverter (class in sparknlp.annotator.ner.ner_converter)": [[89, "sparknlp.annotator.ner.ner_converter.NerConverter"]], "setpreserveposition() (nerconverter method)": [[89, "sparknlp.annotator.ner.ner_converter.NerConverter.setPreservePosition"]], "setwhitelist() (nerconverter method)": [[89, "sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "sparknlp.annotator.ner.ner_converter": [[89, "module-sparknlp.annotator.ner.ner_converter"]], "nercrfapproach (class in sparknlp.annotator.ner.ner_crf)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in sparknlp.annotator.ner.ner_crf)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "setc0() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[90, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "sparknlp.annotator.ner.ner_crf": [[90, "module-sparknlp.annotator.ner.ner_crf"]], "nerdlapproach (class in sparknlp.annotator.ner.ner_dl)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in sparknlp.annotator.ner.ner_dl)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "setbatchsize() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[91, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "sparknlp.annotator.ner.ner_dl": [[91, "module-sparknlp.annotator.ner.ner_dl"]], "neroverwriter (class in sparknlp.annotator.ner.ner_overwriter)": [[92, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "setnerwords() (neroverwriter method)": [[92, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[92, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[92, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "sparknlp.annotator.ner.ner_overwriter": [[92, "module-sparknlp.annotator.ner.ner_overwriter"]], "zeroshotnermodel (class in sparknlp.annotator.ner.zero_shot_ner_model)": [[93, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel"]], "getclasses() (zeroshotnermodel method)": [[93, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.getClasses"]], "load() (zeroshotnermodel static method)": [[93, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.load"]], "pretrained() (zeroshotnermodel static method)": [[93, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.pretrained"]], "setentitydefinitions() (zeroshotnermodel method)": [[93, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setEntityDefinitions"]], "setpredictionthreshold() (zeroshotnermodel method)": [[93, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setPredictionThreshold"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[93, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "normalizer (class in sparknlp.annotator.normalizer)": [[94, "sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in sparknlp.annotator.normalizer)": [[94, "sparknlp.annotator.normalizer.NormalizerModel"]], "setcleanuppatterns() (normalizer method)": [[94, "sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[94, "sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[94, "sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[94, "sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[94, "sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "sparknlp.annotator.normalizer": [[94, "module-sparknlp.annotator.normalizer"]], "classifierencoder (class in sparknlp.annotator.param.classifier_encoder)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "setbatchsize() (classifierencoder method)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[95, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "sparknlp.annotator.param.classifier_encoder": [[95, "module-sparknlp.annotator.param.classifier_encoder"]], "evaluationdlparams (class in sparknlp.annotator.param.evaluation_dl_params)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "setenableoutputlogs() (evaluationdlparams method)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[96, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "sparknlp.annotator.param.evaluation_dl_params": [[96, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[97, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[98, "module-sparknlp.annotator.pos"]], "perceptronapproach (class in sparknlp.annotator.pos.perceptron)": [[99, "sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in sparknlp.annotator.pos.perceptron)": [[99, "sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[99, "sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[99, "sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "setiterations() (perceptronapproach method)": [[99, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[99, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "sparknlp.annotator.pos.perceptron": [[99, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[100, "module-sparknlp.annotator.sentence"]], "sentencedetector (class in sparknlp.annotator.sentence.sentence_detector)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in sparknlp.annotator.sentence.sentence_detector)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "setcustombounds() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[101, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector": [[101, "module-sparknlp.annotator.sentence.sentence_detector"]], "sentencedetectordlapproach (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "setcustombounds() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[102, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[102, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[103, "module-sparknlp.annotator.sentiment"]], "sentimentdetector (class in sparknlp.annotator.sentiment.sentiment_detector)": [[104, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in sparknlp.annotator.sentiment.sentiment_detector)": [[104, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "setdictionary() (sentimentdetector method)": [[104, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "sparknlp.annotator.sentiment.sentiment_detector": [[104, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "viveknsentimentapproach (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[105, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[105, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[105, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "setprunecorpus() (viveknsentimentapproach method)": [[105, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[105, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[105, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "gpt2transformer (class in sparknlp.annotator.seq2seq.gpt2_transformer)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "setconfigprotobytes() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[106, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[106, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[107, "module-sparknlp.annotator.seq2seq"]], "mariantransformer (class in sparknlp.annotator.seq2seq.marian_transformer)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "setconfigprotobytes() (mariantransformer method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[108, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "sparknlp.annotator.seq2seq.marian_transformer": [[108, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "t5transformer (class in sparknlp.annotator.seq2seq.t5_transformer)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "setconfigprotobytes() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[109, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "sparknlp.annotator.seq2seq.t5_transformer": [[109, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "contextspellcheckerapproach (class in sparknlp.annotator.spell_check.context_spell_checker)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in sparknlp.annotator.spell_check.context_spell_checker)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "setbatchsize() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setclasses() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setClasses"]], "setcomparelowcase() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setgraphfolder() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setGraphFolder"]], "setidsvocab() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setIdsVocab"]], "setinitialrate() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxsentlen() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxSentLen"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setvocabfreq() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setVocabFreq"]], "setvocabids() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setVocabIds"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker": [[110, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "updateregexclass() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[110, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "sparknlp.annotator.spell_check": [[111, "module-sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "setcasesensitive() (norvigsweetingapproach method)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[112, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[112, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "symmetricdeleteapproach (class in sparknlp.annotator.spell_check.symmetric_delete)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in sparknlp.annotator.spell_check.symmetric_delete)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[113, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete": [[113, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "stemmer (class in sparknlp.annotator.stemmer)": [[114, "sparknlp.annotator.stemmer.Stemmer"]], "sparknlp.annotator.stemmer": [[114, "module-sparknlp.annotator.stemmer"]], "stopwordscleaner (class in sparknlp.annotator.stop_words_cleaner)": [[115, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[115, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[115, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "setcasesensitive() (stopwordscleaner method)": [[115, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[115, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[115, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "sparknlp.annotator.stop_words_cleaner": [[115, "module-sparknlp.annotator.stop_words_cleaner"]], "tfnerdlgraphbuilder (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[116, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[116, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "chunktokenizer (class in sparknlp.annotator.token.chunk_tokenizer)": [[117, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in sparknlp.annotator.token.chunk_tokenizer)": [[117, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "sparknlp.annotator.token.chunk_tokenizer": [[117, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[118, "module-sparknlp.annotator.token"]], "recursivetokenizer (class in sparknlp.annotator.token.recursive_tokenizer)": [[119, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in sparknlp.annotator.token.recursive_tokenizer)": [[119, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "setinfixes() (recursivetokenizer method)": [[119, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[119, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[119, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[119, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "sparknlp.annotator.token.recursive_tokenizer": [[119, "module-sparknlp.annotator.token.recursive_tokenizer"]], "regextokenizer (class in sparknlp.annotator.token.regex_tokenizer)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "setmaxlength() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[120, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "sparknlp.annotator.token.regex_tokenizer": [[120, "module-sparknlp.annotator.token.regex_tokenizer"]], "tokenizer (class in sparknlp.annotator.token.tokenizer)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in sparknlp.annotator.token.tokenizer)": [[121, "sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[121, "sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[121, "sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "setcasesensitiveexceptions() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[121, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[121, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[121, "sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "sparknlp.annotator.token.tokenizer": [[121, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[122, "module-sparknlp.annotator.ws"]], "wordsegmenterapproach (class in sparknlp.annotator.ws.word_segmenter)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in sparknlp.annotator.ws.word_segmenter)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setenableregextokenizer() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setEnableRegexTokenizer"]], "setenableregextokenizer() (wordsegmentermodel method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setEnableRegexTokenizer"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setpattern() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPattern"]], "setpattern() (wordsegmentermodel method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setPattern"]], "setposcolumn() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "settolowercase() (wordsegmenterapproach method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setToLowercase"]], "settolowercase() (wordsegmentermodel method)": [[123, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setToLowercase"]], "sparknlp.annotator.ws.word_segmenter": [[123, "module-sparknlp.annotator.ws.word_segmenter"]], "audioassembler (class in sparknlp.base.audio_assembler)": [[124, "sparknlp.base.audio_assembler.AudioAssembler"]], "getoutputcol() (audioassembler method)": [[124, "sparknlp.base.audio_assembler.AudioAssembler.getOutputCol"]], "setinputcol() (audioassembler method)": [[124, "sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[124, "sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "sparknlp.base.audio_assembler": [[124, "module-sparknlp.base.audio_assembler"]], "doc2chunk (class in sparknlp.base.doc2_chunk)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk"]], "setchunkcol() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "sparknlp.base.doc2_chunk": [[125, "module-sparknlp.base.doc2_chunk"]], "documentassembler (class in sparknlp.base.document_assembler)": [[126, "sparknlp.base.document_assembler.DocumentAssembler"]], "getoutputcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.getOutputCol"]], "setcleanupmode() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "sparknlp.base.document_assembler": [[126, "module-sparknlp.base.document_assembler"]], "embeddingsfinisher (class in sparknlp.base.embeddings_finisher)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "getinputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getInputCols"]], "getoutputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getOutputCols"]], "setcleanannotations() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "sparknlp.base.embeddings_finisher": [[127, "module-sparknlp.base.embeddings_finisher"]], "finisher (class in sparknlp.base.finisher)": [[128, "sparknlp.base.finisher.Finisher"]], "getinputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.getInputCols"]], "getoutputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.getOutputCols"]], "setannotationsplitsymbol() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "sparknlp.base.finisher": [[128, "module-sparknlp.base.finisher"]], "graphfinisher (class in sparknlp.base.graph_finisher)": [[129, "sparknlp.base.graph_finisher.GraphFinisher"]], "setcleanannotations() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "sparknlp.base.graph_finisher": [[129, "module-sparknlp.base.graph_finisher"]], "hasrecursivefit (class in sparknlp.base.has_recursive_fit)": [[130, "sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "sparknlp.base.has_recursive_fit": [[130, "module-sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in sparknlp.base.has_recursive_transform)": [[131, "sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "sparknlp.base.has_recursive_transform": [[131, "module-sparknlp.base.has_recursive_transform"]], "imageassembler (class in sparknlp.base.image_assembler)": [[132, "sparknlp.base.image_assembler.ImageAssembler"]], "getoutputcol() (imageassembler method)": [[132, "sparknlp.base.image_assembler.ImageAssembler.getOutputCol"]], "setinputcol() (imageassembler method)": [[132, "sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[132, "sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "sparknlp.base.image_assembler": [[132, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[133, "module-sparknlp.base"]], "lightpipeline (class in sparknlp.base.light_pipeline)": [[134, "sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "setignoreunsupported() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "sparknlp.base.light_pipeline": [[134, "module-sparknlp.base.light_pipeline"]], "transform() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in sparknlp.base.multi_document_assembler)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "getoutputcols() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.getOutputCols"]], "setcleanupmode() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "sparknlp.base.multi_document_assembler": [[135, "module-sparknlp.base.multi_document_assembler"]], "recursivepipeline (class in sparknlp.base.recursive_pipeline)": [[136, "sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in sparknlp.base.recursive_pipeline)": [[136, "sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "sparknlp.base.recursive_pipeline": [[136, "module-sparknlp.base.recursive_pipeline"]], "tableassembler (class in sparknlp.base.table_assembler)": [[137, "sparknlp.base.table_assembler.TableAssembler"]], "setcsvdelimiter() (tableassembler method)": [[137, "sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[137, "sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[137, "sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "sparknlp.base.table_assembler": [[137, "module-sparknlp.base.table_assembler"]], "token2chunk (class in sparknlp.base.token2_chunk)": [[138, "sparknlp.base.token2_chunk.Token2Chunk"]], "sparknlp.base.token2_chunk": [[138, "module-sparknlp.base.token2_chunk"]], "tokenassembler (class in sparknlp.base.token_assembler)": [[139, "sparknlp.base.token_assembler.TokenAssembler"]], "setpreserveposition() (tokenassembler method)": [[139, "sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "sparknlp.base.token_assembler": [[139, "module-sparknlp.base.token_assembler"]], "annotatorapproach (class in sparknlp.common.annotator_approach)": [[140, "sparknlp.common.annotator_approach.AnnotatorApproach"]], "sparknlp.common.annotator_approach": [[140, "module-sparknlp.common.annotator_approach"]], "annotatormodel (class in sparknlp.common.annotator_model)": [[141, "sparknlp.common.annotator_model.AnnotatorModel"]], "sparknlp.common.annotator_model": [[141, "module-sparknlp.common.annotator_model"]], "annotatorproperties (class in sparknlp.common.annotator_properties)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "setinputcols() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "sparknlp.common.annotator_properties": [[142, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[143, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[144, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[145, "module-sparknlp.common"]], "hasembeddingsproperties (class in sparknlp.common.properties)": [[146, "sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[146, "sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "setdimension() (hasembeddingsproperties method)": [[146, "sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "sparknlp.common.properties": [[146, "module-sparknlp.common.properties"]], "readas (class in sparknlp.common.read_as)": [[147, "sparknlp.common.read_as.ReadAs"]], "sparknlp.common.read_as": [[147, "module-sparknlp.common.read_as"]], "recursiveannotatorapproach (class in sparknlp.common.recursive_annotator_approach)": [[148, "sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "sparknlp.common.recursive_annotator_approach": [[148, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[149, "module-sparknlp.common.storage"]], "externalresource() (in module sparknlp.common.utils)": [[150, "sparknlp.common.utils.ExternalResource"]], "sparknlp.common.utils": [[150, "module-sparknlp.common.utils"]], "explode_annotations_col() (in module sparknlp.functions)": [[151, "sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module sparknlp.functions)": [[151, "sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations"]], "map_annotations_array() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_strict"]], "sparknlp.functions": [[151, "module-sparknlp.functions"]], "sparknlp": [[152, "module-sparknlp"]], "start() (in module sparknlp)": [[152, "sparknlp.start"]], "version() (in module sparknlp)": [[152, "sparknlp.version"]], "annotatorjavamlreadable (class in sparknlp.internal.annotator_java_ml)": [[153, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in sparknlp.internal.annotator_java_ml)": [[153, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "read() (annotatorjavamlreadable class method)": [[153, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "sparknlp.internal.annotator_java_ml": [[153, "module-sparknlp.internal.annotator_java_ml"]], "annotatortransformer (class in sparknlp.internal.annotator_transformer)": [[154, "sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "sparknlp.internal.annotator_transformer": [[154, "module-sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in sparknlp.internal.extended_java_wrapper)": [[155, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[155, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "sparknlp.internal.extended_java_wrapper": [[155, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[156, "module-sparknlp.internal"]], "paramsgetterssetters (class in sparknlp.internal.params_getters_setters)": [[157, "sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[157, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "setparamvalue() (paramsgetterssetters method)": [[157, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "sparknlp.internal.params_getters_setters": [[157, "module-sparknlp.internal.params_getters_setters"]], "recursiveestimator (class in sparknlp.internal.recursive)": [[158, "sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in sparknlp.internal.recursive)": [[158, "sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[158, "sparknlp.internal.recursive.RecursiveEstimator.fit"]], "sparknlp.internal.recursive": [[158, "module-sparknlp.internal.recursive"]], "cometlogger (class in sparknlp.logging.comet)": [[159, "sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.monitor"]], "sparknlp.logging.comet": [[159, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[160, "module-sparknlp.logging"]], "sparknlp.pretrained": [[161, "module-sparknlp.pretrained"]], "pretrainedpipeline (class in sparknlp.pretrained.pretrained_pipeline)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "fullannotateimage() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotateImage"]], "sparknlp.pretrained.pretrained_pipeline": [[162, "module-sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "resourcedownloader (class in sparknlp.pretrained.resource_downloader)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader"]], "clearcache() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.clearCache"]], "downloadmodel() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModel"]], "downloadmodeldirectly() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModelDirectly"]], "downloadpipeline() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadPipeline"]], "showavailableannotators() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showAvailableAnnotators"]], "showpublicmodels() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicModels"]], "showpublicpipelines() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicPipelines"]], "showuncategorizedresources() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showUnCategorizedResources"]], "sparknlp.pretrained.resource_downloader": [[163, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[164, "module-sparknlp.pretrained.utils"]], "conll (class in sparknlp.training.conll)": [[165, "sparknlp.training.conll.CoNLL"]], "readdataset() (conll method)": [[165, "sparknlp.training.conll.CoNLL.readDataset"]], "sparknlp.training.conll": [[165, "module-sparknlp.training.conll"]], "conllu (class in sparknlp.training.conllu)": [[166, "sparknlp.training.conllu.CoNLLU"]], "readdataset() (conllu method)": [[166, "sparknlp.training.conllu.CoNLLU.readDataset"]], "sparknlp.training.conllu": [[166, "module-sparknlp.training.conllu"]], "sparknlp.training": [[167, "module-sparknlp.training"]], "pos (class in sparknlp.training.pos)": [[168, "sparknlp.training.pos.POS"]], "readdataset() (pos method)": [[168, "sparknlp.training.pos.POS.readDataset"]], "sparknlp.training.pos": [[168, "module-sparknlp.training.pos"]], "pubtator (class in sparknlp.training.pub_tator)": [[169, "sparknlp.training.pub_tator.PubTator"]], "readdataset() (pubtator method)": [[169, "sparknlp.training.pub_tator.PubTator.readDataset"]], "sparknlp.training.pub_tator": [[169, "module-sparknlp.training.pub_tator"]], "spacytoannotation (class in sparknlp.training.spacy_to_annotation)": [[170, "sparknlp.training.spacy_to_annotation.SpacyToAnnotation"]], "sparknlp.training.spacy_to_annotation": [[170, "module-sparknlp.training.spacy_to_annotation"]], "sparknlp.training.tfgraphs": [[171, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[172, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[173, "module-sparknlp.util"]]}})