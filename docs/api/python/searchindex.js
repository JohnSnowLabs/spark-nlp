Search.setIndex({"docnames": ["getting_started/index", "index", "reference/autosummary/sparknlp/annotation/index", "reference/autosummary/sparknlp/annotation_audio/index", "reference/autosummary/sparknlp/annotation_image/index", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index", "reference/autosummary/sparknlp/annotator/audio/index", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/sparknlp/annotator/chunk2_doc/index", "reference/autosummary/sparknlp/annotator/chunker/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/sparknlp/annotator/coref/index", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/sparknlp/annotator/cv/convnext_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/index", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/sparknlp/annotator/date2_chunk/index", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/sparknlp/annotator/dependency/index", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/sparknlp/annotator/document_normalizer/index", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/sparknlp/annotator/er/index", "reference/autosummary/sparknlp/annotator/graph_extraction/index", "reference/autosummary/sparknlp/annotator/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/sparknlp/annotator/ld_dl/index", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/sparknlp/annotator/lemmatizer/index", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/index", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/sparknlp/annotator/ner/index", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index", "reference/autosummary/sparknlp/annotator/normalizer/index", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/sparknlp/annotator/param/index", "reference/autosummary/sparknlp/annotator/pos/index", "reference/autosummary/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/sparknlp/annotator/sentence/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/sparknlp/annotator/sentiment/index", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/index", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/sparknlp/annotator/spell_check/index", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/sparknlp/annotator/stemmer/index", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/index", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/sparknlp/annotator/ws/index", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/sparknlp/base/audio_assembler/index", "reference/autosummary/sparknlp/base/doc2_chunk/index", "reference/autosummary/sparknlp/base/document_assembler/index", "reference/autosummary/sparknlp/base/embeddings_finisher/index", "reference/autosummary/sparknlp/base/finisher/index", "reference/autosummary/sparknlp/base/graph_finisher/index", "reference/autosummary/sparknlp/base/has_recursive_fit/index", "reference/autosummary/sparknlp/base/has_recursive_transform/index", "reference/autosummary/sparknlp/base/image_assembler/index", "reference/autosummary/sparknlp/base/index", "reference/autosummary/sparknlp/base/light_pipeline/index", "reference/autosummary/sparknlp/base/multi_document_assembler/index", "reference/autosummary/sparknlp/base/recursive_pipeline/index", "reference/autosummary/sparknlp/base/table_assembler/index", "reference/autosummary/sparknlp/base/token2_chunk/index", "reference/autosummary/sparknlp/base/token_assembler/index", "reference/autosummary/sparknlp/common/annotator_approach/index", "reference/autosummary/sparknlp/common/annotator_model/index", "reference/autosummary/sparknlp/common/annotator_properties/index", "reference/autosummary/sparknlp/common/annotator_type/index", "reference/autosummary/sparknlp/common/coverage_result/index", "reference/autosummary/sparknlp/common/index", "reference/autosummary/sparknlp/common/properties/index", "reference/autosummary/sparknlp/common/read_as/index", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/sparknlp/common/storage/index", "reference/autosummary/sparknlp/common/utils/index", "reference/autosummary/sparknlp/functions/index", "reference/autosummary/sparknlp/index", "reference/autosummary/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/sparknlp/internal/annotator_transformer/index", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/sparknlp/internal/index", "reference/autosummary/sparknlp/internal/params_getters_setters/index", "reference/autosummary/sparknlp/internal/recursive/index", "reference/autosummary/sparknlp/logging/comet/index", "reference/autosummary/sparknlp/logging/index", "reference/autosummary/sparknlp/pretrained/index", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/sparknlp/pretrained/utils/index", "reference/autosummary/sparknlp/training/conll/index", "reference/autosummary/sparknlp/training/conllu/index", "reference/autosummary/sparknlp/training/index", "reference/autosummary/sparknlp/training/pos/index", "reference/autosummary/sparknlp/training/pub_tator/index", "reference/autosummary/sparknlp/training/spacy_to_annotation/index", "reference/autosummary/sparknlp/training/tfgraphs/index", "reference/autosummary/sparknlp/upload_to_hub/index", "reference/autosummary/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["getting_started/index.rst", "index.rst", "reference/autosummary/sparknlp/annotation/index.rst", "reference/autosummary/sparknlp/annotation_audio/index.rst", "reference/autosummary/sparknlp/annotation_image/index.rst", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/audio/index.rst", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/chunk2_doc/index.rst", "reference/autosummary/sparknlp/annotator/chunker/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/coref/index.rst", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/sparknlp/annotator/cv/convnext_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/index.rst", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/date2_chunk/index.rst", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/dependency/index.rst", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/sparknlp/annotator/er/index.rst", "reference/autosummary/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/sparknlp/annotator/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/sparknlp/annotator/ner/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.rst", "reference/autosummary/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/sparknlp/annotator/param/index.rst", "reference/autosummary/sparknlp/annotator/pos/index.rst", "reference/autosummary/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/sparknlp/annotator/sentence/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/index.rst", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/ws/index.rst", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/sparknlp/base/document_assembler/index.rst", "reference/autosummary/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/sparknlp/base/finisher/index.rst", "reference/autosummary/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/sparknlp/base/image_assembler/index.rst", "reference/autosummary/sparknlp/base/index.rst", "reference/autosummary/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/sparknlp/base/table_assembler/index.rst", "reference/autosummary/sparknlp/base/token2_chunk/index.rst", "reference/autosummary/sparknlp/base/token_assembler/index.rst", "reference/autosummary/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/sparknlp/common/annotator_model/index.rst", "reference/autosummary/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/sparknlp/common/annotator_type/index.rst", "reference/autosummary/sparknlp/common/coverage_result/index.rst", "reference/autosummary/sparknlp/common/index.rst", "reference/autosummary/sparknlp/common/properties/index.rst", "reference/autosummary/sparknlp/common/read_as/index.rst", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/sparknlp/common/storage/index.rst", "reference/autosummary/sparknlp/common/utils/index.rst", "reference/autosummary/sparknlp/functions/index.rst", "reference/autosummary/sparknlp/index.rst", "reference/autosummary/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/sparknlp/internal/index.rst", "reference/autosummary/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/sparknlp/internal/recursive/index.rst", "reference/autosummary/sparknlp/logging/comet/index.rst", "reference/autosummary/sparknlp/logging/index.rst", "reference/autosummary/sparknlp/pretrained/index.rst", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/sparknlp/pretrained/utils/index.rst", "reference/autosummary/sparknlp/training/conll/index.rst", "reference/autosummary/sparknlp/training/conllu/index.rst", "reference/autosummary/sparknlp/training/index.rst", "reference/autosummary/sparknlp/training/pos/index.rst", "reference/autosummary/sparknlp/training/pub_tator/index.rst", "reference/autosummary/sparknlp/training/spacy_to_annotation/index.rst", "reference/autosummary/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/sparknlp/upload_to_hub/index.rst", "reference/autosummary/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.hubert_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.convnext_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.swin_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.date2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.zero_shot_ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.bart_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_type</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.spacy_to_annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188], "thi": [0, 1, 2, 3, 4, 5, 7, 9, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 81, 82, 83, 86, 87, 88, 91, 92, 93, 94, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 123, 124, 126, 127, 129, 130, 132, 135, 137, 138, 139, 140, 141, 142, 144, 145, 149, 155, 156, 160, 161, 162, 165, 166, 171, 173, 177, 178, 181, 182, 183, 185, 186, 187], "can": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 86, 91, 92, 93, 94, 95, 101, 103, 104, 106, 108, 109, 111, 112, 113, 115, 116, 118, 126, 129, 130, 138, 139, 140, 141, 153, 162, 165, 166, 168, 169, 171, 178, 180, 182, 183, 185, 186, 187, 188], "quick": [0, 178, 183], "refer": [0, 1, 5, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 71, 72, 78, 95, 103, 104, 107, 108, 109, 111, 112, 113, 115, 116, 126, 128, 129, 138, 182, 184, 185], "how": [0, 1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 49, 51, 53, 54, 56, 57, 58, 59, 61, 63, 64, 66, 70, 72, 73, 75, 80, 81, 82, 86, 87, 91, 92, 93, 96, 98, 103, 106, 115, 116, 123, 124, 126, 129, 132, 138, 150, 153, 155, 168, 169, 173, 178, 182, 187], "set": [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 142, 144, 145, 149, 153, 155, 160, 161, 162, 166, 168, 178, 182, 185, 186], "up": [0, 1, 5, 20, 31, 60, 63, 66, 68, 78, 108, 109, 112, 155, 178, 182, 185, 186], "your": [0, 1, 20, 31, 35, 49, 59, 60, 64, 66, 68, 81, 82, 86, 87, 91, 92, 93, 96, 101, 106, 107, 113, 115, 120, 122, 126, 130, 180, 182, 185, 186, 188], "environ": [0, 179], "pypi": 0, "pip": 0, "anaconda": 0, "c": [0, 56, 60, 68, 78, 111, 126], "johnsnowlab": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 80, 81, 82, 86, 87, 92, 93, 95, 96, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 124, 126, 130, 131, 140, 155], "load": [0, 1, 3, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 78, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 135, 165, 166, 173, 182, 185], "shell": 0, "packag": [0, 53, 58, 162, 179, 180], "com": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 80, 81, 82, 86, 87, 92, 93, 95, 96, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 124, 126, 140, 155], "nlp_2": [0, 155], "12": [0, 53, 70, 71, 72, 78, 83, 85, 91, 101, 113, 137, 141, 154, 155, 165, 171, 173, 181], "pyspark": [0, 2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 135, 137, 138, 140, 141, 142, 154, 155, 158, 161, 162, 165, 168, 169, 171, 172, 182, 183], "submit": [0, 162, 178], "extern": [0, 78, 81, 86, 87, 93, 113, 119, 139, 153, 168, 169, 171, 172], "jar": [0, 155], "after": [0, 48, 49, 51, 60, 64, 65, 68, 83, 85, 91, 122, 142, 162, 181, 182], "compil": 0, "build": [0, 58, 59, 64, 65, 75, 78, 82, 109, 162, 178], "sbt": 0, "assembli": 0, "i": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 142, 153, 154, 155, 161, 162, 166, 168, 171, 172, 173, 178, 179, 181, 182, 183, 185, 186, 187, 188], "built": [0, 20, 31, 138], "top": [0, 5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 44, 46, 53, 78, 108, 109, 112, 138], "apach": [0, 138, 155], "x": [0, 31, 154, 168, 188], "For": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 124, 126, 129, 130, 131, 138, 142, 162, 165, 172, 178, 179, 181, 182, 183, 184, 185, 186], "you": [0, 49, 51, 57, 59, 64, 66, 75, 83, 94, 130, 132, 137, 155, 162, 166, 171, 173, 178, 180, 182, 183, 186, 187, 188], "need": [0, 5, 7, 9, 49, 51, 59, 64, 69, 73, 75, 78, 83, 86, 92, 93, 96, 98, 101, 104, 107, 109, 113, 115, 116, 123, 124, 127, 135, 137, 162, 166, 168, 169, 171, 178, 180, 182, 183, 186, 188], "java": [0, 80, 143, 144, 151, 157, 158, 161, 166], "8": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 49, 51, 52, 53, 54, 55, 56, 58, 59, 63, 64, 65, 70, 71, 72, 83, 88, 93, 94, 98, 109, 113, 126, 141, 168, 173], "ar": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 47, 49, 51, 53, 54, 56, 58, 59, 61, 63, 64, 67, 69, 70, 71, 72, 73, 75, 78, 80, 81, 83, 86, 88, 91, 93, 94, 95, 96, 101, 103, 104, 107, 108, 109, 111, 112, 113, 117, 119, 126, 130, 137, 139, 140, 150, 154, 155, 162, 166, 172, 173, 178, 179, 180, 181, 182, 183, 186, 187, 188], "note": [0, 5, 7, 20, 31, 35, 53, 59, 61, 64, 66, 69, 70, 72, 78, 93, 108, 109, 111, 112, 137, 155, 187], "sinc": [0, 52, 78, 109, 155, 182, 183, 187], "version": [0, 52, 59, 97, 98, 119, 145, 149, 155, 160, 161, 165, 166, 182, 187], "6": [0, 20, 35, 46, 54, 55, 58, 61, 78, 82, 87, 88, 94, 101, 108, 115, 141, 155, 169, 173, 182], "deprec": [0, 155], "If": [0, 11, 14, 16, 18, 20, 22, 25, 29, 31, 33, 35, 38, 40, 44, 46, 47, 66, 69, 73, 80, 83, 85, 91, 92, 93, 96, 98, 103, 104, 108, 109, 112, 113, 119, 155, 161, 162, 166, 178, 180, 182], "consid": [0, 69, 75, 78, 113, 115, 116, 118, 122, 155, 166], "stick": [0, 155], "lower": [0, 52, 53, 78, 113, 128, 155], "7": [0, 8, 35, 46, 54, 55, 58, 83, 85, 101, 109, 131, 171, 173, 181], "we": [0, 5, 7, 20, 31, 44, 46, 47, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 71, 72, 78, 92, 93, 96, 104, 108, 109, 111, 112, 113, 115, 124, 137, 154, 178, 181, 182, 183, 186, 187, 188], "recommend": [0, 61, 72, 106, 107, 108, 109, 111, 112], "It": [0, 11, 14, 16, 20, 22, 25, 29, 31, 33, 35, 36, 38, 40, 44, 46, 52, 54, 55, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 73, 78, 88, 107, 108, 111, 113, 115, 116, 122, 131, 137, 166, 181, 186], "have": [0, 5, 20, 31, 35, 53, 56, 59, 64, 65, 69, 78, 86, 88, 91, 92, 93, 94, 101, 103, 104, 109, 116, 141, 142, 157, 182, 183, 186], "basic": [0, 46, 78, 103, 181], "knowledg": [0, 59, 78, 132], "framework": [0, 7, 108, 111, 112], "work": [0, 44, 59, 63, 80, 108, 112, 120, 181, 183, 187], "befor": [0, 52, 69, 83, 85, 108, 112, 115, 123, 126, 144, 161, 178], "pleas": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 80, 81, 82, 83, 86, 87, 92, 93, 96, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 126, 129, 138, 139, 179, 180, 184, 187], "document": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 130, 131, 132, 137, 138, 140, 141, 142, 162, 165, 168, 169, 171, 173, 178, 182, 183, 185, 186, 187], "first": [0, 2, 58, 60, 61, 68, 70, 71, 78, 86, 92, 93, 94, 103, 108, 112, 113, 118, 123, 130, 142, 178, 182, 183, 187], "let": [0, 59, 122, 182], "": [0, 1, 10, 13, 16, 17, 21, 24, 28, 32, 37, 44, 46, 47, 52, 53, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 73, 78, 86, 93, 96, 107, 108, 109, 111, 112, 113, 115, 116, 122, 123, 124, 126, 127, 131, 137, 143, 144, 151, 154, 157, 161, 162, 178, 181, 182, 183, 186], "make": [0, 44, 46, 52, 56, 63, 70, 71, 78, 104, 107, 108, 115, 184, 188], "sure": [0, 107], "oracl": 0, "openjdk": 0, "1": [0, 5, 8, 9, 11, 14, 16, 18, 20, 22, 25, 29, 31, 33, 35, 38, 40, 43, 44, 46, 48, 49, 51, 53, 54, 55, 58, 60, 61, 65, 68, 69, 70, 71, 72, 78, 82, 83, 85, 86, 87, 88, 91, 92, 93, 95, 97, 98, 103, 104, 107, 108, 109, 111, 112, 113, 119, 123, 126, 130, 131, 145, 149, 155, 160, 161, 162, 165, 166, 168, 169, 172, 173, 178, 181, 182, 186, 187], "0_292": 0, "creat": [0, 2, 3, 4, 20, 31, 35, 54, 55, 60, 64, 68, 69, 75, 93, 98, 101, 120, 126, 137, 139, 154, 168, 169, 171, 172, 182, 183, 186, 188], "new": [0, 2, 3, 4, 8, 35, 43, 46, 48, 53, 54, 55, 58, 61, 63, 69, 72, 94, 95, 97, 98, 108, 109, 112, 113, 119, 131, 145, 149, 160, 161, 181, 182], "manag": [0, 78, 166, 179], "all": [0, 2, 3, 4, 11, 14, 16, 18, 22, 25, 29, 33, 36, 38, 40, 46, 52, 53, 54, 55, 56, 66, 69, 72, 73, 76, 80, 83, 93, 96, 108, 109, 112, 113, 118, 123, 126, 130, 132, 162, 166, 177, 182, 187], "depend": [0, 2, 43, 56, 66, 72, 73, 75, 76, 78, 80, 93, 111, 113, 126, 155], "Then": [0, 20, 31, 92, 93, 142, 162, 182], "sparknlp": [0, 178, 181, 182, 183, 184, 186, 187, 188], "n": [0, 71, 78, 88, 91, 92, 93, 103, 104, 108, 109, 112, 122, 137, 140, 154, 165], "y": [0, 31], "activ": [0, 11, 14, 16, 18, 25, 29, 33, 38, 40, 78], "jupyt": [0, 162, 178], "now": [0, 56, 104, 137, 183], "should": [0, 2, 3, 4, 9, 20, 31, 35, 44, 46, 47, 60, 68, 70, 78, 80, 87, 88, 92, 93, 98, 103, 104, 111, 113, 123, 137, 144, 145, 157, 161, 165, 168, 169], "readi": [0, 20, 165, 182], "notebook": [0, 162, 178], "run": [0, 59, 78, 162, 166, 179, 187], "also": [0, 20, 31, 35, 44, 46, 47, 52, 53, 61, 63, 69, 70, 71, 73, 75, 78, 83, 86, 91, 92, 93, 97, 98, 104, 107, 108, 118, 137, 140, 145, 149, 160, 178, 182, 183, 184, 185, 187], "python3": 0, "sourc": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 165, 166, 168, 169, 171, 172, 173, 179], "bin": 0, "A": [0, 5, 7, 35, 43, 44, 53, 64, 65, 69, 73, 78, 81, 82, 86, 87, 88, 95, 96, 106, 108, 109, 111, 112, 115, 116, 123, 124, 162, 171, 180, 182, 188], "retriev": [0, 69, 81, 115, 116, 117, 162, 165, 178, 182, 183], "import": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 135, 137, 138, 139, 140, 141, 142, 154, 162, 165, 168, 169, 171, 172, 173, 178, 181, 182, 185, 186, 187, 188], "manual": [0, 181], "sparksess": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 69, 70, 71, 72, 82, 108, 109, 111, 112, 155, 168, 169, 171, 172], "becaus": [0, 106, 144, 161], "other": [0, 5, 8, 31, 44, 56, 66, 67, 75, 78, 96, 106, 108, 109, 112, 113, 120, 122, 130, 131, 182], "configur": [0, 44, 66, 124, 155], "includ": [0, 46, 52, 54, 55, 60, 61, 68, 70, 71, 72, 75, 78, 83, 91, 92, 93, 108, 109, 112, 113, 131, 162, 172, 179, 181, 182, 183, 188], "them": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 44, 46, 47, 53, 54, 56, 58, 59, 63, 64, 70, 72, 73, 75, 78, 83, 86, 104, 113, 118, 126, 139, 142, 182, 183], "builder": [0, 119, 155], "appnam": [0, 155], "master": [0, 155], "local": [0, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 78, 108, 109, 111, 112, 118, 137, 155, 165, 186], "config": [0, 155, 179], "driver": [0, 155], "memori": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 53, 61, 69, 155], "16g": [0, 155], "maxresults": [0, 155], "kryoseri": [0, 155], "buffer": [0, 55, 69, 155], "max": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 53, 54, 55, 56, 58, 59, 63, 64, 65, 70, 71, 72, 78, 116, 155], "2000m": [0, 155], "getorcr": [0, 155], "main": [1, 73, 124, 181, 185, 188], "page": [1, 52, 109, 165, 177, 185, 187], "github": [1, 58, 64, 111, 165], "issu": [1, 126], "workshop": [1, 185], "model": [1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 80, 81, 82, 86, 87, 91, 92, 93, 95, 96, 98, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 122, 124, 126, 144, 155, 161, 162, 165, 166, 178, 179, 181, 185, 187, 188], "hub": [1, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 80, 81, 92, 93, 101, 104, 108, 109, 111, 112, 113, 115, 116, 118, 126], "welcom": [1, 5, 7], "python": [1, 80, 155], "contain": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 160, 161, 162, 163, 165, 166, 167, 168, 169, 171, 172, 176, 178, 181, 182], "inform": [1, 49, 51, 69, 70, 78, 83, 91, 108, 113, 129, 138, 172, 178, 179, 180, 181, 182, 188], "us": [1, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 95, 98, 101, 103, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 123, 124, 126, 128, 129, 130, 131, 137, 138, 139, 140, 141, 142, 154, 155, 162, 165, 166, 168, 169, 171, 172, 179, 180, 181, 182, 183, 185], "librari": [1, 44, 46, 47, 80, 128, 129, 130, 138, 142, 187], "exampl": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 139, 140, 141, 142, 154, 162, 165, 166, 168, 169, 171, 172, 173, 178, 181, 182, 183, 185, 186, 187, 188], "get": [1, 20, 31, 78, 90, 101, 113, 119, 124, 126, 127, 129, 130, 131, 135, 137, 138, 145, 149, 160, 178, 182, 187, 188], "start": [1, 5, 10, 13, 17, 21, 24, 28, 32, 37, 63, 75, 78, 92, 93, 104, 128, 155, 162, 178, 181, 183, 186, 187], "cheat": 1, "sheet": [1, 52], "requir": [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 49, 51, 53, 55, 58, 61, 67, 70, 71, 78, 93, 96, 107, 113, 126, 128, 130, 141, 142, 181, 182, 183], "instal": [1, 162, 180], "session": [1, 155, 168, 169, 171, 172], "from": [1, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 139, 140, 141, 142, 144, 154, 155, 158, 161, 162, 165, 168, 169, 171, 172, 173, 178, 181, 182, 183, 186, 187, 188], "user": [1, 91, 92, 124, 139, 155, 162, 178], "guid": [1, 179], "annot": [1, 3, 4, 127, 128, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 148, 149, 153, 154, 155, 156, 157, 159, 161, 162, 165, 166, 167, 171, 173, 178, 179, 184, 185, 186, 187, 188], "own": [1, 20, 31, 35, 49, 60, 68, 81, 82, 86, 87, 92, 93, 96, 101, 106, 107, 113, 115, 120, 122, 126, 185, 186, 188], "pipelin": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 135, 137, 138, 139, 140, 141, 142, 155, 161, 162, 164, 165, 166, 167, 179, 181, 182, 185], "pretrain": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 83, 86, 87, 92, 93, 94, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 130, 131, 137, 154, 155, 162, 178, 181, 185], "dataset": [1, 20, 31, 35, 49, 51, 56, 60, 63, 64, 65, 68, 69, 78, 80, 92, 93, 98, 104, 109, 113, 126, 161, 165, 168, 169, 171, 172, 185], "train": [1, 5, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 64, 65, 67, 68, 70, 71, 72, 78, 80, 81, 82, 86, 87, 90, 92, 93, 96, 97, 98, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 120, 122, 126, 128, 137, 155, 162, 165, 178, 182, 183, 185, 186], "light": [1, 5, 59, 72, 78, 137, 185, 187], "helper": [1, 101, 126, 132, 154, 171, 172, 173, 185, 188], "function": [1, 61, 69, 108, 112, 130, 166, 177, 185], "third": [1, 103, 118, 163, 168], "parti": [1, 163], "project": [1, 78, 111, 162, 179], "log": [1, 20, 31, 35, 93, 98, 104, 109, 155], "api": [1, 178, 182, 185], "modul": [1, 27, 50, 62, 74, 76, 77, 79, 84, 89, 99, 100, 102, 105, 110, 114, 121, 125, 136, 148, 159, 164, 170], "data": [2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 135, 137, 138, 139, 140, 141, 142, 154, 162, 165, 168, 169, 170, 171, 172, 179, 181, 182, 186, 187, 188], "format": [2, 3, 4, 44, 46, 47, 49, 51, 73, 75, 81, 82, 83, 85, 86, 87, 92, 93, 96, 98, 106, 108, 112, 115, 116, 124, 126, 127, 129, 131, 132, 135, 138, 140, 168, 169, 171, 172, 173, 179, 188], "annotatortyp": [2, 3, 4, 57, 88, 128, 129, 135, 138, 181], "begin": [2, 43, 91, 109, 122, 124, 128, 129, 138, 154, 181], "end": [2, 10, 13, 17, 21, 24, 28, 32, 37, 43, 93, 104, 108, 122, 124, 126, 129, 138, 154, 162, 168, 178, 181, 183], "result": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 141, 142, 154, 155, 162, 165, 168, 169, 173, 178, 179, 181, 182, 183, 186, 187], "metadata": [2, 3, 4, 36, 43, 48, 78, 87, 92, 93, 95, 101, 129, 131, 135, 137, 138, 154, 162, 166, 181, 183], "embed": [2, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 75, 76, 92, 93, 94, 129, 130, 131, 137, 138, 149, 154, 155, 161, 165, 181], "repres": [2, 3, 4, 49, 51, 53, 58, 72, 73, 75, 82, 87, 88, 124, 162, 165, 182], "output": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 141, 142, 145, 154, 155, 162, 171, 178, 181, 182, 183], "spark": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 142, 148, 150, 154, 155, 157, 158, 159, 162, 165, 166, 168, 169, 171, 172, 173, 177, 179, 180, 181, 182, 184, 185, 186, 188], "nlp": [2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 80, 81, 82, 86, 87, 92, 93, 94, 95, 96, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 124, 126, 128, 129, 130, 131, 135, 136, 137, 138, 139, 140, 142, 148, 155, 159, 162, 165, 166, 168, 169, 171, 172, 177, 179, 180, 181, 182, 183, 184, 185, 186, 188], "detail": [2, 3, 4, 70, 71, 78, 95, 108, 109, 112], "paramet": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 141, 142, 145, 149, 153, 154, 155, 160, 161, 162, 165, 166, 168, 169, 171, 172], "annotator_typ": [2, 3, 4], "str": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 142, 145, 153, 154, 155, 160, 162, 165, 166, 168, 169, 171, 172], "The": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 123, 124, 126, 129, 131, 137, 138, 140, 154, 155, 162, 165, 166, 168, 169, 171, 172, 173, 178, 181, 182, 183, 185, 186, 188], "type": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 141, 142, 154, 156, 165, 171, 181, 182, 185], "possibl": [2, 3, 4, 57, 59, 70, 71, 73, 103, 113, 116, 129, 138, 150, 162, 178], "valu": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 73, 75, 78, 80, 81, 83, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 107, 108, 109, 111, 112, 113, 115, 118, 119, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 142, 145, 149, 150, 160, 162, 178, 188], "token": [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 78, 81, 82, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 101, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 126, 128, 130, 137, 139, 141, 142, 155, 165, 168, 172, 173, 182, 186, 187], "wordpiec": 2, "word_embed": [2, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 68, 70, 72, 76, 92, 93, 98], "sentence_embed": [2, 20, 31, 35, 55, 60, 62, 65, 67, 71, 76, 162, 178, 182], "categori": [2, 11, 14, 16, 18, 20, 22, 25, 29, 31, 33, 35, 38, 40, 44, 46, 47, 162, 178, 182], "date": [2, 48, 83, 85, 86], "entiti": [2, 8, 12, 15, 19, 23, 26, 30, 34, 39, 41, 43, 46, 48, 56, 73, 74, 75, 82, 87, 89, 90, 91, 92, 93, 94, 95, 120, 131, 137, 141, 165], "sentiment": [2, 20, 31, 35, 61, 72, 76, 112, 155, 182, 183], "po": [2, 9, 11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 49, 51, 75, 76, 92, 93, 122, 126, 137, 154, 155, 165, 168, 170, 181, 185, 186, 187], "chunk": [2, 8, 9, 10, 13, 17, 21, 24, 28, 32, 36, 37, 48, 57, 60, 68, 73, 78, 82, 86, 87, 88, 91, 120, 128, 131, 141, 154, 162, 172, 178, 188], "named_ent": [2, 12, 15, 19, 23, 26, 30, 34, 39, 41, 75, 91, 92, 93, 94, 95, 98, 137, 165], "negex": 2, "labeled_depend": [2, 51], "languag": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 78, 79, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 128, 138, 142, 166, 182], "keyword": [2, 77, 78, 106], "dummi": [2, 52], "int": [2, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 69, 70, 71, 72, 75, 78, 80, 83, 88, 90, 92, 93, 96, 97, 98, 101, 103, 104, 107, 108, 109, 111, 112, 113, 116, 119, 123, 124, 126, 149, 155, 162, 168], "index": [2, 78, 82, 123, 155, 168], "charact": [2, 52, 61, 63, 73, 80, 86, 88, 96, 103, 104, 113, 115, 116, 123, 124, 126, 131], "under": [2, 59, 72, 78, 155], "last": [2, 83, 85, 120, 173, 186], "string": [2, 20, 31, 35, 43, 49, 52, 73, 86, 88, 94, 96, 104, 112, 116, 118, 122, 128, 129, 131, 135, 137, 138, 186], "dict": [2, 3, 4, 49, 51, 73, 81, 82, 86, 87, 92, 94, 95, 96, 98, 106, 113, 115, 116, 124, 137, 153, 155, 161, 162, 165], "associ": [2, 3, 4, 31, 67, 73, 86, 91, 162], "list": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 73, 75, 78, 80, 83, 86, 90, 91, 93, 94, 95, 96, 97, 103, 104, 108, 109, 111, 112, 113, 118, 122, 124, 130, 131, 137, 138, 145, 154, 161, 162, 165, 166, 173, 177, 182], "vector": [2, 31, 54, 55, 57, 58, 60, 61, 67, 68, 69, 130, 131, 181], "where": [2, 31, 58, 61, 73, 78, 81, 82, 86, 87, 88, 101, 104, 106, 108, 109, 112, 115, 116, 126, 128, 171], "applic": [2, 47, 78, 108, 162, 163, 178, 180], "copi": [2, 3, 4], "differ": [2, 3, 4, 44, 46, 49, 51, 61, 64, 65, 70, 72, 78, 83, 103, 104, 113, 124, 126, 137, 162, 186], "return": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 78, 80, 81, 82, 87, 88, 90, 92, 93, 95, 101, 103, 104, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 122, 124, 126, 128, 137, 153, 154, 155, 156, 161, 165, 166, 168, 169, 171, 172], "newli": [2, 3, 4], "static": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 166, 182], "datatyp": [2, 154], "structtyp": 2, "schema": [2, 91, 162, 178], "look": [2, 93, 115, 181], "like": [2, 5, 10, 13, 17, 20, 21, 24, 28, 32, 37, 43, 52, 53, 57, 59, 63, 66, 72, 75, 78, 86, 91, 104, 107, 109, 113, 124, 126, 162, 178, 180, 181], "struct": [2, 129, 135, 138], "containsnul": [2, 31, 127, 129, 135, 138], "true": [2, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 44, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 80, 82, 83, 85, 87, 91, 93, 96, 103, 104, 113, 115, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 138, 140, 162, 168, 169, 172, 173, 178, 182, 183], "nullabl": [2, 31, 127, 129, 135, 138], "fals": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 130, 131, 132, 137, 138, 140, 141, 142, 154, 155, 162, 165, 168, 169, 171, 173, 178, 181, 182, 183, 188], "integ": [2, 44, 46, 47, 129, 135, 138], "map": [2, 9, 31, 69, 73, 97, 98, 101, 113, 129, 135, 138, 145, 149, 154, 160, 161, 181], "kei": [2, 5, 44, 49, 51, 64, 65, 70, 71, 81, 95, 129, 135, 137, 138, 162, 165, 178], "valuecontainsnul": [2, 129, 135, 138], "arrai": [2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71, 72, 80, 81, 88, 93, 97, 101, 103, 104, 108, 109, 111, 112, 113, 120, 122, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 154, 183, 186], "element": [2, 31, 88, 127, 129, 135, 138], "float": [2, 3, 5, 7, 20, 31, 35, 44, 48, 80, 92, 93, 95, 97, 98, 104, 108, 109, 112, 113, 126, 127, 129, 130, 137, 138], "sql": [2, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 69, 70, 71, 72, 82, 108, 109, 111, 112, 137, 154, 161, 165, 168, 169, 171, 172], "arraytyp": [2, 128, 154], "fromrow": 2, "row": [2, 36, 69, 103, 104, 107, 129, 138, 140, 154, 168], "column": [2, 8, 20, 31, 35, 52, 69, 81, 90, 92, 93, 97, 98, 101, 107, 119, 124, 126, 127, 128, 129, 130, 131, 132, 135, 138, 142, 145, 154, 165, 168, 171, 182], "torow": 2, "transform": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 134, 135, 137, 138, 140, 141, 142, 154, 157, 161, 162, 165, 178, 181, 182, 183, 186, 187, 188], "an": [2, 5, 7, 9, 20, 31, 35, 36, 44, 46, 47, 49, 52, 56, 58, 61, 63, 72, 73, 78, 80, 82, 83, 85, 86, 87, 88, 92, 93, 95, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 120, 124, 126, 128, 129, 130, 131, 132, 137, 138, 142, 145, 149, 153, 154, 156, 160, 161, 162, 168, 169, 171, 172, 177, 179, 181, 182, 183, 185, 186], "annotationaudio": 3, "audio": [3, 127, 162], "alreadi": [3, 75, 78, 92, 93, 94, 124, 137, 141, 165, 186], "process": [3, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 68, 70, 71, 72, 75, 78, 80, 91, 92, 93, 98, 104, 108, 109, 112, 126, 127, 128, 129, 130, 131, 135, 138, 139, 142, 162, 178, 181, 182, 183, 184], "file": [3, 5, 7, 20, 31, 35, 49, 51, 52, 67, 69, 73, 81, 82, 86, 87, 92, 93, 96, 98, 104, 106, 113, 115, 116, 119, 124, 127, 140, 150, 155, 162, 168, 169, 171, 172, 178, 188], "byte": [3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 80, 93, 97, 108, 109, 111, 112, 113, 162], "annotationimag": [4, 137, 165], "origin": [4, 44, 46, 47, 53, 60, 63, 64, 68, 91, 104, 108, 135], "height": [4, 44, 46, 47, 135], "width": [4, 44, 46, 47, 135], "nchannel": [4, 135], "mode": [4, 20, 31, 35, 93, 98, 115, 129, 135, 138, 162], "imag": [4, 44, 46, 47, 135, 137, 165], "uri": 4, "pixel": [4, 46], "number": [4, 16, 20, 31, 35, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 88, 90, 92, 93, 97, 101, 103, 104, 108, 109, 112, 113, 119, 126, 168, 169], "color": 4, "channel": [4, 44, 46, 47, 113], "opencv": 4, "concern": [5, 7, 11, 44, 46, 47, 48, 53], "hubertforctc": 5, "classnam": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 80, 81, 82, 86, 87, 92, 93, 95, 96, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 124, 126, 140, 143, 144, 151, 157], "java_model": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 80, 81, 82, 86, 87, 92, 93, 95, 96, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 124, 126, 134, 140, 144, 161], "none": [5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 80, 81, 82, 86, 87, 92, 93, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 138, 140, 141, 144, 155, 161, 162, 165, 166, 183], "hubert": 5, "head": [5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 43, 53, 72, 91, 92, 93, 137, 154, 165, 182], "connectionist": [5, 7], "tempor": [5, 7], "classif": [5, 7, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 44, 46, 47, 53, 67, 107, 108, 112, 182], "ctc": [5, 7], "wa": [5, 7, 11, 12, 14, 15, 16, 20, 22, 23, 25, 26, 29, 30, 33, 34, 35, 38, 39, 40, 41, 44, 46, 52, 56, 58, 59, 63, 64, 65, 69, 70, 71, 78, 107, 108, 109, 113, 165, 182, 183], "propos": [5, 7, 44, 46, 53, 56, 58, 59, 64, 65, 70, 71, 72], "self": [5, 7, 46, 53, 63, 111], "supervis": [5, 7, 53, 61, 67, 78, 108, 109], "speech": [5, 7, 9, 56, 100, 101, 126, 171, 188], "represent": [5, 7, 46, 53, 54, 55, 59, 60, 61, 68, 69, 70, 71, 72, 91, 112, 140, 153], "learn": [5, 7, 20, 31, 35, 48, 53, 59, 60, 61, 64, 65, 67, 68, 70, 71, 72, 78, 92, 93, 97, 104, 108, 109, 112, 113, 162, 180], "mask": [5, 46, 58, 70, 71, 72, 108, 123], "predict": [5, 46, 58, 93, 109, 112, 162, 178], "hidden": [5, 10, 12, 13, 15, 17, 19, 21, 23, 24, 26, 28, 30, 32, 34, 37, 39, 41, 53, 61, 72, 119], "unit": [5, 109, 119], "wei": [5, 46], "ning": 5, "hsu": 5, "benjamin": [5, 56], "bolt": 5, "yao": 5, "hung": 5, "tsai": 5, "kushal": 5, "lakhotia": 5, "ruslan": 5, "salakhutdinov": 5, "abdelrahman": [5, 7], "moham": [5, 7], "take": [5, 7, 36, 56, 75, 87, 97, 98, 115, 118, 124, 139, 145, 149, 160, 168, 181, 182, 186, 187], "transcrib": [5, 7], "text": [5, 7, 8, 9, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 43, 46, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 128, 129, 130, 131, 132, 138, 140, 141, 142, 150, 153, 154, 162, 168, 169, 171, 172, 178, 181, 182, 183, 187, 188], "provid": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 80, 81, 82, 83, 85, 86, 87, 92, 93, 96, 97, 98, 101, 104, 106, 108, 109, 111, 112, 113, 115, 116, 126, 137, 145, 149, 154, 156, 160, 165, 183], "pre": [5, 7, 20, 31, 35, 47, 54, 55, 58, 59, 61, 67, 93, 98, 108, 112, 129, 131, 138, 142, 169, 182], "current": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 69, 70, 71, 72, 78, 82, 83, 85, 104, 108, 109, 111, 112, 119, 137, 140, 145, 155, 181, 182, 183], "support": [5, 7, 20, 31, 53, 63, 78, 93, 96, 104, 118, 140, 155, 179], "appl": [5, 7, 55, 65, 71, 155], "silicon": [5, 7, 155], "processor": [5, 7], "m1": [5, 7], "due": [5, 7, 11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 53, 63, 108], "instruct": [5, 7], "xla": [5, 7], "companion": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 92, 93, 95, 101, 104, 108, 109, 111, 112, 113, 115, 116, 118, 126, 158], "object": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 92, 93, 95, 101, 104, 108, 109, 111, 112, 113, 115, 116, 117, 118, 126, 150, 157, 158, 162, 181, 182], "speechtotext": [5, 7], "setinputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 138, 140, 141, 142, 145, 162, 178, 182, 183], "audio_assembl": [5, 7, 136, 155], "setoutputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 138, 140, 141, 142, 145, 162, 178, 182, 183], "default": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 124, 126, 128, 129, 130, 131, 132, 137, 138, 140, 153, 154, 155, 162, 165, 166, 168, 169, 171, 172, 182], "asr_hubert_large_ls960": 5, "name": [5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 87, 89, 90, 92, 93, 95, 97, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 124, 126, 127, 128, 129, 130, 131, 132, 135, 138, 140, 142, 145, 154, 160, 162, 165, 166, 168, 171, 178, 182], "avail": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 76, 78, 80, 81, 83, 86, 92, 93, 101, 104, 108, 109, 111, 112, 113, 115, 116, 118, 126, 157, 165, 166, 178, 185], "see": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 124, 126, 129, 130, 131, 132, 138, 142, 162, 165, 172, 178, 179, 180, 185, 187, 188], "To": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 44, 46, 47, 53, 54, 56, 58, 59, 63, 64, 70, 72, 78, 83, 86, 101, 103, 108, 109, 112, 126, 132, 137, 139, 162, 178, 186], "which": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 66, 67, 68, 70, 72, 75, 78, 83, 85, 86, 93, 95, 96, 103, 104, 106, 108, 109, 111, 112, 115, 123, 126, 130, 137, 154, 166, 168, 169, 182, 183], "compat": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 44, 46, 47, 53, 54, 56, 58, 59, 63, 64, 70, 72, 93, 130, 166], "5669": [5, 7, 44, 46, 47, 56], "more": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 47, 52, 56, 59, 61, 66, 70, 71, 75, 78, 88, 91, 95, 104, 108, 109, 112, 115, 123, 124, 129, 130, 131, 138, 142, 162, 165, 172, 178, 179, 180, 182, 185, 188], "extend": [5, 7, 9, 20, 31, 35, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 59, 61, 64, 66, 67, 69, 70, 72, 78, 80, 81, 83, 85, 86, 87, 88, 92, 93, 95, 96, 98, 101, 103, 104, 106, 107, 108, 111, 112, 113, 115, 117, 118, 122, 124, 126, 129, 130, 131, 138, 142, 165], "hubertforctctestspec": 5, "paper": [5, 44, 46, 47, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 71, 72, 78, 104, 107, 108, 109, 111, 112, 126, 172, 188], "abstract": [5, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 78, 108, 109, 111, 112, 119, 172, 188], "approach": [5, 44, 46, 64, 65, 72, 78, 90, 92, 93, 95, 104, 106, 108, 109, 112, 113, 115, 116, 143, 185], "challeng": [5, 31, 46, 59, 61, 64, 65, 78], "three": [5, 113, 141], "uniqu": [5, 108], "problem": [5, 31, 53, 61, 108, 112, 113, 126], "multipl": [5, 31, 47, 56, 73, 78, 83, 103, 108, 124, 154, 162, 168], "sound": 5, "each": [5, 7, 16, 20, 31, 35, 44, 46, 47, 58, 60, 66, 68, 69, 73, 75, 78, 81, 82, 83, 86, 87, 88, 90, 92, 93, 95, 96, 98, 101, 103, 104, 106, 108, 113, 115, 116, 123, 124, 126, 129, 138, 154, 161, 171, 183], "input": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 140, 141, 142, 145, 154, 161, 165, 168, 169, 171, 172, 182, 183, 186, 188], "utter": 5, "lexicon": 5, "dure": [5, 20, 31, 35, 59, 92, 93, 98, 103, 113, 155, 162, 178], "phase": [5, 59, 108], "variabl": [5, 60, 68], "length": [5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 72, 88, 96, 103, 104, 108, 109, 111, 112, 113, 123, 124], "explicit": [5, 103, 109], "segment": [5, 43, 44, 46, 59, 64, 125, 126], "deal": [5, 137, 186], "bert": [5, 11, 13, 14, 15, 16, 18, 22, 25, 26, 29, 33, 36, 38, 40, 53, 54, 55, 58, 59, 63, 64, 65, 70, 71, 72, 93, 94, 95, 108, 112], "util": [5, 57, 92, 95, 103, 104, 116, 139, 147, 148, 150, 152, 155, 156, 160, 164], "offlin": [5, 162], "cluster": [5, 67, 155], "step": [5, 20, 31, 35, 60, 68, 93, 98, 162, 178, 182], "align": 5, "target": [5, 67, 108, 111, 124, 128, 137, 165], "label": [5, 11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 44, 46, 47, 49, 51, 73, 80, 90, 91, 92, 93, 95, 97, 98, 106, 107, 112, 113, 119, 126, 162, 168, 178, 182], "loss": [5, 53, 59, 93, 112, 178], "ingredi": 5, "our": [5, 53, 56, 59, 60, 61, 63, 64, 65, 67, 68, 70, 71, 78, 104, 108, 109, 112, 154, 165, 187], "appli": [5, 8, 20, 31, 35, 44, 47, 52, 73, 75, 93, 94, 98, 103, 112, 113, 115, 131, 154, 168], "over": [5, 59, 70, 71, 72, 108, 115, 124, 154, 162, 178], "region": 5, "onli": [5, 44, 46, 47, 49, 51, 52, 61, 67, 72, 83, 86, 96, 103, 104, 108, 109, 112, 122, 126, 139, 168], "forc": 5, "combin": [5, 16, 59, 63, 69, 78, 108, 112, 113, 115, 126], "acoust": 5, "continu": [5, 91, 109, 132, 178], "reli": [5, 49, 51, 72, 78], "primarili": 5, "consist": [5, 53, 58, 63, 86, 101, 107, 126, 140, 171], "unsupervis": [5, 70, 71, 72, 78, 108, 109], "rather": [5, 44], "than": [5, 31, 35, 44, 59, 60, 68, 70, 71, 72, 78, 80, 88, 92, 109, 115, 116, 182], "intrins": [5, 44], "qualiti": [5, 46, 109], "assign": [5, 31, 73, 94, 106], "simpl": [5, 54, 55, 73, 109, 183], "k": [5, 108, 109, 112, 130], "mean": [5, 9, 16, 31, 44, 46, 47, 70, 78, 80, 83, 85, 108, 109, 111, 112, 123, 130, 137, 182, 183, 186], "teacher": 5, "100": [5, 20, 31, 36, 47, 60, 68, 70, 78, 104, 140], "two": [5, 31, 46, 49, 51, 53, 58, 67, 69, 70, 71, 75, 141, 168, 182], "iter": [5, 49, 51, 53, 60, 68, 101, 126, 162, 178], "either": [5, 20, 35, 47, 51, 56, 57, 66, 73, 78, 80, 86, 106, 107, 112, 126, 128, 129, 137, 138, 140, 165, 183], "match": [5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 68, 70, 71, 72, 73, 82, 83, 84, 85, 86, 87, 96, 101, 103, 108, 109, 124, 126, 128, 181], "improv": [5, 53, 54, 55, 56, 58, 61, 64, 65, 70, 71, 92, 93, 109, 187], "upon": [5, 78], "state": [5, 10, 12, 13, 15, 17, 19, 20, 21, 23, 24, 26, 28, 30, 31, 32, 34, 35, 37, 39, 41, 44, 46, 47, 53, 54, 55, 56, 61, 63, 64, 65, 72, 78, 93, 108, 109, 112, 138, 179, 182], "art": [5, 20, 31, 44, 46, 47, 53, 54, 55, 56, 61, 63, 64, 65, 72, 78, 93, 108, 109, 112, 138], "wav2vec": [5, 7], "perform": [5, 44, 46, 47, 52, 53, 56, 58, 59, 61, 64, 65, 67, 69, 70, 71, 72, 93, 107, 108, 109, 115], "librispeech": 5, "960h": 5, "libri": 5, "60": [5, 59, 103], "000h": 5, "benchmark": [5, 47, 53, 58, 59, 61, 70, 71, 108, 112], "10min": 5, "1h": 5, "10h": 5, "100h": 5, "fine": [5, 43, 54, 55, 59, 95, 108, 112, 173], "tune": [5, 43, 54, 55, 59, 95, 108, 112], "subset": 5, "1b": 5, "show": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 138, 140, 141, 142, 154, 166, 168, 169, 171, 172, 173, 178, 181, 182, 183, 187], "19": [5, 48, 88, 171, 173], "13": [5, 8, 9, 43, 70, 71, 75, 101, 131, 173], "rel": [5, 56, 58, 70, 83, 85, 92, 113, 181], "wer": 5, "reduct": [5, 53, 115], "dev": [5, 46, 53, 61, 67], "test": [5, 20, 31, 35, 44, 46, 47, 49, 51, 54, 55, 67, 69, 81, 82, 86, 87, 92, 93, 98, 101, 109, 115, 116, 120, 126, 168, 169, 171, 172, 173, 182, 188], "evalu": [5, 20, 31, 35, 56, 63, 70, 71, 98, 108, 145, 162], "batchsiz": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 70, 71, 72, 93, 108, 111, 113], "size": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 68, 69, 70, 71, 72, 75, 78, 93, 97, 108, 109, 111, 112, 113, 115, 181, 186, 187], "batch": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 70, 71, 72, 93, 97, 108, 111, 113], "base": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 143, 144, 145, 148, 151, 155, 157, 161, 162, 178, 182, 183, 186], "ml": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 127, 128, 129, 130, 135, 137, 138, 139, 140, 141, 142, 162, 178, 182, 186], "audioassembl": [5, 7, 127], "audio_cont": [5, 7, 127], "setstag": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 130, 140, 141, 142, 182, 183], "processedaudiofloat": [5, 7], "createdatafram": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 130, 131, 138, 140, 141, 142, 154, 162, 178, 181, 182, 183, 187], "rawfloat": [5, 7], "todf": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 130, 131, 135, 138, 140, 141, 142, 154, 181, 182, 183, 187], "fit": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 128, 130, 137, 139, 140, 141, 142, 161, 162, 178, 182, 183, 186], "select": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 48, 57, 59, 69, 75, 78, 80, 92, 93, 95, 107, 108, 109, 112, 113, 115, 116, 122, 126, 127, 129, 131, 132, 135, 138, 140, 142, 154, 162, 178, 183], "truncat": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 69, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 131, 132, 138, 140, 141, 142, 154, 171, 181, 182, 183], "mister": [5, 7], "quilter": [5, 7], "THE": [5, 7, 52], "apostl": [5, 7], "OF": [5, 7, 53], "midl": [5, 7], "clase": [5, 7], "AND": [5, 7], "glad": [5, 7], "TO": [5, 7, 168, 188], "hi": [5, 7, 95, 104], "gospel": [5, 7], "setconfigprotobyt": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 80, 93, 97, 108, 109, 111, 112, 113], "b": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 80, 82, 87, 91, 92, 93, 94, 95, 97, 103, 108, 109, 111, 112, 113, 126, 137, 154, 165, 168, 172, 188], "configproto": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 80, 93, 97, 108, 109, 111, 112, 113], "tensorflow": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 78, 80, 93, 97, 108, 109, 111, 112, 113], "serial": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 73, 80, 93, 97, 108, 109, 111, 112, 113, 155], "loadsavedmodel": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 108, 109, 111, 112], "folder": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 93, 98, 104, 108, 109, 111, 112, 113, 116, 119, 166, 168], "spark_sess": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 108, 109, 111, 112], "save": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 93, 98, 104, 108, 109, 111, 112, 155, 162, 178, 182], "restor": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126], "lang": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 165, 166, 182, 187], "en": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 72, 75, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 165, 166, 169, 182, 187, 188], "remote_loc": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 165, 166], "download": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 75, 80, 81, 82, 87, 92, 93, 94, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 155, 165, 166, 181, 182, 185, 186], "option": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 78, 80, 81, 82, 86, 87, 92, 93, 95, 96, 98, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 127, 129, 133, 134, 137, 138, 153, 154, 155, 161, 162, 165, 166, 168, 169, 171, 172, 182], "remot": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 165, 166], "address": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126], "resourc": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 80, 81, 82, 86, 87, 92, 93, 95, 96, 98, 101, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 124, 126, 139, 150, 153, 164, 166, 168, 169, 171, 172, 173, 182, 188], "Will": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 103, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126], "repositori": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 165, 179], "otherwis": [5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 80, 81, 82, 87, 92, 93, 95, 101, 104, 107, 108, 109, 111, 112, 113, 115, 116, 118, 124, 126, 128, 162], "hubert_for_ctc": 6, "wav2vec2_for_ctc": 6, "wav2vec2forctc": 7, "wav2vec2": 7, "alexei": 7, "baevski": 7, "henri": 7, "zhou": 7, "michael": [7, 120], "auli": 7, "asr_wav2vec2_base_960h": 7, "wav2vec2forctctestspec": 7, "chunk2doc": [8, 128], "convert": [8, 48, 52, 57, 66, 69, 83, 85, 88, 91, 96, 108, 112, 123, 126, 128, 131, 132, 141, 162, 178, 185], "back": [8, 108], "when": [8, 9, 11, 14, 16, 22, 25, 29, 33, 38, 40, 44, 46, 47, 52, 53, 75, 83, 85, 88, 93, 108, 109, 113, 115, 118, 122, 126, 137, 168, 182, 183, 186], "try": [8, 113, 168], "re": [8, 182], "do": [8, 67, 78, 91, 118, 124, 137, 178, 182, 186], "further": [8, 53, 78, 92, 93, 142], "analysi": [8, 20, 31, 35, 61, 72, 105, 106, 112, 147, 183], "doc2chunk": [8, 128], "pretrainedpipelin": [8, 131, 137, 154, 165, 181, 186, 187], "locat": [8, 73, 103, 155, 165, 182], "extract": [8, 9, 10, 13, 17, 21, 24, 28, 32, 37, 44, 46, 47, 49, 57, 69, 73, 74, 75, 77, 78, 82, 83, 85, 87, 91, 92, 93, 94, 103, 104, 106, 113, 116, 120, 130, 131, 132, 137, 141, 155, 162, 165, 178], "york": [8, 95, 131], "jersei": [8, 131], "aren": [8, 131], "t": [8, 16, 59, 64, 81, 96, 104, 106, 124, 131], "far": [8, 109, 131], "apart": [8, 49, 51, 131], "actual": [8, 88, 131, 142], "id": [8, 31, 52, 70, 73, 108, 109, 111, 112, 113, 128, 129, 131, 138, 142, 162, 168], "defin": [8, 9, 91, 92, 93, 113, 118, 122, 131, 154, 162, 165, 178, 182, 186], "amongst": [8, 131], "thing": [8, 113, 131], "explain_document_dl": [8, 131, 137, 154, 165], "chunktodoc": 8, "chunkconvert": 8, "explainresult": [8, 131], "selectexpr": [8, 9, 20, 36, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 81, 82, 83, 85, 86, 87, 88, 91, 94, 95, 96, 101, 103, 104, 106, 111, 117, 118, 120, 123, 124, 128, 130, 131, 141, 154, 168, 169, 171, 181, 182, 187], "explod": [8, 9, 20, 36, 43, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 82, 85, 86, 87, 88, 91, 94, 95, 101, 103, 104, 111, 130, 131, 141, 154, 168, 171, 181, 182, 187], "col": [8, 49, 51, 73, 82, 91, 94, 131, 154, 181], "loc": [8, 12, 15, 19, 23, 26, 30, 34, 39, 41, 75, 91, 92, 93, 131, 137, 154, 165, 168], "sentenc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 80, 81, 82, 83, 85, 86, 87, 88, 91, 92, 93, 94, 95, 101, 107, 108, 111, 113, 118, 120, 123, 126, 129, 131, 137, 138, 140, 141, 142, 155, 165, 168, 169, 171, 172, 173, 182, 186, 187], "22": [8, 131, 168, 181], "pattern": [9, 52, 73, 83, 86, 96, 115, 116, 123, 124, 126], "part": [9, 56, 78, 81, 100, 101, 117, 126, 128, 171, 188], "tag": [9, 20, 31, 35, 52, 56, 90, 91, 92, 93, 94, 100, 101, 126, 154, 162, 168, 171, 172, 188], "order": [9, 72, 73, 78, 108, 115, 116, 137, 142, 154, 182, 183, 186, 188], "meaning": [9, 117], "phrase": [9, 56, 60, 68, 82, 87], "onto": [9, 154, 183], "pars": [9, 49, 50, 51, 56, 73, 81, 83, 85, 113, 115, 116, 137, 140, 165, 168, 171], "regular": [9, 86, 92, 103], "express": [9, 35, 43, 83, 86, 103], "wrap": [9, 143, 144, 151, 157, 161], "angl": 9, "bracket": 9, "easili": [9, 61, 101, 130, 178], "distinguish": 9, "itself": [9, 78, 112, 126, 139, 183], "form": [9, 20, 31, 35, 69, 73, 81, 82, 83, 86, 87, 104, 106, 115, 116, 126, 130, 162, 168, 169, 182], "peter": [9, 63, 81, 96, 101, 104, 115, 117, 168], "piper": [9, 81, 101, 117], "employe": [9, 81, 101, 117], "pick": [9, 81, 101, 117], "peck": [9, 81, 101, 117], "pickl": [9, 81, 101, 117], "pepper": [9, 81, 101, 117], "nnp": [9, 101, 137, 154, 168, 169, 171, 172, 181, 186, 187, 188], "nn": [9, 101, 168, 169, 171, 172, 188], "vbp": [9, 101, 137, 169, 181, 186, 187], "vbg": [9, 101], "IN": [9, 101, 137, 154, 169, 171, 172, 181, 186, 187], "jj": [9, 101, 137, 154, 168, 171, 181, 186, 187, 188], "regexpars": 9, "e": [9, 11, 12, 14, 15, 18, 19, 22, 23, 25, 26, 29, 30, 33, 34, 38, 39, 40, 41, 44, 51, 52, 61, 63, 73, 75, 92, 93, 108, 109, 111, 112, 113, 118, 140, 162, 178], "g": [9, 11, 12, 14, 15, 18, 19, 22, 23, 25, 26, 29, 30, 33, 34, 38, 39, 40, 41, 44, 51, 52, 61, 75, 92, 93, 108, 109, 111, 112, 113, 118, 140, 162, 178], "setregexpars": 9, "enclos": 9, "treat": [9, 113, 126], "group": [9, 124], "so": [9, 20, 35, 78, 91, 104, 139, 162, 178], "here": [9, 81, 154, 182], "specif": [9, 36, 49, 51, 52, 54, 55, 59, 67, 75, 78, 93, 108, 109, 119, 137, 139, 162, 186], "noun": [9, 169], "success": [9, 56, 109], "grammar": 9, "parser": [9, 49, 51, 75], "perceptronmodel": [9, 49, 51, 75, 92, 101, 168], "Of": [9, 53, 126], "documentassembl": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 92, 93, 94, 95, 96, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 126, 128, 129, 130, 138, 139, 140, 141, 142, 162, 168, 178, 182], "sentencedetector": [9, 20, 36, 43, 49, 51, 55, 57, 65, 67, 71, 75, 78, 81, 86, 88, 92, 93, 94, 95, 101, 103, 104, 118, 120, 139, 142, 168, 182, 183], "postag": 9, "11": [9, 48, 70, 71, 83, 85, 88, 101, 173], "21": [9, 83, 85, 94, 101, 173], "35": [9, 101, 173], "39": [9, 94, 101, 171, 173], "52": [9, 94, 101, 171], "58": [9, 46, 101], "albertforquestionansw": 10, "classifi": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 78, 130, 182], "dl": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 80, 93, 95, 115, 116], "albert": [10, 11, 12, 53], "span": [10, 13, 17, 21, 24, 28, 32, 37, 108, 112], "question": [10, 13, 17, 21, 24, 28, 32, 36, 37, 49, 51, 54, 55, 61, 64, 65, 72, 95, 101, 108, 109, 112, 137], "answer": [10, 13, 17, 21, 24, 28, 32, 36, 37, 49, 51, 54, 55, 61, 72, 95, 108, 109, 112, 137], "task": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 46, 47, 53, 54, 55, 56, 58, 59, 63, 67, 70, 71, 72, 78, 95, 108, 109, 111, 112, 139], "squad": [10, 13, 17, 21, 24, 28, 32, 37, 53, 54, 55, 58, 64, 65, 108], "linear": [10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 46, 109], "layer": [10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 53, 54, 55, 58, 61, 72], "comput": [10, 13, 17, 21, 24, 28, 32, 37, 44, 46, 47, 53, 58, 59, 67, 109, 111, 116, 126, 137, 186], "logit": [10, 11, 13, 14, 16, 17, 18, 21, 24, 25, 28, 29, 32, 33, 37, 38, 40], "spanclassifi": [10, 13, 17, 21, 24, 28, 32, 37], "document_quest": [10, 13, 17, 21, 24, 28, 32, 36, 37], "document_context": [10, 13, 17, 21, 24, 28, 32, 37], "albert_base_qa_squad2": 10, "larg": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 44, 46, 47, 53, 58, 59, 61, 70, 71, 72, 78, 80, 82, 87, 93, 108, 109], "allow": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 46, 61, 67, 92, 93, 96, 103, 104, 108, 123, 124, 139], "faster": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 59, 61, 115, 116], "casesensit": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 70, 71, 72, 82, 87, 115, 118], "whether": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 73, 75, 82, 83, 85, 87, 88, 91, 92, 93, 96, 98, 103, 104, 108, 109, 112, 113, 115, 118, 123, 124, 126, 128, 130, 131, 132, 137, 140, 142, 145, 155, 165, 168, 172, 183], "ignor": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 70, 71, 72, 82, 88, 91, 108, 109, 111, 112, 115, 118, 137], "case": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 51, 52, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 70, 71, 72, 73, 80, 82, 87, 113, 115, 118, 124, 128, 168, 169, 182], "configprotobyt": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 46, 47, 53, 54, 55, 56, 58, 59, 61, 63, 64, 65, 67, 70, 71, 72, 80, 93, 108, 109, 111, 112, 113], "maxsentencelength": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 37, 38, 39, 40, 41, 43, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 72], "128": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 53, 54, 55, 56, 58, 59, 64, 65, 70, 71, 72, 162, 178], "multidocumentassembl": [10, 13, 17, 21, 24, 28, 32, 36, 37, 138], "context": [10, 13, 17, 21, 24, 28, 32, 37, 54, 55, 60, 61, 68, 72, 107, 113, 124], "setcasesensit": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 57, 59, 63, 64, 70, 82, 87, 92, 115, 118, 130, 142], "what": [10, 13, 17, 21, 24, 28, 32, 35, 37, 44, 49, 51, 78, 80, 95, 111, 113, 122, 169, 179], "my": [10, 12, 13, 15, 17, 20, 21, 23, 24, 26, 28, 30, 32, 34, 35, 37, 39, 41, 52, 86, 88, 95, 103, 109, 118, 120, 123, 182], "clara": [10, 13, 17, 21, 24, 28, 32, 37, 95], "live": [10, 12, 13, 15, 17, 21, 23, 24, 26, 28, 30, 32, 34, 37, 39, 41, 95, 109, 162, 178], "berkelei": [10, 13, 17, 21, 24, 28, 32, 37], "setmaxsentencelength": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 43, 53, 54, 55, 56, 58, 59, 60, 63, 64, 65, 68, 70, 71, 72], "albertforsequenceclassif": [11, 22], "sequenc": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 44, 46, 47, 63, 108, 109, 110, 111, 112, 113, 118], "regress": [11, 14, 18, 22, 25, 29, 33, 38, 40, 108, 112], "pool": [11, 14, 18, 22, 25, 29, 33, 38, 40, 57, 61, 66], "multi": [11, 14, 18, 20, 22, 25, 29, 31, 33, 35, 38, 40, 53, 67, 70, 71, 78, 80, 111], "sequenceclassifi": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40], "albert_base_sequence_classifier_imdb": 11, "coalescesent": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 80], "instead": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 55, 78, 80, 83, 85, 112, 130, 131, 137, 186], "per": [11, 12, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 70, 71, 80, 83, 88, 90, 91, 92, 93, 126, 137, 154, 165, 168], "inputcol": [11, 14, 16, 18, 20, 22, 25, 29, 31, 33, 35, 38, 40, 66, 80, 127, 129, 130, 131, 132, 135, 138], "averag": [11, 14, 16, 18, 22, 25, 29, 33, 36, 38, 40, 57, 66, 70, 71, 80, 93, 101], "probabl": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 78, 108, 109, 112, 115], "calcul": [11, 14, 16, 18, 20, 25, 29, 31, 33, 35, 38, 40, 69, 88, 93, 98, 106], "via": [11, 14, 16, 18, 25, 29, 33, 38, 40, 67, 135, 155], "softmax": [11, 14, 16, 18, 25, 29, 33, 38, 40, 58, 60, 68, 113], "sigmoid": [11, 14, 16, 18, 25, 29, 33, 38, 40], "love": [11, 14, 16, 20, 22, 25, 29, 33, 38, 40, 55, 65, 71, 104, 107, 182], "movi": [11, 14, 16, 20, 22, 25, 29, 33, 35, 38, 40, 107, 182], "child": [11, 14, 16, 22, 25, 29, 33, 38, 40], "pretti": [11, 14, 16, 22, 25, 29, 31, 33, 38, 40, 78], "bore": [11, 14, 16, 22, 25, 29, 33, 38, 40], "neg": [11, 14, 16, 18, 22, 25, 29, 33, 35, 38, 40, 106, 107, 162, 178], "getclass": [11, 12, 14, 15, 16, 18, 19, 22, 23, 25, 26, 29, 30, 33, 34, 38, 39, 40, 41, 44, 46, 47, 95], "setcoalescesent": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 80], "limit": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 44, 46, 47, 53, 56, 63, 69, 72, 78, 112, 115], "almost": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40], "512": [11, 14, 16, 18, 22, 25, 29, 33, 36, 38, 40, 61], "help": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 49, 51, 53, 111, 124, 162, 178, 183, 187], "feed": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40], "entir": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 44, 111], "bool": [11, 14, 16, 18, 22, 25, 29, 33, 38, 40, 52, 55, 57, 67, 73, 75, 80, 82, 83, 87, 88, 91, 92, 93, 96, 98, 103, 104, 108, 109, 112, 113, 115, 118, 123, 124, 126, 128, 130, 131, 132, 137, 140, 145, 155, 162, 165, 168], "one": [11, 14, 16, 18, 22, 25, 29, 31, 33, 38, 40, 43, 44, 46, 47, 49, 51, 52, 54, 55, 66, 70, 71, 72, 78, 80, 83, 86, 91, 104, 115, 120, 142, 178, 182], "albertfortokenclassif": [12, 53], "recognit": [12, 15, 19, 23, 26, 30, 34, 39, 41, 44, 47, 56, 89, 92, 93, 95], "ner": [12, 15, 19, 23, 26, 30, 34, 39, 41, 70, 71, 75, 76, 120, 137, 154, 155, 162, 165, 178], "token_classifi": [12, 19, 30, 34, 39, 41], "albert_base_token_classifier_conll03": 12, "albertembed": [12, 53], "level": [12, 20, 31, 35, 54, 55, 63, 64, 65, 67, 69, 71, 73, 92, 93, 98, 113, 155, 168], "tokenclassifi": [12, 15, 19, 23, 26, 30, 34, 39, 41], "john": [12, 15, 23, 26, 30, 34, 39, 41, 43, 55, 65, 71, 73, 75, 94, 96, 104, 132, 173], "lenon": [12, 15, 23, 26, 30, 34, 39, 41], "born": [12, 15, 23, 26, 30, 34, 39, 41, 109], "london": [12, 15, 23, 26, 30, 34, 39, 41], "pari": [12, 15, 23, 26, 30, 34, 39, 41, 95], "sarah": [12, 15, 23, 26, 30, 34, 39, 41], "o": [12, 15, 19, 23, 26, 30, 34, 39, 41, 91, 92, 93, 94, 137, 154, 165, 168, 172, 188], "bertforquestionansw": [13, 36], "bert_base_cased_qa_squad2": 13, "bertforsequenceclassif": [14, 16], "bert_base_sequence_classifier_imdb": 14, "bertfortokenclassif": 15, "bert_base_token_classifier_conll03": 15, "bertforzeroshotclassif": 16, "modelforsequenceclassif": 16, "nli": 16, "natur": [16, 35, 47, 53, 54, 55, 56, 58, 59, 60, 67, 68, 72, 80, 108, 109, 112, 128, 138, 142], "infer": [16, 54, 55, 56, 59, 72], "equival": [16, 137, 155, 186], "don": [16, 59, 64, 96], "hardcod": 16, "potenti": [16, 46, 113], "thei": [16, 36, 49, 51, 93, 96, 109, 139, 157, 169, 182], "chosen": [16, 49, 51, 93], "runtim": 16, "usual": [16, 47, 142, 166], "slower": 16, "much": [16, 20, 36, 53, 64, 65, 96, 126, 155, 182], "flexibl": [16, 46], "ani": [16, 60, 67, 68, 73, 78, 93, 109, 112, 113, 130, 131, 166, 179, 182, 183, 188], "pass": 16, "pose": 16, "premis": 16, "hypothesi": 16, "pair": [16, 75, 162], "bert_base_cased_zero_shot_classifier_xnli": 16, "camembertforquestionansw": 17, "camembert": [17, 18, 19, 56], "camembert_base_qa_fquad": 17, "fr": [17, 18, 56, 80], "camembertforsequenceclassif": 18, "sequence_classifi": 18, "camembert_base_sequence_classifier_allocin": 18, "j": [18, 73], "ai": [18, 108, 162, 178], "ador\u00e9": 18, "ce": 18, "film": 18, "lorsqu": 18, "\u00e9tai": 18, "enfant": 18, "je": 18, "d\u00e9test": 18, "\u00e7a": 18, "camembertfortokenclassif": 19, "camembert_base_token_classifier_wikin": 19, "georg": 19, "washington": 19, "est": [19, 56, 80, 111], "all\u00e9": 19, "\u00e0": 19, "classifierdl": [20, 182], "classifierdlapproach": [20, 31, 182], "gener": [20, 31, 44, 46, 53, 57, 59, 63, 66, 72, 75, 78, 92, 93, 95, 104, 108, 109, 112, 113, 115, 116, 131, 132, 162, 178, 181, 182, 183], "univers": [20, 49, 51, 67, 111], "encod": [20, 52, 54, 55, 58, 63, 67, 95, 108, 111, 162], "deep": [20, 54, 55, 61, 78, 92, 104, 113], "dnn": 20, "insid": [20, 31, 91, 101, 124, 168], "instanti": [20, 31, 35, 49, 51, 60, 68, 69, 73, 81, 82, 86, 87, 92, 93, 96, 101, 104, 106, 107, 113, 115, 116, 120, 122, 126, 168, 169], "classifierdlmodel": [20, 31, 182], "monitor": [20, 31, 35, 93, 162, 178], "metric": [20, 31, 35, 93, 116, 162], "done": [20, 31, 35, 64, 65, 92, 93, 183], "settestdataset": [20, 31, 35, 93, 98], "method": [20, 31, 35, 53, 59, 60, 68, 72, 78, 93, 166, 177], "expect": [20, 31, 35, 72, 93, 124, 154], "path": [20, 31, 35, 49, 51, 60, 68, 69, 73, 75, 81, 82, 86, 87, 92, 93, 95, 96, 98, 104, 106, 109, 113, 115, 116, 119, 124, 135, 137, 153, 162, 165, 168, 169, 171, 172, 178], "parquet": [20, 31, 35, 93, 98, 127], "datafram": [20, 31, 35, 47, 69, 93, 98, 101, 126, 137, 150, 154, 161, 162, 165, 168, 169, 171, 172, 178, 182, 186, 188], "ha": [20, 31, 35, 36, 44, 46, 47, 52, 53, 58, 59, 61, 64, 65, 69, 78, 81, 86, 93, 98, 104, 106, 108, 112, 115, 116, 126, 127, 128, 135, 137, 162, 166, 171, 178, 182, 183], "same": [20, 31, 35, 43, 53, 64, 69, 70, 73, 75, 93, 98, 112, 139, 162, 183], "follow": [20, 31, 35, 43, 48, 52, 61, 63, 69, 78, 83, 85, 86, 91, 93, 96, 103, 140, 141, 178, 180, 183], "universalsentenceencod": [20, 31, 35, 67, 162, 178, 182], "preprocessingpipelin": [20, 31, 35, 93, 98], "randomsplit": [20, 31, 35, 93, 98], "write": [20, 31, 35, 69, 93, 98, 115, 116, 183], "overwrit": [20, 31, 35, 93, 94, 98, 162], "test_data": [20, 31, 35, 93, 98], "setlabelcolumn": [20, 31, 35, 90, 92, 93, 97, 119, 162, 178, 182], "usag": [20, 31, 35, 43, 49, 51, 52, 53, 54, 55, 56, 57, 59, 61, 64, 67, 69, 70, 72, 73, 78, 80, 81, 83, 85, 86, 87, 92, 93, 96, 101, 103, 104, 106, 107, 108, 111, 112, 113, 115, 117, 118, 122, 124, 126], "64": [20, 31, 35, 53, 93, 97, 182], "dropout": [20, 35, 93], "coeffici": [20, 35, 92, 93], "5": [20, 31, 35, 43, 46, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 78, 80, 83, 85, 88, 91, 93, 101, 109, 126, 130, 137, 154, 162, 165, 169, 171, 172, 173, 178, 181, 182, 188], "enableoutputlog": [20, 31, 35, 93], "stdout": [20, 31, 35, 93, 98], "addit": [20, 31, 35, 49, 51, 54, 55, 73, 92, 93, 98, 103, 109, 124, 162, 181, 182], "evaluationlogextend": [20, 31, 35, 93], "valid": [20, 31, 35, 83, 93, 98, 104, 113, 178], "displai": [20, 31, 35, 98, 109, 162, 178], "time": [20, 31, 35, 53, 60, 68, 70, 71, 78, 83, 98, 107, 113, 126, 155, 181, 182, 186, 187], "labelcolumn": [20, 31, 35, 92, 93], "lr": [20, 31, 35, 93, 126], "rate": [20, 31, 35, 48, 60, 64, 65, 68, 69, 93, 97, 113], "005": [20, 35, 93, 97], "maxepoch": [20, 31, 35, 92, 93], "maximum": [20, 31, 35, 43, 60, 68, 75, 78, 90, 92, 93, 96, 97, 103, 104, 108, 109, 111, 112, 113, 115, 123, 124], "epoch": [20, 31, 35, 90, 92, 93, 97, 98, 104, 113, 162], "30": [20, 35, 78, 83, 85, 91, 97, 111, 137, 154, 165, 173, 181], "outputlogspath": [20, 31, 35, 93, 104], "randomse": [20, 31, 35, 92, 93], "random": [20, 31, 35, 60, 68, 90, 92, 93, 97, 130], "seed": [20, 31, 35, 60, 68, 90, 92, 93, 97], "shuffl": [20, 31, 90, 97, 108], "testdataset": [20, 31, 35, 93, 162, 178], "statist": [20, 31, 35, 69, 78, 93, 98], "validationsplit": [20, 31, 35, 93, 104], "choos": [20, 31, 35, 57, 66, 93, 104, 115], "proport": [20, 31, 35, 93, 98, 104], "against": [20, 31, 35, 73, 78, 82, 87, 93, 98, 104, 139], "between": [20, 31, 35, 46, 49, 51, 64, 65, 67, 70, 71, 72, 75, 93, 98, 103, 104, 113], "off": [20, 31, 35, 67, 70, 71, 93, 98, 104], "verbos": [20, 31, 35, 92, 93, 98], "multiclassifierdlapproach": [20, 31, 162, 178], "sentimentdlapproach": [20, 31, 35], "accept": [20, 31, 35], "singl": [20, 31, 35, 69, 75, 78, 108, 120, 122, 124, 168], "item": [20, 35, 69, 162, 168, 178], "doubl": [20, 35, 127, 140], "sentenceembed": [20, 31, 35, 66, 69, 130], "In": [20, 31, 35, 44, 47, 56, 58, 59, 63, 69, 72, 73, 78, 80, 81, 82, 86, 87, 103, 104, 106, 108, 109, 112, 115, 116, 126, 162, 171, 178, 182, 183, 187, 188], "csv": [20, 35, 73, 98, 140, 182], "best": [20, 35, 53, 56, 64, 65, 78, 80, 93, 108, 182], "wach": [20, 182], "ever": [20, 35, 52, 182], "opinion": [20, 35, 182], "win": [20, 35, 182], "award": [20, 35, 182], "terribl": [20, 35, 182], "act": [20, 35, 182], "bad": [20, 35, 106, 162, 178, 182], "realli": [20, 35, 107, 182], "trane": 20, "smallcorpu": [20, 35, 182], "read": [20, 35, 44, 46, 47, 49, 51, 60, 68, 78, 81, 82, 83, 85, 86, 87, 92, 95, 96, 98, 104, 106, 109, 113, 115, 116, 124, 126, 127, 129, 135, 138, 150, 153, 155, 156, 162, 166, 168, 169, 171, 172, 178, 182, 188], "header": [20, 35, 36, 140, 182], "src": [20, 35, 44, 46, 47, 49, 51, 69, 81, 82, 86, 87, 92, 93, 101, 115, 116, 120, 126, 168, 169, 171, 172, 173, 182, 188], "useembed": [20, 31, 35, 67, 182], "docclassifi": [20, 31, 35, 182], "setbatchs": [20, 31, 35, 61, 93, 97, 113, 162, 178, 182], "setmaxepoch": [20, 31, 35, 90, 92, 93, 97, 162, 178, 182], "20": [20, 36, 44, 72, 91, 108, 109, 137, 140, 154, 165, 182], "setlr": [20, 31, 35, 93, 97, 162, 178, 182], "5e": [20, 35, 182], "setdropout": [20, 35, 93, 182], "pipelinemodel": [20, 31, 35, 49, 51, 52, 60, 68, 92, 93, 107, 113, 115, 116, 126, 137, 139, 162, 166, 182, 185], "v": [20, 31, 35, 48, 58, 69, 78, 80, 82, 93, 97, 98, 116, 154], "classifierdl_use_trec6": [20, 182], "trec": 20, "multiclassifierdlmodel": [20, 31], "sentimentdlmodel": [20, 31, 35], "sarcasmdl": [20, 182], "classifierdl_use_sarcasm": [20, 182], "sarcasm": [20, 182], "m": [20, 83, 85, 173, 182], "could": [20, 59, 78, 86, 98, 113, 181, 182, 183], "put": [20, 154, 182], "word": [20, 46, 47, 49, 51, 53, 57, 58, 60, 61, 64, 66, 67, 68, 69, 72, 73, 75, 78, 81, 88, 91, 94, 95, 96, 101, 106, 108, 109, 111, 112, 113, 115, 116, 117, 118, 122, 124, 125, 126, 137, 154, 165, 171, 172, 181, 182], "wake": [20, 182], "am": [20, 83, 85, 109, 120, 182], "mondai": [20, 182], "would": [20, 43, 57, 66, 83, 104, 155, 182], "arrays_zip": [20, 49, 51, 78, 182], "out": [20, 78, 81, 96, 108, 109, 111, 112, 117, 118, 182], "normal": [20, 44, 46, 47, 52, 76, 82, 104, 107, 118, 130, 139, 142, 155, 182, 183], "debertaforquestionansw": 21, "deberta": [21, 22, 23, 58], "deberta_v3_xsmall_qa_squad2": 21, "debertaforsequenceclassif": 22, "v2": [22, 23, 54, 55, 58], "v3": [22, 23], "deberta_v3_xsmall_sequence_classifier_imdb": 22, "deberta_base_sequence_classifier_imdb": 22, "debertafortokenclassif": 23, "deberta_v3_xsmall_token_classifier_conll03": 23, "distilbertforquestionansw": 24, "distilbert": [24, 25, 59], "distilbert_base_cased_qa_squad2": 24, "distilbertforsequenceclassif": 25, "distilbert_base_sequence_classifier_imdb": 25, "distilbertfortokenclassif": 26, "distilbert_base_token_classifier_conll03": 26, "albert_for_sequence_classif": [27, 76], "albert_for_token_classif": [27, 76], "bert_for_sequence_classif": [27, 76], "bert_for_token_classif": [27, 76], "bert_for_zero_shot_classif": [27, 76], "camembert_for_sequence_classif": [27, 76], "camembert_for_token_classif": [27, 76], "deberta_for_sequence_classif": [27, 76], "deberta_for_token_classif": [27, 76], "distil_bert_for_sequence_classif": [27, 76], "distil_bert_for_token_classif": [27, 76], "longformer_for_sequence_classif": [27, 76], "longformer_for_token_classif": [27, 76], "multi_classifier_dl": [27, 76], "roberta_for_sequence_classif": [27, 76], "roberta_for_token_classif": [27, 76], "sentiment_dl": [27, 76], "xlm_roberta_for_sequence_classif": [27, 76], "xlm_roberta_for_token_classif": [27, 76], "xlnet_for_sequence_classif": [27, 76], "xlnet_for_token_classif": [27, 76], "longformerforquestionansw": 28, "longform": [28, 29, 30, 63], "longformer_base_base_qa_squad2": 28, "longformerforsequenceclassif": 29, "longformer_base_sequence_classifier_imdb": 29, "4096": [29, 53, 63], "longformerfortokenclassif": 30, "xlnet_base_token_classifier_conll03": [30, 41], "longformer_base_token_classifier_conll03": 30, "multiclassifierdl": 31, "bidirect": [31, 54, 55, 61, 72, 108], "gru": 31, "convolut": [31, 44, 47], "machin": [31, 44, 60, 68, 78, 92, 108, 109, 111, 112, 162, 180], "strongli": 31, "relat": [31, 49, 51, 75, 187], "variant": [31, 48, 63, 67], "mai": [31, 128, 181, 182, 183, 186, 187], "instanc": [31, 95, 97, 98, 145, 149, 155, 156, 160], "multiclass": 31, "categor": [31, 166], "precis": [31, 49, 51], "constraint": 31, "mani": [31, 58, 64, 65, 78, 108, 109, 111, 112, 126], "formal": 31, "find": [31, 49, 51, 64, 65, 67, 73, 75, 81, 83, 108, 109], "binari": [31, 135, 150, 162], "bertsentenceembed": [31, 35, 55, 65, 71], "multiclassifi": [31, 162, 178], "001": [31, 48, 92, 93], "10": [31, 43, 49, 78, 83, 85, 94, 115, 162, 173, 181], "44": [31, 60, 68, 101], "shuffleperepoch": 31, "threshold": [31, 35, 60, 68, 78, 80, 92, 95, 113, 126], "minimum": [31, 35, 60, 68, 75, 78, 80, 90, 92, 93, 96, 103, 104, 108, 109, 112, 115, 116, 123, 124, 168], "ed58abb40640f983": 31, "pn": 31, "newsyou": 31, "toxic": 31, "a1237f726b5f5d89": 31, "dude": 31, "place": [31, 47], "obscen": 31, "insult": 31, "24b0d6c8733c2abe": 31, "thank": [31, 72, 78, 173], "8c4478fb239bcfc0": 31, "gee": 31, "minut": 31, "traindataset": [31, 162, 178], "printschema": [31, 127, 129, 135, 138], "root": [31, 43, 49, 51, 75, 127, 129, 135, 138, 169], "setcleanupmod": [31, 129, 138], "shrink": [31, 129, 138], "1e": [31, 162, 178], "setthreshold": [31, 35, 78, 80, 162, 178], "setvalidationsplit": [31, 98, 104], "setverbos": [31, 92, 93, 98], "multiclassifierdl_use_tox": 31, "comment": [31, 78], "jigsaw": 31, "good": [31, 56, 59, 67, 107], "stuff": 31, "wtf": 31, "kind": [31, 78, 83, 85], "crap": 31, "robertaforquestionansw": [32, 95], "roberta": [32, 33, 34, 37, 38, 39, 56, 58, 63, 64, 65, 70, 71, 95, 108], "roberta_base_qa_squad2": [32, 95], "robertaforsequenceclassif": 33, "roberta_base_sequence_classifier_imdb": 33, "robertafortokenclassif": 34, "roberta_base_token_classifier_conll03": 34, "sentimentdl": 35, "affect": [35, 124], "subject": [35, 49, 51], "view": 35, "common": [35, 73, 120, 128, 155, 185], "product": 35, "review": [35, 158], "tweet": 35, "interpret": [35, 73], "posit": [35, 58, 59, 70, 71, 72, 78, 91, 106, 107, 123, 126, 142, 162, 178], "final": [35, 63, 64, 65, 70, 71, 80, 93, 113, 182], "otheriws": [35, 80], "neutral": [35, 80], "thresholdlabel": [35, 80], "score": [35, 54, 55, 70, 71, 78, 80, 92, 93, 95, 106, 107, 109], "less": [35, 59, 80, 88, 92, 115], "watch": [35, 107], "32": [35, 53, 61, 173, 181, 187], "setthresholdlabel": [35, 80], "p": [35, 52, 60, 68, 80, 93, 98, 122], "sentimentdl_use_imdb": 35, "english": [35, 56, 78, 115, 118, 126, 166], "imdb": 35, "sentimentdl_use_twitt": 35, "wow": 35, "video": [35, 78], "awesom": 35, "bruh": 35, "damn": 35, "wast": [35, 107], "tapasforquestionansw": 36, "implement": [36, 60, 68, 70, 95, 104, 113, 133, 134, 143, 144, 151, 157, 161], "tapa": 36, "design": [36, 44, 46, 48, 54, 55, 64, 65, 82, 108, 111, 162, 178], "about": [36, 49, 51, 64, 65, 69, 78, 95, 103, 116, 137, 139, 181, 183, 186, 187], "tabular": [36, 140], "tabl": [36, 140], "tri": 36, "share": [36, 78, 183], "its": [36, 47, 58, 59, 63, 72, 78, 101, 106, 108, 111, 118, 162, 171], "table_qa_tapas_base_finetuned_wtq": 36, "document_assembl": [36, 95, 136, 140, 155], "table_json": 36, "document_t": [36, 140], "sentence_detector": [36, 76, 95, 102], "table_assembl": [36, 136, 155], "tableassembl": [36, 140], "stage": [36, 137, 139, 162, 178, 182, 183, 186], "json_data": 36, "monei": [36, 140], "ag": [36, 140], "donald": [36, 140], "trump": [36, 140], "000": [36, 78, 109, 126, 140], "75": [36, 78, 140], "elon": [36, 140], "musk": [36, 140], "55": [36, 94, 140, 173], "AS": [36, 43, 95], "who": [36, 122, 182], "earn": 36, "count": [36, 113], "old": [36, 43, 171], "xlmrobertaforquestionansw": 37, "xlm": [37, 38, 39, 70, 71], "xlm_roberta_base_qa_squad2": 37, "xlmrobertaforsequenceclassif": 38, "xlm_roberta_base_sequence_classifier_imdb": 38, "xlmrobertafortokenclassif": 39, "xlm_roberta_base_token_classifier_conll03": 39, "xlnetforsequenceclassif": 40, "xlnet": [40, 41, 72], "xlnet_base_sequence_classifier_imdb": 40, "xlnetfortokenclassif": 41, "spanbert_coref": 42, "spanbertcorefmodel": 43, "corefer": 43, "resolut": [43, 46], "spanbert": 43, "identifi": [43, 69, 78, 82, 86, 123, 124, 162, 183], "given": [43, 44, 46, 47, 73, 78, 95, 108, 109, 112, 113, 115, 116, 118, 161, 162], "told": [43, 85], "mari": [43, 55, 65, 71, 104], "he": [43, 58, 85, 122, 173], "borrow": 43, "book": [43, 52, 109, 113, 169], "her": [43, 95], "link": [43, 165], "ontonot": 43, "corefresolut": 43, "spanbert_base_coref": 43, "maxsegmentlength": 43, "textgenr": 43, "genr": 43, "One": [43, 78, 122, 141], "bc": 43, "broadcast": 43, "convers": 43, "bn": 43, "nw": 43, "wire": 43, "pt": 43, "pivot": 43, "testament": 43, "tc": 43, "telephon": 43, "wb": 43, "web": [43, 52, 56, 109, 162, 178], "setmaxsegmentlength": 43, "settextgenr": 43, "code": [43, 58, 60, 63, 64, 65, 68, 70, 71, 78, 80, 108, 112, 179, 187], "convnextforimageclassif": 44, "convnet": 44, "convnext": 44, "2020": [44, 78, 83, 85, 104], "zhuang": 44, "liu": [44, 46, 58, 64, 65], "hanzi": 44, "mao": 44, "chao": 44, "yuan": 44, "wu": 44, "christoph": 44, "feichtenhof": 44, "trevor": 44, "darrel": 44, "sain": 44, "xie": 44, "pure": [44, 47, 111], "inspir": [44, 107, 115, 116, 158], "vision": [44, 46, 47], "claim": 44, "outperform": [44, 63, 67, 70, 71, 72, 78, 109], "huggingfac": [44, 46, 47, 56], "convnextforimageclassificationtestspec": 44, "roar": 44, "visual": [44, 46, 162], "began": 44, "introduct": 44, "vit": [44, 47], "quickli": 44, "supersed": 44, "vanilla": 44, "hand": [44, 122], "face": 44, "difficulti": 44, "detect": [44, 46, 67, 79, 80, 102, 103, 104], "semant": [44, 46, 61, 67, 126], "hierarch": [44, 46, 60, 68], "swin": [44, 46], "reintroduc": 44, "sever": [44, 188], "prior": [44, 59, 63, 113], "practic": [44, 56, 108, 112], "viabl": 44, "backbon": [44, 46, 72], "demonstr": [44, 46, 59, 63, 78, 109, 111], "remark": 44, "wide": [44, 52, 54, 55, 58, 59, 70, 71, 108], "varieti": [44, 63, 70, 71, 187], "howev": [44, 53, 66, 72, 78, 96, 166, 181], "effect": [44, 46, 47, 63, 103, 108, 112], "hybrid": 44, "still": [44, 109, 162], "credit": 44, "superior": 44, "inher": 44, "induct": [44, 59], "bias": [44, 59], "reexamin": 44, "space": [44, 60, 68, 69, 88, 142], "achiev": [44, 58, 63, 64, 65, 70, 71, 72, 93, 108, 109, 111, 112, 137, 186], "gradual": 44, "modern": 44, "standard": [44, 46, 47, 52, 63, 83, 85, 108, 115, 116, 124], "resnet": 44, "toward": [44, 109], "discov": [44, 179], "compon": [44, 47, 97, 98, 127, 135, 145, 149, 160, 186], "contribut": 44, "along": [44, 75], "wai": [44, 49, 51, 73, 75, 139, 165], "outcom": 44, "explor": [44, 108, 112], "famili": [44, 52], "dub": [44, 70, 71], "construct": [44, 60, 68, 124, 165, 185], "compet": 44, "favor": 44, "term": [44, 78], "accuraci": [44, 46, 49, 51, 54, 55, 60, 67, 68, 70, 71, 92, 93, 101, 115, 126, 178], "scalabl": 44, "87": [44, 46], "imagenet": [44, 46, 47], "coco": [44, 46], "ade20k": [44, 46], "while": [44, 46, 47, 53, 59, 69, 78, 98, 109, 162, 178, 183], "maintain": 44, "simplic": [44, 108], "effici": [44, 46, 58, 60, 67, 68, 111, 181], "dores": [44, 46, 47], "resiz": [44, 46, 47], "certain": [44, 46, 47, 113], "donorm": [44, 46, 47], "deviat": [44, 46, 47], "featureextractortyp": [44, 46, 47], "architectur": [44, 46, 47, 53, 54, 55, 58, 64, 80, 93, 104, 108, 112], "featur": [44, 46, 47, 49, 60, 68, 78, 88, 92, 98, 162, 185], "imagemean": [44, 46, 47], "imagestd": [44, 46, 47], "resampl": [44, 46, 47], "filter": [44, 46, 47, 70, 71, 78, 91, 92, 108, 109, 111, 112, 118, 154, 166], "pil": [44, 46, 47], "nearest": [44, 46, 47], "bilinear": [44, 46, 47], "bicub": [44, 46, 47], "do_res": [44, 46, 47], "tupl": [44, 46, 47, 161], "dorescal": [44, 46], "rescal": [44, 46], "rescalefactor": [44, 46], "factor": [44, 46, 70, 71, 72, 108, 112, 113], "scale": [44, 46, 47, 53, 59, 63, 70, 71, 108, 109, 112], "croppct": 44, "percentag": [44, 69, 113, 126], "crop": 44, "imagedf": [44, 46, 47], "dropinvalid": [44, 46, 47], "imageassembl": [44, 46, 47, 135], "image_assembl": [44, 46, 47, 136, 155], "imageclassifi": [44, 46, 47], "pipelinedf": [44, 46, 47], "revers": [44, 46, 47], "split": [44, 46, 47, 103, 104, 120, 122, 123, 126], "image_nam": [44, 46, 47], "bluetick": [44, 46, 47], "jpg": [44, 46, 47], "chihuahua": [44, 46, 47], "egyptian_cat": [44, 46, 47], "jpeg": [44, 46, 47], "tabbi": [44, 46], "cat": [44, 46, 47], "hen": [44, 46, 47], "hippopotamu": [44, 46, 47], "hippo": [44, 46, 47], "river": [44, 46, 47], "hors": [44, 46, 47], "amphibiu": [44, 46, 47], "junco": [44, 46, 47], "snowbird": [44, 46, 47], "ostrich": [44, 46, 47], "struthio": [44, 46, 47], "camelu": [44, 46, 47], "ox": [44, 46, 47], "palac": [44, 46, 47], "tractor": [44, 46, 47], "thresher": 44, "thrasher": 44, "thresh": 44, "setdorescal": [44, 46], "boolean": [44, 46], "setrescalefactor": [44, 46], "255": [44, 46], "setcroppct": 44, "determin": [44, 70], "smaller": [44, 59, 60, 68], "224": 44, "256": 44, "specifi": [44, 94, 95, 104, 168, 169], "edg": [44, 59, 75], "afterward": 44, "image_classifier_convnext_tiny_224_loc": 44, "convnext_for_image_classif": 45, "swin_for_image_classif": 45, "vit_for_image_classif": 45, "swinforimageclassif": 46, "swinimageclassif": 46, "shift": 46, "window": [46, 60, 63, 68, 78, 93, 113], "ze": 46, "yutong": 46, "lin": 46, "yue": 46, "cao": 46, "han": 46, "hu": 46, "yixuan": 46, "zheng": 46, "zhang": 46, "stephen": 46, "bain": 46, "guo": 46, "whose": 46, "scheme": [46, 64, 108], "bring": [46, 182], "greater": [46, 78], "attent": [46, 47, 58, 63], "non": [46, 124, 126], "overlap": [46, 82, 87], "cross": [46, 70, 71, 94], "connect": 46, "image_classifier_swin_base_patch4_window7_224": 46, "swinforimageclassificationtest": 46, "present": [46, 53, 61, 63, 64, 65, 67, 70, 71, 75, 98, 104, 108, 111], "call": [46, 54, 55, 59, 78, 109, 161, 166, 168, 182, 188], "capabl": [46, 59, 72, 109], "serv": [46, 179], "purpos": [46, 59, 104], "adapt": 46, "aris": 46, "domain": [46, 78, 109], "variat": 46, "high": [46, 67, 70, 71, 108, 111], "compar": [46, 47, 53, 58, 59, 61, 72, 78, 104, 108, 112, 113, 162, 178], "variou": [46, 72, 176], "complex": [46, 61, 67, 78, 115, 116], "respect": [46, 58, 69, 92, 93, 171], "These": [46, 53, 64, 65, 72, 78, 92, 109, 165, 180], "broad": [46, 109], "rang": [46, 54, 55, 58, 59, 70, 71, 108], "1k": 46, "dens": [46, 54, 55], "box": 46, "ap": 46, "51": [46, 129, 138, 171], "53": [46, 82, 87], "miou": 46, "val": 46, "Its": [46, 51, 95, 108], "surpass": [46, 58], "previou": [46, 70, 71, 109, 182], "margin": [46, 72], "prove": 46, "benefici": [46, 78], "mlp": 46, "vitforimageclassif": 47, "altern": [47, 78, 106, 113, 115, 116, 137, 140, 182, 187], "neural": [47, 54, 55, 58, 93, 104, 108, 111], "network": [47, 54, 55, 61, 93, 104], "image_classifier_vit_base_patch16_224": 47, "vitimageclassificationtestspec": 47, "becom": [47, 53, 59, 78], "de": [47, 56, 78, 80, 111], "facto": [47, 78], "remain": [47, 52, 53, 59, 78], "conjunct": 47, "replac": [47, 52, 58, 63, 80, 81, 94, 104, 108, 115, 116, 182], "keep": [47, 78, 96, 108, 109, 112], "overal": [47, 69, 72], "structur": [47, 95, 142, 181], "relianc": 47, "cnn": [47, 80, 93, 104], "necessari": [47, 59, 178, 185], "directli": [47, 137, 162, 166, 178], "patch": 47, "veri": [47, 56, 61, 70, 71, 72, 108, 109, 111, 112, 137, 181, 183, 186, 187], "well": [47, 49, 51, 67, 70, 71, 78, 108, 140], "amount": [47, 67, 78, 87, 109, 126, 137, 186], "transfer": [47, 59, 67, 70, 71, 108, 109, 112], "mid": 47, "small": [47, 52, 53, 56, 59, 60, 68, 81, 101, 137, 171, 186], "cifar": 47, "vtab": 47, "etc": [47, 57, 130, 142, 178], "attain": 47, "excel": [47, 72], "substanti": [47, 54, 55], "fewer": [47, 53], "worth": 47, "16x16": 47, "egyptian": 47, "date2chunk": 48, "datematch": [48, 83], "multidatematch": [48, 83, 85], "entitynam": 48, "date_chunk": 48, "omicron": 48, "covid": 48, "world": [48, 52, 120, 162, 173, 178], "health": 48, "organ": [48, 78, 111], "nov": [48, 83, 85, 171], "26": [48, 91, 137, 154, 165, 173], "2021": [48, 83, 85], "118": [48, 140], "121": 48, "01": [48, 83, 85, 86], "setentitynam": 48, "dependencypars": [49, 51, 75], "dependencyparserapproach": [49, 169, 188], "unlabel": [49, 54, 55, 108, 109, 112], "grammat": [49, 51], "dependencyparsermodel": [49, 51, 75], "relationship": [49, 51, 67, 75], "tell": [49, 51, 78, 154], "verb": [49, 51, 169], "modifi": [49, 51, 64, 65, 91, 104], "describ": [49, 51, 75, 78, 111], "particular": [49, 51, 78, 166, 182], "treebank": 49, "penn": 49, "setdependencytreebank": 49, "conll": [49, 51, 92, 93, 155, 169, 170, 185], "u": [49, 51, 58, 59, 78, 85, 91, 92, 93, 137, 154, 165, 169, 180, 183, 188], "setconllu": [49, 51], "dependencytreebank": 49, "conllu": [49, 51, 81, 155, 170, 185], "numberofiter": [49, 51], "converg": [49, 51, 101, 126], "better": [49, 51, 53, 58, 72, 78, 92, 101, 103, 104, 107, 108, 126], "typeddependencyparserapproach": [49, 51], "postagg": [49, 51, 75, 92, 101], "dependency_treebank": 49, "emptydataset": [49, 51], "tree": [49, 75], "bank": 49, "setnumberofiter": [49, 51], "read_a": [49, 51, 73, 81, 82, 86, 87, 92, 96, 98, 106, 115, 116, 124, 148, 153, 155, 168, 169], "reada": [49, 51, 69, 73, 81, 82, 86, 87, 92, 96, 98, 106, 115, 116, 120, 124, 150, 153, 168, 169], "dep": 49, "dependency_conllu": [49, 75], "perceptron": [49, 76, 100], "typeddependencyparsermdoel": 49, "union": [49, 51], "worker": [49, 51], "turner": [49, 51], "newal": [49, 51], "sai": [49, 51, 78, 124], "disappoint": [49, 51], "talk": [49, 51], "stricken": [49, 51], "parent": [49, 51], "firm": [49, 51], "feder": [49, 51], "mogul": [49, 51], "dependency_pars": [50, 76, 166, 187], "typed_dependency_pars": [50, 76], "typeddependencypars": [51, 75], "conll2009": 51, "typeddependencyparsermodel": [51, 75], "beforehand": 51, "2009": 51, "setconll2009": 51, "dependency_typ": [51, 75], "train_smal": 51, "txt": [51, 60, 68, 69, 81, 82, 86, 87, 101, 104, 106, 113, 115, 116, 120, 124, 171, 172, 188], "descript": [51, 66, 78, 83, 115, 122, 150], "typdep": 51, "dependency_typed_conllu": [51, 75], "amod": 51, "flat": [51, 75, 132], "nsubj": [51, 75, 132, 169], "parataxi": 51, "documentnorm": 52, "raw": [52, 109, 122, 124, 126, 181, 183], "scrape": 52, "xml": 52, "remov": [52, 64, 65, 96, 107, 123, 130, 131, 132], "dirti": [52, 96], "regex": [52, 73, 83, 86, 96, 113, 115, 116, 123, 124, 126], "want": [52, 73, 94, 166, 183], "polici": 52, "__": [52, 108, 130, 131], "action": 52, "clean": [52, 96, 108, 112, 142, 183], "lowercas": [52, 96, 123, 126, 128], "pretty_al": 52, "utf": 52, "cleanuppattern": [52, 96], "normalizeddocu": 52, "setact": 52, "setpattern": [52, 123, 126], "setreplac": 52, "setpolici": 52, "setlowercas": [52, 96, 128, 142], "div": 52, "theworldsgreatest": 52, "right": [52, 54, 55, 108, 126], "hide": 52, "toptext": 52, "style": [52, 80, 112], "font": 52, "sego": 52, "ui": 52, "arial": 52, "san": [52, 78], "serif": 52, "largest": [52, 78, 109], "develop": [52, 78, 111, 159], "site": [52, 78], "h1": 52, "300": 52, "160": 52, "lorem": [52, 82, 87], "ipsum": [52, 82, 87], "simpli": [52, 183], "print": [52, 155, 166], "typeset": 52, "industri": 52, "been": [52, 56, 109, 141, 142, 166], "1500": 52, "unknown": [52, 80], "printer": 52, "took": 52, "gallei": 52, "scrambl": 52, "specimen": 52, "surviv": 52, "five": [52, 94], "centuri": [52, 126], "leap": 52, "electron": 52, "essenti": [52, 109], "unchang": 52, "popularis": 52, "1960": 52, "releas": [52, 53, 56, 58, 64, 65, 70, 71, 108, 112, 155], "letraset": 52, "passag": 52, "recent": [52, 54, 55, 58, 64, 65, 78, 108], "desktop": 52, "publish": [52, 64, 65], "softwar": 52, "aldu": 52, "pagemak": 52, "setencod": 52, "lite": 53, "googl": [53, 54, 55, 58, 60, 61, 64, 65, 67, 68, 78, 112, 169], "research": [53, 54, 55, 58, 60, 68, 111, 112], "toyota": 53, "technolog": 53, "institut": 53, "chicago": 53, "offici": [53, 78, 91, 92, 93, 137, 154, 165, 179], "tf": [53, 67], "wrapper": [53, 158], "port": 53, "properti": [53, 133, 134, 145, 148, 155], "albert_base_uncas": 53, "albert_bas": 53, "768": [53, 54, 55, 56, 58, 59, 63, 64, 65, 70, 71, 72], "emb": 53, "dim": 53, "12m": 53, "albert_large_uncas": 53, "albert_larg": 53, "1024": [53, 61, 63, 72], "24": [53, 72, 82, 87, 91, 113, 137, 154, 165, 181], "16": [53, 72, 94, 171, 181], "18m": 53, "albert_xlarge_uncas": 53, "albert_xlarg": 53, "2048": 53, "60m": 53, "albert_xxlarge_uncas": 53, "albert_xxlarg": 53, "235m": 53, "sentencepiec": [53, 58, 67], "everi": [53, 54, 55, 56, 58, 59, 63, 64, 65, 70, 71, 72, 93, 107, 111, 113, 129, 138, 139, 183], "dimens": [53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 149], "repeat": 53, "footprint": 53, "cost": [53, 113, 115], "similar": [53, 67, 78, 80], "through": [53, 75, 78, 132, 183], "FOR": 53, "http": [53, 56, 58, 60, 61, 67, 68, 108, 126, 179], "tfhub": [53, 61, 67], "q": 53, "increas": [53, 69, 78, 108, 109, 115], "often": [53, 64, 65, 72], "downstream": [53, 56, 58, 61, 63, 72, 108, 109, 112], "some": [53, 55, 70, 78, 93, 104, 109, 139, 162, 173, 181, 182, 186, 187], "point": [53, 54, 55, 103, 104, 129, 138, 168], "harder": 53, "gpu": [53, 108, 109, 111, 112, 155], "tpu": 53, "longer": [53, 60, 63, 68, 80, 187], "techniqu": [53, 58, 108, 109, 112], "consumpt": [53, 67, 69], "speed": [53, 92, 111], "devlin": [53, 64, 65], "et": [53, 64, 65, 80], "al": [53, 64, 65], "2019": [53, 56, 58, 64, 65, 70, 71, 108], "comprehens": [53, 108, 109], "empir": [53, 54, 55, 70, 71, 72], "evid": 53, "lead": [53, 56, 70, 71], "focus": [53, 78], "inter": 53, "coher": [53, 109], "As": [53, 54, 55, 59, 78], "establish": 53, "glue": [53, 54, 55, 59, 64, 65, 70, 71, 108], "race": [53, 58, 64, 65], "embeddingsfinish": [53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 130], "finished_embed": [53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "setoutputasvector": [53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 130], "setcleanannot": [53, 58, 59, 61, 63, 64, 66, 67, 69, 70, 72, 130, 131, 132], "80": [53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 86, 130, 142], "1342473030090332": [53, 58], "3855540752410889": [53, 58], "9818322062492371": [53, 58], "784737348556518": [53, 58], "847029983997345": [53, 58], "047153353691101": [53, 58], "1520637571811676": [53, 58], "6245765686035156": [53, 58], "009860038757324219": [53, 58], "13450059294700623": [53, 58], "707749128341675": [53, 58], "2916892766952": [53, 58], "04192575812339783": [53, 58], "5764210224151611": [53, 58], "3196685314178467": [53, 58], "527840495109": [53, 58], "15583214163780212": [53, 58], "1614152491092682": [53, 58], "28423872590065": [53, 58], "135491415858268": [53, 58], "bertembed": [54, 57, 66, 93, 130], "small_bert_l2_768": 54, "understand": [54, 55, 59, 70, 72, 78, 108, 112, 126, 181], "introduc": [54, 55, 59, 61, 63, 108, 112], "stand": [54, 55], "unlik": [54, 55, 70, 78, 122], "jointli": [54, 55], "condit": [54, 55, 108, 109, 112], "both": [54, 55, 61, 67, 75, 108, 182, 183], "left": [54, 55, 108, 126], "just": [54, 55, 59, 64, 88, 93], "without": [54, 55, 70, 71, 78, 109, 126], "modif": [54, 55], "conceptu": [54, 55], "power": [54, 55, 108, 112], "obtain": [54, 55, 56, 67], "eleven": [54, 55], "push": [54, 55], "absolut": [54, 55], "multinli": [54, 55], "86": [54, 55, 58], "v1": [54, 55], "f1": [54, 55, 70, 71, 93, 109], "93": [54, 55], "83": [54, 55, 58, 171, 172, 188], "small_bert_l2_128": 54, "3497989177703857": 54, "480538547039032": 54, "3238905668258667": 54, "612930893898010": 54, "1357314586639404": 54, "32984697818756104": 54, "6032363176345825": 54, "6791689395904": 54, "8244884014129639": 54, "27088963985443115": 54, "059438943862915": 54, "9817547798156": 54, "1648050546646118": 54, "4725411534309387": 54, "5938255786895752": 54, "5780693292617": 54, "9125322699546814": 54, "4563939869403839": 54, "3975459933280945": 54, "81611204147338": 54, "sentence_bert_embed": 55, "sent_small_bert_l2_768": 55, "islong": 55, "long": [55, 63, 72], "sent_small_bert_l2_128": 55, "orang": [55, 65, 71], "8951074481010437": [55, 65, 71], "13753940165042877": [55, 65, 71], "3108254075050354": [55, 65, 71], "65693199634552": [55, 65, 71], "6180210709571838": [55, 65, 71], "12179657071828842": [55, 65, 71], "191165953874588": [55, 65, 71], "4497021436691": [55, 65, 71], "822715163230896": [55, 65, 71], "7568016648292542": [55, 65, 71], "1165061742067337": [55, 65, 71], "59048593044281": [55, 65, 71], "setislong": 55, "camembertembed": 56, "tasti": 56, "french": [56, 78, 111, 118], "loui": 56, "martin": 56, "muller": 56, "pedro": 56, "javier": 56, "ortiz": 56, "su\u00e1rez": 56, "yoann": 56, "dupont": 56, "laurent": 56, "romari": 56, "\u00e9ric": 56, "villemont": 56, "la": [56, 111], "clergeri": 56, "djam\u00e9": 56, "seddah": 56, "beno\u00eet": 56, "sagot": 56, "facebook": [56, 58, 70, 71, 108], "138gb": 56, "camembert_bas": 56, "camembertembeddingstestspec": 56, "co": [56, 78], "ubiquit": 56, "despit": [56, 108], "most": [56, 59, 63, 78, 93, 108, 109, 111, 112], "concaten": [56, 126], "except": [56, 88, 93, 124], "investig": [56, 59, 67], "feasibl": 56, "monolingu": [56, 70, 71], "crawl": [56, 108, 112], "prefer": [56, 75, 132], "wikipedia": [56, 80, 109], "surprisingli": [56, 67], "4gb": 56, "those": [56, 75, 94, 182, 183], "larger": [56, 59, 64, 65, 108, 109, 111, 112], "130": 56, "gb": 56, "reach": [56, 78, 109, 126], "four": [56, 104, 126, 141], "un": [56, 80], "08442357927560806": 56, "12863239645957947": 56, "03835778683423996": 56, "200479581952": 56, "048462312668561935": 56, "12637358903884888": 56, "27429091930389404": 56, "07516729831": 56, "02690504491329193": 56, "12104076147079468": 56, "012526623904705048": 56, "031543646007": 56, "05877285450696945": 56, "08773420006036758": 56, "06381352990865707": 56, "122621834278": 56, "chunkembed": [57, 130], "wordembed": [57, 66, 69, 93, 130, 155], "chunker": [57, 76, 155], "ngramgener": [57, 88], "nerconvert": [57, 91, 92, 93, 162, 178], "poolingstrategi": [57, 66], "aggreg": [57, 66], "sum": [57, 61, 66], "skipoov": 57, "discard": [57, 95], "oov": 57, "ngram": [57, 88, 108, 109, 112], "setn": [57, 88], "wordembeddingsmodel": [57, 66, 69, 75, 92, 93, 94, 130], "setpoolingstrategi": [57, 66], "55661": 57, "42829502": 57, "86661": 57, "409785": 57, "06316501": 57, "120775": 57, "0732005": 57, "40674996": 57, "22938299": 57, "50597": 57, "288195": 57, "555655": 57, "465145": 57, "140118": 57, "17417": 57, "095253006": 57, "0530925": 57, "218465": 57, "714395": 57, "79860497": 57, "0129999": 57, "139705": 57, "177955": 57, "1887775": 57, "45545": 57, "20030999": 57, "461557": 57, "07891501": 57, "strategi": [57, 66, 86, 103, 113], "setskipoov": 57, "debertaembed": 58, "decod": [58, 63, 108, 109, 111, 112], "enhanc": [58, 107], "disentangl": 58, "pengcheng": 58, "xiaodong": 58, "jianfeng": 58, "gao": 58, "weizhu": 58, "chen": [58, 64, 65], "2018": [58, 64, 65], "half": [58, 78], "deberta_v3_bas": 58, "microsoft": [58, 111], "www": 58, "blog": 58, "human": [58, 78], "superglu": 58, "progress": [58, 104, 123], "significantli": [58, 61, 64, 65, 70, 71, 78], "novel": [58, 72, 78, 108], "mechan": [58, 63], "weight": [58, 61, 78, 92, 94, 113], "among": 58, "matric": 58, "second": [58, 61, 86, 103, 118, 123, 182], "mnli": 58, "9": [58, 70, 71, 88, 181, 186, 187], "90": 58, "91": 58, "88": 58, "made": [58, 67, 178], "publicli": [58, 70, 71], "distilbertembed": 59, "fast": [59, 107, 111, 137, 186], "cheap": 59, "distil": 59, "40": [59, 94, 111], "uncas": 59, "preserv": [59, 91, 123, 142], "95": 59, "measur": [59, 64, 65, 108, 162], "distilbert_base_cas": 59, "doesn": [59, 64], "token_type_id": [59, 64], "indic": [59, 64, 123, 126], "belong": [59, 64], "separ": [59, 64, 86, 88, 103, 104, 115, 124, 126, 131, 154, 168, 180], "sep_token": [59, 64], "sep": 59, "position_id": 59, "ad": [59, 61, 113], "though": [59, 78], "know": [59, 111, 139], "cheaper": 59, "lighter": 59, "preval": 59, "oper": [59, 63, 113, 122, 181], "constrain": 59, "budget": 59, "counterpart": 59, "leverag": [59, 162, 178], "reduc": [59, 115, 116, 142], "retain": 59, "97": [59, 83, 85, 126], "being": [59, 93, 98, 108, 111, 112], "tripl": [59, 75], "cosin": 59, "distanc": [59, 113, 115, 116], "devic": 59, "proof": 59, "concept": [59, 183], "experi": [59, 72, 108, 162, 179], "studi": [59, 64, 65, 108, 112], "1127224713563919": 59, "1982710212469101": 59, "5360898375511169": 59, "272536993026733": 59, "35534414649009705": 59, "13215228915214539": 59, "40981462597846985": 59, "14036104083061": 59, "328085333108902": 59, "06269335001707077": 59, "017595693469047546": 59, "024373905733": 59, "15617232024669647": 59, "2967822253704071": 59, "22324979305267334": 59, "04568954557180": 59, "45411425828933716": 59, "01173491682857275": 59, "190129816532135": 59, "1178255230188369": 59, "doc2vecapproach": 60, "word2vec": [60, 62, 76], "corpu": [60, 61, 68, 78, 81, 101, 108, 112, 113, 171, 188], "algorithm": [60, 68, 78, 92, 107, 113, 115, 116], "vocabulari": [60, 68, 108, 109, 112, 113], "skip": [60, 68, 75, 113], "gram": [60, 68, 78, 88, 108, 109, 112], "doc2vecmodel": 60, "vectors": [60, 68], "windows": [60, 68, 78], "numpartit": [60, 68], "partit": [60, 68, 168], "mincount": [60, 68, 113], "must": [60, 68, 81, 82, 86, 87, 98, 106, 107, 115, 116, 128, 154, 155, 162, 168], "appear": [60, 68, 113], "divid": [60, 68], "1000": [60, 68, 75, 92], "stepsiz": [60, 68], "optim": [60, 64, 65, 68, 93, 95, 104], "025": [60, 68], "maxit": [60, 68], "estim": [60, 68, 119, 133, 143, 151, 161, 182], "distribut": [60, 68], "composition": [60, 68], "sherlockholm": [60, 68, 113, 188], "setvectors": [60, 68], "setwindows": [60, 68, 78], "setsteps": [60, 68], "initi": [60, 68, 113, 123, 139, 155, 168, 169, 171, 172, 178], "setnumpartit": [60, 68], "setmaxit": [60, 68], "numiter": [60, 68], "equal": [60, 68], "setse": [60, 68], "setmincount": [60, 68, 113], "doc2vec_gigaword_300": 60, "06222493574023247": [60, 68], "011579325422644615": [60, 68], "009919632226228714": [60, 68], "109361454844": [60, 68], "doc2vec_wiki": 60, "elmoembed": 61, "elmo": 61, "billion": [61, 109], "computation": [61, 64, 65, 72, 108, 109, 111, 112], "expens": [61, 64, 65, 72, 106, 108, 109, 111, 112, 115], "lookup": [61, 69, 72, 82, 115, 116], "acceler": [61, 72, 108, 109, 111, 112, 155], "setpoolinglay": 61, "word_emb": 61, "shape": 61, "batch_siz": 61, "max_length": 61, "lstm_outputs1": 61, "lstm": [61, 93], "lstm_outputs2": 61, "trainabl": 61, "tensor": 61, "poolinglay": 61, "contextu": [61, 108, 113], "characterist": 61, "syntax": 61, "vari": 61, "across": [61, 109], "linguist": [61, 126], "polysemi": 61, "intern": [61, 97, 98, 113, 124, 126, 140, 145, 149, 155], "bilm": 61, "exist": [61, 113, 130, 132, 162], "six": [61, 115, 116], "textual": 61, "entail": 61, "expos": 61, "crucial": 61, "mix": [61, 144, 161], "semi": 61, "signal": 61, "662458181381226e": 61, "2541114091873169": 61, "6275503039360046": 61, "5787073969841": 61, "19154725968837738": 61, "22998669743537903": 61, "2894386649131775": 61, "21524395048618": 61, "10400570929050446": 61, "12288510054349899": 61, "07056470215320587": 61, "246389418840": 61, "49932169914245605": 61, "12706467509269714": 61, "30969417095184326": 61, "2643227577209": 61, "8871506452560425": 61, "20039963722229004": 61, "0601330995559692": 61, "0348707810044": 61, "albert_embed": [62, 76], "bert_embed": [62, 76], "bert_sentence_embed": [62, 76], "camembert_embed": [62, 76], "chunk_embed": [62, 76], "deberta_embed": [62, 76], "distil_bert_embed": [62, 76], "doc2vec": [62, 76], "elmo_embed": [62, 76], "longformer_embed": [62, 76], "roberta_embed": [62, 76], "roberta_sentence_embed": [62, 76], "universal_sentence_encod": [62, 76], "xlm_roberta_embed": [62, 76], "xlm_roberta_sentence_embed": [62, 76], "xlnet_embed": [62, 76], "longformerembed": 63, "iz": 63, "beltagi": 63, "matthew": 63, "arman": 63, "cohan": 63, "checkpoint": 63, "mlm": 63, "096": 63, "longformer_base_4096": 63, "unabl": 63, "quadrat": 63, "linearli": 63, "easi": 63, "thousand": 63, "drop": [63, 118], "motiv": 63, "global": 63, "text8": 63, "enwik8": 63, "contrast": [63, 82, 112], "finetun": [63, 72], "wikihop": 63, "triviaqa": 63, "led": [63, 64, 65, 78], "arxiv": [63, 108], "summar": [63, 78, 108, 109, 111, 112], "found": [63, 69, 78, 115, 122, 128, 168, 185], "18792399764060974": [63, 64], "14591649174690247": [63, 64], "20547787845134735": [63, 64], "1468472778797": [63, 64], "22845706343650818": [63, 64], "18073144555091858": [63, 64], "09725798666477203": [63, 64], "0417917296290": [63, 64], "07037967443466187": [63, 64], "14801117777824402": [63, 64], "03603338822722435": [63, 64], "17893412709": [63, 64], "08734266459941864": [63, 64], "2486150562763214": [63, 64], "009067727252840996": [63, 64], "24408400058": [63, 64], "22409197688102722": [63, 64], "4312366545200348": [63, 64], "1401449590921402": [63, 64], "356410235166549": [63, 64], "robertaembed": [64, 70], "robustli": [64, 65, 95], "yinhan": [64, 65], "myle": [64, 65, 70, 71], "ott": [64, 65, 70, 71], "naman": [64, 65, 70, 71], "goyal": [64, 65, 70, 71], "jingfei": [64, 65], "du": [64, 65, 80], "mandar": [64, 65], "joshi": [64, 65], "danqi": [64, 65], "omer": [64, 65], "levi": [64, 65], "mike": [64, 65], "lewi": [64, 65], "luke": [64, 65, 70, 71], "zettlemoy": [64, 65, 70, 71], "veselin": [64, 65, 70, 71], "stoyanov": [64, 65, 70, 71], "hyperparamet": [64, 65], "next": [64, 65, 78, 83, 85, 108, 109, 112], "mini": [64, 65], "roberta_bas": 64, "bpe": 64, "gpt": [64, 108, 109], "signific": [64, 65, 70, 71, 78, 81], "gain": [64, 65, 70, 71, 108], "care": [64, 65, 124], "comparison": [64, 65, 67, 118], "privat": [64, 65, 156], "choic": [64, 65, 86], "impact": [64, 65], "replic": [64, 65, 108], "carefulli": [64, 65], "undertrain": [64, 65], "exce": [64, 65], "highlight": [64, 65], "previous": [64, 65, 78], "overlook": [64, 65], "rais": [64, 65, 78, 88, 93, 162], "report": [64, 65, 67, 108, 162, 178], "robertasentenceembed": 65, "sent_roberta_bas": 65, "embeddingssent": 66, "22093398869037628": 66, "25130119919776917": 66, "41810303926467896": 66, "380883991718": 66, "dimension": 67, "tfhub_us": 67, "loadsp": 67, "op": 67, "lingual": [67, 70, 71, 78, 80, 111], "accur": [67, 107, 108, 115], "divers": [67, 108, 109, 112, 179], "trade": [67, 70, 71], "baselin": [67, 109], "tend": 67, "With": [67, 72, 78], "observ": 67, "minim": [67, 95, 111], "encourag": 67, "weat": 67, "bia": 67, "freeli": 67, "04616805538535118": 67, "022307956591248512": 67, "044395286589860916": 67, "0016493503": 67, "setloadsp": 67, "word2vecapproach": 68, "word2vecmodel": 68, "word2vec_gigaword_300": 68, "word2vec_wiki": 68, "custom": [69, 92, 93, 103, 104, 124, 155, 162], "dictionari": [69, 78, 81, 86, 92, 94, 95, 96, 106, 115, 116, 162], "setstoragepath": [69, 82], "line": [69, 73, 82, 87, 104, 106, 113, 165, 168, 171], "delimit": [69, 73, 75, 81, 86, 88, 92, 96, 106, 123, 140, 168, 171], "39658191506190343": 69, "630968081620067": 69, "5393722253731201": 69, "8428180123359783": 69, "were": [69, 93, 162, 178], "7535235923631415": 69, "9699218875629833": 69, "10397182122983872": 69, "11833962569383116": 69, "stress": 69, "0492683418305907": 69, "9415954572751959": 69, "47624463167525755": 69, "16790967216778263": 69, "induc": 69, "1535748762292387": 69, "33498936903209897": 69, "9235178224122094": 69, "1158772920395934": 69, "zero": [69, 95, 109], "withcoveragecolumn": 69, "overallcoverag": 69, "writebuffers": 69, "dump": 69, "disk": [69, 182, 183], "storag": [69, 73, 82, 148, 155], "10000": 69, "readcaches": 69, "cach": [69, 166], "higher": [69, 78, 107, 108, 109, 112], "random_embeddings_dim4": 69, "abov": [69, 75, 171], "setstorageref": 69, "glove_4d": 69, "setdimens": [69, 149], "patient": 69, "diagnos": 69, "diabet": 69, "9439099431037903": 69, "4707513153553009": 69, "806300163269043": 69, "16176554560661316": 69, "7966810464859009": 69, "5551124811172485": 69, "8861005902290344": 69, "28284206986427307": 69, "025029370561242104": 69, "35177749395370483": 69, "052506182342767715": 69, "1887107789516449": 69, "08617766946554184": 69, "8399239182472229": 69, "5395117998123169": 69, "7864698767662048": 69, "6599600911140442": 69, "16109347343444824": 69, "6041093468666077": 69, "8913561105728149": 69, "5955275893211365": 69, "01899011991918087": 69, "4397728443145752": 69, "8911281824111938": 69, "9840458631515503": 69, "7599489092826843": 69, "9417727589607239": 69, "8624503016471863": 69, "setwritebuffers": 69, "setreadcaches": 69, "glove_100d": [69, 93], "There": [69, 73, 75, 122, 180, 182, 183, 188], "conveni": 69, "coverag": [69, 147], "add": [69, 83, 85, 103, 108, 109, 112, 113, 124, 182], "stat": 69, "field": [69, 73, 87], "whole": [69, 165], "570580005645752": 69, "44183000922203064": 69, "7010200023651123": 69, "417129993438720": 69, "542639970779419": 69, "4147599935531616": 69, "0321999788284302": 69, "4024400115013122": 69, "2708599865436554": 69, "04400600120425224": 69, "020260000601410866": 69, "17395000159": 69, "6191999912261963": 69, "14650000631809235": 69, "08592499792575836": 69, "2629800140857": 69, "3397899866104126": 69, "20940999686717987": 69, "46347999572753906": 69, "6479200124740": 69, "embeddings_col": 69, "coverageresult": 69, "coverateresult": 69, "wordsoverallcoverag": 69, "resultdf": 69, "output_col": 69, "wordscoverag": 69, "cov_embed": 69, "loadstorag": [69, 82], "storage_ref": [69, 82], "xlmrobertaembed": 70, "alexi": [70, 71], "conneau": [70, 71], "kartikai": [70, 71], "khandelw": [70, 71], "vishrav": [70, 71], "chaudhari": [70, 71], "guillaum": [70, 71], "wenzek": [70, 71], "francisco": [70, 71, 78], "guzman": 70, "edouard": [70, 71], "grave": [70, 71], "5tb": [70, 71], "commoncrawl": [70, 71], "xlm_roberta_bas": 70, "xx": [70, 71, 80, 111], "multilingu": [70, 71, 126], "doe": [70, 78, 91, 137, 139, 166, 183, 186, 187], "abl": [70, 112, 162, 181], "correct": [70, 113, 115, 116, 126], "hundr": [70, 71], "terabyt": [70, 71], "r": [70, 71, 78], "mbert": [70, 71], "xnli": [70, 71], "mlqa": [70, 71], "particularli": [70, 71, 108], "low": [70, 71, 113], "swahili": [70, 71], "urdu": [70, 71], "capac": [70, 71, 109], "dilut": [70, 71], "sacrif": [70, 71], "ri": [70, 71], "competit": [70, 71, 78], "strong": [70, 71], "05969233065843582": 70, "030789051204919815": 70, "04443822056055069": 70, "09564960747": 70, "038839809596538544": 70, "011712731793522835": 70, "019954433664679527": 70, "0667808502": 70, "03952755779027939": 70, "03455188870429993": 70, "019103847444057465": 70, "04311436787": 70, "09579929709434509": 70, "02494969218969345": 70, "014753809198737144": 70, "10259044915": 70, "004710011184215546": 70, "022148698568344116": 70, "011723337695002556": 70, "013356896": 70, "xlmrobertasentenceembed": 71, "guzm\u00e3": 71, "sent_xlm_roberta_bas": 71, "xlnetembed": 72, "autoregress": 72, "permut": 72, "addition": [72, 93, 101, 129, 138, 165], "emploi": 72, "xl": 72, "exhibit": 72, "involv": [72, 104], "sota": 72, "rank": [72, 113], "xlnet_large_cas": 72, "xlnet_base_cas": 72, "full": [72, 182], "zihangdai": 72, "denois": [72, 108], "autoencod": [72, 108], "corrupt": [72, 108], "neglect": 72, "suffer": 72, "discrep": 72, "pro": 72, "con": 72, "enabl": [72, 93, 115, 155], "maxim": [72, 113], "likelihood": 72, "overcom": 72, "formul": 72, "furthermor": 72, "integr": [72, 78, 111, 162, 178, 180], "idea": 72, "6287205219268799": 72, "4865287244319916": 72, "186111718416214": 72, "234187275171279": 72, "1967450380325317": 72, "2746637463569641": 72, "9481253027915955": 72, "3431355059146881": 72, "0777631998062134": 72, "092679977416992": 72, "5331977605819702": 72, "11190271377563": 72, "8349916934967041": 72, "45627787709236145": 72, "7890847325325012": 72, "028069257736": 72, "134845569729805": 72, "11672890186309814": 72, "4945235550403595": 72, "66587203741073": 72, "entityrul": 73, "entityrulerapproach": 73, "exact": [73, 82, 87], "definit": [73, 95, 168], "json": [73, 140, 162, 173], "jsonl": 73, "setpatternsresourc": 73, "might": [73, 93, 126, 187], "rule": [73, 86, 106, 122, 124], "person": [73, 169], "w": [73, 76, 86, 92, 96, 122, 124, 155], "winterfel": 73, "jon": 73, "snow": [73, 94, 113], "stark": 73, "eddard": 73, "patternsresourc": 73, "usestorag": 73, "rocksdb": 73, "lord": 73, "29": [73, 94, 126, 171, 173], "38": [73, 173], "setusestorag": 73, "setsentencematch": 73, "setalphabetresourc": 73, "alphabet": [73, 96], "plain": [73, 188], "entityrulermodel": 73, "entity_rul": [74, 76], "graphextract": [75, 132], "graph": [75, 93, 111, 113, 119, 132], "nerdlmodel": [75, 91, 92, 93, 94, 162, 166, 178], "store": [75, 97, 98, 140, 145, 149, 160, 165, 173, 179], "node": 75, "relev": [75, 78], "taken": 75, "implicitli": 75, "setmergeent": 75, "automat": [75, 78, 95, 111, 115, 181, 182], "setdependencyparsermodel": 75, "settypeddependencyparsermodel": 75, "setrelationshiptyp": 75, "public": [75, 166, 182], "relationshiptyp": 75, "entitytyp": 75, "explodeent": 75, "roottoken": 75, "travers": 75, "maxsentences": 75, "minsentences": 75, "below": [75, 187], "mergeent": 75, "merg": [75, 82, 87], "neighbor": 75, "includeedg": 75, "symbol": [75, 113, 126], "posmodel": 75, "coordin": [75, 103], "remoteloc": 75, "graphfinish": [75, 132], "rdf": [75, 132], "nertagg": [75, 92, 93, 94], "morn": [75, 132], "flight": [75, 132], "denver": [75, 132], "18": [75, 83, 85, 88, 91, 94, 137, 154, 165, 181], "path1": 75, "setentitytyp": 75, "setexplodeent": 75, "setroottoken": 75, "setmaxsentences": 75, "setminsentences": 75, "setmergeentitiesiobformat": 75, "iob": [75, 91, 92, 93], "iob2": [75, 91], "setincludeedg": 75, "setdelimit": [75, 86, 88], "setposmodel": 75, "class": [76, 148, 152, 159, 170, 177, 178, 186, 188], "classifier_dl": [76, 155], "er": [76, 155], "keyword_extract": [76, 155], "yake_keyword_extract": [76, 77], "ld_dl": [76, 155], "language_detector_dl": [76, 79], "matcher": [76, 155], "big_text_match": [76, 84], "date_match": [76, 84], "multi_date_match": [76, 84], "regex_match": [76, 84], "text_match": [76, 84], "ner_approach": [76, 89], "ner_convert": [76, 89], "ner_crf": [76, 89], "ner_dl": [76, 89], "ner_overwrit": [76, 89], "param": [76, 92, 144, 145, 149, 155, 160, 161], "sentence_detector_dl": [76, 102, 111], "sentiment_detector": [76, 105], "vivekn_senti": [76, 105], "seq2seq": [76, 155], "bart_transform": [76, 110], "gpt2_transform": [76, 110], "marian_transform": [76, 110], "t5_transform": [76, 110], "spell_check": [76, 155], "context_spell_check": [76, 114], "norvig_sweet": [76, 114], "symmetric_delet": [76, 114], "chunk_token": [76, 121], "recursive_token": [76, 121], "regex_token": [76, 121], "word_segment": [76, 125], "chunk2_doc": [76, 155], "date2_chunk": [76, 155], "document_norm": [76, 155], "graph_extract": [76, 155], "lemmat": [76, 106, 118, 139, 142, 155], "n_gram_gener": [76, 155], "stemmer": [76, 118, 155], "stop_words_clean": [76, 155], "yakekeywordextract": 78, "yake": 78, "independ": [78, 115, 116, 122], "individu": [78, 113], "grow": 78, "autom": 78, "adequ": 78, "manner": 78, "emerg": [78, 108, 112], "tool": [78, 108], "system": [78, 108, 109], "nor": 78, "thesauri": 78, "neither": 78, "corpora": [78, 82], "thu": 78, "written": [78, 111], "plethora": 78, "situat": [78, 104], "access": 78, "restrict": 78, "therefor": [78, 186], "sent": 78, "boundari": [78, 103, 104, 107, 124, 126], "detector": [78, 83, 106], "section": [78, 129, 138, 178, 180, 186], "tweakabl": 78, "upper": 78, "bound": [78, 103, 104, 107], "minngram": 78, "maxngram": 78, "occurr": 78, "nkeyword": 78, "stopword": [78, 94, 118], "stop": [78, 92, 118], "campo": 78, "mangaravit": 78, "pasquali": 78, "jatowt": 78, "jorg": 78, "nune": 78, "scienc": [78, 179], "journal": [78, 126], "elsevi": 78, "vol": 78, "509": 78, "pp": [78, 126], "257": 78, "289": 78, "collect": [78, 162, 178], "turn": [78, 142, 182], "come": [78, 91], "fly": 78, "demand": 78, "abil": [78, 108, 109], "within": [78, 101, 107, 108, 109, 124, 128], "resort": 78, "alwai": [78, 112], "solut": 78, "articl": [78, 113], "rest": [78, 91], "merit": 78, "ten": 78, "experiment": 78, "carri": 78, "twenti": 78, "setcontextchar": [78, 124], "setminngram": 78, "setnkeyword": 78, "acquir": 78, "kaggl": 78, "platform": [78, 162, 180], "host": 78, "transact": 78, "somewhat": 78, "vagu": 78, "cloud": 78, "confer": 78, "week": [78, 83, 85, 120], "announc": [78, 94], "earli": 78, "tomorrow": [78, 83, 85], "phone": 78, "founder": 78, "ceo": 78, "anthoni": 78, "goldbloom": 78, "declin": 78, "deni": 78, "acquisit": 78, "happen": 78, "rumor": 78, "million": [78, 94, 109], "scientist": 78, "ben": 78, "hamner": 78, "2010": 78, "servic": [78, 111], "got": 78, "even": [78, 112], "few": [78, 124, 171, 188], "competitor": 78, "drivendata": 78, "topcod": 78, "hackerrank": 78, "stai": 78, "ahead": 78, "nich": 78, "home": [78, 155], "bui": [78, 169], "commun": 78, "mindshar": 78, "too": [78, 106, 181], "plenti": 78, "bit": [78, 104, 187], "histori": [78, 104, 113], "earlier": 78, "month": [78, 83, 85, 171, 188], "team": [78, 111, 162, 178], "around": 78, "youtub": 78, "That": [78, 122, 162, 178, 183], "had": 78, "technologi": 78, "did": 78, "interest": 78, "kernel": 78, "On": [78, 109, 111], "analyz": [78, 107], "compani": [78, 111], "script": 78, "centric": 78, "job": [78, 128], "board": [78, 101, 171], "unclear": 78, "accord": [78, 113, 168], "crunchbas": 78, "pitchbook": 78, "launch": 78, "investor": 78, "ventur": 78, "sv": 78, "angel": 78, "levchin": 78, "naravik": 78, "chie": 78, "economist": 78, "hal": 78, "varian": 78, "khosla": 78, "yuri": 78, "milner": 78, "resulttupl": 78, "ascend": 78, "orderbi": 78, "32051516486864573": 78, "37786450577630676": 78, "39922830978423146": 78, "40224744669493756": 78, "41584827825302534": 78, "setmaxngram": 78, "setstopword": [78, 94, 118], "getstopword": 78, "loaddefaultstopword": [78, 118], "danish": [78, 118], "dutch": [78, 118], "finnish": [78, 118], "german": [78, 118, 168, 188], "hungarian": [78, 118], "italian": [78, 113, 118], "norwegian": [78, 118], "portugues": [78, 118], "russian": [78, 118], "spanish": [78, 118], "swedish": [78, 118], "turkish": [78, 118], "languagedetectordl": 80, "ld": 80, "identif": 80, "rnn": 80, "tatoeba": 80, "140": 80, "wiki": 80, "languagedetector": 80, "ld_wiki_tatoeba_cnn_21": 80, "open": [80, 124, 128, 129, 130, 138, 142, 179], "advanc": [80, 128, 142], "scala": [80, 143, 144, 151, 157, 161], "program": 80, "biblioth\u00e8qu": 80, "traitement": 80, "pour": 80, "le": [80, 111], "avanc\u00e9": 80, "langag": 80, "naturel": 80, "programm": 80, "ist": 80, "ein": 80, "textverarbeitungsbibliothek": 80, "f\u00fcr": 80, "fortgeschritten": 80, "nat\u00fcrlich": 80, "sprachverarbeitung": 80, "die": 80, "programmiersprachen": 80, "und": 80, "lemma": [81, 106, 137, 165, 169, 183, 186, 187], "predefin": [81, 82, 86, 87, 106], "setdictionari": [81, 106, 115, 116], "lemmatizermodel": 81, "lemmas_smal": [81, 106], "setformcol": 81, "correspend": 81, "formcol": [81, 169], "setlemmacol": 81, "fromlemma": 81, "key_delimit": 81, "value_delimit": 81, "lemma_antbnc": 81, "bigtextmatch": [82, 87], "textmatch": [82, 87, 120], "externalresourc": [82, 87, 153], "mergeoverlap": [82, 87], "tokenizermodel": [82, 124], "trie": 82, "dolor": [82, 87], "magna": [82, 87], "aliqua": [82, 87], "sit": [82, 87], "laborum": [82, 87], "hello": [82, 87, 120, 173], "entityextractor": [82, 87, 120], "extractor": [82, 87, 120], "59": [82, 83, 85, 87], "setent": [82, 87, 90, 120], "setmergeoverlap": [82, 87], "settoken": 82, "tokenizer_model": 82, "bigtextmatchermodel": 82, "btm": 82, "textmatchermodel": [82, 87], "searchtri": 82, "datematcherutil": 83, "setinputformat": [83, 140], "setoutputformat": [83, 85], "desir": [83, 85], "yyyi": [83, 85], "mm": [83, 85, 126], "dd": [83, 85, 86], "Not": [83, 93, 139], "setreadmonthfirst": 83, "juli": 83, "5th": 83, "2015": 83, "07": 83, "05": 83, "setdefaultdaywhenmiss": 83, "dai": [83, 85, 113], "miss": [83, 85, 128], "setanchordateyear": [83, 85], "anchor": [83, 85], "year": [83, 85, 109, 120, 171], "setanchordatemonth": [83, 85], "januari": [83, 85], "setanchordatedai": [83, 85], "1978": [83, 85], "28": [83, 85, 91, 137, 154, 165, 173, 181], "1984": [83, 85], "04": [83, 85], "02": [83, 85], "1980": [83, 85], "79": [83, 85], "31st": [83, 85], "april": [83, 85], "2008": [83, 85], "fri": [83, 85], "1997": [83, 85], "jan": [83, 85], "sun": [83, 85], "1st": [83, 85], "thursdai": [83, 85], "wednesdai": [83, 85], "todai": [83, 85, 173], "yesterdai": [83, 85], "0600h": [83, 85], "06": [83, 85], "00": [83, 85], "hour": [83, 85], "6pm": [83, 85], "23": [83, 85, 86, 94, 101, 171, 172, 173, 188], "1988": [83, 85], "31": [83, 85, 86, 94, 101, 171], "dateformat": [83, 85], "readmonthfirst": [83, 85], "defaultdaywhenmiss": [83, 85], "anchordateyear": [83, 85], "anchordatemonth": [83, 85], "anchordatedai": [83, 85], "15": [83, 173], "saw": 85, "him": 85, "me": 85, "visit": 85, "57": [85, 94], "65": [85, 94], "regexmatch": 86, "d": [86, 96, 124, 180], "1970": 86, "setrul": 86, "setexternalrul": 86, "match_first": 86, "match_al": 86, "match_complet": 86, "externalrul": 86, "ceremoni": 86, "setstrategi": 86, "71": 86, "short_dat": 86, "regexmatchermodel": 86, "regardless": 87, "entityvalu": 87, "buildfromtoken": 87, "27": [87, 101, 103, 171], "48": [87, 126, 173], "setentityvalu": 87, "setbuildfromtoken": 87, "null": 88, "empti": [88, 128], "enablecumul": 88, "join": [88, 101, 140, 171], "setenablecumul": 88, "nerapproach": 90, "recogn": [90, 91, 92, 93, 94, 95, 113], "setminepoch": [90, 92], "setrandomse": [90, 93, 97], "getlabelcolumn": [90, 119], "friendli": [91, 111], "whitelist": [91, 122], "setwhitelist": [91, 122], "outsid": 91, "prefix": [91, 122, 124, 162, 178], "preserveposit": [91, 123, 142], "org": [91, 92, 93, 94, 108, 126, 137, 154, 155, 165, 168, 179, 188], "14": [91, 101, 137, 141, 154, 165, 171], "ekeu": [91, 92, 93, 137, 154, 165], "36": [91, 101, 137, 154, 165, 171, 173], "baghdad": [91, 92, 93, 137, 154, 165], "37": [91, 137, 154, 165], "setpreserveposit": [91, 123, 142], "setnerhasnoschema": 91, "nercrf": 92, "nercrfapproach": [92, 93], "nercrfmodel": [92, 93], "crf": [92, 93], "2003": [92, 93, 126, 168, 188], "exclud": [92, 93], "setexternalfeatur": 92, "minepoch": [92, 93], "l2": 92, "c0": 92, "decai": [92, 93], "gradient": 92, "2250000": 92, "lossep": 92, "ep": 92, "minw": 92, "includeconfid": [92, 93], "confid": [92, 93, 95], "externalfeatur": 92, "nerdlapproach": [92, 93, 168, 188], "trainingdata": [92, 93, 104, 115, 116, 168], "readdataset": [92, 93, 101, 126, 168, 169, 171, 172, 173, 188], "conll2003": [92, 93, 168, 188], "eng": [92, 93, 168, 188], "setl2": 92, "l2valu": 92, "setc0": 92, "c0valu": 92, "setlossep": 92, "setminw": 92, "setincludeconfid": [92, 93], "verbosevalu": 92, "prerequisit": [92, 93, 94, 182], "nerdl": 93, "char": [93, 96, 104], "bilstm": 93, "tagger": [93, 171, 188], "50": [93, 94, 101, 108, 109, 173], "real": [93, 155, 162, 178], "rage": 93, "graphfold": [93, 113], "usecontrib": 93, "contrib": 93, "cell": [93, 140], "slightli": [93, 104], "includeallconfidencescor": 93, "enablememoryoptim": 93, "slow": 93, "down": [93, 182, 183], "usebestmodel": 93, "bestmodelmetr": 93, "check": [93, 103, 113, 114, 115, 116, 137, 142, 165, 182, 187], "micro": 93, "macro": 93, "setgraphfold": [93, 113, 119], "setusecontrib": 93, "setpo": 93, "setincludeallconfidencescor": 93, "setenablememoryoptim": 93, "setusebestmodel": 93, "setbestmodelmetr": 93, "nermodel": 93, "neroverwrit": 94, "setnewresult": 94, "nerword": 94, "overwritten": 94, "newnerent": 94, "lab": 94, "42": [94, 101], "45": [94, 101, 171, 173], "47": [94, 171, 173], "66": 94, "ner_overwritten": 94, "setnerword": 94, "setnewnerent": 94, "cardin": 94, "setreplaceent": 94, "rw": 94, "zeroshotnermodel": 95, "shot": [95, 109], "zeroshotn": 95, "zer_shot_n": 95, "entitydefinit": 95, "citi": 95, "town": 95, "predictionthreshold": 95, "01f": 95, "ignoreent": 95, "zero_shot_n": 95, "setentitydefinit": 95, "hellen": 95, "5328949": 95, "9360068": 95, "83294415": 95, "45366877": 95, "setpredictionthreshold": 95, "zero_shot_ner_roberta": 95, "shortcut": 95, "stem": [96, 117, 137, 165, 186, 187], "henc": 96, "pl": 96, "slangdictionari": 96, "slang": 96, "minlength": [96, 103, 104, 123, 124], "maxlength": [96, 103, 104, 123, 124], "setcleanuppattern": 96, "punctuat": [96, 103], "alphanumer": 96, "letter": [96, 109, 113, 171, 188], "za": 96, "z": [96, 124], "brother": 96, "dont": [96, 107], "setslangdictionari": 96, "setminlength": [96, 103, 104, 123, 124], "setmaxlength": [96, 103, 104, 123, 124], "normalizermodel": 96, "classifierencod": 97, "attach": [97, 98, 145, 149, 160, 162], "evaluationdlparam": 98, "setevaluationlogextend": 98, "setenableoutputlog": [98, 162, 178], "setoutputlogspath": [98, 104, 162, 178], "assum": 98, "perceptronapproach": [101, 171, 188], "member": [101, 165], "datasetpath": 101, "pierr": [101, 171], "vinken": [101, 171], "34": [101, 171, 173], "md": [101, 171], "vb": [101, 168, 171, 188], "41": [101, 103, 171, 173], "43": [101, 103, 171, 173], "dt": [101, 171, 172, 188], "49": [101, 171], "poscol": [101, 126, 168], "niter": [101, 126], "anc": [101, 171, 188], "trainingperceptrondf": 101, "trainedpo": 101, "setposcolumn": [101, 126], "cd": [101, 168, 171], "setiter": 101, "getniter": [101, 126], "pos_anc": 101, "25": [101, 103, 171, 173], "33": [101, 173], "sentencedetectorparam": 103, "ii": 103, "abbrevi": 103, "period": 103, "geo": 103, "1026": 103, "253": 103, "553": 103, "ellipsi": 103, "quotat": 103, "mark": [103, 104, 126], "exclam": 103, "breaker": 103, "pragmaticcontentformatt": 103, "custombound": [103, 104], "setcustombound": [103, 104], "usecustomboundsonli": [103, 104], "explodesent": [103, 104, 168, 169], "useabbrevi": 103, "explicitli": [103, 104, 118, 154, 182], "customboundsstrategi": 103, "prepend": [103, 128], "break": 103, "append": [103, 113, 182], "parallel": [103, 104, 137, 168, 186], "splitlength": [103, 104], "forcibli": [103, 104], "99999": [103, 104, 124], "detectlist": 103, "nhow": 103, "setcustomboundsstrategi": 103, "setuseabbrevi": 103, "setdetectlist": 103, "setusecustomboundsonli": [103, 104], "setexplodesent": [103, 104], "setsplitlength": [103, 104], "sentencedetectordl": 104, "sentencedetectordlapproach": 104, "futur": [104, 108, 112], "setmodel": 104, "sentencedetectordlmodel": [104, 111], "modelarchitectur": 104, "impossiblepenultim": 104, "imposs": [104, 126], "penultim": 104, "epochsnumb": 104, "eo": 104, "stefan": 104, "schweter": 104, "sajawel": 104, "ahm": 104, "littl": [104, 187], "cover": [104, 108, 112, 126], "broken": 104, "moder": 104, "lack": 104, "easier": [104, 131, 184, 188], "polit": 104, "successor": 104, "great": 104, "respons": 104, "heritag": 104, "bequeath": 104, "nelson": 104, "mandela": 104, "setepochsnumb": 104, "model_architectur": 104, "validation_split": 104, "epochs_numb": 104, "output_logs_path": 104, "setimpossiblepenultim": 104, "impossible_penultim": 104, "sentencedl": 104, "sentencesdl": 104, "helen": 104, "total": [104, 126], "peopl": 104, "sentimentdetector": 106, "By": [106, 108, 112, 118, 123, 130, 155, 162, 178], "els": 106, "viveknsentimentapproach": [106, 107], "cool": 106, "superb": 106, "uninspir": 106, "sentimentscor": 106, "staff": 106, "restaur": 106, "nice": [106, 162, 178], "avoid": 106, "entri": [106, 129, 138, 166], "sttr": 106, "sentimentdetectormodel": 106, "sda": [106, 107], "pragmat": 106, "viveknsenti": 107, "analys": 107, "vivek": 107, "narayanan": 107, "give": 107, "transit": [107, 113], "sentimentcol": 107, "prunecorpu": 107, "unfrequ": 107, "scenario": 107, "scope": 107, "naiv": 107, "bay": 107, "vivekn": 107, "setsentimentcol": 107, "train_senti": 107, "result_senti": 107, "finish": [107, 130, 132, 136, 139, 155], "final_senti": 107, "cast": [107, 127], "horribl": 107, "never": [107, 182], "go": [107, 182], "again": [107, 122], "anyon": 107, "protagonist": 107, "music": 107, "setprunecorpu": 107, "frequenc": [107, 113, 115, 116, 126], "viveknsentimentmodel": 107, "sentiment_vivekn": 107, "barttransform": 108, "bart": 108, "translat": [108, 109, 111, 112, 126], "auto": [108, 119], "handl": [108, 152, 170], "captur": 108, "past": [108, 111], "incorpor": 108, "versatil": 108, "valuabl": 108, "t5": [108, 112], "settask": [108, 109, 112], "summari": [108, 109, 112], "distilbart_xsum_12_6": 108, "barttestspec": 108, "minoutputlength": [108, 109, 112], "maxoutputlength": [108, 109, 111, 112], "dosampl": [108, 109, 112], "sampl": [108, 109, 112], "greedi": [108, 109, 112], "temperatur": [108, 109, 112], "topk": [108, 109, 112], "highest": [108, 109, 112, 115], "beamsiz": 108, "beam": 108, "search": [108, 115], "topp": [108, 109, 112], "cumul": [108, 109, 112], "kept": [108, 109, 112], "repetitionpenalti": [108, 109, 112], "repetit": [108, 109, 112], "penalti": [108, 109, 112], "norepeatngrams": [108, 109, 112], "occur": [108, 109, 112], "onc": [108, 109, 112], "ignoretokenid": [108, 109, 112], "especi": [108, 109, 111, 112], "ab": 108, "1910": 108, "13461": 108, "pytorch": 108, "fairseq": 108, "arbitrari": 108, "nois": 108, "reconstruct": [108, 142], "tranform": 108, "seen": 108, "randomli": 108, "fill": 108, "dialogu": 108, "roug": 108, "bleu": 108, "ablat": 108, "influenc": [108, 113], "setmaxoutputlength": [108, 109, 111, 112], "200": [108, 112], "rich": [108, 112], "rise": [108, 112], "methodologi": [108, 112], "landscap": [108, 112], "unifi": [108, 112], "systemat": [108, 112], "dozen": [108, 112], "insight": [108, 112], "coloss": [108, 112], "facilit": [108, 112], "setignoretokenid": [108, 109, 111, 112], "setminoutputlength": [108, 109, 112], "setdosampl": [108, 109, 112], "settemperatur": [108, 109, 112], "settopk": [108, 109, 112], "settopp": [108, 109, 112], "setrepetitionpenalti": [108, 109, 112], "ctrl": [108, 109, 112], "control": [108, 109, 111, 112, 113], "setnorepeatngrams": [108, 109, 112], "setbeams": 108, "gpt2transform": 109, "gpt2": 109, "openai": 109, "caus": [109, 124], "goal": [109, 126], "direct": 109, "10x": 109, "synthet": 109, "unpreced": 109, "prime": 109, "lengthi": 109, "suggest": 109, "benefit": 109, "suffici": 109, "multitask": 109, "learner": 109, "typic": 109, "taskspecif": 109, "webpag": [109, 179], "webtext": 109, "plu": 109, "coqa": 109, "exceed": 109, "127": 109, "fashion": 109, "5b": 109, "underfit": 109, "reflect": 109, "paragraph": [109, 113], "promis": 109, "leonardo": 109, "man": 109, "1776": 109, "came": 109, "kingdom": 109, "mariantransform": 111, "marian": 111, "free": 111, "mainli": 111, "academ": 111, "notabl": 111, "edinburgh": 111, "adam": 111, "mickiewicz": 111, "pozna\u0144": 111, "commerci": 111, "contributor": 111, "mariannmt": 111, "engin": [111, 120], "behind": 111, "deploi": [111, 179], "opus_mt_en_fr": 111, "langid": 111, "maxinputlength": 111, "differenti": 111, "dynam": 111, "toolkit": 111, "setmaxinputlength": 111, "capit": [111, 113], "franc": 111, "quell": 111, "capital": 111, "devrait": 111, "savoir": 111, "fran\u00e7ai": 111, "setlangid": 111, "t5transform": 112, "reconsid": 112, "hyper": 112, "t5_small": 112, "contextspellcheck": 113, "contextspellcheckerapproach": [113, 115, 116], "noisi": 113, "spell": [113, 114, 115, 116, 137, 142, 185, 186, 187], "candid": [113, 115, 116, 124], "contextspellcheckermodel": [113, 115, 116], "error": 113, "surround": [113, 140], "edit": [113, 115, 116], "subword": 113, "checker": [113, 115, 116, 185], "languagemodelclass": 113, "lm": 113, "wordmaxdist": 113, "maxcandid": 113, "casestrategi": 113, "uppercas": 113, "errorthreshold": 113, "perplex": 113, "nlm": 113, "initialr": 113, "finalr": 113, "validationfract": 113, "datapoint": 113, "min": 113, "vocab": 113, "compoundcount": 113, "compound": 113, "classcount": 113, "special": [113, 126, 156, 183], "tradeoff": 113, "weighteddistpath": 113, "levenshtein": [113, 115, 116], "maxwindowlen": 113, "rememb": 113, "maxsentlen": 113, "norvigsweetingapproach": [113, 115, 116, 188], "symmetricdeleteapproach": [113, 115, 116, 188], "depth": [113, 185], "explan": [113, 185], "awar": 113, "sherlock": 113, "holm": 113, "spellcheck": [113, 115, 116], "setwordmaxdist": 113, "setepoch": 113, "setlanguagemodelclass": 113, "1650": 113, "addvocabclass": 113, "_name_": 113, "extra": [113, 115, 182], "dist": 113, "setmaxcandid": 113, "setcasestrategi": 113, "seterrorthreshold": 113, "setinitialr": 113, "setfinalr": 113, "setvalidationfract": 113, "fraction": 113, "setcompoundcount": 113, "setclasscount": 113, "settradeoff": 113, "alpha": 113, "setweighteddistpath": 113, "setmaxwindowlen": 113, "setmaxsentlen": 113, "sentlen": 113, "userdist": 113, "addregexclass": 113, "spellcheck_dl": 113, "gamma": 113, "decis": 113, "correctsymbol": 113, "comparelowcas": 113, "vocabfreq": 113, "idsvocab": 113, "vocabid": 113, "usenewlin": 113, "newlin": 113, "norvigsweetingmodel": [113, 115, 116], "symmetricdeletemodel": [113, 115, 116], "doc": [113, 172, 188], "cold": 113, "dreari": 113, "countri": 113, "white": 113, "smow": 113, "setweight": 113, "setgamma": 113, "setvocabfreq": 113, "setidsvocab": 113, "setvocabid": 113, "setclass": 113, "getwordclass": 113, "updateregexclass": 113, "updat": 113, "updatevocabclass": 113, "setcorrectsymbol": 113, "setcomparelowcas": 113, "norvigsweet": 115, "norvig": 115, "bayesian": 115, "tokenpattern": 115, "sensit": [115, 118, 124], "doublevari": 115, "shortcircuit": 115, "frequencyprior": 115, "ham": 115, "intersect": 115, "prioriti": [115, 124], "wordsizeignor": 115, "dupslimit": 115, "duplic": 115, "reductlimit": 115, "attempt": 115, "vowelswaplimit": 115, "vowel": 115, "swap": 115, "corrector": 115, "gummi": [115, 116], "gummic": [115, 116], "gummier": [115, 116], "gummiest": [115, 116], "gummifer": [115, 116], "basi": [115, 116], "token_pattern": [115, 116], "setdoublevari": 115, "setshortcircuit": 115, "setfrequencyprior": 115, "symmetr": [115, 116], "delet": [115, 116, 182], "damerau": [115, 116], "magnitud": [115, 116], "transpos": [115, 116], "insert": [115, 116, 182], "spellcheck_norvig": 115, "symspel": [115, 116], "somtim": 115, "wrrite": [115, 116], "wordz": [115, 116], "erong": [115, 116], "sometim": [115, 116, 182], "wrong": [115, 116], "symmetricdelet": 116, "deriv": 116, "teach": 116, "maxeditdist": 116, "frequencythreshold": [116, 126], "deletesthreshold": 116, "patttern": 116, "setmaxeditdist": 116, "setfrequencythreshold": [116, 126], "setdeletesthreshold": 116, "spellcheck_sd": 116, "spmetim": 116, "hard": 117, "employ": 117, "stopwordsclean": [118, 130, 142], "mllib": [118, 179], "stopwordsremov": 118, "cleantoken": [118, 130, 142], "stopwords_en": 118, "jvm": [118, 155], "forth": 118, "setlocal": 118, "tfnerdlgraphbuildermodel": 119, "tfnerdlgraphbuild": 119, "sethiddenunitsnumb": 119, "assertiondlapproach": 119, "medicalnerapproach": 119, "gethiddenunitsnumb": 119, "getinputcol": [119, 130, 131, 145], "srt": 119, "getgraphfold": 119, "setgraphfil": 119, "greaph": 119, "getgraphfil": 119, "chunktoken": 120, "flatten": 120, "artist": 120, "benezar": 120, "robert": 120, "farendel": 120, "graduat": 120, "luca": 120, "chunktokenizermodel": 120, "recursivetoken": 122, "recurs": [122, 139, 151, 155, 159], "suffix": [122, 124, 182], "infix": [122, 124], "middl": [122, 126], "she": 122, "qam": 122, "setprefix": 122, "setsuffix": 122, "setinfix": 122, "recursivetokenizermodel": 122, "regextoken": [123, 126, 183], "whitespac": [123, 126, 128], "tolowercas": [123, 126], "positionalmask": 123, "guarante": 123, "increment": 123, "trimwhitespac": 123, "flag": 123, "eventu": 123, "settolowercas": [123, 126], "nthi": 123, "setpositionalmask": 123, "settrimwhitespac": 123, "tokenizedsent": 124, "rulefactori": 124, "targetpattern": 124, "grab": 124, "prefixpattern": 124, "suffixpattern": 124, "infixpattern": 124, "sub": 124, "won": 124, "exceptionspath": 124, "casesensitiveexcept": 124, "contextchar": 124, "splitpattern": 124, "splitchar": 124, "didn": 124, "jane": 124, "boyfriend": 124, "getinfixpattern": 124, "getsuffixpattern": 124, "getprefixpattern": 124, "getcontextchar": 124, "getsplitchar": 124, "settargetpattern": 124, "setprefixpattern": 124, "setsuffixpattern": 124, "setinfixpattern": 124, "addinfixpattern": 124, "setexcept": 124, "getexcept": 124, "setexceptionspath": 124, "addexcept": 124, "setcasesensitiveexcept": 124, "getcasesensitiveexcept": 124, "addcontextchar": 124, "setsplitpattern": 124, "setsplitchar": 124, "addsplitchar": 124, "piec": 124, "token_rul": 124, "wordsegment": 126, "wordsegmenterapproach": 126, "korean": 126, "japanes": 126, "chines": 126, "correspond": [126, 162], "ll": 126, "rr": 126, "likewis": 126, "side": 126, "themselv": 126, "\u4e0a\u6d77": 126, "\u8ba1\u5212": 126, "\u5230": 126, "\u672c": 126, "\u4e16\u7eaa": 126, "\u672b": 126, "\u5b9e\u73b0": 126, "\u4eba\u5747": 126, "\u56fd\u5185": 126, "\u751f\u4ea7": 126, "\u603b\u503c": 126, "\u4e94\u5343": 126, "\u7f8e\u5143": 126, "\u4e0a": 126, "\u6d77": 126, "\u8ba1": 126, "\u5212": 126, "\u4e16": 126, "\u7eaa": 126, "\u5b9e": 126, "\u73b0": 126, "\u4eba": 126, "\u5747": 126, "\u56fd": 126, "\u5185": 126, "\u751f": 126, "\u4ea7": 126, "\u603b": 126, "ll\u503c": 126, "\u4e94": 126, "\u5343": 126, "\u7f8e": 126, "\u5143": 126, "shanghai": 126, "plan": 126, "dollar": 126, "capita": 126, "gdp": 126, "wordsegmentermodel": 126, "tip": 126, "frame": 126, "least": 126, "frequent": 126, "ambiguitythreshold": 126, "enableregextoken": 126, "xue": 126, "nianwen": 126, "volum": 126, "februari": 126, "aclweb": 126, "aclanthologi": 126, "o03": 126, "4002": 126, "chinese_train": 126, "utf8": 126, "\u5341": 126, "\u56db": 126, "\u4e0d": 126, "\u662f": 126, "setniter": 126, "trainingdataset": 126, "setambiguitythreshold": 126, "getfrequencythreshold": 126, "getambiguitythreshold": 126, "setenableregextoken": 126, "plit": 126, "words_seg": 126, "wordseg_pku": 126, "zh": 126, "\u7136\u800c": 126, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 126, "\u9019\u6a23": 126, "\u7684": 126, "\u8655\u7406": 126, "\u4e5f": 126, "\u884d\u751f": 126, "\u4e86": 126, "\u4e00\u4e9b": 126, "\u554f\u984c": 126, "prepar": [127, 129, 135, 138], "outputcol": [127, 129, 130, 131, 132, 135, 138], "inferschema": 127, "tmp": [127, 135, 155, 178], "librispeech_asr_dummy_clean_audio_array_parquet": 127, "float_arrai": 127, "getoutputcol": [127, 129, 130, 131, 135, 138, 145], "chunkcol": 128, "stringtyp": 128, "setisarrai": 128, "startcol": 128, "startcolbytokenindex": 128, "isarrai": 128, "failonmiss": 128, "fail": 128, "chunkassembl": 128, "setchunkcol": 128, "setstartcol": 128, "setstartcolbytokenindex": 128, "setfailonmiss": 128, "disabl": [129, 138], "idcol": [129, 138], "metadatacol": [129, 138], "cleanupmod": [129, 138], "cleanup": [129, 138], "inplac": [129, 138], "inplace_ful": [129, 138], "shrink_ful": [129, 138], "each_ful": [129, 138], "delete_ful": [129, 138], "setidcol": [129, 138], "setmetadatacol": [129, 138], "usabl": 130, "lda": 130, "forest": 130, "featurecol": 130, "cleanannot": [130, 131, 132], "outputasvector": 130, "gloveembed": 130, "finished_sentence_embed": 130, "resultwiths": 130, "1619900017976761": 130, "045552998781204224": 130, "03229299932718277": 130, "685609996318": 130, "42416998744010925": 130, "1378999948501587": 130, "5717899799346924": 130, "5078899860382": 130, "08621499687433243": 130, "15772999823093414": 130, "06067200005054474": 130, "395359992980": 130, "4970499873161316": 130, "7164199948310852": 130, "40119001269340515": 130, "05761000141501": 130, "08170200139284134": 130, "7159299850463867": 130, "20677000284194946": 130, "0295659992843": 130, "valuesplitsymbol": 131, "annotationsplitsymbol": 131, "includemetadata": 131, "outputasarrai": [131, 132], "parseembeddingsvector": 131, "setvaluesplitsymbol": 131, "setannotationsplitsymbol": 131, "setincludemetadata": [131, 183], "setoutputasarrai": [131, 132], "setparseembeddingsvector": 131, "finishedresult": 132, "hasrecursivefit": [133, 134], "java_obj": [133, 158, 161], "py4j": [133, 134, 161], "java_gatewai": [133, 134, 161], "javaobject": [133, 134, 161], "recursivepipelin": [133, 134, 139, 145], "hasrecursivetransform": 134, "doc2_chunk": [136, 155], "embeddings_finish": [136, 155], "graph_finish": [136, 155], "has_recursive_fit": [136, 155], "has_recursive_transform": [136, 155], "light_pipelin": [136, 155], "recursive_pipelin": [136, 155], "token2_chunk": [136, 155], "token_assembl": [136, 155], "lightpipelin": [137, 165, 186], "parse_embed": [137, 165], "execut": [137, 182, 186], "hold": [137, 186], "principl": [137, 186], "everyth": [137, 186, 187], "fullannot": [137, 165], "happi": [137, 181, 183, 186, 187], "prp": [137, 169, 171, 181, 186, 187, 188], "rb": [137, 171, 181, 186, 187, 188], "optional_target": [137, 165], "explain_document_pipelin": [137, 154, 165, 181, 186, 187], "dict_kei": [137, 165], "fullannotateimag": [137, 165], "path_to_imag": [137, 165], "setignoreunsupport": 137, "unsupport": 137, "annotatormodel": [137, 144, 166], "getignoreunsupport": 137, "text2": 138, "document1": 138, "document2": 138, "arg": [139, 158], "kwarg": 139, "decid": 139, "advantag": 139, "behav": 139, "exactli": 139, "intent": 139, "recursivepipelinemodel": 139, "pipeline_model": [139, 162, 178], "intend": 139, "tab": [140, 162, 178], "escap": 140, "quot": 140, "inputformat": 140, "csvdelimit": 140, "defailt": 140, "comma": 140, "escapecsvdelimit": 140, "table_csv": 140, "csv_data": 140, "input_format": 140, "setcsvdelimit": 140, "setescapecsvdelimit": 140, "token2chunk": 141, "17": [141, 171, 173], "tokenassembl": 142, "cleantext": 142, "opensourc": 142, "annotatorapproach": [143, 151, 162], "py": [143, 144, 151, 157, 161], "subclass": [144, 157, 161], "inherit": [144, 161], "ins": [144, 161], "uid": [144, 161], "annotatorproperti": 145, "setlazyannot": 145, "lazili": 145, "getlazyannot": 145, "annotator_approach": [148, 155], "annotator_model": [148, 155], "annotator_properti": [148, 155], "coverage_result": [148, 155], "recursive_annotator_approach": [148, 155], "hasembeddingsproperti": 149, "getdimens": 149, "constant": 150, "recursiveannotatorapproach": 151, "fo": 153, "assist": 154, "map_annot": 154, "f": [154, 162, 178], "output_typ": 154, "udf": 154, "userdefinedfunct": 154, "def": 154, "nnp_token": 154, "lambda": 154, "alia": 154, "epeu": 154, "map_annotations_arrai": 154, "map_annotations_strict": 154, "map_annotations_col": 154, "output_column": 154, "annotatyon_typ": 154, "chunks_df": 154, "pos_chunk": 154, "vbz": [154, 168, 188], "filter_by_annotations_col": 154, "filter_po": 154, "explode_annotations_col": 154, "annotator_java_ml": [155, 159], "annotator_transform": [155, 159], "extended_java_wrapp": [155, 159], "params_getters_sett": [155, 159], "comet": [155, 163, 180], "pretrained_pipelin": [155, 164], "resource_download": [155, 164], "pub_tat": [155, 170], "annotation_audio": 155, "annotation_imag": 155, "apple_silicon": 155, "aarch64": 155, "cache_fold": 155, "log_fold": 155, "cluster_tmp_dir": 155, "real_time_output": 155, "output_level": 155, "correctli": 155, "maco": 155, "linux": 155, "alloc": 155, "directori": [155, 166, 178], "cache_pretrain": 155, "temporarili": 155, "unpack": 155, "hadoop": 155, "dir": 155, "s3": 155, "hdf": 155, "dbf": 155, "annotator_log": 155, "annotatorjavamlread": 156, "mixin": 156, "javamlread": 156, "classmethod": 156, "mlreader": 156, "clazz": 156, "rl": 156, "javaparam": 156, "annotatortransform": 157, "ensur": 157, "_java_obj": 157, "extens": 158, "javawrapp": 158, "extendedjavawrapp": 158, "new_java_arrai": 158, "pylist": 158, "java_class": 158, "todo": 158, "chang": 158, "paramsgetterssett": 160, "getparamvalu": 160, "paramnam": 160, "setparamvalu": 160, "recursiveestim": 161, "overrid": 161, "recursivetransform": 161, "cometlogg": [162, 178], "workspac": 162, "project_nam": [162, 178], "comet_mod": [162, 178], "experiment_id": 162, "experiment_kwarg": 162, "logger": [162, 178], "meta": [162, 180], "practition": [162, 178], "reliabl": [162, 178], "streamlin": [162, 178], "lifecycl": [162, 178, 180], "track": [162, 178, 179], "explain": [162, 178, 185, 187], "reproduc": [162, 178, 179], "outputlogpath": [162, 178], "onlin": [162, 178], "reus": 162, "importerror": 162, "output_log_path": [162, 178], "embd": [162, 178], "setshuffleperepoch": [162, 178], "logdir": [162, 178], "interfac": [162, 178, 186], "chart": [162, 178], "attribut": 162, "comet_ml": [162, 178], "log_pipeline_paramet": [162, 178], "log_visu": [162, 178], "html": [162, 178], "viz": [162, 178], "upload": 162, "colum": [162, 178], "ner_chunk": [162, 178], "sparknlp_displai": [162, 178], "nervisu": [162, 178], "idx": [162, 178], "enumer": [162, 178], "label_col": [162, 178], "document_col": [162, 178], "return_html": [162, 178], "log_metr": [162, 178], "sklearn": [162, 178], "preprocess": [162, 178], "multilabelbinar": [162, 178], "classification_report": [162, 178], "preds_df": [162, 178], "topanda": [162, 178], "mlb": [162, 178], "y_true": [162, 178], "fit_transform": [162, 178], "y_pred": [162, 178], "output_dict": [162, 178], "log_paramet": 162, "log_completed_run": 162, "log_file_path": 162, "complet": [162, 179, 182], "log_asset": 162, "asset_path": 162, "asset": 162, "log_asset_data": 162, "interv": 162, "refresh": 162, "outstand": 162, "disk_loc": 165, "fulli": 165, "light_model": 165, "gather": 165, "langaug": 165, "resourcedownload": [166, 182, 187], "showpublicmodel": [166, 182], "onto_100": 166, "onto_300": 166, "ner_dl_bert": 166, "similarli": 166, "showpublicpipelin": [166, 187], "check_spel": [166, 187], "match_datetim": [166, 187], "downloadmodel": 166, "reader": 166, "j_dwn": 166, "pythonresourcedownload": 166, "downloadmodeldirectli": 166, "downloadpipelin": 166, "clearcach": 166, "clear": 166, "argument": 166, "filer": 166, "showuncategorizedresourc": 166, "yet": 166, "showavailableannot": 166, "documentcol": [168, 169], "sentencecol": [168, 169], "tokencol": 168, "conlllabelindex": 168, "conllposindex": 168, "conlldocidcol": 168, "doc_id": [168, 172], "textcol": [168, 169], "labelcol": 168, "includedocid": 168, "docstart": [168, 188], "eu": [168, 188], "np": [168, 188], "reject": [168, 188], "vp": [168, 188], "misc": [168, 188], "boycott": [168, 188], "british": [168, 188], "lamb": [168, 188], "blackburn": 168, "brussel": 168, "1996": 168, "08": 168, "storage_level": 168, "storagelevel": 168, "disk_onli": 168, "lift": 168, "persist": 168, "uposcol": 169, "upo": 169, "xposcol": 169, "xpo": 169, "lemmacol": 169, "sent_id": 169, "sell": 169, "pron": 169, "nom": 169, "plur": 169, "_": 169, "tens": 169, "conj": 169, "cc": 169, "obj": 169, "spaceaft": 169, "No": [169, 181], "punct": 169, "conllufil": [169, 188], "conlldataset": [169, 188], "morph": 169, "Into": 169, "googleo": 169, "sconj": 169, "propn": 169, "adp": 169, "wp": 169, "vbd": [169, 171, 188], "ago": [171, 188], "receiv": [171, 188], "posdf": 171, "61": 171, "56": 171, "67": [171, 172, 188], "nonexecut": 171, "69": 171, "76": 171, "director": 171, "78": 171, "81": 171, "84": 171, "outputposcol": 171, "outputdocumentcol": 171, "outputtextcol": 171, "pubtat": [172, 185], "medic": [172, 188], "titl": [172, 188], "medment": [172, 188], "25763772": [172, 188], "dctn4": [172, 188], "t116": [172, 188], "t123": [172, 188], "c4308010": [172, 188], "63": [172, 188], "chronic": [172, 188], "pseudomona": [172, 188], "aeruginosa": [172, 188], "infect": [172, 188], "t047": [172, 188], "c0854135": [172, 188], "82": [172, 188], "cystic": [172, 188], "fibrosi": [172, 188], "c0010674": [172, 188], "120": [172, 188], "pa": [172, 188], "124": [172, 188], "139": [172, 188], "pubtatorfil": 172, "corpus_pubtator_sampl": 172, "pubtatordataset": 172, "finished_token": [172, 183], "finished_po": 172, "finished_n": 172, "finished_token_metadata": 172, "finished_pos_metadata": 172, "finished_label_metadata": 172, "mo": 172, "ispaddedtoken": 172, "pad": 172, "spacytoannot": 173, "token_spac": 173, "sentence_end": 173, "spaci": 173, "multi_doc_token": 173, "went": 173, "night": 173, "bought": 173, "bread": 173, "54": 173, "46": 173, "overview": [177, 185], "workflow": 178, "dedic": 178, "account": 178, "inspect": 178, "init": 178, "sparknlp_experi": 178, "offline_directori": 178, "later": 178, "nativ": 179, "record": 179, "queri": 179, "registri": 179, "central": 179, "send": 180, "messag": 180, "mlflow": 180, "content": [181, 187], "clearli": 181, "explain_document_ml": [181, 186, 187], "approx": [181, 186, 187], "mb": [181, 186, 187], "ok": [181, 186, 187], "spearhead": 182, "produc": 182, "declar": 182, "accordingli": 182, "extra_loc": 182, "offer": [182, 184, 187], "classifierdl_use_trec50": 182, "classifierdl_use_spam": 182, "column_nam": 182, "preced": 182, "interchang": 183, "anoth": 183, "road": 183, "proce": 183, "At": 183, "sens": 187, "constantli": 187, "server": 187, "train_po": 188, "training_conl": 188, "train_corpu": 188, "withcolumnrenam": 188, "trainingpubtatordf": 188, "corpus_pubt": 188}, "objects": {"": [[155, 0, 0, "-", "sparknlp"]], "sparknlp": [[2, 0, 0, "-", "annotation"], [3, 0, 0, "-", "annotation_audio"], [4, 0, 0, "-", "annotation_image"], [76, 0, 0, "-", "annotator"], [136, 0, 0, "-", "base"], [148, 0, 0, "-", "common"], [154, 0, 0, "-", "functions"], [159, 0, 0, "-", "internal"], [163, 0, 0, "-", "logging"], [164, 0, 0, "-", "pretrained"], [155, 3, 1, "", "start"], [170, 0, 0, "-", "training"], [175, 0, 0, "-", "upload_to_hub"], [176, 0, 0, "-", "util"], [155, 3, 1, "", "version"]], "sparknlp.annotation": [[2, 1, 1, "", "Annotation"]], "sparknlp.annotation.Annotation": [[2, 2, 1, "", "arrayType"], [2, 2, 1, "", "copy"], [2, 2, 1, "", "dataType"], [2, 2, 1, "", "fromRow"], [2, 2, 1, "", "toRow"]], "sparknlp.annotation_audio": [[3, 1, 1, "", "AnnotationAudio"]], "sparknlp.annotation_audio.AnnotationAudio": [[3, 2, 1, "", "copy"]], "sparknlp.annotation_image": [[4, 1, 1, "", "AnnotationImage"]], "sparknlp.annotation_image.AnnotationImage": [[4, 2, 1, "", "copy"]], "sparknlp.annotator": [[6, 0, 0, "-", "audio"], [8, 0, 0, "-", "chunk2_doc"], [9, 0, 0, "-", "chunker"], [27, 0, 0, "-", "classifier_dl"], [42, 0, 0, "-", "coref"], [45, 0, 0, "-", "cv"], [48, 0, 0, "-", "date2_chunk"], [50, 0, 0, "-", "dependency"], [52, 0, 0, "-", "document_normalizer"], [62, 0, 0, "-", "embeddings"], [74, 0, 0, "-", "er"], [75, 0, 0, "-", "graph_extraction"], [77, 0, 0, "-", "keyword_extraction"], [79, 0, 0, "-", "ld_dl"], [81, 0, 0, "-", "lemmatizer"], [84, 0, 0, "-", "matcher"], [88, 0, 0, "-", "n_gram_generator"], [89, 0, 0, "-", "ner"], [96, 0, 0, "-", "normalizer"], [99, 0, 0, "-", "param"], [100, 0, 0, "-", "pos"], [102, 0, 0, "-", "sentence"], [105, 0, 0, "-", "sentiment"], [110, 0, 0, "-", "seq2seq"], [114, 0, 0, "-", "spell_check"], [117, 0, 0, "-", "stemmer"], [118, 0, 0, "-", "stop_words_cleaner"], [119, 0, 0, "-", "tf_ner_dl_graph_builder"], [121, 0, 0, "-", "token"], [125, 0, 0, "-", "ws"]], "sparknlp.annotator.audio": [[5, 0, 0, "-", "hubert_for_ctc"], [7, 0, 0, "-", "wav2vec2_for_ctc"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, 1, 1, "", "HubertForCTC"]], "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC": [[5, 2, 1, "", "loadSavedModel"], [5, 2, 1, "", "pretrained"], [5, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, 1, 1, "", "Wav2Vec2ForCTC"]], "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[7, 2, 1, "", "loadSavedModel"], [7, 2, 1, "", "pretrained"], [7, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.chunk2_doc": [[8, 1, 1, "", "Chunk2Doc"]], "sparknlp.annotator.chunker": [[9, 1, 1, "", "Chunker"]], "sparknlp.annotator.chunker.Chunker": [[9, 2, 1, "", "setRegexParsers"]], "sparknlp.annotator.classifier_dl": [[10, 0, 0, "-", "albert_for_question_answering"], [11, 0, 0, "-", "albert_for_sequence_classification"], [12, 0, 0, "-", "albert_for_token_classification"], [13, 0, 0, "-", "bert_for_question_answering"], [14, 0, 0, "-", "bert_for_sequence_classification"], [15, 0, 0, "-", "bert_for_token_classification"], [16, 0, 0, "-", "bert_for_zero_shot_classification"], [17, 0, 0, "-", "camembert_for_question_answering"], [18, 0, 0, "-", "camembert_for_sequence_classification"], [19, 0, 0, "-", "camembert_for_token_classification"], [20, 0, 0, "-", "classifier_dl"], [21, 0, 0, "-", "deberta_for_question_answering"], [22, 0, 0, "-", "deberta_for_sequence_classification"], [23, 0, 0, "-", "deberta_for_token_classification"], [24, 0, 0, "-", "distil_bert_for_question_answering"], [25, 0, 0, "-", "distil_bert_for_sequence_classification"], [26, 0, 0, "-", "distil_bert_for_token_classification"], [28, 0, 0, "-", "longformer_for_question_answering"], [29, 0, 0, "-", "longformer_for_sequence_classification"], [30, 0, 0, "-", "longformer_for_token_classification"], [31, 0, 0, "-", "multi_classifier_dl"], [32, 0, 0, "-", "roberta_for_question_answering"], [33, 0, 0, "-", "roberta_for_sequence_classification"], [34, 0, 0, "-", "roberta_for_token_classification"], [35, 0, 0, "-", "sentiment_dl"], [36, 0, 0, "-", "tapas_for_question_answering"], [37, 0, 0, "-", "xlm_roberta_for_question_answering"], [38, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [39, 0, 0, "-", "xlm_roberta_for_token_classification"], [40, 0, 0, "-", "xlnet_for_sequence_classification"], [41, 0, 0, "-", "xlnet_for_token_classification"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, 1, 1, "", "AlbertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[10, 2, 1, "", "loadSavedModel"], [10, 2, 1, "", "pretrained"], [10, 2, 1, "", "setConfigProtoBytes"], [10, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, 1, 1, "", "AlbertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[11, 2, 1, "", "getClasses"], [11, 2, 1, "", "loadSavedModel"], [11, 2, 1, "", "pretrained"], [11, 2, 1, "", "setCoalesceSentences"], [11, 2, 1, "", "setConfigProtoBytes"], [11, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, 1, 1, "", "AlbertForTokenClassification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[12, 2, 1, "", "getClasses"], [12, 2, 1, "", "loadSavedModel"], [12, 2, 1, "", "pretrained"], [12, 2, 1, "", "setConfigProtoBytes"], [12, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, 1, 1, "", "BertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[13, 2, 1, "", "loadSavedModel"], [13, 2, 1, "", "pretrained"], [13, 2, 1, "", "setConfigProtoBytes"], [13, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, 1, 1, "", "BertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[14, 2, 1, "", "getClasses"], [14, 2, 1, "", "loadSavedModel"], [14, 2, 1, "", "pretrained"], [14, 2, 1, "", "setCoalesceSentences"], [14, 2, 1, "", "setConfigProtoBytes"], [14, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, 1, 1, "", "BertForTokenClassification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[15, 2, 1, "", "getClasses"], [15, 2, 1, "", "loadSavedModel"], [15, 2, 1, "", "pretrained"], [15, 2, 1, "", "setConfigProtoBytes"], [15, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification": [[16, 1, 1, "", "BertForZeroShotClassification"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification": [[16, 2, 1, "", "getClasses"], [16, 2, 1, "", "loadSavedModel"], [16, 2, 1, "", "pretrained"], [16, 2, 1, "", "setCoalesceSentences"], [16, 2, 1, "", "setConfigProtoBytes"], [16, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[17, 1, 1, "", "CamemBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering": [[17, 2, 1, "", "loadSavedModel"], [17, 2, 1, "", "pretrained"], [17, 2, 1, "", "setConfigProtoBytes"], [17, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[18, 1, 1, "", "CamemBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification": [[18, 2, 1, "", "getClasses"], [18, 2, 1, "", "loadSavedModel"], [18, 2, 1, "", "pretrained"], [18, 2, 1, "", "setCoalesceSentences"], [18, 2, 1, "", "setConfigProtoBytes"], [18, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[19, 1, 1, "", "CamemBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[19, 2, 1, "", "getClasses"], [19, 2, 1, "", "loadSavedModel"], [19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setConfigProtoBytes"], [19, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[20, 1, 1, "", "ClassifierDLApproach"], [20, 1, 1, "", "ClassifierDLModel"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[20, 2, 1, "", "setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[21, 1, 1, "", "DeBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[22, 1, 1, "", "DeBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[22, 2, 1, "", "getClasses"], [22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setCoalesceSentences"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[23, 1, 1, "", "DeBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[23, 2, 1, "", "getClasses"], [23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[24, 1, 1, "", "DistilBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[25, 1, 1, "", "DistilBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[25, 2, 1, "", "getClasses"], [25, 2, 1, "", "loadSavedModel"], [25, 2, 1, "", "pretrained"], [25, 2, 1, "", "setCoalesceSentences"], [25, 2, 1, "", "setConfigProtoBytes"], [25, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[26, 1, 1, "", "DistilBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[26, 2, 1, "", "getClasses"], [26, 2, 1, "", "loadSavedModel"], [26, 2, 1, "", "pretrained"], [26, 2, 1, "", "setConfigProtoBytes"], [26, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[28, 1, 1, "", "LongformerForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[28, 2, 1, "", "loadSavedModel"], [28, 2, 1, "", "pretrained"], [28, 2, 1, "", "setConfigProtoBytes"], [28, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[29, 1, 1, "", "LongformerForSequenceClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[29, 2, 1, "", "getClasses"], [29, 2, 1, "", "loadSavedModel"], [29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setCoalesceSentences"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[30, 1, 1, "", "LongformerForTokenClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[30, 2, 1, "", "getClasses"], [30, 2, 1, "", "loadSavedModel"], [30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[31, 1, 1, "", "MultiClassifierDLApproach"], [31, 1, 1, "", "MultiClassifierDLModel"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[31, 2, 1, "", "setThreshold"], [31, 2, 1, "", "setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setThreshold"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[32, 1, 1, "", "RoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[32, 2, 1, "", "loadSavedModel"], [32, 2, 1, "", "pretrained"], [32, 2, 1, "", "setConfigProtoBytes"], [32, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[33, 1, 1, "", "RoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[33, 2, 1, "", "getClasses"], [33, 2, 1, "", "loadSavedModel"], [33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setCoalesceSentences"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[34, 1, 1, "", "RoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[34, 2, 1, "", "getClasses"], [34, 2, 1, "", "loadSavedModel"], [34, 2, 1, "", "pretrained"], [34, 2, 1, "", "setConfigProtoBytes"], [34, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[35, 1, 1, "", "SentimentDLApproach"], [35, 1, 1, "", "SentimentDLModel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[35, 2, 1, "", "setDropout"], [35, 2, 1, "", "setThreshold"], [35, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[35, 2, 1, "", "pretrained"], [35, 2, 1, "", "setConfigProtoBytes"], [35, 2, 1, "", "setThreshold"], [35, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[36, 1, 1, "", "TapasForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[36, 2, 1, "", "loadSavedModel"], [36, 2, 1, "", "pretrained"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[37, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"], [37, 2, 1, "", "setConfigProtoBytes"], [37, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[38, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[38, 2, 1, "", "getClasses"], [38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setCoalesceSentences"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[39, 1, 1, "", "XlmRoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[39, 2, 1, "", "getClasses"], [39, 2, 1, "", "loadSavedModel"], [39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[40, 1, 1, "", "XlnetForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[40, 2, 1, "", "getClasses"], [40, 2, 1, "", "loadSavedModel"], [40, 2, 1, "", "pretrained"], [40, 2, 1, "", "setCoalesceSentences"], [40, 2, 1, "", "setConfigProtoBytes"], [40, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[41, 1, 1, "", "XlnetForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[41, 2, 1, "", "getClasses"], [41, 2, 1, "", "loadSavedModel"], [41, 2, 1, "", "pretrained"], [41, 2, 1, "", "setConfigProtoBytes"], [41, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.coref": [[43, 0, 0, "-", "spanbert_coref"]], "sparknlp.annotator.coref.spanbert_coref": [[43, 1, 1, "", "SpanBertCorefModel"]], "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[43, 2, 1, "", "loadSavedModel"], [43, 2, 1, "", "pretrained"], [43, 2, 1, "", "setConfigProtoBytes"], [43, 2, 1, "", "setMaxSegmentLength"], [43, 2, 1, "", "setMaxSentenceLength"], [43, 2, 1, "", "setTextGenre"]], "sparknlp.annotator.cv": [[44, 0, 0, "-", "convnext_for_image_classification"], [46, 0, 0, "-", "swin_for_image_classification"], [47, 0, 0, "-", "vit_for_image_classification"]], "sparknlp.annotator.cv.convnext_for_image_classification": [[44, 1, 1, "", "ConvNextForImageClassification"]], "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification": [[44, 2, 1, "", "getClasses"], [44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"], [44, 2, 1, "", "setConfigProtoBytes"], [44, 2, 1, "", "setCropPct"], [44, 2, 1, "", "setDoRescale"], [44, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[46, 1, 1, "", "SwinForImageClassification"]], "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification": [[46, 2, 1, "", "getClasses"], [46, 2, 1, "", "loadSavedModel"], [46, 2, 1, "", "pretrained"], [46, 2, 1, "", "setConfigProtoBytes"], [46, 2, 1, "", "setDoRescale"], [46, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.vit_for_image_classification": [[47, 1, 1, "", "ViTForImageClassification"]], "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[47, 2, 1, "", "getClasses"], [47, 2, 1, "", "loadSavedModel"], [47, 2, 1, "", "pretrained"], [47, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.date2_chunk": [[48, 1, 1, "", "Date2Chunk"]], "sparknlp.annotator.date2_chunk.Date2Chunk": [[48, 2, 1, "", "setEntityName"]], "sparknlp.annotator.dependency": [[49, 0, 0, "-", "dependency_parser"], [51, 0, 0, "-", "typed_dependency_parser"]], "sparknlp.annotator.dependency.dependency_parser": [[49, 1, 1, "", "DependencyParserApproach"], [49, 1, 1, "", "DependencyParserModel"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[49, 2, 1, "", "setConllU"], [49, 2, 1, "", "setDependencyTreeBank"], [49, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[49, 2, 1, "", "pretrained"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[51, 1, 1, "", "TypedDependencyParserApproach"], [51, 1, 1, "", "TypedDependencyParserModel"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[51, 2, 1, "", "setConll2009"], [51, 2, 1, "", "setConllU"], [51, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[51, 2, 1, "", "pretrained"]], "sparknlp.annotator.document_normalizer": [[52, 1, 1, "", "DocumentNormalizer"]], "sparknlp.annotator.document_normalizer.DocumentNormalizer": [[52, 2, 1, "", "setAction"], [52, 2, 1, "", "setEncoding"], [52, 2, 1, "", "setLowercase"], [52, 2, 1, "", "setPatterns"], [52, 2, 1, "", "setPolicy"], [52, 2, 1, "", "setReplacement"]], "sparknlp.annotator.embeddings": [[53, 0, 0, "-", "albert_embeddings"], [54, 0, 0, "-", "bert_embeddings"], [55, 0, 0, "-", "bert_sentence_embeddings"], [56, 0, 0, "-", "camembert_embeddings"], [57, 0, 0, "-", "chunk_embeddings"], [58, 0, 0, "-", "deberta_embeddings"], [59, 0, 0, "-", "distil_bert_embeddings"], [60, 0, 0, "-", "doc2vec"], [61, 0, 0, "-", "elmo_embeddings"], [63, 0, 0, "-", "longformer_embeddings"], [64, 0, 0, "-", "roberta_embeddings"], [65, 0, 0, "-", "roberta_sentence_embeddings"], [66, 0, 0, "-", "sentence_embeddings"], [67, 0, 0, "-", "universal_sentence_encoder"], [68, 0, 0, "-", "word2vec"], [69, 0, 0, "-", "word_embeddings"], [70, 0, 0, "-", "xlm_roberta_embeddings"], [71, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [72, 0, 0, "-", "xlnet_embeddings"]], "sparknlp.annotator.embeddings.albert_embeddings": [[53, 1, 1, "", "AlbertEmbeddings"]], "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[53, 2, 1, "", "loadSavedModel"], [53, 2, 1, "", "pretrained"], [53, 2, 1, "", "setConfigProtoBytes"], [53, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[54, 1, 1, "", "BertEmbeddings"]], "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[54, 2, 1, "", "loadSavedModel"], [54, 2, 1, "", "pretrained"], [54, 2, 1, "", "setConfigProtoBytes"], [54, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[55, 1, 1, "", "BertSentenceEmbeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[55, 2, 1, "", "loadSavedModel"], [55, 2, 1, "", "pretrained"], [55, 2, 1, "", "setConfigProtoBytes"], [55, 2, 1, "", "setIsLong"], [55, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[56, 1, 1, "", "CamemBertEmbeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[56, 2, 1, "", "loadSavedModel"], [56, 2, 1, "", "pretrained"], [56, 2, 1, "", "setConfigProtoBytes"], [56, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[57, 1, 1, "", "ChunkEmbeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[57, 2, 1, "", "setPoolingStrategy"], [57, 2, 1, "", "setSkipOOV"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[58, 1, 1, "", "DeBertaEmbeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[58, 2, 1, "", "loadSavedModel"], [58, 2, 1, "", "pretrained"], [58, 2, 1, "", "setConfigProtoBytes"], [58, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[59, 1, 1, "", "DistilBertEmbeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[59, 2, 1, "", "loadSavedModel"], [59, 2, 1, "", "pretrained"], [59, 2, 1, "", "setConfigProtoBytes"], [59, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.doc2vec": [[60, 1, 1, "", "Doc2VecApproach"], [60, 1, 1, "", "Doc2VecModel"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[60, 2, 1, "", "setMaxIter"], [60, 2, 1, "", "setMaxSentenceLength"], [60, 2, 1, "", "setMinCount"], [60, 2, 1, "", "setNumPartitions"], [60, 2, 1, "", "setSeed"], [60, 2, 1, "", "setStepSize"], [60, 2, 1, "", "setVectorSize"], [60, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[60, 2, 1, "", "pretrained"], [60, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[61, 1, 1, "", "ElmoEmbeddings"]], "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[61, 2, 1, "", "loadSavedModel"], [61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setBatchSize"], [61, 2, 1, "", "setConfigProtoBytes"], [61, 2, 1, "", "setPoolingLayer"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[63, 1, 1, "", "LongformerEmbeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[63, 2, 1, "", "loadSavedModel"], [63, 2, 1, "", "pretrained"], [63, 2, 1, "", "setConfigProtoBytes"], [63, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[64, 1, 1, "", "RoBertaEmbeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[64, 2, 1, "", "loadSavedModel"], [64, 2, 1, "", "pretrained"], [64, 2, 1, "", "setConfigProtoBytes"], [64, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[65, 1, 1, "", "RoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[65, 2, 1, "", "loadSavedModel"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setConfigProtoBytes"], [65, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[66, 1, 1, "", "SentenceEmbeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[66, 2, 1, "", "setPoolingStrategy"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[67, 1, 1, "", "UniversalSentenceEncoder"]], "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[67, 2, 1, "", "loadSavedModel"], [67, 2, 1, "", "pretrained"], [67, 2, 1, "", "setConfigProtoBytes"], [67, 2, 1, "", "setLoadSP"]], "sparknlp.annotator.embeddings.word2vec": [[68, 1, 1, "", "Word2VecApproach"], [68, 1, 1, "", "Word2VecModel"]], "sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[68, 2, 1, "", "setMaxIter"], [68, 2, 1, "", "setMaxSentenceLength"], [68, 2, 1, "", "setMinCount"], [68, 2, 1, "", "setNumPartitions"], [68, 2, 1, "", "setSeed"], [68, 2, 1, "", "setStepSize"], [68, 2, 1, "", "setVectorSize"], [68, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[68, 2, 1, "", "pretrained"], [68, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[69, 1, 1, "", "WordEmbeddings"], [69, 1, 1, "", "WordEmbeddingsModel"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[69, 2, 1, "", "setReadCacheSize"], [69, 2, 1, "", "setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[69, 2, 1, "", "loadStorage"], [69, 2, 1, "", "overallCoverage"], [69, 2, 1, "", "pretrained"], [69, 2, 1, "", "setReadCacheSize"], [69, 2, 1, "", "withCoverageColumn"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[70, 1, 1, "", "XlmRoBertaEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[70, 2, 1, "", "loadSavedModel"], [70, 2, 1, "", "pretrained"], [70, 2, 1, "", "setConfigProtoBytes"], [70, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[71, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[71, 2, 1, "", "loadSavedModel"], [71, 2, 1, "", "pretrained"], [71, 2, 1, "", "setConfigProtoBytes"], [71, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[72, 1, 1, "", "XlnetEmbeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[72, 2, 1, "", "loadSavedModel"], [72, 2, 1, "", "pretrained"], [72, 2, 1, "", "setConfigProtoBytes"], [72, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.er": [[73, 0, 0, "-", "entity_ruler"]], "sparknlp.annotator.er.entity_ruler": [[73, 1, 1, "", "EntityRulerApproach"], [73, 1, 1, "", "EntityRulerModel"]], "sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[73, 2, 1, "", "setAlphabetResource"], [73, 2, 1, "", "setPatternsResource"], [73, 2, 1, "", "setSentenceMatch"], [73, 2, 1, "", "setUseStorage"]], "sparknlp.annotator.graph_extraction": [[75, 1, 1, "", "GraphExtraction"]], "sparknlp.annotator.graph_extraction.GraphExtraction": [[75, 2, 1, "", "setDelimiter"], [75, 2, 1, "", "setDependencyParserModel"], [75, 2, 1, "", "setEntityTypes"], [75, 2, 1, "", "setExplodeEntities"], [75, 2, 1, "", "setIncludeEdges"], [75, 2, 1, "", "setMaxSentenceSize"], [75, 2, 1, "", "setMergeEntities"], [75, 2, 1, "", "setMergeEntitiesIOBFormat"], [75, 2, 1, "", "setMinSentenceSize"], [75, 2, 1, "", "setPosModel"], [75, 2, 1, "", "setRelationshipTypes"], [75, 2, 1, "", "setRootTokens"], [75, 2, 1, "", "setTypedDependencyParserModel"]], "sparknlp.annotator.keyword_extraction": [[78, 0, 0, "-", "yake_keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[78, 1, 1, "", "YakeKeywordExtraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[78, 2, 1, "", "getStopWords"], [78, 2, 1, "", "loadDefaultStopWords"], [78, 2, 1, "", "setMaxNGrams"], [78, 2, 1, "", "setMinNGrams"], [78, 2, 1, "", "setNKeywords"], [78, 2, 1, "", "setStopWords"], [78, 2, 1, "", "setThreshold"], [78, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.ld_dl": [[80, 0, 0, "-", "language_detector_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[80, 1, 1, "", "LanguageDetectorDL"]], "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[80, 2, 1, "", "pretrained"], [80, 2, 1, "", "setCoalesceSentences"], [80, 2, 1, "", "setConfigProtoBytes"], [80, 2, 1, "", "setThreshold"], [80, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.lemmatizer": [[81, 1, 1, "", "Lemmatizer"], [81, 1, 1, "", "LemmatizerModel"]], "sparknlp.annotator.lemmatizer.Lemmatizer": [[81, 2, 1, "", "setDictionary"], [81, 2, 1, "", "setFormCol"], [81, 2, 1, "", "setLemmaCol"]], "sparknlp.annotator.lemmatizer.LemmatizerModel": [[81, 2, 1, "", "pretrained"]], "sparknlp.annotator.matcher": [[82, 0, 0, "-", "big_text_matcher"], [83, 0, 0, "-", "date_matcher"], [85, 0, 0, "-", "multi_date_matcher"], [86, 0, 0, "-", "regex_matcher"], [87, 0, 0, "-", "text_matcher"]], "sparknlp.annotator.matcher.big_text_matcher": [[82, 1, 1, "", "BigTextMatcher"], [82, 1, 1, "", "BigTextMatcherModel"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[82, 2, 1, "", "setCaseSensitive"], [82, 2, 1, "", "setEntities"], [82, 2, 1, "", "setMergeOverlapping"], [82, 2, 1, "", "setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[82, 2, 1, "", "loadStorage"], [82, 2, 1, "", "pretrained"], [82, 2, 1, "", "setCaseSensitive"], [82, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.date_matcher": [[83, 1, 1, "", "DateMatcher"], [83, 1, 1, "", "DateMatcherUtils"]], "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[83, 2, 1, "", "setAnchorDateDay"], [83, 2, 1, "", "setAnchorDateMonth"], [83, 2, 1, "", "setAnchorDateYear"], [83, 2, 1, "", "setDefaultDayWhenMissing"], [83, 2, 1, "", "setInputFormats"], [83, 2, 1, "", "setOutputFormat"], [83, 2, 1, "", "setReadMonthFirst"]], "sparknlp.annotator.matcher.multi_date_matcher": [[85, 1, 1, "", "MultiDateMatcher"]], "sparknlp.annotator.matcher.regex_matcher": [[86, 1, 1, "", "RegexMatcher"], [86, 1, 1, "", "RegexMatcherModel"]], "sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[86, 2, 1, "", "setDelimiter"], [86, 2, 1, "", "setExternalRules"], [86, 2, 1, "", "setRules"], [86, 2, 1, "", "setStrategy"]], "sparknlp.annotator.matcher.text_matcher": [[87, 1, 1, "", "TextMatcher"], [87, 1, 1, "", "TextMatcherModel"]], "sparknlp.annotator.matcher.text_matcher.TextMatcher": [[87, 2, 1, "", "setBuildFromTokens"], [87, 2, 1, "", "setCaseSensitive"], [87, 2, 1, "", "setEntities"], [87, 2, 1, "", "setEntityValue"], [87, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[87, 2, 1, "", "pretrained"], [87, 2, 1, "", "setBuildFromTokens"], [87, 2, 1, "", "setEntityValue"], [87, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.n_gram_generator": [[88, 1, 1, "", "NGramGenerator"]], "sparknlp.annotator.n_gram_generator.NGramGenerator": [[88, 2, 1, "", "setDelimiter"], [88, 2, 1, "", "setEnableCumulative"], [88, 2, 1, "", "setN"]], "sparknlp.annotator.ner": [[90, 0, 0, "-", "ner_approach"], [91, 0, 0, "-", "ner_converter"], [92, 0, 0, "-", "ner_crf"], [93, 0, 0, "-", "ner_dl"], [94, 0, 0, "-", "ner_overwriter"], [95, 0, 0, "-", "zero_shot_ner_model"]], "sparknlp.annotator.ner.ner_approach": [[90, 1, 1, "", "NerApproach"]], "sparknlp.annotator.ner.ner_approach.NerApproach": [[90, 2, 1, "", "getLabelColumn"], [90, 2, 1, "", "setEntities"], [90, 2, 1, "", "setLabelColumn"], [90, 2, 1, "", "setMaxEpochs"], [90, 2, 1, "", "setMinEpochs"], [90, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.ner.ner_converter": [[91, 1, 1, "", "NerConverter"]], "sparknlp.annotator.ner.ner_converter.NerConverter": [[91, 2, 1, "", "setNerHasNoSchema"], [91, 2, 1, "", "setPreservePosition"], [91, 2, 1, "", "setWhiteList"]], "sparknlp.annotator.ner.ner_crf": [[92, 1, 1, "", "NerCrfApproach"], [92, 1, 1, "", "NerCrfModel"]], "sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[92, 2, 1, "", "setC0"], [92, 2, 1, "", "setExternalFeatures"], [92, 2, 1, "", "setIncludeConfidence"], [92, 2, 1, "", "setL2"], [92, 2, 1, "", "setLossEps"], [92, 2, 1, "", "setMinW"], [92, 2, 1, "", "setVerbose"]], "sparknlp.annotator.ner.ner_crf.NerCrfModel": [[92, 2, 1, "", "pretrained"], [92, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_dl": [[93, 1, 1, "", "NerDLApproach"], [93, 1, 1, "", "NerDLModel"]], "sparknlp.annotator.ner.ner_dl.NerDLApproach": [[93, 2, 1, "", "setBatchSize"], [93, 2, 1, "", "setBestModelMetric"], [93, 2, 1, "", "setConfigProtoBytes"], [93, 2, 1, "", "setDropout"], [93, 2, 1, "", "setEnableMemoryOptimizer"], [93, 2, 1, "", "setGraphFolder"], [93, 2, 1, "", "setIncludeAllConfidenceScores"], [93, 2, 1, "", "setIncludeConfidence"], [93, 2, 1, "", "setLr"], [93, 2, 1, "", "setPo"], [93, 2, 1, "", "setUseBestModel"], [93, 2, 1, "", "setUseContrib"]], "sparknlp.annotator.ner.ner_dl.NerDLModel": [[93, 2, 1, "", "pretrained"], [93, 2, 1, "", "setConfigProtoBytes"], [93, 2, 1, "", "setIncludeAllConfidenceScores"], [93, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_overwriter": [[94, 1, 1, "", "NerOverwriter"]], "sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[94, 2, 1, "", "setNerWords"], [94, 2, 1, "", "setNewNerEntity"], [94, 2, 1, "", "setReplaceEntities"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[95, 1, 1, "", "ZeroShotNerModel"]], "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel": [[95, 2, 1, "", "getClasses"], [95, 2, 1, "", "load"], [95, 2, 1, "", "pretrained"], [95, 2, 1, "", "setEntityDefinitions"], [95, 2, 1, "", "setPredictionThreshold"]], "sparknlp.annotator.normalizer": [[96, 1, 1, "", "Normalizer"], [96, 1, 1, "", "NormalizerModel"]], "sparknlp.annotator.normalizer.Normalizer": [[96, 2, 1, "", "setCleanupPatterns"], [96, 2, 1, "", "setLowercase"], [96, 2, 1, "", "setMaxLength"], [96, 2, 1, "", "setMinLength"], [96, 2, 1, "", "setSlangDictionary"]], "sparknlp.annotator.param": [[97, 0, 0, "-", "classifier_encoder"], [98, 0, 0, "-", "evaluation_dl_params"]], "sparknlp.annotator.param.classifier_encoder": [[97, 1, 1, "", "ClassifierEncoder"]], "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[97, 2, 1, "", "setBatchSize"], [97, 2, 1, "", "setConfigProtoBytes"], [97, 2, 1, "", "setLabelColumn"], [97, 2, 1, "", "setLr"], [97, 2, 1, "", "setMaxEpochs"], [97, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.param.evaluation_dl_params": [[98, 1, 1, "", "EvaluationDLParams"]], "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[98, 2, 1, "", "setEnableOutputLogs"], [98, 2, 1, "", "setEvaluationLogExtended"], [98, 2, 1, "", "setOutputLogsPath"], [98, 2, 1, "", "setTestDataset"], [98, 2, 1, "", "setValidationSplit"], [98, 2, 1, "", "setVerbose"]], "sparknlp.annotator.pos": [[101, 0, 0, "-", "perceptron"]], "sparknlp.annotator.pos.perceptron": [[101, 1, 1, "", "PerceptronApproach"], [101, 1, 1, "", "PerceptronModel"]], "sparknlp.annotator.pos.perceptron.PerceptronApproach": [[101, 2, 1, "", "getNIterations"], [101, 2, 1, "", "setIterations"], [101, 2, 1, "", "setPosColumn"]], "sparknlp.annotator.pos.perceptron.PerceptronModel": [[101, 2, 1, "", "pretrained"]], "sparknlp.annotator.sentence": [[103, 0, 0, "-", "sentence_detector"], [104, 0, 0, "-", "sentence_detector_dl"]], "sparknlp.annotator.sentence.sentence_detector": [[103, 1, 1, "", "SentenceDetector"], [103, 1, 1, "", "SentenceDetectorParams"]], "sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[103, 2, 1, "", "setCustomBounds"], [103, 2, 1, "", "setCustomBoundsStrategy"], [103, 2, 1, "", "setDetectLists"], [103, 2, 1, "", "setExplodeSentences"], [103, 2, 1, "", "setMaxLength"], [103, 2, 1, "", "setMinLength"], [103, 2, 1, "", "setSplitLength"], [103, 2, 1, "", "setUseAbbreviations"], [103, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[104, 1, 1, "", "SentenceDetectorDLApproach"], [104, 1, 1, "", "SentenceDetectorDLModel"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[104, 2, 1, "", "setEpochsNumber"], [104, 2, 1, "", "setExplodeSentences"], [104, 2, 1, "", "setImpossiblePenultimates"], [104, 2, 1, "", "setModel"], [104, 2, 1, "", "setOutputLogsPath"], [104, 2, 1, "", "setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[104, 2, 1, "", "pretrained"], [104, 2, 1, "", "setCustomBounds"], [104, 2, 1, "", "setExplodeSentences"], [104, 2, 1, "", "setImpossiblePenultimates"], [104, 2, 1, "", "setMaxLength"], [104, 2, 1, "", "setMinLength"], [104, 2, 1, "", "setModel"], [104, 2, 1, "", "setSplitLength"], [104, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentiment": [[106, 0, 0, "-", "sentiment_detector"], [107, 0, 0, "-", "vivekn_sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[106, 1, 1, "", "SentimentDetector"], [106, 1, 1, "", "SentimentDetectorModel"]], "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[106, 2, 1, "", "setDictionary"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[107, 1, 1, "", "ViveknSentimentApproach"], [107, 1, 1, "", "ViveknSentimentModel"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[107, 2, 1, "", "setPruneCorpus"], [107, 2, 1, "", "setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[107, 2, 1, "", "pretrained"]], "sparknlp.annotator.seq2seq": [[108, 0, 0, "-", "bart_transformer"], [109, 0, 0, "-", "gpt2_transformer"], [111, 0, 0, "-", "marian_transformer"], [112, 0, 0, "-", "t5_transformer"]], "sparknlp.annotator.seq2seq.bart_transformer": [[108, 1, 1, "", "BartTransformer"]], "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer": [[108, 2, 1, "", "loadSavedModel"], [108, 2, 1, "", "pretrained"], [108, 2, 1, "", "setBeamSize"], [108, 2, 1, "", "setConfigProtoBytes"], [108, 2, 1, "", "setDoSample"], [108, 2, 1, "", "setIgnoreTokenIds"], [108, 2, 1, "", "setMaxOutputLength"], [108, 2, 1, "", "setMinOutputLength"], [108, 2, 1, "", "setNoRepeatNgramSize"], [108, 2, 1, "", "setRepetitionPenalty"], [108, 2, 1, "", "setTask"], [108, 2, 1, "", "setTemperature"], [108, 2, 1, "", "setTopK"], [108, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[109, 1, 1, "", "GPT2Transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[109, 2, 1, "", "loadSavedModel"], [109, 2, 1, "", "pretrained"], [109, 2, 1, "", "setConfigProtoBytes"], [109, 2, 1, "", "setDoSample"], [109, 2, 1, "", "setIgnoreTokenIds"], [109, 2, 1, "", "setMaxOutputLength"], [109, 2, 1, "", "setMinOutputLength"], [109, 2, 1, "", "setNoRepeatNgramSize"], [109, 2, 1, "", "setRepetitionPenalty"], [109, 2, 1, "", "setTask"], [109, 2, 1, "", "setTemperature"], [109, 2, 1, "", "setTopK"], [109, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.marian_transformer": [[111, 1, 1, "", "MarianTransformer"]], "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[111, 2, 1, "", "loadSavedModel"], [111, 2, 1, "", "pretrained"], [111, 2, 1, "", "setConfigProtoBytes"], [111, 2, 1, "", "setIgnoreTokenIds"], [111, 2, 1, "", "setLangId"], [111, 2, 1, "", "setMaxInputLength"], [111, 2, 1, "", "setMaxOutputLength"]], "sparknlp.annotator.seq2seq.t5_transformer": [[112, 1, 1, "", "T5Transformer"]], "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[112, 2, 1, "", "loadSavedModel"], [112, 2, 1, "", "pretrained"], [112, 2, 1, "", "setConfigProtoBytes"], [112, 2, 1, "", "setDoSample"], [112, 2, 1, "", "setIgnoreTokenIds"], [112, 2, 1, "", "setMaxOutputLength"], [112, 2, 1, "", "setMinOutputLength"], [112, 2, 1, "", "setNoRepeatNgramSize"], [112, 2, 1, "", "setRepetitionPenalty"], [112, 2, 1, "", "setTask"], [112, 2, 1, "", "setTemperature"], [112, 2, 1, "", "setTopK"], [112, 2, 1, "", "setTopP"]], "sparknlp.annotator.spell_check": [[113, 0, 0, "-", "context_spell_checker"], [115, 0, 0, "-", "norvig_sweeting"], [116, 0, 0, "-", "symmetric_delete"]], "sparknlp.annotator.spell_check.context_spell_checker": [[113, 1, 1, "", "ContextSpellCheckerApproach"], [113, 1, 1, "", "ContextSpellCheckerModel"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[113, 2, 1, "", "addRegexClass"], [113, 2, 1, "", "addVocabClass"], [113, 2, 1, "", "setBatchSize"], [113, 2, 1, "", "setCaseStrategy"], [113, 2, 1, "", "setClassCount"], [113, 2, 1, "", "setCompoundCount"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setEpochs"], [113, 2, 1, "", "setErrorThreshold"], [113, 2, 1, "", "setFinalRate"], [113, 2, 1, "", "setGraphFolder"], [113, 2, 1, "", "setInitialRate"], [113, 2, 1, "", "setLanguageModelClasses"], [113, 2, 1, "", "setMaxCandidates"], [113, 2, 1, "", "setMaxSentLen"], [113, 2, 1, "", "setMaxWindowLen"], [113, 2, 1, "", "setMinCount"], [113, 2, 1, "", "setTradeoff"], [113, 2, 1, "", "setValidationFraction"], [113, 2, 1, "", "setWeightedDistPath"], [113, 2, 1, "", "setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[113, 2, 1, "", "getWordClasses"], [113, 2, 1, "", "pretrained"], [113, 2, 1, "", "setCaseStrategy"], [113, 2, 1, "", "setClasses"], [113, 2, 1, "", "setCompareLowcase"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setCorrectSymbols"], [113, 2, 1, "", "setErrorThreshold"], [113, 2, 1, "", "setGamma"], [113, 2, 1, "", "setIdsVocab"], [113, 2, 1, "", "setMaxCandidates"], [113, 2, 1, "", "setMaxWindowLen"], [113, 2, 1, "", "setTradeoff"], [113, 2, 1, "", "setVocabFreq"], [113, 2, 1, "", "setVocabIds"], [113, 2, 1, "", "setWeights"], [113, 2, 1, "", "setWordMaxDistance"], [113, 2, 1, "", "updateRegexClass"], [113, 2, 1, "", "updateVocabClass"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[115, 1, 1, "", "NorvigSweetingApproach"], [115, 1, 1, "", "NorvigSweetingModel"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[115, 2, 1, "", "setCaseSensitive"], [115, 2, 1, "", "setDictionary"], [115, 2, 1, "", "setDoubleVariants"], [115, 2, 1, "", "setFrequencyPriority"], [115, 2, 1, "", "setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[115, 2, 1, "", "pretrained"]], "sparknlp.annotator.spell_check.symmetric_delete": [[116, 1, 1, "", "SymmetricDeleteApproach"], [116, 1, 1, "", "SymmetricDeleteModel"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[116, 2, 1, "", "setDeletesThreshold"], [116, 2, 1, "", "setDictionary"], [116, 2, 1, "", "setFrequencyThreshold"], [116, 2, 1, "", "setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[116, 2, 1, "", "pretrained"]], "sparknlp.annotator.stemmer": [[117, 1, 1, "", "Stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[118, 1, 1, "", "StopWordsCleaner"]], "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[118, 2, 1, "", "loadDefaultStopWords"], [118, 2, 1, "", "pretrained"], [118, 2, 1, "", "setCaseSensitive"], [118, 2, 1, "", "setLocale"], [118, 2, 1, "", "setStopWords"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[119, 1, 1, "", "TFNerDLGraphBuilder"], [119, 1, 1, "", "TFNerDLGraphBuilderModel"]], "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[119, 2, 1, "", "getGraphFile"], [119, 2, 1, "", "getGraphFolder"], [119, 2, 1, "", "getHiddenUnitsNumber"], [119, 2, 1, "", "getInputCols"], [119, 2, 1, "", "getLabelColumn"], [119, 2, 1, "", "setGraphFile"], [119, 2, 1, "", "setGraphFolder"], [119, 2, 1, "", "setHiddenUnitsNumber"], [119, 2, 1, "", "setInputCols"], [119, 2, 1, "", "setLabelColumn"]], "sparknlp.annotator.token": [[120, 0, 0, "-", "chunk_tokenizer"], [122, 0, 0, "-", "recursive_tokenizer"], [123, 0, 0, "-", "regex_tokenizer"], [124, 0, 0, "-", "tokenizer"]], "sparknlp.annotator.token.chunk_tokenizer": [[120, 1, 1, "", "ChunkTokenizer"], [120, 1, 1, "", "ChunkTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer": [[122, 1, 1, "", "RecursiveTokenizer"], [122, 1, 1, "", "RecursiveTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[122, 2, 1, "", "setInfixes"], [122, 2, 1, "", "setPrefixes"], [122, 2, 1, "", "setSuffixes"], [122, 2, 1, "", "setWhitelist"]], "sparknlp.annotator.token.regex_tokenizer": [[123, 1, 1, "", "RegexTokenizer"]], "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[123, 2, 1, "", "setMaxLength"], [123, 2, 1, "", "setMinLength"], [123, 2, 1, "", "setPattern"], [123, 2, 1, "", "setPositionalMask"], [123, 2, 1, "", "setPreservePosition"], [123, 2, 1, "", "setToLowercase"], [123, 2, 1, "", "setTrimWhitespace"]], "sparknlp.annotator.token.tokenizer": [[124, 1, 1, "", "Tokenizer"], [124, 1, 1, "", "TokenizerModel"]], "sparknlp.annotator.token.tokenizer.Tokenizer": [[124, 2, 1, "", "addContextChars"], [124, 2, 1, "", "addException"], [124, 2, 1, "", "addInfixPattern"], [124, 2, 1, "", "addSplitChars"], [124, 2, 1, "", "getCaseSensitiveExceptions"], [124, 2, 1, "", "getContextChars"], [124, 2, 1, "", "getExceptions"], [124, 2, 1, "", "getInfixPatterns"], [124, 2, 1, "", "getPrefixPattern"], [124, 2, 1, "", "getSplitChars"], [124, 2, 1, "", "getSuffixPattern"], [124, 2, 1, "", "setCaseSensitiveExceptions"], [124, 2, 1, "", "setContextChars"], [124, 2, 1, "", "setExceptions"], [124, 2, 1, "", "setExceptionsPath"], [124, 2, 1, "", "setInfixPatterns"], [124, 2, 1, "", "setMaxLength"], [124, 2, 1, "", "setMinLength"], [124, 2, 1, "", "setPrefixPattern"], [124, 2, 1, "", "setSplitChars"], [124, 2, 1, "", "setSplitPattern"], [124, 2, 1, "", "setSuffixPattern"], [124, 2, 1, "", "setTargetPattern"]], "sparknlp.annotator.token.tokenizer.TokenizerModel": [[124, 2, 1, "", "addSplitChars"], [124, 2, 1, "", "pretrained"], [124, 2, 1, "", "setSplitChars"], [124, 2, 1, "", "setSplitPattern"]], "sparknlp.annotator.ws": [[126, 0, 0, "-", "word_segmenter"]], "sparknlp.annotator.ws.word_segmenter": [[126, 1, 1, "", "WordSegmenterApproach"], [126, 1, 1, "", "WordSegmenterModel"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[126, 2, 1, "", "getAmbiguityThreshold"], [126, 2, 1, "", "getFrequencyThreshold"], [126, 2, 1, "", "getNIterations"], [126, 2, 1, "", "setAmbiguityThreshold"], [126, 2, 1, "", "setEnableRegexTokenizer"], [126, 2, 1, "", "setFrequencyThreshold"], [126, 2, 1, "", "setNIterations"], [126, 2, 1, "", "setPattern"], [126, 2, 1, "", "setPosColumn"], [126, 2, 1, "", "setToLowercase"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[126, 2, 1, "", "pretrained"], [126, 2, 1, "", "setEnableRegexTokenizer"], [126, 2, 1, "", "setPattern"], [126, 2, 1, "", "setToLowercase"]], "sparknlp.base": [[127, 0, 0, "-", "audio_assembler"], [128, 0, 0, "-", "doc2_chunk"], [129, 0, 0, "-", "document_assembler"], [130, 0, 0, "-", "embeddings_finisher"], [131, 0, 0, "-", "finisher"], [132, 0, 0, "-", "graph_finisher"], [133, 0, 0, "-", "has_recursive_fit"], [134, 0, 0, "-", "has_recursive_transform"], [135, 0, 0, "-", "image_assembler"], [137, 0, 0, "-", "light_pipeline"], [138, 0, 0, "-", "multi_document_assembler"], [139, 0, 0, "-", "recursive_pipeline"], [140, 0, 0, "-", "table_assembler"], [141, 0, 0, "-", "token2_chunk"], [142, 0, 0, "-", "token_assembler"]], "sparknlp.base.audio_assembler": [[127, 1, 1, "", "AudioAssembler"]], "sparknlp.base.audio_assembler.AudioAssembler": [[127, 2, 1, "", "getOutputCol"], [127, 2, 1, "", "setInputCol"], [127, 2, 1, "", "setOutputCol"]], "sparknlp.base.doc2_chunk": [[128, 1, 1, "", "Doc2Chunk"]], "sparknlp.base.doc2_chunk.Doc2Chunk": [[128, 2, 1, "", "setChunkCol"], [128, 2, 1, "", "setFailOnMissing"], [128, 2, 1, "", "setIsArray"], [128, 2, 1, "", "setLowerCase"], [128, 2, 1, "", "setStartCol"], [128, 2, 1, "", "setStartColByTokenIndex"]], "sparknlp.base.document_assembler": [[129, 1, 1, "", "DocumentAssembler"]], "sparknlp.base.document_assembler.DocumentAssembler": [[129, 2, 1, "", "getOutputCol"], [129, 2, 1, "", "setCleanupMode"], [129, 2, 1, "", "setIdCol"], [129, 2, 1, "", "setInputCol"], [129, 2, 1, "", "setMetadataCol"], [129, 2, 1, "", "setOutputCol"]], "sparknlp.base.embeddings_finisher": [[130, 1, 1, "", "EmbeddingsFinisher"]], "sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[130, 2, 1, "", "getInputCols"], [130, 2, 1, "", "getOutputCols"], [130, 2, 1, "", "setCleanAnnotations"], [130, 2, 1, "", "setInputCols"], [130, 2, 1, "", "setOutputAsVector"], [130, 2, 1, "", "setOutputCols"]], "sparknlp.base.finisher": [[131, 1, 1, "", "Finisher"]], "sparknlp.base.finisher.Finisher": [[131, 2, 1, "", "getInputCols"], [131, 2, 1, "", "getOutputCols"], [131, 2, 1, "", "setAnnotationSplitSymbol"], [131, 2, 1, "", "setCleanAnnotations"], [131, 2, 1, "", "setIncludeMetadata"], [131, 2, 1, "", "setInputCols"], [131, 2, 1, "", "setOutputAsArray"], [131, 2, 1, "", "setOutputCols"], [131, 2, 1, "", "setParseEmbeddingsVectors"], [131, 2, 1, "", "setValueSplitSymbol"]], "sparknlp.base.graph_finisher": [[132, 1, 1, "", "GraphFinisher"]], "sparknlp.base.graph_finisher.GraphFinisher": [[132, 2, 1, "", "setCleanAnnotations"], [132, 2, 1, "", "setInputCol"], [132, 2, 1, "", "setOutputAsArray"], [132, 2, 1, "", "setOutputCol"]], "sparknlp.base.has_recursive_fit": [[133, 1, 1, "", "HasRecursiveFit"]], "sparknlp.base.has_recursive_transform": [[134, 1, 1, "", "HasRecursiveTransform"]], "sparknlp.base.image_assembler": [[135, 1, 1, "", "ImageAssembler"]], "sparknlp.base.image_assembler.ImageAssembler": [[135, 2, 1, "", "getOutputCol"], [135, 2, 1, "", "setInputCol"], [135, 2, 1, "", "setOutputCol"]], "sparknlp.base.light_pipeline": [[137, 1, 1, "", "LightPipeline"]], "sparknlp.base.light_pipeline.LightPipeline": [[137, 2, 1, "", "annotate"], [137, 2, 1, "", "fullAnnotate"], [137, 2, 1, "", "fullAnnotateImage"], [137, 2, 1, "", "getIgnoreUnsupported"], [137, 2, 1, "", "setIgnoreUnsupported"], [137, 2, 1, "", "transform"]], "sparknlp.base.multi_document_assembler": [[138, 1, 1, "", "MultiDocumentAssembler"]], "sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[138, 2, 1, "", "getOutputCols"], [138, 2, 1, "", "setCleanupMode"], [138, 2, 1, "", "setIdCol"], [138, 2, 1, "", "setInputCols"], [138, 2, 1, "", "setMetadataCol"], [138, 2, 1, "", "setOutputCols"]], "sparknlp.base.recursive_pipeline": [[139, 1, 1, "", "RecursivePipeline"], [139, 1, 1, "", "RecursivePipelineModel"]], "sparknlp.base.table_assembler": [[140, 1, 1, "", "TableAssembler"]], "sparknlp.base.table_assembler.TableAssembler": [[140, 2, 1, "", "setCsvDelimiter"], [140, 2, 1, "", "setEscapeCsvDelimiter"], [140, 2, 1, "", "setInputFormat"]], "sparknlp.base.token2_chunk": [[141, 1, 1, "", "Token2Chunk"]], "sparknlp.base.token_assembler": [[142, 1, 1, "", "TokenAssembler"]], "sparknlp.base.token_assembler.TokenAssembler": [[142, 2, 1, "", "setPreservePosition"]], "sparknlp.common": [[143, 0, 0, "-", "annotator_approach"], [144, 0, 0, "-", "annotator_model"], [145, 0, 0, "-", "annotator_properties"], [146, 0, 0, "-", "annotator_type"], [147, 0, 0, "-", "coverage_result"], [149, 0, 0, "-", "properties"], [150, 0, 0, "-", "read_as"], [151, 0, 0, "-", "recursive_annotator_approach"], [152, 0, 0, "-", "storage"], [153, 0, 0, "-", "utils"]], "sparknlp.common.annotator_approach": [[143, 1, 1, "", "AnnotatorApproach"]], "sparknlp.common.annotator_model": [[144, 1, 1, "", "AnnotatorModel"]], "sparknlp.common.annotator_properties": [[145, 1, 1, "", "AnnotatorProperties"]], "sparknlp.common.annotator_properties.AnnotatorProperties": [[145, 2, 1, "", "getInputCols"], [145, 2, 1, "", "getLazyAnnotator"], [145, 2, 1, "", "getOutputCol"], [145, 2, 1, "", "setInputCols"], [145, 2, 1, "", "setLazyAnnotator"], [145, 2, 1, "", "setOutputCol"]], "sparknlp.common.properties": [[149, 1, 1, "", "HasEmbeddingsProperties"]], "sparknlp.common.properties.HasEmbeddingsProperties": [[149, 2, 1, "", "getDimension"], [149, 2, 1, "", "setDimension"]], "sparknlp.common.read_as": [[150, 1, 1, "", "ReadAs"]], "sparknlp.common.recursive_annotator_approach": [[151, 1, 1, "", "RecursiveAnnotatorApproach"]], "sparknlp.common.utils": [[153, 3, 1, "", "ExternalResource"]], "sparknlp.functions": [[154, 3, 1, "", "explode_annotations_col"], [154, 3, 1, "", "filter_by_annotations_col"], [154, 3, 1, "", "map_annotations"], [154, 3, 1, "", "map_annotations_array"], [154, 3, 1, "", "map_annotations_col"], [154, 3, 1, "", "map_annotations_cols"], [154, 3, 1, "", "map_annotations_strict"]], "sparknlp.internal": [[156, 0, 0, "-", "annotator_java_ml"], [157, 0, 0, "-", "annotator_transformer"], [158, 0, 0, "-", "extended_java_wrapper"], [160, 0, 0, "-", "params_getters_setters"], [161, 0, 0, "-", "recursive"]], "sparknlp.internal.annotator_java_ml": [[156, 1, 1, "", "AnnotatorJavaMLReadable"], [156, 1, 1, "", "AnnotatorJavaMLReader"]], "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[156, 2, 1, "", "read"]], "sparknlp.internal.annotator_transformer": [[157, 1, 1, "", "AnnotatorTransformer"]], "sparknlp.internal.extended_java_wrapper": [[158, 1, 1, "", "ExtendedJavaWrapper"]], "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[158, 2, 1, "", "new_java_array"]], "sparknlp.internal.params_getters_setters": [[160, 1, 1, "", "ParamsGettersSetters"]], "sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[160, 2, 1, "", "getParamValue"], [160, 2, 1, "", "setParamValue"]], "sparknlp.internal.recursive": [[161, 1, 1, "", "RecursiveEstimator"], [161, 1, 1, "", "RecursiveTransformer"]], "sparknlp.internal.recursive.RecursiveEstimator": [[161, 2, 1, "", "fit"]], "sparknlp.logging": [[162, 0, 0, "-", "comet"]], "sparknlp.logging.comet": [[162, 1, 1, "", "CometLogger"]], "sparknlp.logging.comet.CometLogger": [[162, 2, 1, "", "end"], [162, 2, 1, "", "log_asset"], [162, 2, 1, "", "log_asset_data"], [162, 2, 1, "", "log_completed_run"], [162, 2, 1, "", "log_metrics"], [162, 2, 1, "", "log_parameters"], [162, 2, 1, "", "log_pipeline_parameters"], [162, 2, 1, "", "log_visualization"], [162, 2, 1, "", "monitor"]], "sparknlp.pretrained": [[165, 0, 0, "-", "pretrained_pipeline"], [166, 0, 0, "-", "resource_downloader"], [167, 0, 0, "-", "utils"]], "sparknlp.pretrained.pretrained_pipeline": [[165, 1, 1, "", "PretrainedPipeline"]], "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[165, 2, 1, "", "annotate"], [165, 2, 1, "", "fullAnnotate"], [165, 2, 1, "", "fullAnnotateImage"], [165, 2, 1, "", "transform"]], "sparknlp.pretrained.resource_downloader": [[166, 1, 1, "", "ResourceDownloader"]], "sparknlp.pretrained.resource_downloader.ResourceDownloader": [[166, 2, 1, "", "clearCache"], [166, 2, 1, "", "downloadModel"], [166, 2, 1, "", "downloadModelDirectly"], [166, 2, 1, "", "downloadPipeline"], [166, 2, 1, "", "showAvailableAnnotators"], [166, 2, 1, "", "showPublicModels"], [166, 2, 1, "", "showPublicPipelines"], [166, 2, 1, "", "showUnCategorizedResources"]], "sparknlp.training": [[168, 0, 0, "-", "conll"], [169, 0, 0, "-", "conllu"], [171, 0, 0, "-", "pos"], [172, 0, 0, "-", "pub_tator"], [173, 0, 0, "-", "spacy_to_annotation"], [174, 0, 0, "-", "tfgraphs"]], "sparknlp.training.conll": [[168, 1, 1, "", "CoNLL"]], "sparknlp.training.conll.CoNLL": [[168, 2, 1, "", "readDataset"]], "sparknlp.training.conllu": [[169, 1, 1, "", "CoNLLU"]], "sparknlp.training.conllu.CoNLLU": [[169, 2, 1, "", "readDataset"]], "sparknlp.training.pos": [[171, 1, 1, "", "POS"]], "sparknlp.training.pos.POS": [[171, 2, 1, "", "readDataset"]], "sparknlp.training.pub_tator": [[172, 1, 1, "", "PubTator"]], "sparknlp.training.pub_tator.PubTator": [[172, 2, 1, "", "readDataset"]], "sparknlp.training.spacy_to_annotation": [[173, 1, 1, "", "SpacyToAnnotation"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"get": [0, 183], "start": 0, "spark": [0, 1, 178, 183, 187], "nlp": [0, 1, 178, 187], "cheat": 0, "sheet": 0, "requir": 0, "instal": [0, 178], "us": [0, 178, 187], "conda": 0, "virtualenv": 0, "session": 0, "from": 0, "python": 0, "document": 1, "content": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 165, 166, 168, 169, 171, 172, 173], "sparknlp": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176], "annot": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 181, 182, 183], "modul": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 151, 153, 154, 156, 157, 158, 160, 161, 162, 165, 166, 168, 169, 171, 172, 173, 177], "class": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 106, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 151, 156, 157, 158, 160, 161, 162, 165, 166, 168, 169, 171, 172, 173], "annotation_audio": 3, "annotation_imag": 4, "audio": [5, 6, 7], "hubert_for_ctc": 5, "submodul": [6, 27, 42, 45, 50, 62, 74, 76, 77, 79, 84, 89, 100, 102, 105, 110, 114, 121, 125, 136, 148, 155, 159, 163, 164, 170], "wav2vec2_for_ctc": 7, "chunk2_doc": 8, "chunker": 9, "classifier_dl": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "albert_for_question_answ": 10, "albert_for_sequence_classif": 11, "albert_for_token_classif": 12, "bert_for_question_answ": 13, "bert_for_sequence_classif": 14, "bert_for_token_classif": 15, "bert_for_zero_shot_classif": 16, "camembert_for_question_answ": 17, "camembert_for_sequence_classif": 18, "camembert_for_token_classif": 19, "deberta_for_question_answ": 21, "deberta_for_sequence_classif": 22, "deberta_for_token_classif": 23, "distil_bert_for_question_answ": 24, "distil_bert_for_sequence_classif": 25, "distil_bert_for_token_classif": 26, "longformer_for_question_answ": 28, "longformer_for_sequence_classif": 29, "longformer_for_token_classif": 30, "multi_classifier_dl": 31, "roberta_for_question_answ": 32, "roberta_for_sequence_classif": 33, "roberta_for_token_classif": 34, "sentiment_dl": 35, "tapas_for_question_answ": 36, "xlm_roberta_for_question_answ": 37, "xlm_roberta_for_sequence_classif": 38, "xlm_roberta_for_token_classif": 39, "xlnet_for_sequence_classif": 40, "xlnet_for_token_classif": 41, "coref": [42, 43], "spanbert_coref": 43, "cv": [44, 45, 46, 47], "convnext_for_image_classif": 44, "swin_for_image_classif": 46, "vit_for_image_classif": 47, "date2_chunk": 48, "depend": [49, 50, 51], "dependency_pars": 49, "typed_dependency_pars": 51, "document_norm": 52, "embed": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72], "albert_embed": 53, "bert_embed": 54, "bert_sentence_embed": 55, "camembert_embed": 56, "chunk_embed": 57, "deberta_embed": 58, "distil_bert_embed": 59, "doc2vec": 60, "elmo_embed": 61, "longformer_embed": 63, "roberta_embed": 64, "roberta_sentence_embed": 65, "sentence_embed": 66, "universal_sentence_encod": 67, "word2vec": 68, "word_embed": 69, "xlm_roberta_embed": 70, "xlm_roberta_sentence_embed": 71, "xlnet_embed": 72, "er": [73, 74], "entity_rul": 73, "graph_extract": 75, "subpackag": [76, 155], "keyword_extract": [77, 78], "yake_keyword_extract": 78, "ld_dl": [79, 80], "language_detector_dl": 80, "lemmat": 81, "matcher": [82, 83, 84, 85, 86, 87], "big_text_match": 82, "date_match": 83, "multi_date_match": 85, "regex_match": 86, "text_match": 87, "n_gram_gener": 88, "ner": [89, 90, 91, 92, 93, 94, 95], "ner_approach": 90, "ner_convert": 91, "ner_crf": 92, "ner_dl": 93, "ner_overwrit": 94, "zero_shot_ner_model": 95, "normal": 96, "param": [97, 98, 99], "classifier_encod": 97, "evaluation_dl_param": 98, "po": [100, 101, 171, 188], "perceptron": 101, "sentenc": [102, 103, 104, 183], "sentence_detector": 103, "sentence_detector_dl": 104, "sentiment": [105, 106, 107], "sentiment_detector": 106, "vivekn_senti": 107, "seq2seq": [108, 109, 110, 111, 112], "bart_transform": 108, "gpt2_transform": 109, "marian_transform": 111, "t5_transform": 112, "spell_check": [113, 114, 115, 116], "context_spell_check": 113, "norvig_sweet": 115, "symmetric_delet": 116, "stemmer": 117, "stop_words_clean": 118, "tf_ner_dl_graph_build": 119, "token": [120, 121, 122, 123, 124, 183], "chunk_token": 120, "recursive_token": 122, "regex_token": 123, "w": [125, 126], "word_segment": 126, "base": [127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142], "audio_assembl": 127, "doc2_chunk": 128, "document_assembl": 129, "embeddings_finish": 130, "finish": [131, 183], "graph_finish": 132, "has_recursive_fit": 133, "has_recursive_transform": 134, "image_assembl": 135, "light_pipelin": 137, "multi_document_assembl": 138, "recursive_pipelin": 139, "table_assembl": 140, "token2_chunk": 141, "token_assembl": 142, "common": [143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 182], "annotator_approach": 143, "annotator_model": 144, "annotator_properti": 145, "annotator_typ": 146, "coverage_result": 147, "properti": 149, "read_a": 150, "recursive_annotator_approach": 151, "storag": 152, "util": [153, 167, 176], "function": [153, 154, 155, 182, 184], "packag": 155, "intern": [156, 157, 158, 159, 160, 161], "annotator_java_ml": 156, "annotator_transform": 157, "extended_java_wrapp": 158, "params_getters_sett": 160, "recurs": 161, "log": [162, 163, 178, 180], "comet": [162, 178], "pretrain": [164, 165, 166, 167, 182, 186, 187], "pretrained_pipelin": 165, "resource_download": 166, "train": [168, 169, 170, 171, 172, 173, 174, 188], "conll": [168, 188], "conllu": [169, 188], "pub_tat": 172, "spacy_to_annot": 173, "tfgraph": 174, "upload_to_hub": 175, "api": 177, "refer": 177, "A": 178, "meta": 178, "machin": [178, 179], "learn": [178, 179], "platform": [178, 179], "pipelin": [178, 183, 186, 187], "paramet": 178, "evalu": 178, "metric": 178, "visual": 178, "run": 178, "an": 178, "offlin": 178, "experi": 178, "mlflow": 179, "lifecycl": 179, "third": 180, "parti": 180, "project": 180, "approach": 182, "model": 182, "note": 182, "avail": [182, 187], "set": 183, "up": 183, "your": 183, "own": 183, "type": 183, "necessari": 183, "import": 183, "construct": 183, "documentassembl": 183, "data": 183, "detect": 183, "out": 183, "put": 183, "all": 183, "togeth": 183, "ml": [183, 187], "helper": 184, "user": 185, "guid": 185, "light": 186, "convert": 186, "pipelinemodel": 186, "download": 187, "As": 187, "lightpipelin": 187, "load": 188, "dataset": 188, "spell": 188, "checker": 188, "pubtat": 188}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Getting Started": [[0, "getting-started"]], "Spark NLP Cheat Sheet": [[0, "spark-nlp-cheat-sheet"]], "Requirements": [[0, "requirements"]], "Installation": [[0, "installation"], [178, "installation"]], "Using Conda": [[0, "using-conda"]], "Using Virtualenv": [[0, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[0, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[1, "spark-nlp-documentation"]], "Content": [[1, "content"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "Module Contents": [[2, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [8, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [43, "module-contents"], [44, "module-contents"], [46, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [51, "module-contents"], [52, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [75, "module-contents"], [78, "module-contents"], [80, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [85, "module-contents"], [86, "module-contents"], [87, "module-contents"], [88, "module-contents"], [90, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [101, "module-contents"], [103, "module-contents"], [104, "module-contents"], [106, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [111, "module-contents"], [112, "module-contents"], [113, "module-contents"], [115, "module-contents"], [116, "module-contents"], [117, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [145, "module-contents"], [149, "module-contents"], [150, "module-contents"], [151, "module-contents"], [153, "module-contents"], [154, "module-contents"], [156, "module-contents"], [157, "module-contents"], [158, "module-contents"], [160, "module-contents"], [161, "module-contents"], [162, "module-contents"], [165, "module-contents"], [166, "module-contents"], [168, "module-contents"], [169, "module-contents"], [171, "module-contents"], [172, "module-contents"], [173, "module-contents"]], "Classes": [[2, "classes"], [3, "classes"], [4, "classes"], [5, "classes"], [7, "classes"], [8, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [43, "classes"], [44, "classes"], [46, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [51, "classes"], [52, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [75, "classes"], [78, "classes"], [80, "classes"], [81, "classes"], [82, "classes"], [83, "classes"], [85, "classes"], [86, "classes"], [87, "classes"], [88, "classes"], [90, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [95, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [101, "classes"], [103, "classes"], [104, "classes"], [106, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [111, "classes"], [112, "classes"], [113, "classes"], [115, "classes"], [116, "classes"], [117, "classes"], [118, "classes"], [119, "classes"], [120, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [145, "classes"], [149, "classes"], [150, "classes"], [151, "classes"], [156, "classes"], [157, "classes"], [158, "classes"], [160, "classes"], [161, "classes"], [162, "classes"], [165, "classes"], [166, "classes"], [168, "classes"], [169, "classes"], [171, "classes"], [172, "classes"], [173, "classes"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "Submodules": [[6, "submodules"], [27, "submodules"], [42, "submodules"], [45, "submodules"], [50, "submodules"], [62, "submodules"], [74, "submodules"], [76, "submodules"], [77, "submodules"], [79, "submodules"], [84, "submodules"], [89, "submodules"], [100, "submodules"], [102, "submodules"], [105, "submodules"], [110, "submodules"], [114, "submodules"], [121, "submodules"], [125, "submodules"], [136, "submodules"], [148, "submodules"], [155, "submodules"], [159, "submodules"], [163, "submodules"], [164, "submodules"], [170, "submodules"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "sparknlp.annotator.chunk2_doc": [[8, "module-sparknlp.annotator.chunk2_doc"]], "sparknlp.annotator.chunker": [[9, "module-sparknlp.annotator.chunker"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification": [[16, "module-sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[18, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[19, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[20, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[22, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[23, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[26, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[27, "module-sparknlp.annotator.classifier_dl"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[28, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[29, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[30, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[31, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[32, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[33, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[34, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[35, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[36, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[40, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[41, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[42, "module-sparknlp.annotator.coref"]], "sparknlp.annotator.coref.spanbert_coref": [[43, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv.convnext_for_image_classification": [[44, "module-sparknlp.annotator.cv.convnext_for_image_classification"]], "sparknlp.annotator.cv": [[45, "module-sparknlp.annotator.cv"]], "sparknlp.annotator.cv.swin_for_image_classification": [[46, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "sparknlp.annotator.cv.vit_for_image_classification": [[47, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "sparknlp.annotator.date2_chunk": [[48, "module-sparknlp.annotator.date2_chunk"]], "sparknlp.annotator.dependency.dependency_parser": [[49, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[50, "module-sparknlp.annotator.dependency"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[51, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "sparknlp.annotator.document_normalizer": [[52, "module-sparknlp.annotator.document_normalizer"]], "sparknlp.annotator.embeddings.albert_embeddings": [[53, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "sparknlp.annotator.embeddings.bert_embeddings": [[54, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[55, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[56, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[57, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[58, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[59, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "sparknlp.annotator.embeddings.doc2vec": [[60, "module-sparknlp.annotator.embeddings.doc2vec"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[61, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[62, "module-sparknlp.annotator.embeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[63, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[64, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[65, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[66, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[67, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "sparknlp.annotator.embeddings.word2vec": [[68, "module-sparknlp.annotator.embeddings.word2vec"]], "sparknlp.annotator.embeddings.word_embeddings": [[69, "module-sparknlp.annotator.embeddings.word_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[70, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[71, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[72, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "sparknlp.annotator.er.entity_ruler": [[73, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[74, "module-sparknlp.annotator.er"]], "sparknlp.annotator.graph_extraction": [[75, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[76, "module-sparknlp.annotator"]], "Subpackages": [[76, "subpackages"], [155, "subpackages"]], "sparknlp.annotator.keyword_extraction": [[77, "module-sparknlp.annotator.keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[78, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[79, "module-sparknlp.annotator.ld_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[80, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "sparknlp.annotator.lemmatizer": [[81, "module-sparknlp.annotator.lemmatizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[82, "module-sparknlp.annotator.matcher.big_text_matcher"]], "sparknlp.annotator.matcher.date_matcher": [[83, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[84, "module-sparknlp.annotator.matcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[85, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "sparknlp.annotator.matcher.regex_matcher": [[86, "module-sparknlp.annotator.matcher.regex_matcher"]], "sparknlp.annotator.matcher.text_matcher": [[87, "module-sparknlp.annotator.matcher.text_matcher"]], "sparknlp.annotator.n_gram_generator": [[88, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[89, "module-sparknlp.annotator.ner"]], "sparknlp.annotator.ner.ner_approach": [[90, "module-sparknlp.annotator.ner.ner_approach"]], "sparknlp.annotator.ner.ner_converter": [[91, "module-sparknlp.annotator.ner.ner_converter"]], "sparknlp.annotator.ner.ner_crf": [[92, "module-sparknlp.annotator.ner.ner_crf"]], "sparknlp.annotator.ner.ner_dl": [[93, "module-sparknlp.annotator.ner.ner_dl"]], "sparknlp.annotator.ner.ner_overwriter": [[94, "module-sparknlp.annotator.ner.ner_overwriter"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[95, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "sparknlp.annotator.normalizer": [[96, "module-sparknlp.annotator.normalizer"]], "sparknlp.annotator.param.classifier_encoder": [[97, "module-sparknlp.annotator.param.classifier_encoder"]], "sparknlp.annotator.param.evaluation_dl_params": [[98, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[99, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[100, "module-sparknlp.annotator.pos"]], "sparknlp.annotator.pos.perceptron": [[101, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[102, "module-sparknlp.annotator.sentence"]], "sparknlp.annotator.sentence.sentence_detector": [[103, "module-sparknlp.annotator.sentence.sentence_detector"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[104, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[105, "module-sparknlp.annotator.sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[106, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[107, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "sparknlp.annotator.seq2seq.bart_transformer": [[108, "module-sparknlp.annotator.seq2seq.bart_transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[109, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[110, "module-sparknlp.annotator.seq2seq"]], "sparknlp.annotator.seq2seq.marian_transformer": [[111, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "sparknlp.annotator.seq2seq.t5_transformer": [[112, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "sparknlp.annotator.spell_check.context_spell_checker": [[113, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "sparknlp.annotator.spell_check": [[114, "module-sparknlp.annotator.spell_check"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[115, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "sparknlp.annotator.spell_check.symmetric_delete": [[116, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "sparknlp.annotator.stemmer": [[117, "module-sparknlp.annotator.stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[118, "module-sparknlp.annotator.stop_words_cleaner"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[119, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "sparknlp.annotator.token.chunk_tokenizer": [[120, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[121, "module-sparknlp.annotator.token"]], "sparknlp.annotator.token.recursive_tokenizer": [[122, "module-sparknlp.annotator.token.recursive_tokenizer"]], "sparknlp.annotator.token.regex_tokenizer": [[123, "module-sparknlp.annotator.token.regex_tokenizer"]], "sparknlp.annotator.token.tokenizer": [[124, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[125, "module-sparknlp.annotator.ws"]], "sparknlp.annotator.ws.word_segmenter": [[126, "module-sparknlp.annotator.ws.word_segmenter"]], "sparknlp.base.audio_assembler": [[127, "module-sparknlp.base.audio_assembler"]], "sparknlp.base.doc2_chunk": [[128, "module-sparknlp.base.doc2_chunk"]], "sparknlp.base.document_assembler": [[129, "module-sparknlp.base.document_assembler"]], "sparknlp.base.embeddings_finisher": [[130, "module-sparknlp.base.embeddings_finisher"]], "sparknlp.base.finisher": [[131, "module-sparknlp.base.finisher"]], "sparknlp.base.graph_finisher": [[132, "module-sparknlp.base.graph_finisher"]], "sparknlp.base.has_recursive_fit": [[133, "module-sparknlp.base.has_recursive_fit"]], "sparknlp.base.has_recursive_transform": [[134, "module-sparknlp.base.has_recursive_transform"]], "sparknlp.base.image_assembler": [[135, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[136, "module-sparknlp.base"]], "sparknlp.base.light_pipeline": [[137, "module-sparknlp.base.light_pipeline"]], "sparknlp.base.multi_document_assembler": [[138, "module-sparknlp.base.multi_document_assembler"]], "sparknlp.base.recursive_pipeline": [[139, "module-sparknlp.base.recursive_pipeline"]], "sparknlp.base.table_assembler": [[140, "module-sparknlp.base.table_assembler"]], "sparknlp.base.token2_chunk": [[141, "module-sparknlp.base.token2_chunk"]], "sparknlp.base.token_assembler": [[142, "module-sparknlp.base.token_assembler"]], "sparknlp.common.annotator_approach": [[143, "module-sparknlp.common.annotator_approach"]], "sparknlp.common.annotator_model": [[144, "module-sparknlp.common.annotator_model"]], "sparknlp.common.annotator_properties": [[145, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[146, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[147, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[148, "module-sparknlp.common"]], "sparknlp.common.properties": [[149, "module-sparknlp.common.properties"]], "sparknlp.common.read_as": [[150, "module-sparknlp.common.read_as"]], "sparknlp.common.recursive_annotator_approach": [[151, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[152, "module-sparknlp.common.storage"]], "sparknlp.common.utils": [[153, "module-sparknlp.common.utils"]], "Functions": [[153, "functions"], [154, "functions"], [155, "functions"]], "sparknlp.functions": [[154, "module-sparknlp.functions"]], "sparknlp": [[155, "module-sparknlp"]], "Package Contents": [[155, "package-contents"]], "sparknlp.internal.annotator_java_ml": [[156, "module-sparknlp.internal.annotator_java_ml"]], "sparknlp.internal.annotator_transformer": [[157, "module-sparknlp.internal.annotator_transformer"]], "sparknlp.internal.extended_java_wrapper": [[158, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[159, "module-sparknlp.internal"]], "sparknlp.internal.params_getters_setters": [[160, "module-sparknlp.internal.params_getters_setters"]], "sparknlp.internal.recursive": [[161, "module-sparknlp.internal.recursive"]], "sparknlp.logging.comet": [[162, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[163, "module-sparknlp.logging"]], "sparknlp.pretrained": [[164, "module-sparknlp.pretrained"]], "sparknlp.pretrained.pretrained_pipeline": [[165, "module-sparknlp.pretrained.pretrained_pipeline"]], "sparknlp.pretrained.resource_downloader": [[166, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[167, "module-sparknlp.pretrained.utils"]], "sparknlp.training.conll": [[168, "module-sparknlp.training.conll"]], "sparknlp.training.conllu": [[169, "module-sparknlp.training.conllu"]], "sparknlp.training": [[170, "module-sparknlp.training"]], "sparknlp.training.pos": [[171, "module-sparknlp.training.pos"]], "sparknlp.training.pub_tator": [[172, "module-sparknlp.training.pub_tator"]], "sparknlp.training.spacy_to_annotation": [[173, "module-sparknlp.training.spacy_to_annotation"]], "sparknlp.training.tfgraphs": [[174, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[175, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[176, "module-sparknlp.util"]], "API Reference": [[177, "api-reference"]], "Modules": [[177, "modules"]], "Comet - A meta machine learning platform": [[178, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[178, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[178, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[178, "logging-evaluation-metrics"]], "Logging Visualizations": [[178, "logging-visualizations"]], "Running An Offline Experiment": [[178, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[179, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[180, "third-party-projects"]], "Logging": [[180, "logging"]], "Annotation": [[181, "annotation"]], "Annotators": [[182, "annotators"]], "Annotator Approaches": [[182, "annotator-approaches"]], "Annotator Models": [[182, "annotator-models"]], "Note": [[182, "note"]], "Pretrained Models": [[182, "pretrained-models"]], "Common Functions": [[182, "common-functions"]], "Available Annotators": [[182, "available-annotators"]], "Setting up your own pipeline": [[183, "setting-up-your-own-pipeline"]], "Annotator types": [[183, "annotator-types"]], "Necessary imports": [[183, "necessary-imports"]], "Constructing the Pipeline": [[183, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[183, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[183, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[183, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[183, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[184, "helper-functions"]], "User Guide": [[185, "user-guide"]], "Light Pipelines": [[186, "light-pipelines"]], "Converting PipelineModels": [[186, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[186, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[187, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[187, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[187, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[187, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[187, "available-pipelines"]], "Loading datasets for training": [[188, "loading-datasets-for-training"]], "POS Dataset": [[188, "pos-dataset"]], "CoNLL Dataset": [[188, "conll-dataset"]], "CoNLLU Dataset": [[188, "conllu-dataset"]], "Spell Checkers Dataset": [[188, "spell-checkers-dataset"]], "PubTator Dataset": [[188, "pubtator-dataset"]]}, "indexentries": {"annotation (class in sparknlp.annotation)": [[2, "sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[2, "sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.fromRow"]], "module": [[2, "module-sparknlp.annotation"], [3, "module-sparknlp.annotation_audio"], [4, "module-sparknlp.annotation_image"], [5, "module-sparknlp.annotator.audio.hubert_for_ctc"], [6, "module-sparknlp.annotator.audio"], [7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"], [8, "module-sparknlp.annotator.chunk2_doc"], [9, "module-sparknlp.annotator.chunker"], [10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"], [11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"], [13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"], [14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"], [16, "module-sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification"], [17, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"], [18, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"], [19, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [20, "module-sparknlp.annotator.classifier_dl.classifier_dl"], [21, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [22, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [23, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [26, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [27, "module-sparknlp.annotator.classifier_dl"], [28, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [29, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [30, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [31, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"], [32, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [33, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [34, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [35, "module-sparknlp.annotator.classifier_dl.sentiment_dl"], [36, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [39, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [40, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [41, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [42, "module-sparknlp.annotator.coref"], [43, "module-sparknlp.annotator.coref.spanbert_coref"], [44, "module-sparknlp.annotator.cv.convnext_for_image_classification"], [45, "module-sparknlp.annotator.cv"], [46, "module-sparknlp.annotator.cv.swin_for_image_classification"], [47, "module-sparknlp.annotator.cv.vit_for_image_classification"], [48, "module-sparknlp.annotator.date2_chunk"], [49, "module-sparknlp.annotator.dependency.dependency_parser"], [50, "module-sparknlp.annotator.dependency"], [51, "module-sparknlp.annotator.dependency.typed_dependency_parser"], [52, "module-sparknlp.annotator.document_normalizer"], [53, "module-sparknlp.annotator.embeddings.albert_embeddings"], [54, "module-sparknlp.annotator.embeddings.bert_embeddings"], [55, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"], [56, "module-sparknlp.annotator.embeddings.camembert_embeddings"], [57, "module-sparknlp.annotator.embeddings.chunk_embeddings"], [58, "module-sparknlp.annotator.embeddings.deberta_embeddings"], [59, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"], [60, "module-sparknlp.annotator.embeddings.doc2vec"], [61, "module-sparknlp.annotator.embeddings.elmo_embeddings"], [62, "module-sparknlp.annotator.embeddings"], [63, "module-sparknlp.annotator.embeddings.longformer_embeddings"], [64, "module-sparknlp.annotator.embeddings.roberta_embeddings"], [65, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [66, "module-sparknlp.annotator.embeddings.sentence_embeddings"], [67, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"], [68, "module-sparknlp.annotator.embeddings.word2vec"], [69, "module-sparknlp.annotator.embeddings.word_embeddings"], [70, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [71, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [72, "module-sparknlp.annotator.embeddings.xlnet_embeddings"], [73, "module-sparknlp.annotator.er.entity_ruler"], [74, "module-sparknlp.annotator.er"], [75, "module-sparknlp.annotator.graph_extraction"], [76, "module-sparknlp.annotator"], [77, "module-sparknlp.annotator.keyword_extraction"], [78, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [79, "module-sparknlp.annotator.ld_dl"], [80, "module-sparknlp.annotator.ld_dl.language_detector_dl"], [81, "module-sparknlp.annotator.lemmatizer"], [82, "module-sparknlp.annotator.matcher.big_text_matcher"], [83, "module-sparknlp.annotator.matcher.date_matcher"], [84, "module-sparknlp.annotator.matcher"], [85, "module-sparknlp.annotator.matcher.multi_date_matcher"], [86, "module-sparknlp.annotator.matcher.regex_matcher"], [87, "module-sparknlp.annotator.matcher.text_matcher"], [88, "module-sparknlp.annotator.n_gram_generator"], [89, "module-sparknlp.annotator.ner"], [90, "module-sparknlp.annotator.ner.ner_approach"], [91, "module-sparknlp.annotator.ner.ner_converter"], [92, "module-sparknlp.annotator.ner.ner_crf"], [93, "module-sparknlp.annotator.ner.ner_dl"], [94, "module-sparknlp.annotator.ner.ner_overwriter"], [95, "module-sparknlp.annotator.ner.zero_shot_ner_model"], [96, "module-sparknlp.annotator.normalizer"], [97, "module-sparknlp.annotator.param.classifier_encoder"], [98, "module-sparknlp.annotator.param.evaluation_dl_params"], [99, "module-sparknlp.annotator.param"], [100, "module-sparknlp.annotator.pos"], [101, "module-sparknlp.annotator.pos.perceptron"], [102, "module-sparknlp.annotator.sentence"], [103, "module-sparknlp.annotator.sentence.sentence_detector"], [104, "module-sparknlp.annotator.sentence.sentence_detector_dl"], [105, "module-sparknlp.annotator.sentiment"], [106, "module-sparknlp.annotator.sentiment.sentiment_detector"], [107, "module-sparknlp.annotator.sentiment.vivekn_sentiment"], [108, "module-sparknlp.annotator.seq2seq.bart_transformer"], [109, "module-sparknlp.annotator.seq2seq.gpt2_transformer"], [110, "module-sparknlp.annotator.seq2seq"], [111, "module-sparknlp.annotator.seq2seq.marian_transformer"], [112, "module-sparknlp.annotator.seq2seq.t5_transformer"], [113, "module-sparknlp.annotator.spell_check.context_spell_checker"], [114, "module-sparknlp.annotator.spell_check"], [115, "module-sparknlp.annotator.spell_check.norvig_sweeting"], [116, "module-sparknlp.annotator.spell_check.symmetric_delete"], [117, "module-sparknlp.annotator.stemmer"], [118, "module-sparknlp.annotator.stop_words_cleaner"], [119, "module-sparknlp.annotator.tf_ner_dl_graph_builder"], [120, "module-sparknlp.annotator.token.chunk_tokenizer"], [121, "module-sparknlp.annotator.token"], [122, "module-sparknlp.annotator.token.recursive_tokenizer"], [123, "module-sparknlp.annotator.token.regex_tokenizer"], [124, "module-sparknlp.annotator.token.tokenizer"], [125, "module-sparknlp.annotator.ws"], [126, "module-sparknlp.annotator.ws.word_segmenter"], [127, "module-sparknlp.base.audio_assembler"], [128, "module-sparknlp.base.doc2_chunk"], [129, "module-sparknlp.base.document_assembler"], [130, "module-sparknlp.base.embeddings_finisher"], [131, "module-sparknlp.base.finisher"], [132, "module-sparknlp.base.graph_finisher"], [133, "module-sparknlp.base.has_recursive_fit"], [134, "module-sparknlp.base.has_recursive_transform"], [135, "module-sparknlp.base.image_assembler"], [136, "module-sparknlp.base"], [137, "module-sparknlp.base.light_pipeline"], [138, "module-sparknlp.base.multi_document_assembler"], [139, "module-sparknlp.base.recursive_pipeline"], [140, "module-sparknlp.base.table_assembler"], [141, "module-sparknlp.base.token2_chunk"], [142, "module-sparknlp.base.token_assembler"], [143, "module-sparknlp.common.annotator_approach"], [144, "module-sparknlp.common.annotator_model"], [145, "module-sparknlp.common.annotator_properties"], [146, "module-sparknlp.common.annotator_type"], [147, "module-sparknlp.common.coverage_result"], [148, "module-sparknlp.common"], [149, "module-sparknlp.common.properties"], [150, "module-sparknlp.common.read_as"], [151, "module-sparknlp.common.recursive_annotator_approach"], [152, "module-sparknlp.common.storage"], [153, "module-sparknlp.common.utils"], [154, "module-sparknlp.functions"], [155, "module-sparknlp"], [156, "module-sparknlp.internal.annotator_java_ml"], [157, "module-sparknlp.internal.annotator_transformer"], [158, "module-sparknlp.internal.extended_java_wrapper"], [159, "module-sparknlp.internal"], [160, "module-sparknlp.internal.params_getters_setters"], [161, "module-sparknlp.internal.recursive"], [162, "module-sparknlp.logging.comet"], [163, "module-sparknlp.logging"], [164, "module-sparknlp.pretrained"], [165, "module-sparknlp.pretrained.pretrained_pipeline"], [166, "module-sparknlp.pretrained.resource_downloader"], [167, "module-sparknlp.pretrained.utils"], [168, "module-sparknlp.training.conll"], [169, "module-sparknlp.training.conllu"], [170, "module-sparknlp.training"], [171, "module-sparknlp.training.pos"], [172, "module-sparknlp.training.pub_tator"], [173, "module-sparknlp.training.spacy_to_annotation"], [174, "module-sparknlp.training.tfgraphs"], [175, "module-sparknlp.upload_to_hub"], [176, "module-sparknlp.util"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "torow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in sparknlp.annotation_audio)": [[3, "sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[3, "sparknlp.annotation_audio.AnnotationAudio.copy"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "annotationimage (class in sparknlp.annotation_image)": [[4, "sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[4, "sparknlp.annotation_image.AnnotationImage.copy"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "hubertforctc (class in sparknlp.annotator.audio.hubert_for_ctc)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC"]], "loadsavedmodel() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.loadSavedModel"]], "pretrained() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.pretrained"]], "setconfigprotobytes() (hubertforctc method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "wav2vec2forctc (class in sparknlp.annotator.audio.wav2vec2_for_ctc)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "setconfigprotobytes() (wav2vec2forctc method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "chunk2doc (class in sparknlp.annotator.chunk2_doc)": [[8, "sparknlp.annotator.chunk2_doc.Chunk2Doc"]], "sparknlp.annotator.chunk2_doc": [[8, "module-sparknlp.annotator.chunk2_doc"]], "chunker (class in sparknlp.annotator.chunker)": [[9, "sparknlp.annotator.chunker.Chunker"]], "setregexparsers() (chunker method)": [[9, "sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "sparknlp.annotator.chunker": [[9, "module-sparknlp.annotator.chunker"]], "albertforquestionanswering (class in sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (albertforquestionanswering method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "albertforsequenceclassification (class in sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "setcoalescesentences() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "albertfortokenclassification (class in sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "setconfigprotobytes() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[12, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[12, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "bertforquestionanswering (class in sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (bertforquestionanswering method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "bertforsequenceclassification (class in sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "setcoalescesentences() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "bertfortokenclassification (class in sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "setconfigprotobytes() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[15, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[15, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "bertforzeroshotclassification (class in sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification"]], "getclasses() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.getClasses"]], "loadsavedmodel() (bertforzeroshotclassification static method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.loadSavedModel"]], "pretrained() (bertforzeroshotclassification static method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.pretrained"]], "setcoalescesentences() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforzeroshotclassification method)": [[16, "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification": [[16, "module-sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification"]], "camembertforquestionanswering (class in sparknlp.annotator.classifier_dl.camembert_for_question_answering)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering"]], "loadsavedmodel() (camembertforquestionanswering static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.loadSavedModel"]], "pretrained() (camembertforquestionanswering static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (camembertforquestionanswering method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforquestionanswering method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "camembertforsequenceclassification (class in sparknlp.annotator.classifier_dl.camembert_for_sequence_classification)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification"]], "getclasses() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.getClasses"]], "loadsavedmodel() (camembertforsequenceclassification static method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.loadSavedModel"]], "pretrained() (camembertforsequenceclassification static method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.pretrained"]], "setcoalescesentences() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforsequenceclassification method)": [[18, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[18, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "camembertfortokenclassification (class in sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[19, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[19, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "classifierdlapproach (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "setconfigprotobytes() (classifierdlmodel method)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[20, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[20, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "debertaforquestionanswering (class in sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "debertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[22, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[22, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "debertafortokenclassification (class in sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (debertafortokenclassification method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[23, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[23, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "distilbertforquestionanswering (class in sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "distilbertforsequenceclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[25, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[25, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "distilbertfortokenclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[26, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[26, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[27, "module-sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[28, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "longformerforsequenceclassification (class in sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[29, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[29, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "longformerfortokenclassification (class in sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[30, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[30, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "multiclassifierdlapproach (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[31, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[31, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "robertaforquestionanswering (class in sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[32, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "robertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[33, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[33, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "robertafortokenclassification (class in sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (robertafortokenclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[34, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[34, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sentimentdlapproach (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "setconfigprotobytes() (sentimentdlmodel method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[35, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[35, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "tapasforquestionanswering (class in sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[36, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[36, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[36, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[36, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "xlmrobertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[38, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "xlmrobertafortokenclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "xlnetforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[40, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[40, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "xlnetfortokenclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[41, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[41, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[42, "module-sparknlp.annotator.coref"]], "spanbertcorefmodel (class in sparknlp.annotator.coref.spanbert_coref)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[43, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "sparknlp.annotator.coref.spanbert_coref": [[43, "module-sparknlp.annotator.coref.spanbert_coref"]], "convnextforimageclassification (class in sparknlp.annotator.cv.convnext_for_image_classification)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification"]], "getclasses() (convnextforimageclassification method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.getClasses"]], "loadsavedmodel() (convnextforimageclassification static method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.loadSavedModel"]], "pretrained() (convnextforimageclassification static method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.pretrained"]], "setconfigprotobytes() (convnextforimageclassification method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setConfigProtoBytes"]], "setcroppct() (convnextforimageclassification method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setCropPct"]], "setdorescale() (convnextforimageclassification method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setDoRescale"]], "setrescalefactor() (convnextforimageclassification method)": [[44, "sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.convnext_for_image_classification": [[44, "module-sparknlp.annotator.cv.convnext_for_image_classification"]], "sparknlp.annotator.cv": [[45, "module-sparknlp.annotator.cv"]], "swinforimageclassification (class in sparknlp.annotator.cv.swin_for_image_classification)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification"]], "getclasses() (swinforimageclassification method)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.getClasses"]], "loadsavedmodel() (swinforimageclassification static method)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.loadSavedModel"]], "pretrained() (swinforimageclassification static method)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.pretrained"]], "setconfigprotobytes() (swinforimageclassification method)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setConfigProtoBytes"]], "setdorescale() (swinforimageclassification method)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setDoRescale"]], "setrescalefactor() (swinforimageclassification method)": [[46, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[46, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "vitforimageclassification (class in sparknlp.annotator.cv.vit_for_image_classification)": [[47, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[47, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[47, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[47, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "setconfigprotobytes() (vitforimageclassification method)": [[47, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "sparknlp.annotator.cv.vit_for_image_classification": [[47, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "date2chunk (class in sparknlp.annotator.date2_chunk)": [[48, "sparknlp.annotator.date2_chunk.Date2Chunk"]], "setentityname() (date2chunk method)": [[48, "sparknlp.annotator.date2_chunk.Date2Chunk.setEntityName"]], "sparknlp.annotator.date2_chunk": [[48, "module-sparknlp.annotator.date2_chunk"]], "dependencyparserapproach (class in sparknlp.annotator.dependency.dependency_parser)": [[49, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in sparknlp.annotator.dependency.dependency_parser)": [[49, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[49, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "setconllu() (dependencyparserapproach method)": [[49, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[49, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[49, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser": [[49, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[50, "module-sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[51, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[51, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[51, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "setconll2009() (typeddependencyparserapproach method)": [[51, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[51, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[51, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[51, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "documentnormalizer (class in sparknlp.annotator.document_normalizer)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "setaction() (documentnormalizer method)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[52, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "sparknlp.annotator.document_normalizer": [[52, "module-sparknlp.annotator.document_normalizer"]], "albertembeddings (class in sparknlp.annotator.embeddings.albert_embeddings)": [[53, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[53, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[53, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "setconfigprotobytes() (albertembeddings method)": [[53, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[53, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.albert_embeddings": [[53, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "bertembeddings (class in sparknlp.annotator.embeddings.bert_embeddings)": [[54, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[54, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[54, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "setconfigprotobytes() (bertembeddings method)": [[54, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[54, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[54, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "bertsentenceembeddings (class in sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[55, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[55, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[55, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[55, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[55, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[55, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[55, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "camembertembeddings (class in sparknlp.annotator.embeddings.camembert_embeddings)": [[56, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[56, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[56, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "setconfigprotobytes() (camembertembeddings method)": [[56, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[56, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[56, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "chunkembeddings (class in sparknlp.annotator.embeddings.chunk_embeddings)": [[57, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[57, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[57, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[57, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "debertaembeddings (class in sparknlp.annotator.embeddings.deberta_embeddings)": [[58, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[58, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[58, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "setconfigprotobytes() (debertaembeddings method)": [[58, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[58, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[58, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "distilbertembeddings (class in sparknlp.annotator.embeddings.distil_bert_embeddings)": [[59, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[59, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[59, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "setconfigprotobytes() (distilbertembeddings method)": [[59, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[59, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[59, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "doc2vecapproach (class in sparknlp.annotator.embeddings.doc2vec)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in sparknlp.annotator.embeddings.doc2vec)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "setmaxiter() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[60, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec": [[60, "module-sparknlp.annotator.embeddings.doc2vec"]], "elmoembeddings (class in sparknlp.annotator.embeddings.elmo_embeddings)": [[61, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[61, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[61, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "setbatchsize() (elmoembeddings method)": [[61, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[61, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[61, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[61, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[62, "module-sparknlp.annotator.embeddings"]], "longformerembeddings (class in sparknlp.annotator.embeddings.longformer_embeddings)": [[63, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[63, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[63, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "setconfigprotobytes() (longformerembeddings method)": [[63, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[63, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[63, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "robertaembeddings (class in sparknlp.annotator.embeddings.roberta_embeddings)": [[64, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[64, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[64, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (robertaembeddings method)": [[64, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[64, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[64, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "robertasentenceembeddings (class in sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[65, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[65, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[65, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[65, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[65, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[65, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sentenceembeddings (class in sparknlp.annotator.embeddings.sentence_embeddings)": [[66, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[66, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[66, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "universalsentenceencoder (class in sparknlp.annotator.embeddings.universal_sentence_encoder)": [[67, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[67, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[67, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "setconfigprotobytes() (universalsentenceencoder method)": [[67, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[67, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[67, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "word2vecapproach (class in sparknlp.annotator.embeddings.word2vec)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in sparknlp.annotator.embeddings.word2vec)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "setmaxiter() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[68, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.word2vec": [[68, "module-sparknlp.annotator.embeddings.word2vec"]], "wordembeddings (class in sparknlp.annotator.embeddings.word_embeddings)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in sparknlp.annotator.embeddings.word_embeddings)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "setreadcachesize() (wordembeddings method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[69, "module-sparknlp.annotator.embeddings.word_embeddings"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[69, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[70, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[70, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[70, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[70, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[70, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[70, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "xlmrobertasentenceembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[71, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[71, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "xlnetembeddings (class in sparknlp.annotator.embeddings.xlnet_embeddings)": [[72, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[72, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[72, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "setconfigprotobytes() (xlnetembeddings method)": [[72, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[72, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[72, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "entityrulerapproach (class in sparknlp.annotator.er.entity_ruler)": [[73, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in sparknlp.annotator.er.entity_ruler)": [[73, "sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "setalphabetresource() (entityrulerapproach method)": [[73, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setpatternsresource() (entityrulerapproach method)": [[73, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[73, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[73, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "sparknlp.annotator.er.entity_ruler": [[73, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[74, "module-sparknlp.annotator.er"]], "graphextraction (class in sparknlp.annotator.graph_extraction)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction"]], "setdelimiter() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[75, "sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "sparknlp.annotator.graph_extraction": [[75, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[76, "module-sparknlp.annotator"]], "sparknlp.annotator.keyword_extraction": [[77, "module-sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "setmaxngrams() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[78, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[78, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[79, "module-sparknlp.annotator.ld_dl"]], "languagedetectordl (class in sparknlp.annotator.ld_dl.language_detector_dl)": [[80, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[80, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "setcoalescesentences() (languagedetectordl method)": [[80, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[80, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[80, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[80, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[80, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "lemmatizer (class in sparknlp.annotator.lemmatizer)": [[81, "sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in sparknlp.annotator.lemmatizer)": [[81, "sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[81, "sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "setdictionary() (lemmatizer method)": [[81, "sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[81, "sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[81, "sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "sparknlp.annotator.lemmatizer": [[81, "module-sparknlp.annotator.lemmatizer"]], "bigtextmatcher (class in sparknlp.annotator.matcher.big_text_matcher)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in sparknlp.annotator.matcher.big_text_matcher)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "setcasesensitive() (bigtextmatcher method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[82, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[82, "module-sparknlp.annotator.matcher.big_text_matcher"]], "datematcher (class in sparknlp.annotator.matcher.date_matcher)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in sparknlp.annotator.matcher.date_matcher)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "setanchordateday() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[83, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "sparknlp.annotator.matcher.date_matcher": [[83, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[84, "module-sparknlp.annotator.matcher"]], "multidatematcher (class in sparknlp.annotator.matcher.multi_date_matcher)": [[85, "sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[85, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in sparknlp.annotator.matcher.regex_matcher)": [[86, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in sparknlp.annotator.matcher.regex_matcher)": [[86, "sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "setdelimiter() (regexmatcher method)": [[86, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setDelimiter"]], "setexternalrules() (regexmatcher method)": [[86, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setrules() (regexmatcher method)": [[86, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setRules"]], "setstrategy() (regexmatcher method)": [[86, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "sparknlp.annotator.matcher.regex_matcher": [[86, "module-sparknlp.annotator.matcher.regex_matcher"]], "textmatcher (class in sparknlp.annotator.matcher.text_matcher)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in sparknlp.annotator.matcher.text_matcher)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "setbuildfromtokens() (textmatcher method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[87, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher": [[87, "module-sparknlp.annotator.matcher.text_matcher"]], "ngramgenerator (class in sparknlp.annotator.n_gram_generator)": [[88, "sparknlp.annotator.n_gram_generator.NGramGenerator"]], "setdelimiter() (ngramgenerator method)": [[88, "sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[88, "sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[88, "sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "sparknlp.annotator.n_gram_generator": [[88, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[89, "module-sparknlp.annotator.ner"]], "nerapproach (class in sparknlp.annotator.ner.ner_approach)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "setentities() (nerapproach method)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[90, "sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "sparknlp.annotator.ner.ner_approach": [[90, "module-sparknlp.annotator.ner.ner_approach"]], "nerconverter (class in sparknlp.annotator.ner.ner_converter)": [[91, "sparknlp.annotator.ner.ner_converter.NerConverter"]], "setnerhasnoschema() (nerconverter method)": [[91, "sparknlp.annotator.ner.ner_converter.NerConverter.setNerHasNoSchema"]], "setpreserveposition() (nerconverter method)": [[91, "sparknlp.annotator.ner.ner_converter.NerConverter.setPreservePosition"]], "setwhitelist() (nerconverter method)": [[91, "sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "sparknlp.annotator.ner.ner_converter": [[91, "module-sparknlp.annotator.ner.ner_converter"]], "nercrfapproach (class in sparknlp.annotator.ner.ner_crf)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in sparknlp.annotator.ner.ner_crf)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "setc0() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[92, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "sparknlp.annotator.ner.ner_crf": [[92, "module-sparknlp.annotator.ner.ner_crf"]], "nerdlapproach (class in sparknlp.annotator.ner.ner_dl)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in sparknlp.annotator.ner.ner_dl)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "setbatchsize() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[93, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "sparknlp.annotator.ner.ner_dl": [[93, "module-sparknlp.annotator.ner.ner_dl"]], "neroverwriter (class in sparknlp.annotator.ner.ner_overwriter)": [[94, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "setnerwords() (neroverwriter method)": [[94, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[94, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[94, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "sparknlp.annotator.ner.ner_overwriter": [[94, "module-sparknlp.annotator.ner.ner_overwriter"]], "zeroshotnermodel (class in sparknlp.annotator.ner.zero_shot_ner_model)": [[95, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel"]], "getclasses() (zeroshotnermodel method)": [[95, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.getClasses"]], "load() (zeroshotnermodel static method)": [[95, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.load"]], "pretrained() (zeroshotnermodel static method)": [[95, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.pretrained"]], "setentitydefinitions() (zeroshotnermodel method)": [[95, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setEntityDefinitions"]], "setpredictionthreshold() (zeroshotnermodel method)": [[95, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setPredictionThreshold"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[95, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "normalizer (class in sparknlp.annotator.normalizer)": [[96, "sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in sparknlp.annotator.normalizer)": [[96, "sparknlp.annotator.normalizer.NormalizerModel"]], "setcleanuppatterns() (normalizer method)": [[96, "sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[96, "sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[96, "sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[96, "sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[96, "sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "sparknlp.annotator.normalizer": [[96, "module-sparknlp.annotator.normalizer"]], "classifierencoder (class in sparknlp.annotator.param.classifier_encoder)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "setbatchsize() (classifierencoder method)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[97, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "sparknlp.annotator.param.classifier_encoder": [[97, "module-sparknlp.annotator.param.classifier_encoder"]], "evaluationdlparams (class in sparknlp.annotator.param.evaluation_dl_params)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "setenableoutputlogs() (evaluationdlparams method)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[98, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "sparknlp.annotator.param.evaluation_dl_params": [[98, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[99, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[100, "module-sparknlp.annotator.pos"]], "perceptronapproach (class in sparknlp.annotator.pos.perceptron)": [[101, "sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in sparknlp.annotator.pos.perceptron)": [[101, "sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[101, "sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[101, "sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "setiterations() (perceptronapproach method)": [[101, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[101, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "sparknlp.annotator.pos.perceptron": [[101, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[102, "module-sparknlp.annotator.sentence"]], "sentencedetector (class in sparknlp.annotator.sentence.sentence_detector)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in sparknlp.annotator.sentence.sentence_detector)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "setcustombounds() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[103, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector": [[103, "module-sparknlp.annotator.sentence.sentence_detector"]], "sentencedetectordlapproach (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "setcustombounds() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[104, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[104, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[105, "module-sparknlp.annotator.sentiment"]], "sentimentdetector (class in sparknlp.annotator.sentiment.sentiment_detector)": [[106, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in sparknlp.annotator.sentiment.sentiment_detector)": [[106, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "setdictionary() (sentimentdetector method)": [[106, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "sparknlp.annotator.sentiment.sentiment_detector": [[106, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "viveknsentimentapproach (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[107, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[107, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[107, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "setprunecorpus() (viveknsentimentapproach method)": [[107, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[107, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[107, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "barttransformer (class in sparknlp.annotator.seq2seq.bart_transformer)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer"]], "loadsavedmodel() (barttransformer static method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.loadSavedModel"]], "pretrained() (barttransformer static method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.pretrained"]], "setbeamsize() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setBeamSize"]], "setconfigprotobytes() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setConfigProtoBytes"]], "setdosample() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setDoSample"]], "setignoretokenids() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setIgnoreTokenIds"]], "setmaxoutputlength() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMaxOutputLength"]], "setminoutputlength() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setMinOutputLength"]], "setnorepeatngramsize() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setRepetitionPenalty"]], "settask() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTask"]], "settemperature() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTemperature"]], "settopk() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopK"]], "settopp() (barttransformer method)": [[108, "sparknlp.annotator.seq2seq.bart_transformer.BartTransformer.setTopP"]], "sparknlp.annotator.seq2seq.bart_transformer": [[108, "module-sparknlp.annotator.seq2seq.bart_transformer"]], "gpt2transformer (class in sparknlp.annotator.seq2seq.gpt2_transformer)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "setconfigprotobytes() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[109, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[109, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[110, "module-sparknlp.annotator.seq2seq"]], "mariantransformer (class in sparknlp.annotator.seq2seq.marian_transformer)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "setconfigprotobytes() (mariantransformer method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[111, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "sparknlp.annotator.seq2seq.marian_transformer": [[111, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "t5transformer (class in sparknlp.annotator.seq2seq.t5_transformer)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "setconfigprotobytes() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[112, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "sparknlp.annotator.seq2seq.t5_transformer": [[112, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "contextspellcheckerapproach (class in sparknlp.annotator.spell_check.context_spell_checker)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in sparknlp.annotator.spell_check.context_spell_checker)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "setbatchsize() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setclasses() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setClasses"]], "setcomparelowcase() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setgraphfolder() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setGraphFolder"]], "setidsvocab() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setIdsVocab"]], "setinitialrate() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxsentlen() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxSentLen"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setvocabfreq() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setVocabFreq"]], "setvocabids() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setVocabIds"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker": [[113, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "updateregexclass() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[113, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "sparknlp.annotator.spell_check": [[114, "module-sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "setcasesensitive() (norvigsweetingapproach method)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[115, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[115, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "symmetricdeleteapproach (class in sparknlp.annotator.spell_check.symmetric_delete)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in sparknlp.annotator.spell_check.symmetric_delete)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[116, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete": [[116, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "stemmer (class in sparknlp.annotator.stemmer)": [[117, "sparknlp.annotator.stemmer.Stemmer"]], "sparknlp.annotator.stemmer": [[117, "module-sparknlp.annotator.stemmer"]], "stopwordscleaner (class in sparknlp.annotator.stop_words_cleaner)": [[118, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[118, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[118, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "setcasesensitive() (stopwordscleaner method)": [[118, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[118, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[118, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "sparknlp.annotator.stop_words_cleaner": [[118, "module-sparknlp.annotator.stop_words_cleaner"]], "tfnerdlgraphbuilder (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[119, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[119, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "chunktokenizer (class in sparknlp.annotator.token.chunk_tokenizer)": [[120, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in sparknlp.annotator.token.chunk_tokenizer)": [[120, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "sparknlp.annotator.token.chunk_tokenizer": [[120, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[121, "module-sparknlp.annotator.token"]], "recursivetokenizer (class in sparknlp.annotator.token.recursive_tokenizer)": [[122, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in sparknlp.annotator.token.recursive_tokenizer)": [[122, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "setinfixes() (recursivetokenizer method)": [[122, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[122, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[122, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[122, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "sparknlp.annotator.token.recursive_tokenizer": [[122, "module-sparknlp.annotator.token.recursive_tokenizer"]], "regextokenizer (class in sparknlp.annotator.token.regex_tokenizer)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "setmaxlength() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[123, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "sparknlp.annotator.token.regex_tokenizer": [[123, "module-sparknlp.annotator.token.regex_tokenizer"]], "tokenizer (class in sparknlp.annotator.token.tokenizer)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in sparknlp.annotator.token.tokenizer)": [[124, "sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[124, "sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[124, "sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "setcasesensitiveexceptions() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[124, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[124, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[124, "sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "sparknlp.annotator.token.tokenizer": [[124, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[125, "module-sparknlp.annotator.ws"]], "wordsegmenterapproach (class in sparknlp.annotator.ws.word_segmenter)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in sparknlp.annotator.ws.word_segmenter)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setenableregextokenizer() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setEnableRegexTokenizer"]], "setenableregextokenizer() (wordsegmentermodel method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setEnableRegexTokenizer"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setpattern() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPattern"]], "setpattern() (wordsegmentermodel method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setPattern"]], "setposcolumn() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "settolowercase() (wordsegmenterapproach method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setToLowercase"]], "settolowercase() (wordsegmentermodel method)": [[126, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setToLowercase"]], "sparknlp.annotator.ws.word_segmenter": [[126, "module-sparknlp.annotator.ws.word_segmenter"]], "audioassembler (class in sparknlp.base.audio_assembler)": [[127, "sparknlp.base.audio_assembler.AudioAssembler"]], "getoutputcol() (audioassembler method)": [[127, "sparknlp.base.audio_assembler.AudioAssembler.getOutputCol"]], "setinputcol() (audioassembler method)": [[127, "sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[127, "sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "sparknlp.base.audio_assembler": [[127, "module-sparknlp.base.audio_assembler"]], "doc2chunk (class in sparknlp.base.doc2_chunk)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk"]], "setchunkcol() (doc2chunk method)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[128, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "sparknlp.base.doc2_chunk": [[128, "module-sparknlp.base.doc2_chunk"]], "documentassembler (class in sparknlp.base.document_assembler)": [[129, "sparknlp.base.document_assembler.DocumentAssembler"]], "getoutputcol() (documentassembler method)": [[129, "sparknlp.base.document_assembler.DocumentAssembler.getOutputCol"]], "setcleanupmode() (documentassembler method)": [[129, "sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[129, "sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[129, "sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[129, "sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[129, "sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "sparknlp.base.document_assembler": [[129, "module-sparknlp.base.document_assembler"]], "embeddingsfinisher (class in sparknlp.base.embeddings_finisher)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "getinputcols() (embeddingsfinisher method)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getInputCols"]], "getoutputcols() (embeddingsfinisher method)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getOutputCols"]], "setcleanannotations() (embeddingsfinisher method)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[130, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "sparknlp.base.embeddings_finisher": [[130, "module-sparknlp.base.embeddings_finisher"]], "finisher (class in sparknlp.base.finisher)": [[131, "sparknlp.base.finisher.Finisher"]], "getinputcols() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.getInputCols"]], "getoutputcols() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.getOutputCols"]], "setannotationsplitsymbol() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[131, "sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "sparknlp.base.finisher": [[131, "module-sparknlp.base.finisher"]], "graphfinisher (class in sparknlp.base.graph_finisher)": [[132, "sparknlp.base.graph_finisher.GraphFinisher"]], "setcleanannotations() (graphfinisher method)": [[132, "sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[132, "sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[132, "sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[132, "sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "sparknlp.base.graph_finisher": [[132, "module-sparknlp.base.graph_finisher"]], "hasrecursivefit (class in sparknlp.base.has_recursive_fit)": [[133, "sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "sparknlp.base.has_recursive_fit": [[133, "module-sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in sparknlp.base.has_recursive_transform)": [[134, "sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "sparknlp.base.has_recursive_transform": [[134, "module-sparknlp.base.has_recursive_transform"]], "imageassembler (class in sparknlp.base.image_assembler)": [[135, "sparknlp.base.image_assembler.ImageAssembler"]], "getoutputcol() (imageassembler method)": [[135, "sparknlp.base.image_assembler.ImageAssembler.getOutputCol"]], "setinputcol() (imageassembler method)": [[135, "sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[135, "sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "sparknlp.base.image_assembler": [[135, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[136, "module-sparknlp.base"]], "lightpipeline (class in sparknlp.base.light_pipeline)": [[137, "sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[137, "sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[137, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[137, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[137, "sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "setignoreunsupported() (lightpipeline method)": [[137, "sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "sparknlp.base.light_pipeline": [[137, "module-sparknlp.base.light_pipeline"]], "transform() (lightpipeline method)": [[137, "sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in sparknlp.base.multi_document_assembler)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "getoutputcols() (multidocumentassembler method)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.getOutputCols"]], "setcleanupmode() (multidocumentassembler method)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[138, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "sparknlp.base.multi_document_assembler": [[138, "module-sparknlp.base.multi_document_assembler"]], "recursivepipeline (class in sparknlp.base.recursive_pipeline)": [[139, "sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in sparknlp.base.recursive_pipeline)": [[139, "sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "sparknlp.base.recursive_pipeline": [[139, "module-sparknlp.base.recursive_pipeline"]], "tableassembler (class in sparknlp.base.table_assembler)": [[140, "sparknlp.base.table_assembler.TableAssembler"]], "setcsvdelimiter() (tableassembler method)": [[140, "sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[140, "sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[140, "sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "sparknlp.base.table_assembler": [[140, "module-sparknlp.base.table_assembler"]], "token2chunk (class in sparknlp.base.token2_chunk)": [[141, "sparknlp.base.token2_chunk.Token2Chunk"]], "sparknlp.base.token2_chunk": [[141, "module-sparknlp.base.token2_chunk"]], "tokenassembler (class in sparknlp.base.token_assembler)": [[142, "sparknlp.base.token_assembler.TokenAssembler"]], "setpreserveposition() (tokenassembler method)": [[142, "sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "sparknlp.base.token_assembler": [[142, "module-sparknlp.base.token_assembler"]], "annotatorapproach (class in sparknlp.common.annotator_approach)": [[143, "sparknlp.common.annotator_approach.AnnotatorApproach"]], "sparknlp.common.annotator_approach": [[143, "module-sparknlp.common.annotator_approach"]], "annotatormodel (class in sparknlp.common.annotator_model)": [[144, "sparknlp.common.annotator_model.AnnotatorModel"]], "sparknlp.common.annotator_model": [[144, "module-sparknlp.common.annotator_model"]], "annotatorproperties (class in sparknlp.common.annotator_properties)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "setinputcols() (annotatorproperties method)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[145, "sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "sparknlp.common.annotator_properties": [[145, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[146, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[147, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[148, "module-sparknlp.common"]], "hasembeddingsproperties (class in sparknlp.common.properties)": [[149, "sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[149, "sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "setdimension() (hasembeddingsproperties method)": [[149, "sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "sparknlp.common.properties": [[149, "module-sparknlp.common.properties"]], "readas (class in sparknlp.common.read_as)": [[150, "sparknlp.common.read_as.ReadAs"]], "sparknlp.common.read_as": [[150, "module-sparknlp.common.read_as"]], "recursiveannotatorapproach (class in sparknlp.common.recursive_annotator_approach)": [[151, "sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "sparknlp.common.recursive_annotator_approach": [[151, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[152, "module-sparknlp.common.storage"]], "externalresource() (in module sparknlp.common.utils)": [[153, "sparknlp.common.utils.ExternalResource"]], "sparknlp.common.utils": [[153, "module-sparknlp.common.utils"]], "explode_annotations_col() (in module sparknlp.functions)": [[154, "sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module sparknlp.functions)": [[154, "sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module sparknlp.functions)": [[154, "sparknlp.functions.map_annotations"]], "map_annotations_array() (in module sparknlp.functions)": [[154, "sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module sparknlp.functions)": [[154, "sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module sparknlp.functions)": [[154, "sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module sparknlp.functions)": [[154, "sparknlp.functions.map_annotations_strict"]], "sparknlp.functions": [[154, "module-sparknlp.functions"]], "sparknlp": [[155, "module-sparknlp"]], "start() (in module sparknlp)": [[155, "sparknlp.start"]], "version() (in module sparknlp)": [[155, "sparknlp.version"]], "annotatorjavamlreadable (class in sparknlp.internal.annotator_java_ml)": [[156, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in sparknlp.internal.annotator_java_ml)": [[156, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "read() (annotatorjavamlreadable class method)": [[156, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "sparknlp.internal.annotator_java_ml": [[156, "module-sparknlp.internal.annotator_java_ml"]], "annotatortransformer (class in sparknlp.internal.annotator_transformer)": [[157, "sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "sparknlp.internal.annotator_transformer": [[157, "module-sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in sparknlp.internal.extended_java_wrapper)": [[158, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[158, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "sparknlp.internal.extended_java_wrapper": [[158, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[159, "module-sparknlp.internal"]], "paramsgetterssetters (class in sparknlp.internal.params_getters_setters)": [[160, "sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[160, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "setparamvalue() (paramsgetterssetters method)": [[160, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "sparknlp.internal.params_getters_setters": [[160, "module-sparknlp.internal.params_getters_setters"]], "recursiveestimator (class in sparknlp.internal.recursive)": [[161, "sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in sparknlp.internal.recursive)": [[161, "sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[161, "sparknlp.internal.recursive.RecursiveEstimator.fit"]], "sparknlp.internal.recursive": [[161, "module-sparknlp.internal.recursive"]], "cometlogger (class in sparknlp.logging.comet)": [[162, "sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[162, "sparknlp.logging.comet.CometLogger.monitor"]], "sparknlp.logging.comet": [[162, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[163, "module-sparknlp.logging"]], "sparknlp.pretrained": [[164, "module-sparknlp.pretrained"]], "pretrainedpipeline (class in sparknlp.pretrained.pretrained_pipeline)": [[165, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[165, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[165, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "fullannotateimage() (pretrainedpipeline method)": [[165, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotateImage"]], "sparknlp.pretrained.pretrained_pipeline": [[165, "module-sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[165, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "resourcedownloader (class in sparknlp.pretrained.resource_downloader)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader"]], "clearcache() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.clearCache"]], "downloadmodel() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModel"]], "downloadmodeldirectly() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModelDirectly"]], "downloadpipeline() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadPipeline"]], "showavailableannotators() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showAvailableAnnotators"]], "showpublicmodels() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicModels"]], "showpublicpipelines() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicPipelines"]], "showuncategorizedresources() (resourcedownloader static method)": [[166, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showUnCategorizedResources"]], "sparknlp.pretrained.resource_downloader": [[166, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[167, "module-sparknlp.pretrained.utils"]], "conll (class in sparknlp.training.conll)": [[168, "sparknlp.training.conll.CoNLL"]], "readdataset() (conll method)": [[168, "sparknlp.training.conll.CoNLL.readDataset"]], "sparknlp.training.conll": [[168, "module-sparknlp.training.conll"]], "conllu (class in sparknlp.training.conllu)": [[169, "sparknlp.training.conllu.CoNLLU"]], "readdataset() (conllu method)": [[169, "sparknlp.training.conllu.CoNLLU.readDataset"]], "sparknlp.training.conllu": [[169, "module-sparknlp.training.conllu"]], "sparknlp.training": [[170, "module-sparknlp.training"]], "pos (class in sparknlp.training.pos)": [[171, "sparknlp.training.pos.POS"]], "readdataset() (pos method)": [[171, "sparknlp.training.pos.POS.readDataset"]], "sparknlp.training.pos": [[171, "module-sparknlp.training.pos"]], "pubtator (class in sparknlp.training.pub_tator)": [[172, "sparknlp.training.pub_tator.PubTator"]], "readdataset() (pubtator method)": [[172, "sparknlp.training.pub_tator.PubTator.readDataset"]], "sparknlp.training.pub_tator": [[172, "module-sparknlp.training.pub_tator"]], "spacytoannotation (class in sparknlp.training.spacy_to_annotation)": [[173, "sparknlp.training.spacy_to_annotation.SpacyToAnnotation"]], "sparknlp.training.spacy_to_annotation": [[173, "module-sparknlp.training.spacy_to_annotation"]], "sparknlp.training.tfgraphs": [[174, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[175, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[176, "module-sparknlp.util"]]}})