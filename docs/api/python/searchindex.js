Search.setIndex({"docnames": ["_templates/_autoapi/base/base", "_templates/_autoapi/index", "_templates/_autoapi/python/attribute", "_templates/_autoapi/python/class", "_templates/_autoapi/python/data", "_templates/_autoapi/python/exception", "_templates/_autoapi/python/function", "_templates/_autoapi/python/method", "_templates/_autoapi/python/module", "_templates/_autoapi/python/package", "getting_started/index", "index", "reference/autosummary/python/sparknlp/annotation/index", "reference/autosummary/python/sparknlp/annotation_audio/index", "reference/autosummary/python/sparknlp/annotation_image/index", "reference/autosummary/python/sparknlp/annotator/audio/index", "reference/autosummary/python/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/python/sparknlp/annotator/chunker/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/python/sparknlp/annotator/coref/index", "reference/autosummary/python/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/python/sparknlp/annotator/cv/index", "reference/autosummary/python/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/python/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/python/sparknlp/annotator/dependency/index", "reference/autosummary/python/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/python/sparknlp/annotator/document_normalizer/index", "reference/autosummary/python/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/python/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/python/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/python/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/python/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/python/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/python/sparknlp/annotator/er/index", "reference/autosummary/python/sparknlp/annotator/graph_extraction/index", "reference/autosummary/python/sparknlp/annotator/index", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/python/sparknlp/annotator/ld_dl/index", "reference/autosummary/python/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/python/sparknlp/annotator/lemmatizer/index", "reference/autosummary/python/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/python/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/python/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/python/sparknlp/annotator/ner/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/python/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/python/sparknlp/annotator/normalizer/index", "reference/autosummary/python/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/python/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/python/sparknlp/annotator/param/index", "reference/autosummary/python/sparknlp/annotator/pos/index", "reference/autosummary/python/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/python/sparknlp/annotator/sentence/index", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/python/sparknlp/annotator/sentiment/index", "reference/autosummary/python/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/python/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/python/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/python/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/python/sparknlp/annotator/spell_check/index", "reference/autosummary/python/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/python/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/python/sparknlp/annotator/stemmer/index", "reference/autosummary/python/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/python/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/python/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/python/sparknlp/annotator/token/index", "reference/autosummary/python/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/python/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/python/sparknlp/annotator/token/token2_chunk/index", "reference/autosummary/python/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/python/sparknlp/annotator/ws/index", "reference/autosummary/python/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/python/sparknlp/base/audio_assembler/index", "reference/autosummary/python/sparknlp/base/chunk2_doc/index", "reference/autosummary/python/sparknlp/base/doc2_chunk/index", "reference/autosummary/python/sparknlp/base/document_assembler/index", "reference/autosummary/python/sparknlp/base/embeddings_finisher/index", "reference/autosummary/python/sparknlp/base/finisher/index", "reference/autosummary/python/sparknlp/base/graph_finisher/index", "reference/autosummary/python/sparknlp/base/has_recursive_fit/index", "reference/autosummary/python/sparknlp/base/has_recursive_transform/index", "reference/autosummary/python/sparknlp/base/image_assembler/index", "reference/autosummary/python/sparknlp/base/index", "reference/autosummary/python/sparknlp/base/light_pipeline/index", "reference/autosummary/python/sparknlp/base/multi_document_assembler/index", "reference/autosummary/python/sparknlp/base/recursive_pipeline/index", "reference/autosummary/python/sparknlp/base/table_assembler/index", "reference/autosummary/python/sparknlp/base/token_assembler/index", "reference/autosummary/python/sparknlp/common/annotator_approach/index", "reference/autosummary/python/sparknlp/common/annotator_model/index", "reference/autosummary/python/sparknlp/common/annotator_properties/index", "reference/autosummary/python/sparknlp/common/coverage_result/index", "reference/autosummary/python/sparknlp/common/index", "reference/autosummary/python/sparknlp/common/properties/index", "reference/autosummary/python/sparknlp/common/read_as/index", "reference/autosummary/python/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/python/sparknlp/common/storage/index", "reference/autosummary/python/sparknlp/common/utils/index", "reference/autosummary/python/sparknlp/functions/index", "reference/autosummary/python/sparknlp/index", "reference/autosummary/python/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/python/sparknlp/internal/annotator_transformer/index", "reference/autosummary/python/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/python/sparknlp/internal/index", "reference/autosummary/python/sparknlp/internal/params_getters_setters/index", "reference/autosummary/python/sparknlp/internal/recursive/index", "reference/autosummary/python/sparknlp/logging/comet/index", "reference/autosummary/python/sparknlp/logging/index", "reference/autosummary/python/sparknlp/pretrained/index", "reference/autosummary/python/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/python/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/python/sparknlp/pretrained/utils/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/graph_builders/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/create_graph/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/dataset_encoder/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model_saver/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/sentence_grouper/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/core_rnn_cell/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/fused_rnn_cell/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/gru_ops/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/lstm_ops/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn_cell/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/graph_builders/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/create_graph/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/dataset_encoder/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model_saver/index", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/sentence_grouper/index", "reference/autosummary/python/sparknlp/training/conll/index", "reference/autosummary/python/sparknlp/training/conllu/index", "reference/autosummary/python/sparknlp/training/index", "reference/autosummary/python/sparknlp/training/pos/index", "reference/autosummary/python/sparknlp/training/pub_tator/index", "reference/autosummary/python/sparknlp/training/tfgraphs/index", "reference/autosummary/python/sparknlp/upload_to_hub/index", "reference/autosummary/python/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["_templates/_autoapi/base/base.rst", "_templates/_autoapi/index.rst", "_templates/_autoapi/python/attribute.rst", "_templates/_autoapi/python/class.rst", "_templates/_autoapi/python/data.rst", "_templates/_autoapi/python/exception.rst", "_templates/_autoapi/python/function.rst", "_templates/_autoapi/python/method.rst", "_templates/_autoapi/python/module.rst", "_templates/_autoapi/python/package.rst", "getting_started/index.rst", "index.rst", "reference/autosummary/python/sparknlp/annotation/index.rst", "reference/autosummary/python/sparknlp/annotation_audio/index.rst", "reference/autosummary/python/sparknlp/annotation_image/index.rst", "reference/autosummary/python/sparknlp/annotator/audio/index.rst", "reference/autosummary/python/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/python/sparknlp/annotator/chunker/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/coref/index.rst", "reference/autosummary/python/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/python/sparknlp/annotator/cv/index.rst", "reference/autosummary/python/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/python/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/python/sparknlp/annotator/dependency/index.rst", "reference/autosummary/python/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/python/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/python/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/python/sparknlp/annotator/er/index.rst", "reference/autosummary/python/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/python/sparknlp/annotator/index.rst", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/python/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/python/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/python/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/python/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/python/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/python/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/python/sparknlp/annotator/param/index.rst", "reference/autosummary/python/sparknlp/annotator/pos/index.rst", "reference/autosummary/python/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/python/sparknlp/annotator/sentence/index.rst", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/python/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/python/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/python/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/python/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/python/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/python/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/python/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/python/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/python/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/python/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/token/index.rst", "reference/autosummary/python/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/token/token2_chunk/index.rst", "reference/autosummary/python/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/python/sparknlp/annotator/ws/index.rst", "reference/autosummary/python/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/python/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/python/sparknlp/base/chunk2_doc/index.rst", "reference/autosummary/python/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/python/sparknlp/base/document_assembler/index.rst", "reference/autosummary/python/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/python/sparknlp/base/finisher/index.rst", "reference/autosummary/python/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/python/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/python/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/python/sparknlp/base/image_assembler/index.rst", "reference/autosummary/python/sparknlp/base/index.rst", "reference/autosummary/python/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/python/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/python/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/python/sparknlp/base/table_assembler/index.rst", "reference/autosummary/python/sparknlp/base/token_assembler/index.rst", "reference/autosummary/python/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/python/sparknlp/common/annotator_model/index.rst", "reference/autosummary/python/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/python/sparknlp/common/coverage_result/index.rst", "reference/autosummary/python/sparknlp/common/index.rst", "reference/autosummary/python/sparknlp/common/properties/index.rst", "reference/autosummary/python/sparknlp/common/read_as/index.rst", "reference/autosummary/python/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/python/sparknlp/common/storage/index.rst", "reference/autosummary/python/sparknlp/common/utils/index.rst", "reference/autosummary/python/sparknlp/functions/index.rst", "reference/autosummary/python/sparknlp/index.rst", "reference/autosummary/python/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/python/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/python/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/python/sparknlp/internal/index.rst", "reference/autosummary/python/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/python/sparknlp/internal/recursive/index.rst", "reference/autosummary/python/sparknlp/logging/comet/index.rst", "reference/autosummary/python/sparknlp/logging/index.rst", "reference/autosummary/python/sparknlp/pretrained/index.rst", "reference/autosummary/python/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/python/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/python/sparknlp/pretrained/utils/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/graph_builders/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/create_graph/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/dataset_encoder/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/ner_model_saver/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/ner_dl/sentence_grouper/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/core_rnn_cell/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/fused_rnn_cell/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/gru_ops/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/lstm_ops/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders/tf2contrib/rnn_cell/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/graph_builders/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/create_graph/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/dataset_encoder/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/ner_model_saver/index.rst", "reference/autosummary/python/sparknlp/training/_tf_graph_builders_1x/ner_dl/sentence_grouper/index.rst", "reference/autosummary/python/sparknlp/training/conll/index.rst", "reference/autosummary/python/sparknlp/training/conllu/index.rst", "reference/autosummary/python/sparknlp/training/index.rst", "reference/autosummary/python/sparknlp/training/pos/index.rst", "reference/autosummary/python/sparknlp/training/pub_tator/index.rst", "reference/autosummary/python/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/python/sparknlp/upload_to_hub/index.rst", "reference/autosummary/python/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["&lt;no title&gt;", "API Reference", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.create_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.rnn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.graph_builders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">python.sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210], "thi": [1, 10, 11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 83, 84, 85, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 123, 124, 125, 127, 128, 131, 132, 134, 137, 139, 140, 141, 142, 143, 145, 146, 149, 155, 156, 160, 161, 162, 165, 168, 176, 177, 178, 179, 180, 181, 182, 183, 194, 199, 200, 203, 204, 205, 207, 208, 209], "page": [1, 11, 54, 109, 165, 199, 207, 209], "list": [1, 3, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 80, 82, 85, 92, 93, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 118, 122, 125, 132, 133, 139, 140, 154, 161, 162, 165, 180, 181, 199, 204], "an": [1, 12, 16, 17, 25, 36, 40, 41, 50, 51, 54, 58, 60, 63, 65, 74, 75, 80, 82, 84, 85, 87, 89, 90, 94, 95, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 120, 125, 127, 130, 131, 132, 133, 134, 139, 140, 143, 146, 149, 153, 154, 156, 160, 161, 162, 176, 177, 180, 181, 182, 191, 192, 194, 195, 199, 201, 203, 204, 205, 207, 208], "overview": [1, 199, 207], "all": [1, 8, 10, 12, 13, 14, 19, 22, 27, 30, 34, 38, 41, 43, 45, 54, 55, 56, 57, 58, 68, 71, 74, 75, 78, 82, 85, 95, 97, 109, 112, 113, 118, 123, 132, 134, 162, 168, 179, 182, 183, 199, 204, 209], "spark": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 142, 143, 148, 150, 154, 155, 157, 158, 159, 162, 165, 168, 183, 191, 192, 194, 195, 199, 201, 202, 203, 204, 206, 207, 208, 210], "nlp": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 129, 130, 131, 132, 133, 137, 138, 139, 140, 141, 142, 143, 148, 155, 159, 162, 165, 168, 183, 191, 192, 194, 195, 199, 201, 202, 203, 204, 205, 206, 207, 208, 210], "modul": [1, 8, 9, 11, 32, 52, 64, 76, 78, 79, 81, 86, 91, 100, 101, 103, 106, 110, 114, 121, 126, 138, 148, 159, 164, 179, 193], "class": [1, 3, 5, 8, 78, 148, 152, 159, 166, 193, 199, 200, 208, 210], "function": [1, 6, 8, 11, 63, 71, 112, 132, 179, 199, 207], "method": [1, 3, 7, 55, 61, 62, 70, 74, 80, 168, 180, 183, 199], "extend": [2, 5, 9, 16, 17, 25, 36, 40, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 68, 69, 71, 72, 74, 80, 82, 83, 85, 87, 88, 89, 90, 94, 95, 97, 99, 102, 104, 105, 107, 108, 111, 112, 113, 115, 117, 118, 122, 125, 127, 129, 130, 131, 132, 133, 140, 143, 165], "python": [2, 5, 9, 11], "data": [2, 8, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 137, 139, 140, 141, 142, 143, 154, 162, 165, 180, 181, 182, 191, 192, 193, 194, 195, 201, 203, 204, 208, 209, 210], "rst": [2, 5, 8, 9], "obj": [3, 4, 6, 7, 8, 192], "displai": [3, 4, 6, 7, 8, 99, 109, 162, 200], "py": [3, 4, 6, 7, 144, 145, 151, 157, 161], "type": [3, 4, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 154, 156, 165, 180, 181, 182, 194, 203, 204, 207], "short_nam": [3, 6, 7, 8], "arg": [3, 6, 7, 141, 158, 180, 181, 182], "endif": [3, 4, 6, 7, 8], "return_annot": [3, 6, 7], "overload": [3, 6, 7], "length": [3, 7, 8, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 74, 90, 97, 104, 105, 109, 111, 112, 113, 123, 125, 180, 181], "endfor": [3, 6, 7, 8], "base": [3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 144, 145, 146, 148, 151, 155, 157, 161, 162, 168, 178, 180, 182, 183, 200, 204, 205, 208], "show": [3, 4, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 154, 191, 192, 194, 195, 200, 203, 204, 205, 209], "inherit": [3, 145, 161], "autoapi_opt": [3, 8], "link_obj": 3, "loop": [3, 177], "last": [3, 12, 85, 87, 120, 208], "diagram": 3, "object": [3, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 117, 118, 127, 150, 157, 158, 162, 177, 203, 204], "autoapi": [3, 8], "full_nam": 3, "part": [3, 17, 58, 80, 83, 101, 102, 117, 127, 130, 182, 194, 210], "privat": [3, 66, 67, 156], "member": [3, 102, 165], "docstr": [3, 4, 6, 7, 8], "indent": [3, 4, 6, 7, 8], "set": [3, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 145, 146, 149, 153, 155, 160, 161, 162, 182, 191, 200, 204, 207, 208], "visible_class": [3, 8], "selectattr": [3, 8], "els": [3, 4, 6, 7, 8, 107], "rejectattr": [3, 8], "klass": [3, 8], "render": [3, 8], "visible_attribut": [3, 8], "attribut": [3, 8, 162], "visible_method": 3, "name": [4, 8, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 89, 91, 92, 94, 95, 98, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 146, 154, 160, 162, 165, 168, 178, 180, 182, 183, 191, 194, 200, 204], "valu": [4, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 80, 82, 83, 85, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 102, 104, 105, 108, 109, 111, 112, 113, 115, 118, 119, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 149, 150, 160, 162, 180, 181, 200, 210], "i": [4, 6, 7, 8, 10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 153, 154, 155, 161, 162, 177, 178, 179, 180, 181, 182, 191, 194, 195, 200, 201, 203, 204, 205, 207, 208, 209, 210], "none": [4, 6, 7, 8, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 140, 142, 145, 161, 162, 165, 176, 178, 180, 181, 182, 205], "annot": [4, 11, 13, 14, 128, 129, 130, 131, 132, 133, 134, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 153, 154, 155, 156, 157, 159, 161, 162, 165, 167, 168, 183, 194, 200, 201, 206, 207, 208, 209, 210], "string": [4, 12, 25, 36, 40, 48, 51, 54, 75, 90, 96, 97, 105, 112, 116, 118, 122, 130, 131, 133, 137, 139, 140, 182, 208], "splitlin": 4, "count": [4, 41, 113], "multilin": 4, "width": [4, 14, 137], "8": [4, 10, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 51, 53, 54, 55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74, 85, 90, 95, 96, 109, 113, 124, 182, 191], "truncat": [4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 71, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 133, 134, 140, 142, 143, 154, 194, 203, 204, 205], "100": [4, 25, 36, 41, 50, 62, 70, 72, 80, 105, 142], "sphinx_vers": [6, 7], "properti": [6, 7, 55, 135, 136, 146, 148, 155, 180, 181], "method_typ": 7, "orphan": 8, "nest": [8, 181], "pars": [8, 17, 51, 52, 53, 58, 75, 83, 85, 87, 113, 115, 116, 139, 142, 165, 194], "block": [8, 178, 180], "subpackag": 8, "visible_subpackag": 8, "toctre": 8, "titlesonli": 8, "maxdepth": 8, "index": [8, 12, 80, 84, 123, 155, 191], "endblock": 8, "submodul": 8, "visible_submodul": 8, "content": [8, 203, 209], "visible_children": 8, "children": 8, "elif": 8, "equalto": 8, "packag": [8, 10, 55, 60, 162, 201, 202], "import": [8, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 137, 139, 140, 141, 142, 143, 154, 162, 165, 168, 183, 191, 192, 194, 195, 200, 203, 204, 207, 208, 209, 210], "titl": [8, 195, 210], "visible_funct": 8, "summari": [8, 109, 112], "scope": [8, 108, 180, 181, 182], "id": [8, 36, 54, 72, 75, 109, 111, 112, 129, 130, 131, 133, 140, 143, 162, 182], "obj_item": 8, "can": [10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 88, 93, 94, 95, 96, 102, 104, 105, 107, 109, 111, 112, 113, 115, 116, 118, 124, 127, 131, 132, 140, 141, 142, 153, 162, 165, 181, 191, 192, 194, 200, 202, 204, 205, 207, 208, 209, 210], "quick": [10, 200, 205], "refer": [10, 11, 48, 50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 80, 88, 104, 105, 108, 109, 111, 112, 113, 115, 116, 130, 131, 140, 204, 206, 207], "how": [10, 11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 53, 55, 56, 58, 59, 60, 61, 63, 65, 66, 68, 72, 74, 75, 77, 82, 83, 84, 88, 89, 93, 94, 97, 99, 104, 107, 115, 116, 123, 125, 127, 131, 134, 140, 150, 153, 155, 191, 192, 200, 204, 209], "up": [10, 11, 25, 36, 62, 65, 68, 70, 80, 109, 112, 155, 200, 204, 207, 208], "your": [10, 11, 25, 36, 40, 51, 61, 62, 66, 68, 70, 83, 84, 88, 89, 94, 95, 97, 102, 107, 108, 113, 115, 120, 122, 127, 132, 176, 202, 204, 207, 208, 210], "environ": [10, 201], "pypi": 10, "pip": 10, "anaconda": 10, "c": [10, 58, 62, 70, 80, 111, 178, 182], "johnsnowlab": [10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 142, 155], "load": [10, 11, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 80, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 137, 165, 204, 207], "shell": 10, "com": [10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 142, 155, 179, 182], "nlp_2": [10, 155], "12": [10, 55, 72, 73, 74, 80, 85, 87, 93, 102, 113, 124, 139, 154, 155, 165, 168, 183, 194, 203], "pyspark": [10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 137, 139, 140, 142, 143, 154, 155, 158, 161, 162, 165, 191, 192, 194, 195, 204, 205], "submit": [10, 162, 182, 200], "extern": [10, 80, 83, 88, 89, 95, 119, 141, 153, 191, 192, 194, 195], "jar": [10, 155], "after": [10, 51, 53, 62, 66, 67, 70, 85, 87, 93, 122, 143, 162, 182, 203, 204], "compil": 10, "build": [10, 60, 61, 66, 67, 77, 80, 84, 109, 162, 168, 178, 182, 183, 200], "sbt": 10, "assembli": 10, "built": [10, 25, 36, 140, 182], "top": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 55, 80, 109, 112, 140], "apach": [10, 140, 155], "x": [10, 36, 154, 178, 179, 182, 191, 210], "For": [10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 129, 130, 131, 132, 133, 140, 143, 162, 165, 177, 182, 195, 200, 201, 203, 204, 205, 206, 207, 208], "you": [10, 51, 53, 59, 61, 66, 68, 77, 85, 96, 132, 134, 139, 162, 168, 183, 194, 200, 202, 204, 205, 208, 209, 210], "need": [10, 16, 17, 51, 53, 61, 66, 71, 75, 77, 80, 85, 88, 94, 95, 97, 102, 105, 108, 109, 113, 115, 116, 123, 125, 128, 137, 139, 162, 176, 181, 182, 191, 192, 194, 200, 202, 204, 205, 208, 210], "java": [10, 82, 144, 145, 151, 157, 158, 161], "ar": [10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 53, 55, 56, 58, 60, 61, 63, 65, 66, 69, 71, 72, 73, 74, 75, 77, 80, 82, 83, 85, 88, 90, 93, 95, 96, 97, 102, 104, 105, 108, 109, 111, 112, 113, 117, 119, 127, 129, 132, 139, 141, 142, 150, 154, 162, 177, 178, 179, 181, 182, 195, 200, 201, 202, 203, 204, 205, 208, 209, 210], "6": [10, 25, 40, 56, 57, 60, 63, 80, 84, 89, 90, 96, 102, 115, 124, 168, 182, 183, 192, 204], "7": [10, 40, 56, 57, 60, 85, 87, 102, 109, 129, 133, 194, 203], "It": [10, 25, 36, 40, 41, 54, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 75, 80, 90, 108, 111, 113, 115, 116, 122, 133, 139, 180, 182, 203, 208], "recommend": [10, 63, 74, 107, 108, 109, 111, 112], "have": [10, 25, 36, 40, 55, 58, 61, 66, 67, 71, 80, 90, 94, 95, 96, 102, 104, 105, 109, 116, 124, 143, 157, 181, 182, 204, 205, 208], "basic": [10, 80, 104, 180, 182, 203], "knowledg": [10, 61, 80, 134], "framework": [10, 16, 111, 112], "work": [10, 61, 65, 82, 112, 120, 203, 205, 209], "befor": [10, 54, 71, 85, 87, 112, 115, 123, 145, 161, 182, 200], "pleas": [10, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 56, 57, 58, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 82, 83, 84, 85, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 127, 131, 140, 141, 201, 202, 206, 209], "document": [10, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 139, 140, 142, 143, 162, 165, 191, 192, 194, 200, 204, 205, 207, 208, 209], "first": [10, 12, 60, 62, 63, 70, 72, 73, 80, 88, 94, 95, 96, 104, 112, 113, 118, 123, 132, 143, 181, 182, 200, 204, 205, 209], "let": [10, 61, 122, 204], "": [10, 11, 18, 21, 26, 29, 33, 37, 42, 54, 55, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 75, 80, 88, 95, 97, 108, 109, 111, 112, 113, 115, 116, 122, 123, 125, 128, 133, 139, 144, 145, 151, 154, 157, 161, 162, 182, 200, 203, 204, 205, 208], "make": [10, 54, 58, 65, 72, 73, 80, 105, 108, 115, 206, 210], "sure": [10, 108], "version": [10, 54, 61, 98, 99, 119, 146, 149, 155, 160, 161, 165, 168, 204], "oracl": 10, "openjdk": 10, "0_292": 10, "creat": [10, 12, 13, 14, 36, 56, 57, 62, 66, 70, 71, 77, 102, 120, 127, 139, 141, 154, 168, 180, 181, 183, 191, 192, 194, 195, 204, 205, 208, 210], "new": [10, 12, 13, 14, 40, 48, 55, 56, 57, 60, 63, 65, 71, 74, 96, 98, 99, 109, 112, 113, 119, 129, 133, 146, 149, 160, 161, 182, 203, 204], "manag": [10, 80, 201], "depend": [10, 12, 48, 58, 68, 74, 75, 77, 78, 80, 82, 95, 111, 113, 155, 181, 182], "Then": [10, 25, 36, 94, 95, 143, 162, 204], "we": [10, 16, 25, 36, 50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 80, 94, 95, 97, 105, 109, 111, 112, 113, 115, 125, 139, 154, 180, 182, 200, 203, 204, 205, 208, 209, 210], "sparknlp": [10, 200, 203, 204, 205, 206, 208, 209, 210], "n": [10, 73, 80, 90, 93, 94, 95, 104, 105, 109, 112, 122, 139, 142, 154, 165, 182], "y": [10, 36, 182], "activ": [10, 19, 22, 30, 34, 38, 43, 45, 80, 176, 182], "jupyt": [10, 162, 200], "now": [10, 58, 105, 139, 205], "should": [10, 12, 13, 14, 17, 25, 36, 40, 62, 70, 72, 80, 82, 89, 90, 94, 95, 99, 104, 105, 111, 113, 123, 139, 145, 146, 157, 161, 165, 180, 182, 191, 192], "readi": [10, 25, 165, 204], "notebook": [10, 162, 200], "run": [10, 61, 80, 162, 176, 180, 181, 182, 201, 209], "also": [10, 50, 54, 55, 63, 65, 71, 72, 73, 75, 77, 80, 85, 88, 93, 94, 98, 99, 105, 108, 118, 139, 142, 146, 149, 160, 182, 200, 204, 205, 206, 207], "python3": 10, "sourc": [10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 165, 168, 176, 177, 178, 179, 180, 181, 182, 183, 191, 192, 194, 195, 201], "bin": 10, "A": [10, 16, 40, 48, 55, 66, 67, 71, 75, 80, 83, 84, 88, 89, 90, 97, 107, 109, 111, 112, 115, 116, 123, 125, 162, 177, 180, 181, 182, 194, 202, 204, 210], "retriev": [10, 71, 83, 115, 116, 117, 162, 165, 200, 204, 205], "If": [10, 19, 22, 25, 27, 30, 34, 38, 43, 45, 68, 71, 75, 82, 85, 87, 93, 94, 95, 97, 99, 104, 105, 109, 112, 113, 119, 155, 161, 162, 168, 180, 181, 182, 183, 200, 202, 204], "manual": [10, 203], "sparksess": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 84, 109, 111, 112, 155, 191, 192, 194, 195], "becaus": [10, 107, 145, 161, 181], "other": [10, 36, 58, 68, 69, 77, 80, 97, 107, 109, 112, 120, 122, 129, 132, 133, 140, 204], "configur": [10, 68, 125, 155, 168, 183], "includ": [10, 54, 56, 57, 62, 63, 70, 72, 73, 74, 77, 80, 85, 93, 94, 95, 109, 112, 113, 133, 162, 179, 195, 201, 203, 204, 205, 210], "them": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 56, 58, 60, 61, 65, 66, 72, 74, 75, 77, 80, 85, 88, 105, 113, 118, 127, 141, 143, 204, 205], "builder": [10, 119, 155], "appnam": [10, 155], "master": [10, 155], "local": [10, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 80, 109, 111, 112, 118, 139, 155, 165, 208], "config": [10, 155, 201], "driver": [10, 155], "memori": [10, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 55, 63, 71, 155, 180, 181, 182], "16g": [10, 155], "maxresults": [10, 155], "kryoseri": [10, 155], "buffer": [10, 57, 71, 155], "max": [10, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74, 80, 116, 155], "2000m": [10, 155], "getorcr": [10, 155], "main": [11, 75, 125, 203, 207, 210], "github": [11, 16, 50, 55, 56, 57, 58, 60, 66, 74, 108, 109, 111, 112, 165, 179, 182], "issu": 11, "workshop": [11, 17, 25, 36, 40, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 68, 69, 71, 72, 74, 80, 82, 83, 85, 87, 88, 89, 90, 94, 95, 97, 102, 104, 105, 107, 108, 111, 112, 113, 115, 117, 118, 122, 125, 127, 129, 130, 131, 132, 133, 140, 143, 162, 182, 200, 207], "model": [11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 120, 122, 125, 127, 145, 155, 161, 162, 165, 168, 181, 182, 183, 200, 201, 203, 207, 209, 210], "hub": [11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 82, 83, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 118, 127], "welcom": [11, 16], "contain": [11, 12, 13, 14, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 156, 157, 158, 160, 161, 162, 163, 165, 166, 167, 180, 181, 182, 191, 192, 194, 195, 198, 200, 203, 204], "inform": [11, 51, 53, 71, 72, 80, 85, 93, 113, 131, 140, 181, 182, 195, 200, 201, 202, 203, 204, 210], "us": [11, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 99, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 118, 119, 123, 124, 125, 127, 129, 130, 131, 132, 133, 139, 140, 141, 142, 143, 154, 155, 162, 165, 176, 177, 178, 180, 181, 182, 191, 192, 194, 195, 201, 202, 203, 204, 205, 207], "librari": [11, 50, 82, 130, 131, 132, 140, 143, 209], "exampl": [11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 141, 142, 143, 154, 162, 165, 168, 177, 182, 183, 191, 192, 194, 195, 200, 203, 204, 205, 207, 208, 209, 210], "get": [11, 25, 36, 80, 92, 102, 113, 119, 125, 127, 139, 146, 149, 160, 200, 204, 209, 210], "start": [11, 18, 21, 26, 29, 33, 37, 42, 65, 77, 80, 94, 95, 105, 130, 155, 162, 176, 180, 200, 203, 205, 208, 209], "cheat": 11, "sheet": [11, 54], "requir": [11, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 53, 55, 57, 60, 63, 69, 72, 73, 80, 95, 97, 108, 113, 124, 127, 130, 132, 143, 180, 181, 182, 203, 204, 205], "instal": [11, 162, 202], "session": [11, 155, 191, 192, 194, 195], "from": [11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 98, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 141, 142, 143, 145, 154, 155, 158, 161, 162, 165, 168, 176, 178, 180, 181, 182, 183, 191, 192, 194, 195, 200, 203, 204, 205, 208, 209, 210], "user": [11, 93, 94, 125, 141, 155, 162, 200], "guid": [11, 201], "own": [11, 25, 36, 40, 51, 62, 70, 83, 84, 88, 89, 94, 95, 97, 102, 107, 108, 113, 115, 120, 122, 127, 182, 207, 208, 210], "pipelin": [11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 137, 139, 140, 141, 142, 143, 155, 161, 162, 164, 165, 167, 201, 203, 204, 207], "pretrain": [11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 82, 83, 84, 85, 88, 89, 94, 95, 96, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 129, 132, 133, 139, 154, 155, 162, 200, 203, 207], "dataset": [11, 25, 36, 40, 51, 53, 58, 62, 65, 66, 67, 70, 71, 80, 82, 94, 95, 99, 105, 109, 113, 127, 161, 165, 191, 192, 194, 195, 207], "train": [11, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 69, 70, 72, 73, 74, 80, 82, 83, 84, 88, 89, 92, 94, 95, 97, 98, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 120, 122, 127, 130, 139, 155, 162, 165, 200, 204, 205, 207, 208], "light": [11, 61, 74, 80, 139, 207, 209], "helper": [11, 102, 127, 134, 154, 180, 181, 194, 195, 207, 210], "third": [11, 104, 118, 163], "parti": [11, 163], "project": [11, 80, 111, 162, 176, 182, 201], "log": [11, 25, 36, 40, 95, 99, 105, 109, 155], "api": [11, 200, 204, 207], "format": [12, 13, 14, 50, 51, 53, 75, 77, 83, 84, 85, 87, 88, 89, 94, 95, 97, 99, 107, 112, 115, 116, 125, 128, 131, 133, 134, 137, 140, 142, 181, 191, 192, 194, 195, 201, 210], "annotator_typ": [12, 13, 14], "begin": [12, 48, 93, 109, 122, 125, 130, 131, 140, 154, 180, 181, 182, 203], "end": [12, 18, 21, 26, 29, 33, 37, 42, 48, 95, 105, 122, 125, 131, 140, 154, 162, 181, 191, 200, 203, 205], "result": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 154, 155, 162, 165, 182, 191, 192, 200, 201, 203, 204, 205, 208, 209], "metadata": [12, 13, 14, 41, 48, 80, 89, 94, 95, 102, 131, 133, 137, 139, 140, 154, 162, 203, 205], "embed": [12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 77, 78, 94, 95, 96, 131, 132, 133, 139, 140, 149, 154, 155, 161, 165, 168, 176, 183, 203], "repres": [12, 13, 14, 51, 53, 55, 60, 74, 75, 77, 84, 89, 90, 125, 162, 165, 177, 182, 204], "output": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 154, 155, 162, 176, 180, 181, 182, 194, 200, 203, 204, 205], "detail": [12, 13, 14, 72, 73, 80, 109, 112, 182], "paramet": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 149, 153, 154, 155, 160, 161, 162, 165, 168, 181, 183, 191, 192, 194, 195], "str": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 153, 154, 155, 160, 162, 165, 168, 183, 191, 192, 194, 195], "The": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 123, 125, 127, 131, 133, 139, 140, 142, 154, 155, 162, 165, 168, 178, 179, 180, 181, 182, 183, 191, 192, 194, 195, 200, 203, 204, 205, 207, 208, 210], "possibl": [12, 13, 14, 59, 61, 72, 73, 75, 104, 113, 116, 131, 140, 150, 162, 200], "token": [12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 80, 83, 84, 89, 90, 92, 93, 94, 95, 96, 97, 102, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 127, 129, 130, 132, 139, 141, 143, 155, 165, 168, 183, 191, 195, 204, 208, 209], "wordpiec": 12, "word_embed": [12, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 68, 70, 72, 74, 78, 94, 95], "sentence_embed": [12, 25, 36, 40, 57, 62, 64, 67, 69, 73, 78, 162, 200, 204], "categori": [12, 19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 50, 162, 200, 204], "date": [12, 85, 87], "entiti": [12, 20, 23, 24, 28, 31, 35, 39, 44, 46, 48, 58, 75, 76, 77, 84, 89, 91, 92, 93, 94, 95, 96, 120, 124, 129, 133, 139, 165], "sentiment": [12, 25, 36, 40, 63, 74, 78, 112, 155, 204, 205], "po": [12, 17, 19, 22, 27, 30, 34, 38, 43, 45, 51, 53, 77, 78, 94, 95, 122, 127, 139, 154, 155, 165, 191, 193, 203, 207, 208, 209], "chunk": [12, 17, 18, 21, 26, 29, 33, 37, 42, 59, 62, 70, 75, 80, 84, 88, 89, 90, 93, 120, 124, 129, 130, 133, 154, 162, 195, 200, 210], "named_ent": [12, 20, 23, 24, 28, 31, 35, 39, 44, 46, 77, 93, 94, 95, 96, 139, 165], "negex": 12, "labeled_depend": [12, 53], "languag": [12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 80, 81, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 130, 140, 143, 204], "keyword": [12, 79, 80, 107, 182], "dummi": [12, 54], "int": [12, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 77, 80, 82, 85, 90, 92, 94, 95, 97, 98, 99, 102, 104, 105, 108, 109, 111, 112, 113, 116, 119, 123, 125, 127, 149, 155, 162, 182, 191], "charact": [12, 54, 63, 65, 75, 82, 90, 97, 104, 105, 113, 115, 116, 123, 125, 133], "under": [12, 61, 74, 80, 155], "dict": [12, 13, 14, 51, 53, 75, 83, 84, 88, 89, 94, 96, 97, 99, 107, 113, 115, 116, 125, 139, 153, 161, 162, 165, 168, 183], "associ": [12, 13, 14, 36, 69, 75, 88, 93, 162], "vector": [12, 36, 56, 57, 59, 60, 62, 63, 69, 70, 71, 132, 133, 140, 180, 181, 182, 203], "where": [12, 36, 60, 63, 75, 80, 83, 84, 88, 89, 90, 102, 105, 107, 109, 112, 115, 116, 127, 130, 168, 181, 182, 183, 194], "applic": [12, 50, 80, 162, 163, 200, 202], "copi": [12, 13, 14], "differ": [12, 13, 14, 51, 53, 63, 66, 67, 72, 74, 80, 85, 104, 105, 113, 125, 139, 162, 168, 178, 182, 183, 208], "return": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 80, 82, 83, 84, 89, 90, 92, 94, 95, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 117, 118, 122, 125, 127, 130, 139, 153, 154, 155, 156, 161, 165, 168, 180, 181, 182, 183, 191, 192, 194, 195], "newli": [12, 13, 14], "static": [12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 168, 182, 183, 204], "datatyp": [12, 154], "structtyp": 12, "schema": [12, 93, 162, 200], "look": [12, 95, 115, 203], "like": [12, 18, 21, 25, 26, 29, 33, 37, 42, 48, 54, 55, 59, 61, 65, 68, 74, 77, 80, 93, 105, 108, 109, 113, 125, 127, 162, 200, 202, 203], "struct": [12, 131, 137, 140], "containsnul": [12, 36, 128, 131, 137, 140], "true": [12, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 50, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 82, 84, 85, 87, 89, 95, 97, 104, 105, 113, 115, 123, 125, 128, 130, 131, 132, 133, 134, 137, 140, 142, 162, 168, 177, 181, 182, 183, 191, 192, 195, 200, 204, 205], "annotatortyp": [12, 59, 90, 130, 131, 137, 140, 203], "nullabl": [12, 36, 128, 131, 137, 140], "fals": [12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 139, 140, 142, 143, 154, 155, 162, 165, 177, 180, 181, 182, 191, 192, 194, 200, 203, 204, 205, 210], "integ": [12, 131, 137, 140], "map": [12, 17, 36, 71, 75, 98, 99, 102, 113, 131, 137, 140, 146, 149, 154, 160, 161, 182, 203], "kei": [12, 51, 53, 66, 67, 72, 73, 83, 131, 137, 139, 140, 162, 165, 200], "valuecontainsnul": [12, 131, 137, 140], "arrai": [12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 72, 73, 74, 82, 83, 90, 95, 98, 102, 104, 105, 109, 111, 112, 113, 120, 122, 127, 128, 130, 131, 132, 133, 134, 137, 139, 140, 154, 205, 208], "element": [12, 36, 90, 128, 131, 137, 140, 180, 181], "float": [12, 13, 16, 25, 36, 40, 82, 94, 95, 98, 99, 105, 109, 112, 113, 127, 128, 131, 132, 140], "sql": [12, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 84, 109, 111, 112, 139, 154, 161, 165, 191, 192, 194, 195], "arraytyp": [12, 130, 154], "fromrow": 12, "row": [12, 41, 71, 104, 105, 108, 131, 140, 142, 154, 191], "column": [12, 25, 36, 40, 54, 71, 83, 92, 94, 95, 98, 102, 108, 119, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 143, 146, 154, 165, 182, 191, 194, 204], "torow": 12, "transform": [12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 139, 140, 142, 143, 154, 157, 161, 162, 165, 200, 203, 204, 205, 208, 209, 210], "annotationaudio": 13, "audio": [13, 128, 162], "alreadi": [13, 77, 80, 94, 95, 96, 124, 125, 139, 165, 182, 208], "process": [13, 16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 70, 72, 73, 74, 77, 80, 82, 93, 94, 95, 105, 109, 112, 128, 129, 130, 131, 132, 133, 137, 140, 141, 143, 162, 182, 200, 203, 204, 205, 206], "file": [13, 16, 51, 53, 54, 69, 71, 75, 83, 84, 88, 89, 94, 95, 97, 105, 107, 113, 115, 116, 119, 125, 128, 142, 150, 155, 162, 168, 179, 183, 191, 192, 194, 195, 200, 210], "byte": [13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 98, 109, 111, 112, 113, 162], "annotationimag": [14, 139], "origin": [14, 55, 62, 65, 66, 70, 105, 137, 179, 182], "height": [14, 137], "nchannel": [14, 137], "mode": [14, 115, 131, 137, 140, 162], "imag": [14, 50, 137, 139], "uri": 14, "pixel": 14, "number": [14, 25, 36, 40, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 90, 92, 94, 95, 98, 102, 104, 105, 109, 112, 113, 119, 127, 180, 181, 182, 191, 192], "color": 14, "channel": [14, 113], "opencv": 14, "wav2vec2_for_ctc": 15, "concern": [16, 19, 50, 55], "wav2vec2forctc": 16, "classnam": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 142, 144, 145, 151, 157], "java_model": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 82, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 122, 125, 127, 136, 142, 145, 161], "wav2vec2": 16, "head": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 55, 74, 93, 94, 95, 139, 154, 165], "connectionist": 16, "tempor": [16, 181], "classif": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 69, 108, 112, 204], "ctc": 16, "wa": [16, 19, 20, 22, 23, 25, 27, 28, 30, 31, 34, 35, 38, 39, 40, 43, 44, 45, 46, 54, 58, 60, 61, 65, 66, 67, 71, 72, 73, 80, 108, 109, 113, 165, 182, 204, 205], "propos": [16, 55, 58, 60, 61, 66, 67, 72, 73, 74], "wav2vec": 16, "self": [16, 55, 65, 111, 180, 182], "supervis": [16, 55, 63, 69, 80, 109], "learn": [16, 25, 36, 40, 55, 61, 62, 63, 66, 67, 69, 70, 72, 73, 74, 80, 94, 95, 98, 105, 109, 112, 113, 162, 182, 202], "speech": [16, 17, 58, 101, 102, 127, 194, 210], "represent": [16, 55, 56, 57, 61, 62, 63, 70, 71, 72, 73, 74, 93, 112, 140, 142, 153], "alexei": 16, "baevski": 16, "henri": 16, "zhou": 16, "abdelrahman": 16, "moham": 16, "michael": [16, 120], "auli": 16, "take": [16, 41, 58, 77, 89, 98, 99, 115, 118, 125, 141, 146, 149, 160, 181, 191, 203, 204, 208, 209], "transcrib": 16, "text": [16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 134, 140, 142, 143, 150, 153, 154, 162, 191, 192, 194, 195, 200, 203, 204, 205, 209, 210], "provid": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 82, 83, 84, 85, 87, 88, 89, 94, 95, 97, 98, 99, 102, 105, 107, 109, 111, 112, 113, 115, 116, 127, 139, 146, 149, 154, 156, 160, 165, 180, 181, 182, 205], "pre": [16, 50, 56, 57, 60, 61, 63, 69, 112, 129, 130, 131, 133, 140, 143, 192, 204], "note": [16, 25, 36, 40, 55, 61, 63, 66, 68, 71, 72, 74, 80, 95, 109, 111, 112, 139, 155, 176, 209], "current": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 73, 74, 80, 84, 85, 87, 105, 109, 111, 112, 119, 139, 142, 146, 155, 182, 203, 204, 205], "support": [16, 25, 36, 55, 65, 80, 95, 97, 105, 118, 142, 155, 201], "appl": [16, 57, 67, 73], "silicon": 16, "processor": 16, "m1": [16, 155], "due": [16, 19, 22, 27, 30, 34, 38, 43, 45, 55, 65], "instruct": 16, "xla": [16, 182], "companion": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 118, 127, 158], "speechtotext": 16, "setinputcol": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 146, 162, 168, 183, 200, 204, 205], "audio_assembl": [16, 138, 155], "setoutputcol": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 140, 142, 143, 146, 162, 168, 183, 200, 204, 205], "default": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 119, 122, 123, 125, 127, 130, 131, 132, 133, 134, 139, 140, 142, 153, 154, 155, 162, 165, 180, 181, 182, 191, 192, 194, 195, 204], "asr_wav2vec2_base_960h": 16, "avail": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 78, 80, 82, 83, 85, 88, 94, 95, 102, 105, 109, 111, 112, 113, 115, 116, 118, 127, 157, 165, 168, 179, 183, 200, 207], "see": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 125, 127, 129, 130, 131, 132, 133, 134, 140, 143, 162, 165, 182, 195, 200, 201, 202, 207, 209, 210], "To": [16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 55, 56, 58, 60, 61, 65, 66, 72, 74, 75, 80, 85, 102, 104, 109, 112, 127, 134, 139, 141, 162, 182, 200, 208], "which": [16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 70, 72, 74, 77, 80, 85, 87, 95, 97, 104, 105, 107, 109, 111, 112, 115, 123, 127, 132, 139, 154, 177, 181, 182, 191, 192, 204, 205], "compat": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 50, 55, 56, 58, 60, 61, 65, 66, 72, 74, 95, 132, 177, 180], "http": [16, 50, 55, 56, 57, 58, 60, 62, 63, 69, 70, 74, 108, 109, 112, 178, 179, 180, 181, 182, 201], "discuss": [16, 50, 58], "5669": [16, 50, 58], "more": [16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 54, 58, 61, 63, 68, 72, 73, 77, 80, 90, 93, 105, 109, 112, 115, 123, 125, 129, 130, 131, 132, 133, 140, 143, 162, 165, 176, 177, 180, 181, 195, 200, 201, 202, 204, 207, 210], "wav2vec2forctctestspec": 16, "input": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 137, 139, 140, 142, 143, 146, 154, 161, 165, 176, 177, 178, 180, 181, 182, 191, 192, 194, 195, 204, 205, 208, 210], "batchsiz": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 95, 111, 113], "size": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 70, 71, 72, 73, 74, 77, 80, 95, 98, 109, 111, 112, 113, 115, 180, 181, 182, 203, 208, 209], "each": [16, 25, 36, 40, 60, 62, 68, 70, 71, 75, 77, 80, 83, 84, 85, 88, 89, 90, 92, 94, 95, 97, 99, 102, 104, 105, 107, 113, 115, 116, 123, 125, 131, 140, 154, 161, 180, 181, 182, 194, 205], "batch": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 95, 98, 111, 113, 176, 181, 182], "ml": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 128, 130, 131, 132, 137, 139, 140, 141, 142, 143, 162, 200, 204, 208], "audioassembl": [16, 128], "audio_cont": [16, 128], "setstag": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 130, 132, 142, 143, 204, 205], "processedaudiofloat": 16, "createdatafram": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 140, 142, 143, 154, 162, 200, 203, 204, 205, 209], "rawfloat": 16, "todf": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 129, 130, 131, 132, 133, 137, 140, 142, 143, 154, 203, 204, 205, 209], "fit": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 130, 132, 139, 141, 142, 143, 161, 162, 181, 200, 204, 205, 208], "select": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 59, 61, 71, 77, 80, 82, 94, 95, 108, 109, 112, 113, 115, 116, 122, 127, 128, 131, 133, 134, 137, 140, 142, 143, 154, 162, 200, 205], "mister": 16, "quilter": 16, "THE": [16, 54], "apostl": 16, "OF": [16, 55], "midl": 16, "clase": 16, "AND": 16, "glad": 16, "TO": [16, 191, 210], "hi": [16, 105], "gospel": 16, "setconfigprotobyt": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 98, 109, 111, 112, 113], "b": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 84, 89, 93, 94, 95, 96, 98, 104, 109, 111, 112, 113, 139, 154, 165, 182, 191, 195, 210], "configproto": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 98, 109, 111, 112, 113], "tensorflow": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 80, 82, 95, 98, 109, 111, 112, 113, 168, 179, 181, 183], "serial": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 82, 95, 98, 109, 111, 112, 113, 155], "loadsavedmodel": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 109, 111, 112], "folder": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 95, 99, 105, 109, 111, 112, 116, 119, 191], "spark_sess": [16, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 109, 111, 112], "save": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 95, 99, 105, 109, 111, 112, 155, 162, 168, 183, 200, 204], "restor": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127], "lang": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 165], "en": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 74, 77, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 165, 192, 210], "remote_loc": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 165], "download": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 77, 82, 83, 84, 89, 94, 95, 96, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 155, 165, 203, 204, 207, 208], "option": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 80, 82, 83, 84, 88, 89, 94, 95, 97, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 128, 131, 135, 136, 139, 140, 153, 154, 155, 161, 162, 165, 181, 182, 191, 192, 194, 195, 204], "remot": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 165], "address": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127], "resourc": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 82, 83, 84, 88, 89, 94, 95, 97, 99, 102, 105, 107, 108, 109, 111, 112, 113, 115, 116, 118, 120, 125, 127, 141, 150, 153, 164, 191, 192, 194, 195, 204, 210], "Will": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 104, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127], "repositori": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 165, 201], "otherwis": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 82, 83, 84, 89, 94, 95, 102, 105, 108, 109, 111, 112, 113, 115, 116, 118, 125, 127, 130, 162, 182], "match": [17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 70, 72, 73, 74, 75, 84, 85, 86, 87, 88, 89, 97, 102, 104, 109, 125, 127, 130, 180, 181, 203], "pattern": [17, 54, 75, 85, 97, 115, 116, 123, 125, 182], "tag": [17, 25, 36, 40, 54, 58, 92, 93, 94, 95, 96, 101, 102, 127, 154, 162, 191, 194, 195, 210], "order": [17, 74, 75, 80, 115, 116, 139, 143, 154, 180, 182, 204, 205, 208, 210], "meaning": [17, 117], "phrase": [17, 58, 62, 70, 84, 89], "extract": [17, 18, 21, 26, 29, 33, 37, 42, 51, 59, 71, 75, 76, 77, 79, 80, 84, 85, 87, 89, 93, 94, 95, 96, 104, 105, 107, 113, 116, 120, 124, 129, 132, 133, 134, 139, 155, 162, 165, 200], "onto": [17, 154, 205], "sentenc": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 82, 83, 84, 85, 87, 88, 89, 90, 93, 94, 95, 96, 102, 108, 111, 113, 118, 120, 123, 124, 127, 129, 131, 133, 139, 140, 142, 143, 155, 165, 168, 183, 191, 192, 194, 195, 204, 208, 209], "regular": [17, 88, 94, 104, 182], "express": [17, 40, 48, 85, 88, 104], "wrap": [17, 144, 145, 151, 157, 161, 182], "angl": 17, "bracket": 17, "easili": [17, 63, 102, 132, 200], "distinguish": 17, "itself": [17, 80, 112, 141, 205], "form": [17, 25, 36, 40, 71, 75, 83, 84, 85, 88, 89, 105, 107, 115, 116, 127, 132, 162, 181, 191, 192, 204], "peter": [17, 65, 83, 97, 102, 105, 115, 117, 191], "piper": [17, 83, 102, 117], "employe": [17, 83, 102, 117], "pick": [17, 83, 102, 117], "peck": [17, 83, 102, 117], "pickl": [17, 83, 102, 117], "pepper": [17, 83, 102, 117], "nnp": [17, 102, 139, 154, 191, 192, 194, 195, 203, 208, 209, 210], "nn": [17, 102, 177, 191, 192, 194, 195, 210], "vbp": [17, 102, 139, 192, 203, 208, 209], "vbg": [17, 102], "IN": [17, 102, 139, 154, 192, 194, 195, 203, 208, 209], "jj": [17, 102, 139, 154, 191, 194, 203, 208, 209, 210], "regexpars": 17, "e": [17, 19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 53, 54, 63, 65, 75, 77, 94, 95, 109, 111, 112, 113, 118, 142, 162, 182, 200], "g": [17, 19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 53, 54, 63, 77, 94, 95, 109, 111, 112, 113, 118, 142, 162, 182, 200], "setregexpars": 17, "when": [17, 50, 54, 55, 77, 85, 87, 90, 95, 109, 113, 115, 118, 122, 129, 139, 182, 191, 204, 205, 208], "defin": [17, 93, 94, 95, 118, 122, 129, 133, 154, 162, 165, 180, 200, 204, 208], "enclos": 17, "treat": 17, "group": [17, 125, 182], "so": [17, 25, 40, 80, 93, 105, 141, 162, 181, 182, 200], "here": [17, 83, 154, 182, 204], "specif": [17, 41, 51, 53, 54, 56, 57, 61, 69, 77, 80, 95, 109, 119, 139, 141, 162, 168, 183, 208], "mean": [17, 36, 72, 80, 82, 85, 87, 109, 111, 112, 123, 132, 139, 182, 204, 205, 208], "noun": [17, 192], "success": [17, 58, 109], "grammar": 17, "parser": [17, 51, 53, 77], "perceptronmodel": [17, 51, 53, 77, 94, 102, 191], "Of": [17, 55, 127], "documentassembl": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 94, 95, 96, 97, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 127, 130, 131, 132, 140, 141, 142, 143, 162, 191, 200, 204], "sentencedetector": [17, 25, 41, 48, 51, 53, 57, 59, 67, 69, 73, 77, 80, 83, 88, 90, 94, 95, 96, 102, 104, 105, 118, 120, 141, 143, 191, 204, 205], "postag": 17, "selectexpr": [17, 25, 41, 48, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 83, 84, 85, 87, 88, 89, 90, 93, 96, 97, 102, 104, 105, 107, 111, 117, 118, 120, 123, 124, 125, 129, 130, 132, 133, 154, 191, 192, 194, 203, 204, 209], "explod": [17, 25, 41, 48, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 84, 87, 88, 89, 90, 93, 96, 102, 104, 105, 111, 124, 129, 132, 133, 154, 191, 194, 203, 204, 209], "11": [17, 72, 73, 85, 87, 90, 102], "13": [17, 48, 72, 73, 77, 102, 129, 133], "21": [17, 85, 87, 96, 102], "35": [17, 102], "39": [17, 96, 102, 194], "52": [17, 96, 102, 194], "58": [17, 102], "albertforquestionansw": 18, "classifi": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 80, 132, 204], "dl": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 82, 95, 115, 116], "albert": [18, 19, 20, 55], "span": [18, 21, 26, 29, 33, 37, 42, 112], "question": [18, 21, 26, 29, 33, 37, 41, 42, 51, 53, 56, 57, 63, 66, 67, 74, 102, 109, 112, 139], "answer": [18, 21, 26, 29, 33, 37, 41, 42, 51, 53, 56, 57, 63, 74, 109, 112, 139], "task": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 50, 55, 56, 57, 58, 60, 61, 65, 69, 72, 73, 74, 80, 109, 111, 112, 141, 182], "squad": [18, 21, 26, 29, 33, 37, 42, 55, 56, 57, 60, 66, 67], "linear": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 109, 182], "layer": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 55, 56, 57, 60, 63, 74, 181, 182], "hidden": [18, 20, 21, 23, 24, 26, 28, 29, 31, 33, 35, 37, 39, 42, 44, 46, 55, 63, 74, 119, 182], "state": [18, 20, 21, 23, 24, 25, 26, 28, 29, 31, 33, 35, 36, 37, 39, 40, 42, 44, 46, 50, 55, 56, 57, 58, 63, 65, 66, 67, 74, 80, 95, 109, 112, 140, 176, 180, 181, 182, 201, 204], "comput": [18, 21, 26, 29, 33, 37, 42, 50, 55, 60, 61, 69, 109, 111, 116, 139, 178, 181, 182, 208], "logit": [18, 19, 21, 22, 26, 29, 30, 33, 34, 37, 38, 42, 43, 45], "spanclassifi": [18, 21, 26, 29, 33, 37, 42], "document_quest": [18, 21, 26, 29, 33, 37, 41, 42], "document_context": [18, 21, 26, 29, 33, 37, 42], "albert_base_qa_squad2": 18, "larg": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 55, 60, 61, 63, 72, 73, 74, 80, 82, 84, 89, 95, 109, 182], "allow": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 63, 69, 94, 95, 97, 104, 105, 123, 125, 141, 168, 181, 182, 183], "faster": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 61, 63, 115, 116, 180], "casesensit": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 84, 89, 115, 118], "whether": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 84, 85, 87, 89, 90, 94, 95, 97, 99, 104, 105, 109, 112, 113, 115, 118, 123, 125, 130, 132, 133, 134, 139, 142, 143, 146, 155, 165, 182, 191, 195, 205], "ignor": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 84, 90, 93, 109, 111, 112, 115, 118, 139], "case": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 72, 73, 74, 75, 82, 84, 89, 113, 115, 118, 125, 130, 176, 180, 182, 191, 192, 204], "configprotobyt": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 82, 95, 109, 111, 112, 113], "maxsentencelength": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 74], "128": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 55, 56, 57, 58, 60, 61, 66, 67, 72, 73, 74, 162, 182, 200], "multidocumentassembl": [18, 21, 26, 29, 33, 37, 41, 42, 140], "context": [18, 21, 26, 29, 33, 37, 42, 56, 57, 62, 63, 70, 74, 108, 113, 125], "setcasesensit": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 59, 61, 65, 66, 72, 84, 89, 94, 115, 118, 132, 143], "what": [18, 21, 26, 29, 33, 37, 40, 42, 51, 53, 80, 82, 111, 113, 122, 192, 201], "my": [18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 54, 88, 90, 104, 109, 118, 120, 123, 204], "clara": [18, 21, 26, 29, 33, 37, 42], "live": [18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 109, 162, 200], "berkelei": [18, 21, 26, 29, 33, 37, 42], "setmaxsentencelength": [18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 55, 56, 57, 58, 60, 61, 62, 65, 66, 67, 70, 72, 73, 74], "albertforsequenceclassif": [19, 27], "sequenc": [19, 22, 27, 30, 34, 38, 43, 45, 50, 65, 109, 110, 111, 112, 113, 118, 176, 177, 180, 181], "regress": [19, 22, 27, 30, 34, 38, 43, 45, 112], "pool": [19, 22, 27, 30, 34, 38, 43, 45, 59, 63, 68], "multi": [19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 55, 69, 72, 73, 80, 82, 111], "sequenceclassifi": [19, 22, 27, 30, 34, 38, 43, 45], "label": [19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 50, 51, 53, 75, 82, 92, 93, 94, 95, 98, 99, 107, 108, 112, 113, 119, 162, 168, 183, 191, 200, 204], "albert_base_sequence_classifier_imdb": 19, "coalescesent": [19, 22, 27, 30, 34, 38, 43, 45, 82], "instead": [19, 22, 27, 30, 34, 38, 43, 45, 57, 80, 82, 85, 87, 112, 132, 133, 139, 176, 178, 208], "per": [19, 20, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 72, 73, 82, 85, 90, 92, 93, 94, 95, 139, 154, 165, 181, 182, 191], "inputcol": [19, 22, 25, 27, 30, 34, 36, 38, 40, 43, 45, 68, 82, 128, 131, 132, 133, 134, 137, 140], "averag": [19, 22, 27, 30, 34, 38, 41, 43, 45, 59, 68, 72, 73, 82, 95, 102], "probabl": [19, 22, 27, 30, 34, 38, 43, 45, 80, 109, 112, 115], "calcul": [19, 22, 30, 34, 38, 43, 45, 71, 90, 95, 99, 107, 181, 182], "via": [19, 22, 30, 34, 38, 43, 45, 69, 137, 155, 182], "softmax": [19, 22, 30, 34, 38, 43, 45, 60, 62, 70, 113, 176], "sigmoid": [19, 22, 30, 34, 38, 43, 45, 178], "john": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 48, 57, 67, 73, 75, 77, 96, 97, 105, 134], "lenon": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "born": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 109], "london": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "pari": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "sarah": [19, 20, 22, 23, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46], "neg": [19, 22, 27, 30, 34, 38, 40, 43, 45, 107, 108, 162, 200], "getclass": [19, 20, 22, 23, 24, 27, 28, 30, 31, 34, 35, 38, 39, 43, 44, 45, 46, 50], "setcoalescesent": [19, 22, 27, 30, 34, 38, 43, 45, 82], "limit": [19, 22, 27, 30, 34, 38, 43, 45, 50, 55, 58, 65, 71, 74, 80, 112, 115], "almost": [19, 22, 27, 30, 34, 38, 43, 45], "bert": [19, 21, 22, 23, 27, 30, 31, 34, 38, 41, 43, 45, 55, 56, 57, 60, 61, 65, 66, 67, 72, 73, 74, 95, 96, 112], "512": [19, 22, 27, 30, 34, 38, 41, 43, 45, 63], "help": [19, 22, 27, 30, 34, 38, 43, 45, 51, 53, 55, 111, 125, 162, 200, 205, 209], "feed": [19, 22, 27, 30, 34, 38, 43, 45, 176], "entir": [19, 22, 27, 30, 34, 38, 43, 45, 111, 177, 180], "bool": [19, 22, 27, 30, 34, 38, 43, 45, 54, 57, 59, 69, 75, 77, 82, 84, 85, 89, 90, 94, 95, 97, 99, 104, 105, 109, 112, 113, 115, 118, 123, 125, 130, 132, 133, 134, 139, 142, 146, 155, 162, 165, 191], "one": [19, 22, 27, 30, 34, 36, 38, 43, 45, 48, 51, 53, 54, 56, 57, 68, 72, 73, 74, 80, 82, 85, 93, 105, 115, 120, 143, 181, 182, 200, 204], "albertfortokenclassif": [20, 55], "recognit": [20, 23, 24, 28, 31, 35, 39, 44, 46, 50, 58, 91, 94, 95, 182], "ner": [20, 23, 24, 28, 31, 35, 39, 44, 46, 72, 73, 77, 78, 120, 139, 154, 155, 162, 165, 168, 183, 200], "token_classifi": [20, 24, 35, 39, 44, 46], "albert_base_token_classifier_conll03": 20, "albertembed": [20, 55], "level": [20, 25, 36, 40, 56, 57, 65, 66, 67, 69, 71, 73, 75, 94, 95, 99, 113, 155, 191], "tokenclassifi": [20, 23, 24, 28, 31, 35, 39, 44, 46], "o": [20, 23, 24, 28, 31, 35, 39, 44, 46, 93, 94, 95, 96, 139, 154, 165, 182, 191, 195, 210], "loc": [20, 23, 24, 28, 31, 35, 39, 44, 46, 77, 93, 94, 95, 129, 133, 139, 154, 165, 191], "bertforquestionansw": [21, 41], "bert_base_cased_qa_squad2": 21, "bertforsequenceclassif": 22, "bert_base_sequence_classifier_imdb": 22, "bertfortokenclassif": 23, "bert_base_token_classifier_conll03": 23, "camembertfortokenclassif": 24, "camembert": [24, 58], "camembert_base_token_classifier_wikin": 24, "georg": 24, "washington": 24, "est": [24, 58, 82, 111], "all\u00e9": 24, "\u00e0": 24, "classifierdl": [25, 204], "classifierdlapproach": [25, 36, 204], "gener": [25, 36, 55, 59, 61, 65, 68, 74, 77, 80, 94, 95, 105, 109, 112, 113, 115, 116, 133, 134, 162, 168, 183, 200, 203, 204, 205], "art": [25, 36, 50, 55, 56, 57, 58, 63, 65, 66, 67, 74, 80, 95, 109, 112, 140], "univers": [25, 51, 53, 69, 111], "encod": [25, 54, 56, 57, 60, 65, 69, 111, 162], "deep": [25, 56, 57, 63, 80, 94, 105, 113, 182], "dnn": 25, "insid": [25, 36, 93, 102, 125, 177, 191], "instanti": [25, 36, 40, 51, 53, 62, 70, 71, 75, 83, 84, 88, 89, 94, 95, 97, 102, 105, 107, 108, 113, 115, 116, 120, 122, 127, 191, 192], "classifierdlmodel": [25, 36, 204], "usag": [25, 36, 40, 51, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 69, 71, 72, 74, 75, 80, 82, 83, 85, 87, 88, 89, 94, 95, 97, 102, 104, 105, 107, 108, 111, 112, 113, 115, 117, 118, 122, 125, 127], "lr": [25, 36, 40, 95], "rate": [25, 36, 40, 62, 66, 67, 70, 71, 95, 98, 113], "005": [25, 40, 95, 98], "64": [25, 36, 40, 55, 95, 98, 168, 183, 204], "dropout": [25, 40, 95, 182], "coeffici": [25, 40, 94, 95], "5": [25, 36, 40, 48, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 80, 82, 85, 87, 90, 93, 95, 102, 109, 127, 132, 139, 154, 162, 165, 182, 192, 194, 195, 200, 203, 204, 210], "maxepoch": [25, 36, 40, 94, 95], "maximum": [25, 36, 40, 48, 62, 70, 77, 80, 92, 94, 95, 97, 98, 104, 105, 109, 111, 112, 113, 115, 123, 125], "epoch": [25, 36, 40, 92, 94, 95, 98, 99, 105, 113, 162], "30": [25, 40, 80, 85, 87, 93, 98, 111, 139, 154, 165, 203], "validationsplit": [25, 36, 40, 95, 105], "choos": [25, 36, 40, 59, 68, 95, 105, 115], "proport": [25, 36, 40, 95, 99, 105], "valid": [25, 36, 40, 85, 95, 99, 105, 113, 200], "against": [25, 36, 40, 75, 80, 84, 89, 95, 99, 105, 141], "between": [25, 36, 40, 51, 53, 66, 67, 69, 72, 73, 74, 77, 95, 99, 104, 105, 113, 181, 182], "off": [25, 36, 40, 69, 72, 73, 95, 99, 105, 181], "enableoutputlog": [25, 36, 40, 95], "stdout": [25, 36, 40, 95, 99], "addit": [25, 36, 40, 51, 53, 56, 57, 75, 94, 95, 99, 104, 109, 125, 162, 182, 203, 204], "outputlogspath": [25, 36, 40, 95, 105], "path": [25, 36, 40, 51, 53, 62, 70, 71, 75, 77, 83, 84, 88, 89, 94, 95, 97, 99, 105, 107, 109, 113, 115, 116, 119, 125, 137, 139, 153, 162, 165, 168, 183, 191, 192, 194, 195, 200], "labelcolumn": [25, 36, 40, 94, 95], "verbos": [25, 36, 40, 94, 95, 99], "dure": [25, 36, 40, 61, 94, 95, 99, 104, 113, 155, 162, 200], "randomse": [25, 36, 40, 94, 95], "random": [25, 36, 40, 62, 70, 92, 94, 95, 98, 132], "seed": [25, 36, 40, 62, 70, 92, 94, 95, 98], "shuffl": [25, 36, 92, 98], "multiclassifierdlapproach": [25, 36, 162, 200], "sentimentdlapproach": [25, 36, 40], "analysi": [25, 36, 40, 63, 74, 106, 107, 112, 129, 147, 182, 205], "accept": [25, 36, 40, 181], "singl": [25, 36, 40, 71, 77, 80, 120, 122, 125, 180, 181, 182, 191], "item": [25, 40, 71, 162, 200], "either": [25, 40, 50, 53, 58, 59, 68, 75, 80, 82, 88, 107, 108, 112, 130, 131, 139, 140, 142, 165, 181, 205], "doubl": [25, 40, 142], "universalsentenceencod": [25, 36, 40, 69, 162, 200, 204], "sentenceembed": [25, 36, 40, 68, 71, 132], "In": [25, 36, 40, 50, 58, 60, 61, 65, 71, 74, 75, 80, 82, 83, 84, 88, 89, 104, 105, 107, 109, 112, 115, 116, 127, 162, 168, 177, 182, 194, 200, 204, 205, 209, 210], "csv": [25, 40, 75, 99, 142, 204], "ha": [25, 36, 41, 50, 54, 55, 60, 61, 63, 66, 67, 71, 80, 83, 88, 95, 105, 107, 112, 115, 116, 127, 128, 130, 137, 139, 162, 180, 181, 182, 194, 200, 204, 205], "movi": [25, 40, 108, 204], "best": [25, 40, 55, 58, 66, 67, 80, 82, 95, 182, 204], "wach": [25, 204], "ever": [25, 40, 54, 204], "opinion": [25, 40, 204], "win": [25, 40, 204], "award": [25, 40, 204], "terribl": [25, 40, 204], "act": [25, 40, 182, 204], "bad": [25, 40, 107, 162, 200, 204], "realli": [25, 40, 108, 204], "trane": 25, "done": [25, 66, 67, 94, 95, 205], "smallcorpu": [25, 40, 204], "read": [25, 40, 50, 51, 53, 62, 70, 80, 83, 84, 85, 87, 88, 89, 94, 97, 99, 105, 107, 109, 113, 115, 116, 125, 127, 128, 131, 137, 140, 150, 153, 156, 162, 182, 191, 192, 194, 195, 200, 204, 210], "header": [25, 40, 41, 142, 204], "src": [25, 40, 50, 51, 53, 71, 83, 84, 88, 89, 94, 95, 102, 115, 116, 120, 127, 191, 192, 194, 195, 204, 210], "test": [25, 40, 50, 51, 53, 56, 57, 69, 71, 83, 84, 88, 89, 94, 95, 99, 102, 109, 115, 116, 120, 127, 191, 192, 194, 195, 204, 210], "useembed": [25, 36, 40, 69, 204], "docclassifi": [25, 36, 40, 204], "setlabelcolumn": [25, 36, 40, 92, 94, 95, 98, 119, 162, 168, 183, 200, 204], "setbatchs": [25, 36, 40, 63, 95, 98, 113, 162, 168, 183, 200, 204], "setmaxepoch": [25, 36, 40, 92, 94, 95, 98, 162, 168, 183, 200, 204], "20": [25, 41, 74, 93, 109, 139, 142, 154, 165, 182, 204], "setlr": [25, 36, 40, 95, 98, 162, 200, 204], "5e": [25, 40, 204], "setdropout": [25, 40, 95, 204], "pipelinemodel": [25, 36, 40, 51, 53, 54, 62, 70, 94, 95, 108, 113, 115, 116, 127, 139, 141, 162, 204, 207], "v": [25, 36, 40, 60, 71, 80, 82, 84, 95, 98, 99, 116, 154, 182], "classifierdl_use_trec6": 25, "trec": 25, "multiclassifierdlmodel": [25, 36], "sentimentdlmodel": [25, 36, 40], "sarcasmdl": [25, 204], "classifierdl_use_sarcasm": [25, 204], "sarcasm": [25, 204], "m": [25, 85, 87, 204], "could": [25, 61, 80, 113, 203, 204, 205], "put": [25, 154, 168, 177, 183, 204], "word": [25, 50, 51, 53, 55, 59, 60, 62, 63, 66, 68, 69, 70, 71, 74, 75, 77, 80, 83, 90, 93, 96, 97, 102, 107, 109, 111, 112, 113, 115, 116, 117, 118, 122, 125, 126, 127, 139, 154, 165, 194, 195, 203, 204], "much": [25, 41, 55, 66, 67, 97, 127, 155, 177, 180, 204], "love": [25, 57, 67, 73, 105, 108, 204], "wake": [25, 204], "am": [25, 85, 87, 109, 120, 204], "mondai": [25, 204], "would": [25, 48, 59, 68, 85, 105, 155, 181, 204], "arrays_zip": [25, 51, 53, 80, 204], "out": [25, 80, 83, 97, 109, 111, 112, 117, 118, 204], "normal": [25, 54, 78, 84, 105, 108, 118, 132, 141, 143, 155, 182, 204, 205], "debertaforquestionansw": 26, "deberta": [26, 27, 28, 60], "deberta_v3_xsmall_qa_squad2": 26, "debertaforsequenceclassif": 27, "v2": [27, 28, 56, 57, 60], "v3": [27, 28], "deberta_v3_xsmall_sequence_classifier_imdb": 27, "deberta_base_sequence_classifier_imdb": 27, "debertafortokenclassif": 28, "deberta_v3_xsmall_token_classifier_conll03": 28, "distilbertforquestionansw": 29, "distilbert": [29, 30, 61], "distilbert_base_cased_qa_squad2": 29, "distilbertforsequenceclassif": 30, "distilbert_base_sequence_classifier_imdb": 30, "distilbertfortokenclassif": 31, "distilbert_base_token_classifier_conll03": 31, "albert_for_sequence_classif": [32, 78], "albert_for_token_classif": [32, 78], "bert_for_sequence_classif": [32, 78], "bert_for_token_classif": [32, 78], "camembert_for_token_classif": [32, 78], "deberta_for_sequence_classif": [32, 78], "deberta_for_token_classif": [32, 78], "distil_bert_for_sequence_classif": [32, 78], "distil_bert_for_token_classif": [32, 78], "longformer_for_sequence_classif": [32, 78], "longformer_for_token_classif": [32, 78], "multi_classifier_dl": [32, 78], "roberta_for_sequence_classif": [32, 78], "roberta_for_token_classif": [32, 78], "sentiment_dl": [32, 78], "xlm_roberta_for_sequence_classif": [32, 78], "xlm_roberta_for_token_classif": [32, 78], "xlnet_for_sequence_classif": [32, 78], "xlnet_for_token_classif": [32, 78], "longformerforquestionansw": 33, "longform": [33, 34, 35, 65], "longformer_base_base_qa_squad2": 33, "longformerforsequenceclassif": 34, "longformer_base_sequence_classifier_imdb": 34, "4096": [34, 55, 65], "longformerfortokenclassif": 35, "xlnet_base_token_classifier_conll03": [35, 46], "longformer_base_token_classifier_conll03": 35, "multiclassifierdl": 36, "bidirect": [36, 56, 57, 63, 74, 181, 182], "gru": [36, 178, 182], "convolut": [36, 50, 182], "machin": [36, 62, 70, 80, 94, 109, 111, 112, 162, 182, 202], "strongli": 36, "relat": [36, 51, 53, 77, 209], "problem": [36, 55, 63, 112, 113], "variant": [36, 65, 69], "multipl": [36, 50, 58, 75, 80, 85, 104, 125, 154, 162, 182, 191], "mai": [36, 130, 176, 180, 182, 203, 204, 205, 208, 209], "assign": [36, 75, 96, 107], "instanc": [36, 98, 99, 146, 149, 155, 156, 160, 181], "multiclass": 36, "categor": 36, "precis": [36, 51, 53], "than": [36, 40, 61, 62, 70, 72, 73, 74, 80, 82, 90, 94, 109, 115, 116, 180, 204], "two": [36, 51, 53, 55, 60, 69, 71, 72, 73, 77, 124, 182, 191, 204], "constraint": 36, "mani": [36, 60, 66, 67, 80, 109, 111, 112, 127, 176], "formal": 36, "find": [36, 51, 53, 66, 67, 69, 75, 77, 83, 85, 109], "binari": [36, 137, 150, 162], "bertsentenceembed": [36, 40, 57, 67, 73], "001": [36, 94, 95, 182], "10": [36, 48, 51, 80, 85, 87, 96, 115, 162, 177, 203], "44": [36, 62, 70, 102], "shuffleperepoch": 36, "threshold": [36, 40, 62, 70, 80, 82, 94, 113, 127], "minimum": [36, 40, 62, 70, 77, 80, 82, 92, 94, 95, 97, 104, 105, 109, 112, 115, 116, 123, 125, 191], "ed58abb40640f983": 36, "pn": 36, "newsyou": 36, "toxic": 36, "a1237f726b5f5d89": 36, "dude": 36, "place": [36, 50], "obscen": 36, "insult": 36, "24b0d6c8733c2abe": 36, "thank": [36, 74, 80], "8c4478fb239bcfc0": 36, "gee": 36, "minut": 36, "traindataset": [36, 162, 200], "printschema": [36, 128, 131, 137, 140], "root": [36, 48, 51, 53, 77, 128, 131, 137, 140, 192], "setcleanupmod": [36, 131, 140], "shrink": [36, 131, 140], "1e": [36, 162, 200], "setthreshold": [36, 40, 80, 82, 162, 200], "setvalidationsplit": [36, 99, 105, 168, 183], "setverbos": [36, 94, 95, 99, 168, 183], "multiclassifi": [36, 162, 200], "multiclassifierdl_use_tox": 36, "comment": [36, 80], "jigsaw": 36, "challeng": [36, 61, 63, 66, 67, 80], "pretti": [36, 80], "good": [36, 58, 61, 69, 108], "stuff": 36, "wtf": 36, "kind": [36, 80, 85, 87], "crap": 36, "robertaforquestionansw": 37, "roberta": [37, 38, 39, 42, 43, 44, 58, 60, 65, 66, 67, 72, 73], "roberta_base_qa_squad2": 37, "robertaforsequenceclassif": 38, "roberta_base_sequence_classifier_imdb": 38, "robertafortokenclassif": 39, "roberta_base_token_classifier_conll03": 39, "sentimentdl": 40, "natur": [40, 50, 55, 56, 57, 58, 60, 61, 62, 69, 70, 74, 82, 109, 112, 130, 140, 143], "affect": [40, 125, 182], "subject": [40, 51, 53], "view": 40, "common": [40, 75, 120, 130, 155, 168, 183, 207], "product": [40, 182], "review": [40, 158], "tweet": 40, "interpret": [40, 75], "posit": [40, 60, 61, 72, 73, 74, 80, 107, 108, 123, 143, 162, 200], "final": [40, 65, 66, 67, 72, 73, 82, 95, 113, 180, 181, 204], "otheriws": [40, 82], "neutral": [40, 82], "thresholdlabel": [40, 82], "score": [40, 56, 57, 72, 73, 80, 82, 94, 95, 107, 108, 109], "less": [40, 61, 82, 90, 94, 115, 177, 181], "watch": [40, 108], "32": [40, 55, 63, 181, 182, 203, 209], "setthresholdlabel": [40, 82], "p": [40, 54, 62, 70, 82, 95, 99, 122, 182], "sentimentdl_use_imdb": 40, "english": [40, 58, 80, 115, 118, 127], "imdb": 40, "sentimentdl_use_twitt": 40, "wow": 40, "video": [40, 80], "awesom": 40, "bruh": 40, "damn": 40, "wast": [40, 108], "time": [40, 55, 62, 70, 72, 73, 80, 85, 99, 108, 113, 127, 155, 176, 177, 178, 181, 182, 203, 204, 208, 209], "tapasforquestionansw": 41, "implement": [41, 62, 70, 72, 105, 113, 135, 136, 144, 145, 151, 157, 161, 176, 177, 178, 180, 182], "tapa": 41, "design": [41, 56, 57, 66, 67, 84, 111, 162, 182, 200], "about": [41, 51, 53, 66, 67, 71, 80, 104, 116, 139, 141, 203, 205, 208, 209], "tabular": [41, 142], "tabl": [41, 142], "tri": 41, "share": [41, 80, 181, 182, 205], "its": [41, 50, 60, 61, 65, 74, 80, 102, 107, 111, 118, 162, 182, 194], "table_qa_tapas_base_finetuned_wtq": 41, "document_assembl": [41, 138, 142, 155], "table_json": 41, "document_t": [41, 142], "sentence_detector": [41, 78, 103], "table_assembl": [41, 138, 155], "tableassembl": [41, 142], "stage": [41, 139, 141, 162, 200, 204, 205, 208], "json_data": 41, "monei": [41, 142], "ag": [41, 142], "donald": [41, 142], "trump": [41, 142], "000": [41, 80, 109, 142], "75": [41, 80, 142], "elon": [41, 142], "musk": [41, 142], "55": [41, 96, 142], "AS": [41, 48], "who": [41, 122, 204], "earn": 41, "thei": [41, 51, 53, 95, 97, 109, 141, 157, 192, 204], "old": [41, 48, 194], "xlmrobertaforquestionansw": 42, "xlm": [42, 43, 44, 72, 73], "xlm_roberta_base_qa_squad2": 42, "xlmrobertaforsequenceclassif": 43, "xlm_roberta_base_sequence_classifier_imdb": 43, "xlmrobertafortokenclassif": 44, "xlm_roberta_base_token_classifier_conll03": 44, "xlnetforsequenceclassif": 45, "xlnet": [45, 46, 74], "xlnet_base_sequence_classifier_imdb": 45, "xlnetfortokenclassif": 46, "spanbert_coref": 47, "spanbertcorefmodel": 48, "corefer": 48, "resolut": 48, "spanbert": 48, "identifi": [48, 71, 80, 84, 88, 123, 125, 162, 205], "same": [48, 55, 66, 71, 72, 75, 77, 112, 141, 162, 181, 182, 205], "given": [48, 75, 80, 109, 112, 113, 115, 116, 118, 161, 162, 176, 180, 182], "told": [48, 87], "mari": [48, 57, 67, 73, 105], "he": [48, 60, 87, 122], "borrow": 48, "book": [48, 54, 109, 113, 192], "her": 48, "link": [48, 165], "fine": [48, 56, 57, 61, 112], "tune": [48, 56, 57, 61, 112], "ontonot": 48, "corefresolut": 48, "spanbert_base_coref": 48, "maxsegmentlength": 48, "segment": [48, 61, 66, 126, 127], "textgenr": 48, "genr": 48, "One": [48, 80, 122, 124], "follow": [48, 54, 63, 65, 71, 80, 85, 87, 88, 93, 97, 104, 124, 142, 177, 178, 200, 202, 205], "bc": 48, "broadcast": 48, "convers": 48, "bn": 48, "nw": 48, "wire": 48, "pt": 48, "pivot": 48, "testament": 48, "tc": 48, "telephon": 48, "wb": 48, "web": [48, 54, 58, 109, 162, 200], "setmaxsegmentlength": 48, "settextgenr": 48, "code": [48, 60, 62, 65, 66, 67, 70, 72, 73, 80, 82, 112, 179, 182, 201, 209], "vit_for_image_classif": 49, "vitforimageclassif": 50, "vision": 50, "vit": 50, "altern": [50, 80, 107, 113, 115, 116, 139, 142, 180], "neural": [50, 56, 57, 60, 95, 105, 111, 181, 182], "network": [50, 56, 57, 63, 95, 105, 177, 180, 181, 182], "usual": [50, 143, 177], "imageclassifi": 50, "image_assembl": [50, 138, 155], "image_classifier_vit_base_patch16_224": 50, "huggingfac": [50, 58], "vitimageclassificationtestspec": 50, "paper": [50, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 80, 105, 108, 109, 111, 112, 182, 195, 210], "abstract": [50, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 72, 73, 74, 80, 109, 111, 112, 119, 177, 180, 195, 210], "while": [50, 55, 61, 71, 80, 109, 162, 181, 200, 205], "architectur": [50, 55, 56, 57, 60, 66, 82, 95, 105, 112, 182], "becom": [50, 55, 61, 80], "de": [50, 58, 80, 82, 111], "facto": [50, 80], "standard": [50, 54, 65, 85, 87, 115, 116, 125], "remain": [50, 54, 55, 61, 80], "attent": [50, 60, 65, 182], "appli": [50, 54, 75, 77, 96, 104, 112, 113, 115, 129, 133, 154, 182, 191], "conjunct": 50, "replac": [50, 54, 60, 65, 82, 83, 96, 105, 115, 116, 182, 204], "certain": [50, 113], "compon": [50, 98, 99, 128, 137, 146, 149, 160, 208], "keep": [50, 80, 97, 109, 112], "overal": [50, 71, 74], "structur": [50, 143, 203], "relianc": 50, "cnn": [50, 82, 95, 105, 182], "necessari": [50, 61, 200, 207], "pure": [50, 111], "directli": [50, 139, 162, 176, 200], "patch": 50, "perform": [50, 54, 55, 58, 60, 61, 63, 66, 67, 69, 71, 72, 73, 74, 95, 108, 109, 115, 181, 182], "veri": [50, 58, 63, 72, 73, 74, 109, 111, 112, 139, 181, 203, 205, 208, 209], "well": [50, 51, 53, 69, 72, 73, 80, 142, 182], "amount": [50, 69, 80, 89, 109, 127, 139, 208], "transfer": [50, 61, 69, 72, 73, 109, 112], "mid": 50, "small": [50, 54, 55, 58, 61, 62, 70, 83, 102, 139, 194, 208], "benchmark": [50, 55, 60, 61, 63, 72, 73, 112], "imagenet": 50, "cifar": 50, "vtab": 50, "etc": [50, 59, 132, 143, 200], "attain": 50, "excel": [50, 74], "compar": [50, 55, 60, 61, 63, 74, 80, 105, 112, 113, 162, 200], "substanti": [50, 56, 57], "fewer": [50, 55], "worth": 50, "16x16": 50, "scale": [50, 55, 61, 65, 72, 73, 109, 112, 180, 182], "imagedf": 50, "datafram": [50, 71, 102, 127, 139, 150, 154, 161, 162, 165, 191, 192, 194, 195, 200, 204, 208, 210], "dropinvalid": 50, "imageassembl": [50, 137], "pipelinedf": 50, "dependencypars": [51, 53, 77], "dependencyparserapproach": [51, 192, 210], "unlabel": [51, 56, 57, 109, 112], "grammat": [51, 53], "dependencyparsermodel": [51, 53, 77], "relationship": [51, 53, 69, 77], "tell": [51, 53, 80, 154], "verb": [51, 53, 192], "modifi": [51, 53, 66, 67, 105, 179], "describ": [51, 53, 77, 80, 111, 181, 182], "wai": [51, 53, 75, 77, 141, 165], "onli": [51, 53, 54, 63, 69, 74, 85, 97, 104, 105, 109, 112, 122, 141, 178, 179, 182, 191], "chosen": [51, 53, 95], "particular": [51, 53, 80], "treebank": 51, "penn": 51, "setdependencytreebank": 51, "conll": [51, 53, 94, 95, 155, 192, 193, 207], "u": [51, 53, 60, 61, 80, 87, 93, 94, 95, 139, 154, 165, 178, 182, 192, 202, 205, 210], "setconllu": [51, 53], "apart": [51, 53, 129, 133], "dependencytreebank": 51, "conllu": [51, 53, 83, 155, 193, 207], "numberofiter": [51, 53], "iter": [51, 53, 55, 62, 70, 102, 127, 162, 181, 200], "converg": [51, 53, 102, 127], "better": [51, 53, 55, 60, 74, 80, 94, 102, 104, 105, 108, 127], "accuraci": [51, 53, 56, 57, 62, 69, 70, 72, 73, 94, 95, 102, 115, 127, 200], "typeddependencyparserapproach": [51, 53], "postagg": [51, 53, 77, 94, 102], "dependency_treebank": 51, "emptydataset": [51, 53], "reli": [51, 53, 74, 80], "tree": [51, 77], "bank": 51, "setnumberofiter": [51, 53], "read_a": [51, 53, 75, 83, 84, 88, 89, 94, 97, 99, 107, 115, 116, 125, 148, 153, 155, 191, 192], "reada": [51, 53, 71, 75, 83, 84, 88, 89, 94, 97, 99, 107, 115, 116, 120, 125, 150, 153, 191, 192], "dep": 51, "dependency_conllu": [51, 77], "perceptron": [51, 78, 101], "featur": [51, 62, 70, 80, 90, 94, 162, 182, 207], "typeddependencyparsermdoel": 51, "union": [51, 53], "worker": [51, 53], "turner": [51, 53], "newal": [51, 53], "sai": [51, 53, 80, 125], "disappoint": [51, 53], "talk": [51, 53], "stricken": [51, 53], "parent": [51, 53], "firm": [51, 53], "feder": [51, 53], "mogul": [51, 53], "col": [51, 53, 75, 84, 93, 96, 129, 133, 154, 203], "dependency_pars": [52, 78], "typed_dependency_pars": [52, 78], "typeddependencypars": [53, 77], "Its": 53, "conll2009": 53, "typeddependencyparsermodel": [53, 77], "beforehand": 53, "2009": 53, "setconll2009": 53, "dependency_typ": [53, 77], "train_smal": 53, "txt": [53, 62, 70, 71, 83, 84, 88, 89, 102, 105, 107, 113, 115, 116, 120, 125, 194, 195, 210], "descript": [53, 68, 80, 85, 115, 122, 150, 168, 183], "typdep": 53, "dependency_typed_conllu": [53, 77], "amod": 53, "flat": [53, 77, 134], "nsubj": [53, 77, 134, 192], "parataxi": 53, "documentnorm": 54, "raw": [54, 109, 122, 125, 203, 205], "scrape": 54, "xml": 54, "remov": [54, 66, 67, 97, 108, 123, 132, 133, 134], "dirti": [54, 97], "regex": [54, 75, 85, 88, 97, 113, 115, 116, 123, 125], "want": [54, 75, 96, 168, 183, 205], "polici": 54, "lower": [54, 55, 80, 113, 130], "action": 54, "clean": [54, 97, 112, 143, 205], "lowercas": [54, 97, 123, 130], "convert": [54, 59, 68, 71, 85, 87, 90, 93, 97, 112, 123, 124, 129, 130, 133, 134, 162, 200, 207], "pretty_al": 54, "utf": 54, "cleanuppattern": [54, 97], "normalizeddocu": 54, "setact": 54, "setpattern": [54, 123], "setreplac": 54, "setpolici": 54, "setlowercas": [54, 97, 130, 143], "div": 54, "theworldsgreatest": 54, "right": [54, 56, 57], "hide": 54, "wide": [54, 56, 57, 60, 61, 72, 73], "toptext": 54, "style": [54, 82, 112], "font": 54, "famili": 54, "sego": 54, "ui": 54, "arial": 54, "san": [54, 80], "serif": 54, "world": [54, 120, 162, 200], "largest": [54, 80, 109], "develop": [54, 80, 111, 159], "site": [54, 80], "h1": 54, "300": 54, "160": 54, "lorem": [54, 84, 89], "ipsum": [54, 84, 89], "simpli": [54, 205], "print": 54, "typeset": 54, "industri": 54, "been": [54, 58, 109, 124, 143], "sinc": [54, 80, 109, 204, 205, 209], "1500": 54, "unknown": [54, 82], "printer": 54, "took": 54, "gallei": 54, "scrambl": 54, "specimen": 54, "surviv": 54, "five": [54, 96], "centuri": 54, "leap": 54, "electron": 54, "essenti": [54, 109], "unchang": 54, "popularis": 54, "1960": 54, "releas": [54, 55, 58, 60, 66, 67, 72, 73, 112, 155], "letraset": 54, "passag": 54, "recent": [54, 56, 57, 60, 66, 67, 80], "desktop": 54, "publish": [54, 66, 67], "softwar": 54, "aldu": 54, "pagemak": 54, "setencod": 54, "lite": 55, "googl": [55, 56, 57, 60, 62, 63, 66, 67, 69, 70, 80, 112, 182, 192], "research": [55, 56, 57, 60, 62, 70, 111, 112, 182], "toyota": 55, "technolog": 55, "institut": 55, "chicago": 55, "These": [55, 66, 67, 74, 80, 94, 109, 165, 202], "offici": [55, 80, 93, 94, 95, 139, 154, 165, 201], "tf": [55, 69, 168, 177, 179, 180, 181, 183], "wrapper": [55, 158, 176, 178, 182], "port": 55, "albert_base_uncas": 55, "albert_bas": 55, "768": [55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74], "emb": 55, "dim": [55, 182], "12m": 55, "albert_large_uncas": 55, "albert_larg": 55, "1024": [55, 63, 65, 74], "24": [55, 74, 84, 89, 93, 113, 139, 154, 165, 203], "16": [55, 74, 96, 194, 203], "18m": 55, "albert_xlarge_uncas": 55, "albert_xlarg": 55, "2048": 55, "60m": 55, "albert_xxlarge_uncas": 55, "albert_xxlarg": 55, "235m": 55, "sentencepiec": [55, 60, 69], "everi": [55, 56, 57, 58, 60, 61, 65, 66, 67, 72, 73, 74, 95, 108, 111, 113, 131, 140, 141, 168, 177, 183, 205], "dimens": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 149, 177, 180, 182], "repeat": 55, "footprint": 55, "howev": [55, 68, 74, 80, 97, 181, 203], "cost": [55, 113, 115], "similar": [55, 69, 80, 82, 180, 182], "through": [55, 77, 80, 134, 182, 205], "FOR": 55, "tfhub": [55, 63, 69], "dev": [55, 63, 69], "q": 55, "increas": [55, 71, 80, 109, 115], "often": [55, 66, 67, 74], "improv": [55, 56, 57, 58, 60, 63, 66, 67, 72, 73, 94, 95, 109, 182, 209], "downstream": [55, 58, 60, 63, 65, 74, 109, 112], "some": [55, 57, 72, 80, 95, 105, 109, 141, 162, 203, 204, 208, 209], "point": [55, 56, 57, 104, 105, 131, 140, 191], "further": [55, 80, 94, 95, 129, 143], "harder": 55, "gpu": [55, 109, 111, 112, 155, 181], "tpu": 55, "longer": [55, 62, 65, 70, 82, 181, 209], "present": [55, 63, 65, 66, 67, 69, 72, 73, 77, 105, 111], "reduct": [55, 115], "techniqu": [55, 60, 109, 112], "consumpt": [55, 69, 71], "speed": [55, 94, 111], "devlin": [55, 66, 67], "et": [55, 66, 67, 82, 182], "al": [55, 66, 67, 182], "2019": [55, 58, 60, 66, 67, 72, 73], "comprehens": [55, 109], "empir": [55, 56, 57, 72, 73, 74], "evid": 55, "our": [55, 58, 61, 62, 63, 65, 66, 67, 69, 70, 72, 73, 80, 105, 109, 112, 154, 165, 209], "lead": [55, 58, 72, 73, 177], "loss": [55, 61, 95, 112, 182, 200], "focus": [55, 80], "inter": 55, "coher": [55, 109], "consist": [55, 60, 65, 102, 108, 127, 142, 180, 182, 194], "As": [55, 56, 57, 61, 80, 181, 182], "establish": 55, "glue": [55, 56, 57, 61, 66, 67, 72, 73], "race": [55, 60, 66, 67], "embeddingsfinish": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 132], "finished_embed": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "setoutputasvector": [55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 132], "setcleanannot": [55, 60, 61, 63, 65, 66, 68, 69, 71, 72, 74, 132, 133, 134], "80": [55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 88, 132, 143], "1342473030090332": [55, 60], "3855540752410889": [55, 60], "9818322062492371": [55, 60], "784737348556518": [55, 60], "847029983997345": [55, 60], "047153353691101": [55, 60], "1520637571811676": [55, 60], "6245765686035156": [55, 60], "009860038757324219": [55, 60], "13450059294700623": [55, 60], "707749128341675": [55, 60], "2916892766952": [55, 60], "04192575812339783": [55, 60], "5764210224151611": [55, 60], "3196685314178467": [55, 60], "527840495109": [55, 60], "15583214163780212": [55, 60], "1614152491092682": [55, 60], "28423872590065": [55, 60], "135491415858268": [55, 60], "bertembed": [56, 59, 68, 95, 132], "dens": [56, 57], "small_bert_l2_768": 56, "understand": [56, 57, 61, 72, 74, 80, 112, 127, 203], "introduc": [56, 57, 61, 63, 65, 112], "call": [56, 57, 61, 75, 80, 109, 161, 176, 178, 180, 182, 191, 204, 210], "stand": [56, 57], "unlik": [56, 57, 72, 80, 122, 177, 180], "jointli": [56, 57], "condit": [56, 57, 109, 112], "both": [56, 57, 63, 69, 77, 180, 181, 182, 204, 205], "left": [56, 57], "just": [56, 57, 61, 66, 90, 95, 179], "rang": [56, 57, 60, 61, 72, 73], "infer": [56, 57, 58, 61, 74, 181, 182], "without": [56, 57, 72, 73, 80, 109, 127, 182], "modif": [56, 57], "conceptu": [56, 57], "simpl": [56, 57, 75, 109, 182, 205], "power": [56, 57, 112], "obtain": [56, 57, 58, 69], "eleven": [56, 57], "push": [56, 57], "absolut": [56, 57], "multinli": [56, 57], "86": [56, 57, 60], "v1": [56, 57, 177], "f1": [56, 57, 72, 73, 95, 109], "93": [56, 57], "83": [56, 57, 60, 168, 183, 194, 195, 210], "small_bert_l2_128": 56, "3497989177703857": 56, "480538547039032": 56, "3238905668258667": 56, "612930893898010": 56, "1357314586639404": 56, "32984697818756104": 56, "6032363176345825": 56, "6791689395904": 56, "8244884014129639": 56, "27088963985443115": 56, "059438943862915": 56, "9817547798156": 56, "1648050546646118": 56, "4725411534309387": 56, "5938255786895752": 56, "5780693292617": 56, "9125322699546814": 56, "4563939869403839": 56, "3975459933280945": 56, "81611204147338": 56, "sentence_bert_embed": 57, "sent_small_bert_l2_768": 57, "islong": 57, "long": [57, 65, 74, 180, 182], "sent_small_bert_l2_128": 57, "orang": [57, 67, 73], "8951074481010437": [57, 67, 73], "13753940165042877": [57, 67, 73], "3108254075050354": [57, 67, 73], "65693199634552": [57, 67, 73], "6180210709571838": [57, 67, 73], "12179657071828842": [57, 67, 73], "191165953874588": [57, 67, 73], "4497021436691": [57, 67, 73], "822715163230896": [57, 67, 73], "7568016648292542": [57, 67, 73], "1165061742067337": [57, 67, 73], "59048593044281": [57, 67, 73], "setislong": 57, "camembertembed": 58, "tasti": 58, "french": [58, 80, 111, 118], "loui": 58, "martin": 58, "benjamin": 58, "muller": 58, "pedro": 58, "javier": 58, "ortiz": 58, "su\u00e1rez": 58, "yoann": 58, "dupont": 58, "laurent": [58, 182], "romari": 58, "\u00e9ric": 58, "villemont": 58, "la": [58, 111], "clergeri": 58, "djam\u00e9": 58, "seddah": 58, "beno\u00eet": 58, "sagot": 58, "facebook": [58, 60, 72, 73], "138gb": 58, "camembert_bas": 58, "camembertembeddingstestspec": 58, "co": [58, 80], "ubiquit": 58, "despit": 58, "most": [58, 61, 65, 80, 95, 109, 111, 112, 181], "concaten": [58, 127, 176, 181], "practic": [58, 112], "except": [58, 90, 95, 125, 168, 183], "investig": [58, 61, 69], "feasibl": 58, "monolingu": [58, 72, 73], "evalu": [58, 65, 72, 73, 99, 146, 162], "crawl": [58, 112], "prefer": [58, 77, 134], "wikipedia": [58, 82, 109], "surprisingli": [58, 69], "rel": [58, 60, 72, 85, 87, 94, 113, 203], "4gb": 58, "those": [58, 77, 96, 181, 204, 205], "larger": [58, 61, 66, 67, 109, 111, 112], "130": 58, "gb": 58, "reach": [58, 80, 109], "four": [58, 105, 124], "un": [58, 82], "08442357927560806": 58, "12863239645957947": 58, "03835778683423996": 58, "200479581952": 58, "048462312668561935": 58, "12637358903884888": 58, "27429091930389404": 58, "07516729831": 58, "02690504491329193": 58, "12104076147079468": 58, "012526623904705048": 58, "031543646007": 58, "05877285450696945": 58, "08773420006036758": 58, "06381352990865707": 58, "122621834278": 58, "fr": [58, 82], "chunkembed": [59, 132], "util": [59, 94, 104, 105, 116, 141, 147, 148, 150, 152, 155, 156, 160, 164], "wordembed": [59, 68, 71, 95, 132, 155], "chunker": [59, 78, 155], "ngramgener": [59, 90], "nerconvert": [59, 93, 94, 95, 162, 200], "poolingstrategi": [59, 68], "aggreg": [59, 68], "sum": [59, 63, 68, 182], "skipoov": 59, "discard": 59, "oov": 59, "ngram": [59, 90, 109, 112], "setn": [59, 90], "wordembeddingsmodel": [59, 68, 71, 77, 94, 95, 96, 132], "setpoolingstrategi": [59, 68], "55661": 59, "42829502": 59, "86661": 59, "409785": 59, "06316501": 59, "120775": 59, "0732005": 59, "40674996": 59, "22938299": 59, "50597": 59, "288195": 59, "555655": 59, "465145": 59, "140118": 59, "17417": 59, "095253006": 59, "0530925": 59, "218465": 59, "714395": 59, "79860497": 59, "0129999": 59, "139705": 59, "177955": 59, "1887775": 59, "45545": 59, "20030999": 59, "461557": 59, "07891501": 59, "strategi": [59, 68, 88, 104, 113], "setskipoov": 59, "debertaembed": 60, "decod": [60, 65, 109, 111, 112], "enhanc": [60, 108], "disentangl": 60, "pengcheng": 60, "xiaodong": 60, "liu": [60, 66, 67], "jianfeng": 60, "gao": 60, "weizhu": 60, "chen": [60, 66, 67, 182], "2018": [60, 66, 67, 182], "mask": [60, 72, 73, 74, 123], "half": [60, 80], "deberta_v3_bas": 60, "microsoft": [60, 111], "www": 60, "blog": 60, "surpass": 60, "human": [60, 80], "superglu": 60, "progress": [60, 105, 123], "significantli": [60, 63, 66, 67, 72, 73, 80], "novel": [60, 74, 80], "mechan": [60, 65], "respect": [60, 71, 94, 95, 182, 194], "weight": [60, 63, 80, 94, 96, 113, 180, 182], "among": 60, "matric": [60, 180, 182], "second": [60, 63, 88, 104, 118, 123, 182, 204], "predict": [60, 95, 109, 112, 162, 182, 200], "effici": [60, 62, 69, 70, 111, 176, 177, 180, 181, 203], "achiev": [60, 65, 66, 67, 72, 73, 74, 95, 109, 111, 112, 139, 182, 208], "mnli": 60, "9": [60, 72, 73, 90, 203, 208, 209], "90": 60, "91": 60, "88": 60, "made": [60, 69, 200], "publicli": [60, 72, 73], "distilbertembed": 61, "fast": [61, 108, 111, 139, 182, 208], "cheap": 61, "distil": 61, "40": [61, 96, 111], "uncas": 61, "60": [61, 104], "preserv": [61, 123, 143], "over": [61, 72, 73, 74, 115, 125, 154, 162, 177, 200], "95": 61, "measur": [61, 66, 67, 162], "distilbert_base_cas": 61, "doesn": [61, 66, 182], "t": [61, 66, 83, 97, 105, 107, 125, 129, 133, 181, 182], "token_type_id": [61, 66], "don": [61, 66, 97], "indic": [61, 66, 123], "belong": [61, 66], "separ": [61, 66, 88, 90, 104, 105, 115, 125, 127, 133, 154, 191, 202], "sep_token": [61, 66], "sep": 61, "position_id": 61, "ad": [61, 63, 113, 176], "though": [61, 80], "know": [61, 111, 141], "smaller": [61, 62, 70, 181], "cheaper": 61, "lighter": 61, "preval": 61, "oper": [61, 65, 113, 122, 176, 177, 181, 182, 203], "edg": [61, 77], "constrain": 61, "budget": 61, "purpos": [61, 105], "counterpart": 61, "prior": [61, 65, 113], "leverag": [61, 162, 200], "phase": [61, 182], "reduc": [61, 115, 116, 143, 180, 182], "retain": 61, "97": [61, 85, 87, 127], "capabl": [61, 74, 109], "being": [61, 95, 111, 112, 182], "induct": 61, "bias": [61, 178, 180, 182], "tripl": [61, 77], "combin": [61, 65, 71, 80, 112, 113, 115, 181, 182], "cosin": 61, "distanc": [61, 113, 115, 116], "demonstr": [61, 65, 80, 109, 111], "devic": 61, "proof": 61, "concept": [61, 205], "experi": [61, 74, 162, 201], "studi": [61, 66, 67, 112], "1127224713563919": 61, "1982710212469101": 61, "5360898375511169": 61, "272536993026733": 61, "35534414649009705": 61, "13215228915214539": 61, "40981462597846985": 61, "14036104083061": 61, "328085333108902": 61, "06269335001707077": 61, "017595693469047546": 61, "024373905733": 61, "15617232024669647": 61, "2967822253704071": 61, "22324979305267334": 61, "04568954557180": 61, "45411425828933716": 61, "01173491682857275": 61, "190129816532135": 61, "1178255230188369": 61, "doc2vecapproach": 62, "word2vec": [62, 64, 78], "corpu": [62, 63, 70, 80, 83, 102, 112, 113, 194, 210], "algorithm": [62, 70, 80, 94, 108, 113, 115, 116], "construct": [62, 70, 125, 165, 177, 182, 207], "vocabulari": [62, 70, 109, 112, 113], "skip": [62, 70, 77, 113], "gram": [62, 70, 80, 90, 109, 112], "hierarch": [62, 70], "variabl": [62, 70, 178, 180, 182], "doc2vecmodel": 62, "vectors": [62, 70], "windows": [62, 70, 80], "window": [62, 65, 70, 80, 95, 113], "numpartit": [62, 70], "partit": [62, 70, 191], "mincount": [62, 70, 113], "must": [62, 70, 83, 84, 88, 89, 107, 108, 115, 116, 130, 154, 155, 162, 177, 180, 181, 182, 191], "appear": [62, 70, 113], "ani": [62, 69, 70, 75, 80, 95, 109, 112, 132, 133, 181, 201, 204, 205, 210], "divid": [62, 70], "1000": [62, 70, 77, 94, 182], "stepsiz": [62, 70], "step": [62, 70, 162, 178, 182, 200, 204], "optim": [62, 66, 67, 70, 95, 105], "025": [62, 70], "maxit": [62, 70], "estim": [62, 70, 119, 135, 144, 151, 161, 204], "space": [62, 70, 71, 90, 143, 181, 182], "distribut": [62, 70, 179], "composition": [62, 70], "sherlockholm": [62, 70, 113, 210], "setvectors": [62, 70], "setwindows": [62, 70, 80], "setsteps": [62, 70], "initi": [62, 70, 113, 123, 141, 155, 176, 178, 180, 181, 182, 191, 192, 194, 195, 200], "setnumpartit": [62, 70], "setmaxit": [62, 70], "numiter": [62, 70], "equal": [62, 70, 182], "setse": [62, 70], "setmincount": [62, 70, 113], "doc2vec_gigaword_300": 62, "06222493574023247": [62, 70], "011579325422644615": [62, 70], "009919632226228714": [62, 70], "109361454844": [62, 70], "doc2vec_wiki": 62, "elmoembed": 63, "elmo": 63, "billion": [63, 109], "computation": [63, 66, 67, 74, 109, 111, 112], "expens": [63, 66, 67, 74, 107, 109, 111, 112, 115], "lookup": [63, 71, 74, 84, 115, 116], "acceler": [63, 74, 109, 111, 112, 155, 182], "setpoolinglay": 63, "word_emb": 63, "shape": [63, 180, 181, 182], "batch_siz": [63, 180, 181, 182], "max_length": 63, "lstm_outputs1": 63, "lstm": [63, 95, 180, 182], "lstm_outputs2": 63, "trainabl": [63, 182], "tensor": [63, 180, 181, 182], "poolinglay": 63, "contextu": [63, 113], "complex": [63, 69, 80, 115, 116, 177], "characterist": 63, "syntax": 63, "semant": [63, 69, 127], "vari": 63, "across": [63, 109], "linguist": 63, "polysemi": 63, "intern": [63, 98, 99, 125, 142, 146, 149, 155, 182], "bilm": 63, "exist": [63, 113, 132, 134, 162, 182], "six": [63, 115, 116], "textual": 63, "entail": 63, "expos": 63, "crucial": 63, "mix": [63, 145, 161], "semi": 63, "signal": [63, 182], "662458181381226e": 63, "2541114091873169": 63, "6275503039360046": 63, "5787073969841": 63, "19154725968837738": 63, "22998669743537903": 63, "2894386649131775": 63, "21524395048618": 63, "10400570929050446": 63, "12288510054349899": 63, "07056470215320587": 63, "246389418840": 63, "49932169914245605": 63, "12706467509269714": 63, "30969417095184326": 63, "2643227577209": 63, "8871506452560425": 63, "20039963722229004": 63, "0601330995559692": 63, "0348707810044": 63, "albert_embed": [64, 78], "bert_embed": [64, 78], "bert_sentence_embed": [64, 78], "camembert_embed": [64, 78], "chunk_embed": [64, 78], "deberta_embed": [64, 78], "distil_bert_embed": [64, 78], "doc2vec": [64, 78], "elmo_embed": [64, 78], "longformer_embed": [64, 78], "roberta_embed": [64, 78], "roberta_sentence_embed": [64, 78], "universal_sentence_encod": [64, 78], "xlm_roberta_embed": [64, 78], "xlm_roberta_sentence_embed": [64, 78], "xlnet_embed": [64, 78], "longformerembed": 65, "iz": 65, "beltagi": 65, "matthew": 65, "arman": 65, "cohan": 65, "checkpoint": 65, "mlm": 65, "096": 65, "longformer_base_4096": 65, "unabl": 65, "quadrat": 65, "linearli": 65, "easi": 65, "thousand": 65, "drop": [65, 118], "motiv": 65, "global": 65, "text8": 65, "enwik8": 65, "contrast": [65, 84, 112], "finetun": [65, 74], "varieti": [65, 72, 73, 209], "outperform": [65, 69, 72, 73, 74, 80, 109], "wikihop": 65, "triviaqa": 65, "led": [65, 66, 67, 80], "effect": [65, 104, 112, 177], "arxiv": [65, 178, 180, 181, 182], "summar": [65, 80, 109, 111, 112], "found": [65, 71, 80, 115, 122, 130, 207], "18792399764060974": [65, 66], "14591649174690247": [65, 66], "20547787845134735": [65, 66], "1468472778797": [65, 66], "22845706343650818": [65, 66], "18073144555091858": [65, 66], "09725798666477203": [65, 66], "0417917296290": [65, 66], "07037967443466187": [65, 66], "14801117777824402": [65, 66], "03603338822722435": [65, 66], "17893412709": [65, 66], "08734266459941864": [65, 66], "2486150562763214": [65, 66], "009067727252840996": [65, 66], "24408400058": [65, 66], "22409197688102722": [65, 66], "4312366545200348": [65, 66], "1401449590921402": [65, 66], "356410235166549": [65, 66], "robertaembed": [66, 72], "robustli": [66, 67], "approach": [66, 67, 74, 80, 92, 94, 95, 105, 107, 109, 112, 113, 115, 116, 144, 207], "yinhan": [66, 67], "myle": [66, 67, 72, 73], "ott": [66, 67, 72, 73], "naman": [66, 67, 72, 73], "goyal": [66, 67, 72, 73], "jingfei": [66, 67], "du": [66, 67, 82], "mandar": [66, 67], "joshi": [66, 67], "danqi": [66, 67], "omer": [66, 67], "levi": [66, 67], "mike": [66, 67], "lewi": [66, 67], "luke": [66, 67, 72, 73], "zettlemoy": [66, 67, 72, 73], "veselin": [66, 67, 72, 73], "stoyanov": [66, 67, 72, 73], "hyperparamet": [66, 67], "next": [66, 67, 80, 85, 87, 109, 112, 181], "mini": [66, 67], "roberta_bas": 66, "bpe": 66, "gpt": [66, 109], "scheme": [66, 178], "signific": [66, 67, 72, 73, 80, 83], "gain": [66, 67, 72, 73, 182], "care": [66, 67, 125], "comparison": [66, 67, 69, 118], "choic": [66, 67], "impact": [66, 67], "replic": [66, 67], "carefulli": [66, 67], "undertrain": [66, 67], "exce": [66, 67], "highlight": [66, 67], "previous": [66, 67, 80], "overlook": [66, 67], "rais": [66, 67, 80, 90, 95, 162, 180, 181, 182], "report": [66, 67, 69, 162, 200], "robertasentenceembed": 67, "sent_roberta_bas": 67, "embeddingssent": 68, "22093398869037628": 68, "25130119919776917": 68, "41810303926467896": 68, "380883991718": 68, "high": [69, 72, 73, 111], "dimension": [69, 182], "cluster": [69, 155], "tfhub_us": 69, "loadsp": 69, "op": [69, 178, 179, 180], "lingual": [69, 72, 73, 80, 82, 111], "target": [69, 111, 125, 130, 139, 165], "accur": [69, 108, 115], "divers": [69, 109, 112, 201], "trade": [69, 72, 73, 181], "baselin": [69, 109, 182], "do": [69, 80, 93, 118, 125, 129, 139, 176, 181, 200, 204, 208], "tend": 69, "With": [69, 74, 80], "observ": 69, "minim": [69, 111, 181], "encourag": 69, "weat": 69, "detect": [69, 81, 82, 103, 104, 105], "bia": [69, 180, 182], "freeli": 69, "04616805538535118": 69, "022307956591248512": 69, "044395286589860916": 69, "0016493503": 69, "setloadsp": 69, "word2vecapproach": 70, "word2vecmodel": 70, "word2vec_gigaword_300": 70, "word2vec_wiki": 70, "custom": [71, 94, 95, 104, 105, 125, 162], "dictionari": [71, 80, 83, 88, 94, 96, 97, 107, 115, 116, 162], "setstoragepath": [71, 84], "line": [71, 75, 84, 89, 105, 107, 165, 194], "delimit": [71, 75, 77, 83, 88, 90, 94, 97, 107, 123, 142, 191, 194], "39658191506190343": 71, "630968081620067": 71, "5393722253731201": 71, "8428180123359783": 71, "were": [71, 95, 162, 200], "7535235923631415": 71, "9699218875629833": 71, "10397182122983872": 71, "11833962569383116": 71, "stress": 71, "0492683418305907": 71, "9415954572751959": 71, "47624463167525755": 71, "16790967216778263": 71, "induc": 71, "1535748762292387": 71, "33498936903209897": 71, "9235178224122094": 71, "1158772920395934": 71, "zero": [71, 109, 180, 181], "statist": [71, 80, 95, 99], "withcoveragecolumn": 71, "overallcoverag": 71, "writebuffers": 71, "dump": 71, "disk": [71, 204, 205], "storag": [71, 75, 84, 148, 155], "write": [71, 115, 116, 205], "10000": 71, "readcaches": 71, "cach": 71, "higher": [71, 80, 108, 109, 112], "random_embeddings_dim4": 71, "abov": [71, 77, 180, 194], "setstorageref": 71, "glove_4d": 71, "setdimens": [71, 149], "patient": 71, "diagnos": 71, "diabet": 71, "9439099431037903": 71, "4707513153553009": 71, "806300163269043": 71, "16176554560661316": 71, "7966810464859009": 71, "5551124811172485": 71, "8861005902290344": 71, "28284206986427307": 71, "025029370561242104": 71, "35177749395370483": 71, "052506182342767715": 71, "1887107789516449": 71, "08617766946554184": 71, "8399239182472229": 71, "5395117998123169": 71, "7864698767662048": 71, "6599600911140442": 71, "16109347343444824": 71, "6041093468666077": 71, "8913561105728149": 71, "5955275893211365": 71, "01899011991918087": 71, "4397728443145752": 71, "8911281824111938": 71, "9840458631515503": 71, "7599489092826843": 71, "9417727589607239": 71, "8624503016471863": 71, "setwritebuffers": 71, "setreadcaches": 71, "glove_100d": [71, 95], "There": [71, 75, 77, 122, 182, 202, 204, 205, 210], "conveni": 71, "coverag": [71, 147], "add": [71, 85, 87, 104, 109, 112, 113, 125, 180, 182, 204], "stat": 71, "field": [71, 75, 89, 182], "whole": [71, 165, 176], "consid": [71, 77, 80, 113, 115, 116, 118, 122], "570580005645752": 71, "44183000922203064": 71, "7010200023651123": 71, "417129993438720": 71, "542639970779419": 71, "4147599935531616": 71, "0321999788284302": 71, "4024400115013122": 71, "2708599865436554": 71, "04400600120425224": 71, "020260000601410866": 71, "17395000159": 71, "6191999912261963": 71, "14650000631809235": 71, "08592499792575836": 71, "2629800140857": 71, "3397899866104126": 71, "20940999686717987": 71, "46347999572753906": 71, "6479200124740": 71, "embeddings_col": 71, "coverageresult": 71, "coverateresult": 71, "wordsoverallcoverag": 71, "resultdf": 71, "percentag": [71, 113, 127], "output_col": 71, "wordscoverag": 71, "cov_embed": 71, "loadstorag": [71, 84], "storage_ref": [71, 84], "xlmrobertaembed": 72, "unsupervis": [72, 73, 74, 80, 109], "cross": [72, 73, 96], "alexi": [72, 73], "conneau": [72, 73], "kartikai": [72, 73], "khandelw": [72, 73], "vishrav": [72, 73], "chaudhari": [72, 73], "guillaum": [72, 73], "wenzek": [72, 73], "francisco": [72, 73, 80], "guzman": 72, "edouard": [72, 73], "grave": [72, 73, 182], "5tb": [72, 73], "filter": [72, 73, 80, 93, 94, 109, 111, 112, 118, 154], "commoncrawl": [72, 73], "xlm_roberta_bas": 72, "xx": [72, 73, 82, 111], "multilingu": [72, 73], "doe": [72, 80, 93, 139, 141, 181, 182, 205, 208, 209], "abl": [72, 112, 162, 203], "determin": [72, 182], "correct": [72, 113, 115, 116, 127], "hundr": [72, 73], "terabyt": [72, 73], "dub": [72, 73], "r": [72, 73, 80, 178, 182], "mbert": [72, 73], "xnli": [72, 73], "mlqa": [72, 73], "particularli": [72, 73], "low": [72, 73, 113], "swahili": [72, 73], "urdu": [72, 73], "previou": [72, 73, 109, 182, 204], "factor": [72, 73, 74, 112, 113, 182], "capac": [72, 73, 109, 182], "dilut": [72, 73], "sacrif": [72, 73], "ri": [72, 73], "competit": [72, 73, 80], "strong": [72, 73], "05969233065843582": 72, "030789051204919815": 72, "04443822056055069": 72, "09564960747": 72, "038839809596538544": 72, "011712731793522835": 72, "019954433664679527": 72, "0667808502": 72, "03952755779027939": 72, "03455188870429993": 72, "019103847444057465": 72, "04311436787": 72, "09579929709434509": 72, "02494969218969345": 72, "014753809198737144": 72, "10259044915": 72, "004710011184215546": 72, "022148698568344116": 72, "011723337695002556": 72, "013356896": 72, "xlmrobertasentenceembed": 73, "guzm\u00e3": 73, "sent_xlm_roberta_bas": 73, "xlnetembed": 74, "autoregress": 74, "permut": 74, "addition": [74, 95, 102, 131, 140, 165], "emploi": 74, "xl": 74, "backbon": 74, "exhibit": 74, "involv": [74, 105], "sota": 74, "variou": [74, 198], "rank": [74, 113], "xlnet_large_cas": 74, "xlnet_base_cas": 74, "full": [74, 204], "zihangdai": 74, "denois": 74, "autoencod": 74, "corrupt": 74, "neglect": 74, "suffer": 74, "discrep": 74, "pro": 74, "con": 74, "enabl": [74, 75, 95, 115, 155, 179, 182], "maxim": [74, 113], "expect": [74, 125, 154, 180], "likelihood": 74, "overcom": 74, "formul": 74, "furthermor": 74, "integr": [74, 80, 111, 162, 182, 200, 202], "idea": [74, 182], "margin": 74, "6287205219268799": 74, "4865287244319916": 74, "186111718416214": 74, "234187275171279": 74, "1967450380325317": 74, "2746637463569641": 74, "9481253027915955": 74, "3431355059146881": 74, "0777631998062134": 74, "092679977416992": 74, "5331977605819702": 74, "11190271377563": 74, "8349916934967041": 74, "45627787709236145": 74, "7890847325325012": 74, "028069257736": 74, "134845569729805": 74, "11672890186309814": 74, "4945235550403595": 74, "66587203741073": 74, "entityrul": 75, "entityrulerapproach": 75, "exact": [75, 84, 89], "definit": [75, 191], "json": [75, 142, 162], "jsonl": 75, "setpatternsresourc": 75, "might": [75, 95, 127, 209], "setenablepatternregex": 75, "rule": [75, 88, 107, 122, 125], "person": [75, 192], "w": [75, 78, 88, 94, 97, 122, 125, 155, 182], "locat": [75, 104, 129, 155, 165, 204], "winterfel": 75, "j": [75, 182], "jon": 75, "snow": [75, 96, 113], "stark": 75, "eddard": 75, "patternsresourc": 75, "enablepatternregex": 75, "usestorag": 75, "rocksdb": 75, "lord": 75, "29": [75, 96, 194], "38": 75, "setusestorag": 75, "setsentencematch": 75, "setalphabetresourc": 75, "alphabet": [75, 97], "plain": [75, 210], "entityrulermodel": 75, "entity_rul": [76, 78], "graphextract": [77, 134], "graph": [77, 95, 111, 119, 134, 168, 183], "nerdlmodel": [77, 93, 94, 95, 96, 162, 200], "store": [77, 98, 99, 142, 146, 149, 160, 165, 182, 201], "node": [77, 182], "relev": [77, 80], "taken": 77, "implicitli": 77, "setmergeent": 77, "automat": [77, 80, 111, 115, 203, 204], "setdependencyparsermodel": 77, "settypeddependencyparsermodel": 77, "setrelationshiptyp": 77, "public": [77, 204], "relationshiptyp": 77, "pair": [77, 162, 180, 182], "entitytyp": 77, "explodeent": 77, "roottoken": 77, "travers": 77, "along": 77, "maxsentences": 77, "minsentences": 77, "below": [77, 209], "mergeent": 77, "merg": [77, 84, 89], "neighbor": 77, "includeedg": 77, "symbol": [77, 113, 127], "posmodel": 77, "coordin": [77, 104], "remoteloc": 77, "graphfinish": [77, 134], "rdf": [77, 134], "nertagg": [77, 94, 95, 96, 168, 183], "morn": [77, 134], "flight": [77, 134], "denver": [77, 134], "18": [77, 85, 87, 90, 93, 96, 139, 154, 165, 203], "path1": 77, "setentitytyp": 77, "setexplodeent": 77, "setroottoken": 77, "setmaxsentences": 77, "setminsentences": 77, "setmergeentitiesiobformat": 77, "iob": [77, 93, 94, 95], "iob2": [77, 93], "setincludeedg": 77, "setdelimit": [77, 90], "setposmodel": 77, "classifier_dl": [78, 155], "er": [78, 155], "keyword_extract": [78, 155], "yake_keyword_extract": [78, 79], "ld_dl": [78, 155], "language_detector_dl": [78, 81], "matcher": [78, 155], "big_text_match": [78, 86], "date_match": [78, 86], "multi_date_match": [78, 86], "regex_match": [78, 86], "text_match": [78, 86], "ner_approach": [78, 91], "ner_convert": [78, 91], "ner_crf": [78, 91], "ner_dl": [78, 91, 168, 183], "ner_overwrit": [78, 91], "param": [78, 94, 145, 146, 149, 155, 160, 161, 168, 183], "sentence_detector_dl": [78, 103, 111], "sentiment_detector": [78, 106], "vivekn_senti": [78, 106], "seq2seq": [78, 155], "gpt2_transform": [78, 110], "marian_transform": [78, 110], "t5_transform": [78, 110], "spell_check": [78, 155], "context_spell_check": [78, 114], "norvig_sweet": [78, 114], "symmetric_delet": [78, 114], "chunk_token": [78, 121], "recursive_token": [78, 121], "regex_token": [78, 121], "token2_chunk": [78, 121], "word_segment": [78, 126], "document_norm": [78, 155], "graph_extract": [78, 155], "lemmat": [78, 107, 118, 141, 143, 155], "n_gram_gener": [78, 155], "stemmer": [78, 118, 155], "stop_words_clean": [78, 155], "yakekeywordextract": 80, "yake": 80, "independ": [80, 115, 116, 122, 182], "domain": [80, 109], "individu": [80, 113], "organ": [80, 111], "grow": 80, "autom": 80, "adequ": 80, "manner": 80, "emerg": [80, 112], "tool": 80, "system": [80, 109, 182], "nor": 80, "thesauri": 80, "neither": 80, "corpora": [80, 84], "upon": 80, "thu": 80, "written": [80, 111], "benefici": 80, "plethora": 80, "situat": [80, 105], "access": 80, "restrict": 80, "therefor": [80, 179, 182, 208], "sent": 80, "boundari": [80, 104, 105, 108, 125], "detector": [80, 85, 107], "section": [80, 131, 140, 200, 202, 208], "tweakabl": 80, "greater": 80, "upper": 80, "bound": [80, 104, 105, 108], "minngram": 80, "maxngram": 80, "occurr": 80, "nkeyword": 80, "stopword": [80, 96, 118], "stop": [80, 94, 118], "campo": 80, "mangaravit": 80, "pasquali": 80, "jatowt": 80, "jorg": 80, "nune": 80, "2020": [80, 85, 87, 105], "scienc": [80, 201], "journal": 80, "elsevi": 80, "vol": 80, "509": 80, "pp": 80, "257": 80, "289": 80, "collect": [80, 162, 200], "turn": [80, 143, 182, 204], "come": 80, "term": [80, 180, 182], "fly": 80, "demand": 80, "abil": [80, 109], "within": [80, 102, 108, 109, 125, 130], "resort": 80, "alwai": [80, 112], "solut": 80, "articl": [80, 113], "rest": [80, 93], "merit": 80, "ten": 80, "experiment": 80, "carri": 80, "twenti": 80, "setcontextchar": [80, 125], "setminngram": 80, "setnkeyword": 80, "acquir": 80, "kaggl": 80, "platform": [80, 162, 202], "host": 80, "transact": 80, "somewhat": 80, "vagu": 80, "cloud": 80, "confer": 80, "week": [80, 85, 87, 120], "announc": [80, 96], "earli": 80, "tomorrow": [80, 85, 87], "phone": 80, "founder": 80, "ceo": 80, "anthoni": 80, "goldbloom": 80, "declin": 80, "deni": 80, "acquisit": 80, "happen": 80, "rumor": 80, "million": [80, 96, 109], "scientist": 80, "ben": 80, "hamner": 80, "2010": 80, "servic": [80, 111], "got": 80, "even": [80, 112], "few": [80, 125, 194, 210], "competitor": 80, "drivendata": 80, "topcod": 80, "hackerrank": 80, "stai": 80, "ahead": 80, "nich": 80, "home": [80, 155], "bui": [80, 192], "commun": 80, "mindshar": 80, "too": [80, 107, 203], "plenti": 80, "bit": [80, 105, 181, 209], "histori": [80, 105, 113], "earlier": 80, "month": [80, 85, 87, 194, 210], "team": [80, 111, 162, 200], "around": 80, "youtub": 80, "That": [80, 122, 162, 200, 205], "had": 80, "technologi": 80, "did": 80, "interest": 80, "kernel": [80, 178], "On": [80, 109, 111], "analyz": [80, 108], "compani": [80, 111], "script": 80, "centric": 80, "job": [80, 130], "board": [80, 102, 194], "unclear": 80, "accord": [80, 113, 191], "crunchbas": 80, "pitchbook": 80, "launch": 80, "investor": 80, "ventur": 80, "sv": 80, "angel": 80, "levchin": 80, "naravik": 80, "chie": 80, "economist": 80, "hal": 80, "varian": 80, "khosla": 80, "yuri": 80, "milner": 80, "resulttupl": 80, "ascend": 80, "orderbi": 80, "32051516486864573": 80, "37786450577630676": 80, "39922830978423146": 80, "40224744669493756": 80, "41584827825302534": 80, "setmaxngram": 80, "setstopword": [80, 96, 118], "getstopword": 80, "loaddefaultstopword": [80, 118], "danish": [80, 118], "dutch": [80, 118], "finnish": [80, 118], "german": [80, 118, 191, 210], "hungarian": [80, 118], "italian": [80, 113, 118], "norwegian": [80, 118], "portugues": [80, 118], "russian": [80, 118], "spanish": [80, 118], "swedish": [80, 118], "turkish": [80, 118], "languagedetectordl": 82, "ld": 82, "identif": 82, "rnn": [82, 169, 176, 177, 179, 180, 182], "tatoeba": 82, "140": 82, "wiki": 82, "languagedetector": 82, "ld_wiki_tatoeba_cnn_21": 82, "open": [82, 125, 130, 131, 132, 140, 143, 201], "advanc": [82, 130, 143], "scala": [82, 144, 145, 151, 157, 161], "program": 82, "biblioth\u00e8qu": 82, "traitement": 82, "pour": 82, "le": [82, 111, 182], "avanc\u00e9": 82, "langag": 82, "naturel": 82, "programm": 82, "ist": 82, "ein": 82, "textverarbeitungsbibliothek": 82, "f\u00fcr": 82, "fortgeschritten": 82, "nat\u00fcrlich": 82, "sprachverarbeitung": 82, "die": 82, "programmiersprachen": 82, "und": 82, "lemma": [83, 107, 139, 165, 192, 205, 208, 209], "predefin": [83, 84, 88, 89, 107], "setdictionari": [83, 107, 115, 116], "lemmatizermodel": 83, "lemmas_smal": [83, 107], "setformcol": 83, "correspend": 83, "formcol": [83, 192], "setlemmacol": 83, "fromlemma": 83, "key_delimit": 83, "value_delimit": 83, "lemma_antbnc": 83, "bigtextmatch": [84, 89], "textmatch": [84, 89, 120], "externalresourc": [84, 89, 153], "mergeoverlap": [84, 89], "overlap": [84, 89], "tokenizermodel": [84, 125], "trie": 84, "dolor": [84, 89], "magna": [84, 89], "aliqua": [84, 89], "sit": [84, 89], "laborum": [84, 89], "hello": [84, 89, 120], "entityextractor": [84, 89, 120], "extractor": [84, 89, 120], "53": [84, 89], "59": [84, 85, 87, 89], "setent": [84, 89, 92, 120], "setmergeoverlap": [84, 89], "settoken": 84, "tokenizer_model": 84, "bigtextmatchermodel": 84, "btm": 84, "textmatchermodel": [84, 89], "searchtri": 84, "datematch": 85, "datematcherutil": 85, "setinputformat": [85, 142], "setoutputformat": [85, 87], "desir": [85, 87], "yyyi": [85, 87], "mm": [85, 87], "dd": [85, 87], "Not": [85, 95, 141], "setreadmonthfirst": 85, "juli": 85, "5th": 85, "2015": [85, 182], "07": 85, "05": 85, "setdefaultdaywhenmiss": 85, "dai": [85, 87, 113], "miss": [85, 87, 130], "setanchordateyear": [85, 87], "anchor": [85, 87], "year": [85, 87, 109, 120, 194], "2021": [85, 87], "setanchordatemonth": [85, 87], "januari": [85, 87], "setanchordatedai": [85, 87], "multidatematch": [85, 87], "1978": [85, 87], "01": [85, 87], "28": [85, 87, 93, 139, 154, 165, 203], "1984": [85, 87], "04": [85, 87], "02": [85, 87], "1980": [85, 87], "79": [85, 87], "31st": [85, 87], "april": [85, 87], "2008": [85, 87], "fri": [85, 87], "nov": [85, 87, 194], "1997": [85, 87], "jan": [85, 87], "sun": [85, 87], "1st": [85, 87], "thursdai": [85, 87], "wednesdai": [85, 87], "todai": [85, 87], "yesterdai": [85, 87], "0600h": [85, 87], "06": [85, 87], "00": [85, 87], "hour": [85, 87], "6pm": [85, 87], "23": [85, 87, 88, 96, 102, 194, 195, 210], "1988": [85, 87], "31": [85, 87, 88, 96, 102, 194], "dateformat": [85, 87], "readmonthfirst": [85, 87], "defaultdaywhenmiss": [85, 87], "anchordateyear": [85, 87], "anchordatemonth": [85, 87], "anchordatedai": [85, 87], "15": [85, 179], "saw": 87, "him": 87, "me": 87, "visit": 87, "57": [87, 96], "65": [87, 96], "regexmatch": 88, "setexternalrul": 88, "match_first": 88, "match_al": 88, "match_complet": 88, "externalrul": 88, "ceremoni": 88, "setstrategi": 88, "71": 88, "regexmatchermodel": 88, "regardless": 89, "entityvalu": 89, "buildfromtoken": 89, "27": [89, 102, 104, 194], "48": 89, "setentityvalu": 89, "setbuildfromtoken": 89, "null": 90, "empti": [90, 130, 181], "enablecumul": 90, "actual": [90, 129, 133, 143, 181], "join": [90, 102, 142, 194], "19": [90, 194], "setenablecumul": 90, "nerapproach": 92, "recogn": [92, 93, 94, 95, 96], "setminepoch": [92, 94], "setrandomse": [92, 95, 98, 168, 183], "getlabelcolumn": [92, 119], "friendli": [93, 111], "whitelist": [93, 122], "setwhitelist": [93, 122], "outsid": 93, "prefix": [93, 122, 125, 162, 200], "continu": [93, 109, 134, 182, 200], "org": [93, 94, 95, 96, 139, 154, 155, 165, 178, 180, 181, 182, 191, 201, 210], "14": [93, 102, 124, 139, 154, 165, 194], "ekeu": [93, 94, 95, 139, 154, 165], "26": [93, 139, 154, 165], "36": [93, 102, 139, 154, 165, 194], "baghdad": [93, 94, 95, 139, 154, 165], "37": [93, 139, 154, 165], "nercrf": 94, "nercrfapproach": [94, 95], "nercrfmodel": [94, 95], "crf": [94, 95], "2003": [94, 95, 191, 210], "exclud": [94, 95], "setexternalfeatur": 94, "minepoch": [94, 95], "l2": 94, "c0": 94, "decai": [94, 95], "gradient": 94, "2250000": 94, "lossep": 94, "ep": 94, "minw": 94, "includeconfid": [94, 95], "confid": [94, 95], "externalfeatur": 94, "nerdlapproach": [94, 95, 183, 191, 210], "trainingdata": [94, 95, 105, 115, 116, 191], "readdataset": [94, 95, 102, 127, 191, 192, 194, 195, 210], "conll2003": [94, 95, 191, 210], "eng": [94, 95, 191, 210], "setl2": 94, "l2valu": 94, "setc0": 94, "c0valu": 94, "setlossep": 94, "setminw": 94, "setincludeconfid": [94, 95, 168, 183], "verbosevalu": 94, "prerequisit": [94, 95, 96, 204], "nerdl": 95, "char": [95, 97, 105], "bilstm": 95, "50": [95, 96, 102, 109, 182], "real": [95, 155, 162, 182, 200], "rage": 95, "graphfold": 95, "usecontrib": 95, "contrib": [95, 177, 179], "cell": [95, 142, 176, 177, 178, 180, 181, 182], "slightli": [95, 105], "evaluationlogextend": 95, "testdataset": [95, 162, 200], "includeallconfidencescor": 95, "enablememoryoptim": 95, "slow": 95, "down": [95, 204, 205], "usebestmodel": 95, "bestmodelmetr": 95, "check": [95, 104, 113, 114, 115, 116, 139, 143, 165], "micro": 95, "macro": 95, "metric": [95, 116, 162], "setgraphfold": [95, 119, 168, 183], "setusecontrib": 95, "setpo": 95, "setincludeallconfidencescor": 95, "setenablememoryoptim": [95, 168, 183], "setusebestmodel": 95, "monitor": [95, 162, 200], "setbestmodelmetr": 95, "nermodel": 95, "neroverwrit": 96, "overwrit": [96, 162], "specifi": [96, 105, 180, 182, 191, 192], "setnewresult": 96, "nerword": 96, "overwritten": 96, "newnerent": 96, "lab": 96, "42": [96, 102], "45": [96, 102, 194], "47": [96, 194], "66": 96, "ner_overwritten": 96, "setnerword": 96, "setnewnerent": 96, "cardin": 96, "setreplaceent": 96, "rw": 96, "stem": [97, 117, 139, 165, 208, 209], "henc": [97, 182], "pl": 97, "slangdictionari": 97, "slang": 97, "minlength": [97, 104, 105, 123, 125], "maxlength": [97, 104, 105, 123, 125], "setcleanuppattern": 97, "d": [97, 125, 180, 182, 202], "punctuat": [97, 104], "alphanumer": 97, "letter": [97, 109, 113, 194, 210], "za": 97, "z": [97, 125], "brother": 97, "dont": [97, 108], "setslangdictionari": 97, "setminlength": [97, 104, 105, 123, 125], "setmaxlength": [97, 104, 105, 123, 125], "normalizermodel": 97, "classifierencod": 98, "attach": [98, 99, 146, 149, 160, 162], "evaluationdlparam": 99, "setevaluationlogextend": [99, 168, 183], "setenableoutputlog": [99, 162, 168, 183, 200], "setoutputlogspath": [99, 105, 162, 168, 183, 200], "settestdataset": 99, "parquet": [99, 128], "perceptronapproach": [102, 194, 210], "datasetpath": 102, "pierr": [102, 194], "vinken": [102, 194], "34": [102, 194], "md": [102, 194], "vb": [102, 191, 194, 210], "41": [102, 104, 194], "43": [102, 104, 194], "dt": [102, 194, 195, 210], "49": [102, 194], "poscol": [102, 127, 191], "niter": [102, 127], "anc": [102, 194, 210], "trainingperceptrondf": 102, "trainedpo": 102, "setposcolumn": [102, 127], "cd": [102, 191, 194], "setiter": 102, "getniter": [102, 127], "pos_anc": 102, "25": [102, 104, 194], "33": 102, "sentencedetectorparam": 104, "ii": 104, "abbrevi": 104, "period": 104, "geo": 104, "1026": 104, "253": 104, "553": 104, "ellipsi": 104, "quotat": 104, "mark": [104, 105, 127, 182], "exclam": 104, "breaker": 104, "explicit": [104, 109], "pragmaticcontentformatt": 104, "custombound": [104, 105], "setcustombound": [104, 105], "usecustomboundsonli": [104, 105], "explodesent": [104, 105, 191, 192], "useabbrevi": 104, "explicitli": [104, 105, 118, 154, 204], "customboundsstrategi": 104, "prepend": [104, 130], "break": 104, "append": [104, 113, 204], "parallel": [104, 105, 139, 181, 191, 208], "splitlength": [104, 105], "forcibli": [104, 105], "split": [104, 105, 120, 122, 123, 127, 176, 182], "99999": [104, 105, 125], "detectlist": 104, "nhow": 104, "setcustomboundsstrategi": 104, "setuseabbrevi": 104, "setdetectlist": 104, "setusecustomboundsonli": [104, 105], "setexplodesent": [104, 105], "setsplitlength": [104, 105], "sentencedetectordl": 105, "sentencedetectordlapproach": 105, "futur": [105, 112], "setmodel": 105, "sentencedetectordlmodel": [105, 111], "modelarchitectur": 105, "impossiblepenultim": 105, "imposs": [105, 127], "penultim": 105, "epochsnumb": 105, "eo": 105, "stefan": 105, "schweter": 105, "sajawel": 105, "ahm": 105, "littl": [105, 209], "cover": [105, 112, 127], "broken": 105, "moder": 105, "lack": 105, "easier": [105, 133, 206, 210], "polit": 105, "successor": 105, "great": 105, "respons": 105, "heritag": 105, "bequeath": 105, "nelson": 105, "mandela": 105, "setepochsnumb": 105, "model_architectur": 105, "validation_split": 105, "epochs_numb": 105, "output_logs_path": 105, "setimpossiblepenultim": 105, "impossible_penultim": 105, "sentencedl": 105, "sentencesdl": 105, "helen": 105, "total": [105, 127], "peopl": 105, "sentimentdetector": 107, "By": [107, 112, 118, 123, 132, 155, 162, 200], "viveknsentimentapproach": [107, 108], "cool": 107, "superb": 107, "uninspir": 107, "sentimentscor": 107, "staff": 107, "restaur": 107, "nice": [107, 162, 200], "avoid": [107, 181, 182], "entri": [107, 131, 140], "sttr": 107, "sentimentdetectormodel": 107, "sda": [107, 108], "pragmat": 107, "viveknsenti": 108, "analys": 108, "inspir": [108, 115, 116, 158], "vivek": 108, "narayanan": 108, "give": 108, "transit": [108, 113], "sentimentcol": 108, "prunecorpu": 108, "unfrequ": 108, "scenario": 108, "naiv": 108, "bay": 108, "vivekn": 108, "setsentimentcol": 108, "train_senti": 108, "result_senti": 108, "finish": [108, 132, 134, 138, 141, 155], "final_senti": 108, "cast": [108, 128], "horribl": 108, "never": [108, 204], "go": [108, 204], "again": [108, 122], "anyon": 108, "protagonist": 108, "music": 108, "setprunecorpu": 108, "frequenc": [108, 113, 115, 116, 127, 182], "viveknsentimentmodel": 108, "sentiment_vivekn": 108, "gpt2transform": 109, "gpt2": 109, "openai": 109, "caus": [109, 125], "goal": 109, "occur": [109, 112], "direct": [109, 181, 182], "10x": 109, "broad": 109, "synthet": 109, "sampl": [109, 112], "unpreced": 109, "qualiti": 109, "prime": 109, "lengthi": 109, "translat": [109, 111, 112], "far": [109, 129, 133], "suggest": 109, "benefit": 109, "suffici": 109, "minoutputlength": [109, 112], "maxoutputlength": [109, 111, 112], "dosampl": [109, 112], "greedi": [109, 112], "temperatur": [109, 112], "topk": [109, 112], "highest": [109, 112, 115], "k": [109, 112, 132, 182], "topp": [109, 112], "cumul": [109, 112], "kept": [109, 112], "repetitionpenalti": [109, 112], "repetit": [109, 112], "penalti": [109, 112, 181], "norepeatngrams": [109, 112], "onc": [109, 112, 177], "ignoretokenid": [109, 112], "especi": [109, 111, 112], "multitask": 109, "learner": 109, "typic": [109, 181], "taskspecif": 109, "webpag": [109, 201], "webtext": 109, "plu": 109, "coqa": 109, "exceed": 109, "127": 109, "shot": 109, "fashion": 109, "5b": 109, "still": [109, 162], "underfit": 109, "reflect": 109, "paragraph": 109, "promis": 109, "toward": 109, "setmaxoutputlength": [109, 111, 112], "leonardo": 109, "man": 109, "1776": 109, "came": 109, "unit": [109, 119, 180, 182], "kingdom": 109, "settask": [109, 112], "setignoretokenid": [109, 111, 112], "setminoutputlength": [109, 112], "setdosampl": [109, 112], "settemperatur": [109, 112], "settopk": [109, 112], "settopp": [109, 112], "setrepetitionpenalti": [109, 112], "ctrl": [109, 112], "control": [109, 111, 112, 113, 182], "setnorepeatngrams": [109, 112], "mariantransform": 111, "marian": 111, "free": [111, 182], "mainli": 111, "academ": 111, "notabl": 111, "edinburgh": 111, "past": 111, "adam": 111, "mickiewicz": 111, "pozna\u0144": 111, "commerci": 111, "contributor": 111, "mariannmt": 111, "engin": [111, 120], "behind": 111, "deploi": [111, 201], "opus_mt_en_fr": 111, "langid": 111, "maxinputlength": 111, "differenti": 111, "dynam": [111, 181, 182], "toolkit": 111, "setmaxinputlength": 111, "capit": [111, 113], "franc": 111, "quell": 111, "capital": 111, "devrait": 111, "savoir": 111, "fran\u00e7ai": 111, "setlangid": 111, "t5transform": 112, "t5": 112, "reconsid": 112, "unifi": 112, "hyper": 112, "t5_small": 112, "explor": 112, "rich": 112, "rise": 112, "methodologi": 112, "landscap": 112, "systemat": 112, "dozen": 112, "insight": 112, "coloss": 112, "facilit": 112, "200": [112, 168, 182, 183], "contextspellcheck": 113, "contextspellcheckerapproach": [113, 115, 116], "noisi": 113, "spell": [113, 114, 115, 116, 139, 143, 207, 208, 209], "candid": [113, 115, 116, 125], "contextspellcheckermodel": [113, 115, 116], "potenti": 113, "error": [113, 182], "three": [113, 124], "thing": [113, 129, 133], "surround": [113, 142], "edit": [113, 115, 116], "subword": 113, "checker": [113, 115, 116, 207], "languagemodelclass": 113, "lm": 113, "wordmaxdist": 113, "maxcandid": 113, "casestrategi": 113, "try": [113, 129], "uppercas": 113, "errorthreshold": 113, "perplex": 113, "nlm": 113, "initialr": 113, "finalr": 113, "validationfract": 113, "datapoint": 113, "min": 113, "vocab": 113, "compoundcount": 113, "compound": 113, "classcount": 113, "special": [113, 156, 205], "tradeoff": 113, "weighteddistpath": 113, "levenshtein": [113, 115, 116], "maxwindowlen": 113, "rememb": 113, "norvigsweetingapproach": [113, 115, 116, 210], "symmetricdeleteapproach": [113, 115, 116, 210], "depth": [113, 181, 182, 207], "explan": [113, 207], "awar": 113, "sherlock": 113, "holm": 113, "spellcheck": [113, 115, 116], "setwordmaxdist": 113, "setepoch": 113, "setlanguagemodelclass": 113, "1650": 113, "addvocabclass": 113, "_name_": 113, "extra": [113, 115, 204], "dist": 113, "setmaxcandid": 113, "setcasestrategi": 113, "seterrorthreshold": 113, "setinitialr": 113, "setfinalr": 113, "setvalidationfract": 113, "fraction": 113, "setcompoundcount": 113, "setclasscount": 113, "settradeoff": 113, "alpha": 113, "setweighteddistpath": 113, "setmaxwindowlen": 113, "userdist": 113, "addregexclass": 113, "spellcheck_dl": 113, "gamma": 113, "influenc": 113, "decis": 113, "correctsymbol": 113, "comparelowcas": 113, "norvigsweetingmodel": [113, 115, 116], "symmetricdeletemodel": [113, 115, 116], "doc": [113, 195, 210], "cold": 113, "dreari": 113, "countri": 113, "white": 113, "smow": 113, "setweight": 113, "setgamma": 113, "getwordclass": 113, "updateregexclass": 113, "updat": [113, 182], "updatevocabclass": 113, "setcorrectsymbol": 113, "setcomparelowcas": 113, "norvigsweet": 115, "norvig": 115, "bayesian": 115, "tokenpattern": 115, "sensit": [115, 118, 125], "doublevari": 115, "search": [115, 182], "shortcircuit": 115, "frequencyprior": 115, "ham": 115, "intersect": [115, 182], "prioriti": [115, 125], "wordsizeignor": 115, "dupslimit": 115, "duplic": 115, "reductlimit": 115, "attempt": 115, "vowelswaplimit": 115, "vowel": 115, "swap": [115, 181], "corrector": 115, "gummi": [115, 116], "gummic": [115, 116], "gummier": [115, 116], "gummiest": [115, 116], "gummifer": [115, 116], "basi": [115, 116], "token_pattern": [115, 116], "setdoublevari": 115, "setshortcircuit": 115, "setfrequencyprior": 115, "symmetr": [115, 116], "delet": [115, 116, 204], "damerau": [115, 116], "magnitud": [115, 116], "transpos": [115, 116, 181], "insert": [115, 116, 204], "spellcheck_norvig": 115, "symspel": [115, 116], "somtim": 115, "wrrite": [115, 116], "wordz": [115, 116], "erong": [115, 116], "sometim": [115, 116, 204], "wrong": [115, 116], "symmetricdelet": 116, "deriv": 116, "teach": 116, "maxeditdist": 116, "frequencythreshold": [116, 127], "deletesthreshold": 116, "patttern": 116, "setmaxeditdist": 116, "setfrequencythreshold": [116, 127], "setdeletesthreshold": 116, "spellcheck_sd": 116, "spmetim": 116, "hard": 117, "employ": 117, "stopwordsclean": [118, 132, 143], "mllib": [118, 201], "stopwordsremov": 118, "cleantoken": [118, 132, 143], "stopwords_en": 118, "jvm": 118, "forth": 118, "setlocal": 118, "tfnerdlgraphbuildermodel": 119, "tfnerdlgraphbuild": 119, "sethiddenunitsnumb": 119, "assertiondlapproach": 119, "medicalnerapproach": [119, 168, 183], "gethiddenunitsnumb": 119, "getinputcol": [119, 146], "srt": 119, "getgraphfold": 119, "setgraphfil": 119, "greaph": 119, "auto": [119, 168, 183], "getgraphfil": 119, "chunktoken": 120, "flatten": 120, "artist": 120, "benezar": 120, "robert": 120, "farendel": 120, "graduat": 120, "luca": 120, "chunktokenizermodel": 120, "recursivetoken": 122, "recurs": [122, 141, 151, 155, 159], "hand": 122, "suffix": [122, 125, 204], "infix": [122, 125], "middl": 122, "she": 122, "qam": 122, "setprefix": 122, "setsuffix": 122, "setinfix": 122, "recursivetokenizermodel": 122, "regextoken": [123, 205], "whitespac": [123, 127, 130], "tolowercas": 123, "positionalmask": 123, "guarante": 123, "increment": 123, "trimwhitespac": 123, "flag": [123, 182], "preserveposit": [123, 143], "eventu": 123, "settolowercas": 123, "nthi": 123, "setpositionalmask": 123, "settrimwhitespac": 123, "setpreserveposit": [123, 143], "token2chunk": 124, "17": [124, 194], "tokenizedsent": 125, "non": [125, 127, 168, 182, 183], "rulefactori": 125, "targetpattern": 125, "grab": 125, "prefixpattern": 125, "suffixpattern": 125, "infixpattern": 125, "sub": [125, 182], "won": 125, "exceptionspath": 125, "casesensitiveexcept": 125, "contextchar": 125, "splitpattern": 125, "splitchar": 125, "didn": 125, "jane": 125, "boyfriend": 125, "getinfixpattern": 125, "getsuffixpattern": 125, "getprefixpattern": 125, "getcontextchar": 125, "getsplitchar": 125, "settargetpattern": 125, "setprefixpattern": 125, "setsuffixpattern": 125, "setinfixpattern": 125, "addinfixpattern": 125, "setexcept": 125, "getexcept": 125, "setexceptionspath": 125, "addexcept": 125, "setcasesensitiveexcept": 125, "getcasesensitiveexcept": 125, "addcontextchar": 125, "setsplitpattern": 125, "setsplitchar": 125, "addsplitchar": 125, "piec": 125, "token_rul": 125, "wordsegment": 127, "wordsegmenterapproach": 127, "korean": 127, "japanes": 127, "chines": 127, "correspond": [127, 162, 181], "wordsegmentermodel": 127, "tip": 127, "frame": 127, "least": 127, "frequent": 127, "ambiguitythreshold": 127, "chinese_train": 127, "utf8": 127, "\u5341": 127, "ll": 127, "\u56db": 127, "rr": 127, "\u4e0d": 127, "\u662f": 127, "setniter": 127, "trainingdataset": 127, "setambiguitythreshold": 127, "getfrequencythreshold": 127, "getambiguitythreshold": 127, "plit": 127, "words_seg": 127, "wordseg_pku": 127, "zh": 127, "\u7136\u800c": 127, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 127, "\u9019\u6a23": 127, "\u7684": 127, "\u8655\u7406": 127, "\u4e5f": 127, "\u884d\u751f": 127, "\u4e86": 127, "\u4e00\u4e9b": 127, "\u554f\u984c": 127, "prepar": [128, 131, 137, 140], "outputcol": [128, 131, 132, 133, 134, 137, 140], "inferschema": 128, "tmp": [128, 137, 155, 200], "librispeech_asr_dummy_clean_audio_array_parquet": 128, "float_arrai": 128, "chunk2doc": [129, 130], "back": [129, 181], "re": [129, 204], "doc2chunk": [129, 130], "pretrainedpipelin": [129, 133, 139, 154, 165, 203, 208, 209], "york": [129, 133], "jersei": [129, 133], "aren": [129, 133], "amongst": [129, 133], "explain_document_dl": [129, 133, 139, 154, 165], "chunktodoc": 129, "chunkconvert": 129, "explainresult": [129, 133], "22": [129, 133, 191, 203], "chunkcol": 130, "stringtyp": 130, "setisarrai": 130, "startcol": 130, "startcolbytokenindex": 130, "isarrai": 130, "failonmiss": 130, "fail": 130, "chunkassembl": 130, "setchunkcol": 130, "setstartcol": 130, "setstartcolbytokenindex": 130, "setfailonmiss": 130, "disabl": [131, 140], "idcol": [131, 140], "metadatacol": [131, 140], "cleanupmod": [131, 140], "cleanup": [131, 140], "inplac": [131, 140], "inplace_ful": [131, 140], "shrink_ful": [131, 140], "each_ful": [131, 140], "delete_ful": [131, 140], "51": [131, 140, 194], "setidcol": [131, 140], "setmetadatacol": [131, 140], "usabl": 132, "lda": 132, "forest": 132, "featurecol": 132, "cleanannot": [132, 133, 134], "outputasvector": 132, "gloveembed": 132, "finished_sentence_embed": 132, "resultwiths": 132, "1619900017976761": 132, "045552998781204224": 132, "03229299932718277": 132, "685609996318": 132, "42416998744010925": 132, "1378999948501587": 132, "5717899799346924": 132, "5078899860382": 132, "08621499687433243": 132, "15772999823093414": 132, "06067200005054474": 132, "395359992980": 132, "4970499873161316": 132, "7164199948310852": 132, "40119001269340515": 132, "05761000141501": 132, "08170200139284134": 132, "7159299850463867": 132, "20677000284194946": 132, "0295659992843": 132, "valuesplitsymbol": 133, "annotationsplitsymbol": 133, "includemetadata": 133, "outputasarrai": [133, 134], "parseembeddingsvector": 133, "setvaluesplitsymbol": 133, "setannotationsplitsymbol": 133, "setincludemetadata": [133, 205], "setoutputasarrai": [133, 134], "setparseembeddingsvector": 133, "finishedresult": 134, "hasrecursivefit": [135, 136], "java_obj": [135, 158, 161], "py4j": [135, 136, 161], "java_gatewai": [135, 136, 161], "javaobject": [135, 136, 161], "recursivepipelin": [135, 136, 141, 146], "hasrecursivetransform": 136, "chunk2_doc": [138, 155], "doc2_chunk": [138, 155], "embeddings_finish": [138, 155], "graph_finish": [138, 155], "has_recursive_fit": [138, 155], "has_recursive_transform": [138, 155], "light_pipelin": [138, 155], "recursive_pipelin": [138, 155], "token_assembl": [138, 155], "lightpipelin": [139, 165, 208], "parse_embed": [139, 165], "equival": [139, 155, 208], "execut": [139, 182, 204, 208], "hold": [139, 208], "principl": [139, 208], "everyth": [139, 208, 209], "deal": [139, 208], "fullannot": [139, 165], "happi": [139, 203, 205, 208, 209], "prp": [139, 192, 194, 203, 208, 209, 210], "rb": [139, 168, 183, 194, 203, 208, 209, 210], "optional_target": 139, "explain_document_pipelin": [139, 154, 165, 203, 208, 209], "dict_kei": [139, 165], "fullannotateimag": 139, "path_to_imag": 139, "setignoreunsupport": 139, "unsupport": 139, "annotatormodel": [139, 145], "getignoreunsupport": 139, "calculationscol": 140, "text2": 140, "document1": 140, "document2": 140, "kwarg": [141, 182], "decid": 141, "advantag": 141, "behav": 141, "exactli": 141, "intent": 141, "recursivepipelinemodel": 141, "pipeline_model": [141, 162, 200], "intend": 141, "tab": [142, 162, 200], "escap": 142, "quot": 142, "inputformat": 142, "csvdelimit": 142, "defailt": 142, "comma": 142, "escapecsvdelimit": 142, "table_csv": 142, "csv_data": 142, "118": 142, "input_format": 142, "setcsvdelimit": 142, "setescapecsvdelimit": 142, "tokenassembl": 143, "reconstruct": 143, "cleantext": 143, "opensourc": 143, "annotatorapproach": [144, 151, 162], "subclass": [145, 157, 161, 177, 180], "ins": [145, 161], "uid": [145, 161], "annotatorproperti": 146, "getoutputcol": 146, "setlazyannot": 146, "lazili": 146, "getlazyannot": 146, "annotator_approach": [148, 155], "annotator_model": [148, 155], "annotator_properti": [148, 155], "coverage_result": [148, 155], "recursive_annotator_approach": [148, 155], "hasembeddingsproperti": 149, "getdimens": 149, "constant": 150, "recursiveannotatorapproach": 151, "handl": [152, 193], "fo": 153, "assist": 154, "map_annot": 154, "f": [154, 162, 200], "output_typ": 154, "udf": 154, "userdefinedfunct": 154, "def": 154, "nnp_token": 154, "lambda": 154, "alia": 154, "epeu": 154, "map_annotations_arrai": 154, "map_annotations_strict": 154, "map_annotations_col": 154, "output_column": 154, "annotatyon_typ": 154, "chunks_df": 154, "pos_chunk": 154, "vbz": [154, 191, 210], "filter_by_annotations_col": 154, "filter_po": 154, "explode_annotations_col": 154, "annotator_java_ml": [155, 159], "annotator_transform": [155, 159], "extended_java_wrapp": [155, 159], "params_getters_sett": [155, 159], "comet": [155, 163, 202], "pretrained_pipelin": [155, 164], "resource_download": [155, 164], "pub_tat": [155, 193], "annotation_audio": 155, "annotation_imag": 155, "aarch64": 155, "cache_fold": 155, "log_fold": 155, "cluster_tmp_dir": 155, "real_time_output": 155, "output_level": 155, "correctli": 155, "maco": 155, "linux": 155, "alloc": 155, "directori": [155, 200], "cache_pretrain": 155, "temporarili": 155, "unpack": 155, "hadoop": 155, "dir": 155, "s3": 155, "hdf": 155, "dbf": 155, "annotator_log": 155, "annotatorjavamlread": 156, "mixin": 156, "javamlread": 156, "classmethod": 156, "mlreader": 156, "clazz": 156, "rl": 156, "javaparam": 156, "annotatortransform": 157, "ensur": 157, "_java_obj": 157, "extens": 158, "javawrapp": 158, "extendedjavawrapp": 158, "new_java_arrai": 158, "pylist": 158, "java_class": 158, "todo": 158, "chang": [158, 179, 182], "paramsgetterssett": 160, "getparamvalu": 160, "paramnam": 160, "setparamvalu": 160, "recursiveestim": 161, "tupl": [161, 180, 181, 182], "overrid": 161, "recursivetransform": 161, "cometlogg": [162, 200], "workspac": 162, "project_nam": [162, 200], "comet_mod": [162, 200], "experiment_id": 162, "experiment_kwarg": 162, "logger": [162, 200], "meta": [162, 202], "ai": [162, 200], "practition": [162, 200], "reliabl": [162, 200], "streamlin": [162, 200], "lifecycl": [162, 200, 202], "track": [162, 200, 201], "explain": [162, 200, 207, 209], "reproduc": [162, 200, 201], "outputlogpath": [162, 200], "offlin": 162, "onlin": [162, 182, 200], "reus": [162, 176, 178, 180, 182], "importerror": 162, "output_log_path": [162, 200], "embd": [162, 200], "setshuffleperepoch": [162, 200], "logdir": [162, 200], "interfac": [162, 200, 208], "chart": [162, 200], "comet_ml": [162, 200], "log_pipeline_paramet": [162, 200], "log_visu": [162, 200], "html": [162, 200], "viz": [162, 200], "upload": 162, "visual": 162, "colum": [162, 200], "ner_chunk": [162, 200], "sparknlp_displai": [162, 200], "nervisu": [162, 200], "idx": [162, 200], "enumer": [162, 200], "label_col": [162, 200], "document_col": [162, 200], "return_html": [162, 200], "log_metr": [162, 200], "sklearn": [162, 200], "preprocess": [162, 200], "multilabelbinar": [162, 200], "classification_report": [162, 200], "preds_df": [162, 200], "topanda": [162, 200], "mlb": [162, 200], "y_true": [162, 200], "fit_transform": [162, 200], "y_pred": [162, 200], "output_dict": [162, 200], "log_paramet": 162, "log_completed_run": 162, "log_file_path": 162, "complet": [162, 201], "log_asset": 162, "asset_path": 162, "asset": 162, "log_asset_data": 162, "interv": 162, "refresh": 162, "outstand": 162, "disk_loc": 165, "fulli": 165, "light_model": 165, "gather": 165, "langaug": 165, "resourcedownload": 166, "wrongtfvers": [168, 183], "exit": [168, 183], "tensorflowaddonsneed": 168, "tfgraphbuild": [168, 183], "build_param": [168, 183], "generic_classifi": [168, 183], "assertion_dl": [168, 183], "relation_extract": [168, 183], "healthcar": [168, 183], "tfgraph": [168, 183], "tf_graph": [168, 183], "get_model": [168, 183], "nertfgraphbuild": [168, 183], "feat_siz": [168, 183], "n_class": [168, 183], "embeddings_dim": [168, 183], "nchar": [168, 183], "ntag": [168, 183], "model_loc": [168, 183], "medical_ner_graph": [168, 183], "model_filenam": [168, 183], "ner_log": [168, 183], "tfgraphbuilderfactori": [168, 183], "factori": [168, 183], "model_nam": [168, 183], "filenam": [168, 183], "ner_graph": [168, 183], "print_model_param": [168, 183], "sparknlp_jsl": 168, "tf2contrib": 169, "core_rnn_cel": [169, 179], "fused_rnn_cel": [169, 179], "gru_op": [169, 179], "lstm_op": [169, 179], "rnn_cell": [169, 177, 179], "core": 176, "embeddingwrapp": 176, "inputprojectionwrapp": 176, "outputprojectionwrapp": 176, "embedding_class": 176, "embedding_s": 176, "num_proj": [176, 182], "input_s": [176, 180, 181, 182], "output_s": [176, 180], "fuse": 177, "fusedrnncel": [177, 180], "expand": 177, "recurr": [177, 180, 181, 182], "rnncell": [177, 181, 182], "flexibl": 177, "__call__": 177, "signatur": 177, "fusedrnncelladaptor": 177, "use_dynamic_rnn": 177, "adaptor": 177, "timereversedfusedrnn": 177, "revers": 177, "basicrnncel": 177, "fw_lstm": 177, "bw_lstm": 177, "fw_out": 177, "fw_state": 177, "bw_out": 177, "bw_state": 177, "grublockcel": 178, "num_unit": [178, 180, 182], "cell_siz": 178, "gru_cel": 178, "deprec": 178, "grublockcellv2": 178, "ab": [178, 180, 181, 182], "1406": [178, 182], "1078": [178, 182], "forward": [178, 181], "propag": [178, 182], "mathemat": 178, "equat": [178, 182], "b_ru": 178, "constant_initi": 178, "b_c": 178, "x_h_prev": 178, "h_prev": 178, "r_bar": 178, "u_bar": 178, "w_ru": 178, "h_prevr": 178, "circ": [178, 182], "x_h_prevr": 178, "c_bar": 178, "w_c": [178, 182], "tanh": [178, 182], "h": [178, 182], "temporari": 178, "impl": 178, "input_shap": [178, 182], "blob": 179, "r1": 179, "lstmblockcel": 180, "forget_bia": [180, 182], "cell_clip": [180, 182], "use_peephol": [180, 182], "dtype": [180, 181, 182], "lstm_cell": 180, "1409": 180, "2329": 180, "forget": [180, 182], "gate": [180, 182], "rnn_cell_impl": [180, 182], "lstmcell": [180, 182], "monolith": 180, "short": [180, 182], "lstmblockwrapp": 180, "housekeep": 180, "_call_cel": 180, "initial_st": 180, "sequence_length": [180, 181], "time_len": 180, "initial_cell_st": 180, "initial_output": 180, "_num_unit": 180, "heterogen": 180, "int32": [180, 181], "int64": [180, 181], "cell_stat": 180, "valueerror": [180, 181, 182], "mismatch": 180, "lstmblockfusedcel": 180, "lstm_fused_cel": 180, "extrem": 180, "stack_bidirectional_rnn": 181, "cells_fw": 181, "cells_bw": 181, "initial_states_fw": 181, "initial_states_bw": 181, "stack": [181, 182], "sever": [181, 210], "backward": 181, "bidirectional_rnn": 181, "intermedi": 181, "1303": 181, "5778": 181, "appropri": 181, "cell_fw": 181, "state_s": [181, 182], "variablescop": 181, "subgraph": 181, "output_state_fw": 181, "output_state_bw": 181, "output_states_fw": 181, "output_states_bw": 181, "typeerror": 181, "cell_bw": 181, "stack_bidirectional_dynamic_rnn": 181, "parallel_iter": 181, "time_major": 181, "swap_memori": 181, "max_tim": 181, "major": 181, "emit": 181, "transpar": 181, "produc": [181, 182, 204], "prop": 181, "cpu": 181, "layers_output": 181, "coupledinputforgetgatelstmcel": 182, "proj_clip": 182, "num_unit_shard": 182, "num_proj_shard": 182, "state_is_tupl": 182, "math_op": 182, "layer_norm": 182, "norm_gain": 182, "norm_shift": 182, "peephol": 182, "pdf": 182, "semanticscholar": 182, "1154": 182, "0131eae85b2e11d53df7f1360eeb6476e7f4": 182, "felix": 182, "ger": 182, "jurgen": 182, "schmidhub": 182, "fred": 182, "cummin": 182, "iet": 182, "850": 182, "855": 182, "1999": 182, "pub": 182, "archiv": 182, "43905": 182, "hasim": 182, "sak": 182, "andrew": 182, "senior": 182, "francois": 182, "beaufai": 182, "acoust": 182, "interspeech": 182, "2014": 182, "coupl": 182, "1503": 182, "04069": 182, "greff": 182, "odyssei": 182, "peep": 182, "hole": 182, "connect": 182, "1607": 182, "06450": 182, "jimmi": 182, "lei": 182, "ba": 182, "jami": 182, "ryan": 182, "kiro": 182, "geoffrei": 182, "hinton": 182, "nonlinear": 182, "2d": 182, "c_state": 182, "m_state": 182, "output_dim": 182, "cannot": 182, "timefreqlstmcel": 182, "feature_s": 182, "frequency_skip": 182, "tara": 182, "sainath": 182, "bo": 182, "li": 182, "lvcsr": 182, "2016": 182, "clip": 182, "gridlstmcel": 182, "share_time_frequency_weight": 182, "num_frequency_block": 182, "start_freqindex_list": 182, "end_freqindex_list": 182, "couple_input_forget_g": 182, "grid": 182, "nal": 182, "kalchbrenn": 182, "ivo": 182, "danihelka": 182, "alex": 182, "proc": 182, "iclr": 182, "1507": 182, "01526": 182, "shared_weight": 182, "_state_is_tupl": 182, "bidirectionalgridlstmcel": 182, "backward_slice_offset": 182, "gridlstm": 182, "attentioncellwrapp": 182, "attn_length": 182, "attn_siz": 182, "attn_vec_s": 182, "1601": 182, "06733": 182, "lstma": 182, "highwaywrapp": 182, "couple_carry_transform_g": 182, "carry_bias_init": 182, "highwai": 182, "srivastava": 182, "preprint": 182, "1505": 182, "00387": 182, "layernormbasiclstmcel": 182, "dropout_keep_prob": 182, "dropout_prob_se": 182, "1603": 182, "05118": 182, "stanislau": 182, "semeniuta": 182, "aliaksei": 182, "severyn": 182, "erhardt": 182, "barth": 182, "nascel": 182, "use_bia": 182, "na": 182, "1611": 182, "01578": 182, "barret": 182, "zoph": 182, "quoc": 182, "reinforc": 182, "2017": 182, "ugrnncel": 182, "ugrnn": 182, "compromis": 182, "vanilla": 182, "instantan": 182, "feedforward": 182, "09913": 182, "jasmin": 182, "collin": 182, "jascha": 182, "sohl": 182, "dickstein": 182, "david": 182, "sussillo": 182, "num": 182, "new_output": 182, "ident": 182, "new_stat": 182, "intersectionrnncel": 182, "num_in_proj": 182, "y_activ": 182, "nn_op": 182, "relu": 182, "flow": 182, "subsequ": 182, "deepli": 182, "new_i": 182, "compiledwrapp": 182, "compile_st": 182, "jit": 182, "phasedlstmcel": 182, "leak": 182, "ratio_on": 182, "trainable_ratio_on": 182, "period_init_min": 182, "period_init_max": 182, "1610": 182, "09513v1": 182, "float32": 182, "float64": 182, "features_s": 182, "lstmstatetupl": 182, "timestep": 182, "convlstmcel": 182, "conv_ndim": 182, "output_channel": 182, "kernel_shap": 182, "skip_connect": 182, "conv_lstm_cel": 182, "1506": 182, "04214v1": 182, "conv1dlstmcel": 182, "conv_1d_lstm_cel": 182, "1d": 182, "conv2dlstmcel": 182, "conv_2d_lstm_cel": 182, "conv3dlstmcel": 182, "conv_3d_lstm_cel": 182, "3d": 182, "glstmcell": 182, "number_of_group": 182, "1703": 182, "10722": 182, "kuchaiev": 182, "ginsburg": 182, "trick": 182, "brief": 182, "evenli": 182, "fed": 182, "receiv": [182, 194, 210], "num_input": 182, "known": 182, "divis": 182, "innermost": 182, "incompat": 182, "layernormlstmcel": 182, "srucel": 182, "sru": 182, "cf": 182, "1709": 182, "02755": 182, "variat": 182, "character": 182, "simplifi": 182, "consecut": 182, "tradition": 182, "multipli": 182, "matrix": 182, "w_hh": 182, "ensu": 182, "flavor": 182, "h_": 182, "pointwis": 182, "boolean": 182, "mistak": 182, "argument": 182, "weightnormlstmcel": 182, "norm": 182, "adapt": 182, "1602": 182, "07868": 182, "tim": 182, "saliman": 182, "diederik": 182, "kingma": 182, "reparameter": 182, "indrnncel": 182, "indrnn": 182, "1803": 182, "04831": 182, "indygrucel": 182, "kernel_initi": 182, "bias_initi": 182, "grucel": 182, "yet": 182, "u_r": 182, "u_z": 182, "diagon": 182, "hadamard": 182, "r_j": 182, "sigmaleft": 182, "mathbf": 182, "w_rmathbf": 182, "_j": 182, "u_rcirc": 182, "_jright": 182, "z_j": 182, "w_zmathbf": 182, "u_zcirc": 182, "tild": 182, "phileft": 182, "denot": 182, "indygru": 182, "oppos": 182, "nunit": 182, "indylstmcel": 182, "indylstm": 182, "basiclstmcel": 182, "u_f": 182, "u_i": 182, "u_o": 182, "u_c": 182, "f_t": 182, "sigma_gleft": 182, "w_f": 182, "x_t": 182, "b_fright": 182, "i_t": 182, "w_i": 182, "b_iright": 182, "o_t": 182, "w_o": 182, "b_oright": 182, "c_t": 182, "c_": 182, "sigma_cleft": 182, "b_cright": 182, "1903": 182, "08023": 182, "ntmcell": 182, "memory_s": 182, "memory_vector_dim": 182, "read_head_num": 182, "write_head_num": 182, "shift_rang": 182, "clip_valu": 182, "ture": 182, "1807": 182, "08518": 182, "collier": 182, "joeran": 182, "beel": 182, "snowkylin": 182, "ntm": 182, "cours": 182, "1410": 182, "5401": 182, "wayn": 182, "minimalrnncel": 182, "glorot_uniform": 182, "ones": 182, "minimalrnn": 182, "1806": 182, "05394v2": 182, "minmin": 182, "jeffrei": 182, "pennington": 182, "samuel": 182, "schoenholz": 182, "isometri": 182, "theori": 182, "icml": 182, "cfncell": 182, "chao": 182, "openreview": 182, "net": 182, "s1dizvclg": 182, "thoma": 182, "jame": 182, "von": 182, "brecht": 182, "cfn": 182, "goe": 182, "contract": 182, "decoupl": 182, "tf_graph_1x": 183, "documentcol": [191, 192], "sentencecol": [191, 192], "tokencol": 191, "conlllabelindex": 191, "conllposindex": 191, "textcol": [191, 192], "labelcol": 191, "docstart": [191, 210], "eu": [191, 210], "np": [191, 210], "reject": [191, 210], "vp": [191, 210], "misc": [191, 210], "boycott": [191, 210], "british": [191, 210], "lamb": [191, 210], "blackburn": 191, "brussel": 191, "1996": 191, "08": 191, "storage_level": 191, "storagelevel": 191, "disk_onli": 191, "lift": 191, "persist": 191, "uposcol": 192, "upo": 192, "xposcol": 192, "xpo": 192, "lemmacol": 192, "sent_id": 192, "sell": 192, "pron": 192, "nom": 192, "plur": 192, "_": 192, "tens": 192, "conj": 192, "cc": 192, "spaceaft": 192, "No": [192, 203], "punct": 192, "conllufil": [192, 210], "conlldataset": [192, 210], "morph": 192, "Into": 192, "googleo": 192, "sconj": 192, "propn": 192, "adp": 192, "wp": 192, "vbd": [192, 194, 210], "tagger": [194, 210], "ago": [194, 210], "posdf": 194, "61": 194, "56": 194, "67": [194, 195, 210], "nonexecut": 194, "69": 194, "76": 194, "director": 194, "78": 194, "81": 194, "84": 194, "outputposcol": 194, "outputdocumentcol": 194, "outputtextcol": 194, "pubtat": [195, 207], "medic": [195, 210], "medment": [195, 210], "25763772": [195, 210], "dctn4": [195, 210], "t116": [195, 210], "t123": [195, 210], "c4308010": [195, 210], "63": [195, 210], "chronic": [195, 210], "pseudomona": [195, 210], "aeruginosa": [195, 210], "infect": [195, 210], "t047": [195, 210], "c0854135": [195, 210], "82": [195, 210], "cystic": [195, 210], "fibrosi": [195, 210], "c0010674": [195, 210], "120": [195, 210], "pa": [195, 210], "124": [195, 210], "139": [195, 210], "pubtatorfil": 195, "corpus_pubtator_sampl": 195, "pubtatordataset": 195, "doc_id": 195, "finished_token": [195, 205], "finished_po": 195, "finished_n": 195, "finished_token_metadata": 195, "finished_pos_metadata": 195, "finished_label_metadata": 195, "mo": 195, "ispaddedtoken": 195, "pad": 195, "workflow": 200, "dedic": 200, "account": 200, "inspect": 200, "init": 200, "sparknlp_experi": 200, "offline_directori": 200, "later": 200, "nativ": 201, "record": 201, "queri": 201, "serv": 201, "registri": 201, "discov": 201, "central": 201, "send": 202, "messag": 202, "mlflow": 202, "clearli": 203, "explain_document_ml": [203, 208, 209], "approx": [203, 208, 209], "mb": [203, 208, 209], "ok": [203, 208, 209], "spearhead": 204, "declar": 204, "accordingli": 204, "extra_loc": 204, "bring": 204, "offer": [204, 206, 209], "column_nam": 204, "preced": 204, "interchang": 205, "anoth": 205, "road": 205, "proce": 205, "At": 205, "sens": 209, "constantli": 209, "server": 209, "train_po": 210, "training_conl": 210, "train_corpu": 210, "withcolumnrenam": 210, "trainingpubtatordf": 210, "corpus_pubt": 210}, "objects": {"python": [[155, 0, 0, "-", "sparknlp"]], "python.sparknlp": [[12, 0, 0, "-", "annotation"], [13, 0, 0, "-", "annotation_audio"], [14, 0, 0, "-", "annotation_image"], [78, 0, 0, "-", "annotator"], [138, 0, 0, "-", "base"], [148, 0, 0, "-", "common"], [154, 0, 0, "-", "functions"], [159, 0, 0, "-", "internal"], [163, 0, 0, "-", "logging"], [164, 0, 0, "-", "pretrained"], [155, 3, 1, "", "start"], [193, 0, 0, "-", "training"], [197, 0, 0, "-", "upload_to_hub"], [198, 0, 0, "-", "util"], [155, 3, 1, "", "version"]], "python.sparknlp.annotation": [[12, 1, 1, "", "Annotation"]], "python.sparknlp.annotation.Annotation": [[12, 2, 1, "", "arrayType"], [12, 2, 1, "", "copy"], [12, 2, 1, "", "dataType"], [12, 2, 1, "", "fromRow"], [12, 2, 1, "", "toRow"]], "python.sparknlp.annotation_audio": [[13, 1, 1, "", "AnnotationAudio"]], "python.sparknlp.annotation_audio.AnnotationAudio": [[13, 2, 1, "", "copy"]], "python.sparknlp.annotation_image": [[14, 1, 1, "", "AnnotationImage"]], "python.sparknlp.annotation_image.AnnotationImage": [[14, 2, 1, "", "copy"]], "python.sparknlp.annotator": [[15, 0, 0, "-", "audio"], [17, 0, 0, "-", "chunker"], [32, 0, 0, "-", "classifier_dl"], [47, 0, 0, "-", "coref"], [49, 0, 0, "-", "cv"], [52, 0, 0, "-", "dependency"], [54, 0, 0, "-", "document_normalizer"], [64, 0, 0, "-", "embeddings"], [76, 0, 0, "-", "er"], [77, 0, 0, "-", "graph_extraction"], [79, 0, 0, "-", "keyword_extraction"], [81, 0, 0, "-", "ld_dl"], [83, 0, 0, "-", "lemmatizer"], [86, 0, 0, "-", "matcher"], [90, 0, 0, "-", "n_gram_generator"], [91, 0, 0, "-", "ner"], [97, 0, 0, "-", "normalizer"], [100, 0, 0, "-", "param"], [101, 0, 0, "-", "pos"], [103, 0, 0, "-", "sentence"], [106, 0, 0, "-", "sentiment"], [110, 0, 0, "-", "seq2seq"], [114, 0, 0, "-", "spell_check"], [117, 0, 0, "-", "stemmer"], [118, 0, 0, "-", "stop_words_cleaner"], [119, 0, 0, "-", "tf_ner_dl_graph_builder"], [121, 0, 0, "-", "token"], [126, 0, 0, "-", "ws"]], "python.sparknlp.annotator.audio": [[16, 0, 0, "-", "wav2vec2_for_ctc"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc": [[16, 1, 1, "", "Wav2Vec2ForCTC"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[16, 2, 1, "", "loadSavedModel"], [16, 2, 1, "", "pretrained"], [16, 2, 1, "", "setConfigProtoBytes"]], "python.sparknlp.annotator.chunker": [[17, 1, 1, "", "Chunker"]], "python.sparknlp.annotator.chunker.Chunker": [[17, 2, 1, "", "setRegexParsers"]], "python.sparknlp.annotator.classifier_dl": [[18, 0, 0, "-", "albert_for_question_answering"], [19, 0, 0, "-", "albert_for_sequence_classification"], [20, 0, 0, "-", "albert_for_token_classification"], [21, 0, 0, "-", "bert_for_question_answering"], [22, 0, 0, "-", "bert_for_sequence_classification"], [23, 0, 0, "-", "bert_for_token_classification"], [24, 0, 0, "-", "camembert_for_token_classification"], [25, 0, 0, "-", "classifier_dl"], [26, 0, 0, "-", "deberta_for_question_answering"], [27, 0, 0, "-", "deberta_for_sequence_classification"], [28, 0, 0, "-", "deberta_for_token_classification"], [29, 0, 0, "-", "distil_bert_for_question_answering"], [30, 0, 0, "-", "distil_bert_for_sequence_classification"], [31, 0, 0, "-", "distil_bert_for_token_classification"], [33, 0, 0, "-", "longformer_for_question_answering"], [34, 0, 0, "-", "longformer_for_sequence_classification"], [35, 0, 0, "-", "longformer_for_token_classification"], [36, 0, 0, "-", "multi_classifier_dl"], [37, 0, 0, "-", "roberta_for_question_answering"], [38, 0, 0, "-", "roberta_for_sequence_classification"], [39, 0, 0, "-", "roberta_for_token_classification"], [40, 0, 0, "-", "sentiment_dl"], [41, 0, 0, "-", "tapas_for_question_answering"], [42, 0, 0, "-", "xlm_roberta_for_question_answering"], [43, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [44, 0, 0, "-", "xlm_roberta_for_token_classification"], [45, 0, 0, "-", "xlnet_for_sequence_classification"], [46, 0, 0, "-", "xlnet_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering": [[18, 1, 1, "", "AlbertForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[18, 2, 1, "", "loadSavedModel"], [18, 2, 1, "", "pretrained"], [18, 2, 1, "", "setConfigProtoBytes"], [18, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[19, 1, 1, "", "AlbertForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[19, 2, 1, "", "getClasses"], [19, 2, 1, "", "loadSavedModel"], [19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setCoalesceSentences"], [19, 2, 1, "", "setConfigProtoBytes"], [19, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification": [[20, 1, 1, "", "AlbertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[20, 2, 1, "", "getClasses"], [20, 2, 1, "", "loadSavedModel"], [20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setConfigProtoBytes"], [20, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering": [[21, 1, 1, "", "BertForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[22, 1, 1, "", "BertForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[22, 2, 1, "", "getClasses"], [22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setCoalesceSentences"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification": [[23, 1, 1, "", "BertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[23, 2, 1, "", "getClasses"], [23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[24, 1, 1, "", "CamemBertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[24, 2, 1, "", "getClasses"], [24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.classifier_dl": [[25, 1, 1, "", "ClassifierDLApproach"], [25, 1, 1, "", "ClassifierDLModel"]], "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[25, 2, 1, "", "setDropout"]], "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[25, 2, 1, "", "pretrained"], [25, 2, 1, "", "setConfigProtoBytes"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[26, 1, 1, "", "DeBertaForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[26, 2, 1, "", "loadSavedModel"], [26, 2, 1, "", "pretrained"], [26, 2, 1, "", "setConfigProtoBytes"], [26, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[27, 1, 1, "", "DeBertaForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[27, 2, 1, "", "getClasses"], [27, 2, 1, "", "loadSavedModel"], [27, 2, 1, "", "pretrained"], [27, 2, 1, "", "setCoalesceSentences"], [27, 2, 1, "", "setConfigProtoBytes"], [27, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[28, 1, 1, "", "DeBertaForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[28, 2, 1, "", "getClasses"], [28, 2, 1, "", "loadSavedModel"], [28, 2, 1, "", "pretrained"], [28, 2, 1, "", "setConfigProtoBytes"], [28, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[29, 1, 1, "", "DistilBertForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[29, 2, 1, "", "loadSavedModel"], [29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[30, 1, 1, "", "DistilBertForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[30, 2, 1, "", "getClasses"], [30, 2, 1, "", "loadSavedModel"], [30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setCoalesceSentences"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[31, 1, 1, "", "DistilBertForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[31, 2, 1, "", "getClasses"], [31, 2, 1, "", "loadSavedModel"], [31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[33, 1, 1, "", "LongformerForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[33, 2, 1, "", "loadSavedModel"], [33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[34, 1, 1, "", "LongformerForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[34, 2, 1, "", "getClasses"], [34, 2, 1, "", "loadSavedModel"], [34, 2, 1, "", "pretrained"], [34, 2, 1, "", "setCoalesceSentences"], [34, 2, 1, "", "setConfigProtoBytes"], [34, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[35, 1, 1, "", "LongformerForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[35, 2, 1, "", "getClasses"], [35, 2, 1, "", "loadSavedModel"], [35, 2, 1, "", "pretrained"], [35, 2, 1, "", "setConfigProtoBytes"], [35, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl": [[36, 1, 1, "", "MultiClassifierDLApproach"], [36, 1, 1, "", "MultiClassifierDLModel"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[36, 2, 1, "", "setThreshold"], [36, 2, 1, "", "setVerbose"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[36, 2, 1, "", "pretrained"], [36, 2, 1, "", "setConfigProtoBytes"], [36, 2, 1, "", "setThreshold"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[37, 1, 1, "", "RoBertaForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"], [37, 2, 1, "", "setConfigProtoBytes"], [37, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[38, 1, 1, "", "RoBertaForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[38, 2, 1, "", "getClasses"], [38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setCoalesceSentences"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[39, 1, 1, "", "RoBertaForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[39, 2, 1, "", "getClasses"], [39, 2, 1, "", "loadSavedModel"], [39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl": [[40, 1, 1, "", "SentimentDLApproach"], [40, 1, 1, "", "SentimentDLModel"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[40, 2, 1, "", "setDropout"], [40, 2, 1, "", "setThreshold"], [40, 2, 1, "", "setThresholdLabel"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[40, 2, 1, "", "pretrained"], [40, 2, 1, "", "setConfigProtoBytes"], [40, 2, 1, "", "setThreshold"], [40, 2, 1, "", "setThresholdLabel"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[41, 1, 1, "", "TapasForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[41, 2, 1, "", "loadSavedModel"], [41, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[42, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[42, 2, 1, "", "loadSavedModel"], [42, 2, 1, "", "pretrained"], [42, 2, 1, "", "setConfigProtoBytes"], [42, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[43, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[43, 2, 1, "", "getClasses"], [43, 2, 1, "", "loadSavedModel"], [43, 2, 1, "", "pretrained"], [43, 2, 1, "", "setCoalesceSentences"], [43, 2, 1, "", "setConfigProtoBytes"], [43, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[44, 1, 1, "", "XlmRoBertaForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[44, 2, 1, "", "getClasses"], [44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"], [44, 2, 1, "", "setConfigProtoBytes"], [44, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[45, 1, 1, "", "XlnetForSequenceClassification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[45, 2, 1, "", "getClasses"], [45, 2, 1, "", "loadSavedModel"], [45, 2, 1, "", "pretrained"], [45, 2, 1, "", "setCoalesceSentences"], [45, 2, 1, "", "setConfigProtoBytes"], [45, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[46, 1, 1, "", "XlnetForTokenClassification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[46, 2, 1, "", "getClasses"], [46, 2, 1, "", "loadSavedModel"], [46, 2, 1, "", "pretrained"], [46, 2, 1, "", "setConfigProtoBytes"], [46, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.coref": [[48, 0, 0, "-", "spanbert_coref"]], "python.sparknlp.annotator.coref.spanbert_coref": [[48, 1, 1, "", "SpanBertCorefModel"]], "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[48, 2, 1, "", "loadSavedModel"], [48, 2, 1, "", "pretrained"], [48, 2, 1, "", "setConfigProtoBytes"], [48, 2, 1, "", "setMaxSegmentLength"], [48, 2, 1, "", "setMaxSentenceLength"], [48, 2, 1, "", "setTextGenre"]], "python.sparknlp.annotator.cv": [[50, 0, 0, "-", "vit_for_image_classification"]], "python.sparknlp.annotator.cv.vit_for_image_classification": [[50, 1, 1, "", "ViTForImageClassification"]], "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[50, 2, 1, "", "getClasses"], [50, 2, 1, "", "loadSavedModel"], [50, 2, 1, "", "pretrained"], [50, 2, 1, "", "setConfigProtoBytes"]], "python.sparknlp.annotator.dependency": [[51, 0, 0, "-", "dependency_parser"], [53, 0, 0, "-", "typed_dependency_parser"]], "python.sparknlp.annotator.dependency.dependency_parser": [[51, 1, 1, "", "DependencyParserApproach"], [51, 1, 1, "", "DependencyParserModel"]], "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[51, 2, 1, "", "setConllU"], [51, 2, 1, "", "setDependencyTreeBank"], [51, 2, 1, "", "setNumberOfIterations"]], "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[51, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.dependency.typed_dependency_parser": [[53, 1, 1, "", "TypedDependencyParserApproach"], [53, 1, 1, "", "TypedDependencyParserModel"]], "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[53, 2, 1, "", "setConll2009"], [53, 2, 1, "", "setConllU"], [53, 2, 1, "", "setNumberOfIterations"]], "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[53, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.document_normalizer": [[54, 1, 1, "", "DocumentNormalizer"]], "python.sparknlp.annotator.document_normalizer.DocumentNormalizer": [[54, 2, 1, "", "setAction"], [54, 2, 1, "", "setEncoding"], [54, 2, 1, "", "setLowercase"], [54, 2, 1, "", "setPatterns"], [54, 2, 1, "", "setPolicy"], [54, 2, 1, "", "setReplacement"]], "python.sparknlp.annotator.embeddings": [[55, 0, 0, "-", "albert_embeddings"], [56, 0, 0, "-", "bert_embeddings"], [57, 0, 0, "-", "bert_sentence_embeddings"], [58, 0, 0, "-", "camembert_embeddings"], [59, 0, 0, "-", "chunk_embeddings"], [60, 0, 0, "-", "deberta_embeddings"], [61, 0, 0, "-", "distil_bert_embeddings"], [62, 0, 0, "-", "doc2vec"], [63, 0, 0, "-", "elmo_embeddings"], [65, 0, 0, "-", "longformer_embeddings"], [66, 0, 0, "-", "roberta_embeddings"], [67, 0, 0, "-", "roberta_sentence_embeddings"], [68, 0, 0, "-", "sentence_embeddings"], [69, 0, 0, "-", "universal_sentence_encoder"], [70, 0, 0, "-", "word2vec"], [71, 0, 0, "-", "word_embeddings"], [72, 0, 0, "-", "xlm_roberta_embeddings"], [73, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [74, 0, 0, "-", "xlnet_embeddings"]], "python.sparknlp.annotator.embeddings.albert_embeddings": [[55, 1, 1, "", "AlbertEmbeddings"]], "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[55, 2, 1, "", "loadSavedModel"], [55, 2, 1, "", "pretrained"], [55, 2, 1, "", "setConfigProtoBytes"], [55, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.bert_embeddings": [[56, 1, 1, "", "BertEmbeddings"]], "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[56, 2, 1, "", "loadSavedModel"], [56, 2, 1, "", "pretrained"], [56, 2, 1, "", "setConfigProtoBytes"], [56, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings": [[57, 1, 1, "", "BertSentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[57, 2, 1, "", "loadSavedModel"], [57, 2, 1, "", "pretrained"], [57, 2, 1, "", "setConfigProtoBytes"], [57, 2, 1, "", "setIsLong"], [57, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.camembert_embeddings": [[58, 1, 1, "", "CamemBertEmbeddings"]], "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[58, 2, 1, "", "loadSavedModel"], [58, 2, 1, "", "pretrained"], [58, 2, 1, "", "setConfigProtoBytes"], [58, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.chunk_embeddings": [[59, 1, 1, "", "ChunkEmbeddings"]], "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[59, 2, 1, "", "setPoolingStrategy"], [59, 2, 1, "", "setSkipOOV"]], "python.sparknlp.annotator.embeddings.deberta_embeddings": [[60, 1, 1, "", "DeBertaEmbeddings"]], "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[60, 2, 1, "", "loadSavedModel"], [60, 2, 1, "", "pretrained"], [60, 2, 1, "", "setConfigProtoBytes"], [60, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings": [[61, 1, 1, "", "DistilBertEmbeddings"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[61, 2, 1, "", "loadSavedModel"], [61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setConfigProtoBytes"], [61, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.doc2vec": [[62, 1, 1, "", "Doc2VecApproach"], [62, 1, 1, "", "Doc2VecModel"]], "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[62, 2, 1, "", "setMaxIter"], [62, 2, 1, "", "setMaxSentenceLength"], [62, 2, 1, "", "setMinCount"], [62, 2, 1, "", "setNumPartitions"], [62, 2, 1, "", "setSeed"], [62, 2, 1, "", "setStepSize"], [62, 2, 1, "", "setVectorSize"], [62, 2, 1, "", "setWindowSize"]], "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[62, 2, 1, "", "pretrained"], [62, 2, 1, "", "setVectorSize"]], "python.sparknlp.annotator.embeddings.elmo_embeddings": [[63, 1, 1, "", "ElmoEmbeddings"]], "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[63, 2, 1, "", "loadSavedModel"], [63, 2, 1, "", "pretrained"], [63, 2, 1, "", "setBatchSize"], [63, 2, 1, "", "setConfigProtoBytes"], [63, 2, 1, "", "setPoolingLayer"]], "python.sparknlp.annotator.embeddings.longformer_embeddings": [[65, 1, 1, "", "LongformerEmbeddings"]], "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[65, 2, 1, "", "loadSavedModel"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setConfigProtoBytes"], [65, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.roberta_embeddings": [[66, 1, 1, "", "RoBertaEmbeddings"]], "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[66, 2, 1, "", "loadSavedModel"], [66, 2, 1, "", "pretrained"], [66, 2, 1, "", "setConfigProtoBytes"], [66, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[67, 1, 1, "", "RoBertaSentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[67, 2, 1, "", "loadSavedModel"], [67, 2, 1, "", "pretrained"], [67, 2, 1, "", "setConfigProtoBytes"], [67, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.sentence_embeddings": [[68, 1, 1, "", "SentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[68, 2, 1, "", "setPoolingStrategy"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder": [[69, 1, 1, "", "UniversalSentenceEncoder"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[69, 2, 1, "", "loadSavedModel"], [69, 2, 1, "", "pretrained"], [69, 2, 1, "", "setConfigProtoBytes"], [69, 2, 1, "", "setLoadSP"]], "python.sparknlp.annotator.embeddings.word2vec": [[70, 1, 1, "", "Word2VecApproach"], [70, 1, 1, "", "Word2VecModel"]], "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[70, 2, 1, "", "setMaxIter"], [70, 2, 1, "", "setMaxSentenceLength"], [70, 2, 1, "", "setMinCount"], [70, 2, 1, "", "setNumPartitions"], [70, 2, 1, "", "setSeed"], [70, 2, 1, "", "setStepSize"], [70, 2, 1, "", "setVectorSize"], [70, 2, 1, "", "setWindowSize"]], "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[70, 2, 1, "", "pretrained"], [70, 2, 1, "", "setVectorSize"]], "python.sparknlp.annotator.embeddings.word_embeddings": [[71, 1, 1, "", "WordEmbeddings"], [71, 1, 1, "", "WordEmbeddingsModel"]], "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[71, 2, 1, "", "setReadCacheSize"], [71, 2, 1, "", "setWriteBufferSize"]], "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[71, 2, 1, "", "loadStorage"], [71, 2, 1, "", "overallCoverage"], [71, 2, 1, "", "pretrained"], [71, 2, 1, "", "setReadCacheSize"], [71, 2, 1, "", "withCoverageColumn"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[72, 1, 1, "", "XlmRoBertaEmbeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[72, 2, 1, "", "loadSavedModel"], [72, 2, 1, "", "pretrained"], [72, 2, 1, "", "setConfigProtoBytes"], [72, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[73, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[73, 2, 1, "", "loadSavedModel"], [73, 2, 1, "", "pretrained"], [73, 2, 1, "", "setConfigProtoBytes"], [73, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings": [[74, 1, 1, "", "XlnetEmbeddings"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[74, 2, 1, "", "loadSavedModel"], [74, 2, 1, "", "pretrained"], [74, 2, 1, "", "setConfigProtoBytes"], [74, 2, 1, "", "setMaxSentenceLength"]], "python.sparknlp.annotator.er": [[75, 0, 0, "-", "entity_ruler"]], "python.sparknlp.annotator.er.entity_ruler": [[75, 1, 1, "", "EntityRulerApproach"], [75, 1, 1, "", "EntityRulerModel"]], "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[75, 2, 1, "", "setAlphabetResource"], [75, 2, 1, "", "setEnablePatternRegex"], [75, 2, 1, "", "setPatternsResource"], [75, 2, 1, "", "setSentenceMatch"], [75, 2, 1, "", "setUseStorage"]], "python.sparknlp.annotator.graph_extraction": [[77, 1, 1, "", "GraphExtraction"]], "python.sparknlp.annotator.graph_extraction.GraphExtraction": [[77, 2, 1, "", "setDelimiter"], [77, 2, 1, "", "setDependencyParserModel"], [77, 2, 1, "", "setEntityTypes"], [77, 2, 1, "", "setExplodeEntities"], [77, 2, 1, "", "setIncludeEdges"], [77, 2, 1, "", "setMaxSentenceSize"], [77, 2, 1, "", "setMergeEntities"], [77, 2, 1, "", "setMergeEntitiesIOBFormat"], [77, 2, 1, "", "setMinSentenceSize"], [77, 2, 1, "", "setPosModel"], [77, 2, 1, "", "setRelationshipTypes"], [77, 2, 1, "", "setRootTokens"], [77, 2, 1, "", "setTypedDependencyParserModel"]], "python.sparknlp.annotator.keyword_extraction": [[80, 0, 0, "-", "yake_keyword_extraction"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[80, 1, 1, "", "YakeKeywordExtraction"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[80, 2, 1, "", "getStopWords"], [80, 2, 1, "", "loadDefaultStopWords"], [80, 2, 1, "", "setMaxNGrams"], [80, 2, 1, "", "setMinNGrams"], [80, 2, 1, "", "setNKeywords"], [80, 2, 1, "", "setStopWords"], [80, 2, 1, "", "setThreshold"], [80, 2, 1, "", "setWindowSize"]], "python.sparknlp.annotator.ld_dl": [[82, 0, 0, "-", "language_detector_dl"]], "python.sparknlp.annotator.ld_dl.language_detector_dl": [[82, 1, 1, "", "LanguageDetectorDL"]], "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[82, 2, 1, "", "pretrained"], [82, 2, 1, "", "setCoalesceSentences"], [82, 2, 1, "", "setConfigProtoBytes"], [82, 2, 1, "", "setThreshold"], [82, 2, 1, "", "setThresholdLabel"]], "python.sparknlp.annotator.lemmatizer": [[83, 1, 1, "", "Lemmatizer"], [83, 1, 1, "", "LemmatizerModel"]], "python.sparknlp.annotator.lemmatizer.Lemmatizer": [[83, 2, 1, "", "setDictionary"], [83, 2, 1, "", "setFormCol"], [83, 2, 1, "", "setLemmaCol"]], "python.sparknlp.annotator.lemmatizer.LemmatizerModel": [[83, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.matcher": [[84, 0, 0, "-", "big_text_matcher"], [85, 0, 0, "-", "date_matcher"], [87, 0, 0, "-", "multi_date_matcher"], [88, 0, 0, "-", "regex_matcher"], [89, 0, 0, "-", "text_matcher"]], "python.sparknlp.annotator.matcher.big_text_matcher": [[84, 1, 1, "", "BigTextMatcher"], [84, 1, 1, "", "BigTextMatcherModel"]], "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[84, 2, 1, "", "setCaseSensitive"], [84, 2, 1, "", "setEntities"], [84, 2, 1, "", "setMergeOverlapping"], [84, 2, 1, "", "setTokenizer"]], "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[84, 2, 1, "", "loadStorage"], [84, 2, 1, "", "pretrained"], [84, 2, 1, "", "setCaseSensitive"], [84, 2, 1, "", "setMergeOverlapping"]], "python.sparknlp.annotator.matcher.date_matcher": [[85, 1, 1, "", "DateMatcher"], [85, 1, 1, "", "DateMatcherUtils"]], "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[85, 2, 1, "", "setAnchorDateDay"], [85, 2, 1, "", "setAnchorDateMonth"], [85, 2, 1, "", "setAnchorDateYear"], [85, 2, 1, "", "setDefaultDayWhenMissing"], [85, 2, 1, "", "setInputFormats"], [85, 2, 1, "", "setOutputFormat"], [85, 2, 1, "", "setReadMonthFirst"]], "python.sparknlp.annotator.matcher.multi_date_matcher": [[87, 1, 1, "", "MultiDateMatcher"]], "python.sparknlp.annotator.matcher.regex_matcher": [[88, 1, 1, "", "RegexMatcher"], [88, 1, 1, "", "RegexMatcherModel"]], "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[88, 2, 1, "", "setExternalRules"], [88, 2, 1, "", "setStrategy"]], "python.sparknlp.annotator.matcher.text_matcher": [[89, 1, 1, "", "TextMatcher"], [89, 1, 1, "", "TextMatcherModel"]], "python.sparknlp.annotator.matcher.text_matcher.TextMatcher": [[89, 2, 1, "", "setBuildFromTokens"], [89, 2, 1, "", "setCaseSensitive"], [89, 2, 1, "", "setEntities"], [89, 2, 1, "", "setEntityValue"], [89, 2, 1, "", "setMergeOverlapping"]], "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[89, 2, 1, "", "pretrained"], [89, 2, 1, "", "setBuildFromTokens"], [89, 2, 1, "", "setEntityValue"], [89, 2, 1, "", "setMergeOverlapping"]], "python.sparknlp.annotator.n_gram_generator": [[90, 1, 1, "", "NGramGenerator"]], "python.sparknlp.annotator.n_gram_generator.NGramGenerator": [[90, 2, 1, "", "setDelimiter"], [90, 2, 1, "", "setEnableCumulative"], [90, 2, 1, "", "setN"]], "python.sparknlp.annotator.ner": [[92, 0, 0, "-", "ner_approach"], [93, 0, 0, "-", "ner_converter"], [94, 0, 0, "-", "ner_crf"], [95, 0, 0, "-", "ner_dl"], [96, 0, 0, "-", "ner_overwriter"]], "python.sparknlp.annotator.ner.ner_approach": [[92, 1, 1, "", "NerApproach"]], "python.sparknlp.annotator.ner.ner_approach.NerApproach": [[92, 2, 1, "", "getLabelColumn"], [92, 2, 1, "", "setEntities"], [92, 2, 1, "", "setLabelColumn"], [92, 2, 1, "", "setMaxEpochs"], [92, 2, 1, "", "setMinEpochs"], [92, 2, 1, "", "setRandomSeed"]], "python.sparknlp.annotator.ner.ner_converter": [[93, 1, 1, "", "NerConverter"]], "python.sparknlp.annotator.ner.ner_converter.NerConverter": [[93, 2, 1, "", "setWhiteList"]], "python.sparknlp.annotator.ner.ner_crf": [[94, 1, 1, "", "NerCrfApproach"], [94, 1, 1, "", "NerCrfModel"]], "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[94, 2, 1, "", "setC0"], [94, 2, 1, "", "setExternalFeatures"], [94, 2, 1, "", "setIncludeConfidence"], [94, 2, 1, "", "setL2"], [94, 2, 1, "", "setLossEps"], [94, 2, 1, "", "setMinW"], [94, 2, 1, "", "setVerbose"]], "python.sparknlp.annotator.ner.ner_crf.NerCrfModel": [[94, 2, 1, "", "pretrained"], [94, 2, 1, "", "setIncludeConfidence"]], "python.sparknlp.annotator.ner.ner_dl": [[95, 1, 1, "", "NerDLApproach"], [95, 1, 1, "", "NerDLModel"]], "python.sparknlp.annotator.ner.ner_dl.NerDLApproach": [[95, 2, 1, "", "setBatchSize"], [95, 2, 1, "", "setBestModelMetric"], [95, 2, 1, "", "setConfigProtoBytes"], [95, 2, 1, "", "setDropout"], [95, 2, 1, "", "setEnableMemoryOptimizer"], [95, 2, 1, "", "setGraphFolder"], [95, 2, 1, "", "setIncludeAllConfidenceScores"], [95, 2, 1, "", "setIncludeConfidence"], [95, 2, 1, "", "setLr"], [95, 2, 1, "", "setPo"], [95, 2, 1, "", "setUseBestModel"], [95, 2, 1, "", "setUseContrib"]], "python.sparknlp.annotator.ner.ner_dl.NerDLModel": [[95, 2, 1, "", "pretrained"], [95, 2, 1, "", "setConfigProtoBytes"], [95, 2, 1, "", "setIncludeAllConfidenceScores"], [95, 2, 1, "", "setIncludeConfidence"]], "python.sparknlp.annotator.ner.ner_overwriter": [[96, 1, 1, "", "NerOverwriter"]], "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[96, 2, 1, "", "setNerWords"], [96, 2, 1, "", "setNewNerEntity"], [96, 2, 1, "", "setReplaceEntities"]], "python.sparknlp.annotator.normalizer": [[97, 1, 1, "", "Normalizer"], [97, 1, 1, "", "NormalizerModel"]], "python.sparknlp.annotator.normalizer.Normalizer": [[97, 2, 1, "", "setCleanupPatterns"], [97, 2, 1, "", "setLowercase"], [97, 2, 1, "", "setMaxLength"], [97, 2, 1, "", "setMinLength"], [97, 2, 1, "", "setSlangDictionary"]], "python.sparknlp.annotator.param": [[98, 0, 0, "-", "classifier_encoder"], [99, 0, 0, "-", "evaluation_dl_params"]], "python.sparknlp.annotator.param.classifier_encoder": [[98, 1, 1, "", "ClassifierEncoder"]], "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[98, 2, 1, "", "setBatchSize"], [98, 2, 1, "", "setConfigProtoBytes"], [98, 2, 1, "", "setLabelColumn"], [98, 2, 1, "", "setLr"], [98, 2, 1, "", "setMaxEpochs"], [98, 2, 1, "", "setRandomSeed"]], "python.sparknlp.annotator.param.evaluation_dl_params": [[99, 1, 1, "", "EvaluationDLParams"]], "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[99, 2, 1, "", "setEnableOutputLogs"], [99, 2, 1, "", "setEvaluationLogExtended"], [99, 2, 1, "", "setOutputLogsPath"], [99, 2, 1, "", "setTestDataset"], [99, 2, 1, "", "setValidationSplit"], [99, 2, 1, "", "setVerbose"]], "python.sparknlp.annotator.pos": [[102, 0, 0, "-", "perceptron"]], "python.sparknlp.annotator.pos.perceptron": [[102, 1, 1, "", "PerceptronApproach"], [102, 1, 1, "", "PerceptronModel"]], "python.sparknlp.annotator.pos.perceptron.PerceptronApproach": [[102, 2, 1, "", "getNIterations"], [102, 2, 1, "", "setIterations"], [102, 2, 1, "", "setPosColumn"]], "python.sparknlp.annotator.pos.perceptron.PerceptronModel": [[102, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.sentence": [[104, 0, 0, "-", "sentence_detector"], [105, 0, 0, "-", "sentence_detector_dl"]], "python.sparknlp.annotator.sentence.sentence_detector": [[104, 1, 1, "", "SentenceDetector"], [104, 1, 1, "", "SentenceDetectorParams"]], "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[104, 2, 1, "", "setCustomBounds"], [104, 2, 1, "", "setCustomBoundsStrategy"], [104, 2, 1, "", "setDetectLists"], [104, 2, 1, "", "setExplodeSentences"], [104, 2, 1, "", "setMaxLength"], [104, 2, 1, "", "setMinLength"], [104, 2, 1, "", "setSplitLength"], [104, 2, 1, "", "setUseAbbreviations"], [104, 2, 1, "", "setUseCustomBoundsOnly"]], "python.sparknlp.annotator.sentence.sentence_detector_dl": [[105, 1, 1, "", "SentenceDetectorDLApproach"], [105, 1, 1, "", "SentenceDetectorDLModel"]], "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[105, 2, 1, "", "setEpochsNumber"], [105, 2, 1, "", "setExplodeSentences"], [105, 2, 1, "", "setImpossiblePenultimates"], [105, 2, 1, "", "setModel"], [105, 2, 1, "", "setOutputLogsPath"], [105, 2, 1, "", "setValidationSplit"]], "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[105, 2, 1, "", "pretrained"], [105, 2, 1, "", "setCustomBounds"], [105, 2, 1, "", "setExplodeSentences"], [105, 2, 1, "", "setImpossiblePenultimates"], [105, 2, 1, "", "setMaxLength"], [105, 2, 1, "", "setMinLength"], [105, 2, 1, "", "setModel"], [105, 2, 1, "", "setSplitLength"], [105, 2, 1, "", "setUseCustomBoundsOnly"]], "python.sparknlp.annotator.sentiment": [[107, 0, 0, "-", "sentiment_detector"], [108, 0, 0, "-", "vivekn_sentiment"]], "python.sparknlp.annotator.sentiment.sentiment_detector": [[107, 1, 1, "", "SentimentDetector"], [107, 1, 1, "", "SentimentDetectorModel"]], "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[107, 2, 1, "", "setDictionary"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment": [[108, 1, 1, "", "ViveknSentimentApproach"], [108, 1, 1, "", "ViveknSentimentModel"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[108, 2, 1, "", "setPruneCorpus"], [108, 2, 1, "", "setSentimentCol"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[108, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.seq2seq": [[109, 0, 0, "-", "gpt2_transformer"], [111, 0, 0, "-", "marian_transformer"], [112, 0, 0, "-", "t5_transformer"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer": [[109, 1, 1, "", "GPT2Transformer"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[109, 2, 1, "", "loadSavedModel"], [109, 2, 1, "", "pretrained"], [109, 2, 1, "", "setConfigProtoBytes"], [109, 2, 1, "", "setDoSample"], [109, 2, 1, "", "setIgnoreTokenIds"], [109, 2, 1, "", "setMaxOutputLength"], [109, 2, 1, "", "setMinOutputLength"], [109, 2, 1, "", "setNoRepeatNgramSize"], [109, 2, 1, "", "setRepetitionPenalty"], [109, 2, 1, "", "setTask"], [109, 2, 1, "", "setTemperature"], [109, 2, 1, "", "setTopK"], [109, 2, 1, "", "setTopP"]], "python.sparknlp.annotator.seq2seq.marian_transformer": [[111, 1, 1, "", "MarianTransformer"]], "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[111, 2, 1, "", "loadSavedModel"], [111, 2, 1, "", "pretrained"], [111, 2, 1, "", "setConfigProtoBytes"], [111, 2, 1, "", "setIgnoreTokenIds"], [111, 2, 1, "", "setLangId"], [111, 2, 1, "", "setMaxInputLength"], [111, 2, 1, "", "setMaxOutputLength"]], "python.sparknlp.annotator.seq2seq.t5_transformer": [[112, 1, 1, "", "T5Transformer"]], "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[112, 2, 1, "", "loadSavedModel"], [112, 2, 1, "", "pretrained"], [112, 2, 1, "", "setConfigProtoBytes"], [112, 2, 1, "", "setDoSample"], [112, 2, 1, "", "setIgnoreTokenIds"], [112, 2, 1, "", "setMaxOutputLength"], [112, 2, 1, "", "setMinOutputLength"], [112, 2, 1, "", "setNoRepeatNgramSize"], [112, 2, 1, "", "setRepetitionPenalty"], [112, 2, 1, "", "setTask"], [112, 2, 1, "", "setTemperature"], [112, 2, 1, "", "setTopK"], [112, 2, 1, "", "setTopP"]], "python.sparknlp.annotator.spell_check": [[113, 0, 0, "-", "context_spell_checker"], [115, 0, 0, "-", "norvig_sweeting"], [116, 0, 0, "-", "symmetric_delete"]], "python.sparknlp.annotator.spell_check.context_spell_checker": [[113, 1, 1, "", "ContextSpellCheckerApproach"], [113, 1, 1, "", "ContextSpellCheckerModel"]], "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[113, 2, 1, "", "addRegexClass"], [113, 2, 1, "", "addVocabClass"], [113, 2, 1, "", "setBatchSize"], [113, 2, 1, "", "setCaseStrategy"], [113, 2, 1, "", "setClassCount"], [113, 2, 1, "", "setCompoundCount"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setEpochs"], [113, 2, 1, "", "setErrorThreshold"], [113, 2, 1, "", "setFinalRate"], [113, 2, 1, "", "setInitialRate"], [113, 2, 1, "", "setLanguageModelClasses"], [113, 2, 1, "", "setMaxCandidates"], [113, 2, 1, "", "setMaxWindowLen"], [113, 2, 1, "", "setMinCount"], [113, 2, 1, "", "setTradeoff"], [113, 2, 1, "", "setValidationFraction"], [113, 2, 1, "id0", "setWeightedDistPath"], [113, 2, 1, "", "setWordMaxDistance"]], "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[113, 2, 1, "", "getWordClasses"], [113, 2, 1, "", "pretrained"], [113, 2, 1, "", "setCaseStrategy"], [113, 2, 1, "", "setCompareLowcase"], [113, 2, 1, "", "setConfigProtoBytes"], [113, 2, 1, "", "setCorrectSymbols"], [113, 2, 1, "", "setErrorThreshold"], [113, 2, 1, "", "setGamma"], [113, 2, 1, "", "setMaxCandidates"], [113, 2, 1, "", "setMaxWindowLen"], [113, 2, 1, "", "setTradeoff"], [113, 2, 1, "", "setWeights"], [113, 2, 1, "", "setWordMaxDistance"], [113, 2, 1, "", "updateRegexClass"], [113, 2, 1, "", "updateVocabClass"]], "python.sparknlp.annotator.spell_check.norvig_sweeting": [[115, 1, 1, "", "NorvigSweetingApproach"], [115, 1, 1, "", "NorvigSweetingModel"]], "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[115, 2, 1, "", "setCaseSensitive"], [115, 2, 1, "", "setDictionary"], [115, 2, 1, "", "setDoubleVariants"], [115, 2, 1, "", "setFrequencyPriority"], [115, 2, 1, "", "setShortCircuit"]], "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[115, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.spell_check.symmetric_delete": [[116, 1, 1, "", "SymmetricDeleteApproach"], [116, 1, 1, "", "SymmetricDeleteModel"]], "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[116, 2, 1, "", "setDeletesThreshold"], [116, 2, 1, "", "setDictionary"], [116, 2, 1, "", "setFrequencyThreshold"], [116, 2, 1, "", "setMaxEditDistance"]], "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[116, 2, 1, "", "pretrained"]], "python.sparknlp.annotator.stemmer": [[117, 1, 1, "", "Stemmer"]], "python.sparknlp.annotator.stop_words_cleaner": [[118, 1, 1, "", "StopWordsCleaner"]], "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[118, 2, 1, "", "loadDefaultStopWords"], [118, 2, 1, "", "pretrained"], [118, 2, 1, "", "setCaseSensitive"], [118, 2, 1, "", "setLocale"], [118, 2, 1, "", "setStopWords"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder": [[119, 1, 1, "", "TFNerDLGraphBuilder"], [119, 1, 1, "", "TFNerDLGraphBuilderModel"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[119, 2, 1, "", "getGraphFile"], [119, 2, 1, "", "getGraphFolder"], [119, 2, 1, "", "getHiddenUnitsNumber"], [119, 2, 1, "", "getInputCols"], [119, 2, 1, "", "getLabelColumn"], [119, 2, 1, "", "setGraphFile"], [119, 2, 1, "", "setGraphFolder"], [119, 2, 1, "", "setHiddenUnitsNumber"], [119, 2, 1, "", "setInputCols"], [119, 2, 1, "", "setLabelColumn"]], "python.sparknlp.annotator.token": [[120, 0, 0, "-", "chunk_tokenizer"], [122, 0, 0, "-", "recursive_tokenizer"], [123, 0, 0, "-", "regex_tokenizer"], [124, 0, 0, "-", "token2_chunk"], [125, 0, 0, "-", "tokenizer"]], "python.sparknlp.annotator.token.chunk_tokenizer": [[120, 1, 1, "", "ChunkTokenizer"], [120, 1, 1, "", "ChunkTokenizerModel"]], "python.sparknlp.annotator.token.recursive_tokenizer": [[122, 1, 1, "", "RecursiveTokenizer"], [122, 1, 1, "", "RecursiveTokenizerModel"]], "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[122, 2, 1, "", "setInfixes"], [122, 2, 1, "", "setPrefixes"], [122, 2, 1, "", "setSuffixes"], [122, 2, 1, "", "setWhitelist"]], "python.sparknlp.annotator.token.regex_tokenizer": [[123, 1, 1, "", "RegexTokenizer"]], "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[123, 2, 1, "", "setMaxLength"], [123, 2, 1, "", "setMinLength"], [123, 2, 1, "", "setPattern"], [123, 2, 1, "", "setPositionalMask"], [123, 2, 1, "", "setPreservePosition"], [123, 2, 1, "", "setToLowercase"], [123, 2, 1, "", "setTrimWhitespace"]], "python.sparknlp.annotator.token.token2_chunk": [[124, 1, 1, "", "Token2Chunk"]], "python.sparknlp.annotator.token.tokenizer": [[125, 1, 1, "", "Tokenizer"], [125, 1, 1, "", "TokenizerModel"]], "python.sparknlp.annotator.token.tokenizer.Tokenizer": [[125, 2, 1, "", "addContextChars"], [125, 2, 1, "", "addException"], [125, 2, 1, "", "addInfixPattern"], [125, 2, 1, "", "addSplitChars"], [125, 2, 1, "", "getCaseSensitiveExceptions"], [125, 2, 1, "", "getContextChars"], [125, 2, 1, "", "getExceptions"], [125, 2, 1, "", "getInfixPatterns"], [125, 2, 1, "", "getPrefixPattern"], [125, 2, 1, "", "getSplitChars"], [125, 2, 1, "", "getSuffixPattern"], [125, 2, 1, "", "setCaseSensitiveExceptions"], [125, 2, 1, "", "setContextChars"], [125, 2, 1, "", "setExceptions"], [125, 2, 1, "", "setExceptionsPath"], [125, 2, 1, "", "setInfixPatterns"], [125, 2, 1, "", "setMaxLength"], [125, 2, 1, "", "setMinLength"], [125, 2, 1, "", "setPrefixPattern"], [125, 2, 1, "", "setSplitChars"], [125, 2, 1, "", "setSplitPattern"], [125, 2, 1, "", "setSuffixPattern"], [125, 2, 1, "", "setTargetPattern"]], "python.sparknlp.annotator.token.tokenizer.TokenizerModel": [[125, 2, 1, "", "addSplitChars"], [125, 2, 1, "", "pretrained"], [125, 2, 1, "", "setSplitChars"], [125, 2, 1, "", "setSplitPattern"]], "python.sparknlp.annotator.ws": [[127, 0, 0, "-", "word_segmenter"]], "python.sparknlp.annotator.ws.word_segmenter": [[127, 1, 1, "", "WordSegmenterApproach"], [127, 1, 1, "", "WordSegmenterModel"]], "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[127, 2, 1, "", "getAmbiguityThreshold"], [127, 2, 1, "", "getFrequencyThreshold"], [127, 2, 1, "", "getNIterations"], [127, 2, 1, "", "setAmbiguityThreshold"], [127, 2, 1, "", "setFrequencyThreshold"], [127, 2, 1, "", "setNIterations"], [127, 2, 1, "", "setPosColumn"]], "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[127, 2, 1, "", "pretrained"]], "python.sparknlp.base": [[128, 0, 0, "-", "audio_assembler"], [129, 0, 0, "-", "chunk2_doc"], [130, 0, 0, "-", "doc2_chunk"], [131, 0, 0, "-", "document_assembler"], [132, 0, 0, "-", "embeddings_finisher"], [133, 0, 0, "-", "finisher"], [134, 0, 0, "-", "graph_finisher"], [135, 0, 0, "-", "has_recursive_fit"], [136, 0, 0, "-", "has_recursive_transform"], [137, 0, 0, "-", "image_assembler"], [139, 0, 0, "-", "light_pipeline"], [140, 0, 0, "-", "multi_document_assembler"], [141, 0, 0, "-", "recursive_pipeline"], [142, 0, 0, "-", "table_assembler"], [143, 0, 0, "-", "token_assembler"]], "python.sparknlp.base.audio_assembler": [[128, 1, 1, "", "AudioAssembler"]], "python.sparknlp.base.audio_assembler.AudioAssembler": [[128, 2, 1, "", "setInputCol"], [128, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.chunk2_doc": [[129, 1, 1, "", "Chunk2Doc"]], "python.sparknlp.base.doc2_chunk": [[130, 1, 1, "", "Doc2Chunk"]], "python.sparknlp.base.doc2_chunk.Doc2Chunk": [[130, 2, 1, "", "setChunkCol"], [130, 2, 1, "", "setFailOnMissing"], [130, 2, 1, "", "setIsArray"], [130, 2, 1, "", "setLowerCase"], [130, 2, 1, "", "setStartCol"], [130, 2, 1, "", "setStartColByTokenIndex"]], "python.sparknlp.base.document_assembler": [[131, 1, 1, "", "DocumentAssembler"]], "python.sparknlp.base.document_assembler.DocumentAssembler": [[131, 2, 1, "", "setCleanupMode"], [131, 2, 1, "", "setIdCol"], [131, 2, 1, "", "setInputCol"], [131, 2, 1, "", "setMetadataCol"], [131, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.embeddings_finisher": [[132, 1, 1, "", "EmbeddingsFinisher"]], "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[132, 2, 1, "", "setCleanAnnotations"], [132, 2, 1, "", "setInputCols"], [132, 2, 1, "", "setOutputAsVector"], [132, 2, 1, "", "setOutputCols"]], "python.sparknlp.base.finisher": [[133, 1, 1, "", "Finisher"]], "python.sparknlp.base.finisher.Finisher": [[133, 2, 1, "", "setAnnotationSplitSymbol"], [133, 2, 1, "", "setCleanAnnotations"], [133, 2, 1, "", "setIncludeMetadata"], [133, 2, 1, "", "setInputCols"], [133, 2, 1, "", "setOutputAsArray"], [133, 2, 1, "", "setOutputCols"], [133, 2, 1, "", "setParseEmbeddingsVectors"], [133, 2, 1, "", "setValueSplitSymbol"]], "python.sparknlp.base.graph_finisher": [[134, 1, 1, "", "GraphFinisher"]], "python.sparknlp.base.graph_finisher.GraphFinisher": [[134, 2, 1, "", "setCleanAnnotations"], [134, 2, 1, "", "setInputCol"], [134, 2, 1, "", "setOutputAsArray"], [134, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.has_recursive_fit": [[135, 1, 1, "", "HasRecursiveFit"]], "python.sparknlp.base.has_recursive_transform": [[136, 1, 1, "", "HasRecursiveTransform"]], "python.sparknlp.base.image_assembler": [[137, 1, 1, "", "ImageAssembler"]], "python.sparknlp.base.image_assembler.ImageAssembler": [[137, 2, 1, "", "setInputCol"], [137, 2, 1, "", "setOutputCol"]], "python.sparknlp.base.light_pipeline": [[139, 1, 1, "", "LightPipeline"]], "python.sparknlp.base.light_pipeline.LightPipeline": [[139, 2, 1, "", "annotate"], [139, 2, 1, "", "fullAnnotate"], [139, 2, 1, "", "fullAnnotateImage"], [139, 2, 1, "", "getIgnoreUnsupported"], [139, 2, 1, "", "setIgnoreUnsupported"], [139, 2, 1, "", "transform"]], "python.sparknlp.base.multi_document_assembler": [[140, 1, 1, "", "MultiDocumentAssembler"]], "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[140, 2, 1, "", "setCleanupMode"], [140, 2, 1, "", "setIdCol"], [140, 2, 1, "", "setInputCols"], [140, 2, 1, "", "setMetadataCol"], [140, 2, 1, "", "setOutputCols"]], "python.sparknlp.base.recursive_pipeline": [[141, 1, 1, "", "RecursivePipeline"], [141, 1, 1, "", "RecursivePipelineModel"]], "python.sparknlp.base.table_assembler": [[142, 1, 1, "", "TableAssembler"]], "python.sparknlp.base.table_assembler.TableAssembler": [[142, 2, 1, "", "setCsvDelimiter"], [142, 2, 1, "", "setEscapeCsvDelimiter"], [142, 2, 1, "", "setInputFormat"]], "python.sparknlp.base.token_assembler": [[143, 1, 1, "", "TokenAssembler"]], "python.sparknlp.base.token_assembler.TokenAssembler": [[143, 2, 1, "", "setPreservePosition"]], "python.sparknlp.common": [[144, 0, 0, "-", "annotator_approach"], [145, 0, 0, "-", "annotator_model"], [146, 0, 0, "-", "annotator_properties"], [147, 0, 0, "-", "coverage_result"], [149, 0, 0, "-", "properties"], [150, 0, 0, "-", "read_as"], [151, 0, 0, "-", "recursive_annotator_approach"], [152, 0, 0, "-", "storage"], [153, 0, 0, "-", "utils"]], "python.sparknlp.common.annotator_approach": [[144, 1, 1, "", "AnnotatorApproach"]], "python.sparknlp.common.annotator_model": [[145, 1, 1, "", "AnnotatorModel"]], "python.sparknlp.common.annotator_properties": [[146, 1, 1, "", "AnnotatorProperties"]], "python.sparknlp.common.annotator_properties.AnnotatorProperties": [[146, 2, 1, "", "getInputCols"], [146, 2, 1, "", "getLazyAnnotator"], [146, 2, 1, "", "getOutputCol"], [146, 2, 1, "", "setInputCols"], [146, 2, 1, "", "setLazyAnnotator"], [146, 2, 1, "", "setOutputCol"]], "python.sparknlp.common.properties": [[149, 1, 1, "", "HasEmbeddingsProperties"]], "python.sparknlp.common.properties.HasEmbeddingsProperties": [[149, 2, 1, "", "getDimension"], [149, 2, 1, "", "setDimension"]], "python.sparknlp.common.read_as": [[150, 1, 1, "", "ReadAs"]], "python.sparknlp.common.recursive_annotator_approach": [[151, 1, 1, "", "RecursiveAnnotatorApproach"]], "python.sparknlp.common.utils": [[153, 3, 1, "", "ExternalResource"]], "python.sparknlp.functions": [[154, 3, 1, "", "explode_annotations_col"], [154, 3, 1, "", "filter_by_annotations_col"], [154, 3, 1, "", "map_annotations"], [154, 3, 1, "", "map_annotations_array"], [154, 3, 1, "", "map_annotations_col"], [154, 3, 1, "", "map_annotations_cols"], [154, 3, 1, "", "map_annotations_strict"]], "python.sparknlp.internal": [[156, 0, 0, "-", "annotator_java_ml"], [157, 0, 0, "-", "annotator_transformer"], [158, 0, 0, "-", "extended_java_wrapper"], [160, 0, 0, "-", "params_getters_setters"], [161, 0, 0, "-", "recursive"]], "python.sparknlp.internal.annotator_java_ml": [[156, 1, 1, "", "AnnotatorJavaMLReadable"], [156, 1, 1, "", "AnnotatorJavaMLReader"]], "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[156, 2, 1, "", "read"]], "python.sparknlp.internal.annotator_transformer": [[157, 1, 1, "", "AnnotatorTransformer"]], "python.sparknlp.internal.extended_java_wrapper": [[158, 1, 1, "", "ExtendedJavaWrapper"]], "python.sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[158, 2, 1, "", "new_java_array"]], "python.sparknlp.internal.params_getters_setters": [[160, 1, 1, "", "ParamsGettersSetters"]], "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[160, 2, 1, "", "getParamValue"], [160, 2, 1, "", "setParamValue"]], "python.sparknlp.internal.recursive": [[161, 1, 1, "", "RecursiveEstimator"], [161, 1, 1, "", "RecursiveTransformer"]], "python.sparknlp.internal.recursive.RecursiveEstimator": [[161, 2, 1, "", "fit"]], "python.sparknlp.logging": [[162, 0, 0, "-", "comet"]], "python.sparknlp.logging.comet": [[162, 1, 1, "", "CometLogger"]], "python.sparknlp.logging.comet.CometLogger": [[162, 2, 1, "", "end"], [162, 2, 1, "", "log_asset"], [162, 2, 1, "", "log_asset_data"], [162, 2, 1, "", "log_completed_run"], [162, 2, 1, "", "log_metrics"], [162, 2, 1, "", "log_parameters"], [162, 2, 1, "", "log_pipeline_parameters"], [162, 2, 1, "", "log_visualization"], [162, 2, 1, "", "monitor"]], "python.sparknlp.pretrained": [[165, 0, 0, "-", "pretrained_pipeline"], [166, 0, 0, "-", "resource_downloader"], [167, 0, 0, "-", "utils"]], "python.sparknlp.pretrained.pretrained_pipeline": [[165, 1, 1, "", "PretrainedPipeline"]], "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[165, 2, 1, "", "annotate"], [165, 2, 1, "", "fullAnnotate"], [165, 2, 1, "", "transform"]], "python.sparknlp.training": [[169, 0, 0, "-", "_tf_graph_builders"], [184, 0, 0, "-", "_tf_graph_builders_1x"], [191, 0, 0, "-", "conll"], [192, 0, 0, "-", "conllu"], [194, 0, 0, "-", "pos"], [195, 0, 0, "-", "pub_tator"], [196, 0, 0, "-", "tfgraphs"]], "python.sparknlp.training._tf_graph_builders": [[168, 0, 0, "-", "graph_builders"], [172, 0, 0, "-", "ner_dl"], [179, 0, 0, "-", "tf2contrib"]], "python.sparknlp.training._tf_graph_builders.graph_builders": [[168, 1, 1, "", "NerTFGraphBuilder"], [168, 1, 1, "", "TFGraphBuilder"], [168, 1, 1, "", "TFGraphBuilderFactory"], [168, 4, 1, "", "TensorflowAddonsNeeded"], [168, 4, 1, "", "WrongTFVersion"]], "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory": [[168, 2, 1, "", "build"], [168, 2, 1, "", "get_models"], [168, 2, 1, "", "print_model_params"]], "python.sparknlp.training._tf_graph_builders.ner_dl": [[170, 0, 0, "-", "create_graph"], [171, 0, 0, "-", "dataset_encoder"], [173, 0, 0, "-", "ner_model"], [174, 0, 0, "-", "ner_model_saver"], [175, 0, 0, "-", "sentence_grouper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib": [[176, 0, 0, "-", "core_rnn_cell"], [177, 0, 0, "-", "fused_rnn_cell"], [178, 0, 0, "-", "gru_ops"], [180, 0, 0, "-", "lstm_ops"], [181, 0, 0, "-", "rnn"], [182, 0, 0, "-", "rnn_cell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[176, 1, 1, "", "EmbeddingWrapper"], [176, 1, 1, "", "InputProjectionWrapper"], [176, 1, 1, "", "OutputProjectionWrapper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper": [[176, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper": [[176, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper": [[176, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[177, 1, 1, "", "FusedRNNCell"], [177, 1, 1, "", "FusedRNNCellAdaptor"], [177, 1, 1, "", "TimeReversedFusedRNN"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[178, 1, 1, "", "GRUBlockCell"], [178, 1, 1, "", "GRUBlockCellV2"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell": [[178, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2": [[178, 2, 1, "", "build"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[180, 1, 1, "", "LSTMBlockCell"], [180, 1, 1, "", "LSTMBlockFusedCell"], [180, 1, 1, "", "LSTMBlockWrapper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell": [[180, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockFusedCell": [[180, 2, 1, "", "num_units"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper": [[180, 2, 1, "", "call"], [180, 2, 1, "", "num_units"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[181, 3, 1, "", "stack_bidirectional_dynamic_rnn"], [181, 3, 1, "", "stack_bidirectional_rnn"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[182, 1, 1, "", "AttentionCellWrapper"], [182, 1, 1, "", "BidirectionalGridLSTMCell"], [182, 1, 1, "", "CFNCell"], [182, 1, 1, "", "CompiledWrapper"], [182, 1, 1, "", "Conv1DLSTMCell"], [182, 1, 1, "", "Conv2DLSTMCell"], [182, 1, 1, "", "Conv3DLSTMCell"], [182, 1, 1, "", "ConvLSTMCell"], [182, 1, 1, "", "CoupledInputForgetGateLSTMCell"], [182, 1, 1, "", "GLSTMCell"], [182, 1, 1, "", "GridLSTMCell"], [182, 1, 1, "", "HighwayWrapper"], [182, 1, 1, "", "IndRNNCell"], [182, 1, 1, "", "IndyGRUCell"], [182, 1, 1, "", "IndyLSTMCell"], [182, 1, 1, "", "IntersectionRNNCell"], [182, 1, 1, "", "LayerNormBasicLSTMCell"], [182, 1, 1, "", "LayerNormLSTMCell"], [182, 1, 1, "", "MinimalRNNCell"], [182, 1, 1, "", "NASCell"], [182, 1, 1, "", "NTMCell"], [182, 1, 1, "", "PhasedLSTMCell"], [182, 1, 1, "", "SRUCell"], [182, 1, 1, "", "TimeFreqLSTMCell"], [182, 1, 1, "", "UGRNNCell"], [182, 1, 1, "", "WeightNormLSTMCell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell": [[182, 2, 1, "", "call"]], "python.sparknlp.training._tf_graph_builders_1x": [[183, 0, 0, "-", "graph_builders"], [187, 0, 0, "-", "ner_dl"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders": [[183, 1, 1, "", "NerTFGraphBuilder"], [183, 1, 1, "", "TFGraphBuilder"], [183, 1, 1, "", "TFGraphBuilderFactory"], [183, 4, 1, "", "WrongTFVersion"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory": [[183, 2, 1, "", "build"], [183, 2, 1, "", "get_models"], [183, 2, 1, "", "print_model_params"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl": [[185, 0, 0, "-", "create_graph"], [186, 0, 0, "-", "dataset_encoder"], [188, 0, 0, "-", "ner_model"], [189, 0, 0, "-", "ner_model_saver"], [190, 0, 0, "-", "sentence_grouper"]], "python.sparknlp.training.conll": [[191, 1, 1, "", "CoNLL"]], "python.sparknlp.training.conll.CoNLL": [[191, 2, 1, "", "readDataset"]], "python.sparknlp.training.conllu": [[192, 1, 1, "", "CoNLLU"]], "python.sparknlp.training.conllu.CoNLLU": [[192, 2, 1, "", "readDataset"]], "python.sparknlp.training.pos": [[194, 1, 1, "", "POS"]], "python.sparknlp.training.pos.POS": [[194, 2, 1, "", "readDataset"]], "python.sparknlp.training.pub_tator": [[195, 1, 1, "", "PubTator"]], "python.sparknlp.training.pub_tator.PubTator": [[195, 2, 1, "", "readDataset"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "exception", "Python exception"]}, "titleterms": {"api": [1, 199], "refer": [1, 199], "get": [10, 205], "start": 10, "spark": [10, 11, 200, 205, 209], "nlp": [10, 11, 200, 209], "cheat": 10, "sheet": 10, "requir": 10, "instal": [10, 200], "us": [10, 200, 209], "conda": 10, "virtualenv": 10, "session": 10, "from": 10, "python": [10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198], "document": 11, "content": [11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 165, 168, 176, 177, 178, 180, 181, 182, 183, 191, 192, 194, 195], "sparknlp": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198], "annot": [12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 203, 204, 205], "modul": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 153, 154, 156, 157, 158, 160, 161, 162, 165, 168, 176, 177, 178, 180, 181, 182, 183, 191, 192, 194, 195, 199], "class": [12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 80, 82, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 102, 104, 105, 107, 108, 109, 111, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 156, 157, 158, 160, 161, 162, 165, 168, 176, 177, 178, 180, 182, 183, 191, 192, 194, 195], "annotation_audio": 13, "annotation_imag": 14, "audio": [15, 16], "submodul": [15, 32, 47, 49, 52, 64, 76, 78, 79, 81, 86, 91, 101, 103, 106, 110, 114, 121, 126, 138, 148, 155, 159, 163, 164, 179, 193], "wav2vec2_for_ctc": 16, "chunker": 17, "classifier_dl": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46], "albert_for_question_answ": 18, "albert_for_sequence_classif": 19, "albert_for_token_classif": 20, "bert_for_question_answ": 21, "bert_for_sequence_classif": 22, "bert_for_token_classif": 23, "camembert_for_token_classif": 24, "deberta_for_question_answ": 26, "deberta_for_sequence_classif": 27, "deberta_for_token_classif": 28, "distil_bert_for_question_answ": 29, "distil_bert_for_sequence_classif": 30, "distil_bert_for_token_classif": 31, "longformer_for_question_answ": 33, "longformer_for_sequence_classif": 34, "longformer_for_token_classif": 35, "multi_classifier_dl": 36, "roberta_for_question_answ": 37, "roberta_for_sequence_classif": 38, "roberta_for_token_classif": 39, "sentiment_dl": 40, "tapas_for_question_answ": 41, "xlm_roberta_for_question_answ": 42, "xlm_roberta_for_sequence_classif": 43, "xlm_roberta_for_token_classif": 44, "xlnet_for_sequence_classif": 45, "xlnet_for_token_classif": 46, "coref": [47, 48], "spanbert_coref": 48, "cv": [49, 50], "vit_for_image_classif": 50, "depend": [51, 52, 53], "dependency_pars": 51, "typed_dependency_pars": 53, "document_norm": 54, "embed": [55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "albert_embed": 55, "bert_embed": 56, "bert_sentence_embed": 57, "camembert_embed": 58, "chunk_embed": 59, "deberta_embed": 60, "distil_bert_embed": 61, "doc2vec": 62, "elmo_embed": 63, "longformer_embed": 65, "roberta_embed": 66, "roberta_sentence_embed": 67, "sentence_embed": 68, "universal_sentence_encod": 69, "word2vec": 70, "word_embed": 71, "xlm_roberta_embed": 72, "xlm_roberta_sentence_embed": 73, "xlnet_embed": 74, "er": [75, 76], "entity_rul": 75, "graph_extract": 77, "subpackag": [78, 155, 169], "keyword_extract": [79, 80], "yake_keyword_extract": 80, "ld_dl": [81, 82], "language_detector_dl": 82, "lemmat": 83, "matcher": [84, 85, 86, 87, 88, 89], "big_text_match": 84, "date_match": 85, "multi_date_match": 87, "regex_match": 88, "text_match": 89, "n_gram_gener": 90, "ner": [91, 92, 93, 94, 95, 96], "ner_approach": 92, "ner_convert": 93, "ner_crf": 94, "ner_dl": [95, 170, 171, 172, 173, 174, 175, 185, 186, 187, 188, 189, 190], "ner_overwrit": 96, "normal": 97, "param": [98, 99, 100], "classifier_encod": 98, "evaluation_dl_param": 99, "po": [101, 102, 194, 210], "perceptron": 102, "sentenc": [103, 104, 105, 205], "sentence_detector": 104, "sentence_detector_dl": 105, "sentiment": [106, 107, 108], "sentiment_detector": 107, "vivekn_senti": 108, "seq2seq": [109, 110, 111, 112], "gpt2_transform": 109, "marian_transform": 111, "t5_transform": 112, "spell_check": [113, 114, 115, 116], "context_spell_check": 113, "norvig_sweet": 115, "symmetric_delet": 116, "stemmer": 117, "stop_words_clean": 118, "tf_ner_dl_graph_build": 119, "token": [120, 121, 122, 123, 124, 125, 205], "chunk_token": 120, "recursive_token": 122, "regex_token": 123, "token2_chunk": 124, "w": [126, 127], "word_segment": 127, "base": [128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143], "audio_assembl": 128, "chunk2_doc": 129, "doc2_chunk": 130, "document_assembl": 131, "embeddings_finish": 132, "finish": [133, 205], "graph_finish": 134, "has_recursive_fit": 135, "has_recursive_transform": 136, "image_assembl": 137, "light_pipelin": 139, "multi_document_assembl": 140, "recursive_pipelin": 141, "table_assembl": 142, "token_assembl": 143, "common": [144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 204], "annotator_approach": 144, "annotator_model": 145, "annotator_properti": 146, "coverage_result": 147, "properti": 149, "read_a": 150, "recursive_annotator_approach": 151, "storag": 152, "util": [153, 167, 198], "function": [153, 154, 155, 181, 204, 206], "packag": 155, "intern": [156, 157, 158, 159, 160, 161], "annotator_java_ml": 156, "annotator_transform": 157, "extended_java_wrapp": 158, "params_getters_sett": 160, "recurs": 161, "log": [162, 163, 200, 202], "comet": [162, 200], "pretrain": [164, 165, 166, 167, 204, 208, 209], "pretrained_pipelin": 165, "resource_download": 166, "train": [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 210], "_tf_graph_build": [168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182], "graph_build": [168, 183], "create_graph": [170, 185], "dataset_encod": [171, 186], "ner_model": [173, 188], "ner_model_sav": [174, 189], "sentence_group": [175, 190], "tf2contrib": [176, 177, 178, 179, 180, 181, 182], "core_rnn_cel": 176, "fused_rnn_cel": 177, "gru_op": 178, "lstm_op": 180, "rnn": 181, "rnn_cell": 182, "_tf_graph_builders_1x": [183, 184, 185, 186, 187, 188, 189, 190], "conll": [191, 210], "conllu": [192, 210], "pub_tat": 195, "tfgraph": 196, "upload_to_hub": 197, "A": 200, "meta": 200, "machin": [200, 201], "learn": [200, 201], "platform": [200, 201], "pipelin": [200, 205, 208, 209], "paramet": 200, "evalu": 200, "metric": 200, "visual": 200, "run": 200, "an": 200, "offlin": 200, "experi": 200, "mlflow": 201, "lifecycl": 201, "third": 202, "parti": 202, "project": 202, "approach": 204, "model": 204, "note": 204, "avail": [204, 209], "set": 205, "up": 205, "your": 205, "own": 205, "type": 205, "necessari": 205, "import": 205, "construct": 205, "documentassembl": 205, "data": 205, "detect": 205, "out": 205, "put": 205, "all": 205, "togeth": 205, "ml": [205, 209], "helper": 206, "user": 207, "guid": 207, "light": 208, "convert": 208, "pipelinemodel": 208, "download": 209, "As": 209, "lightpipelin": 209, "load": 210, "dataset": 210, "spell": 210, "checker": 210, "pubtat": 210}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"API Reference": [[1, "api-reference"], [199, "api-reference"]], "Getting Started": [[10, "getting-started"]], "Spark NLP Cheat Sheet": [[10, "spark-nlp-cheat-sheet"]], "Requirements": [[10, "requirements"]], "Installation": [[10, "installation"], [200, "installation"]], "Using Conda": [[10, "using-conda"]], "Using Virtualenv": [[10, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[10, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[11, "spark-nlp-documentation"]], "Content": [[11, "content"]], "python.sparknlp.annotation": [[12, "module-python.sparknlp.annotation"]], "Module Contents": [[12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [48, "module-contents"], [50, "module-contents"], [51, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [77, "module-contents"], [80, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [85, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [95, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [102, "module-contents"], [104, "module-contents"], [105, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [111, "module-contents"], [112, "module-contents"], [113, "module-contents"], [115, "module-contents"], [116, "module-contents"], [117, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [145, "module-contents"], [146, "module-contents"], [149, "module-contents"], [150, "module-contents"], [151, "module-contents"], [153, "module-contents"], [154, "module-contents"], [156, "module-contents"], [157, "module-contents"], [158, "module-contents"], [160, "module-contents"], [161, "module-contents"], [162, "module-contents"], [165, "module-contents"], [168, "module-contents"], [176, "module-contents"], [177, "module-contents"], [178, "module-contents"], [180, "module-contents"], [181, "module-contents"], [182, "module-contents"], [183, "module-contents"], [191, "module-contents"], [192, "module-contents"], [194, "module-contents"], [195, "module-contents"]], "Classes": [[12, "classes"], [13, "classes"], [14, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [44, "classes"], [45, "classes"], [46, "classes"], [48, "classes"], [50, "classes"], [51, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [75, "classes"], [77, "classes"], [80, "classes"], [82, "classes"], [83, "classes"], [84, "classes"], [85, "classes"], [87, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [95, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [99, "classes"], [102, "classes"], [104, "classes"], [105, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [111, "classes"], [112, "classes"], [113, "classes"], [115, "classes"], [116, "classes"], [117, "classes"], [118, "classes"], [119, "classes"], [120, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [145, "classes"], [146, "classes"], [149, "classes"], [150, "classes"], [151, "classes"], [156, "classes"], [157, "classes"], [158, "classes"], [160, "classes"], [161, "classes"], [162, "classes"], [165, "classes"], [168, "classes"], [176, "classes"], [177, "classes"], [178, "classes"], [180, "classes"], [182, "classes"], [183, "classes"], [191, "classes"], [192, "classes"], [194, "classes"], [195, "classes"]], "python.sparknlp.annotation_audio": [[13, "module-python.sparknlp.annotation_audio"]], "python.sparknlp.annotation_image": [[14, "module-python.sparknlp.annotation_image"]], "python.sparknlp.annotator.audio": [[15, "module-python.sparknlp.annotator.audio"]], "Submodules": [[15, "submodules"], [32, "submodules"], [47, "submodules"], [49, "submodules"], [52, "submodules"], [64, "submodules"], [76, "submodules"], [78, "submodules"], [79, "submodules"], [81, "submodules"], [86, "submodules"], [91, "submodules"], [101, "submodules"], [103, "submodules"], [106, "submodules"], [110, "submodules"], [114, "submodules"], [121, "submodules"], [126, "submodules"], [138, "submodules"], [148, "submodules"], [155, "submodules"], [159, "submodules"], [163, "submodules"], [164, "submodules"], [179, "submodules"], [193, "submodules"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc": [[16, "module-python.sparknlp.annotator.audio.wav2vec2_for_ctc"]], "python.sparknlp.annotator.chunker": [[17, "module-python.sparknlp.annotator.chunker"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering": [[18, "module-python.sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[19, "module-python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification": [[20, "module-python.sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering": [[21, "module-python.sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[22, "module-python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification": [[23, "module-python.sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[24, "module-python.sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.classifier_dl": [[25, "module-python.sparknlp.annotator.classifier_dl.classifier_dl"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[26, "module-python.sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[27, "module-python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[28, "module-python.sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[29, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[30, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[31, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "python.sparknlp.annotator.classifier_dl": [[32, "module-python.sparknlp.annotator.classifier_dl"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[33, "module-python.sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[34, "module-python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[35, "module-python.sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl": [[36, "module-python.sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[37, "module-python.sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[38, "module-python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[39, "module-python.sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl": [[40, "module-python.sparknlp.annotator.classifier_dl.sentiment_dl"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[41, "module-python.sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[42, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[43, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[44, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[45, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[46, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "python.sparknlp.annotator.coref": [[47, "module-python.sparknlp.annotator.coref"]], "python.sparknlp.annotator.coref.spanbert_coref": [[48, "module-python.sparknlp.annotator.coref.spanbert_coref"]], "python.sparknlp.annotator.cv": [[49, "module-python.sparknlp.annotator.cv"]], "python.sparknlp.annotator.cv.vit_for_image_classification": [[50, "module-python.sparknlp.annotator.cv.vit_for_image_classification"]], "python.sparknlp.annotator.dependency.dependency_parser": [[51, "module-python.sparknlp.annotator.dependency.dependency_parser"]], "python.sparknlp.annotator.dependency": [[52, "module-python.sparknlp.annotator.dependency"]], "python.sparknlp.annotator.dependency.typed_dependency_parser": [[53, "module-python.sparknlp.annotator.dependency.typed_dependency_parser"]], "python.sparknlp.annotator.document_normalizer": [[54, "module-python.sparknlp.annotator.document_normalizer"]], "python.sparknlp.annotator.embeddings.albert_embeddings": [[55, "module-python.sparknlp.annotator.embeddings.albert_embeddings"]], "python.sparknlp.annotator.embeddings.bert_embeddings": [[56, "module-python.sparknlp.annotator.embeddings.bert_embeddings"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings": [[57, "module-python.sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "python.sparknlp.annotator.embeddings.camembert_embeddings": [[58, "module-python.sparknlp.annotator.embeddings.camembert_embeddings"]], "python.sparknlp.annotator.embeddings.chunk_embeddings": [[59, "module-python.sparknlp.annotator.embeddings.chunk_embeddings"]], "python.sparknlp.annotator.embeddings.deberta_embeddings": [[60, "module-python.sparknlp.annotator.embeddings.deberta_embeddings"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings": [[61, "module-python.sparknlp.annotator.embeddings.distil_bert_embeddings"]], "python.sparknlp.annotator.embeddings.doc2vec": [[62, "module-python.sparknlp.annotator.embeddings.doc2vec"]], "python.sparknlp.annotator.embeddings.elmo_embeddings": [[63, "module-python.sparknlp.annotator.embeddings.elmo_embeddings"]], "python.sparknlp.annotator.embeddings": [[64, "module-python.sparknlp.annotator.embeddings"]], "python.sparknlp.annotator.embeddings.longformer_embeddings": [[65, "module-python.sparknlp.annotator.embeddings.longformer_embeddings"]], "python.sparknlp.annotator.embeddings.roberta_embeddings": [[66, "module-python.sparknlp.annotator.embeddings.roberta_embeddings"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[67, "module-python.sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "python.sparknlp.annotator.embeddings.sentence_embeddings": [[68, "module-python.sparknlp.annotator.embeddings.sentence_embeddings"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder": [[69, "module-python.sparknlp.annotator.embeddings.universal_sentence_encoder"]], "python.sparknlp.annotator.embeddings.word2vec": [[70, "module-python.sparknlp.annotator.embeddings.word2vec"]], "python.sparknlp.annotator.embeddings.word_embeddings": [[71, "module-python.sparknlp.annotator.embeddings.word_embeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[72, "module-python.sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[73, "module-python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings": [[74, "module-python.sparknlp.annotator.embeddings.xlnet_embeddings"]], "python.sparknlp.annotator.er.entity_ruler": [[75, "module-python.sparknlp.annotator.er.entity_ruler"]], "python.sparknlp.annotator.er": [[76, "module-python.sparknlp.annotator.er"]], "python.sparknlp.annotator.graph_extraction": [[77, "module-python.sparknlp.annotator.graph_extraction"]], "python.sparknlp.annotator": [[78, "module-python.sparknlp.annotator"]], "Subpackages": [[78, "subpackages"], [155, "subpackages"], [169, "subpackages"]], "python.sparknlp.annotator.keyword_extraction": [[79, "module-python.sparknlp.annotator.keyword_extraction"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[80, "module-python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "python.sparknlp.annotator.ld_dl": [[81, "module-python.sparknlp.annotator.ld_dl"]], "python.sparknlp.annotator.ld_dl.language_detector_dl": [[82, "module-python.sparknlp.annotator.ld_dl.language_detector_dl"]], "python.sparknlp.annotator.lemmatizer": [[83, "module-python.sparknlp.annotator.lemmatizer"]], "python.sparknlp.annotator.matcher.big_text_matcher": [[84, "module-python.sparknlp.annotator.matcher.big_text_matcher"]], "python.sparknlp.annotator.matcher.date_matcher": [[85, "module-python.sparknlp.annotator.matcher.date_matcher"]], "python.sparknlp.annotator.matcher": [[86, "module-python.sparknlp.annotator.matcher"]], "python.sparknlp.annotator.matcher.multi_date_matcher": [[87, "module-python.sparknlp.annotator.matcher.multi_date_matcher"]], "python.sparknlp.annotator.matcher.regex_matcher": [[88, "module-python.sparknlp.annotator.matcher.regex_matcher"]], "python.sparknlp.annotator.matcher.text_matcher": [[89, "module-python.sparknlp.annotator.matcher.text_matcher"]], "python.sparknlp.annotator.n_gram_generator": [[90, "module-python.sparknlp.annotator.n_gram_generator"]], "python.sparknlp.annotator.ner": [[91, "module-python.sparknlp.annotator.ner"]], "python.sparknlp.annotator.ner.ner_approach": [[92, "module-python.sparknlp.annotator.ner.ner_approach"]], "python.sparknlp.annotator.ner.ner_converter": [[93, "module-python.sparknlp.annotator.ner.ner_converter"]], "python.sparknlp.annotator.ner.ner_crf": [[94, "module-python.sparknlp.annotator.ner.ner_crf"]], "python.sparknlp.annotator.ner.ner_dl": [[95, "module-python.sparknlp.annotator.ner.ner_dl"]], "python.sparknlp.annotator.ner.ner_overwriter": [[96, "module-python.sparknlp.annotator.ner.ner_overwriter"]], "python.sparknlp.annotator.normalizer": [[97, "module-python.sparknlp.annotator.normalizer"]], "python.sparknlp.annotator.param.classifier_encoder": [[98, "module-python.sparknlp.annotator.param.classifier_encoder"]], "python.sparknlp.annotator.param.evaluation_dl_params": [[99, "module-python.sparknlp.annotator.param.evaluation_dl_params"]], "python.sparknlp.annotator.param": [[100, "module-python.sparknlp.annotator.param"]], "python.sparknlp.annotator.pos": [[101, "module-python.sparknlp.annotator.pos"]], "python.sparknlp.annotator.pos.perceptron": [[102, "module-python.sparknlp.annotator.pos.perceptron"]], "python.sparknlp.annotator.sentence": [[103, "module-python.sparknlp.annotator.sentence"]], "python.sparknlp.annotator.sentence.sentence_detector": [[104, "module-python.sparknlp.annotator.sentence.sentence_detector"]], "python.sparknlp.annotator.sentence.sentence_detector_dl": [[105, "module-python.sparknlp.annotator.sentence.sentence_detector_dl"]], "python.sparknlp.annotator.sentiment": [[106, "module-python.sparknlp.annotator.sentiment"]], "python.sparknlp.annotator.sentiment.sentiment_detector": [[107, "module-python.sparknlp.annotator.sentiment.sentiment_detector"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment": [[108, "module-python.sparknlp.annotator.sentiment.vivekn_sentiment"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer": [[109, "module-python.sparknlp.annotator.seq2seq.gpt2_transformer"]], "python.sparknlp.annotator.seq2seq": [[110, "module-python.sparknlp.annotator.seq2seq"]], "python.sparknlp.annotator.seq2seq.marian_transformer": [[111, "module-python.sparknlp.annotator.seq2seq.marian_transformer"]], "python.sparknlp.annotator.seq2seq.t5_transformer": [[112, "module-python.sparknlp.annotator.seq2seq.t5_transformer"]], "python.sparknlp.annotator.spell_check.context_spell_checker": [[113, "module-python.sparknlp.annotator.spell_check.context_spell_checker"]], "python.sparknlp.annotator.spell_check": [[114, "module-python.sparknlp.annotator.spell_check"]], "python.sparknlp.annotator.spell_check.norvig_sweeting": [[115, "module-python.sparknlp.annotator.spell_check.norvig_sweeting"]], "python.sparknlp.annotator.spell_check.symmetric_delete": [[116, "module-python.sparknlp.annotator.spell_check.symmetric_delete"]], "python.sparknlp.annotator.stemmer": [[117, "module-python.sparknlp.annotator.stemmer"]], "python.sparknlp.annotator.stop_words_cleaner": [[118, "module-python.sparknlp.annotator.stop_words_cleaner"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder": [[119, "module-python.sparknlp.annotator.tf_ner_dl_graph_builder"]], "python.sparknlp.annotator.token.chunk_tokenizer": [[120, "module-python.sparknlp.annotator.token.chunk_tokenizer"]], "python.sparknlp.annotator.token": [[121, "module-python.sparknlp.annotator.token"]], "python.sparknlp.annotator.token.recursive_tokenizer": [[122, "module-python.sparknlp.annotator.token.recursive_tokenizer"]], "python.sparknlp.annotator.token.regex_tokenizer": [[123, "module-python.sparknlp.annotator.token.regex_tokenizer"]], "python.sparknlp.annotator.token.token2_chunk": [[124, "module-python.sparknlp.annotator.token.token2_chunk"]], "python.sparknlp.annotator.token.tokenizer": [[125, "module-python.sparknlp.annotator.token.tokenizer"]], "python.sparknlp.annotator.ws": [[126, "module-python.sparknlp.annotator.ws"]], "python.sparknlp.annotator.ws.word_segmenter": [[127, "module-python.sparknlp.annotator.ws.word_segmenter"]], "python.sparknlp.base.audio_assembler": [[128, "module-python.sparknlp.base.audio_assembler"]], "python.sparknlp.base.chunk2_doc": [[129, "module-python.sparknlp.base.chunk2_doc"]], "python.sparknlp.base.doc2_chunk": [[130, "module-python.sparknlp.base.doc2_chunk"]], "python.sparknlp.base.document_assembler": [[131, "module-python.sparknlp.base.document_assembler"]], "python.sparknlp.base.embeddings_finisher": [[132, "module-python.sparknlp.base.embeddings_finisher"]], "python.sparknlp.base.finisher": [[133, "module-python.sparknlp.base.finisher"]], "python.sparknlp.base.graph_finisher": [[134, "module-python.sparknlp.base.graph_finisher"]], "python.sparknlp.base.has_recursive_fit": [[135, "module-python.sparknlp.base.has_recursive_fit"]], "python.sparknlp.base.has_recursive_transform": [[136, "module-python.sparknlp.base.has_recursive_transform"]], "python.sparknlp.base.image_assembler": [[137, "module-python.sparknlp.base.image_assembler"]], "python.sparknlp.base": [[138, "module-python.sparknlp.base"]], "python.sparknlp.base.light_pipeline": [[139, "module-python.sparknlp.base.light_pipeline"]], "python.sparknlp.base.multi_document_assembler": [[140, "module-python.sparknlp.base.multi_document_assembler"]], "python.sparknlp.base.recursive_pipeline": [[141, "module-python.sparknlp.base.recursive_pipeline"]], "python.sparknlp.base.table_assembler": [[142, "module-python.sparknlp.base.table_assembler"]], "python.sparknlp.base.token_assembler": [[143, "module-python.sparknlp.base.token_assembler"]], "python.sparknlp.common.annotator_approach": [[144, "module-python.sparknlp.common.annotator_approach"]], "python.sparknlp.common.annotator_model": [[145, "module-python.sparknlp.common.annotator_model"]], "python.sparknlp.common.annotator_properties": [[146, "module-python.sparknlp.common.annotator_properties"]], "python.sparknlp.common.coverage_result": [[147, "module-python.sparknlp.common.coverage_result"]], "python.sparknlp.common": [[148, "module-python.sparknlp.common"]], "python.sparknlp.common.properties": [[149, "module-python.sparknlp.common.properties"]], "python.sparknlp.common.read_as": [[150, "module-python.sparknlp.common.read_as"]], "python.sparknlp.common.recursive_annotator_approach": [[151, "module-python.sparknlp.common.recursive_annotator_approach"]], "python.sparknlp.common.storage": [[152, "module-python.sparknlp.common.storage"]], "python.sparknlp.common.utils": [[153, "module-python.sparknlp.common.utils"]], "Functions": [[153, "functions"], [154, "functions"], [155, "functions"], [181, "functions"]], "python.sparknlp.functions": [[154, "module-python.sparknlp.functions"]], "python.sparknlp": [[155, "module-python.sparknlp"]], "Package Contents": [[155, "package-contents"]], "python.sparknlp.internal.annotator_java_ml": [[156, "module-python.sparknlp.internal.annotator_java_ml"]], "python.sparknlp.internal.annotator_transformer": [[157, "module-python.sparknlp.internal.annotator_transformer"]], "python.sparknlp.internal.extended_java_wrapper": [[158, "module-python.sparknlp.internal.extended_java_wrapper"]], "python.sparknlp.internal": [[159, "module-python.sparknlp.internal"]], "python.sparknlp.internal.params_getters_setters": [[160, "module-python.sparknlp.internal.params_getters_setters"]], "python.sparknlp.internal.recursive": [[161, "module-python.sparknlp.internal.recursive"]], "python.sparknlp.logging.comet": [[162, "module-python.sparknlp.logging.comet"]], "python.sparknlp.logging": [[163, "module-python.sparknlp.logging"]], "python.sparknlp.pretrained": [[164, "module-python.sparknlp.pretrained"]], "python.sparknlp.pretrained.pretrained_pipeline": [[165, "module-python.sparknlp.pretrained.pretrained_pipeline"]], "python.sparknlp.pretrained.resource_downloader": [[166, "module-python.sparknlp.pretrained.resource_downloader"]], "python.sparknlp.pretrained.utils": [[167, "module-python.sparknlp.pretrained.utils"]], "python.sparknlp.training._tf_graph_builders.graph_builders": [[168, "module-python.sparknlp.training._tf_graph_builders.graph_builders"]], "python.sparknlp.training._tf_graph_builders": [[169, "module-python.sparknlp.training._tf_graph_builders"]], "python.sparknlp.training._tf_graph_builders.ner_dl.create_graph": [[170, "module-python.sparknlp.training._tf_graph_builders.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder": [[171, "module-python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders.ner_dl": [[172, "module-python.sparknlp.training._tf_graph_builders.ner_dl"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model": [[173, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver": [[174, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper": [[175, "module-python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[176, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[177, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[178, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib": [[179, "module-python.sparknlp.training._tf_graph_builders.tf2contrib"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[180, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[181, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[182, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders": [[183, "module-python.sparknlp.training._tf_graph_builders_1x.graph_builders"]], "python.sparknlp.training._tf_graph_builders_1x": [[184, "module-python.sparknlp.training._tf_graph_builders_1x"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph": [[185, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder": [[186, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl": [[187, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model": [[188, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver": [[189, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper": [[190, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"]], "python.sparknlp.training.conll": [[191, "module-python.sparknlp.training.conll"]], "python.sparknlp.training.conllu": [[192, "module-python.sparknlp.training.conllu"]], "python.sparknlp.training": [[193, "module-python.sparknlp.training"]], "python.sparknlp.training.pos": [[194, "module-python.sparknlp.training.pos"]], "python.sparknlp.training.pub_tator": [[195, "module-python.sparknlp.training.pub_tator"]], "python.sparknlp.training.tfgraphs": [[196, "module-python.sparknlp.training.tfgraphs"]], "python.sparknlp.upload_to_hub": [[197, "module-python.sparknlp.upload_to_hub"]], "python.sparknlp.util": [[198, "module-python.sparknlp.util"]], "Modules": [[199, "modules"]], "Comet - A meta machine learning platform": [[200, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[200, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[200, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[200, "logging-evaluation-metrics"]], "Logging Visualizations": [[200, "logging-visualizations"]], "Running An Offline Experiment": [[200, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[201, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[202, "third-party-projects"]], "Logging": [[202, "logging"]], "Annotation": [[203, "annotation"]], "Annotators": [[204, "annotators"]], "Annotator Approaches": [[204, "annotator-approaches"]], "Annotator Models": [[204, "annotator-models"]], "Note": [[204, "note"]], "Pretrained Models": [[204, "pretrained-models"]], "Common Functions": [[204, "common-functions"]], "Available Annotators": [[204, "available-annotators"]], "Setting up your own pipeline": [[205, "setting-up-your-own-pipeline"]], "Annotator types": [[205, "annotator-types"]], "Necessary imports": [[205, "necessary-imports"]], "Constructing the Pipeline": [[205, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[205, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[205, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[205, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[205, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[206, "helper-functions"]], "User Guide": [[207, "user-guide"]], "Light Pipelines": [[208, "light-pipelines"]], "Converting PipelineModels": [[208, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[208, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[209, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[209, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[209, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[209, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[209, "available-pipelines"]], "Loading datasets for training": [[210, "loading-datasets-for-training"]], "POS Dataset": [[210, "pos-dataset"]], "CoNLL Dataset": [[210, "conll-dataset"]], "CoNLLU Dataset": [[210, "conllu-dataset"]], "Spell Checkers Dataset": [[210, "spell-checkers-dataset"]], "PubTator Dataset": [[210, "pubtator-dataset"]]}, "indexentries": {"annotation (class in python.sparknlp.annotation)": [[12, "python.sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[12, "python.sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.fromRow"]], "module": [[12, "module-python.sparknlp.annotation"], [13, "module-python.sparknlp.annotation_audio"], [14, "module-python.sparknlp.annotation_image"], [15, "module-python.sparknlp.annotator.audio"], [16, "module-python.sparknlp.annotator.audio.wav2vec2_for_ctc"], [17, "module-python.sparknlp.annotator.chunker"], [18, "module-python.sparknlp.annotator.classifier_dl.albert_for_question_answering"], [19, "module-python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [20, "module-python.sparknlp.annotator.classifier_dl.albert_for_token_classification"], [21, "module-python.sparknlp.annotator.classifier_dl.bert_for_question_answering"], [22, "module-python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [23, "module-python.sparknlp.annotator.classifier_dl.bert_for_token_classification"], [24, "module-python.sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [25, "module-python.sparknlp.annotator.classifier_dl.classifier_dl"], [26, "module-python.sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [27, "module-python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [28, "module-python.sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [29, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [30, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [31, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [32, "module-python.sparknlp.annotator.classifier_dl"], [33, "module-python.sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [34, "module-python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [35, "module-python.sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [36, "module-python.sparknlp.annotator.classifier_dl.multi_classifier_dl"], [37, "module-python.sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [38, "module-python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [39, "module-python.sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [40, "module-python.sparknlp.annotator.classifier_dl.sentiment_dl"], [41, "module-python.sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [42, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [43, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [44, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [45, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [46, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [47, "module-python.sparknlp.annotator.coref"], [48, "module-python.sparknlp.annotator.coref.spanbert_coref"], [49, "module-python.sparknlp.annotator.cv"], [50, "module-python.sparknlp.annotator.cv.vit_for_image_classification"], [51, "module-python.sparknlp.annotator.dependency.dependency_parser"], [52, "module-python.sparknlp.annotator.dependency"], [53, "module-python.sparknlp.annotator.dependency.typed_dependency_parser"], [54, "module-python.sparknlp.annotator.document_normalizer"], [55, "module-python.sparknlp.annotator.embeddings.albert_embeddings"], [56, "module-python.sparknlp.annotator.embeddings.bert_embeddings"], [57, "module-python.sparknlp.annotator.embeddings.bert_sentence_embeddings"], [58, "module-python.sparknlp.annotator.embeddings.camembert_embeddings"], [59, "module-python.sparknlp.annotator.embeddings.chunk_embeddings"], [60, "module-python.sparknlp.annotator.embeddings.deberta_embeddings"], [61, "module-python.sparknlp.annotator.embeddings.distil_bert_embeddings"], [62, "module-python.sparknlp.annotator.embeddings.doc2vec"], [63, "module-python.sparknlp.annotator.embeddings.elmo_embeddings"], [64, "module-python.sparknlp.annotator.embeddings"], [65, "module-python.sparknlp.annotator.embeddings.longformer_embeddings"], [66, "module-python.sparknlp.annotator.embeddings.roberta_embeddings"], [67, "module-python.sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [68, "module-python.sparknlp.annotator.embeddings.sentence_embeddings"], [69, "module-python.sparknlp.annotator.embeddings.universal_sentence_encoder"], [70, "module-python.sparknlp.annotator.embeddings.word2vec"], [71, "module-python.sparknlp.annotator.embeddings.word_embeddings"], [72, "module-python.sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [73, "module-python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [74, "module-python.sparknlp.annotator.embeddings.xlnet_embeddings"], [75, "module-python.sparknlp.annotator.er.entity_ruler"], [76, "module-python.sparknlp.annotator.er"], [77, "module-python.sparknlp.annotator.graph_extraction"], [78, "module-python.sparknlp.annotator"], [79, "module-python.sparknlp.annotator.keyword_extraction"], [80, "module-python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [81, "module-python.sparknlp.annotator.ld_dl"], [82, "module-python.sparknlp.annotator.ld_dl.language_detector_dl"], [83, "module-python.sparknlp.annotator.lemmatizer"], [84, "module-python.sparknlp.annotator.matcher.big_text_matcher"], [85, "module-python.sparknlp.annotator.matcher.date_matcher"], [86, "module-python.sparknlp.annotator.matcher"], [87, "module-python.sparknlp.annotator.matcher.multi_date_matcher"], [88, "module-python.sparknlp.annotator.matcher.regex_matcher"], [89, "module-python.sparknlp.annotator.matcher.text_matcher"], [90, "module-python.sparknlp.annotator.n_gram_generator"], [91, "module-python.sparknlp.annotator.ner"], [92, "module-python.sparknlp.annotator.ner.ner_approach"], [93, "module-python.sparknlp.annotator.ner.ner_converter"], [94, "module-python.sparknlp.annotator.ner.ner_crf"], [95, "module-python.sparknlp.annotator.ner.ner_dl"], [96, "module-python.sparknlp.annotator.ner.ner_overwriter"], [97, "module-python.sparknlp.annotator.normalizer"], [98, "module-python.sparknlp.annotator.param.classifier_encoder"], [99, "module-python.sparknlp.annotator.param.evaluation_dl_params"], [100, "module-python.sparknlp.annotator.param"], [101, "module-python.sparknlp.annotator.pos"], [102, "module-python.sparknlp.annotator.pos.perceptron"], [103, "module-python.sparknlp.annotator.sentence"], [104, "module-python.sparknlp.annotator.sentence.sentence_detector"], [105, "module-python.sparknlp.annotator.sentence.sentence_detector_dl"], [106, "module-python.sparknlp.annotator.sentiment"], [107, "module-python.sparknlp.annotator.sentiment.sentiment_detector"], [108, "module-python.sparknlp.annotator.sentiment.vivekn_sentiment"], [109, "module-python.sparknlp.annotator.seq2seq.gpt2_transformer"], [110, "module-python.sparknlp.annotator.seq2seq"], [111, "module-python.sparknlp.annotator.seq2seq.marian_transformer"], [112, "module-python.sparknlp.annotator.seq2seq.t5_transformer"], [113, "module-python.sparknlp.annotator.spell_check.context_spell_checker"], [114, "module-python.sparknlp.annotator.spell_check"], [115, "module-python.sparknlp.annotator.spell_check.norvig_sweeting"], [116, "module-python.sparknlp.annotator.spell_check.symmetric_delete"], [117, "module-python.sparknlp.annotator.stemmer"], [118, "module-python.sparknlp.annotator.stop_words_cleaner"], [119, "module-python.sparknlp.annotator.tf_ner_dl_graph_builder"], [120, "module-python.sparknlp.annotator.token.chunk_tokenizer"], [121, "module-python.sparknlp.annotator.token"], [122, "module-python.sparknlp.annotator.token.recursive_tokenizer"], [123, "module-python.sparknlp.annotator.token.regex_tokenizer"], [124, "module-python.sparknlp.annotator.token.token2_chunk"], [125, "module-python.sparknlp.annotator.token.tokenizer"], [126, "module-python.sparknlp.annotator.ws"], [127, "module-python.sparknlp.annotator.ws.word_segmenter"], [128, "module-python.sparknlp.base.audio_assembler"], [129, "module-python.sparknlp.base.chunk2_doc"], [130, "module-python.sparknlp.base.doc2_chunk"], [131, "module-python.sparknlp.base.document_assembler"], [132, "module-python.sparknlp.base.embeddings_finisher"], [133, "module-python.sparknlp.base.finisher"], [134, "module-python.sparknlp.base.graph_finisher"], [135, "module-python.sparknlp.base.has_recursive_fit"], [136, "module-python.sparknlp.base.has_recursive_transform"], [137, "module-python.sparknlp.base.image_assembler"], [138, "module-python.sparknlp.base"], [139, "module-python.sparknlp.base.light_pipeline"], [140, "module-python.sparknlp.base.multi_document_assembler"], [141, "module-python.sparknlp.base.recursive_pipeline"], [142, "module-python.sparknlp.base.table_assembler"], [143, "module-python.sparknlp.base.token_assembler"], [144, "module-python.sparknlp.common.annotator_approach"], [145, "module-python.sparknlp.common.annotator_model"], [146, "module-python.sparknlp.common.annotator_properties"], [147, "module-python.sparknlp.common.coverage_result"], [148, "module-python.sparknlp.common"], [149, "module-python.sparknlp.common.properties"], [150, "module-python.sparknlp.common.read_as"], [151, "module-python.sparknlp.common.recursive_annotator_approach"], [152, "module-python.sparknlp.common.storage"], [153, "module-python.sparknlp.common.utils"], [154, "module-python.sparknlp.functions"], [155, "module-python.sparknlp"], [156, "module-python.sparknlp.internal.annotator_java_ml"], [157, "module-python.sparknlp.internal.annotator_transformer"], [158, "module-python.sparknlp.internal.extended_java_wrapper"], [159, "module-python.sparknlp.internal"], [160, "module-python.sparknlp.internal.params_getters_setters"], [161, "module-python.sparknlp.internal.recursive"], [162, "module-python.sparknlp.logging.comet"], [163, "module-python.sparknlp.logging"], [164, "module-python.sparknlp.pretrained"], [165, "module-python.sparknlp.pretrained.pretrained_pipeline"], [166, "module-python.sparknlp.pretrained.resource_downloader"], [167, "module-python.sparknlp.pretrained.utils"], [168, "module-python.sparknlp.training._tf_graph_builders.graph_builders"], [169, "module-python.sparknlp.training._tf_graph_builders"], [170, "module-python.sparknlp.training._tf_graph_builders.ner_dl.create_graph"], [171, "module-python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"], [172, "module-python.sparknlp.training._tf_graph_builders.ner_dl"], [173, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model"], [174, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"], [175, "module-python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"], [176, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"], [177, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"], [178, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"], [179, "module-python.sparknlp.training._tf_graph_builders.tf2contrib"], [180, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"], [181, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn"], [182, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"], [183, "module-python.sparknlp.training._tf_graph_builders_1x.graph_builders"], [184, "module-python.sparknlp.training._tf_graph_builders_1x"], [185, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"], [186, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"], [187, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl"], [188, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"], [189, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"], [190, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"], [191, "module-python.sparknlp.training.conll"], [192, "module-python.sparknlp.training.conllu"], [193, "module-python.sparknlp.training"], [194, "module-python.sparknlp.training.pos"], [195, "module-python.sparknlp.training.pub_tator"], [196, "module-python.sparknlp.training.tfgraphs"], [197, "module-python.sparknlp.upload_to_hub"], [198, "module-python.sparknlp.util"]], "python.sparknlp.annotation": [[12, "module-python.sparknlp.annotation"]], "torow() (annotation static method)": [[12, "python.sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in python.sparknlp.annotation_audio)": [[13, "python.sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[13, "python.sparknlp.annotation_audio.AnnotationAudio.copy"]], "python.sparknlp.annotation_audio": [[13, "module-python.sparknlp.annotation_audio"]], "annotationimage (class in python.sparknlp.annotation_image)": [[14, "python.sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[14, "python.sparknlp.annotation_image.AnnotationImage.copy"]], "python.sparknlp.annotation_image": [[14, "module-python.sparknlp.annotation_image"]], "python.sparknlp.annotator.audio": [[15, "module-python.sparknlp.annotator.audio"]], "wav2vec2forctc (class in python.sparknlp.annotator.audio.wav2vec2_for_ctc)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "python.sparknlp.annotator.audio.wav2vec2_for_ctc": [[16, "module-python.sparknlp.annotator.audio.wav2vec2_for_ctc"]], "setconfigprotobytes() (wav2vec2forctc method)": [[16, "python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "chunker (class in python.sparknlp.annotator.chunker)": [[17, "python.sparknlp.annotator.chunker.Chunker"]], "python.sparknlp.annotator.chunker": [[17, "module-python.sparknlp.annotator.chunker"]], "setregexparsers() (chunker method)": [[17, "python.sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "albertforquestionanswering (class in python.sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.albert_for_question_answering": [[18, "module-python.sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "setconfigprotobytes() (albertforquestionanswering method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[18, "python.sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "albertforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[19, "module-python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "setcoalescesentences() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[19, "python.sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "albertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.albert_for_token_classification": [[20, "module-python.sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "setconfigprotobytes() (albertfortokenclassification method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[20, "python.sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "bertforquestionanswering (class in python.sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.bert_for_question_answering": [[21, "module-python.sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "setconfigprotobytes() (bertforquestionanswering method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[21, "python.sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "bertforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[22, "module-python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "setcoalescesentences() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[22, "python.sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "bertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.bert_for_token_classification": [[23, "module-python.sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "setconfigprotobytes() (bertfortokenclassification method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[23, "python.sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "camembertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[24, "module-python.sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[24, "python.sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "classifierdlapproach (class in python.sparknlp.annotator.classifier_dl.classifier_dl)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in python.sparknlp.annotator.classifier_dl.classifier_dl)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "python.sparknlp.annotator.classifier_dl.classifier_dl": [[25, "module-python.sparknlp.annotator.classifier_dl.classifier_dl"]], "setconfigprotobytes() (classifierdlmodel method)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[25, "python.sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "debertaforquestionanswering (class in python.sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[26, "module-python.sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[26, "python.sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "debertaforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[27, "module-python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[27, "python.sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "debertafortokenclassification (class in python.sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[28, "module-python.sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "setconfigprotobytes() (debertafortokenclassification method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[28, "python.sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "distilbertforquestionanswering (class in python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[29, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[29, "python.sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "distilbertforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[30, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[30, "python.sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "distilbertfortokenclassification (class in python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[31, "module-python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[31, "python.sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "python.sparknlp.annotator.classifier_dl": [[32, "module-python.sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in python.sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[33, "module-python.sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[33, "python.sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "longformerforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[34, "module-python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[34, "python.sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "longformerfortokenclassification (class in python.sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[35, "module-python.sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[35, "python.sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "multiclassifierdlapproach (class in python.sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in python.sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "python.sparknlp.annotator.classifier_dl.multi_classifier_dl": [[36, "module-python.sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[36, "python.sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "robertaforquestionanswering (class in python.sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[37, "module-python.sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[37, "python.sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "robertaforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[38, "module-python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[38, "python.sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "robertafortokenclassification (class in python.sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[39, "module-python.sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "setconfigprotobytes() (robertafortokenclassification method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[39, "python.sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sentimentdlapproach (class in python.sparknlp.annotator.classifier_dl.sentiment_dl)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in python.sparknlp.annotator.classifier_dl.sentiment_dl)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "python.sparknlp.annotator.classifier_dl.sentiment_dl": [[40, "module-python.sparknlp.annotator.classifier_dl.sentiment_dl"]], "setconfigprotobytes() (sentimentdlmodel method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[40, "python.sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "tapasforquestionanswering (class in python.sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[41, "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[41, "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[41, "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[41, "module-python.sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[42, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[42, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "xlmrobertaforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[43, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[43, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "xlmrobertafortokenclassification (class in python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[44, "module-python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[44, "python.sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "xlnetforsequenceclassification (class in python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[45, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[45, "python.sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "xlnetfortokenclassification (class in python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[46, "module-python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[46, "python.sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "python.sparknlp.annotator.coref": [[47, "module-python.sparknlp.annotator.coref"]], "spanbertcorefmodel (class in python.sparknlp.annotator.coref.spanbert_coref)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "python.sparknlp.annotator.coref.spanbert_coref": [[48, "module-python.sparknlp.annotator.coref.spanbert_coref"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[48, "python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "python.sparknlp.annotator.cv": [[49, "module-python.sparknlp.annotator.cv"]], "vitforimageclassification (class in python.sparknlp.annotator.cv.vit_for_image_classification)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "python.sparknlp.annotator.cv.vit_for_image_classification": [[50, "module-python.sparknlp.annotator.cv.vit_for_image_classification"]], "setconfigprotobytes() (vitforimageclassification method)": [[50, "python.sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "dependencyparserapproach (class in python.sparknlp.annotator.dependency.dependency_parser)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in python.sparknlp.annotator.dependency.dependency_parser)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "python.sparknlp.annotator.dependency.dependency_parser": [[51, "module-python.sparknlp.annotator.dependency.dependency_parser"]], "setconllu() (dependencyparserapproach method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[51, "python.sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "python.sparknlp.annotator.dependency": [[52, "module-python.sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in python.sparknlp.annotator.dependency.typed_dependency_parser)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in python.sparknlp.annotator.dependency.typed_dependency_parser)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "python.sparknlp.annotator.dependency.typed_dependency_parser": [[53, "module-python.sparknlp.annotator.dependency.typed_dependency_parser"]], "setconll2009() (typeddependencyparserapproach method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[53, "python.sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "documentnormalizer (class in python.sparknlp.annotator.document_normalizer)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "python.sparknlp.annotator.document_normalizer": [[54, "module-python.sparknlp.annotator.document_normalizer"]], "setaction() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[54, "python.sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "albertembeddings (class in python.sparknlp.annotator.embeddings.albert_embeddings)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.albert_embeddings": [[55, "module-python.sparknlp.annotator.embeddings.albert_embeddings"]], "setconfigprotobytes() (albertembeddings method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[55, "python.sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "bertembeddings (class in python.sparknlp.annotator.embeddings.bert_embeddings)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.bert_embeddings": [[56, "module-python.sparknlp.annotator.embeddings.bert_embeddings"]], "setconfigprotobytes() (bertembeddings method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[56, "python.sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "bertsentenceembeddings (class in python.sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.bert_sentence_embeddings": [[57, "module-python.sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[57, "python.sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "camembertembeddings (class in python.sparknlp.annotator.embeddings.camembert_embeddings)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.camembert_embeddings": [[58, "module-python.sparknlp.annotator.embeddings.camembert_embeddings"]], "setconfigprotobytes() (camembertembeddings method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[58, "python.sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "chunkembeddings (class in python.sparknlp.annotator.embeddings.chunk_embeddings)": [[59, "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "python.sparknlp.annotator.embeddings.chunk_embeddings": [[59, "module-python.sparknlp.annotator.embeddings.chunk_embeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[59, "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[59, "python.sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "debertaembeddings (class in python.sparknlp.annotator.embeddings.deberta_embeddings)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.deberta_embeddings": [[60, "module-python.sparknlp.annotator.embeddings.deberta_embeddings"]], "setconfigprotobytes() (debertaembeddings method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[60, "python.sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "distilbertembeddings (class in python.sparknlp.annotator.embeddings.distil_bert_embeddings)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.distil_bert_embeddings": [[61, "module-python.sparknlp.annotator.embeddings.distil_bert_embeddings"]], "setconfigprotobytes() (distilbertembeddings method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[61, "python.sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "doc2vecapproach (class in python.sparknlp.annotator.embeddings.doc2vec)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in python.sparknlp.annotator.embeddings.doc2vec)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "python.sparknlp.annotator.embeddings.doc2vec": [[62, "module-python.sparknlp.annotator.embeddings.doc2vec"]], "setmaxiter() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[62, "python.sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "elmoembeddings (class in python.sparknlp.annotator.embeddings.elmo_embeddings)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.elmo_embeddings": [[63, "module-python.sparknlp.annotator.embeddings.elmo_embeddings"]], "setbatchsize() (elmoembeddings method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[63, "python.sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "python.sparknlp.annotator.embeddings": [[64, "module-python.sparknlp.annotator.embeddings"]], "longformerembeddings (class in python.sparknlp.annotator.embeddings.longformer_embeddings)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.longformer_embeddings": [[65, "module-python.sparknlp.annotator.embeddings.longformer_embeddings"]], "setconfigprotobytes() (longformerembeddings method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[65, "python.sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "robertaembeddings (class in python.sparknlp.annotator.embeddings.roberta_embeddings)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.roberta_embeddings": [[66, "module-python.sparknlp.annotator.embeddings.roberta_embeddings"]], "setconfigprotobytes() (robertaembeddings method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[66, "python.sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "robertasentenceembeddings (class in python.sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[67, "module-python.sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[67, "python.sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sentenceembeddings (class in python.sparknlp.annotator.embeddings.sentence_embeddings)": [[68, "python.sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "python.sparknlp.annotator.embeddings.sentence_embeddings": [[68, "module-python.sparknlp.annotator.embeddings.sentence_embeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[68, "python.sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "universalsentenceencoder (class in python.sparknlp.annotator.embeddings.universal_sentence_encoder)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "python.sparknlp.annotator.embeddings.universal_sentence_encoder": [[69, "module-python.sparknlp.annotator.embeddings.universal_sentence_encoder"]], "setconfigprotobytes() (universalsentenceencoder method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[69, "python.sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "word2vecapproach (class in python.sparknlp.annotator.embeddings.word2vec)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in python.sparknlp.annotator.embeddings.word2vec)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "python.sparknlp.annotator.embeddings.word2vec": [[70, "module-python.sparknlp.annotator.embeddings.word2vec"]], "setmaxiter() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[70, "python.sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "wordembeddings (class in python.sparknlp.annotator.embeddings.word_embeddings)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in python.sparknlp.annotator.embeddings.word_embeddings)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "python.sparknlp.annotator.embeddings.word_embeddings": [[71, "module-python.sparknlp.annotator.embeddings.word_embeddings"]], "setreadcachesize() (wordembeddings method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[71, "python.sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in python.sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[72, "module-python.sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[72, "python.sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "xlmrobertasentenceembeddings (class in python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[73, "module-python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[73, "python.sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "xlnetembeddings (class in python.sparknlp.annotator.embeddings.xlnet_embeddings)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "python.sparknlp.annotator.embeddings.xlnet_embeddings": [[74, "module-python.sparknlp.annotator.embeddings.xlnet_embeddings"]], "setconfigprotobytes() (xlnetembeddings method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[74, "python.sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "entityrulerapproach (class in python.sparknlp.annotator.er.entity_ruler)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in python.sparknlp.annotator.er.entity_ruler)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "python.sparknlp.annotator.er.entity_ruler": [[75, "module-python.sparknlp.annotator.er.entity_ruler"]], "setalphabetresource() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setenablepatternregex() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setEnablePatternRegex"]], "setpatternsresource() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[75, "python.sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "python.sparknlp.annotator.er": [[76, "module-python.sparknlp.annotator.er"]], "graphextraction (class in python.sparknlp.annotator.graph_extraction)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction"]], "python.sparknlp.annotator.graph_extraction": [[77, "module-python.sparknlp.annotator.graph_extraction"]], "setdelimiter() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[77, "python.sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "python.sparknlp.annotator": [[78, "module-python.sparknlp.annotator"]], "python.sparknlp.annotator.keyword_extraction": [[79, "module-python.sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[80, "module-python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "setmaxngrams() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[80, "python.sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "python.sparknlp.annotator.ld_dl": [[81, "module-python.sparknlp.annotator.ld_dl"]], "languagedetectordl (class in python.sparknlp.annotator.ld_dl.language_detector_dl)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "python.sparknlp.annotator.ld_dl.language_detector_dl": [[82, "module-python.sparknlp.annotator.ld_dl.language_detector_dl"]], "setcoalescesentences() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[82, "python.sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "lemmatizer (class in python.sparknlp.annotator.lemmatizer)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in python.sparknlp.annotator.lemmatizer)": [[83, "python.sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[83, "python.sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "python.sparknlp.annotator.lemmatizer": [[83, "module-python.sparknlp.annotator.lemmatizer"]], "setdictionary() (lemmatizer method)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[83, "python.sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "bigtextmatcher (class in python.sparknlp.annotator.matcher.big_text_matcher)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in python.sparknlp.annotator.matcher.big_text_matcher)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "python.sparknlp.annotator.matcher.big_text_matcher": [[84, "module-python.sparknlp.annotator.matcher.big_text_matcher"]], "setcasesensitive() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[84, "python.sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "datematcher (class in python.sparknlp.annotator.matcher.date_matcher)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in python.sparknlp.annotator.matcher.date_matcher)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "python.sparknlp.annotator.matcher.date_matcher": [[85, "module-python.sparknlp.annotator.matcher.date_matcher"]], "setanchordateday() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[85, "python.sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "python.sparknlp.annotator.matcher": [[86, "module-python.sparknlp.annotator.matcher"]], "multidatematcher (class in python.sparknlp.annotator.matcher.multi_date_matcher)": [[87, "python.sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "python.sparknlp.annotator.matcher.multi_date_matcher": [[87, "module-python.sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in python.sparknlp.annotator.matcher.regex_matcher)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in python.sparknlp.annotator.matcher.regex_matcher)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "python.sparknlp.annotator.matcher.regex_matcher": [[88, "module-python.sparknlp.annotator.matcher.regex_matcher"]], "setexternalrules() (regexmatcher method)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setstrategy() (regexmatcher method)": [[88, "python.sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "textmatcher (class in python.sparknlp.annotator.matcher.text_matcher)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in python.sparknlp.annotator.matcher.text_matcher)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "python.sparknlp.annotator.matcher.text_matcher": [[89, "module-python.sparknlp.annotator.matcher.text_matcher"]], "setbuildfromtokens() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[89, "python.sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "ngramgenerator (class in python.sparknlp.annotator.n_gram_generator)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator"]], "python.sparknlp.annotator.n_gram_generator": [[90, "module-python.sparknlp.annotator.n_gram_generator"]], "setdelimiter() (ngramgenerator method)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[90, "python.sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "python.sparknlp.annotator.ner": [[91, "module-python.sparknlp.annotator.ner"]], "nerapproach (class in python.sparknlp.annotator.ner.ner_approach)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "python.sparknlp.annotator.ner.ner_approach": [[92, "module-python.sparknlp.annotator.ner.ner_approach"]], "setentities() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[92, "python.sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "nerconverter (class in python.sparknlp.annotator.ner.ner_converter)": [[93, "python.sparknlp.annotator.ner.ner_converter.NerConverter"]], "python.sparknlp.annotator.ner.ner_converter": [[93, "module-python.sparknlp.annotator.ner.ner_converter"]], "setwhitelist() (nerconverter method)": [[93, "python.sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "nercrfapproach (class in python.sparknlp.annotator.ner.ner_crf)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in python.sparknlp.annotator.ner.ner_crf)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "python.sparknlp.annotator.ner.ner_crf": [[94, "module-python.sparknlp.annotator.ner.ner_crf"]], "setc0() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[94, "python.sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "nerdlapproach (class in python.sparknlp.annotator.ner.ner_dl)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in python.sparknlp.annotator.ner.ner_dl)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "python.sparknlp.annotator.ner.ner_dl": [[95, "module-python.sparknlp.annotator.ner.ner_dl"]], "setbatchsize() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[95, "python.sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "neroverwriter (class in python.sparknlp.annotator.ner.ner_overwriter)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "python.sparknlp.annotator.ner.ner_overwriter": [[96, "module-python.sparknlp.annotator.ner.ner_overwriter"]], "setnerwords() (neroverwriter method)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[96, "python.sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "normalizer (class in python.sparknlp.annotator.normalizer)": [[97, "python.sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in python.sparknlp.annotator.normalizer)": [[97, "python.sparknlp.annotator.normalizer.NormalizerModel"]], "python.sparknlp.annotator.normalizer": [[97, "module-python.sparknlp.annotator.normalizer"]], "setcleanuppatterns() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[97, "python.sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "classifierencoder (class in python.sparknlp.annotator.param.classifier_encoder)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "python.sparknlp.annotator.param.classifier_encoder": [[98, "module-python.sparknlp.annotator.param.classifier_encoder"]], "setbatchsize() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[98, "python.sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "evaluationdlparams (class in python.sparknlp.annotator.param.evaluation_dl_params)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "python.sparknlp.annotator.param.evaluation_dl_params": [[99, "module-python.sparknlp.annotator.param.evaluation_dl_params"]], "setenableoutputlogs() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[99, "python.sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "python.sparknlp.annotator.param": [[100, "module-python.sparknlp.annotator.param"]], "python.sparknlp.annotator.pos": [[101, "module-python.sparknlp.annotator.pos"]], "perceptronapproach (class in python.sparknlp.annotator.pos.perceptron)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in python.sparknlp.annotator.pos.perceptron)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "python.sparknlp.annotator.pos.perceptron": [[102, "module-python.sparknlp.annotator.pos.perceptron"]], "setiterations() (perceptronapproach method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[102, "python.sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "python.sparknlp.annotator.sentence": [[103, "module-python.sparknlp.annotator.sentence"]], "sentencedetector (class in python.sparknlp.annotator.sentence.sentence_detector)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in python.sparknlp.annotator.sentence.sentence_detector)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "python.sparknlp.annotator.sentence.sentence_detector": [[104, "module-python.sparknlp.annotator.sentence.sentence_detector"]], "setcustombounds() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[104, "python.sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sentencedetectordlapproach (class in python.sparknlp.annotator.sentence.sentence_detector_dl)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in python.sparknlp.annotator.sentence.sentence_detector_dl)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "python.sparknlp.annotator.sentence.sentence_detector_dl": [[105, "module-python.sparknlp.annotator.sentence.sentence_detector_dl"]], "setcustombounds() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[105, "python.sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "python.sparknlp.annotator.sentiment": [[106, "module-python.sparknlp.annotator.sentiment"]], "sentimentdetector (class in python.sparknlp.annotator.sentiment.sentiment_detector)": [[107, "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in python.sparknlp.annotator.sentiment.sentiment_detector)": [[107, "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "python.sparknlp.annotator.sentiment.sentiment_detector": [[107, "module-python.sparknlp.annotator.sentiment.sentiment_detector"]], "setdictionary() (sentimentdetector method)": [[107, "python.sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "viveknsentimentapproach (class in python.sparknlp.annotator.sentiment.vivekn_sentiment)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in python.sparknlp.annotator.sentiment.vivekn_sentiment)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "python.sparknlp.annotator.sentiment.vivekn_sentiment": [[108, "module-python.sparknlp.annotator.sentiment.vivekn_sentiment"]], "setprunecorpus() (viveknsentimentapproach method)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[108, "python.sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "gpt2transformer (class in python.sparknlp.annotator.seq2seq.gpt2_transformer)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "python.sparknlp.annotator.seq2seq.gpt2_transformer": [[109, "module-python.sparknlp.annotator.seq2seq.gpt2_transformer"]], "setconfigprotobytes() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[109, "python.sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "python.sparknlp.annotator.seq2seq": [[110, "module-python.sparknlp.annotator.seq2seq"]], "mariantransformer (class in python.sparknlp.annotator.seq2seq.marian_transformer)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "python.sparknlp.annotator.seq2seq.marian_transformer": [[111, "module-python.sparknlp.annotator.seq2seq.marian_transformer"]], "setconfigprotobytes() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[111, "python.sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "t5transformer (class in python.sparknlp.annotator.seq2seq.t5_transformer)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "python.sparknlp.annotator.seq2seq.t5_transformer": [[112, "module-python.sparknlp.annotator.seq2seq.t5_transformer"]], "setconfigprotobytes() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[112, "python.sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "contextspellcheckerapproach (class in python.sparknlp.annotator.spell_check.context_spell_checker)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in python.sparknlp.annotator.spell_check.context_spell_checker)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "python.sparknlp.annotator.spell_check.context_spell_checker": [[113, "module-python.sparknlp.annotator.spell_check.context_spell_checker"]], "setbatchsize() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setcomparelowcase() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setinitialrate() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[113, "id0"], [113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "updateregexclass() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[113, "python.sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "python.sparknlp.annotator.spell_check": [[114, "module-python.sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in python.sparknlp.annotator.spell_check.norvig_sweeting)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in python.sparknlp.annotator.spell_check.norvig_sweeting)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "python.sparknlp.annotator.spell_check.norvig_sweeting": [[115, "module-python.sparknlp.annotator.spell_check.norvig_sweeting"]], "setcasesensitive() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[115, "python.sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "symmetricdeleteapproach (class in python.sparknlp.annotator.spell_check.symmetric_delete)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in python.sparknlp.annotator.spell_check.symmetric_delete)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "python.sparknlp.annotator.spell_check.symmetric_delete": [[116, "module-python.sparknlp.annotator.spell_check.symmetric_delete"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[116, "python.sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "stemmer (class in python.sparknlp.annotator.stemmer)": [[117, "python.sparknlp.annotator.stemmer.Stemmer"]], "python.sparknlp.annotator.stemmer": [[117, "module-python.sparknlp.annotator.stemmer"]], "stopwordscleaner (class in python.sparknlp.annotator.stop_words_cleaner)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "python.sparknlp.annotator.stop_words_cleaner": [[118, "module-python.sparknlp.annotator.stop_words_cleaner"]], "setcasesensitive() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[118, "python.sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "tfnerdlgraphbuilder (class in python.sparknlp.annotator.tf_ner_dl_graph_builder)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in python.sparknlp.annotator.tf_ner_dl_graph_builder)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "python.sparknlp.annotator.tf_ner_dl_graph_builder": [[119, "module-python.sparknlp.annotator.tf_ner_dl_graph_builder"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[119, "python.sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "chunktokenizer (class in python.sparknlp.annotator.token.chunk_tokenizer)": [[120, "python.sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in python.sparknlp.annotator.token.chunk_tokenizer)": [[120, "python.sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "python.sparknlp.annotator.token.chunk_tokenizer": [[120, "module-python.sparknlp.annotator.token.chunk_tokenizer"]], "python.sparknlp.annotator.token": [[121, "module-python.sparknlp.annotator.token"]], "recursivetokenizer (class in python.sparknlp.annotator.token.recursive_tokenizer)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in python.sparknlp.annotator.token.recursive_tokenizer)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "python.sparknlp.annotator.token.recursive_tokenizer": [[122, "module-python.sparknlp.annotator.token.recursive_tokenizer"]], "setinfixes() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[122, "python.sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "regextokenizer (class in python.sparknlp.annotator.token.regex_tokenizer)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "python.sparknlp.annotator.token.regex_tokenizer": [[123, "module-python.sparknlp.annotator.token.regex_tokenizer"]], "setmaxlength() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[123, "python.sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "token2chunk (class in python.sparknlp.annotator.token.token2_chunk)": [[124, "python.sparknlp.annotator.token.token2_chunk.Token2Chunk"]], "python.sparknlp.annotator.token.token2_chunk": [[124, "module-python.sparknlp.annotator.token.token2_chunk"]], "tokenizer (class in python.sparknlp.annotator.token.tokenizer)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in python.sparknlp.annotator.token.tokenizer)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "python.sparknlp.annotator.token.tokenizer": [[125, "module-python.sparknlp.annotator.token.tokenizer"]], "setcasesensitiveexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[125, "python.sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[125, "python.sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "python.sparknlp.annotator.ws": [[126, "module-python.sparknlp.annotator.ws"]], "wordsegmenterapproach (class in python.sparknlp.annotator.ws.word_segmenter)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in python.sparknlp.annotator.ws.word_segmenter)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "python.sparknlp.annotator.ws.word_segmenter": [[127, "module-python.sparknlp.annotator.ws.word_segmenter"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setposcolumn() (wordsegmenterapproach method)": [[127, "python.sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "audioassembler (class in python.sparknlp.base.audio_assembler)": [[128, "python.sparknlp.base.audio_assembler.AudioAssembler"]], "python.sparknlp.base.audio_assembler": [[128, "module-python.sparknlp.base.audio_assembler"]], "setinputcol() (audioassembler method)": [[128, "python.sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[128, "python.sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "chunk2doc (class in python.sparknlp.base.chunk2_doc)": [[129, "python.sparknlp.base.chunk2_doc.Chunk2Doc"]], "python.sparknlp.base.chunk2_doc": [[129, "module-python.sparknlp.base.chunk2_doc"]], "doc2chunk (class in python.sparknlp.base.doc2_chunk)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk"]], "python.sparknlp.base.doc2_chunk": [[130, "module-python.sparknlp.base.doc2_chunk"]], "setchunkcol() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[130, "python.sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "documentassembler (class in python.sparknlp.base.document_assembler)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler"]], "python.sparknlp.base.document_assembler": [[131, "module-python.sparknlp.base.document_assembler"]], "setcleanupmode() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[131, "python.sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "embeddingsfinisher (class in python.sparknlp.base.embeddings_finisher)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "python.sparknlp.base.embeddings_finisher": [[132, "module-python.sparknlp.base.embeddings_finisher"]], "setcleanannotations() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[132, "python.sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "finisher (class in python.sparknlp.base.finisher)": [[133, "python.sparknlp.base.finisher.Finisher"]], "python.sparknlp.base.finisher": [[133, "module-python.sparknlp.base.finisher"]], "setannotationsplitsymbol() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[133, "python.sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "graphfinisher (class in python.sparknlp.base.graph_finisher)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher"]], "python.sparknlp.base.graph_finisher": [[134, "module-python.sparknlp.base.graph_finisher"]], "setcleanannotations() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[134, "python.sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "hasrecursivefit (class in python.sparknlp.base.has_recursive_fit)": [[135, "python.sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "python.sparknlp.base.has_recursive_fit": [[135, "module-python.sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in python.sparknlp.base.has_recursive_transform)": [[136, "python.sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "python.sparknlp.base.has_recursive_transform": [[136, "module-python.sparknlp.base.has_recursive_transform"]], "imageassembler (class in python.sparknlp.base.image_assembler)": [[137, "python.sparknlp.base.image_assembler.ImageAssembler"]], "python.sparknlp.base.image_assembler": [[137, "module-python.sparknlp.base.image_assembler"]], "setinputcol() (imageassembler method)": [[137, "python.sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[137, "python.sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "python.sparknlp.base": [[138, "module-python.sparknlp.base"]], "lightpipeline (class in python.sparknlp.base.light_pipeline)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "python.sparknlp.base.light_pipeline": [[139, "module-python.sparknlp.base.light_pipeline"]], "setignoreunsupported() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "transform() (lightpipeline method)": [[139, "python.sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in python.sparknlp.base.multi_document_assembler)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "python.sparknlp.base.multi_document_assembler": [[140, "module-python.sparknlp.base.multi_document_assembler"]], "setcleanupmode() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[140, "python.sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "recursivepipeline (class in python.sparknlp.base.recursive_pipeline)": [[141, "python.sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in python.sparknlp.base.recursive_pipeline)": [[141, "python.sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "python.sparknlp.base.recursive_pipeline": [[141, "module-python.sparknlp.base.recursive_pipeline"]], "tableassembler (class in python.sparknlp.base.table_assembler)": [[142, "python.sparknlp.base.table_assembler.TableAssembler"]], "python.sparknlp.base.table_assembler": [[142, "module-python.sparknlp.base.table_assembler"]], "setcsvdelimiter() (tableassembler method)": [[142, "python.sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[142, "python.sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[142, "python.sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "tokenassembler (class in python.sparknlp.base.token_assembler)": [[143, "python.sparknlp.base.token_assembler.TokenAssembler"]], "python.sparknlp.base.token_assembler": [[143, "module-python.sparknlp.base.token_assembler"]], "setpreserveposition() (tokenassembler method)": [[143, "python.sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "annotatorapproach (class in python.sparknlp.common.annotator_approach)": [[144, "python.sparknlp.common.annotator_approach.AnnotatorApproach"]], "python.sparknlp.common.annotator_approach": [[144, "module-python.sparknlp.common.annotator_approach"]], "annotatormodel (class in python.sparknlp.common.annotator_model)": [[145, "python.sparknlp.common.annotator_model.AnnotatorModel"]], "python.sparknlp.common.annotator_model": [[145, "module-python.sparknlp.common.annotator_model"]], "annotatorproperties (class in python.sparknlp.common.annotator_properties)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "python.sparknlp.common.annotator_properties": [[146, "module-python.sparknlp.common.annotator_properties"]], "setinputcols() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[146, "python.sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "python.sparknlp.common.coverage_result": [[147, "module-python.sparknlp.common.coverage_result"]], "python.sparknlp.common": [[148, "module-python.sparknlp.common"]], "hasembeddingsproperties (class in python.sparknlp.common.properties)": [[149, "python.sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[149, "python.sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "python.sparknlp.common.properties": [[149, "module-python.sparknlp.common.properties"]], "setdimension() (hasembeddingsproperties method)": [[149, "python.sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "readas (class in python.sparknlp.common.read_as)": [[150, "python.sparknlp.common.read_as.ReadAs"]], "python.sparknlp.common.read_as": [[150, "module-python.sparknlp.common.read_as"]], "recursiveannotatorapproach (class in python.sparknlp.common.recursive_annotator_approach)": [[151, "python.sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "python.sparknlp.common.recursive_annotator_approach": [[151, "module-python.sparknlp.common.recursive_annotator_approach"]], "python.sparknlp.common.storage": [[152, "module-python.sparknlp.common.storage"]], "externalresource() (in module python.sparknlp.common.utils)": [[153, "python.sparknlp.common.utils.ExternalResource"]], "python.sparknlp.common.utils": [[153, "module-python.sparknlp.common.utils"]], "explode_annotations_col() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.map_annotations"]], "map_annotations_array() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module python.sparknlp.functions)": [[154, "python.sparknlp.functions.map_annotations_strict"]], "python.sparknlp.functions": [[154, "module-python.sparknlp.functions"]], "python.sparknlp": [[155, "module-python.sparknlp"]], "start() (in module python.sparknlp)": [[155, "python.sparknlp.start"]], "version() (in module python.sparknlp)": [[155, "python.sparknlp.version"]], "annotatorjavamlreadable (class in python.sparknlp.internal.annotator_java_ml)": [[156, "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in python.sparknlp.internal.annotator_java_ml)": [[156, "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "python.sparknlp.internal.annotator_java_ml": [[156, "module-python.sparknlp.internal.annotator_java_ml"]], "read() (annotatorjavamlreadable class method)": [[156, "python.sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "annotatortransformer (class in python.sparknlp.internal.annotator_transformer)": [[157, "python.sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "python.sparknlp.internal.annotator_transformer": [[157, "module-python.sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in python.sparknlp.internal.extended_java_wrapper)": [[158, "python.sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[158, "python.sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "python.sparknlp.internal.extended_java_wrapper": [[158, "module-python.sparknlp.internal.extended_java_wrapper"]], "python.sparknlp.internal": [[159, "module-python.sparknlp.internal"]], "paramsgetterssetters (class in python.sparknlp.internal.params_getters_setters)": [[160, "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[160, "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "python.sparknlp.internal.params_getters_setters": [[160, "module-python.sparknlp.internal.params_getters_setters"]], "setparamvalue() (paramsgetterssetters method)": [[160, "python.sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "recursiveestimator (class in python.sparknlp.internal.recursive)": [[161, "python.sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in python.sparknlp.internal.recursive)": [[161, "python.sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[161, "python.sparknlp.internal.recursive.RecursiveEstimator.fit"]], "python.sparknlp.internal.recursive": [[161, "module-python.sparknlp.internal.recursive"]], "cometlogger (class in python.sparknlp.logging.comet)": [[162, "python.sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[162, "python.sparknlp.logging.comet.CometLogger.monitor"]], "python.sparknlp.logging.comet": [[162, "module-python.sparknlp.logging.comet"]], "python.sparknlp.logging": [[163, "module-python.sparknlp.logging"]], "python.sparknlp.pretrained": [[164, "module-python.sparknlp.pretrained"]], "pretrainedpipeline (class in python.sparknlp.pretrained.pretrained_pipeline)": [[165, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[165, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[165, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "python.sparknlp.pretrained.pretrained_pipeline": [[165, "module-python.sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[165, "python.sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "python.sparknlp.pretrained.resource_downloader": [[166, "module-python.sparknlp.pretrained.resource_downloader"]], "python.sparknlp.pretrained.utils": [[167, "module-python.sparknlp.pretrained.utils"]], "nertfgraphbuilder (class in python.sparknlp.training._tf_graph_builders.graph_builders)": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.NerTFGraphBuilder"]], "tfgraphbuilder (class in python.sparknlp.training._tf_graph_builders.graph_builders)": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilder"]], "tfgraphbuilderfactory (class in python.sparknlp.training._tf_graph_builders.graph_builders)": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory"]], "tensorflowaddonsneeded": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.TensorflowAddonsNeeded"]], "wrongtfversion": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.WrongTFVersion"], [183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.WrongTFVersion"]], "build() (tfgraphbuilderfactory static method)": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.build"], [183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.build"]], "get_models() (tfgraphbuilderfactory static method)": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.get_models"], [183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.get_models"]], "print_model_params() (tfgraphbuilderfactory static method)": [[168, "python.sparknlp.training._tf_graph_builders.graph_builders.TFGraphBuilderFactory.print_model_params"], [183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory.print_model_params"]], "python.sparknlp.training._tf_graph_builders.graph_builders": [[168, "module-python.sparknlp.training._tf_graph_builders.graph_builders"]], "python.sparknlp.training._tf_graph_builders": [[169, "module-python.sparknlp.training._tf_graph_builders"]], "python.sparknlp.training._tf_graph_builders.ner_dl.create_graph": [[170, "module-python.sparknlp.training._tf_graph_builders.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder": [[171, "module-python.sparknlp.training._tf_graph_builders.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders.ner_dl": [[172, "module-python.sparknlp.training._tf_graph_builders.ner_dl"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model": [[173, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver": [[174, "module-python.sparknlp.training._tf_graph_builders.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper": [[175, "module-python.sparknlp.training._tf_graph_builders.ner_dl.sentence_grouper"]], "embeddingwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[176, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper"]], "inputprojectionwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[176, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper"]], "outputprojectionwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell)": [[176, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper"]], "call() (embeddingwrapper method)": [[176, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.call"]], "call() (inputprojectionwrapper method)": [[176, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.call"]], "call() (outputprojectionwrapper method)": [[176, "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell": [[176, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.core_rnn_cell"]], "fusedrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.FusedRNNCell"]], "fusedrnncelladaptor (class in python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.FusedRNNCellAdaptor"]], "timereversedfusedrnn (class in python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell)": [[177, "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell.TimeReversedFusedRNN"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell": [[177, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.fused_rnn_cell"]], "grublockcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell"]], "grublockcellv2 (class in python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2"]], "build() (grublockcellv2 method)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCellV2.build"]], "call() (grublockcell method)": [[178, "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops.GRUBlockCell.call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops": [[178, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.gru_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib": [[179, "module-python.sparknlp.training._tf_graph_builders.tf2contrib"]], "lstmblockcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell"]], "lstmblockfusedcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockFusedCell"]], "lstmblockwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper"]], "call() (lstmblockcell method)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockCell.call"]], "call() (lstmblockwrapper method)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper.call"]], "num_units (lstmblockfusedcell property)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockFusedCell.num_units"]], "num_units() (lstmblockwrapper method)": [[180, "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops.LSTMBlockWrapper.num_units"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops": [[180, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.lstm_ops"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn": [[181, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn"]], "stack_bidirectional_dynamic_rnn() (in module python.sparknlp.training._tf_graph_builders.tf2contrib.rnn)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn.stack_bidirectional_dynamic_rnn"]], "stack_bidirectional_rnn() (in module python.sparknlp.training._tf_graph_builders.tf2contrib.rnn)": [[181, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn.stack_bidirectional_rnn"]], "attentioncellwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper"]], "bidirectionalgridlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell"]], "cfncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell"]], "compiledwrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CompiledWrapper"]], "conv1dlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv1DLSTMCell"]], "conv2dlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv2DLSTMCell"]], "conv3dlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.Conv3DLSTMCell"]], "convlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.ConvLSTMCell"]], "coupledinputforgetgatelstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell"]], "glstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell"]], "gridlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell"]], "highwaywrapper (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.HighwayWrapper"]], "indrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell"]], "indygrucell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell"]], "indylstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell"]], "intersectionrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell"]], "layernormbasiclstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell"]], "layernormlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell"]], "minimalrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell"]], "nascell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell"]], "ntmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NTMCell"]], "phasedlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell"]], "srucell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell"]], "timefreqlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell"]], "ugrnncell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell"]], "weightnormlstmcell (class in python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell"]], "call() (attentioncellwrapper method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.AttentionCellWrapper.call"]], "call() (bidirectionalgridlstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.BidirectionalGridLSTMCell.call"]], "call() (cfncell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CFNCell.call"]], "call() (coupledinputforgetgatelstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.CoupledInputForgetGateLSTMCell.call"]], "call() (glstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GLSTMCell.call"]], "call() (gridlstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.GridLSTMCell.call"]], "call() (indrnncell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndRNNCell.call"]], "call() (indygrucell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyGRUCell.call"]], "call() (indylstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IndyLSTMCell.call"]], "call() (intersectionrnncell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.IntersectionRNNCell.call"]], "call() (layernormbasiclstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormBasicLSTMCell.call"]], "call() (layernormlstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.LayerNormLSTMCell.call"]], "call() (minimalrnncell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.MinimalRNNCell.call"]], "call() (nascell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.NASCell.call"]], "call() (phasedlstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.PhasedLSTMCell.call"]], "call() (srucell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.SRUCell.call"]], "call() (timefreqlstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.TimeFreqLSTMCell.call"]], "call() (ugrnncell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.UGRNNCell.call"]], "call() (weightnormlstmcell method)": [[182, "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell.WeightNormLSTMCell.call"]], "python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell": [[182, "module-python.sparknlp.training._tf_graph_builders.tf2contrib.rnn_cell"]], "nertfgraphbuilder (class in python.sparknlp.training._tf_graph_builders_1x.graph_builders)": [[183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.NerTFGraphBuilder"]], "tfgraphbuilder (class in python.sparknlp.training._tf_graph_builders_1x.graph_builders)": [[183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilder"]], "tfgraphbuilderfactory (class in python.sparknlp.training._tf_graph_builders_1x.graph_builders)": [[183, "python.sparknlp.training._tf_graph_builders_1x.graph_builders.TFGraphBuilderFactory"]], "python.sparknlp.training._tf_graph_builders_1x.graph_builders": [[183, "module-python.sparknlp.training._tf_graph_builders_1x.graph_builders"]], "python.sparknlp.training._tf_graph_builders_1x": [[184, "module-python.sparknlp.training._tf_graph_builders_1x"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph": [[185, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.create_graph"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder": [[186, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.dataset_encoder"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl": [[187, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model": [[188, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver": [[189, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.ner_model_saver"]], "python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper": [[190, "module-python.sparknlp.training._tf_graph_builders_1x.ner_dl.sentence_grouper"]], "conll (class in python.sparknlp.training.conll)": [[191, "python.sparknlp.training.conll.CoNLL"]], "python.sparknlp.training.conll": [[191, "module-python.sparknlp.training.conll"]], "readdataset() (conll method)": [[191, "python.sparknlp.training.conll.CoNLL.readDataset"]], "conllu (class in python.sparknlp.training.conllu)": [[192, "python.sparknlp.training.conllu.CoNLLU"]], "python.sparknlp.training.conllu": [[192, "module-python.sparknlp.training.conllu"]], "readdataset() (conllu method)": [[192, "python.sparknlp.training.conllu.CoNLLU.readDataset"]], "python.sparknlp.training": [[193, "module-python.sparknlp.training"]], "pos (class in python.sparknlp.training.pos)": [[194, "python.sparknlp.training.pos.POS"]], "python.sparknlp.training.pos": [[194, "module-python.sparknlp.training.pos"]], "readdataset() (pos method)": [[194, "python.sparknlp.training.pos.POS.readDataset"]], "pubtator (class in python.sparknlp.training.pub_tator)": [[195, "python.sparknlp.training.pub_tator.PubTator"]], "python.sparknlp.training.pub_tator": [[195, "module-python.sparknlp.training.pub_tator"]], "readdataset() (pubtator method)": [[195, "python.sparknlp.training.pub_tator.PubTator.readDataset"]], "python.sparknlp.training.tfgraphs": [[196, "module-python.sparknlp.training.tfgraphs"]], "python.sparknlp.upload_to_hub": [[197, "module-python.sparknlp.upload_to_hub"]], "python.sparknlp.util": [[198, "module-python.sparknlp.util"]]}})