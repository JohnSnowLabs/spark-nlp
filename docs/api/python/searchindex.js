Search.setIndex({"docnames": ["getting_started/index", "index", "reference/autosummary/sparknlp/annotation/index", "reference/autosummary/sparknlp/annotation_audio/index", "reference/autosummary/sparknlp/annotation_image/index", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index", "reference/autosummary/sparknlp/annotator/audio/index", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index", "reference/autosummary/sparknlp/annotator/chunker/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index", "reference/autosummary/sparknlp/annotator/coref/index", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index", "reference/autosummary/sparknlp/annotator/cv/index", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index", "reference/autosummary/sparknlp/annotator/dependency/index", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index", "reference/autosummary/sparknlp/annotator/document_normalizer/index", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index", "reference/autosummary/sparknlp/annotator/er/index", "reference/autosummary/sparknlp/annotator/graph_extraction/index", "reference/autosummary/sparknlp/annotator/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/index", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index", "reference/autosummary/sparknlp/annotator/ld_dl/index", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index", "reference/autosummary/sparknlp/annotator/lemmatizer/index", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/index", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index", "reference/autosummary/sparknlp/annotator/n_gram_generator/index", "reference/autosummary/sparknlp/annotator/ner/index", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index", "reference/autosummary/sparknlp/annotator/normalizer/index", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index", "reference/autosummary/sparknlp/annotator/param/index", "reference/autosummary/sparknlp/annotator/pos/index", "reference/autosummary/sparknlp/annotator/pos/perceptron/index", "reference/autosummary/sparknlp/annotator/sentence/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index", "reference/autosummary/sparknlp/annotator/sentiment/index", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/index", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index", "reference/autosummary/sparknlp/annotator/spell_check/index", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index", "reference/autosummary/sparknlp/annotator/stemmer/index", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/index", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index", "reference/autosummary/sparknlp/annotator/token/tokenizer/index", "reference/autosummary/sparknlp/annotator/ws/index", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index", "reference/autosummary/sparknlp/base/audio_assembler/index", "reference/autosummary/sparknlp/base/chunk2_doc/index", "reference/autosummary/sparknlp/base/date2_chunk/index", "reference/autosummary/sparknlp/base/doc2_chunk/index", "reference/autosummary/sparknlp/base/document_assembler/index", "reference/autosummary/sparknlp/base/embeddings_finisher/index", "reference/autosummary/sparknlp/base/finisher/index", "reference/autosummary/sparknlp/base/graph_finisher/index", "reference/autosummary/sparknlp/base/has_recursive_fit/index", "reference/autosummary/sparknlp/base/has_recursive_transform/index", "reference/autosummary/sparknlp/base/image_assembler/index", "reference/autosummary/sparknlp/base/index", "reference/autosummary/sparknlp/base/light_pipeline/index", "reference/autosummary/sparknlp/base/multi_document_assembler/index", "reference/autosummary/sparknlp/base/recursive_pipeline/index", "reference/autosummary/sparknlp/base/table_assembler/index", "reference/autosummary/sparknlp/base/token2_chunk/index", "reference/autosummary/sparknlp/base/token_assembler/index", "reference/autosummary/sparknlp/common/annotator_approach/index", "reference/autosummary/sparknlp/common/annotator_model/index", "reference/autosummary/sparknlp/common/annotator_properties/index", "reference/autosummary/sparknlp/common/annotator_type/index", "reference/autosummary/sparknlp/common/coverage_result/index", "reference/autosummary/sparknlp/common/index", "reference/autosummary/sparknlp/common/properties/index", "reference/autosummary/sparknlp/common/read_as/index", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index", "reference/autosummary/sparknlp/common/storage/index", "reference/autosummary/sparknlp/common/utils/index", "reference/autosummary/sparknlp/functions/index", "reference/autosummary/sparknlp/index", "reference/autosummary/sparknlp/internal/annotator_java_ml/index", "reference/autosummary/sparknlp/internal/annotator_transformer/index", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index", "reference/autosummary/sparknlp/internal/index", "reference/autosummary/sparknlp/internal/params_getters_setters/index", "reference/autosummary/sparknlp/internal/recursive/index", "reference/autosummary/sparknlp/logging/comet/index", "reference/autosummary/sparknlp/logging/index", "reference/autosummary/sparknlp/pretrained/index", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index", "reference/autosummary/sparknlp/pretrained/resource_downloader/index", "reference/autosummary/sparknlp/pretrained/utils/index", "reference/autosummary/sparknlp/training/conll/index", "reference/autosummary/sparknlp/training/conllu/index", "reference/autosummary/sparknlp/training/index", "reference/autosummary/sparknlp/training/pos/index", "reference/autosummary/sparknlp/training/pub_tator/index", "reference/autosummary/sparknlp/training/tfgraphs/index", "reference/autosummary/sparknlp/upload_to_hub/index", "reference/autosummary/sparknlp/util/index", "reference/index", "third_party/Comet", "third_party/MLflow", "third_party/index", "user_guide/annotation", "user_guide/annotators", "user_guide/custom_pipelines", "user_guide/helpers", "user_guide/index", "user_guide/light_pipelines", "user_guide/pretrained_pipelines", "user_guide/training"], "filenames": ["getting_started/index.rst", "index.rst", "reference/autosummary/sparknlp/annotation/index.rst", "reference/autosummary/sparknlp/annotation_audio/index.rst", "reference/autosummary/sparknlp/annotation_image/index.rst", "reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/audio/index.rst", "reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index.rst", "reference/autosummary/sparknlp/annotator/chunker/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.rst", "reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.rst", "reference/autosummary/sparknlp/annotator/coref/index.rst", "reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.rst", "reference/autosummary/sparknlp/annotator/cv/index.rst", "reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index.rst", "reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/dependency/index.rst", "reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.rst", "reference/autosummary/sparknlp/annotator/document_normalizer/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.rst", "reference/autosummary/sparknlp/annotator/er/entity_ruler/index.rst", "reference/autosummary/sparknlp/annotator/er/index.rst", "reference/autosummary/sparknlp/annotator/graph_extraction/index.rst", "reference/autosummary/sparknlp/annotator/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/index.rst", "reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/lemmatizer/index.rst", "reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.rst", "reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.rst", "reference/autosummary/sparknlp/annotator/n_gram_generator/index.rst", "reference/autosummary/sparknlp/annotator/ner/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_approach/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_converter/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_crf/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_dl/index.rst", "reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.rst", "reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.rst", "reference/autosummary/sparknlp/annotator/normalizer/index.rst", "reference/autosummary/sparknlp/annotator/param/classifier_encoder/index.rst", "reference/autosummary/sparknlp/annotator/param/evaluation_dl_params/index.rst", "reference/autosummary/sparknlp/annotator/param/index.rst", "reference/autosummary/sparknlp/annotator/pos/index.rst", "reference/autosummary/sparknlp/annotator/pos/perceptron/index.rst", "reference/autosummary/sparknlp/annotator/sentence/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.rst", "reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.rst", "reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.rst", "reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.rst", "reference/autosummary/sparknlp/annotator/stemmer/index.rst", "reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.rst", "reference/autosummary/sparknlp/annotator/tf_ner_dl_graph_builder/index.rst", "reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/index.rst", "reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/token/tokenizer/index.rst", "reference/autosummary/sparknlp/annotator/ws/index.rst", "reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.rst", "reference/autosummary/sparknlp/base/audio_assembler/index.rst", "reference/autosummary/sparknlp/base/chunk2_doc/index.rst", "reference/autosummary/sparknlp/base/date2_chunk/index.rst", "reference/autosummary/sparknlp/base/doc2_chunk/index.rst", "reference/autosummary/sparknlp/base/document_assembler/index.rst", "reference/autosummary/sparknlp/base/embeddings_finisher/index.rst", "reference/autosummary/sparknlp/base/finisher/index.rst", "reference/autosummary/sparknlp/base/graph_finisher/index.rst", "reference/autosummary/sparknlp/base/has_recursive_fit/index.rst", "reference/autosummary/sparknlp/base/has_recursive_transform/index.rst", "reference/autosummary/sparknlp/base/image_assembler/index.rst", "reference/autosummary/sparknlp/base/index.rst", "reference/autosummary/sparknlp/base/light_pipeline/index.rst", "reference/autosummary/sparknlp/base/multi_document_assembler/index.rst", "reference/autosummary/sparknlp/base/recursive_pipeline/index.rst", "reference/autosummary/sparknlp/base/table_assembler/index.rst", "reference/autosummary/sparknlp/base/token2_chunk/index.rst", "reference/autosummary/sparknlp/base/token_assembler/index.rst", "reference/autosummary/sparknlp/common/annotator_approach/index.rst", "reference/autosummary/sparknlp/common/annotator_model/index.rst", "reference/autosummary/sparknlp/common/annotator_properties/index.rst", "reference/autosummary/sparknlp/common/annotator_type/index.rst", "reference/autosummary/sparknlp/common/coverage_result/index.rst", "reference/autosummary/sparknlp/common/index.rst", "reference/autosummary/sparknlp/common/properties/index.rst", "reference/autosummary/sparknlp/common/read_as/index.rst", "reference/autosummary/sparknlp/common/recursive_annotator_approach/index.rst", "reference/autosummary/sparknlp/common/storage/index.rst", "reference/autosummary/sparknlp/common/utils/index.rst", "reference/autosummary/sparknlp/functions/index.rst", "reference/autosummary/sparknlp/index.rst", "reference/autosummary/sparknlp/internal/annotator_java_ml/index.rst", "reference/autosummary/sparknlp/internal/annotator_transformer/index.rst", "reference/autosummary/sparknlp/internal/extended_java_wrapper/index.rst", "reference/autosummary/sparknlp/internal/index.rst", "reference/autosummary/sparknlp/internal/params_getters_setters/index.rst", "reference/autosummary/sparknlp/internal/recursive/index.rst", "reference/autosummary/sparknlp/logging/comet/index.rst", "reference/autosummary/sparknlp/logging/index.rst", "reference/autosummary/sparknlp/pretrained/index.rst", "reference/autosummary/sparknlp/pretrained/pretrained_pipeline/index.rst", "reference/autosummary/sparknlp/pretrained/resource_downloader/index.rst", "reference/autosummary/sparknlp/pretrained/utils/index.rst", "reference/autosummary/sparknlp/training/conll/index.rst", "reference/autosummary/sparknlp/training/conllu/index.rst", "reference/autosummary/sparknlp/training/index.rst", "reference/autosummary/sparknlp/training/pos/index.rst", "reference/autosummary/sparknlp/training/pub_tator/index.rst", "reference/autosummary/sparknlp/training/tfgraphs/index.rst", "reference/autosummary/sparknlp/upload_to_hub/index.rst", "reference/autosummary/sparknlp/util/index.rst", "reference/index.rst", "third_party/Comet.rst", "third_party/MLflow.rst", "third_party/index.rst", "user_guide/annotation.rst", "user_guide/annotators.rst", "user_guide/custom_pipelines.rst", "user_guide/helpers.rst", "user_guide/index.rst", "user_guide/light_pipelines.rst", "user_guide/pretrained_pipelines.rst", "user_guide/training.rst"], "titles": ["Getting Started", "Spark NLP Documentation", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotation_image</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.hubert_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.audio.wav2vec2_for_ctc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.chunker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.albert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.camembert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.deberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.distil_bert_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.longformer_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.multi_classifier_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.sentiment_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.tapas_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.classifier_dl.xlnet_for_token_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.coref.spanbert_coref</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.swin_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.cv.vit_for_image_classification</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.dependency.typed_dependency_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.document_normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.albert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.bert_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.camembert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.chunk_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.deberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.distil_bert_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.doc2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.elmo_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.longformer_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.universal_sentence_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word2vec</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.word_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.embeddings.xlnet_embeddings</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er.entity_ruler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.er</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.graph_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.keyword_extraction.yake_keyword_extraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ld_dl.language_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.lemmatizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.big_text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.multi_date_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.regex_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.matcher.text_matcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.n_gram_generator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_crf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.ner_overwriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ner.zero_shot_ner_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.normalizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.classifier_encoder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param.evaluation_dl_params</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.pos.perceptron</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentence.sentence_detector_dl</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.sentiment_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.sentiment.vivekn_sentiment</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.gpt2_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.marian_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.seq2seq.t5_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.context_spell_checker</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.norvig_sweeting</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.spell_check.symmetric_delete</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stemmer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.stop_words_cleaner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.tf_ner_dl_graph_builder</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.chunk_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.recursive_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.regex_tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.token.tokenizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.annotator.ws.word_segmenter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.audio_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.chunk2_doc</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.date2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.doc2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.embeddings_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.graph_finisher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_fit</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.has_recursive_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.image_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.light_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.multi_document_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.recursive_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.table_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token2_chunk</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.base.token_assembler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.annotator_type</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.coverage_result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.properties</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.read_as</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.recursive_annotator_approach</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.storage</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_java_ml</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.annotator_transformer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.extended_java_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.params_getters_setters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.internal.recursive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging.comet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.pretrained_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.resource_downloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.pretrained.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conll</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.conllu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pos</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.pub_tator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.training.tfgraphs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.upload_to_hub</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">sparknlp.util</span></code>", "API Reference", "Comet - A meta machine learning platform", "MLflow - a platform for the machine learning lifecycle", "Third Party Projects", "Annotation", "Annotators", "Setting up your own pipeline", "Helper Functions", "User Guide", "Light Pipelines", "Pretrained Pipelines", "Loading datasets for training"], "terms": {"4": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], "3": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], "0": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184], "thi": [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 77, 78, 79, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 118, 119, 121, 122, 124, 126, 127, 129, 132, 134, 135, 136, 137, 138, 139, 141, 142, 146, 152, 153, 157, 158, 159, 162, 163, 168, 173, 174, 177, 178, 179, 181, 182, 183], "can": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 82, 87, 88, 89, 90, 91, 97, 99, 100, 102, 104, 106, 107, 108, 110, 111, 113, 121, 124, 126, 127, 135, 136, 137, 138, 150, 159, 162, 163, 165, 166, 168, 174, 176, 178, 179, 181, 182, 183, 184], "quick": [0, 174, 179], "refer": [0, 1, 5, 41, 43, 44, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 68, 74, 91, 99, 100, 103, 104, 106, 107, 108, 110, 111, 121, 125, 126, 135, 178, 180, 181], "how": [0, 1, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 45, 47, 49, 50, 52, 53, 54, 55, 57, 59, 60, 62, 66, 68, 69, 71, 76, 77, 78, 82, 83, 87, 88, 89, 92, 94, 99, 102, 110, 111, 118, 119, 121, 126, 129, 135, 147, 150, 152, 165, 166, 174, 178, 183], "set": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 114, 117, 118, 119, 121, 122, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 141, 142, 146, 150, 152, 157, 158, 159, 163, 165, 174, 178, 181, 182], "up": [0, 1, 5, 18, 29, 56, 59, 62, 64, 74, 104, 107, 152, 174, 178, 181, 182], "your": [0, 1, 18, 29, 33, 45, 55, 56, 60, 62, 64, 77, 78, 82, 83, 88, 89, 92, 97, 102, 103, 108, 110, 115, 117, 121, 127, 176, 178, 181, 182, 184], "environ": [0, 175], "pypi": 0, "pip": 0, "anaconda": 0, "c": [0, 52, 56, 64, 74, 106, 121], "johnsnowlab": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 76, 77, 78, 82, 83, 88, 89, 91, 92, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 119, 121, 127, 128, 137, 152], "load": [0, 1, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 74, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 132, 162, 163, 178, 181], "shell": 0, "packag": [0, 49, 54, 159, 175, 176], "com": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 76, 77, 78, 82, 83, 88, 89, 91, 92, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 119, 121, 137, 152], "nlp_2": [0, 152], "12": [0, 49, 66, 67, 68, 74, 79, 81, 87, 97, 108, 134, 138, 151, 152, 162, 168, 177], "pyspark": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 125, 126, 127, 132, 134, 135, 137, 138, 139, 151, 152, 155, 158, 159, 162, 165, 166, 168, 169, 178, 179], "submit": [0, 159, 174], "extern": [0, 74, 77, 82, 83, 89, 114, 136, 150, 165, 166, 168, 169], "jar": [0, 152], "after": [0, 45, 47, 56, 60, 61, 64, 79, 81, 87, 117, 124, 139, 159, 177, 178], "compil": 0, "build": [0, 54, 55, 60, 61, 71, 74, 78, 104, 159, 174], "sbt": 0, "assembli": 0, "i": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 118, 119, 121, 122, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 150, 151, 152, 158, 159, 163, 165, 168, 169, 174, 175, 177, 178, 179, 181, 182, 183, 184], "built": [0, 18, 29, 135], "top": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 43, 49, 74, 104, 107, 135], "apach": [0, 135, 152], "x": [0, 29, 151, 165, 184], "For": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 121, 126, 127, 128, 135, 139, 159, 162, 169, 174, 175, 177, 178, 179, 180, 181, 182], "you": [0, 45, 47, 53, 55, 60, 62, 71, 79, 90, 127, 129, 134, 159, 163, 168, 174, 176, 178, 179, 182, 183, 184], "need": [0, 5, 7, 8, 45, 47, 55, 60, 65, 69, 71, 74, 79, 82, 88, 89, 92, 94, 97, 100, 103, 104, 108, 110, 111, 118, 119, 122, 132, 134, 159, 163, 165, 166, 168, 174, 176, 178, 179, 182, 184], "java": [0, 76, 140, 141, 148, 154, 155, 158, 163], "8": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 45, 47, 48, 49, 50, 51, 52, 54, 55, 59, 60, 61, 66, 67, 68, 79, 84, 89, 90, 94, 104, 108, 121, 138, 165], "1": [0, 5, 8, 10, 13, 16, 18, 20, 23, 27, 29, 31, 33, 36, 38, 41, 43, 45, 47, 49, 50, 51, 54, 56, 57, 61, 64, 65, 66, 67, 68, 74, 78, 79, 81, 82, 83, 84, 87, 88, 89, 91, 93, 94, 99, 100, 103, 104, 106, 107, 108, 114, 118, 121, 123, 124, 127, 128, 142, 146, 152, 157, 158, 159, 162, 163, 165, 166, 169, 174, 177, 178, 182, 183], "ar": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 45, 47, 49, 50, 52, 54, 55, 57, 59, 60, 63, 65, 66, 67, 68, 69, 71, 74, 76, 77, 79, 82, 84, 87, 89, 90, 91, 92, 97, 99, 100, 103, 104, 106, 107, 108, 112, 114, 121, 123, 127, 134, 136, 137, 147, 151, 159, 163, 169, 174, 175, 176, 177, 178, 179, 182, 183, 184], "6": [0, 18, 33, 43, 50, 51, 54, 57, 74, 78, 83, 84, 90, 97, 110, 138, 166, 178], "7": [0, 33, 43, 50, 51, 54, 79, 81, 97, 104, 123, 128, 168, 177], "It": [0, 10, 13, 18, 20, 23, 27, 29, 31, 33, 34, 36, 38, 43, 48, 50, 51, 52, 54, 55, 56, 59, 60, 61, 64, 66, 67, 69, 74, 84, 103, 106, 108, 110, 111, 117, 128, 134, 163, 177, 182], "recommend": [0, 57, 68, 102, 103, 104, 106, 107], "have": [0, 5, 18, 29, 33, 49, 52, 55, 60, 61, 65, 74, 82, 84, 88, 89, 90, 97, 99, 100, 104, 111, 138, 139, 154, 178, 179, 182], "basic": [0, 43, 74, 99, 177], "knowledg": [0, 55, 74, 129], "framework": [0, 7, 106, 107], "work": [0, 55, 59, 76, 107, 115, 177, 179, 183], "befor": [0, 48, 65, 79, 81, 107, 110, 118, 121, 141, 158, 174], "pleas": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 50, 51, 52, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 76, 77, 78, 79, 82, 83, 88, 89, 92, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 121, 126, 135, 136, 175, 176, 180, 183], "document": [0, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 134, 135, 137, 138, 139, 159, 162, 165, 166, 168, 174, 178, 179, 181, 182, 183], "first": [0, 2, 54, 56, 57, 64, 66, 67, 74, 82, 88, 89, 90, 99, 107, 108, 113, 118, 127, 139, 174, 178, 179, 183], "let": [0, 55, 117, 178], "": [0, 1, 9, 12, 15, 19, 22, 26, 30, 35, 48, 49, 52, 54, 55, 56, 59, 60, 61, 64, 66, 67, 69, 74, 82, 89, 92, 103, 104, 106, 107, 108, 110, 111, 117, 118, 119, 121, 122, 128, 134, 140, 141, 148, 151, 154, 158, 159, 174, 177, 178, 179, 182], "make": [0, 43, 48, 52, 59, 66, 67, 74, 100, 103, 110, 180, 184], "sure": [0, 103], "version": [0, 48, 55, 93, 94, 114, 142, 146, 152, 157, 158, 162, 163, 178, 183], "oracl": 0, "openjdk": 0, "0_292": 0, "creat": [0, 2, 3, 4, 18, 29, 33, 50, 51, 56, 60, 64, 65, 71, 89, 94, 97, 115, 121, 134, 136, 151, 165, 166, 168, 169, 178, 179, 182, 184], "new": [0, 2, 3, 4, 33, 41, 43, 49, 50, 51, 54, 57, 59, 65, 68, 90, 91, 93, 94, 104, 107, 108, 114, 123, 124, 128, 142, 146, 157, 158, 177, 178], "manag": [0, 74, 163, 175], "all": [0, 2, 3, 4, 10, 13, 16, 20, 23, 27, 31, 34, 36, 38, 43, 48, 49, 50, 51, 52, 62, 65, 68, 69, 72, 76, 79, 89, 92, 104, 107, 108, 113, 118, 121, 127, 129, 159, 163, 173, 178, 183], "depend": [0, 2, 41, 52, 62, 68, 69, 71, 72, 74, 76, 89, 106, 108, 121, 152], "Then": [0, 18, 29, 88, 89, 139, 159, 178], "we": [0, 5, 7, 18, 29, 43, 44, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 68, 74, 88, 89, 92, 100, 104, 106, 107, 108, 110, 119, 134, 151, 174, 177, 178, 179, 182, 183, 184], "sparknlp": [0, 174, 177, 178, 179, 180, 182, 183, 184], "n": [0, 67, 74, 84, 87, 88, 89, 99, 100, 104, 107, 117, 134, 137, 151, 162], "y": [0, 29], "activ": [0, 10, 13, 16, 23, 27, 31, 36, 38, 74], "jupyt": [0, 159, 174], "now": [0, 52, 100, 134, 179], "should": [0, 2, 3, 4, 8, 18, 29, 33, 56, 64, 66, 74, 76, 83, 84, 88, 89, 94, 99, 100, 106, 108, 118, 134, 141, 142, 154, 158, 162, 165, 166], "readi": [0, 18, 162, 178], "notebook": [0, 159, 174], "run": [0, 55, 74, 159, 163, 175, 183], "also": [0, 18, 29, 33, 43, 44, 48, 49, 57, 59, 65, 66, 67, 69, 71, 74, 79, 82, 87, 88, 89, 93, 94, 100, 103, 113, 134, 137, 142, 146, 157, 174, 178, 179, 180, 181, 183], "python3": 0, "sourc": [0, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169, 175], "bin": 0, "A": [0, 5, 7, 33, 41, 49, 60, 61, 65, 69, 74, 77, 78, 82, 83, 84, 91, 92, 102, 104, 106, 107, 110, 111, 118, 119, 159, 168, 176, 178, 184], "retriev": [0, 65, 77, 110, 111, 112, 159, 162, 174, 178, 179], "import": [0, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 132, 134, 135, 136, 137, 138, 139, 151, 159, 162, 165, 166, 168, 169, 174, 177, 178, 181, 182, 183, 184], "If": [0, 10, 13, 16, 18, 20, 23, 27, 29, 31, 33, 36, 38, 62, 65, 69, 76, 79, 81, 87, 88, 89, 92, 94, 99, 100, 104, 107, 108, 114, 152, 158, 159, 163, 174, 176, 178], "manual": [0, 177], "sparksess": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 65, 66, 67, 68, 78, 104, 106, 107, 152, 165, 166, 168, 169], "becaus": [0, 102, 141, 158], "other": [0, 5, 29, 52, 62, 63, 71, 74, 92, 102, 104, 107, 115, 117, 123, 127, 128, 135, 178], "configur": [0, 62, 119, 152], "includ": [0, 43, 48, 50, 51, 56, 57, 64, 66, 67, 68, 71, 74, 79, 87, 88, 89, 104, 107, 108, 128, 159, 169, 175, 177, 178, 179, 184], "them": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 43, 44, 49, 50, 52, 54, 55, 59, 60, 66, 68, 69, 71, 74, 79, 82, 100, 108, 113, 121, 136, 139, 178, 179], "builder": [0, 114, 152], "appnam": [0, 152], "master": [0, 152], "local": [0, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 74, 104, 106, 107, 113, 134, 152, 162, 182], "config": [0, 152, 175], "driver": [0, 152], "memori": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 49, 57, 65, 152], "16g": [0, 152], "maxresults": [0, 152], "kryoseri": [0, 152], "buffer": [0, 51, 65, 152], "max": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 49, 50, 51, 52, 54, 55, 59, 60, 61, 66, 67, 68, 74, 111, 152], "2000m": [0, 152], "getorcr": [0, 152], "main": [1, 69, 119, 177, 181, 184], "page": [1, 48, 104, 162, 173, 181, 183], "github": [1, 54, 60, 106, 162], "issu": [1, 121], "workshop": [1, 181], "model": [1, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 76, 77, 78, 82, 83, 88, 89, 91, 92, 94, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 117, 119, 121, 141, 152, 158, 159, 162, 163, 174, 175, 177, 181, 183, 184], "hub": [1, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 76, 77, 88, 89, 97, 100, 104, 106, 107, 108, 110, 111, 113, 121], "welcom": [1, 5, 7], "python": [1, 76], "contain": [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 136, 137, 138, 139, 140, 141, 142, 144, 146, 147, 148, 149, 150, 151, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 168, 169, 172, 174, 177, 178], "inform": [1, 45, 47, 65, 66, 74, 79, 87, 108, 126, 135, 169, 174, 175, 176, 177, 178, 184], "us": [1, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 91, 94, 97, 99, 100, 103, 104, 106, 107, 108, 110, 111, 113, 114, 118, 119, 121, 123, 124, 125, 126, 127, 128, 134, 135, 136, 137, 138, 139, 151, 152, 159, 162, 163, 165, 166, 168, 169, 175, 176, 177, 178, 179, 181], "librari": [1, 43, 44, 76, 125, 126, 127, 135, 139, 183], "exampl": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 128, 129, 132, 134, 135, 136, 137, 138, 139, 151, 159, 162, 163, 165, 166, 168, 169, 174, 177, 178, 179, 181, 182, 183, 184], "get": [1, 18, 29, 74, 86, 97, 108, 114, 119, 121, 122, 126, 127, 128, 132, 134, 135, 142, 146, 157, 174, 178, 183, 184], "start": [1, 5, 9, 12, 15, 19, 22, 26, 30, 35, 59, 71, 74, 88, 89, 100, 125, 152, 159, 174, 177, 179, 182, 183], "cheat": 1, "sheet": [1, 48], "requir": [1, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 44, 45, 47, 49, 51, 54, 57, 63, 66, 67, 74, 89, 92, 103, 108, 121, 124, 125, 127, 138, 139, 177, 178, 179], "instal": [1, 159, 176], "session": [1, 152, 165, 166, 168, 169], "from": [1, 2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 93, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 136, 137, 138, 139, 141, 151, 152, 155, 158, 159, 162, 165, 166, 168, 169, 174, 177, 178, 179, 182, 183, 184], "user": [1, 87, 88, 119, 136, 152, 159, 174], "guid": [1, 175], "annot": [1, 3, 4, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 145, 146, 150, 151, 152, 153, 154, 156, 158, 159, 162, 163, 164, 168, 174, 175, 180, 181, 182, 183, 184], "own": [1, 18, 29, 33, 45, 56, 64, 77, 78, 82, 83, 88, 89, 92, 97, 102, 103, 108, 110, 115, 117, 121, 181, 182, 184], "pipelin": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 132, 134, 135, 136, 137, 138, 139, 152, 158, 159, 161, 162, 163, 164, 175, 177, 178, 181], "pretrain": [1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 76, 77, 78, 79, 82, 83, 88, 89, 90, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 123, 127, 128, 134, 151, 152, 159, 174, 177, 181], "dataset": [1, 18, 29, 33, 45, 47, 52, 56, 59, 60, 61, 64, 65, 74, 76, 88, 89, 94, 100, 104, 108, 121, 158, 162, 165, 166, 168, 169, 181], "train": [1, 5, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 60, 61, 63, 64, 66, 67, 68, 74, 76, 77, 78, 82, 83, 86, 88, 89, 92, 93, 94, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 115, 117, 121, 125, 134, 152, 159, 162, 174, 178, 179, 181, 182], "light": [1, 5, 55, 68, 74, 134, 181, 183], "helper": [1, 97, 121, 129, 151, 168, 169, 181, 184], "function": [1, 57, 65, 107, 127, 163, 173, 181], "third": [1, 99, 113, 160, 165], "parti": [1, 160], "project": [1, 74, 106, 159, 175], "log": [1, 18, 29, 33, 89, 94, 100, 104, 152], "api": [1, 174, 178, 181], "modul": [1, 25, 46, 58, 70, 72, 73, 75, 80, 85, 95, 96, 98, 101, 105, 109, 116, 120, 133, 145, 156, 161, 167], "data": [2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 132, 134, 135, 136, 137, 138, 139, 151, 159, 162, 165, 166, 167, 168, 169, 175, 177, 178, 182, 183, 184], "format": [2, 3, 4, 43, 44, 45, 47, 69, 71, 77, 78, 79, 81, 82, 83, 88, 89, 92, 94, 102, 107, 110, 111, 119, 121, 122, 126, 128, 129, 132, 135, 137, 165, 166, 168, 169, 175, 184], "annotatortyp": [2, 3, 4, 53, 84, 125, 126, 132, 135, 177], "begin": [2, 41, 87, 104, 117, 119, 125, 126, 135, 151, 177], "end": [2, 9, 12, 15, 19, 22, 26, 30, 35, 41, 89, 100, 117, 119, 121, 126, 135, 151, 159, 165, 174, 177, 179], "result": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 151, 152, 159, 162, 165, 166, 174, 175, 177, 178, 179, 182, 183], "metadata": [2, 3, 4, 34, 41, 74, 83, 88, 89, 91, 97, 126, 128, 132, 134, 135, 151, 159, 163, 177, 179], "embed": [2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 71, 72, 88, 89, 90, 126, 127, 128, 134, 135, 146, 151, 152, 158, 162, 177], "repres": [2, 3, 4, 45, 47, 49, 54, 68, 69, 71, 78, 83, 84, 119, 159, 162, 178], "output": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 142, 151, 152, 159, 168, 174, 177, 178, 179], "spark": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 139, 145, 147, 151, 152, 154, 155, 156, 159, 162, 163, 165, 166, 168, 169, 173, 175, 176, 177, 178, 180, 181, 182, 184], "nlp": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 76, 77, 78, 82, 83, 88, 89, 90, 91, 92, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 119, 121, 125, 126, 127, 128, 132, 133, 134, 135, 136, 137, 139, 145, 152, 156, 159, 162, 163, 165, 166, 168, 169, 173, 175, 176, 177, 178, 179, 180, 181, 182, 184], "detail": [2, 3, 4, 66, 67, 74, 91, 104, 107], "paramet": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 142, 146, 150, 151, 152, 157, 158, 159, 162, 163, 165, 166, 168, 169], "annotator_typ": [2, 3, 4], "str": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 114, 117, 118, 119, 121, 122, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 142, 150, 151, 152, 157, 159, 162, 163, 165, 166, 168, 169], "The": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 118, 119, 121, 126, 128, 134, 135, 137, 151, 152, 159, 162, 163, 165, 166, 168, 169, 174, 177, 178, 179, 181, 182, 184], "type": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 151, 153, 162, 168, 177, 178, 181], "possibl": [2, 3, 4, 53, 55, 66, 67, 69, 99, 108, 111, 126, 135, 147, 159, 174], "valu": [2, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 69, 71, 74, 76, 77, 79, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 103, 104, 106, 107, 108, 110, 113, 114, 118, 119, 121, 122, 125, 126, 127, 128, 129, 132, 134, 135, 137, 139, 142, 146, 147, 157, 159, 174, 184], "token": [2, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 74, 77, 78, 83, 84, 86, 87, 88, 89, 90, 91, 92, 94, 97, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 121, 123, 125, 127, 134, 136, 138, 139, 152, 162, 165, 169, 178, 182, 183], "wordpiec": 2, "word_embed": [2, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 62, 64, 66, 68, 72, 88, 89, 94], "sentence_embed": [2, 18, 29, 33, 51, 56, 58, 61, 63, 67, 72, 159, 174, 178], "categori": [2, 10, 13, 16, 18, 20, 23, 27, 29, 31, 33, 36, 38, 43, 44, 159, 174, 178], "date": [2, 79, 81, 82, 124], "entiti": [2, 11, 14, 17, 21, 24, 28, 32, 37, 39, 41, 43, 52, 69, 70, 71, 78, 83, 85, 86, 87, 88, 89, 90, 91, 115, 123, 128, 134, 138, 162], "sentiment": [2, 18, 29, 33, 57, 68, 72, 107, 152, 178, 179], "po": [2, 8, 10, 13, 16, 20, 23, 27, 31, 36, 38, 45, 47, 71, 72, 88, 89, 117, 121, 134, 151, 152, 162, 165, 167, 177, 181, 182, 183], "chunk": [2, 8, 9, 12, 15, 19, 22, 26, 30, 34, 35, 53, 56, 64, 69, 74, 78, 82, 83, 84, 87, 115, 123, 124, 125, 128, 138, 151, 159, 169, 174, 184], "named_ent": [2, 11, 14, 17, 21, 24, 28, 32, 37, 39, 71, 87, 88, 89, 90, 91, 94, 134, 162], "negex": 2, "labeled_depend": [2, 47], "languag": [2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 74, 75, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 125, 135, 139, 163, 178], "keyword": [2, 73, 74, 102], "dummi": [2, 48], "int": [2, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 65, 66, 67, 68, 71, 74, 76, 79, 84, 86, 88, 89, 92, 93, 94, 97, 99, 100, 103, 104, 106, 107, 108, 111, 114, 118, 119, 121, 146, 152, 159, 165], "index": [2, 74, 78, 118, 152, 165], "charact": [2, 48, 57, 59, 69, 76, 82, 84, 92, 99, 100, 108, 110, 111, 118, 119, 121, 128], "under": [2, 55, 68, 74, 152], "last": [2, 79, 81, 115, 182], "string": [2, 18, 29, 33, 41, 45, 48, 69, 82, 84, 90, 92, 100, 107, 111, 113, 117, 125, 126, 128, 132, 134, 135, 182], "dict": [2, 3, 4, 45, 47, 69, 77, 78, 82, 83, 88, 90, 91, 92, 94, 102, 108, 110, 111, 119, 134, 150, 158, 159, 162], "associ": [2, 3, 4, 29, 63, 69, 82, 87, 159], "list": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 44, 48, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 69, 71, 74, 76, 79, 82, 86, 87, 89, 90, 91, 92, 93, 99, 100, 104, 106, 107, 108, 113, 117, 119, 127, 128, 134, 135, 142, 151, 158, 159, 162, 163, 173, 178], "vector": [2, 29, 50, 51, 53, 54, 56, 57, 63, 64, 65, 127, 128, 135, 177], "where": [2, 29, 54, 57, 69, 74, 77, 78, 82, 83, 84, 97, 100, 102, 104, 107, 110, 111, 121, 125, 168], "applic": [2, 44, 74, 159, 160, 174, 176], "copi": [2, 3, 4], "differ": [2, 3, 4, 43, 45, 47, 57, 60, 61, 66, 68, 74, 79, 99, 100, 108, 119, 121, 134, 159, 182], "return": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 74, 76, 77, 78, 83, 84, 86, 88, 89, 91, 97, 99, 100, 103, 104, 106, 107, 108, 110, 111, 112, 113, 117, 119, 121, 125, 134, 150, 151, 152, 153, 158, 162, 163, 165, 166, 168, 169], "newli": [2, 3, 4], "static": [2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 163, 178], "datatyp": [2, 151], "structtyp": 2, "schema": [2, 87, 159, 174], "look": [2, 89, 110, 177], "like": [2, 5, 9, 12, 15, 18, 19, 22, 26, 30, 35, 41, 48, 49, 53, 55, 59, 62, 68, 71, 74, 82, 87, 100, 103, 104, 108, 119, 121, 159, 174, 176, 177], "struct": [2, 126, 132, 135], "containsnul": [2, 29, 122, 126, 132, 135], "true": [2, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 43, 44, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 76, 78, 79, 81, 83, 87, 89, 92, 99, 100, 108, 110, 118, 119, 121, 122, 125, 126, 127, 128, 129, 132, 135, 137, 159, 165, 166, 169, 174, 178, 179], "nullabl": [2, 29, 122, 126, 132, 135], "fals": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 134, 135, 137, 138, 139, 151, 152, 159, 162, 165, 166, 168, 174, 177, 178, 179, 184], "integ": [2, 126, 132, 135], "map": [2, 8, 29, 65, 69, 93, 94, 97, 108, 126, 132, 135, 142, 146, 151, 157, 158, 177], "kei": [2, 5, 45, 47, 60, 61, 66, 67, 77, 91, 126, 132, 134, 135, 159, 162, 174], "valuecontainsnul": [2, 126, 132, 135], "arrai": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 62, 63, 66, 67, 68, 76, 77, 84, 89, 93, 97, 99, 100, 104, 106, 107, 108, 115, 117, 121, 122, 125, 126, 127, 128, 129, 132, 134, 135, 151, 179, 182], "element": [2, 29, 84, 122, 126, 132, 135], "float": [2, 3, 5, 7, 18, 29, 33, 76, 88, 89, 91, 93, 94, 100, 104, 107, 108, 121, 122, 126, 127, 134, 135], "sql": [2, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 65, 66, 67, 68, 78, 104, 106, 107, 134, 151, 158, 162, 165, 166, 168, 169], "arraytyp": [2, 125, 151], "fromrow": 2, "row": [2, 34, 65, 99, 100, 103, 126, 135, 137, 151, 165], "column": [2, 18, 29, 33, 48, 65, 77, 86, 88, 89, 93, 94, 97, 103, 114, 119, 121, 122, 123, 125, 126, 127, 128, 129, 132, 135, 139, 142, 151, 162, 165, 168, 178], "torow": 2, "transform": [2, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 134, 135, 137, 138, 139, 151, 154, 158, 159, 162, 174, 177, 178, 179, 182, 183, 184], "an": [2, 5, 7, 8, 18, 29, 33, 34, 43, 44, 45, 48, 52, 54, 57, 59, 68, 69, 74, 76, 78, 79, 81, 82, 83, 84, 88, 89, 91, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 115, 119, 121, 125, 126, 127, 128, 129, 134, 135, 139, 142, 146, 150, 151, 153, 157, 158, 159, 165, 166, 168, 169, 173, 175, 177, 178, 179, 181, 182], "annotationaudio": 3, "audio": [3, 122, 159], "alreadi": [3, 71, 74, 88, 89, 90, 119, 134, 138, 162, 182], "process": [3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 64, 66, 67, 68, 71, 74, 76, 87, 88, 89, 94, 100, 104, 107, 121, 122, 123, 125, 126, 127, 128, 132, 135, 136, 139, 159, 174, 177, 178, 179, 180], "file": [3, 5, 7, 18, 29, 33, 45, 47, 48, 63, 65, 69, 77, 78, 82, 83, 88, 89, 92, 94, 100, 102, 108, 110, 111, 114, 119, 122, 137, 147, 152, 159, 165, 166, 168, 169, 174, 184], "byte": [3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 76, 89, 93, 104, 106, 107, 108, 159], "annotationimag": [4, 134, 162], "origin": [4, 43, 44, 49, 56, 59, 60, 64, 87, 100, 132], "height": [4, 132], "width": [4, 132], "nchannel": [4, 132], "mode": [4, 18, 29, 33, 89, 94, 110, 126, 132, 135, 159], "imag": [4, 43, 44, 132, 134, 162], "uri": 4, "pixel": [4, 43], "number": [4, 18, 29, 33, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 84, 86, 88, 89, 93, 97, 99, 100, 104, 107, 108, 114, 121, 165, 166], "color": 4, "channel": [4, 108], "opencv": 4, "concern": [5, 7, 10, 43, 44, 49, 124], "hubertforctc": 5, "classnam": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 76, 77, 78, 82, 83, 88, 89, 91, 92, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 119, 121, 137, 140, 141, 148, 154], "java_model": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 76, 77, 78, 82, 83, 88, 89, 91, 92, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 117, 119, 121, 131, 137, 141, 158], "none": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 76, 77, 78, 82, 83, 88, 89, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 138, 141, 152, 158, 159, 162, 163, 179], "hubert": 5, "head": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 41, 49, 68, 87, 88, 89, 134, 151, 162, 178], "connectionist": [5, 7], "tempor": [5, 7], "classif": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 43, 44, 49, 63, 103, 107, 178], "ctc": [5, 7], "wa": [5, 7, 10, 11, 13, 14, 18, 20, 21, 23, 24, 27, 28, 31, 32, 33, 36, 37, 38, 39, 43, 48, 52, 54, 55, 59, 60, 61, 65, 66, 67, 74, 103, 104, 108, 162, 178, 179], "propos": [5, 7, 43, 49, 52, 54, 55, 60, 61, 66, 67, 68], "self": [5, 7, 43, 49, 59, 106], "supervis": [5, 7, 49, 57, 63, 74, 104], "speech": [5, 7, 8, 52, 96, 97, 121, 168, 184], "represent": [5, 7, 43, 49, 50, 51, 55, 56, 57, 64, 65, 66, 67, 68, 87, 107, 135, 137, 150], "learn": [5, 7, 18, 29, 33, 49, 55, 56, 57, 60, 61, 63, 64, 66, 67, 68, 74, 88, 89, 93, 100, 104, 107, 108, 159, 176], "mask": [5, 43, 54, 66, 67, 68, 118], "predict": [5, 43, 54, 89, 104, 107, 159, 174], "hidden": [5, 9, 11, 12, 14, 15, 17, 19, 21, 22, 24, 26, 28, 30, 32, 35, 37, 39, 49, 57, 68, 114], "unit": [5, 104, 114], "wei": [5, 43], "ning": 5, "hsu": 5, "benjamin": [5, 52], "bolt": 5, "yao": 5, "hung": 5, "tsai": 5, "kushal": 5, "lakhotia": 5, "ruslan": 5, "salakhutdinov": 5, "abdelrahman": [5, 7], "moham": [5, 7], "take": [5, 7, 34, 52, 71, 83, 93, 94, 110, 113, 119, 136, 142, 146, 157, 165, 177, 178, 182, 183], "transcrib": [5, 7], "text": [5, 7, 8, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 41, 43, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 116, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 129, 135, 137, 138, 139, 147, 150, 151, 159, 165, 166, 168, 169, 174, 177, 178, 179, 183, 184], "provid": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 76, 77, 78, 79, 81, 82, 83, 88, 89, 92, 93, 94, 97, 100, 102, 104, 106, 107, 108, 110, 111, 121, 134, 142, 146, 151, 153, 157, 162, 179], "pre": [5, 7, 18, 29, 33, 44, 50, 51, 54, 55, 57, 63, 89, 94, 107, 126, 128, 135, 139, 166, 178], "note": [5, 7, 18, 29, 33, 49, 55, 57, 60, 62, 65, 66, 68, 74, 89, 104, 106, 107, 134, 152, 183], "current": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 65, 66, 67, 68, 74, 78, 79, 81, 100, 104, 106, 107, 114, 134, 137, 142, 152, 177, 178, 179], "support": [5, 7, 18, 29, 49, 59, 74, 89, 92, 100, 113, 137, 152, 175], "appl": [5, 7, 51, 61, 67, 152], "silicon": [5, 7, 152], "processor": [5, 7], "m1": [5, 7], "due": [5, 7, 10, 13, 16, 20, 23, 27, 31, 36, 38, 49, 59], "instruct": [5, 7], "xla": [5, 7], "companion": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 88, 89, 91, 97, 100, 104, 106, 107, 108, 110, 111, 113, 121, 155], "object": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 88, 89, 91, 97, 100, 104, 106, 107, 108, 110, 111, 112, 113, 121, 147, 154, 155, 159, 177, 178], "speechtotext": [5, 7], "setinputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 138, 139, 142, 159, 174, 178, 179], "audio_assembl": [5, 7, 133, 152], "setoutputcol": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 138, 139, 142, 159, 174, 178, 179], "default": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 114, 117, 118, 119, 121, 125, 126, 127, 128, 129, 134, 135, 137, 150, 151, 152, 159, 162, 163, 165, 166, 168, 169, 178], "asr_hubert_large_ls960": 5, "name": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 83, 85, 86, 88, 89, 91, 93, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 114, 115, 119, 121, 122, 123, 125, 126, 127, 128, 129, 132, 135, 137, 139, 142, 151, 157, 159, 162, 163, 165, 168, 174, 178], "avail": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 72, 74, 76, 77, 79, 82, 88, 89, 97, 100, 104, 106, 107, 108, 110, 111, 113, 121, 154, 162, 163, 174, 181], "see": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 119, 121, 126, 127, 128, 129, 135, 139, 159, 162, 169, 174, 175, 176, 181, 183, 184], "To": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 43, 44, 49, 50, 52, 54, 55, 59, 60, 66, 68, 69, 74, 79, 82, 97, 99, 104, 107, 121, 129, 134, 136, 159, 174, 182], "which": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 62, 63, 64, 66, 68, 71, 74, 79, 81, 82, 89, 91, 92, 99, 100, 102, 104, 106, 107, 110, 118, 121, 124, 127, 134, 151, 163, 165, 166, 178, 179], "compat": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 43, 44, 49, 50, 52, 54, 55, 59, 60, 66, 68, 89, 127, 163], "5669": [5, 7, 43, 44, 52], "more": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 48, 52, 55, 57, 62, 66, 67, 71, 74, 84, 87, 91, 100, 104, 107, 110, 118, 119, 126, 127, 128, 135, 139, 159, 162, 169, 174, 175, 176, 178, 181, 184], "extend": [5, 7, 8, 18, 29, 33, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 57, 60, 62, 63, 65, 66, 68, 74, 76, 77, 79, 81, 82, 83, 84, 88, 89, 91, 92, 94, 97, 99, 100, 102, 103, 106, 107, 108, 110, 112, 113, 117, 119, 121, 126, 127, 128, 135, 139, 162], "hubertforctctestspec": 5, "paper": [5, 43, 44, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 68, 74, 100, 103, 104, 106, 107, 121, 169, 184], "abstract": [5, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 74, 104, 106, 107, 114, 169, 184], "approach": [5, 43, 60, 61, 68, 74, 86, 88, 89, 91, 100, 102, 104, 107, 108, 110, 111, 140, 181], "challeng": [5, 29, 43, 55, 57, 60, 61, 74], "three": [5, 108, 138], "uniqu": 5, "problem": [5, 29, 49, 57, 107, 108, 121], "multipl": [5, 29, 44, 52, 69, 74, 79, 99, 119, 151, 159, 165], "sound": 5, "each": [5, 7, 18, 29, 33, 54, 56, 62, 64, 65, 69, 71, 74, 77, 78, 79, 82, 83, 84, 86, 88, 89, 91, 92, 94, 97, 99, 100, 102, 108, 110, 111, 118, 119, 121, 126, 135, 151, 158, 168, 179], "input": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 125, 126, 127, 128, 129, 132, 134, 135, 137, 138, 139, 142, 151, 158, 162, 165, 166, 168, 169, 178, 179, 182, 184], "utter": 5, "lexicon": 5, "dure": [5, 18, 29, 33, 55, 88, 89, 94, 99, 108, 152, 159, 174], "phase": [5, 55], "variabl": [5, 56, 64], "length": [5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 64, 66, 67, 68, 84, 92, 99, 100, 104, 106, 107, 108, 118, 119], "explicit": [5, 99, 104], "segment": [5, 41, 43, 55, 60, 120, 121], "deal": [5, 134, 182], "bert": [5, 10, 12, 13, 14, 16, 20, 23, 24, 27, 31, 34, 36, 38, 49, 50, 51, 54, 55, 59, 60, 61, 66, 67, 68, 89, 90, 91, 107], "util": [5, 53, 88, 91, 99, 100, 111, 136, 144, 145, 147, 149, 152, 153, 157, 161], "offlin": [5, 159], "cluster": [5, 63, 152], "step": [5, 18, 29, 33, 56, 64, 89, 94, 159, 174, 178], "align": 5, "target": [5, 63, 106, 119, 125, 134, 162], "label": [5, 10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 43, 44, 45, 47, 69, 76, 86, 87, 88, 89, 91, 93, 94, 102, 103, 107, 108, 114, 121, 159, 165, 174, 178], "loss": [5, 49, 55, 89, 107, 174], "ingredi": 5, "our": [5, 49, 52, 55, 56, 57, 59, 60, 61, 63, 64, 66, 67, 74, 100, 104, 107, 151, 162, 183], "appli": [5, 18, 29, 33, 44, 48, 69, 71, 89, 90, 94, 99, 107, 108, 110, 123, 128, 151, 165], "over": [5, 55, 66, 67, 68, 110, 119, 151, 159, 174], "region": 5, "onli": [5, 45, 47, 48, 57, 63, 68, 79, 82, 92, 99, 100, 104, 107, 117, 121, 136, 165], "forc": 5, "combin": [5, 55, 59, 65, 74, 107, 108, 110, 121], "acoust": 5, "continu": [5, 87, 104, 129, 174], "reli": [5, 45, 47, 68, 74], "primarili": 5, "consist": [5, 49, 54, 59, 82, 97, 103, 121, 137, 168], "unsupervis": [5, 66, 67, 68, 74, 104], "rather": 5, "than": [5, 29, 33, 55, 56, 64, 66, 67, 68, 74, 76, 84, 88, 104, 110, 111, 178], "intrins": 5, "qualiti": [5, 43, 104], "assign": [5, 29, 69, 90, 102], "simpl": [5, 50, 51, 69, 104, 179], "k": [5, 104, 107, 127], "mean": [5, 8, 29, 66, 74, 76, 79, 81, 104, 106, 107, 118, 127, 134, 178, 179, 182], "teacher": 5, "100": [5, 18, 29, 34, 44, 56, 64, 66, 74, 100, 137], "two": [5, 29, 43, 45, 47, 49, 54, 63, 65, 66, 67, 71, 138, 165, 178], "iter": [5, 45, 47, 49, 56, 64, 97, 121, 159, 174], "either": [5, 18, 33, 44, 47, 52, 53, 62, 69, 74, 76, 82, 102, 103, 107, 121, 125, 126, 134, 135, 137, 162, 179], "match": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 64, 66, 67, 68, 69, 78, 79, 80, 81, 82, 83, 92, 97, 99, 104, 119, 121, 125, 177], "improv": [5, 49, 50, 51, 52, 54, 57, 60, 61, 66, 67, 88, 89, 104, 183], "upon": [5, 74], "state": [5, 9, 11, 12, 14, 15, 17, 18, 19, 21, 22, 24, 26, 28, 29, 30, 32, 33, 35, 37, 39, 43, 44, 49, 50, 51, 52, 57, 59, 60, 61, 68, 74, 89, 104, 107, 135, 175, 178], "art": [5, 18, 29, 43, 44, 49, 50, 51, 52, 57, 59, 60, 61, 68, 74, 89, 104, 107, 135], "wav2vec": [5, 7], "perform": [5, 43, 44, 48, 49, 52, 54, 55, 57, 60, 61, 63, 65, 66, 67, 68, 89, 103, 104, 110], "librispeech": 5, "960h": 5, "libri": 5, "60": [5, 55, 99], "000h": 5, "benchmark": [5, 44, 49, 54, 55, 57, 66, 67, 107], "10min": 5, "1h": 5, "10h": 5, "100h": 5, "fine": [5, 41, 50, 51, 55, 91, 107], "tune": [5, 41, 50, 51, 55, 91, 107], "subset": 5, "1b": 5, "show": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 135, 137, 138, 139, 151, 163, 165, 166, 168, 169, 174, 177, 178, 179, 183], "19": [5, 84, 124, 168], "13": [5, 8, 41, 66, 67, 71, 97, 123, 128], "rel": [5, 52, 54, 66, 79, 81, 88, 108, 177], "wer": 5, "reduct": [5, 49, 110], "dev": [5, 43, 49, 57, 63], "test": [5, 18, 29, 33, 43, 44, 45, 47, 50, 51, 63, 65, 77, 78, 82, 83, 88, 89, 94, 97, 104, 110, 111, 115, 121, 165, 166, 168, 169, 178, 184], "evalu": [5, 18, 29, 33, 52, 59, 66, 67, 94, 142, 159], "batchsiz": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 66, 67, 68, 89, 106, 108], "size": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 48, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 71, 74, 89, 93, 104, 106, 107, 108, 110, 177, 182, 183], "batch": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 66, 67, 68, 89, 93, 106, 108], "base": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 140, 141, 142, 145, 148, 152, 154, 158, 159, 174, 178, 179, 182], "ml": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 122, 125, 126, 127, 132, 134, 135, 136, 137, 138, 139, 159, 174, 178, 182], "audioassembl": [5, 7, 122], "audio_cont": [5, 7, 122], "setstag": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 124, 125, 127, 137, 138, 139, 178, 179], "processedaudiofloat": [5, 7], "createdatafram": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 135, 137, 138, 139, 151, 159, 174, 177, 178, 179, 183], "rawfloat": [5, 7], "todf": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 123, 124, 125, 126, 127, 128, 132, 135, 137, 138, 139, 151, 177, 178, 179, 183], "fit": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 124, 125, 127, 134, 136, 137, 138, 139, 158, 159, 174, 178, 179, 182], "select": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 53, 55, 65, 71, 74, 76, 88, 89, 91, 103, 104, 107, 108, 110, 111, 117, 121, 122, 124, 126, 128, 129, 132, 135, 137, 139, 151, 159, 174, 179], "truncat": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 65, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 123, 124, 125, 126, 128, 129, 135, 137, 138, 139, 151, 168, 177, 178, 179], "mister": [5, 7], "quilter": [5, 7], "THE": [5, 7, 48], "apostl": [5, 7], "OF": [5, 7, 49], "midl": [5, 7], "clase": [5, 7], "AND": [5, 7], "glad": [5, 7], "TO": [5, 7, 165, 184], "hi": [5, 7, 91, 100], "gospel": [5, 7], "setconfigprotobyt": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 76, 89, 93, 104, 106, 107, 108], "b": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 76, 78, 83, 87, 88, 89, 90, 91, 93, 99, 104, 106, 107, 108, 121, 134, 151, 162, 165, 169, 184], "configproto": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 76, 89, 93, 104, 106, 107, 108], "tensorflow": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 74, 76, 89, 93, 104, 106, 107, 108], "serial": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 69, 76, 89, 93, 104, 106, 107, 108, 152], "loadsavedmodel": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 104, 106, 107], "folder": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 89, 94, 100, 104, 106, 107, 111, 114, 163, 165], "spark_sess": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 104, 106, 107], "save": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 89, 94, 100, 104, 106, 107, 152, 159, 174, 178], "restor": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121], "lang": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 71, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 162, 163, 178, 183], "en": [5, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 68, 71, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 162, 163, 166, 178, 183, 184], "remote_loc": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 162, 163], "download": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 71, 76, 77, 78, 83, 88, 89, 90, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 152, 162, 163, 177, 178, 181, 182], "option": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 74, 76, 77, 78, 82, 83, 88, 89, 91, 92, 94, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 122, 126, 130, 131, 134, 135, 150, 151, 152, 158, 159, 162, 163, 165, 166, 168, 169, 178], "remot": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 162, 163], "address": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121], "resourc": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 76, 77, 78, 82, 83, 88, 89, 91, 92, 94, 97, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 115, 119, 121, 136, 147, 150, 161, 163, 165, 166, 168, 169, 178, 184], "Will": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 99, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121], "repositori": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 162, 175], "otherwis": [5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 76, 77, 78, 83, 88, 89, 91, 97, 100, 103, 104, 106, 107, 108, 110, 111, 113, 119, 121, 125, 159], "hubert_for_ctc": 6, "wav2vec2_for_ctc": 6, "wav2vec2forctc": 7, "wav2vec2": 7, "alexei": 7, "baevski": 7, "henri": 7, "zhou": 7, "michael": [7, 115], "auli": 7, "asr_wav2vec2_base_960h": 7, "wav2vec2forctctestspec": 7, "pattern": [8, 48, 69, 79, 82, 92, 110, 111, 118, 119, 121], "part": [8, 52, 74, 77, 96, 97, 112, 121, 125, 168, 184], "tag": [8, 18, 29, 33, 48, 52, 86, 87, 88, 89, 90, 96, 97, 121, 151, 159, 165, 168, 169, 184], "order": [8, 68, 69, 74, 110, 111, 134, 139, 151, 178, 179, 182, 184], "meaning": [8, 112], "phrase": [8, 52, 56, 64, 78, 83], "extract": [8, 9, 12, 15, 19, 22, 26, 30, 35, 45, 53, 65, 69, 70, 71, 73, 74, 78, 79, 81, 83, 87, 88, 89, 90, 99, 100, 102, 108, 111, 115, 123, 127, 128, 129, 134, 138, 152, 159, 162, 174], "onto": [8, 151, 179], "sentenc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 76, 77, 78, 79, 81, 82, 83, 84, 87, 88, 89, 90, 91, 97, 103, 106, 108, 113, 115, 118, 121, 123, 124, 126, 128, 134, 135, 137, 138, 139, 152, 162, 165, 166, 168, 169, 178, 182, 183], "pars": [8, 45, 46, 47, 52, 69, 77, 79, 81, 108, 110, 111, 134, 137, 162, 165, 168], "regular": [8, 82, 88, 99], "express": [8, 33, 41, 79, 82, 99], "wrap": [8, 140, 141, 148, 154, 158], "angl": 8, "bracket": 8, "easili": [8, 57, 97, 127, 174], "distinguish": 8, "itself": [8, 74, 107, 121, 136, 179], "form": [8, 18, 29, 33, 65, 69, 77, 78, 79, 82, 83, 100, 102, 110, 111, 121, 127, 159, 165, 166, 178], "peter": [8, 59, 77, 92, 97, 100, 110, 112, 165], "piper": [8, 77, 97, 112], "employe": [8, 77, 97, 112], "pick": [8, 77, 97, 112], "peck": [8, 77, 97, 112], "pickl": [8, 77, 97, 112], "pepper": [8, 77, 97, 112], "nnp": [8, 97, 134, 151, 165, 166, 168, 169, 177, 182, 183, 184], "nn": [8, 97, 165, 166, 168, 169, 184], "vbp": [8, 97, 134, 166, 177, 182, 183], "vbg": [8, 97], "IN": [8, 97, 134, 151, 166, 168, 169, 177, 182, 183], "jj": [8, 97, 134, 151, 165, 168, 177, 182, 183, 184], "regexpars": 8, "e": [8, 10, 11, 13, 14, 16, 17, 20, 21, 23, 24, 27, 28, 31, 32, 36, 37, 38, 39, 47, 48, 57, 59, 69, 71, 88, 89, 104, 106, 107, 108, 113, 137, 159, 174], "g": [8, 10, 11, 13, 14, 16, 17, 20, 21, 23, 24, 27, 28, 31, 32, 36, 37, 38, 39, 47, 48, 57, 71, 88, 89, 104, 106, 107, 108, 113, 137, 159, 174], "setregexpars": 8, "when": [8, 10, 13, 20, 23, 27, 31, 36, 38, 44, 48, 49, 71, 79, 81, 84, 89, 104, 108, 110, 113, 117, 121, 123, 134, 165, 178, 179, 182], "defin": [8, 87, 88, 89, 113, 117, 123, 128, 151, 159, 162, 174, 178, 182], "enclos": 8, "treat": [8, 121], "group": [8, 119], "so": [8, 18, 33, 74, 87, 100, 136, 159, 174], "here": [8, 77, 151, 178], "specif": [8, 34, 45, 47, 48, 50, 51, 55, 63, 71, 74, 89, 104, 114, 134, 136, 159, 182], "noun": [8, 166], "success": [8, 52, 104], "grammar": 8, "parser": [8, 45, 47, 71], "perceptronmodel": [8, 45, 47, 71, 88, 97, 165], "Of": [8, 49, 121], "documentassembl": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 91, 92, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 115, 117, 118, 119, 121, 124, 125, 126, 127, 135, 136, 137, 138, 139, 159, 165, 174, 178], "sentencedetector": [8, 18, 34, 41, 45, 47, 51, 53, 61, 63, 67, 71, 74, 77, 82, 84, 88, 89, 90, 91, 97, 99, 100, 113, 115, 136, 139, 165, 178, 179], "postag": 8, "selectexpr": [8, 18, 34, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 77, 78, 79, 81, 82, 83, 84, 87, 90, 91, 92, 97, 99, 100, 102, 106, 112, 113, 115, 118, 119, 123, 125, 127, 128, 138, 151, 165, 166, 168, 177, 178, 183], "explod": [8, 18, 34, 41, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 78, 81, 82, 83, 84, 87, 90, 91, 97, 99, 100, 106, 123, 127, 128, 138, 151, 165, 168, 177, 178, 183], "11": [8, 66, 67, 79, 81, 84, 97, 124], "21": [8, 79, 81, 90, 97], "35": [8, 97], "39": [8, 90, 97, 168], "52": [8, 90, 97, 168], "58": [8, 43, 97], "albertforquestionansw": 9, "classifi": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 74, 127, 178], "dl": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 76, 89, 91, 110, 111], "albert": [9, 10, 11, 49], "span": [9, 12, 15, 19, 22, 26, 30, 35, 107], "question": [9, 12, 15, 19, 22, 26, 30, 34, 35, 45, 47, 50, 51, 57, 60, 61, 68, 91, 97, 104, 107, 134], "answer": [9, 12, 15, 19, 22, 26, 30, 34, 35, 45, 47, 50, 51, 57, 68, 91, 104, 107, 134], "task": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 43, 44, 49, 50, 51, 52, 54, 55, 59, 63, 66, 67, 68, 74, 91, 104, 106, 107, 136], "squad": [9, 12, 15, 19, 22, 26, 30, 35, 49, 50, 51, 54, 60, 61], "linear": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 43, 104], "layer": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 49, 50, 51, 54, 57, 68], "comput": [9, 12, 15, 19, 22, 26, 30, 35, 43, 44, 49, 54, 55, 63, 104, 106, 111, 121, 134, 182], "logit": [9, 10, 12, 13, 15, 16, 19, 22, 23, 26, 27, 30, 31, 35, 36, 38], "spanclassifi": [9, 12, 15, 19, 22, 26, 30, 35], "document_quest": [9, 12, 15, 19, 22, 26, 30, 34, 35], "document_context": [9, 12, 15, 19, 22, 26, 30, 35], "albert_base_qa_squad2": 9, "larg": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 44, 49, 54, 55, 57, 66, 67, 68, 74, 76, 78, 83, 89, 104], "allow": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 57, 63, 88, 89, 92, 99, 100, 118, 119, 136], "faster": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 55, 57, 110, 111], "casesensit": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 66, 67, 68, 78, 83, 110, 113], "whether": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 69, 71, 78, 79, 81, 83, 84, 87, 88, 89, 92, 94, 99, 100, 104, 107, 108, 110, 113, 118, 119, 121, 125, 127, 128, 129, 134, 137, 139, 142, 152, 162, 165, 169, 179], "ignor": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 66, 67, 68, 78, 84, 87, 104, 106, 107, 110, 113, 134], "case": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 47, 48, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 66, 67, 68, 69, 76, 78, 83, 108, 110, 113, 119, 125, 165, 166, 178], "configprotobyt": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 43, 44, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 66, 67, 68, 76, 89, 104, 106, 107, 108], "maxsentencelength": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 64, 66, 67, 68], "128": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 49, 50, 51, 52, 54, 55, 60, 61, 66, 67, 68, 159, 174], "multidocumentassembl": [9, 12, 15, 19, 22, 26, 30, 34, 35, 135], "context": [9, 12, 15, 19, 22, 26, 30, 35, 50, 51, 56, 57, 64, 68, 103, 108, 119], "setcasesensit": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 53, 55, 59, 60, 66, 78, 83, 88, 110, 113, 127, 139], "what": [9, 12, 15, 19, 22, 26, 30, 33, 35, 45, 47, 74, 76, 91, 106, 108, 117, 166, 175], "my": [9, 11, 12, 14, 15, 18, 19, 21, 22, 24, 26, 28, 30, 32, 33, 35, 37, 39, 48, 82, 84, 91, 99, 104, 113, 115, 118, 178], "clara": [9, 12, 15, 19, 22, 26, 30, 35, 91], "live": [9, 11, 12, 14, 15, 19, 21, 22, 24, 26, 28, 30, 32, 35, 37, 39, 91, 104, 159, 174], "berkelei": [9, 12, 15, 19, 22, 26, 30, 35], "setmaxsentencelength": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 41, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 64, 66, 67, 68], "albertforsequenceclassif": [10, 20], "sequenc": [10, 13, 16, 20, 23, 27, 31, 36, 38, 44, 59, 104, 105, 106, 107, 108, 113], "regress": [10, 13, 16, 20, 23, 27, 31, 36, 38, 107], "pool": [10, 13, 16, 20, 23, 27, 31, 36, 38, 53, 57, 62], "multi": [10, 13, 16, 18, 20, 23, 27, 29, 31, 33, 36, 38, 49, 63, 66, 67, 74, 76, 106], "sequenceclassifi": [10, 13, 16, 20, 23, 27, 31, 36, 38], "albert_base_sequence_classifier_imdb": 10, "coalescesent": [10, 13, 16, 20, 23, 27, 31, 36, 38, 76], "instead": [10, 13, 16, 20, 23, 27, 31, 36, 38, 51, 74, 76, 79, 81, 107, 127, 128, 134, 182], "per": [10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 66, 67, 76, 79, 84, 86, 87, 88, 89, 121, 134, 151, 162, 165], "inputcol": [10, 13, 16, 18, 20, 23, 27, 29, 31, 33, 36, 38, 62, 76, 122, 126, 127, 128, 129, 132, 135], "averag": [10, 13, 16, 20, 23, 27, 31, 34, 36, 38, 53, 62, 66, 67, 76, 89, 97], "probabl": [10, 13, 16, 20, 23, 27, 31, 36, 38, 74, 104, 107, 110], "calcul": [10, 13, 16, 18, 23, 27, 29, 31, 33, 36, 38, 65, 84, 89, 94, 102], "via": [10, 13, 16, 23, 27, 31, 36, 38, 63, 132, 152], "softmax": [10, 13, 16, 23, 27, 31, 36, 38, 54, 56, 64, 108], "sigmoid": [10, 13, 16, 23, 27, 31, 36, 38], "love": [10, 13, 18, 20, 23, 27, 31, 36, 38, 51, 61, 67, 100, 103, 178], "movi": [10, 13, 18, 20, 23, 27, 31, 33, 36, 38, 103, 178], "child": [10, 13, 20, 23, 27, 31, 36, 38], "pretti": [10, 13, 20, 23, 27, 29, 31, 36, 38, 74], "bore": [10, 13, 20, 23, 27, 31, 36, 38], "neg": [10, 13, 16, 20, 23, 27, 31, 33, 36, 38, 102, 103, 159, 174], "getclass": [10, 11, 13, 14, 16, 17, 20, 21, 23, 24, 27, 28, 31, 32, 36, 37, 38, 39, 43, 44, 91], "setcoalescesent": [10, 13, 16, 20, 23, 27, 31, 36, 38, 76], "limit": [10, 13, 16, 20, 23, 27, 31, 36, 38, 43, 44, 49, 52, 59, 65, 68, 74, 107, 110], "almost": [10, 13, 16, 20, 23, 27, 31, 36, 38], "512": [10, 13, 16, 20, 23, 27, 31, 34, 36, 38, 57], "help": [10, 13, 16, 20, 23, 27, 31, 36, 38, 45, 47, 49, 106, 119, 159, 174, 179, 183], "feed": [10, 13, 16, 20, 23, 27, 31, 36, 38], "entir": [10, 13, 16, 20, 23, 27, 31, 36, 38, 106], "bool": [10, 13, 16, 20, 23, 27, 31, 36, 38, 48, 51, 53, 63, 69, 71, 76, 78, 79, 83, 84, 87, 88, 89, 92, 94, 99, 100, 104, 107, 108, 110, 113, 118, 119, 121, 125, 127, 128, 129, 134, 137, 142, 152, 159, 162, 165], "one": [10, 13, 16, 20, 23, 27, 29, 31, 36, 38, 41, 45, 47, 48, 50, 51, 62, 66, 67, 68, 74, 76, 79, 82, 87, 100, 110, 115, 139, 174, 178], "albertfortokenclassif": [11, 49], "recognit": [11, 14, 17, 21, 24, 28, 32, 37, 39, 44, 52, 85, 88, 89, 91], "ner": [11, 14, 17, 21, 24, 28, 32, 37, 39, 66, 67, 71, 72, 115, 134, 151, 152, 159, 162, 174], "token_classifi": [11, 17, 28, 32, 37, 39], "albert_base_token_classifier_conll03": 11, "albertembed": [11, 49], "level": [11, 18, 29, 33, 50, 51, 59, 60, 61, 63, 65, 67, 69, 88, 89, 94, 108, 152, 165], "tokenclassifi": [11, 14, 17, 21, 24, 28, 32, 37, 39], "john": [11, 14, 21, 24, 28, 32, 37, 39, 41, 51, 61, 67, 69, 71, 90, 92, 100, 129], "lenon": [11, 14, 21, 24, 28, 32, 37, 39], "born": [11, 14, 21, 24, 28, 32, 37, 39, 104], "london": [11, 14, 21, 24, 28, 32, 37, 39], "pari": [11, 14, 21, 24, 28, 32, 37, 39, 91], "sarah": [11, 14, 21, 24, 28, 32, 37, 39], "o": [11, 14, 17, 21, 24, 28, 32, 37, 39, 87, 88, 89, 90, 134, 151, 162, 165, 169, 184], "loc": [11, 14, 17, 21, 24, 28, 32, 37, 39, 71, 87, 88, 89, 123, 128, 134, 151, 162, 165], "bertforquestionansw": [12, 34], "bert_base_cased_qa_squad2": 12, "bertforsequenceclassif": 13, "bert_base_sequence_classifier_imdb": 13, "bertfortokenclassif": 14, "bert_base_token_classifier_conll03": 14, "camembertforquestionansw": 15, "camembert": [15, 16, 17, 52], "camembert_base_qa_fquad": 15, "fr": [15, 16, 52, 76], "camembertforsequenceclassif": 16, "sequence_classifi": 16, "camembert_base_sequence_classifier_allocin": 16, "j": [16, 69], "ai": [16, 159, 174], "ador\u00e9": 16, "ce": 16, "film": 16, "lorsqu": 16, "\u00e9tai": 16, "enfant": 16, "je": 16, "d\u00e9test": 16, "\u00e7a": 16, "camembertfortokenclassif": 17, "camembert_base_token_classifier_wikin": 17, "georg": 17, "washington": 17, "est": [17, 52, 76, 106], "all\u00e9": 17, "\u00e0": 17, "classifierdl": [18, 178], "classifierdlapproach": [18, 29, 178], "gener": [18, 29, 43, 49, 53, 55, 59, 62, 68, 71, 74, 88, 89, 91, 100, 104, 107, 108, 110, 111, 128, 129, 159, 174, 177, 178, 179], "univers": [18, 45, 47, 63, 106], "encod": [18, 48, 50, 51, 54, 59, 63, 91, 106, 159], "deep": [18, 50, 51, 57, 74, 88, 100, 108], "dnn": 18, "insid": [18, 29, 87, 97, 119, 165], "instanti": [18, 29, 33, 45, 47, 56, 64, 65, 69, 77, 78, 82, 83, 88, 89, 92, 97, 100, 102, 103, 108, 110, 111, 115, 117, 121, 165, 166], "classifierdlmodel": [18, 29, 178], "monitor": [18, 29, 33, 89, 159, 174], "metric": [18, 29, 33, 89, 111, 159], "done": [18, 29, 33, 60, 61, 88, 89, 179], "settestdataset": [18, 29, 33, 89, 94], "method": [18, 29, 33, 49, 55, 56, 64, 68, 74, 89, 163, 173], "expect": [18, 29, 33, 68, 89, 119, 151], "path": [18, 29, 33, 45, 47, 56, 64, 65, 69, 71, 77, 78, 82, 83, 88, 89, 91, 92, 94, 100, 102, 104, 108, 110, 111, 114, 119, 132, 134, 150, 159, 162, 165, 166, 168, 169, 174], "parquet": [18, 29, 33, 89, 94, 122], "datafram": [18, 29, 33, 44, 65, 89, 94, 97, 121, 134, 147, 151, 158, 159, 162, 165, 166, 168, 169, 174, 178, 182, 184], "ha": [18, 29, 33, 34, 43, 44, 48, 49, 54, 55, 57, 60, 61, 65, 74, 77, 82, 89, 94, 100, 102, 107, 110, 111, 121, 122, 125, 132, 134, 159, 163, 168, 174, 178, 179], "same": [18, 29, 33, 41, 49, 60, 65, 66, 69, 71, 89, 94, 107, 136, 159, 179], "follow": [18, 29, 33, 41, 48, 57, 59, 65, 74, 79, 81, 82, 87, 89, 92, 99, 124, 137, 138, 174, 176, 179], "universalsentenceencod": [18, 29, 33, 63, 159, 174, 178], "preprocessingpipelin": [18, 29, 33, 89, 94], "randomsplit": [18, 29, 33, 89, 94], "write": [18, 29, 33, 65, 89, 94, 110, 111, 179], "overwrit": [18, 29, 33, 89, 90, 94, 159], "test_data": [18, 29, 33, 89, 94], "setlabelcolumn": [18, 29, 33, 86, 88, 89, 93, 114, 159, 174, 178], "usag": [18, 29, 33, 41, 45, 47, 48, 49, 50, 51, 52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 74, 76, 77, 79, 81, 82, 83, 88, 89, 92, 97, 99, 100, 102, 103, 106, 107, 108, 110, 112, 113, 117, 119, 121], "64": [18, 29, 33, 49, 89, 93, 178], "dropout": [18, 33, 89], "coeffici": [18, 33, 88, 89], "5": [18, 29, 33, 41, 43, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 74, 76, 79, 81, 84, 87, 89, 97, 104, 121, 127, 134, 151, 159, 162, 166, 168, 169, 174, 177, 178, 184], "enableoutputlog": [18, 29, 33, 89], "stdout": [18, 29, 33, 89, 94], "addit": [18, 29, 33, 45, 47, 50, 51, 69, 88, 89, 94, 99, 104, 119, 159, 177, 178], "evaluationlogextend": [18, 29, 33, 89], "valid": [18, 29, 33, 79, 89, 94, 100, 108, 174], "displai": [18, 29, 33, 94, 104, 159, 174], "time": [18, 29, 33, 49, 56, 64, 66, 67, 74, 79, 94, 103, 108, 121, 152, 177, 178, 182, 183], "labelcolumn": [18, 29, 33, 88, 89], "lr": [18, 29, 33, 89, 121], "rate": [18, 29, 33, 56, 60, 61, 64, 65, 89, 93, 108], "005": [18, 33, 89, 93], "maxepoch": [18, 29, 33, 88, 89], "maximum": [18, 29, 33, 41, 56, 64, 71, 74, 86, 88, 89, 92, 93, 99, 100, 104, 106, 107, 108, 110, 118, 119], "epoch": [18, 29, 33, 86, 88, 89, 93, 94, 100, 108, 159], "30": [18, 33, 74, 79, 81, 87, 93, 106, 134, 151, 162, 177], "outputlogspath": [18, 29, 33, 89, 100], "randomse": [18, 29, 33, 88, 89], "random": [18, 29, 33, 56, 64, 86, 88, 89, 93, 127], "seed": [18, 29, 33, 56, 64, 86, 88, 89, 93], "shuffl": [18, 29, 86, 93], "testdataset": [18, 29, 33, 89, 159, 174], "statist": [18, 29, 33, 65, 74, 89, 94], "validationsplit": [18, 29, 33, 89, 100], "choos": [18, 29, 33, 53, 62, 89, 100, 110], "proport": [18, 29, 33, 89, 94, 100], "against": [18, 29, 33, 69, 74, 78, 83, 89, 94, 100, 136], "between": [18, 29, 33, 43, 45, 47, 60, 61, 63, 66, 67, 68, 71, 89, 94, 99, 100, 108], "off": [18, 29, 33, 63, 66, 67, 89, 94, 100], "verbos": [18, 29, 33, 88, 89, 94], "multiclassifierdlapproach": [18, 29, 159, 174], "sentimentdlapproach": [18, 29, 33], "analysi": [18, 29, 33, 57, 68, 101, 102, 107, 123, 144, 179], "accept": [18, 29, 33], "singl": [18, 29, 33, 65, 71, 74, 115, 117, 119, 165], "item": [18, 33, 65, 159, 165, 174], "doubl": [18, 33, 122, 137], "sentenceembed": [18, 29, 33, 62, 65, 127], "In": [18, 29, 33, 44, 52, 54, 55, 59, 65, 68, 69, 74, 76, 77, 78, 82, 83, 99, 100, 102, 104, 107, 110, 111, 121, 159, 168, 174, 178, 179, 183, 184], "csv": [18, 33, 69, 94, 137, 178], "best": [18, 33, 49, 52, 60, 61, 74, 76, 89, 178], "wach": [18, 178], "ever": [18, 33, 48, 178], "opinion": [18, 33, 178], "win": [18, 33, 178], "award": [18, 33, 178], "terribl": [18, 33, 178], "act": [18, 33, 178], "bad": [18, 33, 102, 159, 174, 178], "realli": [18, 33, 103, 178], "trane": 18, "smallcorpu": [18, 33, 178], "read": [18, 33, 43, 44, 45, 47, 56, 64, 74, 77, 78, 79, 81, 82, 83, 88, 91, 92, 94, 100, 102, 104, 108, 110, 111, 119, 121, 122, 126, 132, 135, 147, 150, 153, 159, 163, 165, 166, 168, 169, 174, 178, 184], "header": [18, 33, 34, 137, 178], "src": [18, 33, 43, 44, 45, 47, 65, 77, 78, 82, 83, 88, 89, 97, 110, 111, 115, 121, 165, 166, 168, 169, 178, 184], "useembed": [18, 29, 33, 63, 178], "docclassifi": [18, 29, 33, 178], "setbatchs": [18, 29, 33, 57, 89, 93, 108, 159, 174, 178], "setmaxepoch": [18, 29, 33, 86, 88, 89, 93, 159, 174, 178], "20": [18, 34, 68, 87, 104, 134, 137, 151, 162, 178], "setlr": [18, 29, 33, 89, 93, 159, 174, 178], "5e": [18, 33, 178], "setdropout": [18, 33, 89, 178], "pipelinemodel": [18, 29, 33, 45, 47, 48, 56, 64, 88, 89, 103, 108, 110, 111, 121, 134, 136, 159, 163, 178, 181], "v": [18, 29, 33, 54, 65, 74, 76, 78, 89, 93, 94, 111, 151], "classifierdl_use_trec6": [18, 178], "trec": 18, "multiclassifierdlmodel": [18, 29], "sentimentdlmodel": [18, 29, 33], "sarcasmdl": [18, 178], "classifierdl_use_sarcasm": [18, 178], "sarcasm": [18, 178], "m": [18, 79, 81, 178], "could": [18, 55, 74, 82, 94, 108, 177, 178, 179], "put": [18, 151, 178], "word": [18, 43, 44, 45, 47, 49, 53, 54, 56, 57, 60, 62, 63, 64, 65, 68, 69, 71, 74, 77, 84, 87, 90, 91, 92, 97, 102, 104, 106, 107, 108, 110, 111, 112, 113, 117, 119, 120, 121, 134, 151, 162, 168, 169, 177, 178], "much": [18, 34, 49, 60, 61, 92, 121, 152, 178], "wake": [18, 178], "am": [18, 79, 81, 104, 115, 178], "mondai": [18, 178], "would": [18, 41, 53, 62, 79, 100, 152, 178], "arrays_zip": [18, 45, 47, 74, 178], "out": [18, 74, 77, 92, 104, 106, 107, 112, 113, 178], "normal": [18, 48, 72, 78, 100, 103, 113, 127, 136, 139, 152, 178, 179], "debertaforquestionansw": 19, "deberta": [19, 20, 21, 54], "deberta_v3_xsmall_qa_squad2": 19, "debertaforsequenceclassif": 20, "v2": [20, 21, 50, 51, 54], "v3": [20, 21], "deberta_v3_xsmall_sequence_classifier_imdb": 20, "deberta_base_sequence_classifier_imdb": 20, "debertafortokenclassif": 21, "deberta_v3_xsmall_token_classifier_conll03": 21, "distilbertforquestionansw": 22, "distilbert": [22, 23, 55], "distilbert_base_cased_qa_squad2": 22, "distilbertforsequenceclassif": 23, "distilbert_base_sequence_classifier_imdb": 23, "distilbertfortokenclassif": 24, "distilbert_base_token_classifier_conll03": 24, "albert_for_sequence_classif": [25, 72], "albert_for_token_classif": [25, 72], "bert_for_sequence_classif": [25, 72], "bert_for_token_classif": [25, 72], "camembert_for_sequence_classif": [25, 72], "camembert_for_token_classif": [25, 72], "deberta_for_sequence_classif": [25, 72], "deberta_for_token_classif": [25, 72], "distil_bert_for_sequence_classif": [25, 72], "distil_bert_for_token_classif": [25, 72], "longformer_for_sequence_classif": [25, 72], "longformer_for_token_classif": [25, 72], "multi_classifier_dl": [25, 72], "roberta_for_sequence_classif": [25, 72], "roberta_for_token_classif": [25, 72], "sentiment_dl": [25, 72], "xlm_roberta_for_sequence_classif": [25, 72], "xlm_roberta_for_token_classif": [25, 72], "xlnet_for_sequence_classif": [25, 72], "xlnet_for_token_classif": [25, 72], "longformerforquestionansw": 26, "longform": [26, 27, 28, 59], "longformer_base_base_qa_squad2": 26, "longformerforsequenceclassif": 27, "longformer_base_sequence_classifier_imdb": 27, "4096": [27, 49, 59], "longformerfortokenclassif": 28, "xlnet_base_token_classifier_conll03": [28, 39], "longformer_base_token_classifier_conll03": 28, "multiclassifierdl": 29, "bidirect": [29, 50, 51, 57, 68], "gru": 29, "convolut": [29, 44], "machin": [29, 56, 64, 74, 88, 104, 106, 107, 159, 176], "strongli": 29, "relat": [29, 45, 47, 71, 183], "variant": [29, 59, 63, 124], "mai": [29, 125, 177, 178, 179, 182, 183], "instanc": [29, 91, 93, 94, 142, 146, 152, 153, 157], "multiclass": 29, "categor": [29, 163], "precis": [29, 45, 47], "constraint": 29, "mani": [29, 54, 60, 61, 74, 104, 106, 107, 121], "formal": 29, "find": [29, 45, 47, 60, 61, 63, 69, 71, 77, 79, 104], "binari": [29, 132, 147, 159], "bertsentenceembed": [29, 33, 51, 61, 67], "multiclassifi": [29, 159, 174], "001": [29, 88, 89], "10": [29, 41, 45, 74, 79, 81, 90, 110, 159, 177], "44": [29, 56, 64, 97], "shuffleperepoch": 29, "threshold": [29, 33, 56, 64, 74, 76, 88, 91, 108, 121], "minimum": [29, 33, 56, 64, 71, 74, 76, 86, 88, 89, 92, 99, 100, 104, 107, 110, 111, 118, 119, 165], "id": [29, 48, 66, 69, 104, 106, 107, 123, 125, 126, 128, 135, 139, 159, 165], "ed58abb40640f983": 29, "pn": 29, "newsyou": 29, "toxic": 29, "a1237f726b5f5d89": 29, "dude": 29, "place": [29, 44], "obscen": 29, "insult": 29, "24b0d6c8733c2abe": 29, "thank": [29, 68, 74], "8c4478fb239bcfc0": 29, "gee": 29, "minut": 29, "traindataset": [29, 159, 174], "printschema": [29, 122, 126, 132, 135], "root": [29, 41, 45, 47, 71, 122, 126, 132, 135, 166], "setcleanupmod": [29, 126, 135], "shrink": [29, 126, 135], "1e": [29, 159, 174], "setthreshold": [29, 33, 74, 76, 159, 174], "setvalidationsplit": [29, 94, 100], "setverbos": [29, 88, 89, 94], "multiclassifierdl_use_tox": 29, "comment": [29, 74], "jigsaw": 29, "good": [29, 52, 55, 63, 103], "stuff": 29, "wtf": 29, "kind": [29, 74, 79, 81], "crap": 29, "robertaforquestionansw": [30, 91], "roberta": [30, 31, 32, 35, 36, 37, 52, 54, 59, 60, 61, 66, 67, 91], "roberta_base_qa_squad2": [30, 91], "robertaforsequenceclassif": 31, "roberta_base_sequence_classifier_imdb": 31, "robertafortokenclassif": 32, "roberta_base_token_classifier_conll03": 32, "sentimentdl": 33, "natur": [33, 44, 49, 50, 51, 52, 54, 55, 56, 63, 64, 68, 76, 104, 107, 125, 135, 139], "affect": [33, 119], "subject": [33, 45, 47], "view": 33, "common": [33, 69, 115, 125, 152, 181], "product": 33, "review": [33, 155], "tweet": 33, "interpret": [33, 69], "posit": [33, 54, 55, 66, 67, 68, 74, 87, 102, 103, 118, 121, 139, 159, 174], "final": [33, 59, 60, 61, 66, 67, 76, 89, 108, 178], "otheriws": [33, 76], "neutral": [33, 76], "thresholdlabel": [33, 76], "score": [33, 50, 51, 66, 67, 74, 76, 88, 89, 91, 102, 103, 104], "less": [33, 55, 76, 84, 88, 110], "watch": [33, 103], "32": [33, 49, 57, 177, 183], "setthresholdlabel": [33, 76], "p": [33, 48, 56, 64, 76, 89, 94, 117], "sentimentdl_use_imdb": 33, "english": [33, 52, 74, 110, 113, 121, 163], "imdb": 33, "sentimentdl_use_twitt": 33, "wow": 33, "video": [33, 74], "awesom": 33, "bruh": 33, "damn": 33, "wast": [33, 103], "tapasforquestionansw": 34, "implement": [34, 56, 64, 66, 91, 100, 108, 130, 131, 140, 141, 148, 154, 158], "tapa": 34, "design": [34, 43, 50, 51, 60, 61, 78, 106, 124, 159, 174], "about": [34, 45, 47, 60, 61, 65, 74, 91, 99, 111, 134, 136, 177, 179, 182, 183], "tabular": [34, 137], "tabl": [34, 137], "tri": 34, "share": [34, 74, 179], "its": [34, 44, 54, 55, 59, 68, 74, 97, 102, 106, 113, 159, 168], "table_qa_tapas_base_finetuned_wtq": 34, "document_assembl": [34, 91, 133, 137, 152], "table_json": 34, "document_t": [34, 137], "sentence_detector": [34, 72, 91, 98], "table_assembl": [34, 133, 152], "tableassembl": [34, 137], "stage": [34, 134, 136, 159, 174, 178, 179, 182], "json_data": 34, "monei": [34, 137], "ag": [34, 137], "donald": [34, 137], "trump": [34, 137], "000": [34, 74, 104, 121, 137], "75": [34, 74, 137], "elon": [34, 137], "musk": [34, 137], "55": [34, 90, 137], "AS": [34, 41, 91], "who": [34, 117, 178], "earn": 34, "thei": [34, 45, 47, 89, 92, 104, 136, 154, 166, 178], "count": [34, 108], "old": [34, 41, 168], "xlmrobertaforquestionansw": 35, "xlm": [35, 36, 37, 66, 67], "xlm_roberta_base_qa_squad2": 35, "xlmrobertaforsequenceclassif": 36, "xlm_roberta_base_sequence_classifier_imdb": 36, "xlmrobertafortokenclassif": 37, "xlm_roberta_base_token_classifier_conll03": 37, "xlnetforsequenceclassif": 38, "xlnet": [38, 39, 68], "xlnet_base_sequence_classifier_imdb": 38, "xlnetfortokenclassif": 39, "spanbert_coref": 40, "spanbertcorefmodel": 41, "corefer": 41, "resolut": [41, 43], "spanbert": 41, "identifi": [41, 65, 74, 78, 82, 118, 119, 159, 179], "given": [41, 69, 74, 91, 104, 107, 108, 110, 111, 113, 158, 159], "told": [41, 81], "mari": [41, 51, 61, 67, 100], "he": [41, 54, 81, 117], "borrow": 41, "book": [41, 48, 104, 108, 166], "her": [41, 91], "link": [41, 162], "ontonot": 41, "corefresolut": 41, "spanbert_base_coref": 41, "maxsegmentlength": 41, "textgenr": 41, "genr": 41, "One": [41, 74, 117, 138], "bc": 41, "broadcast": 41, "convers": 41, "bn": 41, "nw": 41, "wire": 41, "pt": 41, "pivot": 41, "testament": 41, "tc": 41, "telephon": 41, "wb": 41, "web": [41, 48, 52, 104, 159, 174], "setmaxsegmentlength": 41, "settextgenr": 41, "code": [41, 54, 56, 59, 60, 61, 64, 66, 67, 74, 76, 107, 175, 183], "swin_for_image_classif": 42, "vit_for_image_classif": 42, "swinforimageclassif": 43, "swinimageclassif": 43, "swin": 43, "hierarch": [43, 56, 64], "vision": [43, 44], "shift": 43, "window": [43, 56, 59, 64, 74, 89, 108], "ze": 43, "liu": [43, 54, 60, 61], "yutong": 43, "lin": 43, "yue": 43, "cao": 43, "han": 43, "hu": 43, "yixuan": 43, "zheng": 43, "zhang": 43, "stephen": 43, "bain": 43, "guo": 43, "whose": 43, "scheme": [43, 60], "bring": [43, 178], "greater": [43, 74], "effici": [43, 54, 56, 63, 64, 106, 177], "attent": [43, 44, 54, 59], "non": [43, 119, 121], "overlap": [43, 78, 83], "while": [43, 44, 49, 55, 65, 74, 94, 104, 159, 174, 179], "cross": [43, 66, 67, 90], "connect": 43, "imageclassifi": [43, 44], "image_assembl": [43, 44, 133, 152], "image_classifier_swin_base_patch4_window7_224": 43, "huggingfac": [43, 44, 52], "swinforimageclassificationtest": 43, "present": [43, 49, 57, 59, 60, 61, 63, 66, 67, 71, 94, 100, 106], "call": [43, 50, 51, 55, 69, 74, 104, 158, 163, 165, 178, 184], "capabl": [43, 55, 68, 104], "serv": [43, 175], "purpos": [43, 55, 100], "backbon": [43, 68], "adapt": 43, "aris": 43, "domain": [43, 74, 104], "variat": 43, "scale": [43, 44, 49, 55, 59, 66, 67, 104, 107], "visual": [43, 159], "high": [43, 63, 66, 67, 106], "compar": [43, 44, 49, 54, 55, 57, 68, 74, 100, 107, 108, 159, 174], "architectur": [43, 44, 49, 50, 51, 54, 60, 76, 89, 100, 107], "flexibl": 43, "variou": [43, 68, 172], "complex": [43, 57, 63, 74, 110, 111], "respect": [43, 54, 65, 88, 89, 168], "These": [43, 49, 60, 61, 68, 74, 88, 104, 162, 176], "broad": [43, 104], "rang": [43, 50, 51, 54, 55, 66, 67], "87": 43, "accuraci": [43, 45, 47, 50, 51, 56, 63, 64, 66, 67, 88, 89, 97, 110, 121, 174], "imagenet": [43, 44], "1k": 43, "dens": [43, 50, 51], "detect": [43, 63, 75, 76, 98, 99, 100], "box": 43, "ap": 43, "51": [43, 126, 135, 168], "coco": 43, "semant": [43, 57, 63, 121], "53": [43, 78, 83], "miou": 43, "ade20k": 43, "val": 43, "Its": [43, 47, 91], "surpass": [43, 54], "previou": [43, 66, 67, 104, 178], "margin": [43, 68], "demonstr": [43, 55, 59, 74, 104, 106], "potenti": [43, 108], "prove": 43, "benefici": [43, 74], "mlp": 43, "imagedf": [43, 44], "dropinvalid": [43, 44], "imageassembl": [43, 44, 132], "pipelinedf": [43, 44], "revers": [43, 44], "split": [43, 44, 99, 100, 115, 117, 118, 121], "image_nam": [43, 44], "palac": [43, 44], "jpeg": [43, 44], "egyptian_cat": [43, 44], "tabbi": 43, "cat": [43, 44], "hippopotamu": [43, 44], "hippo": [43, 44], "river": [43, 44], "hors": [43, 44], "amphibiu": [43, 44], "hen": [43, 44], "ostrich": [43, 44], "struthio": [43, 44], "camelu": [43, 44], "junco": [43, 44], "snowbird": [43, 44], "bluetick": [43, 44], "jpg": [43, 44], "chihuahua": [43, 44], "tractor": [43, 44], "ox": [43, 44], "setdorescal": 43, "rescal": 43, "rescalefactor": 43, "boolean": 43, "setrescalefactor": 43, "factor": [43, 66, 67, 68, 107, 108], "255": 43, "vitforimageclassif": 44, "vit": 44, "altern": [44, 74, 102, 108, 110, 111, 134, 137, 178, 183], "neural": [44, 50, 51, 54, 89, 100, 106], "network": [44, 50, 51, 57, 89, 100], "usual": [44, 139, 163], "image_classifier_vit_base_patch16_224": 44, "vitimageclassificationtestspec": 44, "becom": [44, 49, 55, 74], "de": [44, 52, 74, 76, 106], "facto": [44, 74], "standard": [44, 48, 59, 79, 81, 110, 111, 119], "remain": [44, 48, 49, 55, 74], "conjunct": 44, "replac": [44, 48, 54, 59, 76, 77, 90, 100, 110, 111, 178], "certain": [44, 108], "compon": [44, 93, 94, 122, 132, 142, 146, 157, 182], "keep": [44, 74, 92, 104, 107], "overal": [44, 65, 68], "structur": [44, 91, 139, 177], "relianc": 44, "cnn": [44, 76, 89, 100], "necessari": [44, 55, 174, 181], "pure": [44, 106], "directli": [44, 134, 159, 163, 174], "patch": 44, "veri": [44, 52, 57, 66, 67, 68, 104, 106, 107, 134, 177, 179, 182, 183], "well": [44, 45, 47, 63, 66, 67, 74, 137], "amount": [44, 63, 74, 83, 104, 121, 134, 182], "transfer": [44, 55, 63, 66, 67, 104, 107], "mid": 44, "small": [44, 48, 49, 52, 55, 56, 64, 77, 97, 134, 168, 182], "cifar": 44, "vtab": 44, "etc": [44, 53, 127, 139, 174], "attain": 44, "excel": [44, 68], "substanti": [44, 50, 51], "fewer": [44, 49], "worth": 44, "16x16": 44, "egyptian": 44, "dependencypars": [45, 47, 71], "dependencyparserapproach": [45, 166, 184], "unlabel": [45, 50, 51, 104, 107], "grammat": [45, 47], "dependencyparsermodel": [45, 47, 71], "relationship": [45, 47, 63, 71], "tell": [45, 47, 74, 151], "verb": [45, 47, 166], "modifi": [45, 47, 60, 61, 87, 100], "describ": [45, 47, 71, 74, 106], "wai": [45, 47, 69, 71, 136, 162], "chosen": [45, 47, 89], "particular": [45, 47, 74, 163, 178], "treebank": 45, "penn": 45, "setdependencytreebank": 45, "conll": [45, 47, 88, 89, 152, 166, 167, 181], "u": [45, 47, 54, 55, 74, 81, 87, 88, 89, 134, 151, 162, 166, 176, 179, 184], "setconllu": [45, 47], "apart": [45, 47, 123, 128], "dependencytreebank": 45, "conllu": [45, 47, 77, 152, 167, 181], "numberofiter": [45, 47], "converg": [45, 47, 97, 121], "better": [45, 47, 49, 54, 68, 74, 88, 97, 99, 100, 103, 121], "typeddependencyparserapproach": [45, 47], "postagg": [45, 47, 71, 88, 97], "dependency_treebank": 45, "emptydataset": [45, 47], "tree": [45, 71], "bank": 45, "setnumberofiter": [45, 47], "read_a": [45, 47, 69, 77, 78, 82, 83, 88, 92, 94, 102, 110, 111, 119, 145, 150, 152, 165, 166], "reada": [45, 47, 65, 69, 77, 78, 82, 83, 88, 92, 94, 102, 110, 111, 115, 119, 147, 150, 165, 166], "dep": 45, "dependency_conllu": [45, 71], "perceptron": [45, 72, 96], "featur": [45, 56, 64, 74, 84, 88, 94, 159, 181], "typeddependencyparsermdoel": 45, "union": [45, 47], "worker": [45, 47], "turner": [45, 47], "newal": [45, 47], "sai": [45, 47, 74, 119], "disappoint": [45, 47], "talk": [45, 47], "stricken": [45, 47], "parent": [45, 47], "firm": [45, 47], "feder": [45, 47], "mogul": [45, 47], "col": [45, 47, 69, 78, 87, 90, 123, 128, 151, 177], "dependency_pars": [46, 72, 163, 183], "typed_dependency_pars": [46, 72], "typeddependencypars": [47, 71], "conll2009": 47, "typeddependencyparsermodel": [47, 71], "beforehand": 47, "2009": 47, "setconll2009": 47, "dependency_typ": [47, 71], "train_smal": 47, "txt": [47, 56, 64, 65, 77, 78, 82, 83, 97, 100, 102, 108, 110, 111, 115, 119, 168, 169, 184], "descript": [47, 62, 74, 79, 110, 117, 147], "typdep": 47, "dependency_typed_conllu": [47, 71], "amod": 47, "flat": [47, 71, 129], "nsubj": [47, 71, 129, 166], "parataxi": 47, "documentnorm": 48, "raw": [48, 104, 117, 119, 121, 177, 179], "scrape": 48, "xml": 48, "remov": [48, 60, 61, 92, 103, 118, 127, 128, 129], "dirti": [48, 92], "regex": [48, 69, 79, 82, 92, 108, 110, 111, 118, 119, 121], "want": [48, 69, 90, 163, 179], "polici": 48, "lower": [48, 49, 74, 108, 125], "__": [48, 127, 128], "action": 48, "clean": [48, 92, 107, 139, 179], "lowercas": [48, 92, 118, 121, 125], "convert": [48, 53, 62, 65, 79, 81, 84, 87, 92, 107, 118, 121, 123, 124, 125, 128, 129, 138, 159, 174, 181], "pretty_al": 48, "utf": 48, "cleanuppattern": [48, 92], "normalizeddocu": 48, "setact": 48, "setpattern": [48, 118, 121], "setreplac": 48, "setpolici": 48, "setlowercas": [48, 92, 125, 139], "div": 48, "theworldsgreatest": 48, "right": [48, 50, 51, 121], "hide": 48, "wide": [48, 50, 51, 54, 55, 66, 67], "toptext": 48, "style": [48, 76, 107], "font": 48, "famili": 48, "sego": 48, "ui": 48, "arial": 48, "san": [48, 74], "serif": 48, "world": [48, 115, 124, 159, 174], "largest": [48, 74, 104], "develop": [48, 74, 106, 156], "site": [48, 74], "h1": 48, "300": 48, "160": 48, "lorem": [48, 78, 83], "ipsum": [48, 78, 83], "simpli": [48, 179], "print": [48, 163], "typeset": 48, "industri": 48, "been": [48, 52, 104, 138, 139, 163], "sinc": [48, 74, 104, 178, 179, 183], "1500": 48, "unknown": [48, 76], "printer": 48, "took": 48, "gallei": 48, "scrambl": 48, "specimen": 48, "surviv": 48, "five": [48, 90], "centuri": [48, 121], "leap": 48, "electron": 48, "essenti": [48, 104], "unchang": 48, "popularis": 48, "1960": 48, "releas": [48, 49, 52, 54, 60, 61, 66, 67, 107, 152], "letraset": 48, "passag": 48, "recent": [48, 50, 51, 54, 60, 61, 74], "desktop": 48, "publish": [48, 60, 61], "softwar": 48, "aldu": 48, "pagemak": 48, "setencod": 48, "lite": 49, "googl": [49, 50, 51, 54, 56, 57, 60, 61, 63, 64, 74, 107, 166], "research": [49, 50, 51, 54, 56, 64, 106, 107], "toyota": 49, "technolog": 49, "institut": 49, "chicago": 49, "offici": [49, 74, 87, 88, 89, 134, 151, 162, 175], "tf": [49, 63], "wrapper": [49, 155], "port": 49, "properti": [49, 130, 131, 142, 145, 152], "albert_base_uncas": 49, "albert_bas": 49, "768": [49, 50, 51, 52, 54, 55, 59, 60, 61, 66, 67, 68], "emb": 49, "dim": 49, "12m": 49, "albert_large_uncas": 49, "albert_larg": 49, "1024": [49, 57, 59, 68], "24": [49, 68, 78, 83, 87, 108, 134, 151, 162, 177], "16": [49, 68, 90, 168, 177], "18m": 49, "albert_xlarge_uncas": 49, "albert_xlarg": 49, "2048": 49, "60m": 49, "albert_xxlarge_uncas": 49, "albert_xxlarg": 49, "235m": 49, "sentencepiec": [49, 54, 63], "everi": [49, 50, 51, 52, 54, 55, 59, 60, 61, 66, 67, 68, 89, 103, 106, 108, 126, 135, 136, 179], "dimens": [49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 146], "repeat": 49, "footprint": 49, "howev": [49, 62, 68, 74, 92, 163, 177], "cost": [49, 108, 110], "similar": [49, 63, 74, 76], "through": [49, 71, 74, 129, 179], "FOR": 49, "http": [49, 52, 54, 56, 57, 63, 64, 121, 175], "tfhub": [49, 57, 63], "q": 49, "increas": [49, 65, 74, 104, 110], "often": [49, 60, 61, 68], "downstream": [49, 52, 54, 57, 59, 68, 104, 107], "some": [49, 51, 66, 74, 89, 100, 104, 136, 159, 177, 178, 182, 183], "point": [49, 50, 51, 99, 100, 126, 135, 165], "further": [49, 74, 88, 89, 123, 139], "harder": 49, "gpu": [49, 104, 106, 107, 152], "tpu": 49, "longer": [49, 56, 59, 64, 76, 183], "techniqu": [49, 54, 104, 107], "consumpt": [49, 63, 65], "speed": [49, 88, 106], "devlin": [49, 60, 61], "et": [49, 60, 61, 76], "al": [49, 60, 61], "2019": [49, 52, 54, 60, 61, 66, 67], "comprehens": [49, 104], "empir": [49, 50, 51, 66, 67, 68], "evid": 49, "lead": [49, 52, 66, 67], "focus": [49, 74], "inter": 49, "coher": [49, 104], "As": [49, 50, 51, 55, 74], "establish": 49, "glue": [49, 50, 51, 55, 60, 61, 66, 67], "race": [49, 54, 60, 61], "embeddingsfinish": [49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 127], "finished_embed": [49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "setoutputasvector": [49, 50, 51, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 127], "setcleanannot": [49, 54, 55, 57, 59, 60, 62, 63, 65, 66, 68, 127, 128, 129], "80": [49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 82, 127, 139], "1342473030090332": [49, 54], "3855540752410889": [49, 54], "9818322062492371": [49, 54], "784737348556518": [49, 54], "847029983997345": [49, 54], "047153353691101": [49, 54], "1520637571811676": [49, 54], "6245765686035156": [49, 54], "009860038757324219": [49, 54], "13450059294700623": [49, 54], "707749128341675": [49, 54], "2916892766952": [49, 54], "04192575812339783": [49, 54], "5764210224151611": [49, 54], "3196685314178467": [49, 54], "527840495109": [49, 54], "15583214163780212": [49, 54], "1614152491092682": [49, 54], "28423872590065": [49, 54], "135491415858268": [49, 54], "bertembed": [50, 53, 62, 89, 127], "small_bert_l2_768": 50, "understand": [50, 51, 55, 66, 68, 74, 107, 121, 177], "introduc": [50, 51, 55, 57, 59, 107], "stand": [50, 51], "unlik": [50, 51, 66, 74, 117], "jointli": [50, 51], "condit": [50, 51, 104, 107], "both": [50, 51, 57, 63, 71, 178, 179], "left": [50, 51, 121], "just": [50, 51, 55, 60, 84, 89], "infer": [50, 51, 52, 55, 68], "without": [50, 51, 66, 67, 74, 104, 121], "modif": [50, 51], "conceptu": [50, 51], "power": [50, 51, 107], "obtain": [50, 51, 52, 63], "eleven": [50, 51], "push": [50, 51], "absolut": [50, 51], "multinli": [50, 51], "86": [50, 51, 54], "v1": [50, 51], "f1": [50, 51, 66, 67, 89, 104], "93": [50, 51], "83": [50, 51, 54, 168, 169, 184], "small_bert_l2_128": 50, "3497989177703857": 50, "480538547039032": 50, "3238905668258667": 50, "612930893898010": 50, "1357314586639404": 50, "32984697818756104": 50, "6032363176345825": 50, "6791689395904": 50, "8244884014129639": 50, "27088963985443115": 50, "059438943862915": 50, "9817547798156": 50, "1648050546646118": 50, "4725411534309387": 50, "5938255786895752": 50, "5780693292617": 50, "9125322699546814": 50, "4563939869403839": 50, "3975459933280945": 50, "81611204147338": 50, "sentence_bert_embed": 51, "sent_small_bert_l2_768": 51, "islong": 51, "long": [51, 59, 68], "sent_small_bert_l2_128": 51, "orang": [51, 61, 67], "8951074481010437": [51, 61, 67], "13753940165042877": [51, 61, 67], "3108254075050354": [51, 61, 67], "65693199634552": [51, 61, 67], "6180210709571838": [51, 61, 67], "12179657071828842": [51, 61, 67], "191165953874588": [51, 61, 67], "4497021436691": [51, 61, 67], "822715163230896": [51, 61, 67], "7568016648292542": [51, 61, 67], "1165061742067337": [51, 61, 67], "59048593044281": [51, 61, 67], "setislong": 51, "camembertembed": 52, "tasti": 52, "french": [52, 74, 106, 113], "loui": 52, "martin": 52, "muller": 52, "pedro": 52, "javier": 52, "ortiz": 52, "su\u00e1rez": 52, "yoann": 52, "dupont": 52, "laurent": 52, "romari": 52, "\u00e9ric": 52, "villemont": 52, "la": [52, 106], "clergeri": 52, "djam\u00e9": 52, "seddah": 52, "beno\u00eet": 52, "sagot": 52, "facebook": [52, 54, 66, 67], "138gb": 52, "camembert_bas": 52, "camembertembeddingstestspec": 52, "co": [52, 74], "ubiquit": 52, "despit": 52, "most": [52, 55, 59, 74, 89, 104, 106, 107], "concaten": [52, 121], "practic": [52, 107], "except": [52, 84, 89, 119], "investig": [52, 55, 63], "feasibl": 52, "monolingu": [52, 66, 67], "crawl": [52, 107], "prefer": [52, 71, 129], "wikipedia": [52, 76, 104], "surprisingli": [52, 63], "4gb": 52, "those": [52, 71, 90, 178, 179], "larger": [52, 55, 60, 61, 104, 106, 107], "130": 52, "gb": 52, "reach": [52, 74, 104, 121], "four": [52, 100, 121, 138], "un": [52, 76], "08442357927560806": 52, "12863239645957947": 52, "03835778683423996": 52, "200479581952": 52, "048462312668561935": 52, "12637358903884888": 52, "27429091930389404": 52, "07516729831": 52, "02690504491329193": 52, "12104076147079468": 52, "012526623904705048": 52, "031543646007": 52, "05877285450696945": 52, "08773420006036758": 52, "06381352990865707": 52, "122621834278": 52, "chunkembed": [53, 127], "wordembed": [53, 62, 65, 89, 127, 152], "chunker": [53, 72, 152], "ngramgener": [53, 84], "nerconvert": [53, 87, 88, 89, 159, 174], "poolingstrategi": [53, 62], "aggreg": [53, 62], "sum": [53, 57, 62], "skipoov": 53, "discard": [53, 91], "oov": 53, "ngram": [53, 84, 104, 107], "setn": [53, 84], "wordembeddingsmodel": [53, 62, 65, 71, 88, 89, 90, 127], "setpoolingstrategi": [53, 62], "55661": 53, "42829502": 53, "86661": 53, "409785": 53, "06316501": 53, "120775": 53, "0732005": 53, "40674996": 53, "22938299": 53, "50597": 53, "288195": 53, "555655": 53, "465145": 53, "140118": 53, "17417": 53, "095253006": 53, "0530925": 53, "218465": 53, "714395": 53, "79860497": 53, "0129999": 53, "139705": 53, "177955": 53, "1887775": 53, "45545": 53, "20030999": 53, "461557": 53, "07891501": 53, "strategi": [53, 62, 82, 99, 108], "setskipoov": 53, "debertaembed": 54, "decod": [54, 59, 104, 106, 107], "enhanc": [54, 103], "disentangl": 54, "pengcheng": 54, "xiaodong": 54, "jianfeng": 54, "gao": 54, "weizhu": 54, "chen": [54, 60, 61], "2018": [54, 60, 61], "half": [54, 74], "deberta_v3_bas": 54, "microsoft": [54, 106], "www": 54, "blog": 54, "human": [54, 74], "superglu": 54, "progress": [54, 100, 118], "significantli": [54, 57, 60, 61, 66, 67, 74], "novel": [54, 68, 74], "mechan": [54, 59], "weight": [54, 57, 74, 88, 90, 108], "among": 54, "matric": 54, "second": [54, 57, 82, 99, 113, 118, 178], "achiev": [54, 59, 60, 61, 66, 67, 68, 89, 104, 106, 107, 134, 182], "mnli": 54, "9": [54, 66, 67, 84, 177, 182, 183], "90": 54, "91": 54, "88": 54, "made": [54, 63, 174], "publicli": [54, 66, 67], "distilbertembed": 55, "fast": [55, 103, 106, 134, 182], "cheap": 55, "distil": 55, "40": [55, 90, 106], "uncas": 55, "preserv": [55, 87, 118, 139], "95": 55, "measur": [55, 60, 61, 159], "distilbert_base_cas": 55, "doesn": [55, 60], "t": [55, 60, 77, 92, 100, 102, 119, 123, 128], "token_type_id": [55, 60], "don": [55, 60, 92], "indic": [55, 60, 118, 121], "belong": [55, 60], "separ": [55, 60, 82, 84, 99, 100, 110, 119, 121, 128, 151, 165, 176], "sep_token": [55, 60], "sep": 55, "position_id": 55, "ad": [55, 57, 108], "though": [55, 74], "know": [55, 106, 136], "smaller": [55, 56, 64], "cheaper": 55, "lighter": 55, "preval": 55, "oper": [55, 59, 108, 117, 177], "edg": [55, 71], "constrain": 55, "budget": 55, "counterpart": 55, "prior": [55, 59, 108], "leverag": [55, 159, 174], "reduc": [55, 110, 111, 139], "retain": 55, "97": [55, 79, 81, 121], "being": [55, 89, 94, 106, 107], "induct": 55, "bias": 55, "tripl": [55, 71], "cosin": 55, "distanc": [55, 108, 110, 111], "devic": 55, "proof": 55, "concept": [55, 179], "experi": [55, 68, 159, 175], "studi": [55, 60, 61, 107], "1127224713563919": 55, "1982710212469101": 55, "5360898375511169": 55, "272536993026733": 55, "35534414649009705": 55, "13215228915214539": 55, "40981462597846985": 55, "14036104083061": 55, "328085333108902": 55, "06269335001707077": 55, "017595693469047546": 55, "024373905733": 55, "15617232024669647": 55, "2967822253704071": 55, "22324979305267334": 55, "04568954557180": 55, "45411425828933716": 55, "01173491682857275": 55, "190129816532135": 55, "1178255230188369": 55, "doc2vecapproach": 56, "word2vec": [56, 58, 72], "corpu": [56, 57, 64, 74, 77, 97, 107, 108, 168, 184], "algorithm": [56, 64, 74, 88, 103, 108, 110, 111], "construct": [56, 64, 119, 162, 181], "vocabulari": [56, 64, 104, 107, 108], "skip": [56, 64, 71, 108], "gram": [56, 64, 74, 84, 104, 107], "doc2vecmodel": 56, "vectors": [56, 64], "windows": [56, 64, 74], "numpartit": [56, 64], "partit": [56, 64, 165], "mincount": [56, 64, 108], "must": [56, 64, 77, 78, 82, 83, 94, 102, 103, 110, 111, 125, 151, 152, 159, 165], "appear": [56, 64, 108], "ani": [56, 63, 64, 69, 74, 89, 104, 107, 127, 128, 163, 175, 178, 179, 184], "divid": [56, 64], "1000": [56, 64, 71, 88], "stepsiz": [56, 64], "optim": [56, 60, 61, 64, 89, 91, 100], "025": [56, 64], "maxit": [56, 64], "estim": [56, 64, 114, 130, 140, 148, 158, 178], "space": [56, 64, 65, 84, 139], "distribut": [56, 64], "composition": [56, 64], "sherlockholm": [56, 64, 108, 184], "setvectors": [56, 64], "setwindows": [56, 64, 74], "setsteps": [56, 64], "initi": [56, 64, 108, 118, 136, 152, 165, 166, 168, 169, 174], "setnumpartit": [56, 64], "setmaxit": [56, 64], "numiter": [56, 64], "equal": [56, 64], "setse": [56, 64], "setmincount": [56, 64, 108], "doc2vec_gigaword_300": 56, "06222493574023247": [56, 64], "011579325422644615": [56, 64], "009919632226228714": [56, 64], "109361454844": [56, 64], "doc2vec_wiki": 56, "elmoembed": 57, "elmo": 57, "billion": [57, 104], "computation": [57, 60, 61, 68, 104, 106, 107], "expens": [57, 60, 61, 68, 102, 104, 106, 107, 110], "lookup": [57, 65, 68, 78, 110, 111], "acceler": [57, 68, 104, 106, 107, 152], "setpoolinglay": 57, "word_emb": 57, "shape": 57, "batch_siz": 57, "max_length": 57, "lstm_outputs1": 57, "lstm": [57, 89], "lstm_outputs2": 57, "trainabl": 57, "tensor": 57, "poolinglay": 57, "contextu": [57, 108], "characterist": 57, "syntax": 57, "vari": 57, "across": [57, 104], "linguist": [57, 121], "polysemi": 57, "intern": [57, 93, 94, 119, 121, 137, 142, 146, 152], "bilm": 57, "exist": [57, 108, 127, 129, 159], "six": [57, 110, 111], "textual": 57, "entail": 57, "expos": 57, "crucial": 57, "mix": [57, 141, 158], "semi": 57, "signal": 57, "662458181381226e": 57, "2541114091873169": 57, "6275503039360046": 57, "5787073969841": 57, "19154725968837738": 57, "22998669743537903": 57, "2894386649131775": 57, "21524395048618": 57, "10400570929050446": 57, "12288510054349899": 57, "07056470215320587": 57, "246389418840": 57, "49932169914245605": 57, "12706467509269714": 57, "30969417095184326": 57, "2643227577209": 57, "8871506452560425": 57, "20039963722229004": 57, "0601330995559692": 57, "0348707810044": 57, "albert_embed": [58, 72], "bert_embed": [58, 72], "bert_sentence_embed": [58, 72], "camembert_embed": [58, 72], "chunk_embed": [58, 72], "deberta_embed": [58, 72], "distil_bert_embed": [58, 72], "doc2vec": [58, 72], "elmo_embed": [58, 72], "longformer_embed": [58, 72], "roberta_embed": [58, 72], "roberta_sentence_embed": [58, 72], "universal_sentence_encod": [58, 72], "xlm_roberta_embed": [58, 72], "xlm_roberta_sentence_embed": [58, 72], "xlnet_embed": [58, 72], "longformerembed": 59, "iz": 59, "beltagi": 59, "matthew": 59, "arman": 59, "cohan": 59, "checkpoint": 59, "mlm": 59, "096": 59, "longformer_base_4096": 59, "unabl": 59, "quadrat": 59, "linearli": 59, "easi": 59, "thousand": 59, "drop": [59, 113], "motiv": 59, "global": 59, "text8": 59, "enwik8": 59, "contrast": [59, 78, 107], "finetun": [59, 68], "varieti": [59, 66, 67, 183], "outperform": [59, 63, 66, 67, 68, 74, 104], "wikihop": 59, "triviaqa": 59, "led": [59, 60, 61, 74], "effect": [59, 99, 107], "arxiv": 59, "summar": [59, 74, 104, 106, 107], "found": [59, 65, 74, 110, 117, 125, 165, 181], "18792399764060974": [59, 60], "14591649174690247": [59, 60], "20547787845134735": [59, 60], "1468472778797": [59, 60], "22845706343650818": [59, 60], "18073144555091858": [59, 60], "09725798666477203": [59, 60], "0417917296290": [59, 60], "07037967443466187": [59, 60], "14801117777824402": [59, 60], "03603338822722435": [59, 60], "17893412709": [59, 60], "08734266459941864": [59, 60], "2486150562763214": [59, 60], "009067727252840996": [59, 60], "24408400058": [59, 60], "22409197688102722": [59, 60], "4312366545200348": [59, 60], "1401449590921402": [59, 60], "356410235166549": [59, 60], "robertaembed": [60, 66], "robustli": [60, 61, 91], "yinhan": [60, 61], "myle": [60, 61, 66, 67], "ott": [60, 61, 66, 67], "naman": [60, 61, 66, 67], "goyal": [60, 61, 66, 67], "jingfei": [60, 61], "du": [60, 61, 76], "mandar": [60, 61], "joshi": [60, 61], "danqi": [60, 61], "omer": [60, 61], "levi": [60, 61], "mike": [60, 61], "lewi": [60, 61], "luke": [60, 61, 66, 67], "zettlemoy": [60, 61, 66, 67], "veselin": [60, 61, 66, 67], "stoyanov": [60, 61, 66, 67], "hyperparamet": [60, 61], "next": [60, 61, 74, 79, 81, 104, 107], "mini": [60, 61], "roberta_bas": 60, "bpe": 60, "gpt": [60, 104], "signific": [60, 61, 66, 67, 74, 77], "gain": [60, 61, 66, 67], "care": [60, 61, 119], "comparison": [60, 61, 63, 113], "privat": [60, 61, 153], "choic": [60, 61, 82], "impact": [60, 61], "replic": [60, 61], "carefulli": [60, 61], "undertrain": [60, 61], "exce": [60, 61], "highlight": [60, 61], "previous": [60, 61, 74], "overlook": [60, 61], "rais": [60, 61, 74, 84, 89, 159], "report": [60, 61, 63, 159, 174], "robertasentenceembed": 61, "sent_roberta_bas": 61, "embeddingssent": 62, "22093398869037628": 62, "25130119919776917": 62, "41810303926467896": 62, "380883991718": 62, "dimension": 63, "tfhub_us": 63, "loadsp": 63, "op": 63, "lingual": [63, 66, 67, 74, 76, 106], "accur": [63, 103, 110], "divers": [63, 104, 107, 175], "trade": [63, 66, 67], "baselin": [63, 104], "do": [63, 74, 87, 113, 119, 123, 134, 174, 178, 182], "tend": 63, "With": [63, 68, 74], "observ": 63, "minim": [63, 91, 106], "encourag": 63, "weat": 63, "bia": 63, "freeli": 63, "04616805538535118": 63, "022307956591248512": 63, "044395286589860916": 63, "0016493503": 63, "setloadsp": 63, "word2vecapproach": 64, "word2vecmodel": 64, "word2vec_gigaword_300": 64, "word2vec_wiki": 64, "custom": [65, 88, 89, 99, 100, 119, 159], "dictionari": [65, 74, 77, 82, 88, 90, 91, 92, 102, 110, 111, 159], "setstoragepath": [65, 78], "line": [65, 69, 78, 83, 100, 102, 162, 165, 168], "delimit": [65, 69, 71, 77, 82, 84, 88, 92, 102, 118, 137, 165, 168], "39658191506190343": 65, "630968081620067": 65, "5393722253731201": 65, "8428180123359783": 65, "were": [65, 89, 159, 174], "7535235923631415": 65, "9699218875629833": 65, "10397182122983872": 65, "11833962569383116": 65, "stress": 65, "0492683418305907": 65, "9415954572751959": 65, "47624463167525755": 65, "16790967216778263": 65, "induc": 65, "1535748762292387": 65, "33498936903209897": 65, "9235178224122094": 65, "1158772920395934": 65, "zero": [65, 91, 104], "withcoveragecolumn": 65, "overallcoverag": 65, "writebuffers": 65, "dump": 65, "disk": [65, 178, 179], "storag": [65, 69, 78, 145, 152], "10000": 65, "readcaches": 65, "cach": [65, 163], "higher": [65, 74, 103, 104, 107], "random_embeddings_dim4": 65, "abov": [65, 71, 168], "setstorageref": 65, "glove_4d": 65, "setdimens": [65, 146], "patient": 65, "diagnos": 65, "diabet": 65, "9439099431037903": 65, "4707513153553009": 65, "806300163269043": 65, "16176554560661316": 65, "7966810464859009": 65, "5551124811172485": 65, "8861005902290344": 65, "28284206986427307": 65, "025029370561242104": 65, "35177749395370483": 65, "052506182342767715": 65, "1887107789516449": 65, "08617766946554184": 65, "8399239182472229": 65, "5395117998123169": 65, "7864698767662048": 65, "6599600911140442": 65, "16109347343444824": 65, "6041093468666077": 65, "8913561105728149": 65, "5955275893211365": 65, "01899011991918087": 65, "4397728443145752": 65, "8911281824111938": 65, "9840458631515503": 65, "7599489092826843": 65, "9417727589607239": 65, "8624503016471863": 65, "setwritebuffers": 65, "setreadcaches": 65, "glove_100d": [65, 89], "There": [65, 69, 71, 117, 176, 178, 179, 184], "conveni": 65, "coverag": [65, 144], "add": [65, 79, 81, 99, 104, 107, 108, 119, 178], "stat": 65, "field": [65, 69, 83], "whole": [65, 162], "consid": [65, 71, 74, 108, 110, 111, 113, 117, 163], "570580005645752": 65, "44183000922203064": 65, "7010200023651123": 65, "417129993438720": 65, "542639970779419": 65, "4147599935531616": 65, "0321999788284302": 65, "4024400115013122": 65, "2708599865436554": 65, "04400600120425224": 65, "020260000601410866": 65, "17395000159": 65, "6191999912261963": 65, "14650000631809235": 65, "08592499792575836": 65, "2629800140857": 65, "3397899866104126": 65, "20940999686717987": 65, "46347999572753906": 65, "6479200124740": 65, "embeddings_col": 65, "coverageresult": 65, "coverateresult": 65, "wordsoverallcoverag": 65, "resultdf": 65, "percentag": [65, 108, 121], "output_col": 65, "wordscoverag": 65, "cov_embed": 65, "loadstorag": [65, 78], "storage_ref": [65, 78], "xlmrobertaembed": 66, "alexi": [66, 67], "conneau": [66, 67], "kartikai": [66, 67], "khandelw": [66, 67], "vishrav": [66, 67], "chaudhari": [66, 67], "guillaum": [66, 67], "wenzek": [66, 67], "francisco": [66, 67, 74], "guzman": 66, "edouard": [66, 67], "grave": [66, 67], "5tb": [66, 67], "filter": [66, 67, 74, 87, 88, 104, 106, 107, 113, 151, 163], "commoncrawl": [66, 67], "xlm_roberta_bas": 66, "xx": [66, 67, 76, 106], "multilingu": [66, 67, 121], "doe": [66, 74, 87, 134, 136, 163, 179, 182, 183], "abl": [66, 107, 159, 177], "determin": 66, "correct": [66, 108, 110, 111, 121], "hundr": [66, 67], "terabyt": [66, 67], "dub": [66, 67], "r": [66, 67, 74], "mbert": [66, 67], "xnli": [66, 67], "mlqa": [66, 67], "particularli": [66, 67], "low": [66, 67, 108], "swahili": [66, 67], "urdu": [66, 67], "capac": [66, 67, 104], "dilut": [66, 67], "sacrif": [66, 67], "ri": [66, 67], "competit": [66, 67, 74], "strong": [66, 67], "05969233065843582": 66, "030789051204919815": 66, "04443822056055069": 66, "09564960747": 66, "038839809596538544": 66, "011712731793522835": 66, "019954433664679527": 66, "0667808502": 66, "03952755779027939": 66, "03455188870429993": 66, "019103847444057465": 66, "04311436787": 66, "09579929709434509": 66, "02494969218969345": 66, "014753809198737144": 66, "10259044915": 66, "004710011184215546": 66, "022148698568344116": 66, "011723337695002556": 66, "013356896": 66, "xlmrobertasentenceembed": 67, "guzm\u00e3": 67, "sent_xlm_roberta_bas": 67, "xlnetembed": 68, "autoregress": 68, "permut": 68, "addition": [68, 89, 97, 126, 135, 162], "emploi": 68, "xl": 68, "exhibit": 68, "involv": [68, 100], "sota": 68, "rank": [68, 108], "xlnet_large_cas": 68, "xlnet_base_cas": 68, "full": [68, 178], "zihangdai": 68, "denois": 68, "autoencod": 68, "corrupt": 68, "neglect": 68, "suffer": 68, "discrep": 68, "pro": 68, "con": 68, "enabl": [68, 69, 89, 110, 152], "maxim": [68, 108], "likelihood": 68, "overcom": 68, "formul": 68, "furthermor": 68, "integr": [68, 74, 106, 159, 174, 176], "idea": 68, "6287205219268799": 68, "4865287244319916": 68, "186111718416214": 68, "234187275171279": 68, "1967450380325317": 68, "2746637463569641": 68, "9481253027915955": 68, "3431355059146881": 68, "0777631998062134": 68, "092679977416992": 68, "5331977605819702": 68, "11190271377563": 68, "8349916934967041": 68, "45627787709236145": 68, "7890847325325012": 68, "028069257736": 68, "134845569729805": 68, "11672890186309814": 68, "4945235550403595": 68, "66587203741073": 68, "entityrul": 69, "entityrulerapproach": 69, "exact": [69, 78, 83], "definit": [69, 91, 165], "json": [69, 137, 159], "jsonl": 69, "setpatternsresourc": 69, "might": [69, 89, 121, 183], "setenablepatternregex": 69, "rule": [69, 82, 102, 117, 119], "person": [69, 166], "w": [69, 72, 82, 88, 92, 117, 119, 152], "locat": [69, 99, 123, 152, 162, 178], "winterfel": 69, "jon": 69, "snow": [69, 90, 108], "stark": 69, "eddard": 69, "patternsresourc": 69, "enablepatternregex": 69, "usestorag": 69, "rocksdb": 69, "lord": 69, "29": [69, 90, 121, 168], "38": 69, "setusestorag": 69, "setsentencematch": 69, "setalphabetresourc": 69, "alphabet": [69, 92], "plain": [69, 184], "entityrulermodel": 69, "entity_rul": [70, 72], "graphextract": [71, 129], "graph": [71, 89, 106, 114, 129], "nerdlmodel": [71, 87, 88, 89, 90, 159, 163, 174], "store": [71, 93, 94, 137, 142, 146, 157, 162, 175], "node": 71, "relev": [71, 74], "taken": 71, "implicitli": 71, "setmergeent": 71, "automat": [71, 74, 91, 106, 110, 177, 178], "setdependencyparsermodel": 71, "settypeddependencyparsermodel": 71, "setrelationshiptyp": 71, "public": [71, 163, 178], "relationshiptyp": 71, "pair": [71, 159], "entitytyp": 71, "explodeent": 71, "roottoken": 71, "travers": 71, "along": 71, "maxsentences": 71, "minsentences": 71, "below": [71, 183], "mergeent": 71, "merg": [71, 78, 83], "neighbor": 71, "includeedg": 71, "symbol": [71, 108, 121], "posmodel": 71, "coordin": [71, 99], "remoteloc": 71, "graphfinish": [71, 129], "rdf": [71, 129], "nertagg": [71, 88, 89, 90], "morn": [71, 129], "flight": [71, 129], "denver": [71, 129], "18": [71, 79, 81, 84, 87, 90, 134, 151, 162, 177], "path1": 71, "setentitytyp": 71, "setexplodeent": 71, "setroottoken": 71, "setmaxsentences": 71, "setminsentences": 71, "setmergeentitiesiobformat": 71, "iob": [71, 87, 88, 89], "iob2": [71, 87], "setincludeedg": 71, "setdelimit": [71, 82, 84], "setposmodel": 71, "class": [72, 145, 149, 156, 167, 173, 174, 182, 184], "classifier_dl": [72, 152], "er": [72, 152], "keyword_extract": [72, 152], "yake_keyword_extract": [72, 73], "ld_dl": [72, 152], "language_detector_dl": [72, 75], "matcher": [72, 152], "big_text_match": [72, 80], "date_match": [72, 80], "multi_date_match": [72, 80], "regex_match": [72, 80], "text_match": [72, 80], "ner_approach": [72, 85], "ner_convert": [72, 85], "ner_crf": [72, 85], "ner_dl": [72, 85], "ner_overwrit": [72, 85], "param": [72, 88, 141, 142, 146, 152, 157, 158], "sentence_detector_dl": [72, 98, 106], "sentiment_detector": [72, 101], "vivekn_senti": [72, 101], "seq2seq": [72, 152], "gpt2_transform": [72, 105], "marian_transform": [72, 105], "t5_transform": [72, 105], "spell_check": [72, 152], "context_spell_check": [72, 109], "norvig_sweet": [72, 109], "symmetric_delet": [72, 109], "chunk_token": [72, 116], "recursive_token": [72, 116], "regex_token": [72, 116], "word_segment": [72, 120], "document_norm": [72, 152], "graph_extract": [72, 152], "lemmat": [72, 102, 113, 136, 139, 152], "n_gram_gener": [72, 152], "stemmer": [72, 113, 152], "stop_words_clean": [72, 152], "yakekeywordextract": 74, "yake": 74, "independ": [74, 110, 111, 117], "individu": [74, 108], "organ": [74, 106, 124], "grow": 74, "autom": 74, "adequ": 74, "manner": 74, "emerg": [74, 107], "tool": 74, "system": [74, 104], "nor": 74, "thesauri": 74, "neither": 74, "corpora": [74, 78], "thu": 74, "written": [74, 106], "plethora": 74, "situat": [74, 100], "access": 74, "restrict": 74, "therefor": [74, 182], "sent": 74, "boundari": [74, 99, 100, 103, 119, 121], "detector": [74, 79, 102], "section": [74, 126, 135, 174, 176, 182], "tweakabl": 74, "upper": 74, "bound": [74, 99, 100, 103], "minngram": 74, "maxngram": 74, "occurr": 74, "nkeyword": 74, "stopword": [74, 90, 113], "stop": [74, 88, 113], "campo": 74, "mangaravit": 74, "pasquali": 74, "jatowt": 74, "jorg": 74, "nune": 74, "2020": [74, 79, 81, 100], "scienc": [74, 175], "journal": [74, 121], "elsevi": 74, "vol": 74, "509": 74, "pp": [74, 121], "257": 74, "289": 74, "collect": [74, 159, 174], "turn": [74, 139, 178], "come": 74, "term": 74, "fly": 74, "demand": 74, "abil": [74, 104], "within": [74, 97, 103, 104, 119, 125], "resort": 74, "alwai": [74, 107], "solut": 74, "articl": [74, 108], "rest": [74, 87], "merit": 74, "ten": 74, "experiment": 74, "carri": 74, "twenti": 74, "setcontextchar": [74, 119], "setminngram": 74, "setnkeyword": 74, "acquir": 74, "kaggl": 74, "platform": [74, 159, 176], "host": 74, "transact": 74, "somewhat": 74, "vagu": 74, "cloud": 74, "confer": 74, "week": [74, 79, 81, 115], "announc": [74, 90], "earli": 74, "tomorrow": [74, 79, 81], "phone": 74, "founder": 74, "ceo": 74, "anthoni": 74, "goldbloom": 74, "declin": 74, "deni": 74, "acquisit": 74, "happen": 74, "rumor": 74, "million": [74, 90, 104], "scientist": 74, "ben": 74, "hamner": 74, "2010": 74, "servic": [74, 106], "got": 74, "even": [74, 107], "few": [74, 119, 168, 184], "competitor": 74, "drivendata": 74, "topcod": 74, "hackerrank": 74, "stai": 74, "ahead": 74, "nich": 74, "home": [74, 152], "bui": [74, 166], "commun": 74, "mindshar": 74, "too": [74, 102, 177], "plenti": 74, "bit": [74, 100, 183], "histori": [74, 100, 108], "earlier": 74, "month": [74, 79, 81, 168, 184], "team": [74, 106, 159, 174], "around": 74, "youtub": 74, "That": [74, 117, 159, 174, 179], "had": 74, "technologi": 74, "did": 74, "interest": 74, "kernel": 74, "On": [74, 104, 106], "analyz": [74, 103], "compani": [74, 106], "script": 74, "centric": 74, "job": [74, 125], "board": [74, 97, 168], "unclear": 74, "accord": [74, 108, 165], "crunchbas": 74, "pitchbook": 74, "launch": 74, "investor": 74, "ventur": 74, "sv": 74, "angel": 74, "levchin": 74, "naravik": 74, "chie": 74, "economist": 74, "hal": 74, "varian": 74, "khosla": 74, "yuri": 74, "milner": 74, "resulttupl": 74, "ascend": 74, "orderbi": 74, "32051516486864573": 74, "37786450577630676": 74, "39922830978423146": 74, "40224744669493756": 74, "41584827825302534": 74, "setmaxngram": 74, "setstopword": [74, 90, 113], "getstopword": 74, "loaddefaultstopword": [74, 113], "danish": [74, 113], "dutch": [74, 113], "finnish": [74, 113], "german": [74, 113, 165, 184], "hungarian": [74, 113], "italian": [74, 108, 113], "norwegian": [74, 113], "portugues": [74, 113], "russian": [74, 113], "spanish": [74, 113], "swedish": [74, 113], "turkish": [74, 113], "languagedetectordl": 76, "ld": 76, "identif": 76, "rnn": 76, "tatoeba": 76, "140": 76, "wiki": 76, "languagedetector": 76, "ld_wiki_tatoeba_cnn_21": 76, "open": [76, 119, 125, 126, 127, 135, 139, 175], "advanc": [76, 125, 139], "scala": [76, 140, 141, 148, 154, 158], "program": 76, "biblioth\u00e8qu": 76, "traitement": 76, "pour": 76, "le": [76, 106], "avanc\u00e9": 76, "langag": 76, "naturel": 76, "programm": 76, "ist": 76, "ein": 76, "textverarbeitungsbibliothek": 76, "f\u00fcr": 76, "fortgeschritten": 76, "nat\u00fcrlich": 76, "sprachverarbeitung": 76, "die": 76, "programmiersprachen": 76, "und": 76, "lemma": [77, 102, 134, 162, 166, 179, 182, 183], "predefin": [77, 78, 82, 83, 102], "setdictionari": [77, 102, 110, 111], "lemmatizermodel": 77, "lemmas_smal": [77, 102], "setformcol": 77, "correspend": 77, "formcol": [77, 166], "setlemmacol": 77, "fromlemma": 77, "key_delimit": 77, "value_delimit": 77, "lemma_antbnc": 77, "bigtextmatch": [78, 83], "textmatch": [78, 83, 115], "externalresourc": [78, 83, 150], "mergeoverlap": [78, 83], "tokenizermodel": [78, 119], "trie": 78, "dolor": [78, 83], "magna": [78, 83], "aliqua": [78, 83], "sit": [78, 83], "laborum": [78, 83], "hello": [78, 83, 115], "entityextractor": [78, 83, 115], "extractor": [78, 83, 115], "59": [78, 79, 81, 83], "setent": [78, 83, 86, 115], "setmergeoverlap": [78, 83], "settoken": 78, "tokenizer_model": 78, "bigtextmatchermodel": 78, "btm": 78, "textmatchermodel": [78, 83], "searchtri": 78, "datematch": [79, 124], "datematcherutil": 79, "setinputformat": [79, 137], "setoutputformat": [79, 81], "desir": [79, 81], "yyyi": [79, 81], "mm": [79, 81, 121], "dd": [79, 81, 82], "Not": [79, 89, 136], "setreadmonthfirst": 79, "juli": 79, "5th": 79, "2015": 79, "07": 79, "05": 79, "setdefaultdaywhenmiss": 79, "dai": [79, 81, 108], "miss": [79, 81, 125], "setanchordateyear": [79, 81], "anchor": [79, 81], "year": [79, 81, 104, 115, 168], "2021": [79, 81, 124], "setanchordatemonth": [79, 81], "januari": [79, 81], "setanchordatedai": [79, 81], "multidatematch": [79, 81, 124], "1978": [79, 81], "01": [79, 81, 82, 124], "28": [79, 81, 87, 134, 151, 162, 177], "1984": [79, 81], "04": [79, 81], "02": [79, 81], "1980": [79, 81], "79": [79, 81], "31st": [79, 81], "april": [79, 81], "2008": [79, 81], "fri": [79, 81], "nov": [79, 81, 124, 168], "1997": [79, 81], "jan": [79, 81], "sun": [79, 81], "1st": [79, 81], "thursdai": [79, 81], "wednesdai": [79, 81], "todai": [79, 81], "yesterdai": [79, 81], "0600h": [79, 81], "06": [79, 81], "00": [79, 81], "hour": [79, 81], "6pm": [79, 81], "23": [79, 81, 82, 90, 97, 168, 169, 184], "1988": [79, 81], "31": [79, 81, 82, 90, 97, 168], "dateformat": [79, 81], "readmonthfirst": [79, 81], "defaultdaywhenmiss": [79, 81], "anchordateyear": [79, 81], "anchordatemonth": [79, 81], "anchordatedai": [79, 81], "15": 79, "saw": 81, "him": 81, "me": 81, "visit": 81, "57": [81, 90], "65": [81, 90], "regexmatch": 82, "d": [82, 92, 119, 176], "1970": 82, "setrul": 82, "setexternalrul": 82, "match_first": 82, "match_al": 82, "match_complet": 82, "externalrul": 82, "ceremoni": 82, "setstrategi": 82, "71": 82, "short_dat": 82, "regexmatchermodel": 82, "regardless": 83, "entityvalu": 83, "buildfromtoken": 83, "27": [83, 97, 99, 168], "48": [83, 121], "setentityvalu": 83, "setbuildfromtoken": 83, "null": 84, "empti": [84, 125], "enablecumul": 84, "actual": [84, 123, 128, 139], "join": [84, 97, 137, 168], "setenablecumul": 84, "nerapproach": 86, "recogn": [86, 87, 88, 89, 90, 91], "setminepoch": [86, 88], "setrandomse": [86, 89, 93], "getlabelcolumn": [86, 114], "friendli": [87, 106], "whitelist": [87, 117], "setwhitelist": [87, 117], "outsid": 87, "prefix": [87, 117, 119, 159, 174], "preserveposit": [87, 118, 139], "org": [87, 88, 89, 90, 121, 134, 151, 152, 162, 165, 175, 184], "14": [87, 97, 134, 138, 151, 162, 168], "ekeu": [87, 88, 89, 134, 151, 162], "26": [87, 124, 134, 151, 162], "36": [87, 97, 134, 151, 162, 168], "baghdad": [87, 88, 89, 134, 151, 162], "37": [87, 134, 151, 162], "setpreserveposit": [87, 118, 139], "nercrf": 88, "nercrfapproach": [88, 89], "nercrfmodel": [88, 89], "crf": [88, 89], "2003": [88, 89, 121, 165, 184], "exclud": [88, 89], "setexternalfeatur": 88, "minepoch": [88, 89], "l2": 88, "c0": 88, "decai": [88, 89], "gradient": 88, "2250000": 88, "lossep": 88, "ep": 88, "minw": 88, "includeconfid": [88, 89], "confid": [88, 89, 91], "externalfeatur": 88, "nerdlapproach": [88, 89, 165, 184], "trainingdata": [88, 89, 100, 110, 111, 165], "readdataset": [88, 89, 97, 121, 165, 166, 168, 169, 184], "conll2003": [88, 89, 165, 184], "eng": [88, 89, 165, 184], "setl2": 88, "l2valu": 88, "setc0": 88, "c0valu": 88, "setlossep": 88, "setminw": 88, "setincludeconfid": [88, 89], "verbosevalu": 88, "prerequisit": [88, 89, 90, 178], "nerdl": 89, "char": [89, 92, 100], "bilstm": 89, "tagger": [89, 168, 184], "50": [89, 90, 97, 104], "real": [89, 152, 159, 174], "rage": 89, "graphfold": 89, "usecontrib": 89, "contrib": 89, "cell": [89, 137], "slightli": [89, 100], "includeallconfidencescor": 89, "enablememoryoptim": 89, "slow": 89, "down": [89, 178, 179], "usebestmodel": 89, "bestmodelmetr": 89, "check": [89, 99, 108, 109, 110, 111, 134, 139, 162, 178, 183], "micro": 89, "macro": 89, "setgraphfold": [89, 114], "setusecontrib": 89, "setpo": 89, "setincludeallconfidencescor": 89, "setenablememoryoptim": 89, "setusebestmodel": 89, "setbestmodelmetr": 89, "nermodel": 89, "neroverwrit": 90, "specifi": [90, 91, 100, 165, 166], "setnewresult": 90, "nerword": 90, "overwritten": 90, "newnerent": 90, "lab": 90, "42": [90, 97], "45": [90, 97, 168], "47": [90, 168], "66": 90, "ner_overwritten": 90, "setnerword": 90, "setnewnerent": 90, "cardin": 90, "setreplaceent": 90, "rw": 90, "zeroshotnermodel": 91, "shot": [91, 104], "zeroshotn": 91, "zer_shot_n": 91, "entitydefinit": 91, "citi": 91, "town": 91, "predictionthreshold": 91, "01f": 91, "ignoreent": 91, "zero_shot_n": 91, "setentitydefinit": 91, "york": [91, 123, 128], "hellen": 91, "5328949": 91, "9360068": 91, "83294415": 91, "45366877": 91, "setpredictionthreshold": 91, "zero_shot_ner_roberta": 91, "shortcut": 91, "stem": [92, 112, 134, 162, 182, 183], "henc": 92, "pl": 92, "slangdictionari": 92, "slang": 92, "minlength": [92, 99, 100, 118, 119], "maxlength": [92, 99, 100, 118, 119], "setcleanuppattern": 92, "punctuat": [92, 99], "alphanumer": 92, "letter": [92, 104, 108, 168, 184], "za": 92, "z": [92, 119], "brother": 92, "dont": [92, 103], "setslangdictionari": 92, "setminlength": [92, 99, 100, 118, 119], "setmaxlength": [92, 99, 100, 118, 119], "normalizermodel": 92, "classifierencod": 93, "attach": [93, 94, 142, 146, 157, 159], "evaluationdlparam": 94, "setevaluationlogextend": 94, "setenableoutputlog": [94, 159, 174], "setoutputlogspath": [94, 100, 159, 174], "assum": 94, "perceptronapproach": [97, 168, 184], "member": [97, 162], "datasetpath": 97, "pierr": [97, 168], "vinken": [97, 168], "34": [97, 168], "md": [97, 168], "vb": [97, 165, 168, 184], "41": [97, 99, 168], "43": [97, 99, 168], "dt": [97, 168, 169, 184], "49": [97, 168], "poscol": [97, 121, 165], "niter": [97, 121], "anc": [97, 168, 184], "trainingperceptrondf": 97, "trainedpo": 97, "setposcolumn": [97, 121], "cd": [97, 165, 168], "setiter": 97, "getniter": [97, 121], "pos_anc": 97, "25": [97, 99, 168], "33": 97, "sentencedetectorparam": 99, "ii": 99, "abbrevi": 99, "period": 99, "geo": 99, "1026": 99, "253": 99, "553": 99, "ellipsi": 99, "quotat": 99, "mark": [99, 100, 121], "exclam": 99, "breaker": 99, "pragmaticcontentformatt": 99, "custombound": [99, 100], "setcustombound": [99, 100], "usecustomboundsonli": [99, 100], "explodesent": [99, 100, 165, 166], "useabbrevi": 99, "explicitli": [99, 100, 113, 151, 178], "customboundsstrategi": 99, "prepend": [99, 125], "break": 99, "append": [99, 108, 178], "parallel": [99, 100, 134, 165, 182], "splitlength": [99, 100], "forcibli": [99, 100], "99999": [99, 100, 119], "detectlist": 99, "nhow": 99, "setcustomboundsstrategi": 99, "setuseabbrevi": 99, "setdetectlist": 99, "setusecustomboundsonli": [99, 100], "setexplodesent": [99, 100], "setsplitlength": [99, 100], "sentencedetectordl": 100, "sentencedetectordlapproach": 100, "futur": [100, 107], "setmodel": 100, "sentencedetectordlmodel": [100, 106], "modelarchitectur": 100, "impossiblepenultim": 100, "imposs": [100, 121], "penultim": 100, "epochsnumb": 100, "eo": 100, "stefan": 100, "schweter": 100, "sajawel": 100, "ahm": 100, "littl": [100, 183], "cover": [100, 107, 121], "broken": 100, "moder": 100, "lack": 100, "easier": [100, 128, 180, 184], "polit": 100, "successor": 100, "great": 100, "respons": 100, "heritag": 100, "bequeath": 100, "nelson": 100, "mandela": 100, "setepochsnumb": 100, "model_architectur": 100, "validation_split": 100, "epochs_numb": 100, "output_logs_path": 100, "setimpossiblepenultim": 100, "impossible_penultim": 100, "sentencedl": 100, "sentencesdl": 100, "helen": 100, "total": [100, 121], "peopl": 100, "sentimentdetector": 102, "By": [102, 107, 113, 118, 127, 152, 159, 174], "els": 102, "viveknsentimentapproach": [102, 103], "cool": 102, "superb": 102, "uninspir": 102, "sentimentscor": 102, "staff": 102, "restaur": 102, "nice": [102, 159, 174], "avoid": 102, "entri": [102, 126, 135, 163], "sttr": 102, "sentimentdetectormodel": 102, "sda": [102, 103], "pragmat": 102, "viveknsenti": 103, "analys": 103, "inspir": [103, 110, 111, 155], "vivek": 103, "narayanan": 103, "give": 103, "transit": [103, 108], "sentimentcol": 103, "prunecorpu": 103, "unfrequ": 103, "scenario": 103, "scope": 103, "naiv": 103, "bay": 103, "vivekn": 103, "setsentimentcol": 103, "train_senti": 103, "result_senti": 103, "finish": [103, 127, 129, 133, 136, 152], "final_senti": 103, "cast": [103, 122], "horribl": 103, "never": [103, 178], "go": [103, 178], "again": [103, 117], "anyon": 103, "protagonist": 103, "music": 103, "setprunecorpu": 103, "frequenc": [103, 108, 110, 111, 121], "viveknsentimentmodel": 103, "sentiment_vivekn": 103, "gpt2transform": 104, "gpt2": 104, "openai": 104, "caus": [104, 119], "goal": [104, 121], "occur": [104, 107], "direct": 104, "10x": 104, "synthet": 104, "sampl": [104, 107], "unpreced": 104, "prime": 104, "lengthi": 104, "translat": [104, 106, 107, 121], "far": [104, 123, 128], "suggest": 104, "benefit": 104, "suffici": 104, "minoutputlength": [104, 107], "maxoutputlength": [104, 106, 107], "dosampl": [104, 107], "greedi": [104, 107], "temperatur": [104, 107], "topk": [104, 107], "highest": [104, 107, 110], "topp": [104, 107], "cumul": [104, 107], "kept": [104, 107], "repetitionpenalti": [104, 107], "repetit": [104, 107], "penalti": [104, 107], "norepeatngrams": [104, 107], "onc": [104, 107], "ignoretokenid": [104, 107], "especi": [104, 106, 107], "multitask": 104, "learner": 104, "typic": 104, "taskspecif": 104, "webpag": [104, 175], "webtext": 104, "plu": 104, "coqa": 104, "exceed": 104, "127": 104, "fashion": 104, "5b": 104, "still": [104, 159], "underfit": 104, "reflect": 104, "paragraph": 104, "promis": 104, "toward": 104, "setmaxoutputlength": [104, 106, 107], "leonardo": 104, "summari": [104, 107], "man": 104, "1776": 104, "came": 104, "kingdom": 104, "settask": [104, 107], "setignoretokenid": [104, 106, 107], "setminoutputlength": [104, 107], "setdosampl": [104, 107], "settemperatur": [104, 107], "settopk": [104, 107], "settopp": [104, 107], "setrepetitionpenalti": [104, 107], "ctrl": [104, 107], "control": [104, 106, 107, 108], "setnorepeatngrams": [104, 107], "mariantransform": 106, "marian": 106, "free": 106, "mainli": 106, "academ": 106, "notabl": 106, "edinburgh": 106, "past": 106, "adam": 106, "mickiewicz": 106, "pozna\u0144": 106, "commerci": 106, "contributor": 106, "mariannmt": 106, "engin": [106, 115], "behind": 106, "deploi": [106, 175], "opus_mt_en_fr": 106, "langid": 106, "maxinputlength": 106, "differenti": 106, "dynam": 106, "toolkit": 106, "setmaxinputlength": 106, "capit": [106, 108], "franc": 106, "quell": 106, "capital": 106, "devrait": 106, "savoir": 106, "fran\u00e7ai": 106, "setlangid": 106, "t5transform": 107, "t5": 107, "reconsid": 107, "unifi": 107, "hyper": 107, "t5_small": 107, "explor": 107, "rich": 107, "rise": 107, "methodologi": 107, "landscap": 107, "systemat": 107, "dozen": 107, "insight": 107, "coloss": 107, "facilit": 107, "200": 107, "contextspellcheck": 108, "contextspellcheckerapproach": [108, 110, 111], "noisi": 108, "spell": [108, 109, 110, 111, 134, 139, 181, 182, 183], "candid": [108, 110, 111, 119], "contextspellcheckermodel": [108, 110, 111], "error": 108, "thing": [108, 123, 128], "surround": [108, 137], "edit": [108, 110, 111], "subword": 108, "checker": [108, 110, 111, 181], "languagemodelclass": 108, "lm": 108, "wordmaxdist": 108, "maxcandid": 108, "casestrategi": 108, "try": [108, 123, 165], "uppercas": 108, "errorthreshold": 108, "perplex": 108, "nlm": 108, "initialr": 108, "finalr": 108, "validationfract": 108, "datapoint": 108, "min": 108, "vocab": 108, "compoundcount": 108, "compound": 108, "classcount": 108, "special": [108, 121, 153, 179], "tradeoff": 108, "weighteddistpath": 108, "levenshtein": [108, 110, 111], "maxwindowlen": 108, "rememb": 108, "norvigsweetingapproach": [108, 110, 111, 184], "symmetricdeleteapproach": [108, 110, 111, 184], "depth": [108, 181], "explan": [108, 181], "awar": 108, "sherlock": 108, "holm": 108, "spellcheck": [108, 110, 111], "setwordmaxdist": 108, "setepoch": 108, "setlanguagemodelclass": 108, "1650": 108, "addvocabclass": 108, "_name_": 108, "extra": [108, 110, 178], "dist": 108, "setmaxcandid": 108, "setcasestrategi": 108, "seterrorthreshold": 108, "setinitialr": 108, "setfinalr": 108, "setvalidationfract": 108, "fraction": 108, "setcompoundcount": 108, "setclasscount": 108, "settradeoff": 108, "alpha": 108, "setweighteddistpath": 108, "setmaxwindowlen": 108, "userdist": 108, "addregexclass": 108, "spellcheck_dl": 108, "gamma": 108, "influenc": 108, "decis": 108, "correctsymbol": 108, "comparelowcas": 108, "norvigsweetingmodel": [108, 110, 111], "symmetricdeletemodel": [108, 110, 111], "doc": [108, 169, 184], "cold": 108, "dreari": 108, "countri": 108, "white": 108, "smow": 108, "setweight": 108, "setgamma": 108, "getwordclass": 108, "updateregexclass": 108, "updat": 108, "updatevocabclass": 108, "setcorrectsymbol": 108, "setcomparelowcas": 108, "norvigsweet": 110, "norvig": 110, "bayesian": 110, "tokenpattern": 110, "sensit": [110, 113, 119], "doublevari": 110, "search": 110, "shortcircuit": 110, "frequencyprior": 110, "ham": 110, "intersect": 110, "prioriti": [110, 119], "wordsizeignor": 110, "dupslimit": 110, "duplic": 110, "reductlimit": 110, "attempt": 110, "vowelswaplimit": 110, "vowel": 110, "swap": 110, "corrector": 110, "gummi": [110, 111], "gummic": [110, 111], "gummier": [110, 111], "gummiest": [110, 111], "gummifer": [110, 111], "basi": [110, 111], "token_pattern": [110, 111], "setdoublevari": 110, "setshortcircuit": 110, "setfrequencyprior": 110, "symmetr": [110, 111], "delet": [110, 111, 178], "damerau": [110, 111], "magnitud": [110, 111], "transpos": [110, 111], "insert": [110, 111, 178], "spellcheck_norvig": 110, "symspel": [110, 111], "somtim": 110, "wrrite": [110, 111], "wordz": [110, 111], "erong": [110, 111], "sometim": [110, 111, 178], "wrong": [110, 111], "symmetricdelet": 111, "deriv": 111, "teach": 111, "maxeditdist": 111, "frequencythreshold": [111, 121], "deletesthreshold": 111, "patttern": 111, "setmaxeditdist": 111, "setfrequencythreshold": [111, 121], "setdeletesthreshold": 111, "spellcheck_sd": 111, "spmetim": 111, "hard": 112, "employ": 112, "stopwordsclean": [113, 127, 139], "mllib": [113, 175], "stopwordsremov": 113, "cleantoken": [113, 127, 139], "stopwords_en": 113, "jvm": 113, "forth": 113, "setlocal": 113, "tfnerdlgraphbuildermodel": 114, "tfnerdlgraphbuild": 114, "sethiddenunitsnumb": 114, "assertiondlapproach": 114, "medicalnerapproach": 114, "gethiddenunitsnumb": 114, "getinputcol": [114, 127, 128, 142], "srt": 114, "getgraphfold": 114, "setgraphfil": 114, "greaph": 114, "auto": 114, "getgraphfil": 114, "chunktoken": 115, "flatten": 115, "artist": 115, "benezar": 115, "robert": 115, "farendel": 115, "graduat": 115, "luca": 115, "chunktokenizermodel": 115, "recursivetoken": 117, "recurs": [117, 136, 148, 152, 156], "hand": 117, "suffix": [117, 119, 178], "infix": [117, 119], "middl": [117, 121], "she": 117, "qam": 117, "setprefix": 117, "setsuffix": 117, "setinfix": 117, "recursivetokenizermodel": 117, "regextoken": [118, 121, 179], "whitespac": [118, 121, 125], "tolowercas": [118, 121], "positionalmask": 118, "guarante": 118, "increment": 118, "trimwhitespac": 118, "flag": 118, "eventu": 118, "settolowercas": [118, 121], "nthi": 118, "setpositionalmask": 118, "settrimwhitespac": 118, "tokenizedsent": 119, "rulefactori": 119, "targetpattern": 119, "grab": 119, "prefixpattern": 119, "suffixpattern": 119, "infixpattern": 119, "sub": 119, "won": 119, "exceptionspath": 119, "casesensitiveexcept": 119, "contextchar": 119, "splitpattern": 119, "splitchar": 119, "didn": 119, "jane": 119, "boyfriend": 119, "getinfixpattern": 119, "getsuffixpattern": 119, "getprefixpattern": 119, "getcontextchar": 119, "getsplitchar": 119, "settargetpattern": 119, "setprefixpattern": 119, "setsuffixpattern": 119, "setinfixpattern": 119, "addinfixpattern": 119, "setexcept": 119, "getexcept": 119, "setexceptionspath": 119, "addexcept": 119, "setcasesensitiveexcept": 119, "getcasesensitiveexcept": 119, "addcontextchar": 119, "setsplitpattern": 119, "setsplitchar": 119, "addsplitchar": 119, "piec": 119, "token_rul": 119, "wordsegment": 121, "wordsegmenterapproach": 121, "korean": 121, "japanes": 121, "chines": 121, "correspond": [121, 159], "ll": 121, "rr": 121, "likewis": 121, "side": 121, "themselv": 121, "\u4e0a\u6d77": 121, "\u8ba1\u5212": 121, "\u5230": 121, "\u672c": 121, "\u4e16\u7eaa": 121, "\u672b": 121, "\u5b9e\u73b0": 121, "\u4eba\u5747": 121, "\u56fd\u5185": 121, "\u751f\u4ea7": 121, "\u603b\u503c": 121, "\u4e94\u5343": 121, "\u7f8e\u5143": 121, "\u4e0a": 121, "\u6d77": 121, "\u8ba1": 121, "\u5212": 121, "\u4e16": 121, "\u7eaa": 121, "\u5b9e": 121, "\u73b0": 121, "\u4eba": 121, "\u5747": 121, "\u56fd": 121, "\u5185": 121, "\u751f": 121, "\u4ea7": 121, "\u603b": 121, "ll\u503c": 121, "\u4e94": 121, "\u5343": 121, "\u7f8e": 121, "\u5143": 121, "shanghai": 121, "plan": 121, "dollar": 121, "capita": 121, "gdp": 121, "wordsegmentermodel": 121, "tip": 121, "frame": 121, "least": 121, "frequent": 121, "ambiguitythreshold": 121, "enableregextoken": 121, "xue": 121, "nianwen": 121, "volum": 121, "februari": 121, "aclweb": 121, "aclanthologi": 121, "o03": 121, "4002": 121, "chinese_train": 121, "utf8": 121, "\u5341": 121, "\u56db": 121, "\u4e0d": 121, "\u662f": 121, "setniter": 121, "trainingdataset": 121, "setambiguitythreshold": 121, "getfrequencythreshold": 121, "getambiguitythreshold": 121, "setenableregextoken": 121, "plit": 121, "words_seg": 121, "wordseg_pku": 121, "zh": 121, "\u7136\u800c": 121, "\u9019\u6a23\u7684\u8655\u7406\u4e5f\u884d\u751f\u4e86\u4e00\u4e9b\u554f\u984c": 121, "\u9019\u6a23": 121, "\u7684": 121, "\u8655\u7406": 121, "\u4e5f": 121, "\u884d\u751f": 121, "\u4e86": 121, "\u4e00\u4e9b": 121, "\u554f\u984c": 121, "prepar": [122, 126, 132, 135], "outputcol": [122, 126, 127, 128, 129, 132, 135], "inferschema": 122, "tmp": [122, 132, 152, 174], "librispeech_asr_dummy_clean_audio_array_parquet": 122, "float_arrai": 122, "getoutputcol": [122, 126, 127, 128, 132, 135, 142], "chunk2doc": [123, 125], "back": 123, "re": [123, 178], "doc2chunk": [123, 125], "pretrainedpipelin": [123, 128, 134, 151, 162, 177, 182, 183], "jersei": [123, 128], "aren": [123, 128], "amongst": [123, 128], "explain_document_dl": [123, 128, 134, 151, 162], "chunktodoc": 123, "chunkconvert": 123, "explainresult": [123, 128], "22": [123, 128, 165, 177], "date2chunk": 124, "date_chunk": 124, "omicron": 124, "covid": 124, "health": 124, "118": [124, 137], "121": 124, "chunkcol": 125, "stringtyp": 125, "setisarrai": 125, "startcol": 125, "startcolbytokenindex": 125, "isarrai": 125, "failonmiss": 125, "fail": 125, "chunkassembl": 125, "setchunkcol": 125, "setstartcol": 125, "setstartcolbytokenindex": 125, "setfailonmiss": 125, "disabl": [126, 135], "idcol": [126, 135], "metadatacol": [126, 135], "cleanupmod": [126, 135], "cleanup": [126, 135], "inplac": [126, 135], "inplace_ful": [126, 135], "shrink_ful": [126, 135], "each_ful": [126, 135], "delete_ful": [126, 135], "setidcol": [126, 135], "setmetadatacol": [126, 135], "usabl": 127, "lda": 127, "forest": 127, "featurecol": 127, "cleanannot": [127, 128, 129], "outputasvector": 127, "gloveembed": 127, "finished_sentence_embed": 127, "resultwiths": 127, "1619900017976761": 127, "045552998781204224": 127, "03229299932718277": 127, "685609996318": 127, "42416998744010925": 127, "1378999948501587": 127, "5717899799346924": 127, "5078899860382": 127, "08621499687433243": 127, "15772999823093414": 127, "06067200005054474": 127, "395359992980": 127, "4970499873161316": 127, "7164199948310852": 127, "40119001269340515": 127, "05761000141501": 127, "08170200139284134": 127, "7159299850463867": 127, "20677000284194946": 127, "0295659992843": 127, "valuesplitsymbol": 128, "annotationsplitsymbol": 128, "includemetadata": 128, "outputasarrai": [128, 129], "parseembeddingsvector": 128, "setvaluesplitsymbol": 128, "setannotationsplitsymbol": 128, "setincludemetadata": [128, 179], "setoutputasarrai": [128, 129], "setparseembeddingsvector": 128, "finishedresult": 129, "hasrecursivefit": [130, 131], "java_obj": [130, 155, 158], "py4j": [130, 131, 158], "java_gatewai": [130, 131, 158], "javaobject": [130, 131, 158], "recursivepipelin": [130, 131, 136, 142], "hasrecursivetransform": 131, "chunk2_doc": [133, 152], "date2_chunk": [133, 152], "doc2_chunk": [133, 152], "embeddings_finish": [133, 152], "graph_finish": [133, 152], "has_recursive_fit": [133, 152], "has_recursive_transform": [133, 152], "light_pipelin": [133, 152], "recursive_pipelin": [133, 152], "token2_chunk": [133, 152], "token_assembl": [133, 152], "lightpipelin": [134, 162, 182], "parse_embed": [134, 162], "equival": [134, 152, 182], "execut": [134, 178, 182], "hold": [134, 182], "principl": [134, 182], "everyth": [134, 182, 183], "fullannot": [134, 162], "happi": [134, 177, 179, 182, 183], "prp": [134, 166, 168, 177, 182, 183, 184], "rb": [134, 168, 177, 182, 183, 184], "optional_target": [134, 162], "explain_document_pipelin": [134, 151, 162, 177, 182, 183], "dict_kei": [134, 162], "fullannotateimag": [134, 162], "path_to_imag": [134, 162], "setignoreunsupport": 134, "unsupport": 134, "annotatormodel": [134, 141, 163], "getignoreunsupport": 134, "calculationscol": 135, "text2": 135, "document1": 135, "document2": 135, "arg": [136, 155], "kwarg": 136, "decid": 136, "advantag": 136, "behav": 136, "exactli": 136, "intent": 136, "recursivepipelinemodel": 136, "pipeline_model": [136, 159, 174], "intend": 136, "tab": [137, 159, 174], "escap": 137, "quot": 137, "inputformat": 137, "csvdelimit": 137, "defailt": 137, "comma": 137, "escapecsvdelimit": 137, "table_csv": 137, "csv_data": 137, "input_format": 137, "setcsvdelimit": 137, "setescapecsvdelimit": 137, "token2chunk": 138, "17": [138, 168], "tokenassembl": 139, "reconstruct": 139, "cleantext": 139, "opensourc": 139, "annotatorapproach": [140, 148, 159], "py": [140, 141, 148, 154, 158], "subclass": [141, 154, 158], "inherit": [141, 158], "ins": [141, 158], "uid": [141, 158], "annotatorproperti": 142, "setlazyannot": 142, "lazili": 142, "getlazyannot": 142, "annotator_approach": [145, 152], "annotator_model": [145, 152], "annotator_properti": [145, 152], "coverage_result": [145, 152], "recursive_annotator_approach": [145, 152], "hasembeddingsproperti": 146, "getdimens": 146, "constant": 147, "recursiveannotatorapproach": 148, "handl": [149, 167], "fo": 150, "assist": 151, "map_annot": 151, "f": [151, 159, 174], "output_typ": 151, "udf": 151, "userdefinedfunct": 151, "def": 151, "nnp_token": 151, "lambda": 151, "alia": 151, "epeu": 151, "map_annotations_arrai": 151, "map_annotations_strict": 151, "map_annotations_col": 151, "output_column": 151, "annotatyon_typ": 151, "chunks_df": 151, "pos_chunk": 151, "vbz": [151, 165, 184], "filter_by_annotations_col": 151, "filter_po": 151, "explode_annotations_col": 151, "annotator_java_ml": [152, 156], "annotator_transform": [152, 156], "extended_java_wrapp": [152, 156], "params_getters_sett": [152, 156], "comet": [152, 160, 176], "pretrained_pipelin": [152, 161], "resource_download": [152, 161], "pub_tat": [152, 167], "annotation_audio": 152, "annotation_imag": 152, "apple_silicon": 152, "aarch64": 152, "cache_fold": 152, "log_fold": 152, "cluster_tmp_dir": 152, "real_time_output": 152, "output_level": 152, "correctli": 152, "maco": 152, "linux": 152, "alloc": 152, "directori": [152, 163, 174], "cache_pretrain": 152, "temporarili": 152, "unpack": 152, "hadoop": 152, "dir": 152, "s3": 152, "hdf": 152, "dbf": 152, "annotator_log": 152, "annotatorjavamlread": 153, "mixin": 153, "javamlread": 153, "classmethod": 153, "mlreader": 153, "clazz": 153, "rl": 153, "javaparam": 153, "annotatortransform": 154, "ensur": 154, "_java_obj": 154, "extens": 155, "javawrapp": 155, "extendedjavawrapp": 155, "new_java_arrai": 155, "pylist": 155, "java_class": 155, "todo": 155, "chang": 155, "paramsgetterssett": 157, "getparamvalu": 157, "paramnam": 157, "setparamvalu": 157, "recursiveestim": 158, "tupl": 158, "overrid": 158, "recursivetransform": 158, "cometlogg": [159, 174], "workspac": 159, "project_nam": [159, 174], "comet_mod": [159, 174], "experiment_id": 159, "experiment_kwarg": 159, "logger": [159, 174], "meta": [159, 176], "practition": [159, 174], "reliabl": [159, 174], "streamlin": [159, 174], "lifecycl": [159, 174, 176], "track": [159, 174, 175], "explain": [159, 174, 181, 183], "reproduc": [159, 174, 175], "outputlogpath": [159, 174], "onlin": [159, 174], "reus": 159, "importerror": 159, "output_log_path": [159, 174], "embd": [159, 174], "setshuffleperepoch": [159, 174], "logdir": [159, 174], "interfac": [159, 174, 182], "chart": [159, 174], "attribut": 159, "comet_ml": [159, 174], "log_pipeline_paramet": [159, 174], "log_visu": [159, 174], "html": [159, 174], "viz": [159, 174], "upload": 159, "colum": [159, 174], "ner_chunk": [159, 174], "sparknlp_displai": [159, 174], "nervisu": [159, 174], "idx": [159, 174], "enumer": [159, 174], "label_col": [159, 174], "document_col": [159, 174], "return_html": [159, 174], "log_metr": [159, 174], "sklearn": [159, 174], "preprocess": [159, 174], "multilabelbinar": [159, 174], "classification_report": [159, 174], "preds_df": [159, 174], "topanda": [159, 174], "mlb": [159, 174], "y_true": [159, 174], "fit_transform": [159, 174], "y_pred": [159, 174], "output_dict": [159, 174], "log_paramet": 159, "log_completed_run": 159, "log_file_path": 159, "complet": [159, 175, 178], "log_asset": 159, "asset_path": 159, "asset": 159, "log_asset_data": 159, "interv": 159, "refresh": 159, "outstand": 159, "disk_loc": 162, "fulli": 162, "light_model": 162, "gather": 162, "langaug": 162, "resourcedownload": [163, 178, 183], "showpublicmodel": [163, 178], "onto_100": 163, "onto_300": 163, "ner_dl_bert": 163, "similarli": 163, "showpublicpipelin": [163, 183], "check_spel": [163, 183], "match_datetim": [163, 183], "downloadmodel": 163, "reader": 163, "j_dwn": 163, "pythonresourcedownload": 163, "downloadmodeldirectli": 163, "downloadpipelin": 163, "clearcach": 163, "clear": 163, "argument": 163, "filer": 163, "showuncategorizedresourc": 163, "yet": 163, "showavailableannot": 163, "documentcol": [165, 166], "sentencecol": [165, 166], "tokencol": 165, "conlllabelindex": 165, "conllposindex": 165, "conlldocidcol": 165, "doc_id": [165, 169], "textcol": [165, 166], "labelcol": 165, "includedocid": 165, "docstart": [165, 184], "eu": [165, 184], "np": [165, 184], "reject": [165, 184], "vp": [165, 184], "misc": [165, 184], "boycott": [165, 184], "british": [165, 184], "lamb": [165, 184], "blackburn": 165, "brussel": 165, "1996": 165, "08": 165, "storage_level": 165, "storagelevel": 165, "disk_onli": 165, "lift": 165, "persist": 165, "uposcol": 166, "upo": 166, "xposcol": 166, "xpo": 166, "lemmacol": 166, "sent_id": 166, "sell": 166, "pron": 166, "nom": 166, "plur": 166, "_": 166, "tens": 166, "conj": 166, "cc": 166, "obj": 166, "spaceaft": 166, "No": [166, 177], "punct": 166, "conllufil": [166, 184], "conlldataset": [166, 184], "morph": 166, "Into": 166, "googleo": 166, "sconj": 166, "propn": 166, "adp": 166, "wp": 166, "vbd": [166, 168, 184], "ago": [168, 184], "receiv": [168, 184], "posdf": 168, "61": 168, "56": 168, "67": [168, 169, 184], "nonexecut": 168, "69": 168, "76": 168, "director": 168, "78": 168, "81": 168, "84": 168, "outputposcol": 168, "outputdocumentcol": 168, "outputtextcol": 168, "pubtat": [169, 181], "medic": [169, 184], "titl": [169, 184], "medment": [169, 184], "25763772": [169, 184], "dctn4": [169, 184], "t116": [169, 184], "t123": [169, 184], "c4308010": [169, 184], "63": [169, 184], "chronic": [169, 184], "pseudomona": [169, 184], "aeruginosa": [169, 184], "infect": [169, 184], "t047": [169, 184], "c0854135": [169, 184], "82": [169, 184], "cystic": [169, 184], "fibrosi": [169, 184], "c0010674": [169, 184], "120": [169, 184], "pa": [169, 184], "124": [169, 184], "139": [169, 184], "pubtatorfil": 169, "corpus_pubtator_sampl": 169, "pubtatordataset": 169, "finished_token": [169, 179], "finished_po": 169, "finished_n": 169, "finished_token_metadata": 169, "finished_pos_metadata": 169, "finished_label_metadata": 169, "mo": 169, "ispaddedtoken": 169, "pad": 169, "overview": [173, 181], "workflow": 174, "dedic": 174, "account": 174, "inspect": 174, "init": 174, "sparknlp_experi": 174, "offline_directori": 174, "later": 174, "nativ": 175, "record": 175, "queri": 175, "registri": 175, "discov": 175, "central": 175, "send": 176, "messag": 176, "mlflow": 176, "content": [177, 183], "clearli": 177, "explain_document_ml": [177, 182, 183], "approx": [177, 182, 183], "mb": [177, 182, 183], "ok": [177, 182, 183], "spearhead": 178, "produc": 178, "declar": 178, "accordingli": 178, "extra_loc": 178, "offer": [178, 180, 183], "classifierdl_use_trec50": 178, "classifierdl_use_spam": 178, "column_nam": 178, "preced": 178, "interchang": 179, "anoth": 179, "road": 179, "proce": 179, "At": 179, "sens": 183, "constantli": 183, "server": 183, "sever": 184, "train_po": 184, "training_conl": 184, "train_corpu": 184, "withcolumnrenam": 184, "trainingpubtatordf": 184, "corpus_pubt": 184}, "objects": {"": [[152, 0, 0, "-", "sparknlp"]], "sparknlp": [[2, 0, 0, "-", "annotation"], [3, 0, 0, "-", "annotation_audio"], [4, 0, 0, "-", "annotation_image"], [72, 0, 0, "-", "annotator"], [133, 0, 0, "-", "base"], [145, 0, 0, "-", "common"], [151, 0, 0, "-", "functions"], [156, 0, 0, "-", "internal"], [160, 0, 0, "-", "logging"], [161, 0, 0, "-", "pretrained"], [152, 3, 1, "", "start"], [167, 0, 0, "-", "training"], [171, 0, 0, "-", "upload_to_hub"], [172, 0, 0, "-", "util"], [152, 3, 1, "", "version"]], "sparknlp.annotation": [[2, 1, 1, "", "Annotation"]], "sparknlp.annotation.Annotation": [[2, 2, 1, "", "arrayType"], [2, 2, 1, "", "copy"], [2, 2, 1, "", "dataType"], [2, 2, 1, "", "fromRow"], [2, 2, 1, "", "toRow"]], "sparknlp.annotation_audio": [[3, 1, 1, "", "AnnotationAudio"]], "sparknlp.annotation_audio.AnnotationAudio": [[3, 2, 1, "", "copy"]], "sparknlp.annotation_image": [[4, 1, 1, "", "AnnotationImage"]], "sparknlp.annotation_image.AnnotationImage": [[4, 2, 1, "", "copy"]], "sparknlp.annotator": [[6, 0, 0, "-", "audio"], [8, 0, 0, "-", "chunker"], [25, 0, 0, "-", "classifier_dl"], [40, 0, 0, "-", "coref"], [42, 0, 0, "-", "cv"], [46, 0, 0, "-", "dependency"], [48, 0, 0, "-", "document_normalizer"], [58, 0, 0, "-", "embeddings"], [70, 0, 0, "-", "er"], [71, 0, 0, "-", "graph_extraction"], [73, 0, 0, "-", "keyword_extraction"], [75, 0, 0, "-", "ld_dl"], [77, 0, 0, "-", "lemmatizer"], [80, 0, 0, "-", "matcher"], [84, 0, 0, "-", "n_gram_generator"], [85, 0, 0, "-", "ner"], [92, 0, 0, "-", "normalizer"], [95, 0, 0, "-", "param"], [96, 0, 0, "-", "pos"], [98, 0, 0, "-", "sentence"], [101, 0, 0, "-", "sentiment"], [105, 0, 0, "-", "seq2seq"], [109, 0, 0, "-", "spell_check"], [112, 0, 0, "-", "stemmer"], [113, 0, 0, "-", "stop_words_cleaner"], [114, 0, 0, "-", "tf_ner_dl_graph_builder"], [116, 0, 0, "-", "token"], [120, 0, 0, "-", "ws"]], "sparknlp.annotator.audio": [[5, 0, 0, "-", "hubert_for_ctc"], [7, 0, 0, "-", "wav2vec2_for_ctc"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, 1, 1, "", "HubertForCTC"]], "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC": [[5, 2, 1, "", "loadSavedModel"], [5, 2, 1, "", "pretrained"], [5, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, 1, 1, "", "Wav2Vec2ForCTC"]], "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC": [[7, 2, 1, "", "loadSavedModel"], [7, 2, 1, "", "pretrained"], [7, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.chunker": [[8, 1, 1, "", "Chunker"]], "sparknlp.annotator.chunker.Chunker": [[8, 2, 1, "", "setRegexParsers"]], "sparknlp.annotator.classifier_dl": [[9, 0, 0, "-", "albert_for_question_answering"], [10, 0, 0, "-", "albert_for_sequence_classification"], [11, 0, 0, "-", "albert_for_token_classification"], [12, 0, 0, "-", "bert_for_question_answering"], [13, 0, 0, "-", "bert_for_sequence_classification"], [14, 0, 0, "-", "bert_for_token_classification"], [15, 0, 0, "-", "camembert_for_question_answering"], [16, 0, 0, "-", "camembert_for_sequence_classification"], [17, 0, 0, "-", "camembert_for_token_classification"], [18, 0, 0, "-", "classifier_dl"], [19, 0, 0, "-", "deberta_for_question_answering"], [20, 0, 0, "-", "deberta_for_sequence_classification"], [21, 0, 0, "-", "deberta_for_token_classification"], [22, 0, 0, "-", "distil_bert_for_question_answering"], [23, 0, 0, "-", "distil_bert_for_sequence_classification"], [24, 0, 0, "-", "distil_bert_for_token_classification"], [26, 0, 0, "-", "longformer_for_question_answering"], [27, 0, 0, "-", "longformer_for_sequence_classification"], [28, 0, 0, "-", "longformer_for_token_classification"], [29, 0, 0, "-", "multi_classifier_dl"], [30, 0, 0, "-", "roberta_for_question_answering"], [31, 0, 0, "-", "roberta_for_sequence_classification"], [32, 0, 0, "-", "roberta_for_token_classification"], [33, 0, 0, "-", "sentiment_dl"], [34, 0, 0, "-", "tapas_for_question_answering"], [35, 0, 0, "-", "xlm_roberta_for_question_answering"], [36, 0, 0, "-", "xlm_roberta_for_sequence_classification"], [37, 0, 0, "-", "xlm_roberta_for_token_classification"], [38, 0, 0, "-", "xlnet_for_sequence_classification"], [39, 0, 0, "-", "xlnet_for_token_classification"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[9, 1, 1, "", "AlbertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering": [[9, 2, 1, "", "loadSavedModel"], [9, 2, 1, "", "pretrained"], [9, 2, 1, "", "setConfigProtoBytes"], [9, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[10, 1, 1, "", "AlbertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification": [[10, 2, 1, "", "getClasses"], [10, 2, 1, "", "loadSavedModel"], [10, 2, 1, "", "pretrained"], [10, 2, 1, "", "setCoalesceSentences"], [10, 2, 1, "", "setConfigProtoBytes"], [10, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[11, 1, 1, "", "AlbertForTokenClassification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification": [[11, 2, 1, "", "getClasses"], [11, 2, 1, "", "loadSavedModel"], [11, 2, 1, "", "pretrained"], [11, 2, 1, "", "setConfigProtoBytes"], [11, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[12, 1, 1, "", "BertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering": [[12, 2, 1, "", "loadSavedModel"], [12, 2, 1, "", "pretrained"], [12, 2, 1, "", "setConfigProtoBytes"], [12, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[13, 1, 1, "", "BertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification": [[13, 2, 1, "", "getClasses"], [13, 2, 1, "", "loadSavedModel"], [13, 2, 1, "", "pretrained"], [13, 2, 1, "", "setCoalesceSentences"], [13, 2, 1, "", "setConfigProtoBytes"], [13, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[14, 1, 1, "", "BertForTokenClassification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification": [[14, 2, 1, "", "getClasses"], [14, 2, 1, "", "loadSavedModel"], [14, 2, 1, "", "pretrained"], [14, 2, 1, "", "setConfigProtoBytes"], [14, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[15, 1, 1, "", "CamemBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering": [[15, 2, 1, "", "loadSavedModel"], [15, 2, 1, "", "pretrained"], [15, 2, 1, "", "setConfigProtoBytes"], [15, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[16, 1, 1, "", "CamemBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification": [[16, 2, 1, "", "getClasses"], [16, 2, 1, "", "loadSavedModel"], [16, 2, 1, "", "pretrained"], [16, 2, 1, "", "setCoalesceSentences"], [16, 2, 1, "", "setConfigProtoBytes"], [16, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[17, 1, 1, "", "CamemBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification": [[17, 2, 1, "", "getClasses"], [17, 2, 1, "", "loadSavedModel"], [17, 2, 1, "", "pretrained"], [17, 2, 1, "", "setConfigProtoBytes"], [17, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[18, 1, 1, "", "ClassifierDLApproach"], [18, 1, 1, "", "ClassifierDLModel"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach": [[18, 2, 1, "", "setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel": [[18, 2, 1, "", "pretrained"], [18, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[19, 1, 1, "", "DeBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering": [[19, 2, 1, "", "loadSavedModel"], [19, 2, 1, "", "pretrained"], [19, 2, 1, "", "setConfigProtoBytes"], [19, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[20, 1, 1, "", "DeBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification": [[20, 2, 1, "", "getClasses"], [20, 2, 1, "", "loadSavedModel"], [20, 2, 1, "", "pretrained"], [20, 2, 1, "", "setCoalesceSentences"], [20, 2, 1, "", "setConfigProtoBytes"], [20, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[21, 1, 1, "", "DeBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification": [[21, 2, 1, "", "getClasses"], [21, 2, 1, "", "loadSavedModel"], [21, 2, 1, "", "pretrained"], [21, 2, 1, "", "setConfigProtoBytes"], [21, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[22, 1, 1, "", "DistilBertForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering": [[22, 2, 1, "", "loadSavedModel"], [22, 2, 1, "", "pretrained"], [22, 2, 1, "", "setConfigProtoBytes"], [22, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[23, 1, 1, "", "DistilBertForSequenceClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification": [[23, 2, 1, "", "getClasses"], [23, 2, 1, "", "loadSavedModel"], [23, 2, 1, "", "pretrained"], [23, 2, 1, "", "setCoalesceSentences"], [23, 2, 1, "", "setConfigProtoBytes"], [23, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[24, 1, 1, "", "DistilBertForTokenClassification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification": [[24, 2, 1, "", "getClasses"], [24, 2, 1, "", "loadSavedModel"], [24, 2, 1, "", "pretrained"], [24, 2, 1, "", "setConfigProtoBytes"], [24, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[26, 1, 1, "", "LongformerForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering": [[26, 2, 1, "", "loadSavedModel"], [26, 2, 1, "", "pretrained"], [26, 2, 1, "", "setConfigProtoBytes"], [26, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[27, 1, 1, "", "LongformerForSequenceClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification": [[27, 2, 1, "", "getClasses"], [27, 2, 1, "", "loadSavedModel"], [27, 2, 1, "", "pretrained"], [27, 2, 1, "", "setCoalesceSentences"], [27, 2, 1, "", "setConfigProtoBytes"], [27, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[28, 1, 1, "", "LongformerForTokenClassification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification": [[28, 2, 1, "", "getClasses"], [28, 2, 1, "", "loadSavedModel"], [28, 2, 1, "", "pretrained"], [28, 2, 1, "", "setConfigProtoBytes"], [28, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[29, 1, 1, "", "MultiClassifierDLApproach"], [29, 1, 1, "", "MultiClassifierDLModel"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach": [[29, 2, 1, "", "setThreshold"], [29, 2, 1, "", "setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel": [[29, 2, 1, "", "pretrained"], [29, 2, 1, "", "setConfigProtoBytes"], [29, 2, 1, "", "setThreshold"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[30, 1, 1, "", "RoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering": [[30, 2, 1, "", "loadSavedModel"], [30, 2, 1, "", "pretrained"], [30, 2, 1, "", "setConfigProtoBytes"], [30, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[31, 1, 1, "", "RoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification": [[31, 2, 1, "", "getClasses"], [31, 2, 1, "", "loadSavedModel"], [31, 2, 1, "", "pretrained"], [31, 2, 1, "", "setCoalesceSentences"], [31, 2, 1, "", "setConfigProtoBytes"], [31, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[32, 1, 1, "", "RoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification": [[32, 2, 1, "", "getClasses"], [32, 2, 1, "", "loadSavedModel"], [32, 2, 1, "", "pretrained"], [32, 2, 1, "", "setConfigProtoBytes"], [32, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[33, 1, 1, "", "SentimentDLApproach"], [33, 1, 1, "", "SentimentDLModel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach": [[33, 2, 1, "", "setDropout"], [33, 2, 1, "", "setThreshold"], [33, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel": [[33, 2, 1, "", "pretrained"], [33, 2, 1, "", "setConfigProtoBytes"], [33, 2, 1, "", "setThreshold"], [33, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[34, 1, 1, "", "TapasForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering": [[34, 2, 1, "", "loadSavedModel"], [34, 2, 1, "", "pretrained"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[35, 1, 1, "", "XlmRoBertaForQuestionAnswering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering": [[35, 2, 1, "", "loadSavedModel"], [35, 2, 1, "", "pretrained"], [35, 2, 1, "", "setConfigProtoBytes"], [35, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[36, 1, 1, "", "XlmRoBertaForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification": [[36, 2, 1, "", "getClasses"], [36, 2, 1, "", "loadSavedModel"], [36, 2, 1, "", "pretrained"], [36, 2, 1, "", "setCoalesceSentences"], [36, 2, 1, "", "setConfigProtoBytes"], [36, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[37, 1, 1, "", "XlmRoBertaForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification": [[37, 2, 1, "", "getClasses"], [37, 2, 1, "", "loadSavedModel"], [37, 2, 1, "", "pretrained"], [37, 2, 1, "", "setConfigProtoBytes"], [37, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[38, 1, 1, "", "XlnetForSequenceClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification": [[38, 2, 1, "", "getClasses"], [38, 2, 1, "", "loadSavedModel"], [38, 2, 1, "", "pretrained"], [38, 2, 1, "", "setCoalesceSentences"], [38, 2, 1, "", "setConfigProtoBytes"], [38, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[39, 1, 1, "", "XlnetForTokenClassification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification": [[39, 2, 1, "", "getClasses"], [39, 2, 1, "", "loadSavedModel"], [39, 2, 1, "", "pretrained"], [39, 2, 1, "", "setConfigProtoBytes"], [39, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.coref": [[41, 0, 0, "-", "spanbert_coref"]], "sparknlp.annotator.coref.spanbert_coref": [[41, 1, 1, "", "SpanBertCorefModel"]], "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel": [[41, 2, 1, "", "loadSavedModel"], [41, 2, 1, "", "pretrained"], [41, 2, 1, "", "setConfigProtoBytes"], [41, 2, 1, "", "setMaxSegmentLength"], [41, 2, 1, "", "setMaxSentenceLength"], [41, 2, 1, "", "setTextGenre"]], "sparknlp.annotator.cv": [[43, 0, 0, "-", "swin_for_image_classification"], [44, 0, 0, "-", "vit_for_image_classification"]], "sparknlp.annotator.cv.swin_for_image_classification": [[43, 1, 1, "", "SwinForImageClassification"]], "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification": [[43, 2, 1, "", "getClasses"], [43, 2, 1, "", "loadSavedModel"], [43, 2, 1, "", "pretrained"], [43, 2, 1, "", "setConfigProtoBytes"], [43, 2, 1, "", "setDoRescale"], [43, 2, 1, "", "setRescaleFactor"]], "sparknlp.annotator.cv.vit_for_image_classification": [[44, 1, 1, "", "ViTForImageClassification"]], "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification": [[44, 2, 1, "", "getClasses"], [44, 2, 1, "", "loadSavedModel"], [44, 2, 1, "", "pretrained"], [44, 2, 1, "", "setConfigProtoBytes"]], "sparknlp.annotator.dependency": [[45, 0, 0, "-", "dependency_parser"], [47, 0, 0, "-", "typed_dependency_parser"]], "sparknlp.annotator.dependency.dependency_parser": [[45, 1, 1, "", "DependencyParserApproach"], [45, 1, 1, "", "DependencyParserModel"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach": [[45, 2, 1, "", "setConllU"], [45, 2, 1, "", "setDependencyTreeBank"], [45, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel": [[45, 2, 1, "", "pretrained"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[47, 1, 1, "", "TypedDependencyParserApproach"], [47, 1, 1, "", "TypedDependencyParserModel"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach": [[47, 2, 1, "", "setConll2009"], [47, 2, 1, "", "setConllU"], [47, 2, 1, "", "setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel": [[47, 2, 1, "", "pretrained"]], "sparknlp.annotator.document_normalizer": [[48, 1, 1, "", "DocumentNormalizer"]], "sparknlp.annotator.document_normalizer.DocumentNormalizer": [[48, 2, 1, "", "setAction"], [48, 2, 1, "", "setEncoding"], [48, 2, 1, "", "setLowercase"], [48, 2, 1, "", "setPatterns"], [48, 2, 1, "", "setPolicy"], [48, 2, 1, "", "setReplacement"]], "sparknlp.annotator.embeddings": [[49, 0, 0, "-", "albert_embeddings"], [50, 0, 0, "-", "bert_embeddings"], [51, 0, 0, "-", "bert_sentence_embeddings"], [52, 0, 0, "-", "camembert_embeddings"], [53, 0, 0, "-", "chunk_embeddings"], [54, 0, 0, "-", "deberta_embeddings"], [55, 0, 0, "-", "distil_bert_embeddings"], [56, 0, 0, "-", "doc2vec"], [57, 0, 0, "-", "elmo_embeddings"], [59, 0, 0, "-", "longformer_embeddings"], [60, 0, 0, "-", "roberta_embeddings"], [61, 0, 0, "-", "roberta_sentence_embeddings"], [62, 0, 0, "-", "sentence_embeddings"], [63, 0, 0, "-", "universal_sentence_encoder"], [64, 0, 0, "-", "word2vec"], [65, 0, 0, "-", "word_embeddings"], [66, 0, 0, "-", "xlm_roberta_embeddings"], [67, 0, 0, "-", "xlm_roberta_sentence_embeddings"], [68, 0, 0, "-", "xlnet_embeddings"]], "sparknlp.annotator.embeddings.albert_embeddings": [[49, 1, 1, "", "AlbertEmbeddings"]], "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings": [[49, 2, 1, "", "loadSavedModel"], [49, 2, 1, "", "pretrained"], [49, 2, 1, "", "setConfigProtoBytes"], [49, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[50, 1, 1, "", "BertEmbeddings"]], "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings": [[50, 2, 1, "", "loadSavedModel"], [50, 2, 1, "", "pretrained"], [50, 2, 1, "", "setConfigProtoBytes"], [50, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[51, 1, 1, "", "BertSentenceEmbeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings": [[51, 2, 1, "", "loadSavedModel"], [51, 2, 1, "", "pretrained"], [51, 2, 1, "", "setConfigProtoBytes"], [51, 2, 1, "", "setIsLong"], [51, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[52, 1, 1, "", "CamemBertEmbeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings": [[52, 2, 1, "", "loadSavedModel"], [52, 2, 1, "", "pretrained"], [52, 2, 1, "", "setConfigProtoBytes"], [52, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[53, 1, 1, "", "ChunkEmbeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings": [[53, 2, 1, "", "setPoolingStrategy"], [53, 2, 1, "", "setSkipOOV"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[54, 1, 1, "", "DeBertaEmbeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings": [[54, 2, 1, "", "loadSavedModel"], [54, 2, 1, "", "pretrained"], [54, 2, 1, "", "setConfigProtoBytes"], [54, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[55, 1, 1, "", "DistilBertEmbeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings": [[55, 2, 1, "", "loadSavedModel"], [55, 2, 1, "", "pretrained"], [55, 2, 1, "", "setConfigProtoBytes"], [55, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.doc2vec": [[56, 1, 1, "", "Doc2VecApproach"], [56, 1, 1, "", "Doc2VecModel"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach": [[56, 2, 1, "", "setMaxIter"], [56, 2, 1, "", "setMaxSentenceLength"], [56, 2, 1, "", "setMinCount"], [56, 2, 1, "", "setNumPartitions"], [56, 2, 1, "", "setSeed"], [56, 2, 1, "", "setStepSize"], [56, 2, 1, "", "setVectorSize"], [56, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel": [[56, 2, 1, "", "pretrained"], [56, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[57, 1, 1, "", "ElmoEmbeddings"]], "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings": [[57, 2, 1, "", "loadSavedModel"], [57, 2, 1, "", "pretrained"], [57, 2, 1, "", "setBatchSize"], [57, 2, 1, "", "setConfigProtoBytes"], [57, 2, 1, "", "setPoolingLayer"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[59, 1, 1, "", "LongformerEmbeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings": [[59, 2, 1, "", "loadSavedModel"], [59, 2, 1, "", "pretrained"], [59, 2, 1, "", "setConfigProtoBytes"], [59, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[60, 1, 1, "", "RoBertaEmbeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings": [[60, 2, 1, "", "loadSavedModel"], [60, 2, 1, "", "pretrained"], [60, 2, 1, "", "setConfigProtoBytes"], [60, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[61, 1, 1, "", "RoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings": [[61, 2, 1, "", "loadSavedModel"], [61, 2, 1, "", "pretrained"], [61, 2, 1, "", "setConfigProtoBytes"], [61, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[62, 1, 1, "", "SentenceEmbeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings": [[62, 2, 1, "", "setPoolingStrategy"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[63, 1, 1, "", "UniversalSentenceEncoder"]], "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder": [[63, 2, 1, "", "loadSavedModel"], [63, 2, 1, "", "pretrained"], [63, 2, 1, "", "setConfigProtoBytes"], [63, 2, 1, "", "setLoadSP"]], "sparknlp.annotator.embeddings.word2vec": [[64, 1, 1, "", "Word2VecApproach"], [64, 1, 1, "", "Word2VecModel"]], "sparknlp.annotator.embeddings.word2vec.Word2VecApproach": [[64, 2, 1, "", "setMaxIter"], [64, 2, 1, "", "setMaxSentenceLength"], [64, 2, 1, "", "setMinCount"], [64, 2, 1, "", "setNumPartitions"], [64, 2, 1, "", "setSeed"], [64, 2, 1, "", "setStepSize"], [64, 2, 1, "", "setVectorSize"], [64, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.embeddings.word2vec.Word2VecModel": [[64, 2, 1, "", "pretrained"], [64, 2, 1, "", "setVectorSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[65, 1, 1, "", "WordEmbeddings"], [65, 1, 1, "", "WordEmbeddingsModel"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings": [[65, 2, 1, "", "setReadCacheSize"], [65, 2, 1, "", "setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel": [[65, 2, 1, "", "loadStorage"], [65, 2, 1, "", "overallCoverage"], [65, 2, 1, "", "pretrained"], [65, 2, 1, "", "setReadCacheSize"], [65, 2, 1, "", "withCoverageColumn"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[66, 1, 1, "", "XlmRoBertaEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings": [[66, 2, 1, "", "loadSavedModel"], [66, 2, 1, "", "pretrained"], [66, 2, 1, "", "setConfigProtoBytes"], [66, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[67, 1, 1, "", "XlmRoBertaSentenceEmbeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings": [[67, 2, 1, "", "loadSavedModel"], [67, 2, 1, "", "pretrained"], [67, 2, 1, "", "setConfigProtoBytes"], [67, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[68, 1, 1, "", "XlnetEmbeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings": [[68, 2, 1, "", "loadSavedModel"], [68, 2, 1, "", "pretrained"], [68, 2, 1, "", "setConfigProtoBytes"], [68, 2, 1, "", "setMaxSentenceLength"]], "sparknlp.annotator.er": [[69, 0, 0, "-", "entity_ruler"]], "sparknlp.annotator.er.entity_ruler": [[69, 1, 1, "", "EntityRulerApproach"], [69, 1, 1, "", "EntityRulerModel"]], "sparknlp.annotator.er.entity_ruler.EntityRulerApproach": [[69, 2, 1, "", "setAlphabetResource"], [69, 2, 1, "", "setEnablePatternRegex"], [69, 2, 1, "", "setPatternsResource"], [69, 2, 1, "", "setSentenceMatch"], [69, 2, 1, "", "setUseStorage"]], "sparknlp.annotator.graph_extraction": [[71, 1, 1, "", "GraphExtraction"]], "sparknlp.annotator.graph_extraction.GraphExtraction": [[71, 2, 1, "", "setDelimiter"], [71, 2, 1, "", "setDependencyParserModel"], [71, 2, 1, "", "setEntityTypes"], [71, 2, 1, "", "setExplodeEntities"], [71, 2, 1, "", "setIncludeEdges"], [71, 2, 1, "", "setMaxSentenceSize"], [71, 2, 1, "", "setMergeEntities"], [71, 2, 1, "", "setMergeEntitiesIOBFormat"], [71, 2, 1, "", "setMinSentenceSize"], [71, 2, 1, "", "setPosModel"], [71, 2, 1, "", "setRelationshipTypes"], [71, 2, 1, "", "setRootTokens"], [71, 2, 1, "", "setTypedDependencyParserModel"]], "sparknlp.annotator.keyword_extraction": [[74, 0, 0, "-", "yake_keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[74, 1, 1, "", "YakeKeywordExtraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction": [[74, 2, 1, "", "getStopWords"], [74, 2, 1, "", "loadDefaultStopWords"], [74, 2, 1, "", "setMaxNGrams"], [74, 2, 1, "", "setMinNGrams"], [74, 2, 1, "", "setNKeywords"], [74, 2, 1, "", "setStopWords"], [74, 2, 1, "", "setThreshold"], [74, 2, 1, "", "setWindowSize"]], "sparknlp.annotator.ld_dl": [[76, 0, 0, "-", "language_detector_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[76, 1, 1, "", "LanguageDetectorDL"]], "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL": [[76, 2, 1, "", "pretrained"], [76, 2, 1, "", "setCoalesceSentences"], [76, 2, 1, "", "setConfigProtoBytes"], [76, 2, 1, "", "setThreshold"], [76, 2, 1, "", "setThresholdLabel"]], "sparknlp.annotator.lemmatizer": [[77, 1, 1, "", "Lemmatizer"], [77, 1, 1, "", "LemmatizerModel"]], "sparknlp.annotator.lemmatizer.Lemmatizer": [[77, 2, 1, "", "setDictionary"], [77, 2, 1, "", "setFormCol"], [77, 2, 1, "", "setLemmaCol"]], "sparknlp.annotator.lemmatizer.LemmatizerModel": [[77, 2, 1, "", "pretrained"]], "sparknlp.annotator.matcher": [[78, 0, 0, "-", "big_text_matcher"], [79, 0, 0, "-", "date_matcher"], [81, 0, 0, "-", "multi_date_matcher"], [82, 0, 0, "-", "regex_matcher"], [83, 0, 0, "-", "text_matcher"]], "sparknlp.annotator.matcher.big_text_matcher": [[78, 1, 1, "", "BigTextMatcher"], [78, 1, 1, "", "BigTextMatcherModel"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher": [[78, 2, 1, "", "setCaseSensitive"], [78, 2, 1, "", "setEntities"], [78, 2, 1, "", "setMergeOverlapping"], [78, 2, 1, "", "setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel": [[78, 2, 1, "", "loadStorage"], [78, 2, 1, "", "pretrained"], [78, 2, 1, "", "setCaseSensitive"], [78, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.date_matcher": [[79, 1, 1, "", "DateMatcher"], [79, 1, 1, "", "DateMatcherUtils"]], "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils": [[79, 2, 1, "", "setAnchorDateDay"], [79, 2, 1, "", "setAnchorDateMonth"], [79, 2, 1, "", "setAnchorDateYear"], [79, 2, 1, "", "setDefaultDayWhenMissing"], [79, 2, 1, "", "setInputFormats"], [79, 2, 1, "", "setOutputFormat"], [79, 2, 1, "", "setReadMonthFirst"]], "sparknlp.annotator.matcher.multi_date_matcher": [[81, 1, 1, "", "MultiDateMatcher"]], "sparknlp.annotator.matcher.regex_matcher": [[82, 1, 1, "", "RegexMatcher"], [82, 1, 1, "", "RegexMatcherModel"]], "sparknlp.annotator.matcher.regex_matcher.RegexMatcher": [[82, 2, 1, "", "setDelimiter"], [82, 2, 1, "", "setExternalRules"], [82, 2, 1, "", "setRules"], [82, 2, 1, "", "setStrategy"]], "sparknlp.annotator.matcher.text_matcher": [[83, 1, 1, "", "TextMatcher"], [83, 1, 1, "", "TextMatcherModel"]], "sparknlp.annotator.matcher.text_matcher.TextMatcher": [[83, 2, 1, "", "setBuildFromTokens"], [83, 2, 1, "", "setCaseSensitive"], [83, 2, 1, "", "setEntities"], [83, 2, 1, "", "setEntityValue"], [83, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher.TextMatcherModel": [[83, 2, 1, "", "pretrained"], [83, 2, 1, "", "setBuildFromTokens"], [83, 2, 1, "", "setEntityValue"], [83, 2, 1, "", "setMergeOverlapping"]], "sparknlp.annotator.n_gram_generator": [[84, 1, 1, "", "NGramGenerator"]], "sparknlp.annotator.n_gram_generator.NGramGenerator": [[84, 2, 1, "", "setDelimiter"], [84, 2, 1, "", "setEnableCumulative"], [84, 2, 1, "", "setN"]], "sparknlp.annotator.ner": [[86, 0, 0, "-", "ner_approach"], [87, 0, 0, "-", "ner_converter"], [88, 0, 0, "-", "ner_crf"], [89, 0, 0, "-", "ner_dl"], [90, 0, 0, "-", "ner_overwriter"], [91, 0, 0, "-", "zero_shot_ner_model"]], "sparknlp.annotator.ner.ner_approach": [[86, 1, 1, "", "NerApproach"]], "sparknlp.annotator.ner.ner_approach.NerApproach": [[86, 2, 1, "", "getLabelColumn"], [86, 2, 1, "", "setEntities"], [86, 2, 1, "", "setLabelColumn"], [86, 2, 1, "", "setMaxEpochs"], [86, 2, 1, "", "setMinEpochs"], [86, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.ner.ner_converter": [[87, 1, 1, "", "NerConverter"]], "sparknlp.annotator.ner.ner_converter.NerConverter": [[87, 2, 1, "", "setPreservePosition"], [87, 2, 1, "", "setWhiteList"]], "sparknlp.annotator.ner.ner_crf": [[88, 1, 1, "", "NerCrfApproach"], [88, 1, 1, "", "NerCrfModel"]], "sparknlp.annotator.ner.ner_crf.NerCrfApproach": [[88, 2, 1, "", "setC0"], [88, 2, 1, "", "setExternalFeatures"], [88, 2, 1, "", "setIncludeConfidence"], [88, 2, 1, "", "setL2"], [88, 2, 1, "", "setLossEps"], [88, 2, 1, "", "setMinW"], [88, 2, 1, "", "setVerbose"]], "sparknlp.annotator.ner.ner_crf.NerCrfModel": [[88, 2, 1, "", "pretrained"], [88, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_dl": [[89, 1, 1, "", "NerDLApproach"], [89, 1, 1, "", "NerDLModel"]], "sparknlp.annotator.ner.ner_dl.NerDLApproach": [[89, 2, 1, "", "setBatchSize"], [89, 2, 1, "", "setBestModelMetric"], [89, 2, 1, "", "setConfigProtoBytes"], [89, 2, 1, "", "setDropout"], [89, 2, 1, "", "setEnableMemoryOptimizer"], [89, 2, 1, "", "setGraphFolder"], [89, 2, 1, "", "setIncludeAllConfidenceScores"], [89, 2, 1, "", "setIncludeConfidence"], [89, 2, 1, "", "setLr"], [89, 2, 1, "", "setPo"], [89, 2, 1, "", "setUseBestModel"], [89, 2, 1, "", "setUseContrib"]], "sparknlp.annotator.ner.ner_dl.NerDLModel": [[89, 2, 1, "", "pretrained"], [89, 2, 1, "", "setConfigProtoBytes"], [89, 2, 1, "", "setIncludeAllConfidenceScores"], [89, 2, 1, "", "setIncludeConfidence"]], "sparknlp.annotator.ner.ner_overwriter": [[90, 1, 1, "", "NerOverwriter"]], "sparknlp.annotator.ner.ner_overwriter.NerOverwriter": [[90, 2, 1, "", "setNerWords"], [90, 2, 1, "", "setNewNerEntity"], [90, 2, 1, "", "setReplaceEntities"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[91, 1, 1, "", "ZeroShotNerModel"]], "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel": [[91, 2, 1, "", "getClasses"], [91, 2, 1, "", "load"], [91, 2, 1, "", "pretrained"], [91, 2, 1, "", "setEntityDefinitions"], [91, 2, 1, "", "setPredictionThreshold"]], "sparknlp.annotator.normalizer": [[92, 1, 1, "", "Normalizer"], [92, 1, 1, "", "NormalizerModel"]], "sparknlp.annotator.normalizer.Normalizer": [[92, 2, 1, "", "setCleanupPatterns"], [92, 2, 1, "", "setLowercase"], [92, 2, 1, "", "setMaxLength"], [92, 2, 1, "", "setMinLength"], [92, 2, 1, "", "setSlangDictionary"]], "sparknlp.annotator.param": [[93, 0, 0, "-", "classifier_encoder"], [94, 0, 0, "-", "evaluation_dl_params"]], "sparknlp.annotator.param.classifier_encoder": [[93, 1, 1, "", "ClassifierEncoder"]], "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder": [[93, 2, 1, "", "setBatchSize"], [93, 2, 1, "", "setConfigProtoBytes"], [93, 2, 1, "", "setLabelColumn"], [93, 2, 1, "", "setLr"], [93, 2, 1, "", "setMaxEpochs"], [93, 2, 1, "", "setRandomSeed"]], "sparknlp.annotator.param.evaluation_dl_params": [[94, 1, 1, "", "EvaluationDLParams"]], "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams": [[94, 2, 1, "", "setEnableOutputLogs"], [94, 2, 1, "", "setEvaluationLogExtended"], [94, 2, 1, "", "setOutputLogsPath"], [94, 2, 1, "", "setTestDataset"], [94, 2, 1, "", "setValidationSplit"], [94, 2, 1, "", "setVerbose"]], "sparknlp.annotator.pos": [[97, 0, 0, "-", "perceptron"]], "sparknlp.annotator.pos.perceptron": [[97, 1, 1, "", "PerceptronApproach"], [97, 1, 1, "", "PerceptronModel"]], "sparknlp.annotator.pos.perceptron.PerceptronApproach": [[97, 2, 1, "", "getNIterations"], [97, 2, 1, "", "setIterations"], [97, 2, 1, "", "setPosColumn"]], "sparknlp.annotator.pos.perceptron.PerceptronModel": [[97, 2, 1, "", "pretrained"]], "sparknlp.annotator.sentence": [[99, 0, 0, "-", "sentence_detector"], [100, 0, 0, "-", "sentence_detector_dl"]], "sparknlp.annotator.sentence.sentence_detector": [[99, 1, 1, "", "SentenceDetector"], [99, 1, 1, "", "SentenceDetectorParams"]], "sparknlp.annotator.sentence.sentence_detector.SentenceDetector": [[99, 2, 1, "", "setCustomBounds"], [99, 2, 1, "", "setCustomBoundsStrategy"], [99, 2, 1, "", "setDetectLists"], [99, 2, 1, "", "setExplodeSentences"], [99, 2, 1, "", "setMaxLength"], [99, 2, 1, "", "setMinLength"], [99, 2, 1, "", "setSplitLength"], [99, 2, 1, "", "setUseAbbreviations"], [99, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[100, 1, 1, "", "SentenceDetectorDLApproach"], [100, 1, 1, "", "SentenceDetectorDLModel"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach": [[100, 2, 1, "", "setEpochsNumber"], [100, 2, 1, "", "setExplodeSentences"], [100, 2, 1, "", "setImpossiblePenultimates"], [100, 2, 1, "", "setModel"], [100, 2, 1, "", "setOutputLogsPath"], [100, 2, 1, "", "setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel": [[100, 2, 1, "", "pretrained"], [100, 2, 1, "", "setCustomBounds"], [100, 2, 1, "", "setExplodeSentences"], [100, 2, 1, "", "setImpossiblePenultimates"], [100, 2, 1, "", "setMaxLength"], [100, 2, 1, "", "setMinLength"], [100, 2, 1, "", "setModel"], [100, 2, 1, "", "setSplitLength"], [100, 2, 1, "", "setUseCustomBoundsOnly"]], "sparknlp.annotator.sentiment": [[102, 0, 0, "-", "sentiment_detector"], [103, 0, 0, "-", "vivekn_sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[102, 1, 1, "", "SentimentDetector"], [102, 1, 1, "", "SentimentDetectorModel"]], "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector": [[102, 2, 1, "", "setDictionary"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[103, 1, 1, "", "ViveknSentimentApproach"], [103, 1, 1, "", "ViveknSentimentModel"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach": [[103, 2, 1, "", "setPruneCorpus"], [103, 2, 1, "", "setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel": [[103, 2, 1, "", "pretrained"]], "sparknlp.annotator.seq2seq": [[104, 0, 0, "-", "gpt2_transformer"], [106, 0, 0, "-", "marian_transformer"], [107, 0, 0, "-", "t5_transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[104, 1, 1, "", "GPT2Transformer"]], "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer": [[104, 2, 1, "", "loadSavedModel"], [104, 2, 1, "", "pretrained"], [104, 2, 1, "", "setConfigProtoBytes"], [104, 2, 1, "", "setDoSample"], [104, 2, 1, "", "setIgnoreTokenIds"], [104, 2, 1, "", "setMaxOutputLength"], [104, 2, 1, "", "setMinOutputLength"], [104, 2, 1, "", "setNoRepeatNgramSize"], [104, 2, 1, "", "setRepetitionPenalty"], [104, 2, 1, "", "setTask"], [104, 2, 1, "", "setTemperature"], [104, 2, 1, "", "setTopK"], [104, 2, 1, "", "setTopP"]], "sparknlp.annotator.seq2seq.marian_transformer": [[106, 1, 1, "", "MarianTransformer"]], "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer": [[106, 2, 1, "", "loadSavedModel"], [106, 2, 1, "", "pretrained"], [106, 2, 1, "", "setConfigProtoBytes"], [106, 2, 1, "", "setIgnoreTokenIds"], [106, 2, 1, "", "setLangId"], [106, 2, 1, "", "setMaxInputLength"], [106, 2, 1, "", "setMaxOutputLength"]], "sparknlp.annotator.seq2seq.t5_transformer": [[107, 1, 1, "", "T5Transformer"]], "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer": [[107, 2, 1, "", "loadSavedModel"], [107, 2, 1, "", "pretrained"], [107, 2, 1, "", "setConfigProtoBytes"], [107, 2, 1, "", "setDoSample"], [107, 2, 1, "", "setIgnoreTokenIds"], [107, 2, 1, "", "setMaxOutputLength"], [107, 2, 1, "", "setMinOutputLength"], [107, 2, 1, "", "setNoRepeatNgramSize"], [107, 2, 1, "", "setRepetitionPenalty"], [107, 2, 1, "", "setTask"], [107, 2, 1, "", "setTemperature"], [107, 2, 1, "", "setTopK"], [107, 2, 1, "", "setTopP"]], "sparknlp.annotator.spell_check": [[108, 0, 0, "-", "context_spell_checker"], [110, 0, 0, "-", "norvig_sweeting"], [111, 0, 0, "-", "symmetric_delete"]], "sparknlp.annotator.spell_check.context_spell_checker": [[108, 1, 1, "", "ContextSpellCheckerApproach"], [108, 1, 1, "", "ContextSpellCheckerModel"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach": [[108, 2, 1, "", "addRegexClass"], [108, 2, 1, "", "addVocabClass"], [108, 2, 1, "", "setBatchSize"], [108, 2, 1, "", "setCaseStrategy"], [108, 2, 1, "", "setClassCount"], [108, 2, 1, "", "setCompoundCount"], [108, 2, 1, "", "setConfigProtoBytes"], [108, 2, 1, "", "setEpochs"], [108, 2, 1, "", "setErrorThreshold"], [108, 2, 1, "", "setFinalRate"], [108, 2, 1, "", "setInitialRate"], [108, 2, 1, "", "setLanguageModelClasses"], [108, 2, 1, "", "setMaxCandidates"], [108, 2, 1, "", "setMaxWindowLen"], [108, 2, 1, "", "setMinCount"], [108, 2, 1, "", "setTradeoff"], [108, 2, 1, "", "setValidationFraction"], [108, 2, 1, "", "setWeightedDistPath"], [108, 2, 1, "", "setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel": [[108, 2, 1, "", "getWordClasses"], [108, 2, 1, "", "pretrained"], [108, 2, 1, "", "setCaseStrategy"], [108, 2, 1, "", "setCompareLowcase"], [108, 2, 1, "", "setConfigProtoBytes"], [108, 2, 1, "", "setCorrectSymbols"], [108, 2, 1, "", "setErrorThreshold"], [108, 2, 1, "", "setGamma"], [108, 2, 1, "", "setMaxCandidates"], [108, 2, 1, "", "setMaxWindowLen"], [108, 2, 1, "", "setTradeoff"], [108, 2, 1, "", "setWeights"], [108, 2, 1, "", "setWordMaxDistance"], [108, 2, 1, "", "updateRegexClass"], [108, 2, 1, "", "updateVocabClass"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[110, 1, 1, "", "NorvigSweetingApproach"], [110, 1, 1, "", "NorvigSweetingModel"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach": [[110, 2, 1, "", "setCaseSensitive"], [110, 2, 1, "", "setDictionary"], [110, 2, 1, "", "setDoubleVariants"], [110, 2, 1, "", "setFrequencyPriority"], [110, 2, 1, "", "setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel": [[110, 2, 1, "", "pretrained"]], "sparknlp.annotator.spell_check.symmetric_delete": [[111, 1, 1, "", "SymmetricDeleteApproach"], [111, 1, 1, "", "SymmetricDeleteModel"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach": [[111, 2, 1, "", "setDeletesThreshold"], [111, 2, 1, "", "setDictionary"], [111, 2, 1, "", "setFrequencyThreshold"], [111, 2, 1, "", "setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel": [[111, 2, 1, "", "pretrained"]], "sparknlp.annotator.stemmer": [[112, 1, 1, "", "Stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[113, 1, 1, "", "StopWordsCleaner"]], "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner": [[113, 2, 1, "", "loadDefaultStopWords"], [113, 2, 1, "", "pretrained"], [113, 2, 1, "", "setCaseSensitive"], [113, 2, 1, "", "setLocale"], [113, 2, 1, "", "setStopWords"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[114, 1, 1, "", "TFNerDLGraphBuilder"], [114, 1, 1, "", "TFNerDLGraphBuilderModel"]], "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder": [[114, 2, 1, "", "getGraphFile"], [114, 2, 1, "", "getGraphFolder"], [114, 2, 1, "", "getHiddenUnitsNumber"], [114, 2, 1, "", "getInputCols"], [114, 2, 1, "", "getLabelColumn"], [114, 2, 1, "", "setGraphFile"], [114, 2, 1, "", "setGraphFolder"], [114, 2, 1, "", "setHiddenUnitsNumber"], [114, 2, 1, "", "setInputCols"], [114, 2, 1, "", "setLabelColumn"]], "sparknlp.annotator.token": [[115, 0, 0, "-", "chunk_tokenizer"], [117, 0, 0, "-", "recursive_tokenizer"], [118, 0, 0, "-", "regex_tokenizer"], [119, 0, 0, "-", "tokenizer"]], "sparknlp.annotator.token.chunk_tokenizer": [[115, 1, 1, "", "ChunkTokenizer"], [115, 1, 1, "", "ChunkTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer": [[117, 1, 1, "", "RecursiveTokenizer"], [117, 1, 1, "", "RecursiveTokenizerModel"]], "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer": [[117, 2, 1, "", "setInfixes"], [117, 2, 1, "", "setPrefixes"], [117, 2, 1, "", "setSuffixes"], [117, 2, 1, "", "setWhitelist"]], "sparknlp.annotator.token.regex_tokenizer": [[118, 1, 1, "", "RegexTokenizer"]], "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer": [[118, 2, 1, "", "setMaxLength"], [118, 2, 1, "", "setMinLength"], [118, 2, 1, "", "setPattern"], [118, 2, 1, "", "setPositionalMask"], [118, 2, 1, "", "setPreservePosition"], [118, 2, 1, "", "setToLowercase"], [118, 2, 1, "", "setTrimWhitespace"]], "sparknlp.annotator.token.tokenizer": [[119, 1, 1, "", "Tokenizer"], [119, 1, 1, "", "TokenizerModel"]], "sparknlp.annotator.token.tokenizer.Tokenizer": [[119, 2, 1, "", "addContextChars"], [119, 2, 1, "", "addException"], [119, 2, 1, "", "addInfixPattern"], [119, 2, 1, "", "addSplitChars"], [119, 2, 1, "", "getCaseSensitiveExceptions"], [119, 2, 1, "", "getContextChars"], [119, 2, 1, "", "getExceptions"], [119, 2, 1, "", "getInfixPatterns"], [119, 2, 1, "", "getPrefixPattern"], [119, 2, 1, "", "getSplitChars"], [119, 2, 1, "", "getSuffixPattern"], [119, 2, 1, "", "setCaseSensitiveExceptions"], [119, 2, 1, "", "setContextChars"], [119, 2, 1, "", "setExceptions"], [119, 2, 1, "", "setExceptionsPath"], [119, 2, 1, "", "setInfixPatterns"], [119, 2, 1, "", "setMaxLength"], [119, 2, 1, "", "setMinLength"], [119, 2, 1, "", "setPrefixPattern"], [119, 2, 1, "", "setSplitChars"], [119, 2, 1, "", "setSplitPattern"], [119, 2, 1, "", "setSuffixPattern"], [119, 2, 1, "", "setTargetPattern"]], "sparknlp.annotator.token.tokenizer.TokenizerModel": [[119, 2, 1, "", "addSplitChars"], [119, 2, 1, "", "pretrained"], [119, 2, 1, "", "setSplitChars"], [119, 2, 1, "", "setSplitPattern"]], "sparknlp.annotator.ws": [[121, 0, 0, "-", "word_segmenter"]], "sparknlp.annotator.ws.word_segmenter": [[121, 1, 1, "", "WordSegmenterApproach"], [121, 1, 1, "", "WordSegmenterModel"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach": [[121, 2, 1, "", "getAmbiguityThreshold"], [121, 2, 1, "", "getFrequencyThreshold"], [121, 2, 1, "", "getNIterations"], [121, 2, 1, "", "setAmbiguityThreshold"], [121, 2, 1, "", "setEnableRegexTokenizer"], [121, 2, 1, "", "setFrequencyThreshold"], [121, 2, 1, "", "setNIterations"], [121, 2, 1, "", "setPattern"], [121, 2, 1, "", "setPosColumn"], [121, 2, 1, "", "setToLowercase"]], "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel": [[121, 2, 1, "", "pretrained"], [121, 2, 1, "", "setEnableRegexTokenizer"], [121, 2, 1, "", "setPattern"], [121, 2, 1, "", "setToLowercase"]], "sparknlp.base": [[122, 0, 0, "-", "audio_assembler"], [123, 0, 0, "-", "chunk2_doc"], [124, 0, 0, "-", "date2_chunk"], [125, 0, 0, "-", "doc2_chunk"], [126, 0, 0, "-", "document_assembler"], [127, 0, 0, "-", "embeddings_finisher"], [128, 0, 0, "-", "finisher"], [129, 0, 0, "-", "graph_finisher"], [130, 0, 0, "-", "has_recursive_fit"], [131, 0, 0, "-", "has_recursive_transform"], [132, 0, 0, "-", "image_assembler"], [134, 0, 0, "-", "light_pipeline"], [135, 0, 0, "-", "multi_document_assembler"], [136, 0, 0, "-", "recursive_pipeline"], [137, 0, 0, "-", "table_assembler"], [138, 0, 0, "-", "token2_chunk"], [139, 0, 0, "-", "token_assembler"]], "sparknlp.base.audio_assembler": [[122, 1, 1, "", "AudioAssembler"]], "sparknlp.base.audio_assembler.AudioAssembler": [[122, 2, 1, "", "getOutputCol"], [122, 2, 1, "", "setInputCol"], [122, 2, 1, "", "setOutputCol"]], "sparknlp.base.chunk2_doc": [[123, 1, 1, "", "Chunk2Doc"]], "sparknlp.base.date2_chunk": [[124, 1, 1, "", "Date2Chunk"]], "sparknlp.base.doc2_chunk": [[125, 1, 1, "", "Doc2Chunk"]], "sparknlp.base.doc2_chunk.Doc2Chunk": [[125, 2, 1, "", "setChunkCol"], [125, 2, 1, "", "setFailOnMissing"], [125, 2, 1, "", "setIsArray"], [125, 2, 1, "", "setLowerCase"], [125, 2, 1, "", "setStartCol"], [125, 2, 1, "", "setStartColByTokenIndex"]], "sparknlp.base.document_assembler": [[126, 1, 1, "", "DocumentAssembler"]], "sparknlp.base.document_assembler.DocumentAssembler": [[126, 2, 1, "", "getOutputCol"], [126, 2, 1, "", "setCleanupMode"], [126, 2, 1, "", "setIdCol"], [126, 2, 1, "", "setInputCol"], [126, 2, 1, "", "setMetadataCol"], [126, 2, 1, "", "setOutputCol"]], "sparknlp.base.embeddings_finisher": [[127, 1, 1, "", "EmbeddingsFinisher"]], "sparknlp.base.embeddings_finisher.EmbeddingsFinisher": [[127, 2, 1, "", "getInputCols"], [127, 2, 1, "", "getOutputCols"], [127, 2, 1, "", "setCleanAnnotations"], [127, 2, 1, "", "setInputCols"], [127, 2, 1, "", "setOutputAsVector"], [127, 2, 1, "", "setOutputCols"]], "sparknlp.base.finisher": [[128, 1, 1, "", "Finisher"]], "sparknlp.base.finisher.Finisher": [[128, 2, 1, "", "getInputCols"], [128, 2, 1, "", "getOutputCols"], [128, 2, 1, "", "setAnnotationSplitSymbol"], [128, 2, 1, "", "setCleanAnnotations"], [128, 2, 1, "", "setIncludeMetadata"], [128, 2, 1, "", "setInputCols"], [128, 2, 1, "", "setOutputAsArray"], [128, 2, 1, "", "setOutputCols"], [128, 2, 1, "", "setParseEmbeddingsVectors"], [128, 2, 1, "", "setValueSplitSymbol"]], "sparknlp.base.graph_finisher": [[129, 1, 1, "", "GraphFinisher"]], "sparknlp.base.graph_finisher.GraphFinisher": [[129, 2, 1, "", "setCleanAnnotations"], [129, 2, 1, "", "setInputCol"], [129, 2, 1, "", "setOutputAsArray"], [129, 2, 1, "", "setOutputCol"]], "sparknlp.base.has_recursive_fit": [[130, 1, 1, "", "HasRecursiveFit"]], "sparknlp.base.has_recursive_transform": [[131, 1, 1, "", "HasRecursiveTransform"]], "sparknlp.base.image_assembler": [[132, 1, 1, "", "ImageAssembler"]], "sparknlp.base.image_assembler.ImageAssembler": [[132, 2, 1, "", "getOutputCol"], [132, 2, 1, "", "setInputCol"], [132, 2, 1, "", "setOutputCol"]], "sparknlp.base.light_pipeline": [[134, 1, 1, "", "LightPipeline"]], "sparknlp.base.light_pipeline.LightPipeline": [[134, 2, 1, "", "annotate"], [134, 2, 1, "", "fullAnnotate"], [134, 2, 1, "", "fullAnnotateImage"], [134, 2, 1, "", "getIgnoreUnsupported"], [134, 2, 1, "", "setIgnoreUnsupported"], [134, 2, 1, "", "transform"]], "sparknlp.base.multi_document_assembler": [[135, 1, 1, "", "MultiDocumentAssembler"]], "sparknlp.base.multi_document_assembler.MultiDocumentAssembler": [[135, 2, 1, "", "getOutputCols"], [135, 2, 1, "", "setCleanupMode"], [135, 2, 1, "", "setIdCol"], [135, 2, 1, "", "setInputCols"], [135, 2, 1, "", "setMetadataCol"], [135, 2, 1, "", "setOutputCols"]], "sparknlp.base.recursive_pipeline": [[136, 1, 1, "", "RecursivePipeline"], [136, 1, 1, "", "RecursivePipelineModel"]], "sparknlp.base.table_assembler": [[137, 1, 1, "", "TableAssembler"]], "sparknlp.base.table_assembler.TableAssembler": [[137, 2, 1, "", "setCsvDelimiter"], [137, 2, 1, "", "setEscapeCsvDelimiter"], [137, 2, 1, "", "setInputFormat"]], "sparknlp.base.token2_chunk": [[138, 1, 1, "", "Token2Chunk"]], "sparknlp.base.token_assembler": [[139, 1, 1, "", "TokenAssembler"]], "sparknlp.base.token_assembler.TokenAssembler": [[139, 2, 1, "", "setPreservePosition"]], "sparknlp.common": [[140, 0, 0, "-", "annotator_approach"], [141, 0, 0, "-", "annotator_model"], [142, 0, 0, "-", "annotator_properties"], [143, 0, 0, "-", "annotator_type"], [144, 0, 0, "-", "coverage_result"], [146, 0, 0, "-", "properties"], [147, 0, 0, "-", "read_as"], [148, 0, 0, "-", "recursive_annotator_approach"], [149, 0, 0, "-", "storage"], [150, 0, 0, "-", "utils"]], "sparknlp.common.annotator_approach": [[140, 1, 1, "", "AnnotatorApproach"]], "sparknlp.common.annotator_model": [[141, 1, 1, "", "AnnotatorModel"]], "sparknlp.common.annotator_properties": [[142, 1, 1, "", "AnnotatorProperties"]], "sparknlp.common.annotator_properties.AnnotatorProperties": [[142, 2, 1, "", "getInputCols"], [142, 2, 1, "", "getLazyAnnotator"], [142, 2, 1, "", "getOutputCol"], [142, 2, 1, "", "setInputCols"], [142, 2, 1, "", "setLazyAnnotator"], [142, 2, 1, "", "setOutputCol"]], "sparknlp.common.properties": [[146, 1, 1, "", "HasEmbeddingsProperties"]], "sparknlp.common.properties.HasEmbeddingsProperties": [[146, 2, 1, "", "getDimension"], [146, 2, 1, "", "setDimension"]], "sparknlp.common.read_as": [[147, 1, 1, "", "ReadAs"]], "sparknlp.common.recursive_annotator_approach": [[148, 1, 1, "", "RecursiveAnnotatorApproach"]], "sparknlp.common.utils": [[150, 3, 1, "", "ExternalResource"]], "sparknlp.functions": [[151, 3, 1, "", "explode_annotations_col"], [151, 3, 1, "", "filter_by_annotations_col"], [151, 3, 1, "", "map_annotations"], [151, 3, 1, "", "map_annotations_array"], [151, 3, 1, "", "map_annotations_col"], [151, 3, 1, "", "map_annotations_cols"], [151, 3, 1, "", "map_annotations_strict"]], "sparknlp.internal": [[153, 0, 0, "-", "annotator_java_ml"], [154, 0, 0, "-", "annotator_transformer"], [155, 0, 0, "-", "extended_java_wrapper"], [157, 0, 0, "-", "params_getters_setters"], [158, 0, 0, "-", "recursive"]], "sparknlp.internal.annotator_java_ml": [[153, 1, 1, "", "AnnotatorJavaMLReadable"], [153, 1, 1, "", "AnnotatorJavaMLReader"]], "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable": [[153, 2, 1, "", "read"]], "sparknlp.internal.annotator_transformer": [[154, 1, 1, "", "AnnotatorTransformer"]], "sparknlp.internal.extended_java_wrapper": [[155, 1, 1, "", "ExtendedJavaWrapper"]], "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper": [[155, 2, 1, "", "new_java_array"]], "sparknlp.internal.params_getters_setters": [[157, 1, 1, "", "ParamsGettersSetters"]], "sparknlp.internal.params_getters_setters.ParamsGettersSetters": [[157, 2, 1, "", "getParamValue"], [157, 2, 1, "", "setParamValue"]], "sparknlp.internal.recursive": [[158, 1, 1, "", "RecursiveEstimator"], [158, 1, 1, "", "RecursiveTransformer"]], "sparknlp.internal.recursive.RecursiveEstimator": [[158, 2, 1, "", "fit"]], "sparknlp.logging": [[159, 0, 0, "-", "comet"]], "sparknlp.logging.comet": [[159, 1, 1, "", "CometLogger"]], "sparknlp.logging.comet.CometLogger": [[159, 2, 1, "", "end"], [159, 2, 1, "", "log_asset"], [159, 2, 1, "", "log_asset_data"], [159, 2, 1, "", "log_completed_run"], [159, 2, 1, "", "log_metrics"], [159, 2, 1, "", "log_parameters"], [159, 2, 1, "", "log_pipeline_parameters"], [159, 2, 1, "", "log_visualization"], [159, 2, 1, "", "monitor"]], "sparknlp.pretrained": [[162, 0, 0, "-", "pretrained_pipeline"], [163, 0, 0, "-", "resource_downloader"], [164, 0, 0, "-", "utils"]], "sparknlp.pretrained.pretrained_pipeline": [[162, 1, 1, "", "PretrainedPipeline"]], "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline": [[162, 2, 1, "", "annotate"], [162, 2, 1, "", "fullAnnotate"], [162, 2, 1, "", "fullAnnotateImage"], [162, 2, 1, "", "transform"]], "sparknlp.pretrained.resource_downloader": [[163, 1, 1, "", "ResourceDownloader"]], "sparknlp.pretrained.resource_downloader.ResourceDownloader": [[163, 2, 1, "", "clearCache"], [163, 2, 1, "", "downloadModel"], [163, 2, 1, "", "downloadModelDirectly"], [163, 2, 1, "", "downloadPipeline"], [163, 2, 1, "", "showAvailableAnnotators"], [163, 2, 1, "", "showPublicModels"], [163, 2, 1, "", "showPublicPipelines"], [163, 2, 1, "", "showUnCategorizedResources"]], "sparknlp.training": [[165, 0, 0, "-", "conll"], [166, 0, 0, "-", "conllu"], [168, 0, 0, "-", "pos"], [169, 0, 0, "-", "pub_tator"], [170, 0, 0, "-", "tfgraphs"]], "sparknlp.training.conll": [[165, 1, 1, "", "CoNLL"]], "sparknlp.training.conll.CoNLL": [[165, 2, 1, "", "readDataset"]], "sparknlp.training.conllu": [[166, 1, 1, "", "CoNLLU"]], "sparknlp.training.conllu.CoNLLU": [[166, 2, 1, "", "readDataset"]], "sparknlp.training.pos": [[168, 1, 1, "", "POS"]], "sparknlp.training.pos.POS": [[168, 2, 1, "", "readDataset"]], "sparknlp.training.pub_tator": [[169, 1, 1, "", "PubTator"]], "sparknlp.training.pub_tator.PubTator": [[169, 2, 1, "", "readDataset"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"get": [0, 179], "start": 0, "spark": [0, 1, 174, 179, 183], "nlp": [0, 1, 174, 183], "cheat": 0, "sheet": 0, "requir": 0, "instal": [0, 174], "us": [0, 174, 183], "conda": 0, "virtualenv": 0, "session": 0, "from": 0, "python": 0, "document": 1, "content": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169], "sparknlp": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172], "annot": [2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 177, 178, 179], "modul": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 150, 151, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169, 173], "class": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 146, 147, 148, 153, 154, 155, 157, 158, 159, 162, 163, 165, 166, 168, 169], "annotation_audio": 3, "annotation_imag": 4, "audio": [5, 6, 7], "hubert_for_ctc": 5, "submodul": [6, 25, 40, 42, 46, 58, 70, 72, 73, 75, 80, 85, 96, 98, 101, 105, 109, 116, 120, 133, 145, 152, 156, 160, 161, 167], "wav2vec2_for_ctc": 7, "chunker": 8, "classifier_dl": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "albert_for_question_answ": 9, "albert_for_sequence_classif": 10, "albert_for_token_classif": 11, "bert_for_question_answ": 12, "bert_for_sequence_classif": 13, "bert_for_token_classif": 14, "camembert_for_question_answ": 15, "camembert_for_sequence_classif": 16, "camembert_for_token_classif": 17, "deberta_for_question_answ": 19, "deberta_for_sequence_classif": 20, "deberta_for_token_classif": 21, "distil_bert_for_question_answ": 22, "distil_bert_for_sequence_classif": 23, "distil_bert_for_token_classif": 24, "longformer_for_question_answ": 26, "longformer_for_sequence_classif": 27, "longformer_for_token_classif": 28, "multi_classifier_dl": 29, "roberta_for_question_answ": 30, "roberta_for_sequence_classif": 31, "roberta_for_token_classif": 32, "sentiment_dl": 33, "tapas_for_question_answ": 34, "xlm_roberta_for_question_answ": 35, "xlm_roberta_for_sequence_classif": 36, "xlm_roberta_for_token_classif": 37, "xlnet_for_sequence_classif": 38, "xlnet_for_token_classif": 39, "coref": [40, 41], "spanbert_coref": 41, "cv": [42, 43, 44], "swin_for_image_classif": 43, "vit_for_image_classif": 44, "depend": [45, 46, 47], "dependency_pars": 45, "typed_dependency_pars": 47, "document_norm": 48, "embed": [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68], "albert_embed": 49, "bert_embed": 50, "bert_sentence_embed": 51, "camembert_embed": 52, "chunk_embed": 53, "deberta_embed": 54, "distil_bert_embed": 55, "doc2vec": 56, "elmo_embed": 57, "longformer_embed": 59, "roberta_embed": 60, "roberta_sentence_embed": 61, "sentence_embed": 62, "universal_sentence_encod": 63, "word2vec": 64, "word_embed": 65, "xlm_roberta_embed": 66, "xlm_roberta_sentence_embed": 67, "xlnet_embed": 68, "er": [69, 70], "entity_rul": 69, "graph_extract": 71, "subpackag": [72, 152], "keyword_extract": [73, 74], "yake_keyword_extract": 74, "ld_dl": [75, 76], "language_detector_dl": 76, "lemmat": 77, "matcher": [78, 79, 80, 81, 82, 83], "big_text_match": 78, "date_match": 79, "multi_date_match": 81, "regex_match": 82, "text_match": 83, "n_gram_gener": 84, "ner": [85, 86, 87, 88, 89, 90, 91], "ner_approach": 86, "ner_convert": 87, "ner_crf": 88, "ner_dl": 89, "ner_overwrit": 90, "zero_shot_ner_model": 91, "normal": 92, "param": [93, 94, 95], "classifier_encod": 93, "evaluation_dl_param": 94, "po": [96, 97, 168, 184], "perceptron": 97, "sentenc": [98, 99, 100, 179], "sentence_detector": 99, "sentence_detector_dl": 100, "sentiment": [101, 102, 103], "sentiment_detector": 102, "vivekn_senti": 103, "seq2seq": [104, 105, 106, 107], "gpt2_transform": 104, "marian_transform": 106, "t5_transform": 107, "spell_check": [108, 109, 110, 111], "context_spell_check": 108, "norvig_sweet": 110, "symmetric_delet": 111, "stemmer": 112, "stop_words_clean": 113, "tf_ner_dl_graph_build": 114, "token": [115, 116, 117, 118, 119, 179], "chunk_token": 115, "recursive_token": 117, "regex_token": 118, "w": [120, 121], "word_segment": 121, "base": [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139], "audio_assembl": 122, "chunk2_doc": 123, "date2_chunk": 124, "doc2_chunk": 125, "document_assembl": 126, "embeddings_finish": 127, "finish": [128, 179], "graph_finish": 129, "has_recursive_fit": 130, "has_recursive_transform": 131, "image_assembl": 132, "light_pipelin": 134, "multi_document_assembl": 135, "recursive_pipelin": 136, "table_assembl": 137, "token2_chunk": 138, "token_assembl": 139, "common": [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 178], "annotator_approach": 140, "annotator_model": 141, "annotator_properti": 142, "annotator_typ": 143, "coverage_result": 144, "properti": 146, "read_a": 147, "recursive_annotator_approach": 148, "storag": 149, "util": [150, 164, 172], "function": [150, 151, 152, 178, 180], "packag": 152, "intern": [153, 154, 155, 156, 157, 158], "annotator_java_ml": 153, "annotator_transform": 154, "extended_java_wrapp": 155, "params_getters_sett": 157, "recurs": 158, "log": [159, 160, 174, 176], "comet": [159, 174], "pretrain": [161, 162, 163, 164, 178, 182, 183], "pretrained_pipelin": 162, "resource_download": 163, "train": [165, 166, 167, 168, 169, 170, 184], "conll": [165, 184], "conllu": [166, 184], "pub_tat": 169, "tfgraph": 170, "upload_to_hub": 171, "api": 173, "refer": 173, "A": 174, "meta": 174, "machin": [174, 175], "learn": [174, 175], "platform": [174, 175], "pipelin": [174, 179, 182, 183], "paramet": 174, "evalu": 174, "metric": 174, "visual": 174, "run": 174, "an": 174, "offlin": 174, "experi": 174, "mlflow": 175, "lifecycl": 175, "third": 176, "parti": 176, "project": 176, "approach": 178, "model": 178, "note": 178, "avail": [178, 183], "set": 179, "up": 179, "your": 179, "own": 179, "type": 179, "necessari": 179, "import": 179, "construct": 179, "documentassembl": 179, "data": 179, "detect": 179, "out": 179, "put": 179, "all": 179, "togeth": 179, "ml": [179, 183], "helper": 180, "user": 181, "guid": 181, "light": 182, "convert": 182, "pipelinemodel": 182, "download": 183, "As": 183, "lightpipelin": 183, "load": 184, "dataset": 184, "spell": 184, "checker": 184, "pubtat": 184}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Getting Started": [[0, "getting-started"]], "Spark NLP Cheat Sheet": [[0, "spark-nlp-cheat-sheet"]], "Requirements": [[0, "requirements"]], "Installation": [[0, "installation"], [174, "installation"]], "Using Conda": [[0, "using-conda"]], "Using Virtualenv": [[0, "using-virtualenv"]], "Starting a Spark NLP Session from Python": [[0, "starting-a-spark-nlp-session-from-python"]], "Spark NLP Documentation": [[1, "spark-nlp-documentation"]], "Content": [[1, "content"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "Module Contents": [[2, "module-contents"], [3, "module-contents"], [4, "module-contents"], [5, "module-contents"], [7, "module-contents"], [8, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [29, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [41, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [50, "module-contents"], [51, "module-contents"], [52, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [71, "module-contents"], [74, "module-contents"], [76, "module-contents"], [77, "module-contents"], [78, "module-contents"], [79, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [86, "module-contents"], [87, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [97, "module-contents"], [99, "module-contents"], [100, "module-contents"], [102, "module-contents"], [103, "module-contents"], [104, "module-contents"], [106, "module-contents"], [107, "module-contents"], [108, "module-contents"], [110, "module-contents"], [111, "module-contents"], [112, "module-contents"], [113, "module-contents"], [114, "module-contents"], [115, "module-contents"], [117, "module-contents"], [118, "module-contents"], [119, "module-contents"], [121, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [130, "module-contents"], [131, "module-contents"], [132, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [146, "module-contents"], [147, "module-contents"], [148, "module-contents"], [150, "module-contents"], [151, "module-contents"], [153, "module-contents"], [154, "module-contents"], [155, "module-contents"], [157, "module-contents"], [158, "module-contents"], [159, "module-contents"], [162, "module-contents"], [163, "module-contents"], [165, "module-contents"], [166, "module-contents"], [168, "module-contents"], [169, "module-contents"]], "Classes": [[2, "classes"], [3, "classes"], [4, "classes"], [5, "classes"], [7, "classes"], [8, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [29, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [41, "classes"], [43, "classes"], [44, "classes"], [45, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [50, "classes"], [51, "classes"], [52, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [71, "classes"], [74, "classes"], [76, "classes"], [77, "classes"], [78, "classes"], [79, "classes"], [81, "classes"], [82, "classes"], [83, "classes"], [84, "classes"], [86, "classes"], [87, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [97, "classes"], [99, "classes"], [100, "classes"], [102, "classes"], [103, "classes"], [104, "classes"], [106, "classes"], [107, "classes"], [108, "classes"], [110, "classes"], [111, "classes"], [112, "classes"], [113, "classes"], [114, "classes"], [115, "classes"], [117, "classes"], [118, "classes"], [119, "classes"], [121, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [130, "classes"], [131, "classes"], [132, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [146, "classes"], [147, "classes"], [148, "classes"], [153, "classes"], [154, "classes"], [155, "classes"], [157, "classes"], [158, "classes"], [159, "classes"], [162, "classes"], [163, "classes"], [165, "classes"], [166, "classes"], [168, "classes"], [169, "classes"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "Submodules": [[6, "submodules"], [25, "submodules"], [40, "submodules"], [42, "submodules"], [46, "submodules"], [58, "submodules"], [70, "submodules"], [72, "submodules"], [73, "submodules"], [75, "submodules"], [80, "submodules"], [85, "submodules"], [96, "submodules"], [98, "submodules"], [101, "submodules"], [105, "submodules"], [109, "submodules"], [116, "submodules"], [120, "submodules"], [133, "submodules"], [145, "submodules"], [152, "submodules"], [156, "submodules"], [160, "submodules"], [161, "submodules"], [167, "submodules"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "sparknlp.annotator.chunker": [[8, "module-sparknlp.annotator.chunker"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[9, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[12, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[15, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[16, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[18, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[19, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[20, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[22, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[23, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[25, "module-sparknlp.annotator.classifier_dl"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[26, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[27, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[28, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[29, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[30, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[31, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[32, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[33, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[34, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[35, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[36, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[38, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[40, "module-sparknlp.annotator.coref"]], "sparknlp.annotator.coref.spanbert_coref": [[41, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv": [[42, "module-sparknlp.annotator.cv"]], "sparknlp.annotator.cv.swin_for_image_classification": [[43, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "sparknlp.annotator.cv.vit_for_image_classification": [[44, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "sparknlp.annotator.dependency.dependency_parser": [[45, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[46, "module-sparknlp.annotator.dependency"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[47, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "sparknlp.annotator.document_normalizer": [[48, "module-sparknlp.annotator.document_normalizer"]], "sparknlp.annotator.embeddings.albert_embeddings": [[49, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "sparknlp.annotator.embeddings.bert_embeddings": [[50, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[51, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[52, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[53, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[54, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[55, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "sparknlp.annotator.embeddings.doc2vec": [[56, "module-sparknlp.annotator.embeddings.doc2vec"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[57, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[58, "module-sparknlp.annotator.embeddings"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[59, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[60, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[61, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[62, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[63, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "sparknlp.annotator.embeddings.word2vec": [[64, "module-sparknlp.annotator.embeddings.word2vec"]], "sparknlp.annotator.embeddings.word_embeddings": [[65, "module-sparknlp.annotator.embeddings.word_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[66, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[67, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[68, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "sparknlp.annotator.er.entity_ruler": [[69, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[70, "module-sparknlp.annotator.er"]], "sparknlp.annotator.graph_extraction": [[71, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[72, "module-sparknlp.annotator"]], "Subpackages": [[72, "subpackages"], [152, "subpackages"]], "sparknlp.annotator.keyword_extraction": [[73, "module-sparknlp.annotator.keyword_extraction"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[74, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[75, "module-sparknlp.annotator.ld_dl"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[76, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "sparknlp.annotator.lemmatizer": [[77, "module-sparknlp.annotator.lemmatizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[78, "module-sparknlp.annotator.matcher.big_text_matcher"]], "sparknlp.annotator.matcher.date_matcher": [[79, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[80, "module-sparknlp.annotator.matcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[81, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "sparknlp.annotator.matcher.regex_matcher": [[82, "module-sparknlp.annotator.matcher.regex_matcher"]], "sparknlp.annotator.matcher.text_matcher": [[83, "module-sparknlp.annotator.matcher.text_matcher"]], "sparknlp.annotator.n_gram_generator": [[84, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[85, "module-sparknlp.annotator.ner"]], "sparknlp.annotator.ner.ner_approach": [[86, "module-sparknlp.annotator.ner.ner_approach"]], "sparknlp.annotator.ner.ner_converter": [[87, "module-sparknlp.annotator.ner.ner_converter"]], "sparknlp.annotator.ner.ner_crf": [[88, "module-sparknlp.annotator.ner.ner_crf"]], "sparknlp.annotator.ner.ner_dl": [[89, "module-sparknlp.annotator.ner.ner_dl"]], "sparknlp.annotator.ner.ner_overwriter": [[90, "module-sparknlp.annotator.ner.ner_overwriter"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[91, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "sparknlp.annotator.normalizer": [[92, "module-sparknlp.annotator.normalizer"]], "sparknlp.annotator.param.classifier_encoder": [[93, "module-sparknlp.annotator.param.classifier_encoder"]], "sparknlp.annotator.param.evaluation_dl_params": [[94, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[95, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[96, "module-sparknlp.annotator.pos"]], "sparknlp.annotator.pos.perceptron": [[97, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[98, "module-sparknlp.annotator.sentence"]], "sparknlp.annotator.sentence.sentence_detector": [[99, "module-sparknlp.annotator.sentence.sentence_detector"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[100, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[101, "module-sparknlp.annotator.sentiment"]], "sparknlp.annotator.sentiment.sentiment_detector": [[102, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[103, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[104, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[105, "module-sparknlp.annotator.seq2seq"]], "sparknlp.annotator.seq2seq.marian_transformer": [[106, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "sparknlp.annotator.seq2seq.t5_transformer": [[107, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "sparknlp.annotator.spell_check.context_spell_checker": [[108, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "sparknlp.annotator.spell_check": [[109, "module-sparknlp.annotator.spell_check"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[110, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "sparknlp.annotator.spell_check.symmetric_delete": [[111, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "sparknlp.annotator.stemmer": [[112, "module-sparknlp.annotator.stemmer"]], "sparknlp.annotator.stop_words_cleaner": [[113, "module-sparknlp.annotator.stop_words_cleaner"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[114, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "sparknlp.annotator.token.chunk_tokenizer": [[115, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[116, "module-sparknlp.annotator.token"]], "sparknlp.annotator.token.recursive_tokenizer": [[117, "module-sparknlp.annotator.token.recursive_tokenizer"]], "sparknlp.annotator.token.regex_tokenizer": [[118, "module-sparknlp.annotator.token.regex_tokenizer"]], "sparknlp.annotator.token.tokenizer": [[119, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[120, "module-sparknlp.annotator.ws"]], "sparknlp.annotator.ws.word_segmenter": [[121, "module-sparknlp.annotator.ws.word_segmenter"]], "sparknlp.base.audio_assembler": [[122, "module-sparknlp.base.audio_assembler"]], "sparknlp.base.chunk2_doc": [[123, "module-sparknlp.base.chunk2_doc"]], "sparknlp.base.date2_chunk": [[124, "module-sparknlp.base.date2_chunk"]], "sparknlp.base.doc2_chunk": [[125, "module-sparknlp.base.doc2_chunk"]], "sparknlp.base.document_assembler": [[126, "module-sparknlp.base.document_assembler"]], "sparknlp.base.embeddings_finisher": [[127, "module-sparknlp.base.embeddings_finisher"]], "sparknlp.base.finisher": [[128, "module-sparknlp.base.finisher"]], "sparknlp.base.graph_finisher": [[129, "module-sparknlp.base.graph_finisher"]], "sparknlp.base.has_recursive_fit": [[130, "module-sparknlp.base.has_recursive_fit"]], "sparknlp.base.has_recursive_transform": [[131, "module-sparknlp.base.has_recursive_transform"]], "sparknlp.base.image_assembler": [[132, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[133, "module-sparknlp.base"]], "sparknlp.base.light_pipeline": [[134, "module-sparknlp.base.light_pipeline"]], "sparknlp.base.multi_document_assembler": [[135, "module-sparknlp.base.multi_document_assembler"]], "sparknlp.base.recursive_pipeline": [[136, "module-sparknlp.base.recursive_pipeline"]], "sparknlp.base.table_assembler": [[137, "module-sparknlp.base.table_assembler"]], "sparknlp.base.token2_chunk": [[138, "module-sparknlp.base.token2_chunk"]], "sparknlp.base.token_assembler": [[139, "module-sparknlp.base.token_assembler"]], "sparknlp.common.annotator_approach": [[140, "module-sparknlp.common.annotator_approach"]], "sparknlp.common.annotator_model": [[141, "module-sparknlp.common.annotator_model"]], "sparknlp.common.annotator_properties": [[142, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[143, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[144, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[145, "module-sparknlp.common"]], "sparknlp.common.properties": [[146, "module-sparknlp.common.properties"]], "sparknlp.common.read_as": [[147, "module-sparknlp.common.read_as"]], "sparknlp.common.recursive_annotator_approach": [[148, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[149, "module-sparknlp.common.storage"]], "sparknlp.common.utils": [[150, "module-sparknlp.common.utils"]], "Functions": [[150, "functions"], [151, "functions"], [152, "functions"]], "sparknlp.functions": [[151, "module-sparknlp.functions"]], "sparknlp": [[152, "module-sparknlp"]], "Package Contents": [[152, "package-contents"]], "sparknlp.internal.annotator_java_ml": [[153, "module-sparknlp.internal.annotator_java_ml"]], "sparknlp.internal.annotator_transformer": [[154, "module-sparknlp.internal.annotator_transformer"]], "sparknlp.internal.extended_java_wrapper": [[155, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[156, "module-sparknlp.internal"]], "sparknlp.internal.params_getters_setters": [[157, "module-sparknlp.internal.params_getters_setters"]], "sparknlp.internal.recursive": [[158, "module-sparknlp.internal.recursive"]], "sparknlp.logging.comet": [[159, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[160, "module-sparknlp.logging"]], "sparknlp.pretrained": [[161, "module-sparknlp.pretrained"]], "sparknlp.pretrained.pretrained_pipeline": [[162, "module-sparknlp.pretrained.pretrained_pipeline"]], "sparknlp.pretrained.resource_downloader": [[163, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[164, "module-sparknlp.pretrained.utils"]], "sparknlp.training.conll": [[165, "module-sparknlp.training.conll"]], "sparknlp.training.conllu": [[166, "module-sparknlp.training.conllu"]], "sparknlp.training": [[167, "module-sparknlp.training"]], "sparknlp.training.pos": [[168, "module-sparknlp.training.pos"]], "sparknlp.training.pub_tator": [[169, "module-sparknlp.training.pub_tator"]], "sparknlp.training.tfgraphs": [[170, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[171, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[172, "module-sparknlp.util"]], "API Reference": [[173, "api-reference"]], "Modules": [[173, "modules"]], "Comet - A meta machine learning platform": [[174, "comet-a-meta-machine-learning-platform"]], "Using Comet with Spark NLP": [[174, "using-comet-with-spark-nlp"]], "Logging Pipeline Parameters": [[174, "logging-pipeline-parameters"]], "Logging Evaluation Metrics": [[174, "logging-evaluation-metrics"]], "Logging Visualizations": [[174, "logging-visualizations"]], "Running An Offline Experiment": [[174, "running-an-offline-experiment"]], "MLflow - a platform for the machine learning lifecycle": [[175, "mlflow-a-platform-for-the-machine-learning-lifecycle"]], "Third Party Projects": [[176, "third-party-projects"]], "Logging": [[176, "logging"]], "Annotation": [[177, "annotation"]], "Annotators": [[178, "annotators"]], "Annotator Approaches": [[178, "annotator-approaches"]], "Annotator Models": [[178, "annotator-models"]], "Note": [[178, "note"]], "Pretrained Models": [[178, "pretrained-models"]], "Common Functions": [[178, "common-functions"]], "Available Annotators": [[178, "available-annotators"]], "Setting up your own pipeline": [[179, "setting-up-your-own-pipeline"]], "Annotator types": [[179, "annotator-types"]], "Necessary imports": [[179, "necessary-imports"]], "Constructing the Pipeline": [[179, "constructing-the-pipeline"]], "DocumentAssembler: Getting data in": [[179, "documentassembler-getting-data-in"]], "Sentence detection and tokenization": [[179, "sentence-detection-and-tokenization"]], "Finisher: Getting data out": [[179, "finisher-getting-data-out"]], "Putting it all together as a Spark ML Pipeline": [[179, "putting-it-all-together-as-a-spark-ml-pipeline"]], "Helper Functions": [[180, "helper-functions"]], "User Guide": [[181, "user-guide"]], "Light Pipelines": [[182, "light-pipelines"]], "Converting PipelineModels": [[182, "converting-pipelinemodels"]], "Pretrained Light Pipelines": [[182, "pretrained-light-pipelines"]], "Pretrained Pipelines": [[183, "pretrained-pipelines"]], "Downloading and using a pretrained pipeline": [[183, "downloading-and-using-a-pretrained-pipeline"]], "As a Spark ML Pipeline": [[183, "as-a-spark-ml-pipeline"]], "As a Spark NLP LightPipeline": [[183, "as-a-spark-nlp-lightpipeline"]], "Available Pipelines": [[183, "available-pipelines"]], "Loading datasets for training": [[184, "loading-datasets-for-training"]], "POS Dataset": [[184, "pos-dataset"]], "CoNLL Dataset": [[184, "conll-dataset"]], "CoNLLU Dataset": [[184, "conllu-dataset"]], "Spell Checkers Dataset": [[184, "spell-checkers-dataset"]], "PubTator Dataset": [[184, "pubtator-dataset"]]}, "indexentries": {"annotation (class in sparknlp.annotation)": [[2, "sparknlp.annotation.Annotation"]], "arraytype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.arrayType"]], "copy() (annotation method)": [[2, "sparknlp.annotation.Annotation.copy"]], "datatype() (annotation static method)": [[2, "sparknlp.annotation.Annotation.dataType"]], "fromrow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.fromRow"]], "module": [[2, "module-sparknlp.annotation"], [3, "module-sparknlp.annotation_audio"], [4, "module-sparknlp.annotation_image"], [5, "module-sparknlp.annotator.audio.hubert_for_ctc"], [6, "module-sparknlp.annotator.audio"], [7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"], [8, "module-sparknlp.annotator.chunker"], [9, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"], [10, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"], [11, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"], [12, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"], [13, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"], [14, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"], [15, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"], [16, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"], [17, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"], [18, "module-sparknlp.annotator.classifier_dl.classifier_dl"], [19, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"], [20, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"], [21, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"], [22, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"], [23, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"], [24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"], [25, "module-sparknlp.annotator.classifier_dl"], [26, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"], [27, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"], [28, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"], [29, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"], [30, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"], [31, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"], [32, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"], [33, "module-sparknlp.annotator.classifier_dl.sentiment_dl"], [34, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"], [35, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"], [36, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"], [37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"], [38, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"], [39, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"], [40, "module-sparknlp.annotator.coref"], [41, "module-sparknlp.annotator.coref.spanbert_coref"], [42, "module-sparknlp.annotator.cv"], [43, "module-sparknlp.annotator.cv.swin_for_image_classification"], [44, "module-sparknlp.annotator.cv.vit_for_image_classification"], [45, "module-sparknlp.annotator.dependency.dependency_parser"], [46, "module-sparknlp.annotator.dependency"], [47, "module-sparknlp.annotator.dependency.typed_dependency_parser"], [48, "module-sparknlp.annotator.document_normalizer"], [49, "module-sparknlp.annotator.embeddings.albert_embeddings"], [50, "module-sparknlp.annotator.embeddings.bert_embeddings"], [51, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"], [52, "module-sparknlp.annotator.embeddings.camembert_embeddings"], [53, "module-sparknlp.annotator.embeddings.chunk_embeddings"], [54, "module-sparknlp.annotator.embeddings.deberta_embeddings"], [55, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"], [56, "module-sparknlp.annotator.embeddings.doc2vec"], [57, "module-sparknlp.annotator.embeddings.elmo_embeddings"], [58, "module-sparknlp.annotator.embeddings"], [59, "module-sparknlp.annotator.embeddings.longformer_embeddings"], [60, "module-sparknlp.annotator.embeddings.roberta_embeddings"], [61, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"], [62, "module-sparknlp.annotator.embeddings.sentence_embeddings"], [63, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"], [64, "module-sparknlp.annotator.embeddings.word2vec"], [65, "module-sparknlp.annotator.embeddings.word_embeddings"], [66, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"], [67, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"], [68, "module-sparknlp.annotator.embeddings.xlnet_embeddings"], [69, "module-sparknlp.annotator.er.entity_ruler"], [70, "module-sparknlp.annotator.er"], [71, "module-sparknlp.annotator.graph_extraction"], [72, "module-sparknlp.annotator"], [73, "module-sparknlp.annotator.keyword_extraction"], [74, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"], [75, "module-sparknlp.annotator.ld_dl"], [76, "module-sparknlp.annotator.ld_dl.language_detector_dl"], [77, "module-sparknlp.annotator.lemmatizer"], [78, "module-sparknlp.annotator.matcher.big_text_matcher"], [79, "module-sparknlp.annotator.matcher.date_matcher"], [80, "module-sparknlp.annotator.matcher"], [81, "module-sparknlp.annotator.matcher.multi_date_matcher"], [82, "module-sparknlp.annotator.matcher.regex_matcher"], [83, "module-sparknlp.annotator.matcher.text_matcher"], [84, "module-sparknlp.annotator.n_gram_generator"], [85, "module-sparknlp.annotator.ner"], [86, "module-sparknlp.annotator.ner.ner_approach"], [87, "module-sparknlp.annotator.ner.ner_converter"], [88, "module-sparknlp.annotator.ner.ner_crf"], [89, "module-sparknlp.annotator.ner.ner_dl"], [90, "module-sparknlp.annotator.ner.ner_overwriter"], [91, "module-sparknlp.annotator.ner.zero_shot_ner_model"], [92, "module-sparknlp.annotator.normalizer"], [93, "module-sparknlp.annotator.param.classifier_encoder"], [94, "module-sparknlp.annotator.param.evaluation_dl_params"], [95, "module-sparknlp.annotator.param"], [96, "module-sparknlp.annotator.pos"], [97, "module-sparknlp.annotator.pos.perceptron"], [98, "module-sparknlp.annotator.sentence"], [99, "module-sparknlp.annotator.sentence.sentence_detector"], [100, "module-sparknlp.annotator.sentence.sentence_detector_dl"], [101, "module-sparknlp.annotator.sentiment"], [102, "module-sparknlp.annotator.sentiment.sentiment_detector"], [103, "module-sparknlp.annotator.sentiment.vivekn_sentiment"], [104, "module-sparknlp.annotator.seq2seq.gpt2_transformer"], [105, "module-sparknlp.annotator.seq2seq"], [106, "module-sparknlp.annotator.seq2seq.marian_transformer"], [107, "module-sparknlp.annotator.seq2seq.t5_transformer"], [108, "module-sparknlp.annotator.spell_check.context_spell_checker"], [109, "module-sparknlp.annotator.spell_check"], [110, "module-sparknlp.annotator.spell_check.norvig_sweeting"], [111, "module-sparknlp.annotator.spell_check.symmetric_delete"], [112, "module-sparknlp.annotator.stemmer"], [113, "module-sparknlp.annotator.stop_words_cleaner"], [114, "module-sparknlp.annotator.tf_ner_dl_graph_builder"], [115, "module-sparknlp.annotator.token.chunk_tokenizer"], [116, "module-sparknlp.annotator.token"], [117, "module-sparknlp.annotator.token.recursive_tokenizer"], [118, "module-sparknlp.annotator.token.regex_tokenizer"], [119, "module-sparknlp.annotator.token.tokenizer"], [120, "module-sparknlp.annotator.ws"], [121, "module-sparknlp.annotator.ws.word_segmenter"], [122, "module-sparknlp.base.audio_assembler"], [123, "module-sparknlp.base.chunk2_doc"], [124, "module-sparknlp.base.date2_chunk"], [125, "module-sparknlp.base.doc2_chunk"], [126, "module-sparknlp.base.document_assembler"], [127, "module-sparknlp.base.embeddings_finisher"], [128, "module-sparknlp.base.finisher"], [129, "module-sparknlp.base.graph_finisher"], [130, "module-sparknlp.base.has_recursive_fit"], [131, "module-sparknlp.base.has_recursive_transform"], [132, "module-sparknlp.base.image_assembler"], [133, "module-sparknlp.base"], [134, "module-sparknlp.base.light_pipeline"], [135, "module-sparknlp.base.multi_document_assembler"], [136, "module-sparknlp.base.recursive_pipeline"], [137, "module-sparknlp.base.table_assembler"], [138, "module-sparknlp.base.token2_chunk"], [139, "module-sparknlp.base.token_assembler"], [140, "module-sparknlp.common.annotator_approach"], [141, "module-sparknlp.common.annotator_model"], [142, "module-sparknlp.common.annotator_properties"], [143, "module-sparknlp.common.annotator_type"], [144, "module-sparknlp.common.coverage_result"], [145, "module-sparknlp.common"], [146, "module-sparknlp.common.properties"], [147, "module-sparknlp.common.read_as"], [148, "module-sparknlp.common.recursive_annotator_approach"], [149, "module-sparknlp.common.storage"], [150, "module-sparknlp.common.utils"], [151, "module-sparknlp.functions"], [152, "module-sparknlp"], [153, "module-sparknlp.internal.annotator_java_ml"], [154, "module-sparknlp.internal.annotator_transformer"], [155, "module-sparknlp.internal.extended_java_wrapper"], [156, "module-sparknlp.internal"], [157, "module-sparknlp.internal.params_getters_setters"], [158, "module-sparknlp.internal.recursive"], [159, "module-sparknlp.logging.comet"], [160, "module-sparknlp.logging"], [161, "module-sparknlp.pretrained"], [162, "module-sparknlp.pretrained.pretrained_pipeline"], [163, "module-sparknlp.pretrained.resource_downloader"], [164, "module-sparknlp.pretrained.utils"], [165, "module-sparknlp.training.conll"], [166, "module-sparknlp.training.conllu"], [167, "module-sparknlp.training"], [168, "module-sparknlp.training.pos"], [169, "module-sparknlp.training.pub_tator"], [170, "module-sparknlp.training.tfgraphs"], [171, "module-sparknlp.upload_to_hub"], [172, "module-sparknlp.util"]], "sparknlp.annotation": [[2, "module-sparknlp.annotation"]], "torow() (annotation static method)": [[2, "sparknlp.annotation.Annotation.toRow"]], "annotationaudio (class in sparknlp.annotation_audio)": [[3, "sparknlp.annotation_audio.AnnotationAudio"]], "copy() (annotationaudio method)": [[3, "sparknlp.annotation_audio.AnnotationAudio.copy"]], "sparknlp.annotation_audio": [[3, "module-sparknlp.annotation_audio"]], "annotationimage (class in sparknlp.annotation_image)": [[4, "sparknlp.annotation_image.AnnotationImage"]], "copy() (annotationimage method)": [[4, "sparknlp.annotation_image.AnnotationImage.copy"]], "sparknlp.annotation_image": [[4, "module-sparknlp.annotation_image"]], "hubertforctc (class in sparknlp.annotator.audio.hubert_for_ctc)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC"]], "loadsavedmodel() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.loadSavedModel"]], "pretrained() (hubertforctc static method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.pretrained"]], "setconfigprotobytes() (hubertforctc method)": [[5, "sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.hubert_for_ctc": [[5, "module-sparknlp.annotator.audio.hubert_for_ctc"]], "sparknlp.annotator.audio": [[6, "module-sparknlp.annotator.audio"]], "wav2vec2forctc (class in sparknlp.annotator.audio.wav2vec2_for_ctc)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC"]], "loadsavedmodel() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.loadSavedModel"]], "pretrained() (wav2vec2forctc static method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.pretrained"]], "setconfigprotobytes() (wav2vec2forctc method)": [[7, "sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC.setConfigProtoBytes"]], "sparknlp.annotator.audio.wav2vec2_for_ctc": [[7, "module-sparknlp.annotator.audio.wav2vec2_for_ctc"]], "chunker (class in sparknlp.annotator.chunker)": [[8, "sparknlp.annotator.chunker.Chunker"]], "setregexparsers() (chunker method)": [[8, "sparknlp.annotator.chunker.Chunker.setRegexParsers"]], "sparknlp.annotator.chunker": [[8, "module-sparknlp.annotator.chunker"]], "albertforquestionanswering (class in sparknlp.annotator.classifier_dl.albert_for_question_answering)": [[9, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering"]], "loadsavedmodel() (albertforquestionanswering static method)": [[9, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.loadSavedModel"]], "pretrained() (albertforquestionanswering static method)": [[9, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (albertforquestionanswering method)": [[9, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (albertforquestionanswering method)": [[9, "sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_question_answering": [[9, "module-sparknlp.annotator.classifier_dl.albert_for_question_answering"]], "albertforsequenceclassification (class in sparknlp.annotator.classifier_dl.albert_for_sequence_classification)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification"]], "getclasses() (albertforsequenceclassification method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.getClasses"]], "loadsavedmodel() (albertforsequenceclassification static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.loadSavedModel"]], "pretrained() (albertforsequenceclassification static method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.pretrained"]], "setcoalescesentences() (albertforsequenceclassification method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (albertforsequenceclassification method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertforsequenceclassification method)": [[10, "sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_sequence_classification": [[10, "module-sparknlp.annotator.classifier_dl.albert_for_sequence_classification"]], "albertfortokenclassification (class in sparknlp.annotator.classifier_dl.albert_for_token_classification)": [[11, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification"]], "getclasses() (albertfortokenclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.getClasses"]], "loadsavedmodel() (albertfortokenclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.loadSavedModel"]], "pretrained() (albertfortokenclassification static method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.pretrained"]], "setconfigprotobytes() (albertfortokenclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (albertfortokenclassification method)": [[11, "sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.albert_for_token_classification": [[11, "module-sparknlp.annotator.classifier_dl.albert_for_token_classification"]], "bertforquestionanswering (class in sparknlp.annotator.classifier_dl.bert_for_question_answering)": [[12, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering"]], "loadsavedmodel() (bertforquestionanswering static method)": [[12, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.loadSavedModel"]], "pretrained() (bertforquestionanswering static method)": [[12, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (bertforquestionanswering method)": [[12, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (bertforquestionanswering method)": [[12, "sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_question_answering": [[12, "module-sparknlp.annotator.classifier_dl.bert_for_question_answering"]], "bertforsequenceclassification (class in sparknlp.annotator.classifier_dl.bert_for_sequence_classification)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification"]], "getclasses() (bertforsequenceclassification method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.getClasses"]], "loadsavedmodel() (bertforsequenceclassification static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.loadSavedModel"]], "pretrained() (bertforsequenceclassification static method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.pretrained"]], "setcoalescesentences() (bertforsequenceclassification method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (bertforsequenceclassification method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertforsequenceclassification method)": [[13, "sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_sequence_classification": [[13, "module-sparknlp.annotator.classifier_dl.bert_for_sequence_classification"]], "bertfortokenclassification (class in sparknlp.annotator.classifier_dl.bert_for_token_classification)": [[14, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification"]], "getclasses() (bertfortokenclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.getClasses"]], "loadsavedmodel() (bertfortokenclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.loadSavedModel"]], "pretrained() (bertfortokenclassification static method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.pretrained"]], "setconfigprotobytes() (bertfortokenclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (bertfortokenclassification method)": [[14, "sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.bert_for_token_classification": [[14, "module-sparknlp.annotator.classifier_dl.bert_for_token_classification"]], "camembertforquestionanswering (class in sparknlp.annotator.classifier_dl.camembert_for_question_answering)": [[15, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering"]], "loadsavedmodel() (camembertforquestionanswering static method)": [[15, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.loadSavedModel"]], "pretrained() (camembertforquestionanswering static method)": [[15, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (camembertforquestionanswering method)": [[15, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforquestionanswering method)": [[15, "sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_question_answering": [[15, "module-sparknlp.annotator.classifier_dl.camembert_for_question_answering"]], "camembertforsequenceclassification (class in sparknlp.annotator.classifier_dl.camembert_for_sequence_classification)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification"]], "getclasses() (camembertforsequenceclassification method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.getClasses"]], "loadsavedmodel() (camembertforsequenceclassification static method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.loadSavedModel"]], "pretrained() (camembertforsequenceclassification static method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.pretrained"]], "setcoalescesentences() (camembertforsequenceclassification method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (camembertforsequenceclassification method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertforsequenceclassification method)": [[16, "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_sequence_classification": [[16, "module-sparknlp.annotator.classifier_dl.camembert_for_sequence_classification"]], "camembertfortokenclassification (class in sparknlp.annotator.classifier_dl.camembert_for_token_classification)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification"]], "getclasses() (camembertfortokenclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.getClasses"]], "loadsavedmodel() (camembertfortokenclassification static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.loadSavedModel"]], "pretrained() (camembertfortokenclassification static method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.pretrained"]], "setconfigprotobytes() (camembertfortokenclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (camembertfortokenclassification method)": [[17, "sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.camembert_for_token_classification": [[17, "module-sparknlp.annotator.classifier_dl.camembert_for_token_classification"]], "classifierdlapproach (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[18, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach"]], "classifierdlmodel (class in sparknlp.annotator.classifier_dl.classifier_dl)": [[18, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel"]], "pretrained() (classifierdlmodel static method)": [[18, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.pretrained"]], "setconfigprotobytes() (classifierdlmodel method)": [[18, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel.setConfigProtoBytes"]], "setdropout() (classifierdlapproach method)": [[18, "sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach.setDropout"]], "sparknlp.annotator.classifier_dl.classifier_dl": [[18, "module-sparknlp.annotator.classifier_dl.classifier_dl"]], "debertaforquestionanswering (class in sparknlp.annotator.classifier_dl.deberta_for_question_answering)": [[19, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering"]], "loadsavedmodel() (debertaforquestionanswering static method)": [[19, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (debertaforquestionanswering static method)": [[19, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (debertaforquestionanswering method)": [[19, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforquestionanswering method)": [[19, "sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_question_answering": [[19, "module-sparknlp.annotator.classifier_dl.deberta_for_question_answering"]], "debertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.deberta_for_sequence_classification)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification"]], "getclasses() (debertaforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (debertaforsequenceclassification static method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.loadSavedModel"]], "pretrained() (debertaforsequenceclassification static method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (debertaforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (debertaforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertaforsequenceclassification method)": [[20, "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_sequence_classification": [[20, "module-sparknlp.annotator.classifier_dl.deberta_for_sequence_classification"]], "debertafortokenclassification (class in sparknlp.annotator.classifier_dl.deberta_for_token_classification)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification"]], "getclasses() (debertafortokenclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.getClasses"]], "loadsavedmodel() (debertafortokenclassification static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.loadSavedModel"]], "pretrained() (debertafortokenclassification static method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (debertafortokenclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (debertafortokenclassification method)": [[21, "sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.deberta_for_token_classification": [[21, "module-sparknlp.annotator.classifier_dl.deberta_for_token_classification"]], "distilbertforquestionanswering (class in sparknlp.annotator.classifier_dl.distil_bert_for_question_answering)": [[22, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering"]], "loadsavedmodel() (distilbertforquestionanswering static method)": [[22, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.loadSavedModel"]], "pretrained() (distilbertforquestionanswering static method)": [[22, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.pretrained"]], "setconfigprotobytes() (distilbertforquestionanswering method)": [[22, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforquestionanswering method)": [[22, "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_question_answering": [[22, "module-sparknlp.annotator.classifier_dl.distil_bert_for_question_answering"]], "distilbertforsequenceclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification"]], "getclasses() (distilbertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.getClasses"]], "loadsavedmodel() (distilbertforsequenceclassification static method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.loadSavedModel"]], "pretrained() (distilbertforsequenceclassification static method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.pretrained"]], "setcoalescesentences() (distilbertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (distilbertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertforsequenceclassification method)": [[23, "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification": [[23, "module-sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification"]], "distilbertfortokenclassification (class in sparknlp.annotator.classifier_dl.distil_bert_for_token_classification)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification"]], "getclasses() (distilbertfortokenclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.getClasses"]], "loadsavedmodel() (distilbertfortokenclassification static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.loadSavedModel"]], "pretrained() (distilbertfortokenclassification static method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.pretrained"]], "setconfigprotobytes() (distilbertfortokenclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertfortokenclassification method)": [[24, "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.distil_bert_for_token_classification": [[24, "module-sparknlp.annotator.classifier_dl.distil_bert_for_token_classification"]], "sparknlp.annotator.classifier_dl": [[25, "module-sparknlp.annotator.classifier_dl"]], "longformerforquestionanswering (class in sparknlp.annotator.classifier_dl.longformer_for_question_answering)": [[26, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering"]], "loadsavedmodel() (longformerforquestionanswering static method)": [[26, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.loadSavedModel"]], "pretrained() (longformerforquestionanswering static method)": [[26, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.pretrained"]], "setconfigprotobytes() (longformerforquestionanswering method)": [[26, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforquestionanswering method)": [[26, "sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_question_answering": [[26, "module-sparknlp.annotator.classifier_dl.longformer_for_question_answering"]], "longformerforsequenceclassification (class in sparknlp.annotator.classifier_dl.longformer_for_sequence_classification)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification"]], "getclasses() (longformerforsequenceclassification method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.getClasses"]], "loadsavedmodel() (longformerforsequenceclassification static method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.loadSavedModel"]], "pretrained() (longformerforsequenceclassification static method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.pretrained"]], "setcoalescesentences() (longformerforsequenceclassification method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (longformerforsequenceclassification method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerforsequenceclassification method)": [[27, "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_sequence_classification": [[27, "module-sparknlp.annotator.classifier_dl.longformer_for_sequence_classification"]], "longformerfortokenclassification (class in sparknlp.annotator.classifier_dl.longformer_for_token_classification)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification"]], "getclasses() (longformerfortokenclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.getClasses"]], "loadsavedmodel() (longformerfortokenclassification static method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.loadSavedModel"]], "pretrained() (longformerfortokenclassification static method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.pretrained"]], "setconfigprotobytes() (longformerfortokenclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (longformerfortokenclassification method)": [[28, "sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.longformer_for_token_classification": [[28, "module-sparknlp.annotator.classifier_dl.longformer_for_token_classification"]], "multiclassifierdlapproach (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach"]], "multiclassifierdlmodel (class in sparknlp.annotator.classifier_dl.multi_classifier_dl)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel"]], "pretrained() (multiclassifierdlmodel static method)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.pretrained"]], "setconfigprotobytes() (multiclassifierdlmodel method)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setConfigProtoBytes"]], "setthreshold() (multiclassifierdlapproach method)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setThreshold"]], "setthreshold() (multiclassifierdlmodel method)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel.setThreshold"]], "setverbose() (multiclassifierdlapproach method)": [[29, "sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach.setVerbose"]], "sparknlp.annotator.classifier_dl.multi_classifier_dl": [[29, "module-sparknlp.annotator.classifier_dl.multi_classifier_dl"]], "robertaforquestionanswering (class in sparknlp.annotator.classifier_dl.roberta_for_question_answering)": [[30, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering"]], "loadsavedmodel() (robertaforquestionanswering static method)": [[30, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (robertaforquestionanswering static method)": [[30, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (robertaforquestionanswering method)": [[30, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforquestionanswering method)": [[30, "sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_question_answering": [[30, "module-sparknlp.annotator.classifier_dl.roberta_for_question_answering"]], "robertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.roberta_for_sequence_classification)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification"]], "getclasses() (robertaforsequenceclassification method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (robertaforsequenceclassification static method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (robertaforsequenceclassification static method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (robertaforsequenceclassification method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (robertaforsequenceclassification method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertaforsequenceclassification method)": [[31, "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_sequence_classification": [[31, "module-sparknlp.annotator.classifier_dl.roberta_for_sequence_classification"]], "robertafortokenclassification (class in sparknlp.annotator.classifier_dl.roberta_for_token_classification)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification"]], "getclasses() (robertafortokenclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (robertafortokenclassification static method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.loadSavedModel"]], "pretrained() (robertafortokenclassification static method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (robertafortokenclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (robertafortokenclassification method)": [[32, "sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.roberta_for_token_classification": [[32, "module-sparknlp.annotator.classifier_dl.roberta_for_token_classification"]], "sentimentdlapproach (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach"]], "sentimentdlmodel (class in sparknlp.annotator.classifier_dl.sentiment_dl)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel"]], "pretrained() (sentimentdlmodel static method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.pretrained"]], "setconfigprotobytes() (sentimentdlmodel method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setConfigProtoBytes"]], "setdropout() (sentimentdlapproach method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setDropout"]], "setthreshold() (sentimentdlapproach method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThreshold"]], "setthreshold() (sentimentdlmodel method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThreshold"]], "setthresholdlabel() (sentimentdlapproach method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach.setThresholdLabel"]], "setthresholdlabel() (sentimentdlmodel method)": [[33, "sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel.setThresholdLabel"]], "sparknlp.annotator.classifier_dl.sentiment_dl": [[33, "module-sparknlp.annotator.classifier_dl.sentiment_dl"]], "tapasforquestionanswering (class in sparknlp.annotator.classifier_dl.tapas_for_question_answering)": [[34, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering"]], "loadsavedmodel() (tapasforquestionanswering static method)": [[34, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.loadSavedModel"]], "pretrained() (tapasforquestionanswering static method)": [[34, "sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering.pretrained"]], "sparknlp.annotator.classifier_dl.tapas_for_question_answering": [[34, "module-sparknlp.annotator.classifier_dl.tapas_for_question_answering"]], "xlmrobertaforquestionanswering (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering)": [[35, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering"]], "loadsavedmodel() (xlmrobertaforquestionanswering static method)": [[35, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.loadSavedModel"]], "pretrained() (xlmrobertaforquestionanswering static method)": [[35, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.pretrained"]], "setconfigprotobytes() (xlmrobertaforquestionanswering method)": [[35, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforquestionanswering method)": [[35, "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering": [[35, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering"]], "xlmrobertaforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification"]], "getclasses() (xlmrobertaforsequenceclassification method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.getClasses"]], "loadsavedmodel() (xlmrobertaforsequenceclassification static method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.loadSavedModel"]], "pretrained() (xlmrobertaforsequenceclassification static method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.pretrained"]], "setcoalescesentences() (xlmrobertaforsequenceclassification method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlmrobertaforsequenceclassification method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaforsequenceclassification method)": [[36, "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification": [[36, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification"]], "xlmrobertafortokenclassification (class in sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification"]], "getclasses() (xlmrobertafortokenclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.getClasses"]], "loadsavedmodel() (xlmrobertafortokenclassification static method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.loadSavedModel"]], "pretrained() (xlmrobertafortokenclassification static method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.pretrained"]], "setconfigprotobytes() (xlmrobertafortokenclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertafortokenclassification method)": [[37, "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification": [[37, "module-sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification"]], "xlnetforsequenceclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification"]], "getclasses() (xlnetforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.getClasses"]], "loadsavedmodel() (xlnetforsequenceclassification static method)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.loadSavedModel"]], "pretrained() (xlnetforsequenceclassification static method)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.pretrained"]], "setcoalescesentences() (xlnetforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setCoalesceSentences"]], "setconfigprotobytes() (xlnetforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetforsequenceclassification method)": [[38, "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification": [[38, "module-sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification"]], "xlnetfortokenclassification (class in sparknlp.annotator.classifier_dl.xlnet_for_token_classification)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification"]], "getclasses() (xlnetfortokenclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.getClasses"]], "loadsavedmodel() (xlnetfortokenclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.loadSavedModel"]], "pretrained() (xlnetfortokenclassification static method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.pretrained"]], "setconfigprotobytes() (xlnetfortokenclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetfortokenclassification method)": [[39, "sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification.setMaxSentenceLength"]], "sparknlp.annotator.classifier_dl.xlnet_for_token_classification": [[39, "module-sparknlp.annotator.classifier_dl.xlnet_for_token_classification"]], "sparknlp.annotator.coref": [[40, "module-sparknlp.annotator.coref"]], "spanbertcorefmodel (class in sparknlp.annotator.coref.spanbert_coref)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel"]], "loadsavedmodel() (spanbertcorefmodel static method)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.loadSavedModel"]], "pretrained() (spanbertcorefmodel static method)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.pretrained"]], "setconfigprotobytes() (spanbertcorefmodel method)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setConfigProtoBytes"]], "setmaxsegmentlength() (spanbertcorefmodel method)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSegmentLength"]], "setmaxsentencelength() (spanbertcorefmodel method)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setMaxSentenceLength"]], "settextgenre() (spanbertcorefmodel method)": [[41, "sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel.setTextGenre"]], "sparknlp.annotator.coref.spanbert_coref": [[41, "module-sparknlp.annotator.coref.spanbert_coref"]], "sparknlp.annotator.cv": [[42, "module-sparknlp.annotator.cv"]], "swinforimageclassification (class in sparknlp.annotator.cv.swin_for_image_classification)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification"]], "getclasses() (swinforimageclassification method)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.getClasses"]], "loadsavedmodel() (swinforimageclassification static method)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.loadSavedModel"]], "pretrained() (swinforimageclassification static method)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.pretrained"]], "setconfigprotobytes() (swinforimageclassification method)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setConfigProtoBytes"]], "setdorescale() (swinforimageclassification method)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setDoRescale"]], "setrescalefactor() (swinforimageclassification method)": [[43, "sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification.setRescaleFactor"]], "sparknlp.annotator.cv.swin_for_image_classification": [[43, "module-sparknlp.annotator.cv.swin_for_image_classification"]], "vitforimageclassification (class in sparknlp.annotator.cv.vit_for_image_classification)": [[44, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification"]], "getclasses() (vitforimageclassification method)": [[44, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.getClasses"]], "loadsavedmodel() (vitforimageclassification static method)": [[44, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.loadSavedModel"]], "pretrained() (vitforimageclassification static method)": [[44, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.pretrained"]], "setconfigprotobytes() (vitforimageclassification method)": [[44, "sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification.setConfigProtoBytes"]], "sparknlp.annotator.cv.vit_for_image_classification": [[44, "module-sparknlp.annotator.cv.vit_for_image_classification"]], "dependencyparserapproach (class in sparknlp.annotator.dependency.dependency_parser)": [[45, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach"]], "dependencyparsermodel (class in sparknlp.annotator.dependency.dependency_parser)": [[45, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel"]], "pretrained() (dependencyparsermodel static method)": [[45, "sparknlp.annotator.dependency.dependency_parser.DependencyParserModel.pretrained"]], "setconllu() (dependencyparserapproach method)": [[45, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setConllU"]], "setdependencytreebank() (dependencyparserapproach method)": [[45, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setDependencyTreeBank"]], "setnumberofiterations() (dependencyparserapproach method)": [[45, "sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.dependency_parser": [[45, "module-sparknlp.annotator.dependency.dependency_parser"]], "sparknlp.annotator.dependency": [[46, "module-sparknlp.annotator.dependency"]], "typeddependencyparserapproach (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[47, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach"]], "typeddependencyparsermodel (class in sparknlp.annotator.dependency.typed_dependency_parser)": [[47, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel"]], "pretrained() (typeddependencyparsermodel static method)": [[47, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel.pretrained"]], "setconll2009() (typeddependencyparserapproach method)": [[47, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConll2009"]], "setconllu() (typeddependencyparserapproach method)": [[47, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setConllU"]], "setnumberofiterations() (typeddependencyparserapproach method)": [[47, "sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach.setNumberOfIterations"]], "sparknlp.annotator.dependency.typed_dependency_parser": [[47, "module-sparknlp.annotator.dependency.typed_dependency_parser"]], "documentnormalizer (class in sparknlp.annotator.document_normalizer)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer"]], "setaction() (documentnormalizer method)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setAction"]], "setencoding() (documentnormalizer method)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setEncoding"]], "setlowercase() (documentnormalizer method)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setLowercase"]], "setpatterns() (documentnormalizer method)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPatterns"]], "setpolicy() (documentnormalizer method)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setPolicy"]], "setreplacement() (documentnormalizer method)": [[48, "sparknlp.annotator.document_normalizer.DocumentNormalizer.setReplacement"]], "sparknlp.annotator.document_normalizer": [[48, "module-sparknlp.annotator.document_normalizer"]], "albertembeddings (class in sparknlp.annotator.embeddings.albert_embeddings)": [[49, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings"]], "loadsavedmodel() (albertembeddings static method)": [[49, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.loadSavedModel"]], "pretrained() (albertembeddings static method)": [[49, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.pretrained"]], "setconfigprotobytes() (albertembeddings method)": [[49, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (albertembeddings method)": [[49, "sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.albert_embeddings": [[49, "module-sparknlp.annotator.embeddings.albert_embeddings"]], "bertembeddings (class in sparknlp.annotator.embeddings.bert_embeddings)": [[50, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings"]], "loadsavedmodel() (bertembeddings static method)": [[50, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.loadSavedModel"]], "pretrained() (bertembeddings static method)": [[50, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.pretrained"]], "setconfigprotobytes() (bertembeddings method)": [[50, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (bertembeddings method)": [[50, "sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_embeddings": [[50, "module-sparknlp.annotator.embeddings.bert_embeddings"]], "bertsentenceembeddings (class in sparknlp.annotator.embeddings.bert_sentence_embeddings)": [[51, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings"]], "loadsavedmodel() (bertsentenceembeddings static method)": [[51, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.loadSavedModel"]], "pretrained() (bertsentenceembeddings static method)": [[51, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (bertsentenceembeddings method)": [[51, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setConfigProtoBytes"]], "setislong() (bertsentenceembeddings method)": [[51, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setIsLong"]], "setmaxsentencelength() (bertsentenceembeddings method)": [[51, "sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.bert_sentence_embeddings": [[51, "module-sparknlp.annotator.embeddings.bert_sentence_embeddings"]], "camembertembeddings (class in sparknlp.annotator.embeddings.camembert_embeddings)": [[52, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings"]], "loadsavedmodel() (camembertembeddings static method)": [[52, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.loadSavedModel"]], "pretrained() (camembertembeddings static method)": [[52, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.pretrained"]], "setconfigprotobytes() (camembertembeddings method)": [[52, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (camembertembeddings method)": [[52, "sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.camembert_embeddings": [[52, "module-sparknlp.annotator.embeddings.camembert_embeddings"]], "chunkembeddings (class in sparknlp.annotator.embeddings.chunk_embeddings)": [[53, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings"]], "setpoolingstrategy() (chunkembeddings method)": [[53, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setPoolingStrategy"]], "setskipoov() (chunkembeddings method)": [[53, "sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings.setSkipOOV"]], "sparknlp.annotator.embeddings.chunk_embeddings": [[53, "module-sparknlp.annotator.embeddings.chunk_embeddings"]], "debertaembeddings (class in sparknlp.annotator.embeddings.deberta_embeddings)": [[54, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings"]], "loadsavedmodel() (debertaembeddings static method)": [[54, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.loadSavedModel"]], "pretrained() (debertaembeddings static method)": [[54, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.pretrained"]], "setconfigprotobytes() (debertaembeddings method)": [[54, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (debertaembeddings method)": [[54, "sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.deberta_embeddings": [[54, "module-sparknlp.annotator.embeddings.deberta_embeddings"]], "distilbertembeddings (class in sparknlp.annotator.embeddings.distil_bert_embeddings)": [[55, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings"]], "loadsavedmodel() (distilbertembeddings static method)": [[55, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.loadSavedModel"]], "pretrained() (distilbertembeddings static method)": [[55, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.pretrained"]], "setconfigprotobytes() (distilbertembeddings method)": [[55, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (distilbertembeddings method)": [[55, "sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.distil_bert_embeddings": [[55, "module-sparknlp.annotator.embeddings.distil_bert_embeddings"]], "doc2vecapproach (class in sparknlp.annotator.embeddings.doc2vec)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach"]], "doc2vecmodel (class in sparknlp.annotator.embeddings.doc2vec)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel"]], "pretrained() (doc2vecmodel static method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.pretrained"]], "setmaxiter() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxIter"]], "setmaxsentencelength() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMaxSentenceLength"]], "setmincount() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setMinCount"]], "setnumpartitions() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setNumPartitions"]], "setseed() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setSeed"]], "setstepsize() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setStepSize"]], "setvectorsize() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setVectorSize"]], "setvectorsize() (doc2vecmodel method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecModel.setVectorSize"]], "setwindowsize() (doc2vecapproach method)": [[56, "sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.doc2vec": [[56, "module-sparknlp.annotator.embeddings.doc2vec"]], "elmoembeddings (class in sparknlp.annotator.embeddings.elmo_embeddings)": [[57, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings"]], "loadsavedmodel() (elmoembeddings static method)": [[57, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.loadSavedModel"]], "pretrained() (elmoembeddings static method)": [[57, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.pretrained"]], "setbatchsize() (elmoembeddings method)": [[57, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setBatchSize"]], "setconfigprotobytes() (elmoembeddings method)": [[57, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setConfigProtoBytes"]], "setpoolinglayer() (elmoembeddings method)": [[57, "sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings.setPoolingLayer"]], "sparknlp.annotator.embeddings.elmo_embeddings": [[57, "module-sparknlp.annotator.embeddings.elmo_embeddings"]], "sparknlp.annotator.embeddings": [[58, "module-sparknlp.annotator.embeddings"]], "longformerembeddings (class in sparknlp.annotator.embeddings.longformer_embeddings)": [[59, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings"]], "loadsavedmodel() (longformerembeddings static method)": [[59, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.loadSavedModel"]], "pretrained() (longformerembeddings static method)": [[59, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.pretrained"]], "setconfigprotobytes() (longformerembeddings method)": [[59, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (longformerembeddings method)": [[59, "sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.longformer_embeddings": [[59, "module-sparknlp.annotator.embeddings.longformer_embeddings"]], "robertaembeddings (class in sparknlp.annotator.embeddings.roberta_embeddings)": [[60, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings"]], "loadsavedmodel() (robertaembeddings static method)": [[60, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.loadSavedModel"]], "pretrained() (robertaembeddings static method)": [[60, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (robertaembeddings method)": [[60, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertaembeddings method)": [[60, "sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_embeddings": [[60, "module-sparknlp.annotator.embeddings.roberta_embeddings"]], "robertasentenceembeddings (class in sparknlp.annotator.embeddings.roberta_sentence_embeddings)": [[61, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings"]], "loadsavedmodel() (robertasentenceembeddings static method)": [[61, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (robertasentenceembeddings static method)": [[61, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (robertasentenceembeddings method)": [[61, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (robertasentenceembeddings method)": [[61, "sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.roberta_sentence_embeddings": [[61, "module-sparknlp.annotator.embeddings.roberta_sentence_embeddings"]], "sentenceembeddings (class in sparknlp.annotator.embeddings.sentence_embeddings)": [[62, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings"]], "setpoolingstrategy() (sentenceembeddings method)": [[62, "sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings.setPoolingStrategy"]], "sparknlp.annotator.embeddings.sentence_embeddings": [[62, "module-sparknlp.annotator.embeddings.sentence_embeddings"]], "universalsentenceencoder (class in sparknlp.annotator.embeddings.universal_sentence_encoder)": [[63, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder"]], "loadsavedmodel() (universalsentenceencoder static method)": [[63, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.loadSavedModel"]], "pretrained() (universalsentenceencoder static method)": [[63, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.pretrained"]], "setconfigprotobytes() (universalsentenceencoder method)": [[63, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setConfigProtoBytes"]], "setloadsp() (universalsentenceencoder method)": [[63, "sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder.setLoadSP"]], "sparknlp.annotator.embeddings.universal_sentence_encoder": [[63, "module-sparknlp.annotator.embeddings.universal_sentence_encoder"]], "word2vecapproach (class in sparknlp.annotator.embeddings.word2vec)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach"]], "word2vecmodel (class in sparknlp.annotator.embeddings.word2vec)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecModel"]], "pretrained() (word2vecmodel static method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.pretrained"]], "setmaxiter() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxIter"]], "setmaxsentencelength() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMaxSentenceLength"]], "setmincount() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setMinCount"]], "setnumpartitions() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setNumPartitions"]], "setseed() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setSeed"]], "setstepsize() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setStepSize"]], "setvectorsize() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setVectorSize"]], "setvectorsize() (word2vecmodel method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecModel.setVectorSize"]], "setwindowsize() (word2vecapproach method)": [[64, "sparknlp.annotator.embeddings.word2vec.Word2VecApproach.setWindowSize"]], "sparknlp.annotator.embeddings.word2vec": [[64, "module-sparknlp.annotator.embeddings.word2vec"]], "wordembeddings (class in sparknlp.annotator.embeddings.word_embeddings)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings"]], "wordembeddingsmodel (class in sparknlp.annotator.embeddings.word_embeddings)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel"]], "loadstorage() (wordembeddingsmodel static method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.loadStorage"]], "overallcoverage() (wordembeddingsmodel static method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.overallCoverage"]], "pretrained() (wordembeddingsmodel static method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.pretrained"]], "setreadcachesize() (wordembeddings method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setReadCacheSize"]], "setreadcachesize() (wordembeddingsmodel method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.setReadCacheSize"]], "setwritebuffersize() (wordembeddings method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings.setWriteBufferSize"]], "sparknlp.annotator.embeddings.word_embeddings": [[65, "module-sparknlp.annotator.embeddings.word_embeddings"]], "withcoveragecolumn() (wordembeddingsmodel static method)": [[65, "sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel.withCoverageColumn"]], "xlmrobertaembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_embeddings)": [[66, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings"]], "loadsavedmodel() (xlmrobertaembeddings static method)": [[66, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertaembeddings static method)": [[66, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertaembeddings method)": [[66, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertaembeddings method)": [[66, "sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_embeddings": [[66, "module-sparknlp.annotator.embeddings.xlm_roberta_embeddings"]], "xlmrobertasentenceembeddings (class in sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings)": [[67, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings"]], "loadsavedmodel() (xlmrobertasentenceembeddings static method)": [[67, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.loadSavedModel"]], "pretrained() (xlmrobertasentenceembeddings static method)": [[67, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.pretrained"]], "setconfigprotobytes() (xlmrobertasentenceembeddings method)": [[67, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlmrobertasentenceembeddings method)": [[67, "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings": [[67, "module-sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings"]], "xlnetembeddings (class in sparknlp.annotator.embeddings.xlnet_embeddings)": [[68, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings"]], "loadsavedmodel() (xlnetembeddings static method)": [[68, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.loadSavedModel"]], "pretrained() (xlnetembeddings static method)": [[68, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.pretrained"]], "setconfigprotobytes() (xlnetembeddings method)": [[68, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setConfigProtoBytes"]], "setmaxsentencelength() (xlnetembeddings method)": [[68, "sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings.setMaxSentenceLength"]], "sparknlp.annotator.embeddings.xlnet_embeddings": [[68, "module-sparknlp.annotator.embeddings.xlnet_embeddings"]], "entityrulerapproach (class in sparknlp.annotator.er.entity_ruler)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach"]], "entityrulermodel (class in sparknlp.annotator.er.entity_ruler)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerModel"]], "setalphabetresource() (entityrulerapproach method)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setAlphabetResource"]], "setenablepatternregex() (entityrulerapproach method)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setEnablePatternRegex"]], "setpatternsresource() (entityrulerapproach method)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setPatternsResource"]], "setsentencematch() (entityrulerapproach method)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setSentenceMatch"]], "setusestorage() (entityrulerapproach method)": [[69, "sparknlp.annotator.er.entity_ruler.EntityRulerApproach.setUseStorage"]], "sparknlp.annotator.er.entity_ruler": [[69, "module-sparknlp.annotator.er.entity_ruler"]], "sparknlp.annotator.er": [[70, "module-sparknlp.annotator.er"]], "graphextraction (class in sparknlp.annotator.graph_extraction)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction"]], "setdelimiter() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setDelimiter"]], "setdependencyparsermodel() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setDependencyParserModel"]], "setentitytypes() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setEntityTypes"]], "setexplodeentities() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setExplodeEntities"]], "setincludeedges() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setIncludeEdges"]], "setmaxsentencesize() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setMaxSentenceSize"]], "setmergeentities() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntities"]], "setmergeentitiesiobformat() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setMergeEntitiesIOBFormat"]], "setminsentencesize() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setMinSentenceSize"]], "setposmodel() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setPosModel"]], "setrelationshiptypes() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setRelationshipTypes"]], "setroottokens() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setRootTokens"]], "settypeddependencyparsermodel() (graphextraction method)": [[71, "sparknlp.annotator.graph_extraction.GraphExtraction.setTypedDependencyParserModel"]], "sparknlp.annotator.graph_extraction": [[71, "module-sparknlp.annotator.graph_extraction"]], "sparknlp.annotator": [[72, "module-sparknlp.annotator"]], "sparknlp.annotator.keyword_extraction": [[73, "module-sparknlp.annotator.keyword_extraction"]], "yakekeywordextraction (class in sparknlp.annotator.keyword_extraction.yake_keyword_extraction)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction"]], "getstopwords() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.getStopWords"]], "loaddefaultstopwords() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.loadDefaultStopWords"]], "setmaxngrams() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMaxNGrams"]], "setminngrams() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setMinNGrams"]], "setnkeywords() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setNKeywords"]], "setstopwords() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setStopWords"]], "setthreshold() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setThreshold"]], "setwindowsize() (yakekeywordextraction method)": [[74, "sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction.setWindowSize"]], "sparknlp.annotator.keyword_extraction.yake_keyword_extraction": [[74, "module-sparknlp.annotator.keyword_extraction.yake_keyword_extraction"]], "sparknlp.annotator.ld_dl": [[75, "module-sparknlp.annotator.ld_dl"]], "languagedetectordl (class in sparknlp.annotator.ld_dl.language_detector_dl)": [[76, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL"]], "pretrained() (languagedetectordl static method)": [[76, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.pretrained"]], "setcoalescesentences() (languagedetectordl method)": [[76, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setCoalesceSentences"]], "setconfigprotobytes() (languagedetectordl method)": [[76, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setConfigProtoBytes"]], "setthreshold() (languagedetectordl method)": [[76, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThreshold"]], "setthresholdlabel() (languagedetectordl method)": [[76, "sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL.setThresholdLabel"]], "sparknlp.annotator.ld_dl.language_detector_dl": [[76, "module-sparknlp.annotator.ld_dl.language_detector_dl"]], "lemmatizer (class in sparknlp.annotator.lemmatizer)": [[77, "sparknlp.annotator.lemmatizer.Lemmatizer"]], "lemmatizermodel (class in sparknlp.annotator.lemmatizer)": [[77, "sparknlp.annotator.lemmatizer.LemmatizerModel"]], "pretrained() (lemmatizermodel static method)": [[77, "sparknlp.annotator.lemmatizer.LemmatizerModel.pretrained"]], "setdictionary() (lemmatizer method)": [[77, "sparknlp.annotator.lemmatizer.Lemmatizer.setDictionary"]], "setformcol() (lemmatizer method)": [[77, "sparknlp.annotator.lemmatizer.Lemmatizer.setFormCol"]], "setlemmacol() (lemmatizer method)": [[77, "sparknlp.annotator.lemmatizer.Lemmatizer.setLemmaCol"]], "sparknlp.annotator.lemmatizer": [[77, "module-sparknlp.annotator.lemmatizer"]], "bigtextmatcher (class in sparknlp.annotator.matcher.big_text_matcher)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher"]], "bigtextmatchermodel (class in sparknlp.annotator.matcher.big_text_matcher)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel"]], "loadstorage() (bigtextmatchermodel static method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.loadStorage"]], "pretrained() (bigtextmatchermodel static method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.pretrained"]], "setcasesensitive() (bigtextmatcher method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setCaseSensitive"]], "setcasesensitive() (bigtextmatchermodel method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setCaseSensitive"]], "setentities() (bigtextmatcher method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setEntities"]], "setmergeoverlapping() (bigtextmatcher method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (bigtextmatchermodel method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel.setMergeOverlapping"]], "settokenizer() (bigtextmatcher method)": [[78, "sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher.setTokenizer"]], "sparknlp.annotator.matcher.big_text_matcher": [[78, "module-sparknlp.annotator.matcher.big_text_matcher"]], "datematcher (class in sparknlp.annotator.matcher.date_matcher)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcher"]], "datematcherutils (class in sparknlp.annotator.matcher.date_matcher)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils"]], "setanchordateday() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateDay"]], "setanchordatemonth() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateMonth"]], "setanchordateyear() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setAnchorDateYear"]], "setdefaultdaywhenmissing() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setDefaultDayWhenMissing"]], "setinputformats() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setInputFormats"]], "setoutputformat() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setOutputFormat"]], "setreadmonthfirst() (datematcherutils method)": [[79, "sparknlp.annotator.matcher.date_matcher.DateMatcherUtils.setReadMonthFirst"]], "sparknlp.annotator.matcher.date_matcher": [[79, "module-sparknlp.annotator.matcher.date_matcher"]], "sparknlp.annotator.matcher": [[80, "module-sparknlp.annotator.matcher"]], "multidatematcher (class in sparknlp.annotator.matcher.multi_date_matcher)": [[81, "sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher"]], "sparknlp.annotator.matcher.multi_date_matcher": [[81, "module-sparknlp.annotator.matcher.multi_date_matcher"]], "regexmatcher (class in sparknlp.annotator.matcher.regex_matcher)": [[82, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher"]], "regexmatchermodel (class in sparknlp.annotator.matcher.regex_matcher)": [[82, "sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel"]], "setdelimiter() (regexmatcher method)": [[82, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setDelimiter"]], "setexternalrules() (regexmatcher method)": [[82, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setExternalRules"]], "setrules() (regexmatcher method)": [[82, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setRules"]], "setstrategy() (regexmatcher method)": [[82, "sparknlp.annotator.matcher.regex_matcher.RegexMatcher.setStrategy"]], "sparknlp.annotator.matcher.regex_matcher": [[82, "module-sparknlp.annotator.matcher.regex_matcher"]], "textmatcher (class in sparknlp.annotator.matcher.text_matcher)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcher"]], "textmatchermodel (class in sparknlp.annotator.matcher.text_matcher)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel"]], "pretrained() (textmatchermodel static method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.pretrained"]], "setbuildfromtokens() (textmatcher method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setBuildFromTokens"]], "setbuildfromtokens() (textmatchermodel method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setBuildFromTokens"]], "setcasesensitive() (textmatcher method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setCaseSensitive"]], "setentities() (textmatcher method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntities"]], "setentityvalue() (textmatcher method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setEntityValue"]], "setentityvalue() (textmatchermodel method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setEntityValue"]], "setmergeoverlapping() (textmatcher method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcher.setMergeOverlapping"]], "setmergeoverlapping() (textmatchermodel method)": [[83, "sparknlp.annotator.matcher.text_matcher.TextMatcherModel.setMergeOverlapping"]], "sparknlp.annotator.matcher.text_matcher": [[83, "module-sparknlp.annotator.matcher.text_matcher"]], "ngramgenerator (class in sparknlp.annotator.n_gram_generator)": [[84, "sparknlp.annotator.n_gram_generator.NGramGenerator"]], "setdelimiter() (ngramgenerator method)": [[84, "sparknlp.annotator.n_gram_generator.NGramGenerator.setDelimiter"]], "setenablecumulative() (ngramgenerator method)": [[84, "sparknlp.annotator.n_gram_generator.NGramGenerator.setEnableCumulative"]], "setn() (ngramgenerator method)": [[84, "sparknlp.annotator.n_gram_generator.NGramGenerator.setN"]], "sparknlp.annotator.n_gram_generator": [[84, "module-sparknlp.annotator.n_gram_generator"]], "sparknlp.annotator.ner": [[85, "module-sparknlp.annotator.ner"]], "nerapproach (class in sparknlp.annotator.ner.ner_approach)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach"]], "getlabelcolumn() (nerapproach method)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach.getLabelColumn"]], "setentities() (nerapproach method)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach.setEntities"]], "setlabelcolumn() (nerapproach method)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach.setLabelColumn"]], "setmaxepochs() (nerapproach method)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach.setMaxEpochs"]], "setminepochs() (nerapproach method)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach.setMinEpochs"]], "setrandomseed() (nerapproach method)": [[86, "sparknlp.annotator.ner.ner_approach.NerApproach.setRandomSeed"]], "sparknlp.annotator.ner.ner_approach": [[86, "module-sparknlp.annotator.ner.ner_approach"]], "nerconverter (class in sparknlp.annotator.ner.ner_converter)": [[87, "sparknlp.annotator.ner.ner_converter.NerConverter"]], "setpreserveposition() (nerconverter method)": [[87, "sparknlp.annotator.ner.ner_converter.NerConverter.setPreservePosition"]], "setwhitelist() (nerconverter method)": [[87, "sparknlp.annotator.ner.ner_converter.NerConverter.setWhiteList"]], "sparknlp.annotator.ner.ner_converter": [[87, "module-sparknlp.annotator.ner.ner_converter"]], "nercrfapproach (class in sparknlp.annotator.ner.ner_crf)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach"]], "nercrfmodel (class in sparknlp.annotator.ner.ner_crf)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfModel"]], "pretrained() (nercrfmodel static method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfModel.pretrained"]], "setc0() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setC0"]], "setexternalfeatures() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setExternalFeatures"]], "setincludeconfidence() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setIncludeConfidence"]], "setincludeconfidence() (nercrfmodel method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfModel.setIncludeConfidence"]], "setl2() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setL2"]], "setlosseps() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setLossEps"]], "setminw() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setMinW"]], "setverbose() (nercrfapproach method)": [[88, "sparknlp.annotator.ner.ner_crf.NerCrfApproach.setVerbose"]], "sparknlp.annotator.ner.ner_crf": [[88, "module-sparknlp.annotator.ner.ner_crf"]], "nerdlapproach (class in sparknlp.annotator.ner.ner_dl)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach"]], "nerdlmodel (class in sparknlp.annotator.ner.ner_dl)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLModel"]], "pretrained() (nerdlmodel static method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLModel.pretrained"]], "setbatchsize() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBatchSize"]], "setbestmodelmetric() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setBestModelMetric"]], "setconfigprotobytes() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setConfigProtoBytes"]], "setconfigprotobytes() (nerdlmodel method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLModel.setConfigProtoBytes"]], "setdropout() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setDropout"]], "setenablememoryoptimizer() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setEnableMemoryOptimizer"]], "setgraphfolder() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setGraphFolder"]], "setincludeallconfidencescores() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeAllConfidenceScores"]], "setincludeallconfidencescores() (nerdlmodel method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeAllConfidenceScores"]], "setincludeconfidence() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setIncludeConfidence"]], "setincludeconfidence() (nerdlmodel method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLModel.setIncludeConfidence"]], "setlr() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setLr"]], "setpo() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setPo"]], "setusebestmodel() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseBestModel"]], "setusecontrib() (nerdlapproach method)": [[89, "sparknlp.annotator.ner.ner_dl.NerDLApproach.setUseContrib"]], "sparknlp.annotator.ner.ner_dl": [[89, "module-sparknlp.annotator.ner.ner_dl"]], "neroverwriter (class in sparknlp.annotator.ner.ner_overwriter)": [[90, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter"]], "setnerwords() (neroverwriter method)": [[90, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNerWords"]], "setnewnerentity() (neroverwriter method)": [[90, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setNewNerEntity"]], "setreplaceentities() (neroverwriter method)": [[90, "sparknlp.annotator.ner.ner_overwriter.NerOverwriter.setReplaceEntities"]], "sparknlp.annotator.ner.ner_overwriter": [[90, "module-sparknlp.annotator.ner.ner_overwriter"]], "zeroshotnermodel (class in sparknlp.annotator.ner.zero_shot_ner_model)": [[91, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel"]], "getclasses() (zeroshotnermodel method)": [[91, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.getClasses"]], "load() (zeroshotnermodel static method)": [[91, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.load"]], "pretrained() (zeroshotnermodel static method)": [[91, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.pretrained"]], "setentitydefinitions() (zeroshotnermodel method)": [[91, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setEntityDefinitions"]], "setpredictionthreshold() (zeroshotnermodel method)": [[91, "sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel.setPredictionThreshold"]], "sparknlp.annotator.ner.zero_shot_ner_model": [[91, "module-sparknlp.annotator.ner.zero_shot_ner_model"]], "normalizer (class in sparknlp.annotator.normalizer)": [[92, "sparknlp.annotator.normalizer.Normalizer"]], "normalizermodel (class in sparknlp.annotator.normalizer)": [[92, "sparknlp.annotator.normalizer.NormalizerModel"]], "setcleanuppatterns() (normalizer method)": [[92, "sparknlp.annotator.normalizer.Normalizer.setCleanupPatterns"]], "setlowercase() (normalizer method)": [[92, "sparknlp.annotator.normalizer.Normalizer.setLowercase"]], "setmaxlength() (normalizer method)": [[92, "sparknlp.annotator.normalizer.Normalizer.setMaxLength"]], "setminlength() (normalizer method)": [[92, "sparknlp.annotator.normalizer.Normalizer.setMinLength"]], "setslangdictionary() (normalizer method)": [[92, "sparknlp.annotator.normalizer.Normalizer.setSlangDictionary"]], "sparknlp.annotator.normalizer": [[92, "module-sparknlp.annotator.normalizer"]], "classifierencoder (class in sparknlp.annotator.param.classifier_encoder)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder"]], "setbatchsize() (classifierencoder method)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setBatchSize"]], "setconfigprotobytes() (classifierencoder method)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setConfigProtoBytes"]], "setlabelcolumn() (classifierencoder method)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLabelColumn"]], "setlr() (classifierencoder method)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setLr"]], "setmaxepochs() (classifierencoder method)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setMaxEpochs"]], "setrandomseed() (classifierencoder method)": [[93, "sparknlp.annotator.param.classifier_encoder.ClassifierEncoder.setRandomSeed"]], "sparknlp.annotator.param.classifier_encoder": [[93, "module-sparknlp.annotator.param.classifier_encoder"]], "evaluationdlparams (class in sparknlp.annotator.param.evaluation_dl_params)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams"]], "setenableoutputlogs() (evaluationdlparams method)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEnableOutputLogs"]], "setevaluationlogextended() (evaluationdlparams method)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setEvaluationLogExtended"]], "setoutputlogspath() (evaluationdlparams method)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setOutputLogsPath"]], "settestdataset() (evaluationdlparams method)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setTestDataset"]], "setvalidationsplit() (evaluationdlparams method)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setValidationSplit"]], "setverbose() (evaluationdlparams method)": [[94, "sparknlp.annotator.param.evaluation_dl_params.EvaluationDLParams.setVerbose"]], "sparknlp.annotator.param.evaluation_dl_params": [[94, "module-sparknlp.annotator.param.evaluation_dl_params"]], "sparknlp.annotator.param": [[95, "module-sparknlp.annotator.param"]], "sparknlp.annotator.pos": [[96, "module-sparknlp.annotator.pos"]], "perceptronapproach (class in sparknlp.annotator.pos.perceptron)": [[97, "sparknlp.annotator.pos.perceptron.PerceptronApproach"]], "perceptronmodel (class in sparknlp.annotator.pos.perceptron)": [[97, "sparknlp.annotator.pos.perceptron.PerceptronModel"]], "getniterations() (perceptronapproach method)": [[97, "sparknlp.annotator.pos.perceptron.PerceptronApproach.getNIterations"]], "pretrained() (perceptronmodel static method)": [[97, "sparknlp.annotator.pos.perceptron.PerceptronModel.pretrained"]], "setiterations() (perceptronapproach method)": [[97, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setIterations"]], "setposcolumn() (perceptronapproach method)": [[97, "sparknlp.annotator.pos.perceptron.PerceptronApproach.setPosColumn"]], "sparknlp.annotator.pos.perceptron": [[97, "module-sparknlp.annotator.pos.perceptron"]], "sparknlp.annotator.sentence": [[98, "module-sparknlp.annotator.sentence"]], "sentencedetector (class in sparknlp.annotator.sentence.sentence_detector)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector"]], "sentencedetectorparams (class in sparknlp.annotator.sentence.sentence_detector)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetectorParams"]], "setcustombounds() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBounds"]], "setcustomboundsstrategy() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setCustomBoundsStrategy"]], "setdetectlists() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setDetectLists"]], "setexplodesentences() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setExplodeSentences"]], "setmaxlength() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMaxLength"]], "setminlength() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setMinLength"]], "setsplitlength() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setSplitLength"]], "setuseabbreviations() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseAbbreviations"]], "setusecustomboundsonly() (sentencedetector method)": [[99, "sparknlp.annotator.sentence.sentence_detector.SentenceDetector.setUseCustomBoundsOnly"]], "sparknlp.annotator.sentence.sentence_detector": [[99, "module-sparknlp.annotator.sentence.sentence_detector"]], "sentencedetectordlapproach (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach"]], "sentencedetectordlmodel (class in sparknlp.annotator.sentence.sentence_detector_dl)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel"]], "pretrained() (sentencedetectordlmodel static method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.pretrained"]], "setcustombounds() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setCustomBounds"]], "setepochsnumber() (sentencedetectordlapproach method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setEpochsNumber"]], "setexplodesentences() (sentencedetectordlapproach method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setExplodeSentences"]], "setexplodesentences() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setExplodeSentences"]], "setimpossiblepenultimates() (sentencedetectordlapproach method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setImpossiblePenultimates"]], "setimpossiblepenultimates() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setImpossiblePenultimates"]], "setmaxlength() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMaxLength"]], "setminlength() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setMinLength"]], "setmodel() (sentencedetectordlapproach method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setModel"]], "setmodel() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setModel"]], "setoutputlogspath() (sentencedetectordlapproach method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setOutputLogsPath"]], "setsplitlength() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setSplitLength"]], "setusecustomboundsonly() (sentencedetectordlmodel method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel.setUseCustomBoundsOnly"]], "setvalidationsplit() (sentencedetectordlapproach method)": [[100, "sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach.setValidationSplit"]], "sparknlp.annotator.sentence.sentence_detector_dl": [[100, "module-sparknlp.annotator.sentence.sentence_detector_dl"]], "sparknlp.annotator.sentiment": [[101, "module-sparknlp.annotator.sentiment"]], "sentimentdetector (class in sparknlp.annotator.sentiment.sentiment_detector)": [[102, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector"]], "sentimentdetectormodel (class in sparknlp.annotator.sentiment.sentiment_detector)": [[102, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel"]], "setdictionary() (sentimentdetector method)": [[102, "sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector.setDictionary"]], "sparknlp.annotator.sentiment.sentiment_detector": [[102, "module-sparknlp.annotator.sentiment.sentiment_detector"]], "viveknsentimentapproach (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[103, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach"]], "viveknsentimentmodel (class in sparknlp.annotator.sentiment.vivekn_sentiment)": [[103, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel"]], "pretrained() (viveknsentimentmodel static method)": [[103, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel.pretrained"]], "setprunecorpus() (viveknsentimentapproach method)": [[103, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setPruneCorpus"]], "setsentimentcol() (viveknsentimentapproach method)": [[103, "sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach.setSentimentCol"]], "sparknlp.annotator.sentiment.vivekn_sentiment": [[103, "module-sparknlp.annotator.sentiment.vivekn_sentiment"]], "gpt2transformer (class in sparknlp.annotator.seq2seq.gpt2_transformer)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer"]], "loadsavedmodel() (gpt2transformer static method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.loadSavedModel"]], "pretrained() (gpt2transformer static method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.pretrained"]], "setconfigprotobytes() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setConfigProtoBytes"]], "setdosample() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setDoSample"]], "setignoretokenids() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMaxOutputLength"]], "setminoutputlength() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setMinOutputLength"]], "setnorepeatngramsize() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setRepetitionPenalty"]], "settask() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTask"]], "settemperature() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTemperature"]], "settopk() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopK"]], "settopp() (gpt2transformer method)": [[104, "sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer.setTopP"]], "sparknlp.annotator.seq2seq.gpt2_transformer": [[104, "module-sparknlp.annotator.seq2seq.gpt2_transformer"]], "sparknlp.annotator.seq2seq": [[105, "module-sparknlp.annotator.seq2seq"]], "mariantransformer (class in sparknlp.annotator.seq2seq.marian_transformer)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer"]], "loadsavedmodel() (mariantransformer static method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.loadSavedModel"]], "pretrained() (mariantransformer static method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.pretrained"]], "setconfigprotobytes() (mariantransformer method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setConfigProtoBytes"]], "setignoretokenids() (mariantransformer method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setIgnoreTokenIds"]], "setlangid() (mariantransformer method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setLangId"]], "setmaxinputlength() (mariantransformer method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxInputLength"]], "setmaxoutputlength() (mariantransformer method)": [[106, "sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer.setMaxOutputLength"]], "sparknlp.annotator.seq2seq.marian_transformer": [[106, "module-sparknlp.annotator.seq2seq.marian_transformer"]], "t5transformer (class in sparknlp.annotator.seq2seq.t5_transformer)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer"]], "loadsavedmodel() (t5transformer static method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.loadSavedModel"]], "pretrained() (t5transformer static method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.pretrained"]], "setconfigprotobytes() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setConfigProtoBytes"]], "setdosample() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setDoSample"]], "setignoretokenids() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setIgnoreTokenIds"]], "setmaxoutputlength() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMaxOutputLength"]], "setminoutputlength() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setMinOutputLength"]], "setnorepeatngramsize() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setNoRepeatNgramSize"]], "setrepetitionpenalty() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setRepetitionPenalty"]], "settask() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTask"]], "settemperature() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTemperature"]], "settopk() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopK"]], "settopp() (t5transformer method)": [[107, "sparknlp.annotator.seq2seq.t5_transformer.T5Transformer.setTopP"]], "sparknlp.annotator.seq2seq.t5_transformer": [[107, "module-sparknlp.annotator.seq2seq.t5_transformer"]], "contextspellcheckerapproach (class in sparknlp.annotator.spell_check.context_spell_checker)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach"]], "contextspellcheckermodel (class in sparknlp.annotator.spell_check.context_spell_checker)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel"]], "addregexclass() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addRegexClass"]], "addvocabclass() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.addVocabClass"]], "getwordclasses() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.getWordClasses"]], "pretrained() (contextspellcheckermodel static method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.pretrained"]], "setbatchsize() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setBatchSize"]], "setcasestrategy() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCaseStrategy"]], "setcasestrategy() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCaseStrategy"]], "setclasscount() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setClassCount"]], "setcomparelowcase() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCompareLowcase"]], "setcompoundcount() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setCompoundCount"]], "setconfigprotobytes() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setConfigProtoBytes"]], "setconfigprotobytes() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setConfigProtoBytes"]], "setcorrectsymbols() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setCorrectSymbols"]], "setepochs() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setEpochs"]], "seterrorthreshold() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setErrorThreshold"]], "seterrorthreshold() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setErrorThreshold"]], "setfinalrate() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setFinalRate"]], "setgamma() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setGamma"]], "setinitialrate() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setInitialRate"]], "setlanguagemodelclasses() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setLanguageModelClasses"]], "setmaxcandidates() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxCandidates"]], "setmaxcandidates() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxCandidates"]], "setmaxwindowlen() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMaxWindowLen"]], "setmaxwindowlen() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setMaxWindowLen"]], "setmincount() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setMinCount"]], "settradeoff() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setTradeoff"]], "settradeoff() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setTradeoff"]], "setvalidationfraction() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setValidationFraction"]], "setweighteddistpath() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWeightedDistPath"]], "setweights() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWeights"]], "setwordmaxdistance() (contextspellcheckerapproach method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach.setWordMaxDistance"]], "setwordmaxdistance() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.setWordMaxDistance"]], "sparknlp.annotator.spell_check.context_spell_checker": [[108, "module-sparknlp.annotator.spell_check.context_spell_checker"]], "updateregexclass() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateRegexClass"]], "updatevocabclass() (contextspellcheckermodel method)": [[108, "sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel.updateVocabClass"]], "sparknlp.annotator.spell_check": [[109, "module-sparknlp.annotator.spell_check"]], "norvigsweetingapproach (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach"]], "norvigsweetingmodel (class in sparknlp.annotator.spell_check.norvig_sweeting)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel"]], "pretrained() (norvigsweetingmodel static method)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel.pretrained"]], "setcasesensitive() (norvigsweetingapproach method)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setCaseSensitive"]], "setdictionary() (norvigsweetingapproach method)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDictionary"]], "setdoublevariants() (norvigsweetingapproach method)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setDoubleVariants"]], "setfrequencypriority() (norvigsweetingapproach method)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setFrequencyPriority"]], "setshortcircuit() (norvigsweetingapproach method)": [[110, "sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach.setShortCircuit"]], "sparknlp.annotator.spell_check.norvig_sweeting": [[110, "module-sparknlp.annotator.spell_check.norvig_sweeting"]], "symmetricdeleteapproach (class in sparknlp.annotator.spell_check.symmetric_delete)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach"]], "symmetricdeletemodel (class in sparknlp.annotator.spell_check.symmetric_delete)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel"]], "pretrained() (symmetricdeletemodel static method)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel.pretrained"]], "setdeletesthreshold() (symmetricdeleteapproach method)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDeletesThreshold"]], "setdictionary() (symmetricdeleteapproach method)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setDictionary"]], "setfrequencythreshold() (symmetricdeleteapproach method)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setFrequencyThreshold"]], "setmaxeditdistance() (symmetricdeleteapproach method)": [[111, "sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach.setMaxEditDistance"]], "sparknlp.annotator.spell_check.symmetric_delete": [[111, "module-sparknlp.annotator.spell_check.symmetric_delete"]], "stemmer (class in sparknlp.annotator.stemmer)": [[112, "sparknlp.annotator.stemmer.Stemmer"]], "sparknlp.annotator.stemmer": [[112, "module-sparknlp.annotator.stemmer"]], "stopwordscleaner (class in sparknlp.annotator.stop_words_cleaner)": [[113, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner"]], "loaddefaultstopwords() (stopwordscleaner method)": [[113, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.loadDefaultStopWords"]], "pretrained() (stopwordscleaner static method)": [[113, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.pretrained"]], "setcasesensitive() (stopwordscleaner method)": [[113, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setCaseSensitive"]], "setlocale() (stopwordscleaner method)": [[113, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setLocale"]], "setstopwords() (stopwordscleaner method)": [[113, "sparknlp.annotator.stop_words_cleaner.StopWordsCleaner.setStopWords"]], "sparknlp.annotator.stop_words_cleaner": [[113, "module-sparknlp.annotator.stop_words_cleaner"]], "tfnerdlgraphbuilder (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder"]], "tfnerdlgraphbuildermodel (class in sparknlp.annotator.tf_ner_dl_graph_builder)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilderModel"]], "getgraphfile() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFile"]], "getgraphfolder() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getGraphFolder"]], "gethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getHiddenUnitsNumber"]], "getinputcols() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getInputCols"]], "getlabelcolumn() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.getLabelColumn"]], "setgraphfile() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFile"]], "setgraphfolder() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setGraphFolder"]], "sethiddenunitsnumber() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setHiddenUnitsNumber"]], "setinputcols() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setInputCols"]], "setlabelcolumn() (tfnerdlgraphbuilder method)": [[114, "sparknlp.annotator.tf_ner_dl_graph_builder.TFNerDLGraphBuilder.setLabelColumn"]], "sparknlp.annotator.tf_ner_dl_graph_builder": [[114, "module-sparknlp.annotator.tf_ner_dl_graph_builder"]], "chunktokenizer (class in sparknlp.annotator.token.chunk_tokenizer)": [[115, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer"]], "chunktokenizermodel (class in sparknlp.annotator.token.chunk_tokenizer)": [[115, "sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel"]], "sparknlp.annotator.token.chunk_tokenizer": [[115, "module-sparknlp.annotator.token.chunk_tokenizer"]], "sparknlp.annotator.token": [[116, "module-sparknlp.annotator.token"]], "recursivetokenizer (class in sparknlp.annotator.token.recursive_tokenizer)": [[117, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer"]], "recursivetokenizermodel (class in sparknlp.annotator.token.recursive_tokenizer)": [[117, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel"]], "setinfixes() (recursivetokenizer method)": [[117, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setInfixes"]], "setprefixes() (recursivetokenizer method)": [[117, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setPrefixes"]], "setsuffixes() (recursivetokenizer method)": [[117, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setSuffixes"]], "setwhitelist() (recursivetokenizer method)": [[117, "sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer.setWhitelist"]], "sparknlp.annotator.token.recursive_tokenizer": [[117, "module-sparknlp.annotator.token.recursive_tokenizer"]], "regextokenizer (class in sparknlp.annotator.token.regex_tokenizer)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer"]], "setmaxlength() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMaxLength"]], "setminlength() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setMinLength"]], "setpattern() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPattern"]], "setpositionalmask() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPositionalMask"]], "setpreserveposition() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setPreservePosition"]], "settolowercase() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setToLowercase"]], "settrimwhitespace() (regextokenizer method)": [[118, "sparknlp.annotator.token.regex_tokenizer.RegexTokenizer.setTrimWhitespace"]], "sparknlp.annotator.token.regex_tokenizer": [[118, "module-sparknlp.annotator.token.regex_tokenizer"]], "tokenizer (class in sparknlp.annotator.token.tokenizer)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer"]], "tokenizermodel (class in sparknlp.annotator.token.tokenizer)": [[119, "sparknlp.annotator.token.tokenizer.TokenizerModel"]], "addcontextchars() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.addContextChars"]], "addexception() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.addException"]], "addinfixpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.addInfixPattern"]], "addsplitchars() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.addSplitChars"]], "addsplitchars() (tokenizermodel method)": [[119, "sparknlp.annotator.token.tokenizer.TokenizerModel.addSplitChars"]], "getcasesensitiveexceptions() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getCaseSensitiveExceptions"]], "getcontextchars() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getContextChars"]], "getexceptions() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getExceptions"]], "getinfixpatterns() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getInfixPatterns"]], "getprefixpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getPrefixPattern"]], "getsplitchars() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getSplitChars"]], "getsuffixpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.getSuffixPattern"]], "pretrained() (tokenizermodel static method)": [[119, "sparknlp.annotator.token.tokenizer.TokenizerModel.pretrained"]], "setcasesensitiveexceptions() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setCaseSensitiveExceptions"]], "setcontextchars() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setContextChars"]], "setexceptions() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptions"]], "setexceptionspath() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setExceptionsPath"]], "setinfixpatterns() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setInfixPatterns"]], "setmaxlength() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setMaxLength"]], "setminlength() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setMinLength"]], "setprefixpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setPrefixPattern"]], "setsplitchars() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitChars"]], "setsplitchars() (tokenizermodel method)": [[119, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitChars"]], "setsplitpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setSplitPattern"]], "setsplitpattern() (tokenizermodel method)": [[119, "sparknlp.annotator.token.tokenizer.TokenizerModel.setSplitPattern"]], "setsuffixpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setSuffixPattern"]], "settargetpattern() (tokenizer method)": [[119, "sparknlp.annotator.token.tokenizer.Tokenizer.setTargetPattern"]], "sparknlp.annotator.token.tokenizer": [[119, "module-sparknlp.annotator.token.tokenizer"]], "sparknlp.annotator.ws": [[120, "module-sparknlp.annotator.ws"]], "wordsegmenterapproach (class in sparknlp.annotator.ws.word_segmenter)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach"]], "wordsegmentermodel (class in sparknlp.annotator.ws.word_segmenter)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel"]], "getambiguitythreshold() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getAmbiguityThreshold"]], "getfrequencythreshold() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getFrequencyThreshold"]], "getniterations() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.getNIterations"]], "pretrained() (wordsegmentermodel static method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.pretrained"]], "setambiguitythreshold() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setAmbiguityThreshold"]], "setenableregextokenizer() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setEnableRegexTokenizer"]], "setenableregextokenizer() (wordsegmentermodel method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setEnableRegexTokenizer"]], "setfrequencythreshold() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setFrequencyThreshold"]], "setniterations() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setNIterations"]], "setpattern() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPattern"]], "setpattern() (wordsegmentermodel method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setPattern"]], "setposcolumn() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setPosColumn"]], "settolowercase() (wordsegmenterapproach method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach.setToLowercase"]], "settolowercase() (wordsegmentermodel method)": [[121, "sparknlp.annotator.ws.word_segmenter.WordSegmenterModel.setToLowercase"]], "sparknlp.annotator.ws.word_segmenter": [[121, "module-sparknlp.annotator.ws.word_segmenter"]], "audioassembler (class in sparknlp.base.audio_assembler)": [[122, "sparknlp.base.audio_assembler.AudioAssembler"]], "getoutputcol() (audioassembler method)": [[122, "sparknlp.base.audio_assembler.AudioAssembler.getOutputCol"]], "setinputcol() (audioassembler method)": [[122, "sparknlp.base.audio_assembler.AudioAssembler.setInputCol"]], "setoutputcol() (audioassembler method)": [[122, "sparknlp.base.audio_assembler.AudioAssembler.setOutputCol"]], "sparknlp.base.audio_assembler": [[122, "module-sparknlp.base.audio_assembler"]], "chunk2doc (class in sparknlp.base.chunk2_doc)": [[123, "sparknlp.base.chunk2_doc.Chunk2Doc"]], "sparknlp.base.chunk2_doc": [[123, "module-sparknlp.base.chunk2_doc"]], "date2chunk (class in sparknlp.base.date2_chunk)": [[124, "sparknlp.base.date2_chunk.Date2Chunk"]], "sparknlp.base.date2_chunk": [[124, "module-sparknlp.base.date2_chunk"]], "doc2chunk (class in sparknlp.base.doc2_chunk)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk"]], "setchunkcol() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setChunkCol"]], "setfailonmissing() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setFailOnMissing"]], "setisarray() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setIsArray"]], "setlowercase() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setLowerCase"]], "setstartcol() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartCol"]], "setstartcolbytokenindex() (doc2chunk method)": [[125, "sparknlp.base.doc2_chunk.Doc2Chunk.setStartColByTokenIndex"]], "sparknlp.base.doc2_chunk": [[125, "module-sparknlp.base.doc2_chunk"]], "documentassembler (class in sparknlp.base.document_assembler)": [[126, "sparknlp.base.document_assembler.DocumentAssembler"]], "getoutputcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.getOutputCol"]], "setcleanupmode() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setCleanupMode"]], "setidcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setIdCol"]], "setinputcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setInputCol"]], "setmetadatacol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setMetadataCol"]], "setoutputcol() (documentassembler method)": [[126, "sparknlp.base.document_assembler.DocumentAssembler.setOutputCol"]], "sparknlp.base.document_assembler": [[126, "module-sparknlp.base.document_assembler"]], "embeddingsfinisher (class in sparknlp.base.embeddings_finisher)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher"]], "getinputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getInputCols"]], "getoutputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.getOutputCols"]], "setcleanannotations() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setCleanAnnotations"]], "setinputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setInputCols"]], "setoutputasvector() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputAsVector"]], "setoutputcols() (embeddingsfinisher method)": [[127, "sparknlp.base.embeddings_finisher.EmbeddingsFinisher.setOutputCols"]], "sparknlp.base.embeddings_finisher": [[127, "module-sparknlp.base.embeddings_finisher"]], "finisher (class in sparknlp.base.finisher)": [[128, "sparknlp.base.finisher.Finisher"]], "getinputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.getInputCols"]], "getoutputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.getOutputCols"]], "setannotationsplitsymbol() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setAnnotationSplitSymbol"]], "setcleanannotations() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setCleanAnnotations"]], "setincludemetadata() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setIncludeMetadata"]], "setinputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setInputCols"]], "setoutputasarray() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setOutputAsArray"]], "setoutputcols() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setOutputCols"]], "setparseembeddingsvectors() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setParseEmbeddingsVectors"]], "setvaluesplitsymbol() (finisher method)": [[128, "sparknlp.base.finisher.Finisher.setValueSplitSymbol"]], "sparknlp.base.finisher": [[128, "module-sparknlp.base.finisher"]], "graphfinisher (class in sparknlp.base.graph_finisher)": [[129, "sparknlp.base.graph_finisher.GraphFinisher"]], "setcleanannotations() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setCleanAnnotations"]], "setinputcol() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setInputCol"]], "setoutputasarray() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setOutputAsArray"]], "setoutputcol() (graphfinisher method)": [[129, "sparknlp.base.graph_finisher.GraphFinisher.setOutputCol"]], "sparknlp.base.graph_finisher": [[129, "module-sparknlp.base.graph_finisher"]], "hasrecursivefit (class in sparknlp.base.has_recursive_fit)": [[130, "sparknlp.base.has_recursive_fit.HasRecursiveFit"]], "sparknlp.base.has_recursive_fit": [[130, "module-sparknlp.base.has_recursive_fit"]], "hasrecursivetransform (class in sparknlp.base.has_recursive_transform)": [[131, "sparknlp.base.has_recursive_transform.HasRecursiveTransform"]], "sparknlp.base.has_recursive_transform": [[131, "module-sparknlp.base.has_recursive_transform"]], "imageassembler (class in sparknlp.base.image_assembler)": [[132, "sparknlp.base.image_assembler.ImageAssembler"]], "getoutputcol() (imageassembler method)": [[132, "sparknlp.base.image_assembler.ImageAssembler.getOutputCol"]], "setinputcol() (imageassembler method)": [[132, "sparknlp.base.image_assembler.ImageAssembler.setInputCol"]], "setoutputcol() (imageassembler method)": [[132, "sparknlp.base.image_assembler.ImageAssembler.setOutputCol"]], "sparknlp.base.image_assembler": [[132, "module-sparknlp.base.image_assembler"]], "sparknlp.base": [[133, "module-sparknlp.base"]], "lightpipeline (class in sparknlp.base.light_pipeline)": [[134, "sparknlp.base.light_pipeline.LightPipeline"]], "annotate() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.annotate"]], "fullannotate() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotate"]], "fullannotateimage() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.fullAnnotateImage"]], "getignoreunsupported() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.getIgnoreUnsupported"]], "setignoreunsupported() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.setIgnoreUnsupported"]], "sparknlp.base.light_pipeline": [[134, "module-sparknlp.base.light_pipeline"]], "transform() (lightpipeline method)": [[134, "sparknlp.base.light_pipeline.LightPipeline.transform"]], "multidocumentassembler (class in sparknlp.base.multi_document_assembler)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler"]], "getoutputcols() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.getOutputCols"]], "setcleanupmode() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setCleanupMode"]], "setidcol() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol"]], "setinputcols() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setInputCols"]], "setmetadatacol() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setMetadataCol"]], "setoutputcols() (multidocumentassembler method)": [[135, "sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setOutputCols"]], "sparknlp.base.multi_document_assembler": [[135, "module-sparknlp.base.multi_document_assembler"]], "recursivepipeline (class in sparknlp.base.recursive_pipeline)": [[136, "sparknlp.base.recursive_pipeline.RecursivePipeline"]], "recursivepipelinemodel (class in sparknlp.base.recursive_pipeline)": [[136, "sparknlp.base.recursive_pipeline.RecursivePipelineModel"]], "sparknlp.base.recursive_pipeline": [[136, "module-sparknlp.base.recursive_pipeline"]], "tableassembler (class in sparknlp.base.table_assembler)": [[137, "sparknlp.base.table_assembler.TableAssembler"]], "setcsvdelimiter() (tableassembler method)": [[137, "sparknlp.base.table_assembler.TableAssembler.setCsvDelimiter"]], "setescapecsvdelimiter() (tableassembler method)": [[137, "sparknlp.base.table_assembler.TableAssembler.setEscapeCsvDelimiter"]], "setinputformat() (tableassembler method)": [[137, "sparknlp.base.table_assembler.TableAssembler.setInputFormat"]], "sparknlp.base.table_assembler": [[137, "module-sparknlp.base.table_assembler"]], "token2chunk (class in sparknlp.base.token2_chunk)": [[138, "sparknlp.base.token2_chunk.Token2Chunk"]], "sparknlp.base.token2_chunk": [[138, "module-sparknlp.base.token2_chunk"]], "tokenassembler (class in sparknlp.base.token_assembler)": [[139, "sparknlp.base.token_assembler.TokenAssembler"]], "setpreserveposition() (tokenassembler method)": [[139, "sparknlp.base.token_assembler.TokenAssembler.setPreservePosition"]], "sparknlp.base.token_assembler": [[139, "module-sparknlp.base.token_assembler"]], "annotatorapproach (class in sparknlp.common.annotator_approach)": [[140, "sparknlp.common.annotator_approach.AnnotatorApproach"]], "sparknlp.common.annotator_approach": [[140, "module-sparknlp.common.annotator_approach"]], "annotatormodel (class in sparknlp.common.annotator_model)": [[141, "sparknlp.common.annotator_model.AnnotatorModel"]], "sparknlp.common.annotator_model": [[141, "module-sparknlp.common.annotator_model"]], "annotatorproperties (class in sparknlp.common.annotator_properties)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties"]], "getinputcols() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.getInputCols"]], "getlazyannotator() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.getLazyAnnotator"]], "getoutputcol() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.getOutputCol"]], "setinputcols() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.setInputCols"]], "setlazyannotator() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.setLazyAnnotator"]], "setoutputcol() (annotatorproperties method)": [[142, "sparknlp.common.annotator_properties.AnnotatorProperties.setOutputCol"]], "sparknlp.common.annotator_properties": [[142, "module-sparknlp.common.annotator_properties"]], "sparknlp.common.annotator_type": [[143, "module-sparknlp.common.annotator_type"]], "sparknlp.common.coverage_result": [[144, "module-sparknlp.common.coverage_result"]], "sparknlp.common": [[145, "module-sparknlp.common"]], "hasembeddingsproperties (class in sparknlp.common.properties)": [[146, "sparknlp.common.properties.HasEmbeddingsProperties"]], "getdimension() (hasembeddingsproperties method)": [[146, "sparknlp.common.properties.HasEmbeddingsProperties.getDimension"]], "setdimension() (hasembeddingsproperties method)": [[146, "sparknlp.common.properties.HasEmbeddingsProperties.setDimension"]], "sparknlp.common.properties": [[146, "module-sparknlp.common.properties"]], "readas (class in sparknlp.common.read_as)": [[147, "sparknlp.common.read_as.ReadAs"]], "sparknlp.common.read_as": [[147, "module-sparknlp.common.read_as"]], "recursiveannotatorapproach (class in sparknlp.common.recursive_annotator_approach)": [[148, "sparknlp.common.recursive_annotator_approach.RecursiveAnnotatorApproach"]], "sparknlp.common.recursive_annotator_approach": [[148, "module-sparknlp.common.recursive_annotator_approach"]], "sparknlp.common.storage": [[149, "module-sparknlp.common.storage"]], "externalresource() (in module sparknlp.common.utils)": [[150, "sparknlp.common.utils.ExternalResource"]], "sparknlp.common.utils": [[150, "module-sparknlp.common.utils"]], "explode_annotations_col() (in module sparknlp.functions)": [[151, "sparknlp.functions.explode_annotations_col"]], "filter_by_annotations_col() (in module sparknlp.functions)": [[151, "sparknlp.functions.filter_by_annotations_col"]], "map_annotations() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations"]], "map_annotations_array() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_array"]], "map_annotations_col() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_col"]], "map_annotations_cols() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_cols"]], "map_annotations_strict() (in module sparknlp.functions)": [[151, "sparknlp.functions.map_annotations_strict"]], "sparknlp.functions": [[151, "module-sparknlp.functions"]], "sparknlp": [[152, "module-sparknlp"]], "start() (in module sparknlp)": [[152, "sparknlp.start"]], "version() (in module sparknlp)": [[152, "sparknlp.version"]], "annotatorjavamlreadable (class in sparknlp.internal.annotator_java_ml)": [[153, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable"]], "annotatorjavamlreader (class in sparknlp.internal.annotator_java_ml)": [[153, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReader"]], "read() (annotatorjavamlreadable class method)": [[153, "sparknlp.internal.annotator_java_ml.AnnotatorJavaMLReadable.read"]], "sparknlp.internal.annotator_java_ml": [[153, "module-sparknlp.internal.annotator_java_ml"]], "annotatortransformer (class in sparknlp.internal.annotator_transformer)": [[154, "sparknlp.internal.annotator_transformer.AnnotatorTransformer"]], "sparknlp.internal.annotator_transformer": [[154, "module-sparknlp.internal.annotator_transformer"]], "extendedjavawrapper (class in sparknlp.internal.extended_java_wrapper)": [[155, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper"]], "new_java_array() (extendedjavawrapper method)": [[155, "sparknlp.internal.extended_java_wrapper.ExtendedJavaWrapper.new_java_array"]], "sparknlp.internal.extended_java_wrapper": [[155, "module-sparknlp.internal.extended_java_wrapper"]], "sparknlp.internal": [[156, "module-sparknlp.internal"]], "paramsgetterssetters (class in sparknlp.internal.params_getters_setters)": [[157, "sparknlp.internal.params_getters_setters.ParamsGettersSetters"]], "getparamvalue() (paramsgetterssetters method)": [[157, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.getParamValue"]], "setparamvalue() (paramsgetterssetters method)": [[157, "sparknlp.internal.params_getters_setters.ParamsGettersSetters.setParamValue"]], "sparknlp.internal.params_getters_setters": [[157, "module-sparknlp.internal.params_getters_setters"]], "recursiveestimator (class in sparknlp.internal.recursive)": [[158, "sparknlp.internal.recursive.RecursiveEstimator"]], "recursivetransformer (class in sparknlp.internal.recursive)": [[158, "sparknlp.internal.recursive.RecursiveTransformer"]], "fit() (recursiveestimator method)": [[158, "sparknlp.internal.recursive.RecursiveEstimator.fit"]], "sparknlp.internal.recursive": [[158, "module-sparknlp.internal.recursive"]], "cometlogger (class in sparknlp.logging.comet)": [[159, "sparknlp.logging.comet.CometLogger"]], "end() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.end"]], "log_asset() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_asset"]], "log_asset_data() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_asset_data"]], "log_completed_run() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_completed_run"]], "log_metrics() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_metrics"]], "log_parameters() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_parameters"]], "log_pipeline_parameters() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_pipeline_parameters"]], "log_visualization() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.log_visualization"]], "monitor() (cometlogger method)": [[159, "sparknlp.logging.comet.CometLogger.monitor"]], "sparknlp.logging.comet": [[159, "module-sparknlp.logging.comet"]], "sparknlp.logging": [[160, "module-sparknlp.logging"]], "sparknlp.pretrained": [[161, "module-sparknlp.pretrained"]], "pretrainedpipeline (class in sparknlp.pretrained.pretrained_pipeline)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline"]], "annotate() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.annotate"]], "fullannotate() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotate"]], "fullannotateimage() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.fullAnnotateImage"]], "sparknlp.pretrained.pretrained_pipeline": [[162, "module-sparknlp.pretrained.pretrained_pipeline"]], "transform() (pretrainedpipeline method)": [[162, "sparknlp.pretrained.pretrained_pipeline.PretrainedPipeline.transform"]], "resourcedownloader (class in sparknlp.pretrained.resource_downloader)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader"]], "clearcache() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.clearCache"]], "downloadmodel() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModel"]], "downloadmodeldirectly() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadModelDirectly"]], "downloadpipeline() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.downloadPipeline"]], "showavailableannotators() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showAvailableAnnotators"]], "showpublicmodels() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicModels"]], "showpublicpipelines() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showPublicPipelines"]], "showuncategorizedresources() (resourcedownloader static method)": [[163, "sparknlp.pretrained.resource_downloader.ResourceDownloader.showUnCategorizedResources"]], "sparknlp.pretrained.resource_downloader": [[163, "module-sparknlp.pretrained.resource_downloader"]], "sparknlp.pretrained.utils": [[164, "module-sparknlp.pretrained.utils"]], "conll (class in sparknlp.training.conll)": [[165, "sparknlp.training.conll.CoNLL"]], "readdataset() (conll method)": [[165, "sparknlp.training.conll.CoNLL.readDataset"]], "sparknlp.training.conll": [[165, "module-sparknlp.training.conll"]], "conllu (class in sparknlp.training.conllu)": [[166, "sparknlp.training.conllu.CoNLLU"]], "readdataset() (conllu method)": [[166, "sparknlp.training.conllu.CoNLLU.readDataset"]], "sparknlp.training.conllu": [[166, "module-sparknlp.training.conllu"]], "sparknlp.training": [[167, "module-sparknlp.training"]], "pos (class in sparknlp.training.pos)": [[168, "sparknlp.training.pos.POS"]], "readdataset() (pos method)": [[168, "sparknlp.training.pos.POS.readDataset"]], "sparknlp.training.pos": [[168, "module-sparknlp.training.pos"]], "pubtator (class in sparknlp.training.pub_tator)": [[169, "sparknlp.training.pub_tator.PubTator"]], "readdataset() (pubtator method)": [[169, "sparknlp.training.pub_tator.PubTator.readDataset"]], "sparknlp.training.pub_tator": [[169, "module-sparknlp.training.pub_tator"]], "sparknlp.training.tfgraphs": [[170, "module-sparknlp.training.tfgraphs"]], "sparknlp.upload_to_hub": [[171, "module-sparknlp.upload_to_hub"]], "sparknlp.util": [[172, "module-sparknlp.util"]]}})