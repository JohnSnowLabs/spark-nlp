<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Spark NLP for Healthcare | John Snow Labs</title><meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/licensed_release_notes"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" >
<link rel="stylesheet" href="/static/models.css" /><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP for Healthcare</li><li class="toc-h2"><a href="/docs/en/license_getting_started">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/licensed_install">Installation</a></li><li class="toc-h2"><a href="/docs/en/licensed_annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/licensed_training">Training</a></li><li class="toc-h2"><a href="/docs/en/licensed_models">Models</a></li><li class="toc-h2"><a href="/docs/en/evaluation">Evaluation</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_synapseml">Serving Spark NLP&#58 SynapseML</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_fastapi">Serving Spark NLP&#58 FastAPI</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_databricks_mlflow">Serving Spark NLP&#58 MLFlow on Databricks</a></li><li class="toc-h2"><a href="/licensed/api/">Scala API (Scaladoc)</a></li><li class="toc-h2"><a href="/licensed/api/python">Python API (Sphinx)</a></li><li class="toc-h2"><a href="/docs/en/licensed_version_compatibility">Version Compatibility</a></li><li class="toc-h2 active"><a href="/docs/en/licensed_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/docs/en/benchmark">Cluster Speed Benchmarks</a></li><li class="toc-h2"><a href="/docs/en/cpu-ner-benchmark">CPU NER Benchmarks</a></li><li class="toc-h2"><a href="/docs/en/CPUvsGPUbenchmark_healthcare">GPU vs CPU benchmarks</a></li><li class="toc-h2"><a href="/docs/en/best_practices_pretrained_models">Best Practices Using Pretrained Models Together</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) --><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/demos">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class="fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://www.johnsnowlabs.com/slack-redirect/"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><div class="header-nav"><div class="main-docs">
  <ul class="breadcrambs">
    <li><a href="/docs">Documentation</a></li>
    <li>Spark NLP for Healthcare Release Notes</li>
  </ul>
</div></div><header class="main-docs"><h1>Spark NLP for Healthcare Release Notes</h1></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/licensed_release_notes.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Spark NLP for Healthcare Release Notes"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><h2 id="352">3.5.2</h2>

<h4 id="highlights">Highlights</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> annotator to create graphs for training NER, Assertion, Relation Extraction, and Generic Classifier models</li>
  <li>Default TF graphs added for <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code> to let users train models without custom graphs</li>
  <li>New functionalities in <code class="language-plaintext highlighter-rouge">ContextualParserApproach</code></li>
  <li>Printing the list of clinical pretrained models and pipelines with one-liner</li>
  <li>New clinical models
    <ul>
      <li>Clinical NER model (<code class="language-plaintext highlighter-rouge">ner_biomedical_bc2gm</code>)</li>
      <li>Clinical <code class="language-plaintext highlighter-rouge">ChunkMapper</code> models (<code class="language-plaintext highlighter-rouge">abbreviation_mapper</code>, <code class="language-plaintext highlighter-rouge">rxnorm_ndc_mapper</code>, <code class="language-plaintext highlighter-rouge">drug_brandname_ndc_mapper</code>, <code class="language-plaintext highlighter-rouge">rxnorm_action_treatment_mapper</code>)</li>
    </ul>
  </li>
  <li>Bug fixes</li>
  <li>New and updated notebooks</li>
  <li>List of recently updated or added models</li>
</ul>

<h4 id="tfgraphbuilder-annotator-to-create-graphs-for-training-ner-assertion-relation-extraction-and-generic-classifier-models"><code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> annotator to create graphs for Training NER, Assertion, Relation Extraction, and Generic Classifier Models</h4>

<p>We have a new annotator used to create graphs in the model training pipeline. <code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> inspects the data and creates the proper graph if a suitable version of TensorFlow (&lt;= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach.</p>

<p>You can use this builder with <code class="language-plaintext highlighter-rouge">MedicalNerApproach</code>, <code class="language-plaintext highlighter-rouge">RelationExtractionApproach</code>, <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code>, and <code class="language-plaintext highlighter-rouge">GenericClassifierApproach</code></p>

<p><em>Example:</em></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graph_folder_path</span> <span class="o">=</span> <span class="s">"./medical_graphs"</span>

<span class="n">med_ner_graph_builder</span> <span class="o">=</span> <span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"ner_dl"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"auto"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setHiddenUnitsNumber</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder_path</span><span class="p">)</span>

<span class="n">med_ner</span> <span class="o">=</span> <span class="n">MedicalNerApproach</span><span class="p">()</span> \
    <span class="p">...</span>
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>

<span class="n">medner_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()([</span>
    <span class="p">...,</span>
    <span class="n">med_ner_graph_builder</span><span class="p">,</span>
    <span class="n">med_ner</span>    
    <span class="p">])</span>
</code></pre></div></div>

<p>For more examples, please check <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb">TFGraph Builder Notebook</a>.</p>

<h4 id="default-tf-graphs-added-for-assertiondlapproach-to-let-users-train-models-without-custom-graphs">Default TF graphs added for <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code> to let users train models without custom graphs</h4>

<p>We added default TF graphs for the <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code> to let users train assertion models without specifying any custom TF graph.</p>

<p><strong>Default Graph Features:</strong></p>
<ul>
  <li>Feature Sizes: 100, 200, 768</li>
  <li>Number of Classes: 2, 4, 8</li>
</ul>

<h4 id="new-functionalities-in-contextualparserapproach">New Functionalities in <code class="language-plaintext highlighter-rouge">ContextualParserApproach</code></h4>

<ul>
  <li>Added <code class="language-plaintext highlighter-rouge">.setOptionalContextRules</code> parameter that allows to output regex matches regardless of context match (prefix, suffix configuration).</li>
  <li>Allows sending a JSON string of the configuration file to <code class="language-plaintext highlighter-rouge">setJsonPath</code> parameter.</li>
</ul>

<p><strong>Confidence Value Scenarios:</strong></p>

<ol>
  <li>When there is regex match only, the confidence value will be 0.5.</li>
  <li>When there are regex and prefix matches together, the confidence value will be &gt; 0.5 depending on the distance between target token and the prefix.</li>
  <li>When there are regex and suffix matches together, the confidence value will be &gt; 0.5 depending on the distance between target token and the suffix.</li>
  <li>When there are regex, prefix, and suffix matches all together, the confidence value will be &gt; than the other scenarios.</li>
</ol>

<p><em>Example</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">jsonString</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"entity"</span><span class="p">:</span> <span class="s">"CarId"</span><span class="p">,</span>
    <span class="s">"ruleScope"</span><span class="p">:</span> <span class="s">"sentence"</span><span class="p">,</span>
    <span class="s">"completeMatchRegex"</span><span class="p">:</span> <span class="s">"false"</span><span class="p">,</span>
    <span class="s">"regex"</span><span class="p">:</span> <span class="s">"</span><span class="se">\\</span><span class="s">d+"</span><span class="p">,</span>
    <span class="s">"prefix"</span><span class="p">:</span> <span class="p">[</span><span class="s">"red"</span><span class="p">],</span>
    <span class="s">"contextLength"</span><span class="p">:</span> <span class="mi">100</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"jsonString.json"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">jsonString</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

<span class="n">contextual_parser</span> <span class="o">=</span> <span class="n">ContextualParserApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"jsonString.json"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOptionalContextRules</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="printing-the-list-of-clinical-pretrained-models-and-pipelines-with-one-liner">Printing the List of Clinical Pretrained Models and Pipelines with One-Liner</h4>

<p>Now we can check what the clinical model names are of a specific annotator and the names of clinical pretrained pipelines in a language.</p>

<ul>
  <li><strong>Listing Clinical Model Names:</strong></li>
</ul>

<p><em>Example</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp_jsl.pretrained</span> <span class="kn">import</span> <span class="n">InternalResourceDownloader</span>

<span class="n">InternalResourceDownloader</span><span class="p">.</span><span class="n">showPrivateModels</span><span class="p">(</span><span class="s">"AssertionDLModel"</span><span class="p">)</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------------+------+---------+
| Model                             | lang | version |
+-----------------------------------+------+---------+
| assertion_ml                      |  en  | 2.0.2   |
| assertion_dl                      |  en  | 2.0.2   |
| assertion_dl_healthcare           |  en  | 2.7.2   |
| assertion_dl_biobert              |  en  | 2.7.2   |
| assertion_dl                      |  en  | 2.7.2   |
| assertion_dl_radiology            |  en  | 2.7.4   |
| assertion_jsl_large               |  en  | 3.1.2   |
| assertion_jsl                     |  en  | 3.1.2   |
| assertion_dl_scope_L10R10         |  en  | 3.4.2   |
| assertion_dl_biobert_scope_L10R10 |  en  | 3.4.2   |
+-----------------------------------+------+---------+
</code></pre></div></div>

<ul>
  <li><strong>Listing Clinical Pretrained Pipelines:</strong></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp_jsl.pretrained</span> <span class="kn">import</span> <span class="n">InternalResourceDownloader</span>

<span class="n">InternalResourceDownloader</span><span class="p">.</span><span class="n">showPrivatePipelines</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------------------------------------+------+---------+
| Pipeline                                               | lang | version |
+--------------------------------------------------------+------+---------+
| clinical_analysis                                      |  en  | 2.4.0   |
| clinical_ner_assertion                                 |  en  | 2.4.0   |
| clinical_deidentification                              |  en  | 2.4.0   |
| clinical_analysis                                      |  en  | 2.4.0   |
| explain_clinical_doc_ade                               |  en  | 2.7.3   |
| icd10cm_snomed_mapping                                 |  en  | 2.7.5   |
| recognize_entities_posology                            |  en  | 3.0.0   |
| explain_clinical_doc_carp                              |  en  | 3.0.0   |
| recognize_entities_posology                            |  en  | 3.0.0   |
| explain_clinical_doc_ade                               |  en  | 3.0.0   |
| explain_clinical_doc_era                               |  en  | 3.0.0   |
| icd10cm_snomed_mapping                                 |  en  | 3.0.2   |
| snomed_icd10cm_mapping                                 |  en  | 3.0.2   |
| icd10cm_umls_mapping                                   |  en  | 3.0.2   |
| snomed_umls_mapping                                    |  en  | 3.0.2   |
| ...                                                    |  ... | ...     |
+--------------------------------------------------------+------+---------+
</code></pre></div></div>

<h4 id="new-ner_biomedical_bc2gm-ner-model">New <code class="language-plaintext highlighter-rouge">ner_biomedical_bc2gm</code> NER Model</h4>

<p>This model has been trained to extract genes/proteins from a medical text.</p>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/05/10/ner_biomedical_bc2gm_en_3_0.html">Model Card</a> for more details.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_biomedical_bc2gm"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Immunohistochemical staining was positive for S-100 in all 9 cases stained, positive for HMB-45 in 9 (90%) of 10, and negative for cytokeratin in all 9 cases in which myxoid melanoma remained in the block after previous sections."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div></div>
<p><em>Results</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------+------------+
|chunk      |ner_label   |
+-----------+------------+
|S-100      |GENE_PROTEIN|
|HMB-45     |GENE_PROTEIN|
|cytokeratin|GENE_PROTEIN|
+-----------+------------+
</code></pre></div></div>

<h4 id="new-clinical-chunkmapper-models">New Clinical <code class="language-plaintext highlighter-rouge">ChunkMapper</code> Models</h4>

<p>We have 4 new <code class="language-plaintext highlighter-rouge">ChunkMapper</code> models and a new <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Chunk Mapping Notebook</a> for showing their examples.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">drug_brandname_ndc_mapper</code>: This model maps drug brand names to corresponding National Drug Codes (NDC). Product NDCs for each strength are returned in result and metadata.</li>
</ul>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/05/11/drug_brandname_ndc_mapper_en_3_0.html">Model Card</a> for more details.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"drug_brandname_ndc_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ndc"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setRel</span><span class="p">(</span><span class="s">"Strength_NDC"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PipelineModel</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
                                 <span class="n">chunkerMapper</span><span class="p">])</span>  

<span class="n">light_model</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">light_model</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">([</span><span class="s">"zytiga"</span><span class="p">,</span> <span class="s">"ZYVOX"</span><span class="p">,</span> <span class="s">"ZYTIGA"</span><span class="p">])</span>
</code></pre></div></div>

<p><em>Results</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------+--------------------------+-----------------------------------------------------------+
| Brandname   | Strenth_NDC              | Other_NDSs                                                |
+-------------+--------------------------+-----------------------------------------------------------+
| zytiga      | 500 mg/1 | 57894-195     | <span class="o">[</span><span class="s1">'250 mg/1 | 57894-150'</span><span class="o">]</span>                                  |
| ZYVOX       | 600 mg/300mL | 0009-4992 | <span class="o">[</span><span class="s1">'600 mg/300mL | 66298-7807'</span>, <span class="s1">'600 mg/300mL | 0009-7807'</span><span class="o">]</span> |
| ZYTIGA      | 500 mg/1 | 57894-195     | <span class="o">[</span><span class="s1">'250 mg/1 | 57894-150'</span><span class="o">]</span>                                  |
+-------------+--------------------------+-----------------------------------------------------------+

</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">abbreviation_mapper</code>: This model maps abbreviations and acronyms of medical regulatory activities with their definitions.</li>
</ul>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/05/11/abbreviation_mapper_en_3_0.html">Model Card</a> for details.</p>

<p><em>Example:</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input <span class="o">=</span> <span class="o">[</span><span class="s2">"""Gravid with estimated fetal weight of 6-6/12 pounds.
            LABORATORY DATA: Laboratory tests include a CBC which is normal. 
            HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet."""</span><span class="o">]</span>
           
<span class="o">&gt;&gt;</span> output:
+------------+----------------------------+
|Abbreviation|Definition                  |
+------------+----------------------------+
|CBC         |complete blood count        |
|HIV         |human immunodeficiency virus|
+------------+----------------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">rxnorm_action_treatment_mapper</code>: RxNorm and RxNorm Extension codes with their corresponding action and treatment. Action refers to the function of the drug in various body systems; treatment refers to which disease the drug is used to treat.</li>
</ul>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/05/08/rxnorm_action_treatment_mapper_en_3_0.html">Model Card</a> for more details.</p>

<p><em>Example:</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input <span class="o">=</span> <span class="o">[</span><span class="s1">'Sinequan 150 MG'</span>, <span class="s1">'Zonalon 50 mg'</span><span class="o">]</span>
           
<span class="o">&gt;&gt;</span> output:
+---------------+------------+---------------+
|chunk          |rxnorm_code |Action         |
+---------------+------------+---------------+
|Sinequan 150 MG|1000067     |Antidepressant |
|Zonalon 50 mg  |103971      |Analgesic      |
+---------------+------------+---------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">rxnorm_ndc_mapper</code>: This pretrained model maps RxNorm and RxNorm Extension codes with corresponding National Drug Codes (NDC).</li>
</ul>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/05/09/rxnorm_ndc_mapper_en_3_0.html">Model Card</a> for more details.</p>

<p><em>Example:</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input <span class="o">=</span> <span class="o">[</span><span class="s1">'doxepin hydrochloride 50 MG/ML'</span>, <span class="s1">'macadamia nut 100 MG/ML'</span><span class="o">]</span>
           
<span class="o">&gt;&gt;</span> output:
+------------------------------+------------+------------+
|chunk                         |rxnorm_code |Product NDC |
+------------------------------+------------+------------+
|doxepin hydrochloride 50 MG/ML|1000091     |00378-8117  |
|macadamia nut 100 MG/ML       |212433      |00064-2120  |
+------------------------------+------------+------------+
</code></pre></div></div>

<h4 id="bug-fixes">Bug Fixes</h4>

<p>We fixed some issues in <code class="language-plaintext highlighter-rouge">DrugNormalizer</code>, <code class="language-plaintext highlighter-rouge">DateNormalizer</code> and <code class="language-plaintext highlighter-rouge">ContextualParserApproach</code> annotators.</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">DateNormalizer</code></strong> : We fixed some relative date issues and also <code class="language-plaintext highlighter-rouge">DateNormalizer</code> takes account the Leap years now.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">DrugNormalizer</code></strong> : Fixed some formats.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">ContextualParserApproach</code></strong> :
    <ul>
      <li>Computing the right distance for prefix.</li>
      <li>Extracting the right content for suffix.</li>
      <li>Handling special characters in prefix and suffix.</li>
    </ul>
  </li>
</ul>

<h4 id="new-and-updated-notebooks">New and Updated Notebooks</h4>
<ul>
  <li>We prepared <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/1hr_workshop/SparkNLP_for_Healthcare_3h_Notebook.ipynb">Spark NLP for Healthcare 3hr Notebook</a> to cover mostly used components of Spark NLP in ODSC East 2022-3 hours hands-on workshop on ‘Modular Approach to Solve Problems at Scale in Healthcare NLP’. You can also find its Databricks version <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/databricks/python/healthcare_tutorials/SparkNLP_for_Healthcare_3h_Notebook.ipynb">here</a>.</li>
  <li>New <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Chunk Mapping Notebook</a> for showing the examples of Chunk Mapper models.</li>
  <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare/databricks_notebooks">Updated healthcare tutorial notebooks for Databricks</a> with <code class="language-plaintext highlighter-rouge">sparknlp_jsl</code> v3.5.1</li>
  <li>We have a new <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/databricks/python/healthcare_tutorials">Databricks healthcare tutorials folder</a> in which you can find all Spark NLP for Healthcare Databricks tutorial notebooks.</li>
  <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb">Updated Graph Builder Notebook</a> by adding the examples of new <code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> annotator.</li>
</ul>

<h4 id="list-of-recently-updated-or-added-models">List of Recently Updated or Added Models</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_action_treatment</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_biomedical_bc2gm</code></li>
  <li><code class="language-plaintext highlighter-rouge">abbreviation_mapper</code></li>
  <li><code class="language-plaintext highlighter-rouge">rxnorm_ndc_mapper</code></li>
  <li><code class="language-plaintext highlighter-rouge">drug_brandname_ndc_mapper</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_procedures_measurements_augmented</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_slim_billable_hcc</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_slim_normalized</code></li>
</ul>

<p><strong>For all Spark NLP for healthcare models, please check : <a href="https://nlp.johnsnowlabs.com/models?edition=Spark+NLP+for+Healthcare">Models Hub Page</a></strong></p>

<h2 id="351">3.5.1</h2>
<p>We are glad to announce that 3.5.1 version of Spark NLP for Healthcare has been released!</p>

<h4 id="highlights-1">Highlights</h4>
<ul>
  <li><strong>Deidentification</strong>:
    <ul>
      <li>New <strong>Portuguese</strong> <strong>Deidentification</strong> NER models and pretrained pipeline. This is the 6th supported language for deidentification (English, German, Spanish, Italian, French and Portuguese).</li>
    </ul>
  </li>
  <li><strong>New pretrained models and pipelines</strong>:
    <ul>
      <li>New <strong>RxNorm</strong> Sentence Entity Resolver model to map and extract pharmaceutical actions (e.g. analgesic, hypoglycemic) as well as treatments (e.g. backache, diabetes) along with the RxNorm code resolved (<code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_action_treatment</code>)</li>
      <li>New <strong>RCT</strong> classification models and pretrained pipelines to classify the sections within the abstracts of scientific articles regarding randomized clinical trials (RCT). (<code class="language-plaintext highlighter-rouge">rct_binary_classifier_use</code>, <code class="language-plaintext highlighter-rouge">rct_binary_classifier_biobert</code>, <code class="language-plaintext highlighter-rouge">bert_sequence_classifier_binary_rct_biobert</code>, <code class="language-plaintext highlighter-rouge">rct_binary_classifier_use_pipeline</code>, <code class="language-plaintext highlighter-rouge">rct_binary_classifier_biobert_pipeline</code>, <code class="language-plaintext highlighter-rouge">bert_sequence_classifier_binary_rct_biobert_pipeline</code>)</li>
    </ul>
  </li>
  <li><strong>New features</strong>:
    <ul>
      <li>Add <code class="language-plaintext highlighter-rouge">getClasses()</code> attribute for <code class="language-plaintext highlighter-rouge">MedicalBertForTokenClassifier</code> and <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> to find out the entity classes of the models</li>
      <li>Download the AnnotatorModels from the healthcare library using the Healthcare version instead of the open source version (the pretrained models were used to be dependent on open source Spark NLP version before)</li>
      <li>New functionality to download and extract clinical models from S3 via direct zip url.</li>
    </ul>
  </li>
  <li><strong>Core improvements</strong>:
    <ul>
      <li>Fixing the confidence scores in <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> when <code class="language-plaintext highlighter-rouge">setIncludeAllConfidenceScores</code> is true</li>
      <li>Graph_builder <code class="language-plaintext highlighter-rouge">relation_extraction</code> model file name extension problem with <code class="language-plaintext highlighter-rouge">auto</code> parameter.</li>
    </ul>
  </li>
  <li><strong>List of recently updated or added models</strong></li>
</ul>

<h4 id="portuguese-deidentification-models">Portuguese Deidentification Models</h4>

<p>This is the 6th supported language for deidentification (English, German, Spanish, Italian, French and Portuguese). This version includes two Portuguese deidentification models to mask or obfuscate Protected Health Information in the Portuguese language. The models are the following:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_generic</code>:  extracts <code class="language-plaintext highlighter-rouge">Name</code>, <code class="language-plaintext highlighter-rouge">Profession</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Contact</code> (Telephone numbers, Email addresses), <code class="language-plaintext highlighter-rouge">Location</code> (Address, City, Postal code, Hospital Name, Organization), <code class="language-plaintext highlighter-rouge">ID</code> (Social Security numbers, Medical record numbers) and <code class="language-plaintext highlighter-rouge">Sex</code> entities.</p>

    <p>See <a href="https://nlp.johnsnowlabs.com/2022/04/13/ner_deid_generic_pt_3_0.html">Model Hub Page</a> for details.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_subentity</code>: <code class="language-plaintext highlighter-rouge">Patient</code> (name), <code class="language-plaintext highlighter-rouge">Hospital</code> (name), <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Organization</code>, <code class="language-plaintext highlighter-rouge">City</code>, <code class="language-plaintext highlighter-rouge">ID</code>, <code class="language-plaintext highlighter-rouge">Street</code>, <code class="language-plaintext highlighter-rouge">Sex</code>, <code class="language-plaintext highlighter-rouge">Email</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">Profession</code>, <code class="language-plaintext highlighter-rouge">Phone</code>, <code class="language-plaintext highlighter-rouge">Country</code>, <code class="language-plaintext highlighter-rouge">Doctor</code> (name) and <code class="language-plaintext highlighter-rouge">Age</code></p>

    <p>See <a href="https://nlp.johnsnowlabs.com/2022/04/13/ner_deid_subentity_pt_3_0.html">Model Hub Page</a> for details.</p>
  </li>
</ul>

<p>You will use the <code class="language-plaintext highlighter-rouge">w2v_cc_300d</code> Portuguese Embeddings with these models. The pipeline should look as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"w2v_cc_300d"</span><span class="p">,</span> <span class="s">"pt"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_subentity</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity"</span><span class="p">,</span> <span class="s">"pt"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\    
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_deid_subentity"</span><span class="p">)</span>

<span class="n">ner_converter_subentity</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_deid_subentity"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_subentity"</span><span class="p">)</span>

<span class="n">ner_generic</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic"</span><span class="p">,</span> <span class="s">"pt"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\    
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_deid_generic"</span><span class="p">)</span>

<span class="n">ner_converter_generic</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_deid_generic"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_generic"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentencerDL</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">ner_subentity</span><span class="p">,</span>
      <span class="n">ner_converter_subentity</span><span class="p">,</span>
      <span class="n">ner_generic</span><span class="p">,</span>
      <span class="n">ner_converter_generic</span><span class="p">,</span>
      <span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""Detalhes do paciente.
Nome do paciente:  Pedro Gonçalves
NHC: 2569870.
Endereço: Rua Das Flores 23.
Código Postal: 21754-987.
Dados de cuidados.
Data de nascimento: 10/10/1963.
Idade: 53 anos
Data de admissão: 17/06/2016.
Doutora: Maria Santos"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

</code></pre></div></div>

<p>Results:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------+-------------------------------------+
|chunk            |ner_generic_label|ner_subentity_label|
+-----------------+-------------------------------------+
|Pedro Gonçalves  |      NAME       |      PATIENT      |
|2569870          |      ID         |      ID           |
|Rua Das Flores 23|      LOCATION   |      STREET       |
|21754-987        |      LOCATION   |      ZIP          |
|10/10/1963       |      DATE       |      DATE         |
|53               |      AGE        |      AGE          |
|17/06/2016       |      DATE       |      DATE         |
|Maria Santos     |      NAME       |      DOCTOR       |
+-----------------+-------------------------------------+
</code></pre></div></div>

<p>We also include a Clinical Deidentification Pipeline for Portuguese that uses <code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> NER model and also several <code class="language-plaintext highlighter-rouge">ContextualParsers</code> for rule based contextual Named Entity Recognition tasks. It’s available to be used as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">PretrainedPipeline</span>

<span class="n">deid_pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">"clinical_deidentification"</span><span class="p">,</span> <span class="s">"pt"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
</code></pre></div></div>

<p>The pretrained pipeline comes with Deidentification and Obfuscation capabilities as shows the following example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>text = """RELAÇÃO HOSPITALAR
NOME: Pedro Gonçalves
NHC: MVANSK92F09W408A
ENDEREÇO: Rua Burcardo 7
CÓDIGO POSTAL: 80139
DATA DE NASCIMENTO: 03/03/1946
IDADE: 70 anos
SEXO: Homens
E-MAIL: pgon21@tim.pt
DATA DE ADMISSÃO: 12/12/2016
DOUTORA: Eva Andrade
RELATO CLÍNICO: 70 anos, aposentado, sem alergia a medicamentos conhecida, com a seguinte história: ex-acidente de trabalho com fratura de vértebras e costelas; operado de doença de Dupuytren na mão direita e ponte ílio-femoral esquerda; diabetes tipo II, hipercolesterolemia e hiperuricemia; alcoolismo ativo, fuma 20 cigarros/dia.
Ele foi encaminhado a nós por apresentar hematúria macroscópica pós-evacuação em uma ocasião e microhematúria persistente posteriormente, com evacuação normal.
O exame físico mostrou bom estado geral, com abdome e genitais normais; o toque retal foi compatível com adenoma de próstata grau I/IV.
A urinálise mostrou 4 hemácias/campo e 0-5 leucócitos/campo; o resto do sedimento era normal.
O hemograma é normal; a bioquímica mostrou uma glicemia de 169 mg/dl e triglicerídeos 456 mg/dl; função hepática e renal são normais. PSA de 1,16 ng/ml.

DIRIGIDA A: Dr. Eva Andrade - Centro Hospitalar do Medio Ave - Avenida Dos Aliados, 56
E-MAIL: evandrade@poste.pt
"""

result = deid_pipeline.annotate(text)
</code></pre></div></div>

<p>Results:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | Sentence                       | Masked                     | Masked with Chars              | Masked with Fixed Chars   | Obfuscated                        |
|---:|:-------------------------------|:---------------------------|:-------------------------------|:--------------------------|:----------------------------------|
|  0 | RELAÇÃO HOSPITALAR             | RELAÇÃO HOSPITALAR         | RELAÇÃO HOSPITALAR             | RELAÇÃO HOSPITALAR        | RELAÇÃO HOSPITALAR                |
|    | NOME: Pedro Gonçalves          | NOME: &lt;DOCTOR&gt;             | NOME: [*************]          | NOME: ****                | NOME: Isabel Magalhães            |
|  1 | NHC: MVANSK92F09W408A          | NHC: &lt;ID&gt;                  | NHC: [**************]          | NHC: ****                 | NHC: 124 445 311                  |
|  2 | ENDEREÇO: Rua Burcardo 7       | ENDEREÇO: &lt;STREET&gt;         | ENDEREÇO: [************]       | ENDEREÇO: ****            | ENDEREÇO: Rua de Santa María, 100 |
|  3 | CÓDIGO POSTAL: 80139           | CÓDIGO POSTAL: &lt;ZIP&gt;       | CÓDIGO POSTAL: [***]           | CÓDIGO POSTAL: ****       | CÓDIGO POSTAL: 1000-306           |
|    | DATA DE NASCIMENTO: 03/03/1946 | DATA DE NASCIMENTO: &lt;DATE&gt; | DATA DE NASCIMENTO: [********] | DATA DE NASCIMENTO: ****  | DATA DE NASCIMENTO: 04/04/1946    |
|  4 | IDADE: 70 anos                 | IDADE: &lt;AGE&gt; anos          | IDADE: ** anos                 | IDADE: **** anos          | IDADE: 46 anos                    |
|  5 | SEXO: Homens                   | SEXO: &lt;SEX&gt;                | SEXO: [****]                   | SEXO: ****                | SEXO: Mulher                      |
|  6 | E-MAIL: pgon21@tim.pt          | E-MAIL: &lt;EMAIL&gt;            | E-MAIL: [***********]          | E-MAIL: ****              | E-MAIL: eric.shannon@geegle.com   |
|    | DATA DE ADMISSÃO: 12/12/2016   | DATA DE ADMISSÃO: &lt;DATE&gt;   | DATA DE ADMISSÃO: [********]   | DATA DE ADMISSÃO: ****    | DATA DE ADMISSÃO: 23/12/2016      |
|  7 | DOUTORA: Eva Andrade           | DOUTORA: &lt;DOCTOR&gt;          | DOUTORA: [*********]           | DOUTORA: ****             | DOUTORA: Isabel Magalhães         |
</code></pre></div></div>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/04/14/clinical_deidentification_pt_3_0.html">Model Hub Page</a> for details.</p>

<p>Check Spark NLP Portuguese capabilities in <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.7.Clinical_Deidentification_in_Portuguese.ipynb">4.7.Clinical_Deidentification_in_Portuguese.ipynb notebook</a> we have prepared for you.</p>

<h4 id="new-rxnorm-sentence-entity-resolver-model-sbiobertresolve_rxnorm_action_treatment">New RxNorm Sentence Entity Resolver Model (<code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_action_treatment</code>)</h4>

<p>We are releasing <code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_action_treatment</code> model that maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings. This resolver model maps and extracts pharmaceutical actions (e.g analgesic, hypoglycemic) as well as treatments (e.g backache, diabetes) along with the RxNorm code resolved. Actions and treatments of the drugs are returned in <code class="language-plaintext highlighter-rouge">all_k_aux_labels</code> column.</p>

<p>See <a href="https://nlp.johnsnowlabs.com/2022/04/25/sbiobertresolve_rxnorm_action_treatment_en_2_4.html">Model Card</a> for details.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'sbiobert_base_cased_mli'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">rxnorm_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_action_treatment"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">PipelineModel</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sbert_embedder</span><span class="p">,</span>
        <span class="n">rxnorm_resolver</span><span class="p">])</span>

<span class="n">lp_model</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">pipelineModel</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Zita 200 mg"</span><span class="p">,</span> <span class="s">"coumadin 5 mg"</span><span class="p">,</span> <span class="s">'avandia 4 mg'</span><span class="p">]</span>

<span class="n">result</span><span class="o">=</span> <span class="n">lp_model</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

</code></pre></div></div>
<p>Results* :</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | ner_chunk     |   rxnorm_code | action                                  | treatment                          |
|---:|:--------------|--------------:|:----------------------------------------|------------------------------------|
|  0 | Zita 200 mg   |        104080 | ['Analgesic', 'Antacid', 'Antipyretic'] | ['Backache', 'Pain', 'Sore Throat']|
|  1 | coumadin 5 mg |        855333 | ['Anticoagulant']                       | ['Cerebrovascular Accident']       |
|  2 | avandia 4 mg  |        261242 | ['Drugs Used In Diabets','Hypoglycemic']| ['Diabetes Mellitus', ...]         |                                                                                              |
</code></pre></div></div>

<h4 id="new-rct-classification-models-and-pretrained-pipelines">New RCT Classification Models and Pretrained Pipelines</h4>

<p>We are releasing new <strong>Randomized Clinical Trial (RCT)</strong> classification models and pretrained pipelines that can classify the sections within the abstracts of scientific articles regarding randomized clinical trials (RCT).</p>

<ul>
  <li>Classification Models:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">rct_binary_classifier_use</code> (<a href="https://nlp.johnsnowlabs.com/2022/04/24/rct_binary_classifier_use_en_3_0.html">Models Hub page</a>)</li>
      <li><code class="language-plaintext highlighter-rouge">rct_binary_classifier_biobert</code> (<a href="https://nlp.johnsnowlabs.com/2022/04/25/rct_binary_classifier_biobert_en_3_0.html">Models Hub page</a>)</li>
      <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_binary_rct_biobert</code> (<a href="https://nlp.johnsnowlabs.com/2022/04/25/bert_sequence_classifier_binary_rct_biobert_en_3_0.html">Models Hub page</a>)</li>
    </ul>
  </li>
  <li>Pretrained Pipelines:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">rct_binary_classifier_use_pipeline</code> (<a href="https://nlp.johnsnowlabs.com/2022/04/25/rct_binary_classifier_use_pipeline_en_3_0.html">Models Hub page</a>)</li>
      <li><code class="language-plaintext highlighter-rouge">rct_binary_classifier_biobert_pipeline</code> (<a href="https://nlp.johnsnowlabs.com/2022/04/25/rct_binary_classifier_biobert_pipeline_en_3_0.html">Models Hub page</a>)</li>
      <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_binary_rct_biobert_pipeline</code> (<a href="https://nlp.johnsnowlabs.com/2022/04/25/bert_sequence_classifier_binary_rct_biobert_pipeline_en_3_0.html">Models Hub page</a>)</li>
    </ul>
  </li>
</ul>

<p><em>Classification Model Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">use</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">classifier_dl</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'rct_binary_classifier_use'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">use_clf_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">use</span><span class="p">,</span>
        <span class="n">classifier_dl</span>
    <span class="p">])</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""Abstract:Based on the American Society of Anesthesiologists' Practice Guidelines for Sedation and Analgesia by Non-Anesthesiologists (ASA-SED), a sedation training course aimed at improving medical safety was developed by the Japanese Association for Medical Simulation in 2011. This study evaluated the effect of debriefing on participants' perceptions of the essential points of the ASA-SED. A total of 38 novice doctors participated in the sedation training course during the research period. Of these doctors, 18 participated in the debriefing group, and 20 participated in non-debriefing group. Scoring of participants' guideline perceptions was conducted using an evaluation sheet (nine items, 16 points) created based on the ASA-SED. The debriefing group showed a greater perception of the ASA-SED, as reflected in the significantly higher scores on the evaluation sheet (median, 16 points) than the control group (median, 13 points; p &lt; 0.05). No significant differences were identified before or during sedation, but the difference after sedation was significant (p &lt; 0.05). Debriefing after sedation training courses may contribute to better perception of the ASA-SED, and may lead to enhanced attitudes toward medical safety during sedation and analgesia. """</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">use_clf_pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

</code></pre></div></div>

<p><em>Results</em> :</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; class: True
</code></pre></div></div>

<p><em>Pretrained Pipeline Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">PretrainedPipeline</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">"rct_binary_classifier_use_pipeline"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>text = """Abstract:Based on the American Society of Anesthesiologists' Practice Guidelines for Sedation and Analgesia by Non-Anesthesiologists (ASA-SED), a sedation training course aimed at improving medical safety was developed by the Japanese Association for Medical Simulation in 2011. This study evaluated the effect of debriefing on participants' perceptions of the essential points of the ASA-SED. A total of 38 novice doctors participated in the sedation training course during the research period. Of these doctors, 18 participated in the debriefing group, and 20 participated in non-debriefing group. Scoring of participants' guideline perceptions was conducted using an evaluation sheet (nine items, 16 points) created based on the ASA-SED. The debriefing group showed a greater perception of the ASA-SED, as reflected in the significantly higher scores on the evaluation sheet (median, 16 points) than the control group (median, 13 points; p &lt; 0.05). No significant differences were identified before or during sedation, but the difference after sedation was significant (p &lt; 0.05). Debriefing after sedation training courses may contribute to better perception of the ASA-SED, and may lead to enhanced attitudes toward medical safety during sedation and analgesia. """

result = pipeline.annotate(text)
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; class: True
</code></pre></div></div>

<h4 id="new-features">New Features</h4>
<h5 id="add-getclasses-attribute-to-medicalbertfortokenclassifier-and-medicalbertforsequenceclassification">Add <code class="language-plaintext highlighter-rouge">getClasses()</code> attribute to <code class="language-plaintext highlighter-rouge">MedicalBertForTokenClassifier</code> and <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code></h5>
<p>Now you can use <code class="language-plaintext highlighter-rouge">getClasses()</code> method for checking the entity labels of  <code class="language-plaintext highlighter-rouge">MedicalBertForTokenClassifier</code> and <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> like <code class="language-plaintext highlighter-rouge">MedicalNerModel</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">MedicalBertForTokenClassifier</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_token_classifier_ner_ade"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  	<span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">)</span>\
  	<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
  	<span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
  	<span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

  <span class="n">tokenClassifier</span><span class="p">.</span><span class="n">getClasses</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="o">[</span><span class="s1">'B-DRUG'</span>, <span class="s1">'I-ADE'</span>, <span class="s1">'I-DRUG'</span>, <span class="s1">'O'</span>, <span class="s1">'B-ADE'</span><span class="o">]</span>
</code></pre></div></div>

<h5 id="download-the-annotatormodels-from-the-healthcare-library-using-the-healthcare-version-instead-of-the-open-source-version">Download the AnnotatorModels from the healthcare library using the Healthcare version instead of the open source version</h5>

<p>Now we download the private models using the Healthcare version instead of the open source version (the pretrained models were used to be dependent on open source Spark NLP version before).</p>

<h5 id="new-functionality-to-download-and-extract-clinical-models-from-s3-via-direct-link">New functionality to download and extract clinical models from S3 via direct link.</h5>
<p>Now, you can download clinical models from S3 via direct link directly by <code class="language-plaintext highlighter-rouge">downloadModelDirectly</code> method. See the <a href="https://nlp.johnsnowlabs.com/models">Models Hub Page</a> to find out the download url of each model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">ResourceDownloader</span>

  <span class="c1">#The first argument is the path to the zip file and the second one is the folder.
</span>  <span class="n">ResourceDownloader</span><span class="p">.</span><span class="n">downloadModelDirectly</span><span class="p">(</span><span class="s">"clinical/models/assertion_dl_en_2.0.2_2.4_1556655581078.zip"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>  
</code></pre></div></div>

<h4 id="core-improvements">Core improvements:</h4>

<h5 id="fix-medicalnermodel-confidence-scores-when-setincludeallconfidencescores-is-true">Fix <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> confidence scores when <code class="language-plaintext highlighter-rouge">setIncludeAllConfidenceScores</code> is <code class="language-plaintext highlighter-rouge">True</code></h5>

<p>A mismatch problem between the tag with the highest confidence score and the predicted tag in <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> is resolved.</p>

<h5 id="graph_builder-relation_extraction-model-file-name-extension-problem-with-auto-param">Graph_builder <code class="language-plaintext highlighter-rouge">relation_extraction</code> model file name extension problem with <code class="language-plaintext highlighter-rouge">auto</code> param</h5>

<p>A naming problem which occurs while generating a graph for Relation Extraction via graph builder was resolved. Now, the TF graph is generated with the correct extension (<code class="language-plaintext highlighter-rouge">.pb</code>).</p>

<h4 id="list-of-recently-updated-or-added-models-1">List of Recently Updated or Added Models</h4>

<ul>
  <li>ner_deid_generic_pt</li>
  <li>ner_deid_subentity_pt</li>
  <li>clinical_deidentification_pt</li>
  <li>sbiobertresolve_rxnorm_action_treatment</li>
  <li>rct_binary_classifier_use</li>
  <li>rct_binary_classifier_biobert</li>
  <li>bert_sequence_classifier_binary_rct_biobert</li>
  <li>rct_binary_classifier_use_pipeline</li>
  <li>rct_binary_classifier_biobert_pipeline</li>
  <li>bert_sequence_classifier_binary_rct_biobert_pipeline</li>
  <li>sbiobertresolve_ndc</li>
</ul>

<h2 id="350">3.5.0</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.5.0 has been released!</p>

<h4 id="highlights-2">Highlights</h4>
<ul>
  <li><strong>Zero-shot Relation Extraction</strong> to extract relations between clinical entities with no training dataset</li>
  <li><strong>Deidentification</strong>:
    <ul>
      <li>New <strong>French</strong> <strong>Deidentification</strong> NER models and pipeline</li>
      <li>New <strong>Italian</strong> <strong>Deidentification</strong> NER models and pipeline</li>
      <li>Check our reference table for <strong>French and Italian deidentification metrics</strong></li>
      <li>Added <strong>French support to the “fake” generation of data</strong> (aka data obfuscation) in the Deidentification annotator</li>
      <li><strong>Deidentification</strong> <strong>benchmark</strong>: Spark NLP vs Cloud Providers (AWS, Azure, GCP)</li>
    </ul>
  </li>
  <li><strong>Graph generation</strong>:
    <ul>
      <li><strong>ChunkMapperApproach</strong> to augment NER chunks extracted by Spark NLP with a custom <strong>graph-like dictionary of relationships</strong></li>
    </ul>
  </li>
  <li><strong>New Relation Extraction features</strong>:
    <ul>
      <li>Configuration of <strong>case sensitivity</strong> in the name of the <strong>relations</strong> in <strong>Relation Extraction Models</strong></li>
    </ul>
  </li>
  <li><strong>Models and Demos</strong>:
    <ul>
      <li>We have reached <strong>600 clinical models and pipelines</strong>, what sums up to <strong>5000+ overall models</strong> in <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a>!</li>
      <li>Check our new <a href="https://nlp.johnsnowlabs.com/demos">live demos</a> including <a href="https://demo.johnsnowlabs.com/healthcare/DEID_PHI_TEXT_MULTI/">multilanguage deidentification</a> to anonymize clinical notes in 5 different languages</li>
    </ul>
  </li>
  <li>Generate Dataframes to <strong>train Assertion Status models</strong> using <strong>JSON Files</strong> exported <strong>from Annotation Lab</strong> (ALAB)</li>
  <li>Guide about how to scale <strong>from PoC to Production</strong> using Spark NLP for Healthcare in our new Medium Article, available <a href="https://medium.com/spark-nlp/deploying-spark-nlp-for-healthcare-from-zero-to-hero-88949b0c866d">here</a></li>
  <li><strong>Core improvements</strong>:
    <ul>
      <li><strong>Contextual Parser</strong> (our Rule-based NER annotator) is now <strong>much more performant</strong>!</li>
      <li><strong>Bug fixing and compatibility additions</strong> affecting and improving some behaviours of <em>AssertionDL, BertSentenceChunkEmbeddings, AssertionFilterer and EntityRulerApproach</em></li>
    </ul>
  </li>
  <li><strong>New notebooks: zero-shot relation extraction and Deidentification benchmark vs Cloud Providers</strong></li>
</ul>

<h4 id="zero-shot-relation-extraction-to-extract-relations-between-clinical-entities-with-no-training-dataset">Zero-shot Relation Extraction to extract relations between clinical entities with no training dataset</h4>
<p>This release includes a zero-shot relation extraction model that leverages <code class="language-plaintext highlighter-rouge">BertForSequenceClassificaiton</code> to return, based on a predefined set of relation candidates (including no-relation / O), which one has the higher probability to be linking two entities.</p>

<p>The dataset will be a csv which contains the following columns: <code class="language-plaintext highlighter-rouge">sentence</code>, <code class="language-plaintext highlighter-rouge">chunk1</code>, <code class="language-plaintext highlighter-rouge">firstCharEnt1</code>, <code class="language-plaintext highlighter-rouge">lastCharEnt1</code>, <code class="language-plaintext highlighter-rouge">label1</code>, <code class="language-plaintext highlighter-rouge">chunk2</code>, <code class="language-plaintext highlighter-rouge">firstCharEnt2</code>, <code class="language-plaintext highlighter-rouge">lastCharEnt2</code>, <code class="language-plaintext highlighter-rouge">label2</code>, <code class="language-plaintext highlighter-rouge">rel</code>.</p>

<p>For example, let’s take a look at this dataset (columns <code class="language-plaintext highlighter-rouge">chunk1</code>, <code class="language-plaintext highlighter-rouge">rel</code>, <code class="language-plaintext highlighter-rouge">chunk2</code> and <code class="language-plaintext highlighter-rouge">sentence</code>):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------------------------------------+-------+-------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| chunk1                                       | rel   | chunk2                              | sentence                                                                                                                                                                       |
|----------------------------------------------+-------+-------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| light-headedness                             | PIP   | diaphoresis                         | She states this light-headedness is often associated with shortness of breath and diaphoresis occasionally with nausea .                                                       |
| respiratory rate                             | O     | saturation                          | VITAL SIGNS - Temp 98.8 , pulse 60 , BP 150/94 , respiratory rate 18 , and saturation 96% on room air .                                                                        |
| lotions                                      | TrNAP | incisions                           | No lotions , creams or powders to incisions .                                                                                                                                  |
| abdominal ultrasound                         | TeRP  | gallbladder sludge                  | Abdominal ultrasound on 2/23/00 - This study revealed gallbladder sludge but no cholelithiasis .                                                                               |
| ir placement of a drainage catheter          | TrAP  | his abdominopelvic fluid collection | At that time he was made NPO with IVF , placed on Ampicillin / Levofloxacin / Flagyl and underwent IR placement of a drainage catheter for his abdominopelvic fluid collection |
+----------------------------------------------+-------+-------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div></div>

<p>The relation types (TeRP, TrAP, PIP, TrNAP, etc…) are described <a href="https://www.i2b2.org/NLP/Relations/assets/Relation%20Annotation%20Guideline.pdf">here</a></p>

<p>Let’s take a look at the first sentence!</p>

<p><code class="language-plaintext highlighter-rouge">She states this light-headedness is often associated with shortness of breath and diaphoresis occasionally with nausea</code></p>

<p>As we see in the table, the sentences includes a <code class="language-plaintext highlighter-rouge">PIP</code> relationship (<code class="language-plaintext highlighter-rouge">Medical problem indicates medical problem</code>), meaning that in that sentence, chunk1 (<code class="language-plaintext highlighter-rouge">light-headedness</code>) <em>indicates</em> chunk2 (<code class="language-plaintext highlighter-rouge">diaphoresis</code>).</p>

<p>We set a list of candidates tags (<code class="language-plaintext highlighter-rouge">[PIP, TrAP, TrNAP, TrWP, O]</code>) and candidate sentences (<code class="language-plaintext highlighter-rouge">[light-headedness caused diaphoresis, light-headedness was administered for diaphoresis, light-headedness was not given for diaphoresis, light-headedness worsened diaphoresis]</code>), meaning that:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">PIP</code> is expressed by <code class="language-plaintext highlighter-rouge">light-headedness caused diaphoresis</code></li>
  <li><code class="language-plaintext highlighter-rouge">TrAP</code> is expressed by <code class="language-plaintext highlighter-rouge">light-headedness was administered for diaphoresis</code></li>
  <li><code class="language-plaintext highlighter-rouge">TrNAP</code> is expressed by <code class="language-plaintext highlighter-rouge">light-headedness was not given for diaphoresis</code></li>
  <li><code class="language-plaintext highlighter-rouge">TrWP</code> is expressed by <code class="language-plaintext highlighter-rouge">light-headedness worsened diaphoresis</code></li>
  <li>or something generic, like <code class="language-plaintext highlighter-rouge">O</code> is expressed by <code class="language-plaintext highlighter-rouge">light-headedness and diaphoresis</code>…</li>
</ul>

<p>We will get that the biggest probability of is <code class="language-plaintext highlighter-rouge">PIP</code>, since it’s phrase <code class="language-plaintext highlighter-rouge">light-headedness caused diaphoresis</code> is the most similar relationship expressing the meaning in the original sentence (<code class="language-plaintext highlighter-rouge">light-headnedness is often associated with ... and diaphoresis</code>)</p>

<p>The example code is the following:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
re_ner_chunk_filter = sparknlp_jsl.annotator.RENerChunksFilter() \
    .setRelationPairs(["problem-test","problem-treatment"]) \
    .setMaxSyntacticDistance(4)\
    .setDocLevelRelations(False)\
    .setInputCols(["ner_chunks", "dependencies"]) \
    .setOutputCol("re_ner_chunks")

# The relations are defined by a map- keys are relation label, values are lists of predicated statements. The variables in curly brackets are NER entities, there could be more than one, e.g. " improves "
re_model = sparknlp_jsl.annotator.ZeroShotRelationExtractionModel \
    .pretrained("re_zeroshot_biobert", "en", "clinical/models")\
    .setRelationalCategories({
        "CURE": [" cures ."],
        "IMPROVE": [" improves .", " cures ."],
        "REVEAL": [" reveals ."]})\
    .setMultiLabel(False)\
    .setInputCols(["re_ner_chunks", "sentences"]) \
    .setOutputCol("relations")

pipeline = sparknlp.base.Pipeline() \
    .setStages([documenter, tokenizer, sentencer, words_embedder, pos_tagger, ner_tagger, ner_converter,
                dependency_parser, re_ner_chunk_filter, re_model])

data = spark.createDataFrame(
    [["Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer."]]
).toDF("text")

model = pipeline.fit(data)
results = model.transform(data)

results\
    .selectExpr("explode(relations) as relation")\
    .show(truncate=False)    
</code></pre></div></div>

<p>Results:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|relation                                                                                                                                                                                                                                                                                                                                                              |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|{category, 534, 613, REVEAL, {entity1_begin -&gt; 48, relation -&gt; REVEAL, hypothesis -&gt; An MRI test reveals cancer., confidence -&gt; 0.9760039, nli_prediction -&gt; entail, entity1 -&gt; TEST, syntactic_distance -&gt; 4, chunk2 -&gt; cancer, entity2_end -&gt; 85, entity1_end -&gt; 58, entity2_begin -&gt; 80, entity2 -&gt; PROBLEM, chunk1 -&gt; An MRI test, sentence -&gt; 1}, []}            |
|{category, 267, 357, IMPROVE, {entity1_begin -&gt; 0, relation -&gt; IMPROVE, hypothesis -&gt; Paracetamol improves sickness., confidence -&gt; 0.98819494, nli_prediction -&gt; entail, entity1 -&gt; TREATMENT, syntactic_distance -&gt; 3, chunk2 -&gt; sickness, entity2_end -&gt; 45, entity1_end -&gt; 10, entity2_begin -&gt; 38, entity2 -&gt; PROBLEM, chunk1 -&gt; Paracetamol, sentence -&gt; 0}, []}|
|{category, 0, 90, IMPROVE, {entity1_begin -&gt; 0, relation -&gt; IMPROVE, hypothesis -&gt; Paracetamol improves headache., confidence -&gt; 0.9929625, nli_prediction -&gt; entail, entity1 -&gt; TREATMENT, syntactic_distance -&gt; 2, chunk2 -&gt; headache, entity2_end -&gt; 33, entity1_end -&gt; 10, entity2_begin -&gt; 26, entity2 -&gt; PROBLEM, chunk1 -&gt; Paracetamol, sentence -&gt; 0}, []}    |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div></div>

<p>Take a look at the example notebook <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.3.ZeroShot_Clinical_Relation_Extraction.ipynb">here</a>.</p>

<p>Stay tuned for the <strong>few-shot</strong> Annotator to be release soon!</p>

<h4 id="new-french-deidentification-ner-models-and-pipeline">New French Deidentification NER models and pipeline</h4>
<p>We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in <strong>French</strong>. <code class="language-plaintext highlighter-rouge">ner_deid_generic</code> and <code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> models are trained with in-house annotations.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic</code> : Detects 7 PHI entities in French (<code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">NAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">ID</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> : Detects 15 PHI sub-entities in French (<code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">E-MAIL</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>).
<em>Example</em> :
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings <span class="o">=</span> WordEmbeddingsModel.pretrained<span class="o">(</span><span class="s2">"w2v_cc_300d"</span>, <span class="s2">"fr"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
     .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>
deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_generic"</span>, <span class="s2">"fr"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
deid_sub_entity_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity"</span>, <span class="s2">"fr"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner_sub_entity"</span><span class="o">)</span>
...
text <span class="o">=</span> <span class="s2">"""J'ai vu en consultation Michel Martinez (49 ans) adressé au Centre Hospitalier De Plaisir pour un diabète mal contrôlé avec des symptômes datant de Mars 2015."""</span>
result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>text]], <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div>    </div>
    <p><em>Results</em> :</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| chunk              		| ner_deid_generic_chunk | ner_deid_subentity_chunk |
|-------------------------------|------------------------|--------------------------|
| Michel Martinez    		| NAME                   | PATIENT                  |
| 49 ans             		| AGE                    | AGE                      |
| Centre Hospitalier De Plaisir | LOCATION        	 | HOSPITAL                 |
| Mars 2015          		| DATE                   | DATE                     |
</code></pre></div></div>

<p>We also developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from <strong>French</strong> medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate the following entities: <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">SEX</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">E-MAIL</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">ACCOUNT</code>, <code class="language-plaintext highlighter-rouge">PLATE</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">URL</code>, and <code class="language-plaintext highlighter-rouge">IPADDR</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
deid_pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"clinical_deidentification"</span>, <span class="s2">"fr"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>
text <span class="o">=</span> <span class="s2">"""PRENOM : Jean NOM : Dubois NUMÉRO DE SÉCURITÉ SOCIALE : 1780160471058 ADRESSE : 18 Avenue Matabiau VILLE : Grenoble CODE POSTAL : 38000"""</span>
result <span class="o">=</span> deid_pipeline.annotate<span class="o">(</span>text<span class="o">)</span>
</code></pre></div></div>
<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Masked with entity labels
<span class="nt">------------------------------</span>
PRENOM : &lt;PATIENT&gt; NOM : &lt;PATIENT&gt; NUMÉRO DE SÉCURITÉ SOCIALE : &lt;SSN&gt;  ADRESSE : &lt;STREET&gt; VILLE : &lt;CITY&gt; CODE POSTAL : &lt;ZIP&gt;
Masked with chars
<span class="nt">------------------------------</span>
PRENOM : <span class="o">[</span><span class="k">**</span><span class="o">]</span> NOM : <span class="o">[</span><span class="k">****</span><span class="o">]</span> NUMÉRO DE SÉCURITÉ SOCIALE : <span class="o">[</span><span class="k">***********</span><span class="o">]</span>  ADRESSE : <span class="o">[</span><span class="k">****************</span><span class="o">]</span> VILLE : <span class="o">[</span><span class="k">******</span><span class="o">]</span> CODE POSTAL : <span class="o">[</span><span class="k">***</span><span class="o">]</span>
Masked with fixed length chars
<span class="nt">------------------------------</span>
PRENOM : <span class="k">****</span> NOM : <span class="k">****</span> NUMÉRO DE SÉCURITÉ SOCIALE : <span class="k">****</span>  ADRESSE : <span class="k">****</span> VILLE : <span class="k">****</span> CODE POSTAL : <span class="k">****</span>
Obfuscated
<span class="nt">------------------------------</span>
PRENOM : Mme Olivier NOM : Mme Traore NUMÉRO DE SÉCURITÉ SOCIALE : 164033818514436  ADRESSE : 731, boulevard de Legrand VILLE : Sainte Antoine CODE POSTAL : 37443
</code></pre></div></div>

<h4 id="new-italian-deidentification-ner-models-and-pipeline">New Italian Deidentification NER models and pipeline</h4>

<p>We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in <strong>Italian</strong>. <code class="language-plaintext highlighter-rouge">ner_deid_generic</code> and <code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> models are trained with in-house annotations.</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic</code> : Detects 8 PHI entities in Italian (<code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">NAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">ID</code>, <code class="language-plaintext highlighter-rouge">SEX</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> : Detects 19 PHI sub-entities in Italian (<code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">SEX</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">EMAIL</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">URL</code>).
<em>Example</em> :
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings <span class="o">=</span> WordEmbeddingsModel.pretrained<span class="o">(</span><span class="s2">"w2v_cc_300d"</span>, <span class="s2">"it"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
     .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>
deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_generic"</span>, <span class="s2">"it"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
deid_sub_entity_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity"</span>, <span class="s2">"it"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner_sub_entity"</span><span class="o">)</span>
...
text <span class="o">=</span> <span class="s2">"""Ho visto Gastone Montanariello (49 anni) riferito all' Ospedale San Camillo per diabete mal controllato con sintomi risalenti a marzo 2015."""</span>
result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>text]], <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div>    </div>
    <p><em>Results</em> :</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| chunk                | ner_deid_generic_chunk | ner_deid_subentity_chunk |
|----------------------|------------------------|--------------------------|
| Gastone Montanariello| NAME                   | PATIENT                  |
| 49                   | AGE                    | AGE                      |
| Ospedale San Camillo | LOCATION               | HOSPITAL                 |
| marzo 2015           | DATE                   | DATE                     |
</code></pre></div></div>

<p>We also developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from <strong>Italian</strong> medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate the following entities: <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">SEX</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">E-MAIL</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">ACCOUNT</code>, <code class="language-plaintext highlighter-rouge">PLATE</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">URL</code>, and <code class="language-plaintext highlighter-rouge">IPADDR</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
deid_pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"clinical_deidentification"</span>, <span class="s2">"it"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>
sample_text <span class="o">=</span> <span class="s2">"""NOME: Stefano Montanariello CODICE FISCALE: YXYGXN51C61Y662I INDIRIZZO: Viale Burcardo 7 CODICE POSTALE: 80139"""</span>
result <span class="o">=</span> deid_pipeline.annotate<span class="o">(</span>sample_text<span class="o">)</span>
</code></pre></div></div>
<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Masked with entity labels
<span class="nt">------------------------------</span>
NOME: &lt;PATIENT&gt; CODICE FISCALE: &lt;SSN&gt; INDIRIZZO: &lt;STREET&gt; CODICE POSTALE: &lt;ZIP&gt;

Masked with chars
<span class="nt">------------------------------</span>
NOME: <span class="o">[</span><span class="k">*******************</span><span class="o">]</span> CODICE FISCALE: <span class="o">[</span><span class="k">**************</span><span class="o">]</span> INDIRIZZO: <span class="o">[</span><span class="k">**************</span><span class="o">]</span> CODICE POSTALE: <span class="o">[</span><span class="k">***</span><span class="o">]</span>

Masked with fixed length chars
<span class="nt">------------------------------</span>
NOME: <span class="k">****</span> CODICE FISCALE: <span class="k">****</span> INDIRIZZO: <span class="k">****</span> CODICE POSTALE: <span class="k">****</span>

Obfuscated
<span class="nt">------------------------------</span>
NOME: Stefania Gregori CODICE FISCALE: UIWSUS86M04J604B INDIRIZZO: Viale Orlando 808 CODICE POSTALE: 53581
</code></pre></div></div>

<h4 id="check-our-reference-table-for-french-and-italian-deidentification-metrics">Check our reference table for <strong>French and Italian deidentification metrics</strong></h4>
<p>Please find this reference table with metrics comparing F1 score for the available entities in French and Italian clinical pipelines:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|Entity Label |Italian|French|
|-------------|-------|------|
|PATIENT      |0.9069 |0.9382|
|DOCTOR       |0.9171 |0.9912|
|HOSPITAL     |0.8968 |0.9375|
|DATE         |0.9835 |0.9849|
|AGE          |0.9832 |0.8575|
|PROFESSION   |0.8864 |0.8147|
|ORGANIZATION |0.7385 |0.7697|
|STREET       |0.9754 |0.8986|
|CITY         |0.9678 |0.8643|
|COUNTRY      |0.9262 |0.8983|
|PHONE        |0.9815 |0.9785|
|USERNAME     |0.9091 |0.9239|
|ZIP          |0.9867 |1.0   |
|E-MAIL       |1      |1.0   |
|MEDICALRECORD|0.8085 |0.939 |
|SSN          |0.9286 |N/A   |
|URL          |1      |N/A   |
|SEX          |0.9697 |N/A   |
|IDNUM        |0.9576 |N/A   |
</code></pre></div></div>

<h4 id="added-french-support-in-deidentification-annotator-for-data-obfuscation">Added French support in Deidentification Annotator for data obfuscation</h4>
<p>Our <code class="language-plaintext highlighter-rouge">Deidentificator</code> annotator is now able to obfuscate entities (coming from a deid NER model) with fake data in French language. Example:</p>

<p>Example code:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings = WordEmbeddingsModel.pretrained("w2v_cc_300d", "fr").setInputCols(["sentence", "token"]).setOutputCol("word_embeddings")

clinical_ner = MedicalNerModel.pretrained("ner_deid_subentity", "fr", "clinical/models").setInputCols(["sentence","token", "word_embeddings"]).setOutputCol("ner")

ner_converter = NerConverter().setInputCols(["sentence", "token", "ner"]).setOutputCol("ner_chunk")

de_identification = DeIdentification() \
    .setInputCols(["ner_chunk", "token", "sentence"]) \
    .setOutputCol("dei") \
    .setMode("obfuscate") \
    .setObfuscateDate(True) \
    .setRefSep("#") \
    .setDateTag("DATE") \
    .setLanguage("fr") \
    .setObfuscateRefSource('faker')

pipeline = Pipeline() \
    .setStages([
    documentAssembler,
    sentenceDetector,
    tokenizer,
    embeddings,
    clinical_ner,
    ner_converter,
    de_identification
])
sentences = [
["""J'ai vu en consultation Michel Martinez (49 ans) adressé au Centre Hospitalier De Plaisir pour un diabète mal contrôlé avec des symptômes datant"""]
]

my_input_df = spark.createDataFrame(sentences).toDF("text")
output = pipeline.fit(my_input_df).transform(my_input_df)
...
</code></pre></div></div>

<p>Entities detected:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------------+----------+
|token       |entity    |
+------------+----------+
|J'ai        |O         |
|vu          |O         |
|en          |O         |
|consultation|O         |
|Michel      |B-PATIENT |
|Martinez    |I-PATIENT |
|(           |O         |
|49          |B-AGE     |
|ans         |O         |
|)           |O         |
|adressé     |O         |
|au          |O         |
|Centre      |B-HOSPITAL|
|Hospitalier |I-HOSPITAL|
|De          |I-HOSPITAL|
|Plaisir     |I-HOSPITAL|
|pour        |O         |
|un          |O         |
|diabète     |O         |
|mal         |O         |
+------------+----------+
</code></pre></div></div>

<p>Obfuscated sentence:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|result                                                                                                                                                  |
+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|[J'ai vu en consultation Sacrispeyre Ligniez (86 ans) adressé au Centre Hospitalier Pierre Futin pour un diabète mal contrôlé avec des symptômes datant]|
+--------------------------------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div></div>

<h4 id="deidentification-benchmark-spark-nlp-vs-cloud-providers-aws-azure-gcp">Deidentification benchmark: Spark NLP vs Cloud Providers (AWS, Azure, GCP)</h4>
<p>We have published a new notebook with a benchmark and the reproduceable code, comparing Spark NLP for Healthcare Deidentification capabilities of one of our English pipelines (<code class="language-plaintext highlighter-rouge">clinical_deidentification_glove_augmented</code>) versus:</p>
<ul>
  <li>AWS Comprehend Medical</li>
  <li>Azure Cognitive Services</li>
  <li>GCP Data Loss Prevention</li>
</ul>

<p>The notebook is available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.3.Clinical_Deidentification_SparkNLP_vs_Cloud_Providers_Comparison.ipynb">here</a>, and the results are the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        SPARK NLP   AWS    AZURE      GCP
AGE          1      0.96    0.93      0.9
DATE         1      0.99    0.9       0.96
DOCTOR      0.98    0.96    0.7       0.6
HOSPITAL    0.92    0.89    0.72      0.72
LOCATION    0.9     0.81    0.87      0.73
PATIENT     0.96    0.95    0.78      0.48
PHONE        1       1      0.8       0.97
ID          0.93    0.93     -          -
</code></pre></div></div>

<h4 id="chunkmapperapproach-mapping-extracted-entities-to-an-ontology-json-dictionary-with-relations">ChunkMapperApproach: mapping extracted entities to an ontology (Json dictionary) with relations</h4>
<p>We have released a new annotator, called <strong>ChunkMapperApproach</strong>(), that receives a <strong>ner_chunk</strong> and a Json with a mapping of NER entities and relations, and returns the <strong>ner_chunk</strong> augmented with the relations from the Json ontology.</p>

<p>Example of a small ontology with relations:</p>

<p>Giving the map with entities and relationships stored in mapper.json, we will use an NER to detect entities in a text and, in case any of them is found, the <strong>ChunkMapper</strong> will augment the output with the relationships from this dictionary:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{"mappings": [{
             "key": "metformin",
             "relations": [{
                   "key": "action",
                   "values" : ["hypoglycemic", "Drugs Used In Diabets"]
                   },{
                   "key": "treatment",
                   "values" : ["diabetes", "t2dm"]
                   }]
           }]
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>text = ["""The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also
given 1 unit of Metformin daily.
He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night ,
12 units of insulin lispro with meals , and metformin 1000 mg two times a day."""]
...
nerconverter = NerConverterInternal()\
  .setInputCols("sentence", "token", "ner")\
  .setOutputCol("ner_chunk")

chunkerMapper = ChunkMapperApproach() \
  .setInputCols("ner_chunk")\
  .setOutputCol("relations")\
  .setDictionary("mapper.json")\
  .setRel("action")

pipeline = Pipeline().setStages([document_assembler,sentence_detector,tokenizer, ner, nerconverter, chunkerMapper])

res = pipeline.fit(test_data).transform(test_data)

res.select(F.explode('ner_chunk.result').alias("chunks")).show(truncate=False)
</code></pre></div></div>

<p>Entities:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------+
|chunks          |
+----------------+
|Metformin       |
|insulin glargine|
|insulin lispro  |
|metformin       |
|mg              |
|times           |
+----------------+
</code></pre></div></div>

<p>Checking the relations:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
pd_df = res.select(F.explode('relations').alias('res')).select('res.result', 'res.metadata').toPandas()
...
</code></pre></div></div>

<p>Results:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Entity:					metformin
Main relation:				hypoglycemic
Other relations (included in metadata):	Drugs Used In Diabets
</code></pre></div></div>

<h4 id="configuration-of-case-sensitivity-in-the-name-of-the-relations-in-relation-extraction-models">Configuration of case sensitivity in the name of the relations in Relation Extraction Models</h4>
<p>We have added a new parameter, called ‘relationPairsCaseSensitive’, which affects the way <code class="language-plaintext highlighter-rouge">setRelationPairs</code> works. If <code class="language-plaintext highlighter-rouge">relationPairsCaseSensitive</code> is True, then the pairs of entities in the dataset should match the pairs in setRelationPairs in their specific case (case sensitive). By default it’s set to False, meaning that the match of those relation names is case insensitive.</p>

<p>Before 3.5.0, <code class="language-plaintext highlighter-rouge">.setRelationPairs(["dosage-drug"])</code> would not return relations if it was trained with a relation called <code class="language-plaintext highlighter-rouge">DOSAGE-DRUG</code> (different casing). Now, setting <code class="language-plaintext highlighter-rouge">.setRelationPairs(["dosage-drug"])</code>and <code class="language-plaintext highlighter-rouge">relationPairsCaseSensitive(False)</code> or just leaving it by default, it will return any <code class="language-plaintext highlighter-rouge">dosage-drug</code> or <code class="language-plaintext highlighter-rouge">DOSAGE-DRUG</code> relationship.</p>

<p>Example of usage in Python:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
reModel = RelationExtractionModel()\
    .pretrained("posology_re")\
    .setInputCols(["embeddings", "pos_tags", "ner_chunks", "dependencies"])\
    .setMaxSyntacticDistance(4)\
    .setRelationPairs(["dosage-drug"]) \
    .setRelationPairsCaseSensitive(False) \
    .setOutputCol("relations_case_insensitive")
...
</code></pre></div></div>

<p>This will return relations named dosage-drug, DOSAGE-DRUG, etc.</p>

<h4 id="we-have-reached-the-milestone-of-600-clinical-models-and-5000-models-overall--">We have reached the milestone of 600 clinical models (and 5000+ models overall) ! 🥳</h4>
<p>This release added to Spark NLP Models Hub 100+ pretrained clinical pipelines, available to use as one-liners, including some of the most used NER models, namely:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_pipeline_de</code>: German deidentification pipeline with aggregated (generic) labels</li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_pipeline_de</code>: German deidentification pipeline with specific (subentity) labels</li>
  <li><code class="language-plaintext highlighter-rouge">ner_clinical_biobert_pipeline_en</code>: A pretrained pipeline based on <code class="language-plaintext highlighter-rouge">ner_clinical_biobert</code> to carry out NER on BioBERT embeddings</li>
  <li><code class="language-plaintext highlighter-rouge">ner_abbreviation_clinical_pipeline_en</code>: A pretrained pipeline based on <code class="language-plaintext highlighter-rouge">ner_abbreviation_clinical</code> that detects medical acronyms and abbreviations</li>
  <li><code class="language-plaintext highlighter-rouge">ner_ade_biobert_pipeline_en</code>: A pretrained pipeline based on <code class="language-plaintext highlighter-rouge">ner_ade_biobert</code> to carry out Adverse Drug Events NER recognition using BioBERT embeddings</li>
  <li><code class="language-plaintext highlighter-rouge">ner_ade_clinical_pipeline_en</code>: Similar to the previous one, but using <code class="language-plaintext highlighter-rouge">clinical_embeddings</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_radiology_pipeline_en</code>: A pretrained pipeline to detect Radiology entities (coming from <code class="language-plaintext highlighter-rouge">ner_radiology_wip</code> model)</li>
  <li><code class="language-plaintext highlighter-rouge">ner_events_clinical_pipeline_en</code>: A pretrained pipeline to extract Clinical Events related entities (leveraging <code class="language-plaintext highlighter-rouge">ner_events_clinical</code>)</li>
  <li><code class="language-plaintext highlighter-rouge">ner_anatomy_biobert_pipeline_en</code>: A pretrained pipeline to extract Anamoty entities (from <code class="language-plaintext highlighter-rouge">ner_anamoty_biobert</code>)</li>
  <li>…100 more</li>
</ul>

<p>Here is how you can use any of the pipelines with one line of code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline

pipeline = PretrainedPipeline("explain_clinical_doc_medication", "en", "clinical/models")

result = pipeline.fullAnnotate("""The patient is a 30-year-old female with a long history of insulin dependent diabetes, type 2. She received a course of Bactrim for 14 days for UTI.  She was prescribed 5000 units of Fragmin  subcutaneously daily, and along with Lantus 40 units subcutaneously at bedtime.""")[0]
</code></pre></div></div>

<p>Results:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----+----------------+------------+
|    | chunks         | entities   |
|---:|:---------------|:-----------|
|  0 | insulin        | DRUG       |
|  1 | Bactrim        | DRUG       |
|  2 | for 14 days    | DURATION   |
|  3 | 5000 units     | DOSAGE     |
|  4 | Fragmin        | DRUG       |
|  5 | subcutaneously | ROUTE      |
|  6 | daily          | FREQUENCY  |
|  7 | Lantus         | DRUG       |
|  8 | 40 units       | DOSAGE     |
|  9 | subcutaneously | ROUTE      |
| 10 | at bedtime     | FREQUENCY  |
+----+----------------+------------+
+----+----------+------------+-------------+
|    | chunks   | entities   | assertion   |
|---:|:---------|:-----------|:------------|
|  0 | insulin  | DRUG       | Present     |
|  1 | Bactrim  | DRUG       | Past        |
|  2 | Fragmin  | DRUG       | Planned     |
|  3 | Lantus   | DRUG       | Planned     |
+----+----------+------------+-------------+
+----------------+-----------+------------+-----------+----------------+
| relation       | entity1   | chunk1     | entity2   | chunk2         |
|:---------------|:----------|:-----------|:----------|:---------------|
| DRUG-DURATION  | DRUG      | Bactrim    | DURATION  | for 14 days    |
| DOSAGE-DRUG    | DOSAGE    | 5000 units | DRUG      | Fragmin        |
| DRUG-ROUTE     | DRUG      | Fragmin    | ROUTE     | subcutaneously |
| DRUG-FREQUENCY | DRUG      | Fragmin    | FREQUENCY | daily          |
| DRUG-DOSAGE    | DRUG      | Lantus     | DOSAGE    | 40 units       |
| DRUG-ROUTE     | DRUG      | Lantus     | ROUTE     | subcutaneously |
| DRUG-FREQUENCY | DRUG      | Lantus     | FREQUENCY | at bedtime     |
+----------------+-----------+------------+-----------+----------------+
</code></pre></div></div>

<p>We have updated our <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb">11.Pretrained_Clinical_Pipelines.ipynb</a> notebook to properly show this addition. Don’t forget to check it out!</p>

<p>All of our scalable, production-ready Spark NLP Clinical Models and Pipelines can be found in our Models Hub</p>

<p>Finally, we have added two new <strong>entityMapper</strong> models: <strong>drug_ontology</strong> and <strong>section_mapper</strong></p>

<p>For all Spark NLP for healthcare models, please check our <a href="https://nlp.johnsnowlabs.com/models?edition=Spark+NLP+for+Healthcare">Models Hub webpage</a></p>

<h4 id="have-you-checked-our-demo-page">Have you checked our demo page?</h4>
<p>New several demos were created, available at https://nlp.johnsnowlabs.com/demos</p>

<p>In this release we feature the <strong>Multilingual deidentification</strong>, showcasing how to deidentify clinical texts in English, Spanish, German, French and Italian. This demo is available <a href="https://demo.johnsnowlabs.com/healthcare/DEID_PHI_TEXT_MULTI">here</a></p>

<p><strong>For the rest of the demos, please visit <a href="https://nlp.johnsnowlabs.com/demos">Models Hub Demos Page</a></strong></p>

<h4 id="generate-dataframes-to-train-assertion-status-models-using-json-files-exported-from-annotation-lab-alab">Generate Dataframes to train Assertion Status Models using JSON files exported from Annotation Lab (ALAB)</h4>
<p>Now we can generate a dataframe that can be used to train an <code class="language-plaintext highlighter-rouge">AssertionDLModel</code> by using the output of <code class="language-plaintext highlighter-rouge">AnnotationToolJsonReader.generatePlainAssertionTrainSet()</code>. The dataframe contains all the columns that you need for training.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filename</span> <span class="o">=</span> <span class="s">"../json_import.json"</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">AnnotationToolJsonReader</span><span class="p">(</span><span class="n">assertion_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'AsPresent'</span><span class="p">,</span> <span class="s">'AsAbsent'</span><span class="p">,</span> <span class="s">'AsConditional'</span><span class="p">,</span> <span class="s">'AsHypothetical'</span><span class="p">,</span> <span class="s">'AsFamily'</span><span class="p">,</span> <span class="s">'AsPossible'</span><span class="p">,</span> <span class="s">'AsElse'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span>  <span class="n">reader</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="n">reader</span><span class="p">.</span><span class="n">generatePlainAssertionTrainSet</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------+--------------------------------------------+-----+---+-----------+---------+
|task_id|sentence                                    |begin|end|ner        |assertion|
+-------+--------------------------------------------+-----+---+-----------+---------+
|1      |Patient has a headache for the last 2 weeks |2    |3  |a headache |AsPresent|
+-------+--------------------------------------------+-----+---+-----------+---------+
</code></pre></div></div>

<h4 id="understand-how-to-scale-from-a-poc-to-production-using-spark-nlp-for-healthcare-in-our-new-medium-article-available-here">Understand how to scale from a PoC to Production using Spark NLP for Healthcare in our new Medium Article, available here</h4>

<p>We receive many questions about how Spark work distribution is carried out, what specially becomes important before making the leap from a PoC to a big scalable, production-ready cluster.</p>

<p>This article helps you understand:</p>
<ul>
  <li>How many different ways to create a cluster are available, as well as their advantages and disadvantages;</li>
  <li>How to scale all of them;</li>
  <li>How to take advantage of autoscalability and autotermination policy in Cloud Providers;</li>
  <li>Which are the steps to take depending on your infrastructure, to make the leap to production;</li>
</ul>

<p>If you need further assistance, please reach our Support team at <a href="mailto:support@johnsnowlabs.com">support@johnsnowlabs.com</a></p>

<h4 id="contextual-parser-our-rule-based-ner-annotator-is-now-much-more-performant">Contextual Parser (our Rule-based NER annotator) is now much more performant!</h4>
<p>Contextual Parser has been improved in terms of performance. These are the metrics comparing 3.4.2 and 3.5.0</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4 cores and 30 GB RAM
=====================
	10 MB	20 MB	30MB	50MB		
3.4.2	349	786	982	1633		
3.5.0   142	243	352	556		

8 cores and 60 GB RAM
=====================
	10 MB	20 MB	30MB	50MB
3.4.2	197	373	554	876
3.5.0   79	136	197	294
</code></pre></div></div>

<h4 id="we-have-reached-the-milestone-of-600-clinical-demos">We have reached the milestone of 600 clinical demos!</h4>
<p>During this release, we included:</p>
<ul>
  <li>More than 100+ recently created clinical models and pipelines, including NER, NER+RE, NER+Assertion+RE, etc.</li>
  <li>Added two new <code class="language-plaintext highlighter-rouge">entityMapper</code> models: <code class="language-plaintext highlighter-rouge">drug_action_treatment_mapper</code> and <code class="language-plaintext highlighter-rouge">normalized_section_header_mapper</code></li>
</ul>

<p><strong>For all Spark NLP for healthcare models, please check : <a href="https://nlp.johnsnowlabs.com/models?edition=Spark+NLP+for+Healthcare">Models Hub Page</a></strong></p>

<h4 id="bug-fixing-and-compatibility-additions">Bug fixing and compatibility additions</h4>
<p>This is the list of fixed issues and bugs, as well as one compatibility addition between <strong>EntityRuler</strong> and <strong>AssertionFiltered</strong>:</p>

<ul>
  <li><strong>Error in AssertionDLApproach and AssertionLogRegApproach</strong>: an error was being triggered wthen the dataset contained long (64bits) instead of 32 bits integers for the start / end columns. Now this bug is fixed.</li>
  <li><strong>Error in BertSentenceChunkEmbeddings</strong>: loading a model after downloading it with pretrained() was triggering an error. Now you can load any model after downloading it with <code class="language-plaintext highlighter-rouge">pretrained()</code>.</li>
  <li>Adding <strong>setIncludeConfidence</strong> to AssertionDL Python version, where it was missing. Now, it’s included in both Python and Scala, as described <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLModel.html#setIncludeConfidence(value:Boolean):AssertionDLModel.this.type">here</a></li>
  <li><strong>Making EntityRuler and AssertionFiltered compatible</strong>: AssertionFilterer annotator that is being used to filter the entities based on entity labels now can be used by EntityRulerApproach, a rule based entity extractor:</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Path("test_file.jsonl").write_text(json.dumps({"id":"cough","label":"COUGH","patterns":["cough","coughing"]}))
...
entityRuler = EntityRulerApproach()\
    .setInputCols(["sentence", "token"])\
    .setOutputCol("ner_chunk")\
    .setPatternsResource("test_file.jsonl", ReadAs.TEXT, {"format": "jsonl"})

clinical_assertion = AssertionDLModel.pretrained("assertion_dl", "en", "clinical/models") \
    .setInputCols(["sentence", "ner_chunk", "embeddings"]) \
    .setOutputCol("assertion")

assertion_filterer = AssertionFilterer()\
    .setInputCols("sentence","ner_chunk","assertion")\
    .setOutputCol("assertion_filtered")\
    .setWhiteList(["present"])\

...

empty_data = spark.createDataFrame([[""]]).toDF("text")
ruler_model = rulerPipeline.fit(empty_data)

text = "I have a cough but no fatigue or chills."

ruler_light_model = LightPipeline(ruler_model).fullAnnotate(text)[0]['assertion_filtered']
</code></pre></div></div>

<p>Result:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Annotation(chunk, 9, 13, cough, {'entity': 'COUGH', 'id': 'cough', 'sentence': '0'})]
</code></pre></div></div>

<h4 id="new-notebooks-zero-shot-relation-extraction-and-deidentification-benchmark-spark-nlp-and-cloud-providers"><strong>New notebooks: zero-shot relation extraction and Deidentification benchmark (Spark NLP and Cloud Providers)</strong></h4>
<p>Check these recently notebooks created by our Healthcare team and available in our <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/">Spark NLP Workshop git repo</a>, where you can find many more.</p>
<ul>
  <li>Zero-shot Relation Extraction, available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.3.ZeroShot_Clinical_Relation_Extraction.ipynb">here</a>.</li>
  <li>Deidentification benchmark (SparkNLP and Cloud Providers), available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.3.Clinical_Deidentification_SparkNLP_vs_Cloud_Providers_Comparison.ipynb">here</a></li>
</ul>

<h2 id="342">3.4.2</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.4.2 has been released!</p>

<h4 id="highlights-3">Highlights</h4>

<ul>
  <li>New RCT Classifier, NER models and pipeline (Deidentification)</li>
  <li>Setting the scope window (target area) dynamically in Assertion Status detection models</li>
  <li>Reading JSON files (exported from ALAB) from HDFS with <code class="language-plaintext highlighter-rouge">AnnotationJsonReader</code></li>
  <li>Allow users to write Tensorflow graphs to HDFS</li>
  <li>Serving Spark NLP on APIs</li>
  <li>Updated documentation on installing Spark NLP for Healthcare in AWS EMR (Jupyter, Livy, Yarn, Hadoop)</li>
  <li>New series of notebooks to reproduce the academic papers published by our colleagues</li>
  <li>PySpark tutorial notebooks to let non-Spark users get started with Apache Spark ecosystem in Python</li>
  <li>New &amp; updated notebooks</li>
  <li>List of recently updated or added models</li>
</ul>

<h4 id="new-rct-classifier-ner-models-and-pipeline-deidentification">New RCT Classifier, NER Models and Pipeline (Deidentification)</h4>

<p>We are releasing a new <code class="language-plaintext highlighter-rouge">bert_sequence_classifier_rct_biobert</code> model, four new Spanish deidentification NER models (<code class="language-plaintext highlighter-rouge">ner_deid_generic_augmented</code>, <code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code>, <code class="language-plaintext highlighter-rouge">ner_deid_generic_roberta_augmented</code>, <code class="language-plaintext highlighter-rouge">ner_deid_subentity_roberta_augmented</code>) and a pipeline (<code class="language-plaintext highlighter-rouge">clinical_deidentification_augmented</code>).</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_rct_biobert</code>: This model can classify the sections within abstract of scientific articles regarding randomized clinical trials (RCT) (<code class="language-plaintext highlighter-rouge">BACKGROUND</code>, <code class="language-plaintext highlighter-rouge">CONCLUSIONS</code>, <code class="language-plaintext highlighter-rouge">METHODS</code>, <code class="language-plaintext highlighter-rouge">OBJECTIVE</code>, <code class="language-plaintext highlighter-rouge">RESULTS</code>).</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">sequenceClassifier_model</span> <span class="o">=</span> <span class="n">MedicalBertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_sequence_classifier_rct_biobert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">'token'</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"Previous attempts to prevent all the unwanted postoperative responses to major surgery with an epidural hydrophilic opioid , morphine , have not succeeded . The authors ' hypothesis was that the lipophilic opioid fentanyl , infused epidurally close to the spinal-cord opioid receptors corresponding to the dermatome of the surgical incision , gives equal pain relief but attenuates postoperative hormonal and metabolic responses more effectively than does systemic fentanyl ."</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">sequence_clf_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="o">&gt;&gt;</span> <span class="n">class</span><span class="p">:</span> <span class="s">'BACKGROUND'</span>
</code></pre></div></div>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_generic_augmented</code>, <code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code>, <code class="language-plaintext highlighter-rouge">ner_deid_generic_roberta_augmented</code>, <code class="language-plaintext highlighter-rouge">ner_deid_subentity_roberta_augmented</code> models and <code class="language-plaintext highlighter-rouge">clinical_deidentification_augmented</code> pipeline : You can use either <code class="language-plaintext highlighter-rouge">sciwi-embeddings</code> (300 dimensions) or the Roberta Clinical Embeddings (infix <code class="language-plaintext highlighter-rouge">_roberta_</code>) with these NER models. These models and pipeline are different to their non-augmented versions in the following:</p>

    <ul>
      <li>They are trained with more data, now including an in-house annotated deidentification dataset;</li>
      <li>New <code class="language-plaintext highlighter-rouge">SEX</code> tag is available for all of them. This tag is now included in the NER and has been improved with more rules in the ContextualParsers of the pipeline, resulting in having a bigger recall to detect the sex of the patient.</li>
      <li>New <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">CITY</code> and <code class="language-plaintext highlighter-rouge">COUNTRY</code> entities are added to subentity versions.</li>
    </ul>
  </li>
</ul>

<p>For more details and examples, please check <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.2.Clinical_Deidentification_in_Spanish.ipynb">Clinical Deidentification in Spanish notebook</a>.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_sciwiki_300d"</span><span class="p">,</span><span class="s">"es"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">deid_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="p">,</span> <span class="s">"es"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">deid_sub_entity_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="p">,</span> <span class="s">"es"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_sub_entity"</span><span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<p><em>Results</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chunk                    entity_subentity    entity_generic
<span class="nt">-----------------------</span>  <span class="nt">------------------</span>  <span class="nt">----------------</span>
Antonio Miguel Martínez  PATIENT             NAME
un varón                 SEX                 SEX
35                       AGE                 AGE
auxiliar de enfermería   PROFESSION          PROFESSION
Cadiz                    CITY                LOCATION
España                   COUNTRY             LOCATION
Clinica San Carlos       HOSPITAL            LOCATION
</code></pre></div></div>

<h4 id="setting-the-scope-window-target-area-dynamically-in-assertion-status-detection-models">Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models</h4>

<p>This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format <code class="language-plaintext highlighter-rouge">[X,Y]</code> being <code class="language-plaintext highlighter-rouge">X</code> the number of tokens to consider on the left of the chunk, and <code class="language-plaintext highlighter-rouge">Y</code> the max number of tokens to consider on the right. Let’s take a look at what different windows mean:</p>

<ul>
  <li>By default, the window is <code class="language-plaintext highlighter-rouge">[-1,-1]</code> which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in <code class="language-plaintext highlighter-rouge">setMaxSentLen()</code>).</li>
  <li><code class="language-plaintext highlighter-rouge">[0,0]</code> means “don’t pay attention to any token except the ner_chunk”, what basically is not considering any context for the Assertion resolution.</li>
  <li><code class="language-plaintext highlighter-rouge">[9,15]</code> is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.</li>
</ul>

<p>Check this <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb">scope window tuning assertion status detection notebook</a> that illustrates the effect of the different windows and how to properly <strong>fine-tune</strong> your AssertionDLModels to get the best of them.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">assertion_status</span> <span class="o">=</span> <span class="n">AssertionDLApproach</span><span class="p">()</span> \
          <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">"assertion_dl/"</span><span class="p">)</span> \
          <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span> \
          <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
          <span class="p">...</span>
          <span class="p">...</span>
          <span class="p">.</span><span class="n">setScopeWindow</span><span class="p">([</span><span class="mi">9</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>     <span class="c1"># NEW! Scope Window!
</span></code></pre></div></div>

<h4 id="reading-json-files-exported-from-alab-from-hdfs-with-annotationjsonreader">Reading JSON Files (Exported from ALAB) From HDFS with <code class="language-plaintext highlighter-rouge">AnnotationJsonReader</code></h4>

<p>Now we can read the dataframe from a HDFS that we read the files from in our cluster.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filename</span> <span class="o">=</span> <span class="s">"hdfs:///user/livy/import.json"</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">AnnotationToolJsonReader</span><span class="p">(</span><span class="n">assertion_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'AsPresent'</span><span class="p">,</span> <span class="s">'AsAbsent'</span><span class="p">,</span> <span class="s">'AsConditional'</span><span class="p">,</span> <span class="s">'AsHypothetical'</span><span class="p">,</span> <span class="s">'Family'</span><span class="p">,</span> <span class="s">'AsPossible'</span><span class="p">,</span> <span class="s">'AsElse'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">reader</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="allow-users-write-tensorflow-graphs-to-hdfs">Allow Users Write Tensorflow Graphs to HDFS</h4>

<p>Now we can save custom Tensorflow graphs to the HDFS that mainly being used in a cluster environment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf_graph</span><span class="p">.</span><span class="n">build</span><span class="p">(</span><span class="s">"ner_dl"</span><span class="p">,</span> <span class="n">build_params</span><span class="o">=</span><span class="p">{</span><span class="s">"embeddings_dim"</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span> <span class="s">"nchars"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span> <span class="s">"ntags"</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span> <span class="s">"is_medical"</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span> <span class="n">model_location</span><span class="o">=</span><span class="s">"hdfs:///user/livy"</span><span class="p">,</span> <span class="n">model_filename</span><span class="o">=</span><span class="s">"auto"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="serving-spark-nlp-on-apis">Serving Spark NLP on APIs</h4>

<p>Two new notebooks and a series of blog posts / Medium articles have been created to guide Spark NLP users to serve Spark NLP on a RestAPI.</p>

<ul>
  <li>The notebooks can be found <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/RestAPI">here</a>.</li>
  <li>The articles can be found in the Technical Documentation of Spark NLP, available <a href="https://nlp.johnsnowlabs.com/docs/en/quickstart">here</a> and also in Medium:
    <ul>
      <li><a href="https://medium.com/@jjmcarrascosa/serving-spark-nlp-via-api-1-3-microsoft-synapse-ml-2c77a3f61f9d">Serving Spark NLP via API (1/3): Microsoft’s Synapse ML</a></li>
      <li><a href="https://medium.com/@jjmcarrascosa/serving-spark-nlp-via-api-2-3-fastapi-and-lightpipelines-218d1980c9fc">Serving Spark NLP via API (2/3): FastAPI and LightPipelines</a></li>
      <li><a href="https://medium.com/@jjmcarrascosa/serving-spark-nlp-via-api-3-3-databricks-and-mlflow-serve-apis-4ef113e7fac4">Serving Spark NLP via API (3/3): Databricks Jobs and MLFlow Serve APIs</a></li>
    </ul>
  </li>
</ul>

<p>The difference between both approaches are the following:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">SynapseML</code> is a Microsoft Azure Open Source library used to carry out ML at scale. In this case, we use the Spark Serving feature, that leverages Spark Streaming and adds a web server with a Load Balancer, allowing concurrent processing of Spark NLP calls. Best approach if you look for scalability with Load Balancing.</li>
  <li><code class="language-plaintext highlighter-rouge">FastAPI</code> + <code class="language-plaintext highlighter-rouge">LightPipelines</code>: A solution to run Spark NLP using a FastAPI webserver. It uses LightPipelines, what means having a very good performance but not leveraging Spark Clusters. Also, no Load Balancer is available in the suggestion, but you can create your own. Best approach if you look for performance.</li>
  <li><code class="language-plaintext highlighter-rouge">Databricks</code> and <code class="language-plaintext highlighter-rouge">MLFlow</code>: Using MLFlow Serve or Databricks Jobs APIs to serve for inference Spark NLP pipelines from within Databricks. Best approach if you look for scalability within Databricks.</li>
</ul>

<h4 id="updated-documentation-on-installing-spark-nlp-for-healthcare-in-aws-emr-jupyter-livy-yarn-hadoop">Updated Documentation on Installing Spark NLP For Healthcare in AWS EMR (Jupyter, Livy, Yarn, Hadoop)</h4>

<p>Ready-to-go Spark NLP for Healthcare environment in AWS EMR. Full instructions are <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/platforms/emr">here</a>.</p>

<h4 id="new-series-of-notebooks-to-reproduce-the-academic-papers-published-by-our-colleagues">New Series of Notebooks to Reproduce the Academic Papers Published by Our Colleagues</h4>

<p>You can find all these notebooks <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/academic">here</a></p>

<h4 id="pyspark-tutorial-notebooks-to-let-non-spark-users-to-get-started-with-apache-spark-ecosystem-in-python">PySpark Tutorial Notebooks to Let Non-Spark Users to Get Started with Apache Spark Ecosystem in Python</h4>

<p>John Snow Labs has created a series of 8 notebooks to go over PySpark from zero to hero. Notebooks cover PySpark essentials, DataFrame creation, querying, importing data from different formats, functions / udfs, Spark MLLib examples (regression, classification, clustering) and Spark NLP best practises (usage of parquet, repartition, coalesce, custom annotators, etc).</p>

<p>You can find all these notebooks <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/PySpark">here</a>.</p>

<h4 id="new--updated-notebooks">New &amp; Updated Notebooks</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Series of academic notebooks</code> : A new series of academic paper notebooks, available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/academic">here</a></li>
  <li><code class="language-plaintext highlighter-rouge">Clinical_Deidentification_in_Spanish.ipynb</code>: A notebook showcasing Clinical Deidentification in Spanish, available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.2.Clinical_Deidentification_in_Spanish.ipynb">here</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">Clinical_Deidentification_Comparison.ipynb</code>: A new series of comparisons between different Deidentification libraries. So far, it contains Spark NLP for Healthcare and ScrubaDub with Spacy Transformers. Available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.3.Clinical_Deidentification_Comparison.ipynb">here</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">Scope_window_tuning_assertion_status_detection.ipynb</code>: How to finetune Assertion Status using the Scope Window. Available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb">here</a></li>
  <li><code class="language-plaintext highlighter-rouge">Clinical_Longformer_vs_BertSentence_&amp;_USE.ipynb</code>: A Comparison of how Clinical Longformer embeddings, averaged by the Sentence Embeddings annotator, performs compared to BioBert and UniversalSentenceEncoding. Link <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/clinical_text_classification/3.Clinical_Longformer_vs_BertSentence_%26_USE.ipynb">here</a>.</li>
  <li><code class="language-plaintext highlighter-rouge">Serving_SparkNLP_with_Synapse.ipynb</code>: Serving SparkNLP for production purposes using Synapse ML. Available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/RestAPI/Serving_SparkNLP_with_Synapse.ipynb">here</a></li>
  <li><code class="language-plaintext highlighter-rouge">Serving_SparkNLP_with_FastAPI_and_LP.ipynb</code>: Serving SparkNLP for production purposes using FastAPI, RestAPI and LightPipelines. Available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/RestAPI/Serving_SparkNLP_with_FastAPI_and_LP.ipynb">here</a></li>
  <li><code class="language-plaintext highlighter-rouge">Series of PySpark tutorial notebooks</code>: Available <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/PySpark">here</a></li>
</ul>

<h4 id="list-of-recently-updated-or-added-models-2">List of Recently Updated or Added Models</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_hcpcs</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_rct_biobert</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_augmented_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_roberta_augmented_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_roberta_augmented_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">clinical_deidentification_augmented_es</code></li>
</ul>

<p><strong>For all Spark NLP for healthcare models, please check : <a href="https://nlp.johnsnowlabs.com/models?edition=Spark+NLP+for+Healthcare">Models Hub Page</a></strong></p>

<h2 id="341">3.4.1</h2>

<p>We are glad to announce that Spark NLP Healthcare 3.4.1 has been released!</p>

<h4 id="highlights-4">Highlights</h4>

<ul>
  <li>Brand new Spanish deidentification NER models</li>
  <li>Brand new Spanish deidentification pretrained pipeline</li>
  <li>New clinical NER model to detect supplements</li>
  <li>New RxNorm sentence entity resolver model</li>
  <li>New <code class="language-plaintext highlighter-rouge">EntityChunkEmbeddings</code> annotator</li>
  <li>New <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> annotator</li>
  <li>New <code class="language-plaintext highlighter-rouge">MedicalDistilBertForSequenceClassification</code> annotator</li>
  <li>New <code class="language-plaintext highlighter-rouge">MedicalDistilBertForSequenceClassification</code> and <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> models</li>
  <li>Redesign of the <code class="language-plaintext highlighter-rouge">ContextualParserApproach</code> annotator</li>
  <li><code class="language-plaintext highlighter-rouge">getClasses</code> method in <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> and <code class="language-plaintext highlighter-rouge">RelationExtractionDLModel</code> annotators</li>
  <li>Label customization feature for <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> and <code class="language-plaintext highlighter-rouge">RelationExtractionDL</code> models</li>
  <li><code class="language-plaintext highlighter-rouge">useBestModel</code> parameter in <code class="language-plaintext highlighter-rouge">MedicalNerApproach</code> annotator</li>
  <li>Early stopping feature in <code class="language-plaintext highlighter-rouge">MedicalNerApproach</code> annotator</li>
  <li>Multi-Language support for faker and regex lists of <code class="language-plaintext highlighter-rouge">Deidentification</code> annotator</li>
  <li>Spark 3.2.0 compatibility for the entire library</li>
  <li>Saving visualization feature in <code class="language-plaintext highlighter-rouge">spark-nlp-display</code> library</li>
  <li>Deploying a custom Spark NLP image (for opensource, healthcare, and Spark OCR) to an enterprise version of Kubernetes: OpenShift</li>
  <li>New speed benchmarks table on databricks</li>
  <li>New &amp; Updated Notebooks</li>
  <li>List of recently updated or added models</li>
</ul>

<h4 id="brand-new-spanish-deidentification-ner-models">Brand New Spanish Deidentification NER Models</h4>

<p>We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in <strong>Spanish</strong>. <code class="language-plaintext highlighter-rouge">ner_deid_generic</code> and <code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> models are trained with in-house annotations. Both also are available for using Roberta Spanish Clinical Embeddings and sciwiki 300d.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_generic</code> : Detects 7 PHI entities in Spanish (<code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">NAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">ID</code>).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> : Detects 13 PHI sub-entities in Spanish (<code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">E-MAIL</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">AGE</code>).</p>
  </li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings <span class="o">=</span> WordEmbeddingsModel.pretrained<span class="o">(</span><span class="s2">"embeddings_sciwiki_300d"</span>,<span class="s2">"es"</span>,<span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>

deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_generic"</span>, <span class="s2">"es"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>

deid_sub_entity_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity"</span>, <span class="s2">"es"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_sub_entity"</span><span class="o">)</span>
...

text <span class="o">=</span> <span class="s2">"""Antonio Pérez Juan, nacido en Cadiz, España. Aún no estaba vacunado, se infectó con Covid-19 el dia 14/03/2020
y tuvo que ir al Hospital. Fue tratado con anticuerpos monoclonales en la Clinica San Carlos.."""</span>
result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>text]], <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| chunk              | ner_deid_generic_chunk | ner_deid_subentity_chunk |
|--------------------|------------------------|--------------------------|
| Antonio Pérez Juan | NAME                   | PATIENT                  |
| Cádiz              | LOCATION               | LOCATION                 |
| España             | LOCATION               | LOCATION                 |
| 14/03/2022         | DATE                   | DATE                     |
| Clínica San Carlos | LOCATION               | HOSPITAL                 |
</code></pre></div></div>

<h4 id="brand-new-spanish-deidentification-pretrained-pipeline">Brand New Spanish Deidentification Pretrained Pipeline</h4>

<p>We developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from <strong>Spanish</strong> medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask, fake or obfuscate the following entities: <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">E-MAIL</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">URL</code>, <code class="language-plaintext highlighter-rouge">IP</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">ACCOUNT</code>, <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">PLATE</code>, <code class="language-plaintext highlighter-rouge">SEX</code> and <code class="language-plaintext highlighter-rouge">IPADDR</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
deid_pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"clinical_deidentification"</span>, <span class="s2">"es"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>

sample_text <span class="o">=</span> <span class="s2">"""Datos del paciente. Nombre:  Jose . Apellidos: Aranda Martinez. NHC: 2748903. NASS: 26 37482910."""</span>

result <span class="o">=</span> deid_pipe.annotate<span class="o">(</span>text<span class="o">)</span>

print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'masked'</span><span class="o">]))</span>
print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'masked_with_chars'</span><span class="o">]))</span>
print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'masked_fixed_length_chars'</span><span class="o">]))</span>
print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'obfuscated'</span><span class="o">]))</span>
</code></pre></div></div>
<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Masked with entity labels
<span class="nt">------------------------------</span>
Datos del paciente. Nombre:  &lt;PATIENT&gt; <span class="nb">.</span> Apellidos: &lt;PATIENT&gt;. NHC: &lt;SSN&gt;. NASS: &lt;SSN&gt; &lt;SSN&gt;

Masked with chars
<span class="nt">------------------------------</span>
Datos del paciente. Nombre:  <span class="o">[</span><span class="k">**</span><span class="o">]</span> <span class="nb">.</span> Apellidos: <span class="o">[</span><span class="k">*************</span><span class="o">]</span><span class="nb">.</span> NHC: <span class="o">[</span><span class="k">*****</span><span class="o">]</span><span class="nb">.</span> NASS: <span class="o">[</span><span class="k">**</span><span class="o">]</span> <span class="o">[</span><span class="k">******</span><span class="o">]</span>

Masked with fixed length chars
<span class="nt">------------------------------</span>
Datos del paciente. Nombre:  <span class="k">****</span> <span class="nb">.</span> Apellidos: <span class="k">****</span><span class="nb">.</span> NHC: <span class="k">****</span><span class="nb">.</span> NASS: <span class="k">****</span> <span class="k">****</span>

Obfuscated
<span class="nt">------------------------------</span>
Datos del paciente. Nombre:  Sr. Lerma <span class="nb">.</span> Apellidos: Aristides Gonzalez Gelabert. NHC: BBBBBBBBQR648597. NASS: 041010000011 RZRM020101906017 04.
</code></pre></div></div>

<h4 id="new-clinical-ner-model-to-detect-supplements">New Clinical NER Model to Detect Supplements</h4>

<p>We are releasing <code class="language-plaintext highlighter-rouge">ner_supplement_clinical</code> model that can extract benefits of using drugs for certain conditions. It can label detected entities as <code class="language-plaintext highlighter-rouge">CONDITION</code> and <code class="language-plaintext highlighter-rouge">BENEFIT</code>. Also this model is trained on the dataset that is released by Spacy in their HealthSea product. Here is the benchmark comparison of both versions:</p>

<table>
  <thead>
    <tr>
      <th>Entity</th>
      <th>Spark NLP</th>
      <th>Spacy-HealthSea</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BENEFIT</td>
      <td>0.8729641</td>
      <td>0.8330684</td>
    </tr>
    <tr>
      <td>CONDITION</td>
      <td>0.8339274</td>
      <td>0.8333333</td>
    </tr>
  </tbody>
</table>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_supplement_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_tags"</span><span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Excellent!. The state of health improves, nervousness disappears, and night sleep improves. It also promotes hair and nail growth."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+------------------------+---------------+
| chunk                  | ner_label     |
+------------------------+---------------+
| nervousness            | CONDITION     |
| night <span class="nb">sleep </span>improves   | BENEFIT       |
| hair                   | BENEFIT       |
| nail                   | BENEFIT       |
+------------------------+---------------+
</code></pre></div></div>

<h4 id="new-rxnorm-sentence-entity-resolver-model">New RxNorm Sentence Entity Resolver Model</h4>

<p><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_augmented_re</code> : This model maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes without specifying the relations between the entities (relations are calculated on the fly inside the annotator) using sbiobert_base_cased_mli Sentence Bert Embeddings (EntityChunkEmbeddings).</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">rxnorm_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span>\
      <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented_re"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"entity_chunk_embeddings"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
<span class="p">...</span>
</code></pre></div></div>

<h4 id="new-entitychunkembeddings-annotator">New <code class="language-plaintext highlighter-rouge">EntityChunkEmbeddings</code> Annotator</h4>

<p>We have a new <code class="language-plaintext highlighter-rouge">EntityChunkEmbeddings</code> annotator to compute a weighted average vector representing entity-related vectors. The model’s input usually consists of chunks of recognized named entities produced by MedicalNerModel. We can specify relations between the entities by the <code class="language-plaintext highlighter-rouge">setTargetEntities()</code> parameter, and the internal Relation Extraction model finds related entities and creates a chunk. Embedding for the chunk is calculated according to the weights specified in the <code class="language-plaintext highlighter-rouge">setEntityWeights()</code> parameter.</p>

<p>For instance, the chunk <code class="language-plaintext highlighter-rouge">warfarin sodium 5 MG Oral Tablet</code> has <code class="language-plaintext highlighter-rouge">DRUG</code>, <code class="language-plaintext highlighter-rouge">STRENGTH</code>, <code class="language-plaintext highlighter-rouge">ROUTE</code>, and <code class="language-plaintext highlighter-rouge">FORM</code> entity types. Since DRUG label is the most prominent label for resolver models, now we can assign weight to prioritize DRUG label (i.e <code class="language-plaintext highlighter-rouge">{"DRUG": 0.8, "STRENGTH": 0.2, "ROUTE": 0.2, "FORM": 0.2}</code> as shown below). In other words, embeddings of these labels are multipled by the assigned weights such as <code class="language-plaintext highlighter-rouge">DRUG</code> by <code class="language-plaintext highlighter-rouge">0.8</code>.</p>

<p>For more details and examples, please check <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.2.Sentence_Entity_Resolvers_with_EntityChunkEmbeddings.ipynb">Sentence Entity Resolvers with EntityChunkEmbeddings Notebook</a> in the Spark NLP workshop repo.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>

<span class="n">drug_chunk_embeddings</span> <span class="o">=</span> <span class="n">EntityChunkEmbeddings</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"drug_chunk_embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTargetEntities</span><span class="p">({</span><span class="s">"DRUG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"STRENGTH"</span><span class="p">,</span> <span class="s">"ROUTE"</span><span class="p">,</span> <span class="s">"FORM"</span><span class="p">]})</span>\
    <span class="p">.</span><span class="n">setEntityWeights</span><span class="p">({</span><span class="s">"DRUG"</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s">"STRENGTH"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">"ROUTE"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">"FORM"</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">})</span>

<span class="n">rxnorm_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented_re"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"drug_chunk_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">rxnorm_weighted_pipeline_re</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">documenter</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">posology_ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">pos_tager</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">drug_chunk_embeddings</span><span class="p">,</span>
        <span class="n">rxnorm_resolver</span><span class="p">])</span>

<span class="n">sampleText</span> <span class="o">=</span> <span class="p">[</span><span class="s">"The patient was given metformin 500 mg, 2.5 mg of coumadin and then ibuprofen."</span><span class="p">,</span>
              <span class="s">"The patient was given metformin 400 mg, coumadin 5 mg, coumadin, amlodipine 10 MG"</span><span class="p">]</span>

<span class="n">data_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_df</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">rxnorm_weighted_pipeline_re</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data_df</span><span class="p">)</span>
</code></pre></div></div>

<p>The internal relation extraction creates the chunks here, and the embedding is computed according to the weights.</p>

<p><em>Results</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----+----------------+--------------------------+--------------------------------------------------+
|index|           chunk|rxnorm_code_weighted_08_re|                                      Concept_Name|
+-----+----------------+--------------------------+--------------------------------------------------+
|    0|metformin 500 mg|                    860974|metformin hydrochloride 500 MG:::metformin 500 ...|
|    0| 2.5 mg coumadin|                    855313|warfarin sodium 2.5 MG <span class="o">[</span>Coumadin]:::warfarin so...|
|    0|       ibuprofen|                   1747293|ibuprofen Injection:::ibuprofen Pill:::ibuprofe...|
|    1|metformin 400 mg|                    332809|metformin 400 MG:::metformin 250 MG Oral Tablet...|
|    1|   coumadin 5 mg|                    855333|warfarin sodium 5 MG <span class="o">[</span>Coumadin]:::warfarin sodi...|
|    1|        coumadin|                    202421|Coumadin:::warfarin sodium 2 MG/ML Injectable S...|
|    1|amlodipine 10 MG|                    308135|amlodipine 10 MG Oral Tablet:::amlodipine 10 MG...|
+-----+----------------+--------------------------+--------------------------------------------------+
</code></pre></div></div>

<h4 id="new-medicalbertforsequenceclassification-annotator">New <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> Annotator</h4>

<p>We developed a new annotator called <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code>. It can load BERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</p>

<h4 id="new-medicaldistilbertforsequenceclassification-annotator">New <code class="language-plaintext highlighter-rouge">MedicalDistilBertForSequenceClassification</code> Annotator</h4>

<p>We developed a new annotator called <code class="language-plaintext highlighter-rouge">MedicalDistilBertForSequenceClassification</code>. It can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</p>

<h4 id="new-medicaldistilbertforsequenceclassification-and-medicalbertforsequenceclassification-models">New <code class="language-plaintext highlighter-rouge">MedicalDistilBertForSequenceClassification</code> and <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> Models</h4>

<p>We are releasing a new <code class="language-plaintext highlighter-rouge">MedicalDistilBertForSequenceClassification</code> model and three new <code class="language-plaintext highlighter-rouge">MedicalBertForSequenceClassification</code> models.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_ade_biobert</code>: a classifier for detecting if a sentence is talking about a possible ADE (<code class="language-plaintext highlighter-rouge">TRUE</code>, <code class="language-plaintext highlighter-rouge">FALSE</code>)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_gender_biobert</code>: a classifier for detecting the gender of the main subject of the sentence (<code class="language-plaintext highlighter-rouge">MALE</code>, <code class="language-plaintext highlighter-rouge">FEMALE</code>, <code class="language-plaintext highlighter-rouge">UNKNOWN</code>)</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_pico_biobert</code>: a classifier for detecting the class of a sentence according to PICO framework (<code class="language-plaintext highlighter-rouge">CONCLUSIONS</code>, <code class="language-plaintext highlighter-rouge">DESIGN_SETTING</code>,<code class="language-plaintext highlighter-rouge">INTERVENTION</code>, <code class="language-plaintext highlighter-rouge">PARTICIPANTS</code>, <code class="language-plaintext highlighter-rouge">FINDINGS</code>, <code class="language-plaintext highlighter-rouge">MEASUREMENTS</code>, <code class="language-plaintext highlighter-rouge">AIMS</code>)</p>
  </li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">MedicalBertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_sequence_classifier_pico"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"To compare the results of recording enamel opacities using the TF and modified DDE indices."</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">sequence_clf_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------------------------------------------------------------------+-----+
|text                                                                                       |label|
+-------------------------------------------------------------------------------------------+-----+
|To compare the results of recording enamel opacities using the TF and modified DDE indices.|AIMS |
+-------------------------------------------------------------------------------------------+-----+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">distilbert_sequence_classifier_ade</code> : This model is a DistilBertForSequenceClassification model for classifying clinical texts whether they contain ADE (<code class="language-plaintext highlighter-rouge">TRUE</code>, <code class="language-plaintext highlighter-rouge">FALSE</code>).</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">MedicalDistilBertForSequenceClassification</span>\
      <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'distilbert_sequence_classifier_ade'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'token'</span><span class="p">,</span> <span class="s">'document'</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'class'</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"I felt a bit drowsy and had blurred vision after taking Aspirin."</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">sequence_clf_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------------------------------------------------------+-----+
|text                                                            |label|
+----------------------------------------------------------------+-----+
|I felt a bit drowsy and had blurred vision after taking Aspirin.| True|
+----------------------------------------------------------------+-----+
</code></pre></div></div>

<h4 id="redesign-of-the-contextualparserapproach-annotator">Redesign of the <code class="language-plaintext highlighter-rouge">ContextualParserApproach</code> Annotator</h4>

<ul>
  <li>We’ve dropped the annotator’s <code class="language-plaintext highlighter-rouge">contextMatch</code> parameter and removed the need for a <code class="language-plaintext highlighter-rouge">context</code> field when feeding a JSON configuration file to the annotator. Context information can now be fully defined using the <code class="language-plaintext highlighter-rouge">prefix</code>, <code class="language-plaintext highlighter-rouge">suffix</code> and <code class="language-plaintext highlighter-rouge">contextLength</code> fields in the JSON configuration file.</li>
  <li>We’ve also fixed issues with the <code class="language-plaintext highlighter-rouge">contextException</code> field in the JSON configuration file - it was mismatching values in documents with several sentences and ignoring exceptions situated to the right of a word/token.</li>
  <li>The <code class="language-plaintext highlighter-rouge">ruleScope</code> field in the JSON configuration file can now be set to <code class="language-plaintext highlighter-rouge">document</code> instead of <code class="language-plaintext highlighter-rouge">sentence</code>. This allows you to match multi-word entities like “New York” or “Salt Lake City”. You can do this by setting <code class="language-plaintext highlighter-rouge">"ruleScope" : "document"</code> in the JSON configuration file and feeding a dictionary (csv or tsv) to the annotator with its <code class="language-plaintext highlighter-rouge">setDictionary</code> parameter. These changes also mean that we’ve dropped the <code class="language-plaintext highlighter-rouge">updateTokenizer</code> parameter since the new capabilities of <code class="language-plaintext highlighter-rouge">ruleScope</code> improve the user experience for matching multi-word entities.</li>
  <li>You can now feed in a dictionary in your chosen format - either vertical or horizontal. You can set that with the following parameter: <code class="language-plaintext highlighter-rouge">setDictionary("dictionary.csv", options={"orientation":"vertical"})</code></li>
  <li>Lastly, there was an improvement made to the confidence value calculation process to better measure successful hits.</li>
</ul>

<p>For more explanation and examples, please check this <a href="https://medium.com/spark-nlp/contextual-parser-increased-flexibility-extracting-entities-in-spark-nlp-123ed58672f0">Contextual Parser medium article</a> and <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.2.Contextual_Parser_Rule_Based_NER.ipynb">Contextual Parser Notebook</a>.</p>

<h4 id="getclasses-method-in-relationextractionmodel-and-relationextractiondlmodel-annotators"><code class="language-plaintext highlighter-rouge">getClasses</code> Method in <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> and <code class="language-plaintext highlighter-rouge">RelationExtractionDLModel</code> Annotators</h4>

<p>Now you can use <code class="language-plaintext highlighter-rouge">getClasses()</code> method for checking the relation labels of RE models (RelationExtractionModel and RelationExtractionDLModel) like MedicalNerModel().</p>

<p><em>Example</em> :</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clinical_re_Model</span> <span class="o">=</span> <span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_temporal_events_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\

<span class="n">clinical_re_Model</span><span class="p">.</span><span class="n">getClasses</span><span class="p">()</span>
</code></pre></div></div>

<p><em>Output</em> :</p>
<pre><code class="language-output">['OVERLAP', 'BEFORE', 'AFTER']
</code></pre>

<h4 id="label-customization-feature-for-relationextractionmodel-and-relationextractiondl-models">Label Customization Feature for <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> and <code class="language-plaintext highlighter-rouge">RelationExtractionDL</code> Models</h4>

<p>We are releasing label customization feature for Relation Extraction and Relation Extraction DL models by using <code class="language-plaintext highlighter-rouge">.setCustomLabels()</code> parameter.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">reModel</span> <span class="o">=</span> <span class="n">RelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"drug-ade, ade-drug"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setCustomLabels</span><span class="p">({</span><span class="s">"1"</span><span class="p">:</span> <span class="s">"is_related"</span><span class="p">,</span> <span class="s">"0"</span><span class="p">:</span> <span class="s">"not_related"</span><span class="p">})</span>

<span class="n">redl_model</span> <span class="o">=</span> <span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'redl_ade_biobert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCustomLabels</span><span class="p">({</span><span class="s">"1"</span><span class="p">:</span> <span class="s">"is_related"</span><span class="p">,</span> <span class="s">"0"</span><span class="p">:</span> <span class="s">"not_related"</span><span class="p">})</span>
<span class="p">...</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"I experienced fatigue and muscle cramps after taking Lipitor but no more adverse after passing Zocor."</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------+-------+-------------+-------+-------+----------+
|   relation|entity1|       chunk1|entity2| chunk2|confidence|
+-----------+-------+-------------+-------+-------+----------+
| is_related|    ADE|      fatigue|   DRUG|Lipitor| 0.9999825|
|not_related|    ADE|      fatigue|   DRUG|  Zocor| 0.9960077|
| is_related|    ADE|muscle cramps|   DRUG|Lipitor|       1.0|
|not_related|    ADE|muscle cramps|   DRUG|  Zocor|   0.94971|
+-----------+-------+-------------+-------+-------+----------+
</code></pre></div></div>

<h4 id="usebestmodel-parameter-in-medicalnerapproach-annotator"><code class="language-plaintext highlighter-rouge">useBestModel</code> Parameter in <code class="language-plaintext highlighter-rouge">MedicalNerApproach</code> Annotator</h4>

<p>Introducing <code class="language-plaintext highlighter-rouge">useBestModel</code> param in MedicalNerApproach annotator. This param preserves and restores the model that has achieved the best performance at the end of the training. The priority is metrics from testDataset (micro F1), metrics from validationSplit (micro F1), and if none is set it will keep track of loss during the training.</p>

<p><em>Example</em> :</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">med_ner</span> <span class="o">=</span> <span class="n">MedicalNerApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">...</span>
    <span class="p">...</span>
    <span class="p">.</span><span class="n">setUseBestModel</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
</code></pre></div></div>

<h4 id="early-stopping-feature-in-medicalnerapproach-annotator">Early Stopping Feature in <code class="language-plaintext highlighter-rouge">MedicalNerApproach</code> Annotator</h4>

<p>Introducing <code class="language-plaintext highlighter-rouge">earlyStopping</code> feature for MedicalNerApproach(). You can stop training at the point when the perforfmance on test/validation dataset starts to degrage. Two params are added to MedicalNerApproach() in order to use this feature:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">earlyStoppingCriterion</code> : (float) This is used set the minimal improvement of the test metric to terminate training. The metric monitored is the same as the metrics used in <code class="language-plaintext highlighter-rouge">useBestModel</code> (macro F1 when using test/validation set, loss otherwise). Default is 0 which means no early stopping is applied.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">earlyStoppingPatience</code>: (int), the number of epoch without improvement which will be tolerated. Default is 0, which means that early stopping will occur at the first time when performance in the current epoch is no better than in the previous epoch.</p>
  </li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">med_ner</span> <span class="o">=</span> <span class="n">MedicalNerApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">...</span>
    <span class="p">...</span>
    <span class="p">.</span><span class="n">setTestDataset</span><span class="p">(</span><span class="n">test_data_parquet_path</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEarlyStoppingCriterion</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEarlyStoppingPatience</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
</code></pre></div></div>

<h4 id="multi-language-support-for-faker-and-regex-lists-of-deidentification-annotator">Multi-Language Support for Faker and Regex Lists of <code class="language-plaintext highlighter-rouge">Deidentification</code> Annotator</h4>

<p>We have a new <code class="language-plaintext highlighter-rouge">.setLanguage()</code> parameter in order to use internal Faker and Regex list for multi-language texts. When you are working with German and Spanish texts for a Deidentification, you can set this parameter to <code class="language-plaintext highlighter-rouge">de</code> for German and <code class="language-plaintext highlighter-rouge">es</code> for Spanish. Default value of this parameter is <code class="language-plaintext highlighter-rouge">en</code>.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">deid_obfuscated</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"obfuscated"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">'de'</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span>\
</code></pre></div></div>

<h4 id="spark-320-compatibility-for-the-entire-library">Spark 3.2.0 Compatibility for the Entire Library</h4>

<p>Now we can use the <a href="https://spark.apache.org/docs/3.2.0/">Spark 3.2.0</a> version for Spark NLP for Healthcare by setting <code class="language-plaintext highlighter-rouge">spark32=True</code> in <code class="language-plaintext highlighter-rouge">sparknlp_jsl.start()</code> function.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">!</span> pip <span class="nb">install</span> <span class="nt">--ignore-installed</span> <span class="nt">-q</span> <span class="nv">pyspark</span><span class="o">==</span>3.2.0
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import sparknlp_jsl

spark <span class="o">=</span> sparknlp_jsl.start<span class="o">(</span>SECRET, <span class="nv">spark32</span><span class="o">=</span>True<span class="o">)</span>
</code></pre></div></div>

<h4 id="saving-visualization-feature-in-spark-nlp-display-library">Saving Visualization Feature in <code class="language-plaintext highlighter-rouge">spark-nlp-display</code> Library</h4>

<p>We have a new <code class="language-plaintext highlighter-rouge">save_path</code> parameter in <code class="language-plaintext highlighter-rouge">spark-nlp-display</code> library for saving any visualization results in Spark NLP.</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_display import NerVisualizer

visualiser <span class="o">=</span> NerVisualizer<span class="o">()</span>

visualiser.display<span class="o">(</span>light_result[0], <span class="nv">label_col</span><span class="o">=</span><span class="s1">'ner_chunk'</span>, <span class="nv">document_col</span><span class="o">=</span><span class="s1">'document'</span>, <span class="nv">save_path</span><span class="o">=</span><span class="s2">"display_result.html"</span><span class="o">)</span>
</code></pre></div></div>

<h4 id="deploying-a-custom-spark-nlp-image-for-opensource-healthcare-and-spark-ocr-to-an-enterprise-version-of-kubernetes-openshift">Deploying a Custom Spark NLP Image (for opensource, healthcare, and Spark OCR) to an Enterprise Version of Kubernetes: OpenShift</h4>

<p>Spark NLP for opensource, healthcare, and SPARK OCR is now available for Openshift - enterprise version of Kubernetes. For deployment, please refer to:</p>

<p>Github Link: https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/platforms/openshift</p>

<p>Youtube: https://www.youtube.com/watch?v=FBes-6ylFrM&amp;ab_channel=JohnSnowLabs</p>

<h4 id="new-speed-benchmarks-table-on-databricks">New Speed Benchmarks Table on Databricks</h4>

<p>We prepared a speed benchmark table by running a clinical BERT For Token Classification model pipeline on various number of repartitioning and writing the results to parquet or delta formats. You can find the details here : <a href="https://nlp.johnsnowlabs.com/docs/en/benchmark#clinical-bert-for-token-classification-benchmark-experiment">Clinical Bert For Token Classification Benchmark Experiment</a>.</p>

<h4 id="new--updated-notebooks-1">New &amp; Updated Notebooks</h4>

<ul>
  <li>We have updated our existing workshop notebooks with v3.4.0 by adding new features and functionalities.</li>
  <li>You can find the workshop notebooks updated with previous versions in the branches named with the relevant version.</li>
  <li>We have updated the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.2.Contextual_Parser_Rule_Based_NER.ipynb">ContextualParser Notebook</a> with the new updates in this version.</li>
  <li>We have a new <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.2.Sentence_Entity_Resolvers_with_EntityChunkEmbeddings.ipynb">Sentence Entity Resolvers with EntityChunkEmbeddings Notebook</a> for the new <code class="language-plaintext highlighter-rouge">EntityChunkEmbeddings</code> annotator.</li>
</ul>

<p><strong>To see more, please check : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></strong></p>

<h4 id="list-of-recently-updated-or-added-models-3">List of Recently Updated or Added Models</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_ade_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_gender_biobert_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_pico_biobert_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">distilbert_sequence_classifier_ade_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_supplement_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">deid_pipeline_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_roberta_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_roberta_es</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_nature_nero_clinical_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">ner_supplement_clinical_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_clinical_abbreviation_acronym_en</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_augmented_re</code></li>
</ul>

<p><strong>For all Spark NLP for healthcare models, please check : <a href="https://nlp.johnsnowlabs.com/models?edition=Spark+NLP+for+Healthcare">Models Hub Page</a></strong></p>

<h2 id="340">3.4.0</h2>

<p>We are glad to announce that Spark NLP Healthcare 3.4.0 has been released!
This is a massive release: new features, new models, academic papers, and more!</p>

<h4 id="highlights-5">Highlights</h4>

<ul>
  <li>New German Deidentification NER Models</li>
  <li>New German Deidentification Pretrained Pipeline</li>
  <li>New Clinical NER Models</li>
  <li>New AnnotationMerger Annotator</li>
  <li>New MedicalBertForTokenClassifier Annotator</li>
  <li>New BERT-Based Clinical NER Models</li>
  <li>New Clinical Relation Extraction Models</li>
  <li>New LOINC, SNOMED, UMLS and Clinical Abbreviation Entity Resolver Models</li>
  <li>New ICD10 to ICD9 Code Mapping Pretrained Pipeline</li>
  <li>New Clinical Sentence Embedding Models</li>
  <li>Printing Validation and Test Logs for MedicalNerApproach and AssertionDLApproach</li>
  <li>Filter Only the Regex Entities Feature in Deidentification Annotator</li>
  <li>Add <code class="language-plaintext highlighter-rouge">.setMaskingPolicy</code> Parameter in Deidentification Annotator</li>
  <li>Add <code class="language-plaintext highlighter-rouge">.cache_folder</code> Parameter in <code class="language-plaintext highlighter-rouge">UpdateModels.updateCacheModels()</code></li>
  <li>S3 Access Credentials No Longer Shipped Along Licenses</li>
  <li>Enhanced Security for the Library and log4shell Update</li>
  <li>New Peer-Reviewed Conference Paper on Clinical Relation Extraction</li>
  <li>New Peer-Reviewed Conference Paper on Adverse Drug Events Extraction</li>
  <li>New and Updated Notebooks</li>
</ul>

<h4 id="new-german-deidentification-ner-models">New German Deidentification NER Models</h4>

<p>We trained two new NER models to find PHI data (protected health information) that may need to be deidentified in <strong>German</strong>.
<code class="language-plaintext highlighter-rouge">ner_deid_generic</code> and <code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> models are trained with in-house annotations.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_generic</code> : Detects 7 PHI entities in German (<code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">NAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">ID</code>).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_deid_subentity</code> : Detects 12 PHI sub-entities in German (<code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">AGE</code>).</p>
  </li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...

embeddings <span class="o">=</span> WordEmbeddingsModel.pretrained<span class="o">(</span><span class="s2">"w2v_cc_300d"</span>,<span class="s2">"de"</span>,<span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>

deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_generic"</span>, <span class="s2">"de"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>

deid_sub_entity_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity"</span>, <span class="s2">"de"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner_sub_entity"</span><span class="o">)</span>
...

text <span class="o">=</span> <span class="s2">"""Michael Berger wird am Morgen des 12 Dezember 2018 ins St. Elisabeth-Krankenhaus
in Bad Kissingen eingeliefert. Herr Berger ist 76 Jahre alt und hat zu viel Wasser in den Beinen."""</span>

result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>text]], <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------+----------------------+-------------------------+
|chunk                    |ner_deid_generic_chunk|ner_deid_subentity_chunk |
+-------------------------+----------------------+-------------------------+
|Michael Berger           |NAME                  |PATIENT                  |
|12 Dezember 2018         |DATE                  |DATE                     |
|St. Elisabeth-Krankenhaus|LOCATION              |HOSPITAL                 |
|Bad Kissingen            |LOCATION              |CITY                     |
|Berger                   |NAME                  |PATIENT                  |
|76                       |AGE                   |AGE                      |
+-------------------------+----------------------+-------------------------+
</code></pre></div></div>
<h4 id="new-german-deidentification-pretrained-pipeline">New German Deidentification Pretrained Pipeline</h4>

<p>We developed a clinical deidentification pretrained pipeline that can be used to deidentify PHI information from <strong>German</strong> medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">ID</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">ACCOUNT</code>, <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">DLN</code>, <code class="language-plaintext highlighter-rouge">PLATE</code> entities.</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
from sparknlp.pretrained import PretrainedPipeline

deid_pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"clinical_deidentification"</span>, <span class="s2">"de"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>

text <span class="o">=</span> <span class="s2">"""Zusammenfassung : Michael Berger wird am Morgen des 12 Dezember 2018 ins St.Elisabeth Krankenhaus in Bad Kissingen eingeliefert.
Herr Michael Berger ist 76 Jahre alt und hat zu viel Wasser in den Beinen.

Persönliche Daten :
ID-Nummer: T0110053F
Platte A-BC124
Kontonummer: DE89370400440532013000
SSN : 13110587M565
Lizenznummer: B072RRE2I55
Adresse : St.Johann-Straße 13 19300"""</span>

result <span class="o">=</span> deid_pipe.annotate<span class="o">(</span>text<span class="o">)</span>

print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'masked'</span><span class="o">]))</span>
print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'obfuscated'</span><span class="o">]))</span>
print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'masked_with_chars'</span><span class="o">]))</span>
print<span class="o">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span>.join<span class="o">(</span>result[<span class="s1">'masked_fixed_length_chars'</span><span class="o">]))</span>

</code></pre></div></div>
<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Zusammenfassung : &lt;PATIENT&gt; wird am Morgen des &lt;DATE&gt; ins &lt;HOSPITAL&gt; eingeliefert.
Herr &lt;PATIENT&gt; ist &lt;AGE&gt; Jahre alt und hat zu viel Wasser <span class="k">in </span>den Beinen.
Persönliche Daten :
ID-Nummer: &lt;ID&gt;
Platte &lt;PLATE&gt;
Kontonummer: &lt;ACCOUNT&gt;
SSN : &lt;SSN&gt;
Lizenznummer: &lt;DLN&gt;
Adresse : &lt;STREET&gt; &lt;ZIP&gt;

Zusammenfassung : Herrmann Kallert wird am Morgen des 11-26-1977 ins International Neuroscience eingeliefert.
Herr Herrmann Kallert ist 79 Jahre alt und hat zu viel Wasser <span class="k">in </span>den Beinen.
Persönliche Daten :
ID-Nummer: 136704D357
Platte QA348G
Kontonummer: 192837465738
SSN : 1310011981M454
Lizenznummer: XX123456
Adresse : Klingelhöferring 31206

Zusammenfassung : <span class="k">****</span> wird am Morgen des <span class="k">****</span> ins <span class="k">****</span> eingeliefert.
Herr <span class="k">****</span> ist <span class="k">****</span> Jahre alt und hat zu viel Wasser <span class="k">in </span>den Beinen.
Persönliche Daten :
ID-Nummer: <span class="k">****</span>
Platte <span class="k">****</span>
Kontonummer: <span class="k">****</span>
SSN : <span class="k">****</span>
Lizenznummer: <span class="k">****</span>
Adresse : <span class="k">****</span> <span class="k">****</span>

Zusammenfassung : <span class="o">[</span><span class="k">************</span><span class="o">]</span> wird am Morgen des <span class="o">[</span><span class="k">**************</span><span class="o">]</span> ins <span class="o">[</span><span class="k">**********************</span><span class="o">]</span> eingeliefert.
Herr <span class="o">[</span><span class="k">************</span><span class="o">]</span> ist <span class="k">**</span> Jahre alt und hat zu viel Wasser <span class="k">in </span>den Beinen.
Persönliche Daten :
ID-Nummer: <span class="o">[</span><span class="k">*******</span><span class="o">]</span>
Platte <span class="o">[</span><span class="k">*****</span><span class="o">]</span>
Kontonummer: <span class="o">[</span><span class="k">********************</span><span class="o">]</span>
SSN : <span class="o">[</span><span class="k">**********</span><span class="o">]</span>
Lizenznummer: <span class="o">[</span><span class="k">*********</span><span class="o">]</span>
Adresse : <span class="o">[</span><span class="k">*****************</span><span class="o">]</span> <span class="o">[</span><span class="k">***</span><span class="o">]</span>
</code></pre></div></div>

<h4 id="new-clinical-ner-models">New Clinical NER Models</h4>

<p>We have two new clinical NER models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_abbreviation_clinical</code> : This model is trained to extract clinical abbreviations and acronyms in texts and labels these entities as <code class="language-plaintext highlighter-rouge">ABBR</code>.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_abbreviation_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----+---------+
|chunk|ner_label|
+-----+---------+
|CBC  |ABBR     |
|AB   |ABBR     |
|VDRL |ABBR     |
|HIV  |ABBR     |
+-----+---------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_drugprot_clinical</code> : This model detects chemical compounds/drugs and genes/proteins in medical text and research articles. Here are the labels it can detect : <code class="language-plaintext highlighter-rouge">GENE</code>, <code class="language-plaintext highlighter-rouge">CHEMICAL</code>, <code class="language-plaintext highlighter-rouge">GENE_AND_CHEMICAL</code>.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_drugprot_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Anabolic effects of clenbuterol on skeletal muscle are mediated by beta 2-adrenoceptor activation"</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                | ner_label         |
|---:|:---------------------|:------------------|
|  0 | clenbuterol          | CHEMICAL          |
|  1 | beta 2-adrenoceptor  | GENE              |

</code></pre></div></div>

<h4 id="new-annotationmerger-annotator">New AnnotationMerger Annotator</h4>

<p>A new annotator: <code class="language-plaintext highlighter-rouge">AnnotationMerger</code>. Besides NERs, now we will be able to merge results of <strong>Relation Extraction models</strong> and <strong>Assertion models</strong> as well. Therefore, it can merge results of Relation Extraction models, NER models, and Assertion Status models.</p>

<p><em>Example-1</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
annotation_merger <span class="o">=</span> AnnotationMerger<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"ade_relations"</span>, <span class="s2">"pos_relations"</span>, <span class="s2">"events_relations"</span><span class="o">)</span><span class="se">\</span>
    .setInputType<span class="o">(</span><span class="s2">"category"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"all_relations"</span><span class="o">)</span>
...

results <span class="o">=</span> ann_merger_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results-1</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | all_relations   | all_relations_entity1   | all_relations_chunk1   | all_relations_entity2   | all_relations_chunk2                                      |
|---:|:----------------|:------------------------|:-----------------------|:------------------------|:----------------------------------------------------------|
|  0 | 1               | DRUG                    | oxaprozin              | ADE                     | tense bullae                                              |
|  1 | 1               | DRUG                    | oxaprozin              | ADE                     | cutaneous fragility on the face and the back of the hands |
|  2 | DOSAGE-DRUG     | DOSAGE                  | 1 unit                 | DRUG                    | naproxen                                                  |
|  3 | DRUG-DURATION   | DRUG                    | naproxen               | DURATION                | <span class="k">for </span>5 days                                                |
|  4 | DOSAGE-DRUG     | DOSAGE                  | 1 unit                 | DRUG                    | oxaprozin                                                 |
|  5 | DRUG-FREQUENCY  | DRUG                    | oxaprozin              | FREQUENCY               | daily                                                     |
|  6 | OVERLAP         | TREATMENT               | naproxen               | DURATION                | 5 days                                                    |
|  7 | OVERLAP         | TREATMENT               | oxaprozin              | FREQUENCY               | daily                                                     |
|  8 | BEFORE          | TREATMENT               | oxaprozin              | PROBLEM                 | rheumatoid arthritis                                      |
|  9 | AFTER           | TREATMENT               | oxaprozin              | OCCURRENCE              | presented                                                 |
| 10 | OVERLAP         | FREQUENCY               | daily                  | PROBLEM                 | rheumatoid arthritis                                      |
| 11 | OVERLAP         | FREQUENCY               | daily                  | PROBLEM                 | tense bullae                                              |
| 12 | OVERLAP         | FREQUENCY               | daily                  | PROBLEM                 | cutaneous fragility on the face                           |
| 13 | BEFORE          | PROBLEM                 | rheumatoid arthritis   | OCCURRENCE              | presented                                                 |
| 14 | OVERLAP         | PROBLEM                 | rheumatoid arthritis   | PROBLEM                 | tense bullae                                              |
| 15 | OVERLAP         | PROBLEM                 | rheumatoid arthritis   | PROBLEM                 | cutaneous fragility on the face                           |
| 16 | BEFORE          | OCCURRENCE              | presented              | PROBLEM                 | tense bullae                                              |
| 17 | BEFORE          | OCCURRENCE              | presented              | PROBLEM                 | cutaneous fragility on the face                           |
| 18 | OVERLAP         | PROBLEM                 | tense bullae           | PROBLEM                 | cutaneous fragility on the face                           |
</code></pre></div></div>

<p><em>Example-2</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
ner_annotation_merger <span class="o">=</span> AnnotationMerger<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"ner_chunk"</span>, <span class="s2">"radiology_ner_chunk"</span>, <span class="s2">"jsl_ner_chunk"</span><span class="o">)</span><span class="se">\</span>
    .setInputType<span class="o">(</span><span class="s2">"chunk"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"all_ners"</span><span class="o">)</span>

assertion_annotation_merger <span class="o">=</span> AnnotationMerger<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"clinical_assertion"</span>, <span class="s2">"radiology_assertion"</span>, <span class="s2">"jsl_assertion"</span><span class="o">)</span><span class="se">\</span>
    .setInputType<span class="o">(</span><span class="s2">"assertion"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"all_assertions"</span><span class="o">)</span>
...

results <span class="o">=</span> ann_merger_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results-2</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | ners                            | all_assertions   |
|---:|:--------------------------------|:-----------------|
|  0 | naproxen                        | present          |
|  1 | chronic low back pain           | present          |
|  2 | oxaprozin                       | present          |
|  3 | rheumatoid arthritis            | present          |
|  4 | tense bullae                    | present          |
|  5 | cutaneous fragility on the face | present          |
|  6 | low back                        | Confirmed        |
|  7 | pain                            | Confirmed        |
|  8 | rheumatoid arthritis            | Confirmed        |
|  9 | tense bullae                    | Confirmed        |
| 10 | cutaneous                       | Confirmed        |
| 11 | fragility                       | Confirmed        |
| 12 | face                            | Confirmed        |
| 13 | back                            | Confirmed        |
| 14 | hands                           | Confirmed        |
| 15 | 1 unit                          | Present          |
| 16 | naproxen                        | Past             |
| 17 | <span class="k">for </span>5 days                      | Past             |
| 18 | chronic                         | Someoneelse      |
| 19 | low                             | Past             |
| 20 | back pain                       | Present          |
| 21 | 1 unit                          | Past             |
| 22 | oxaprozin                       | Past             |
| 23 | daily                           | Past             |
| 24 | rheumatoid arthritis            | Present          |
| 25 | tense                           | Present          |
| 26 | bullae                          | Present          |
| 27 | cutaneous fragility             | Present          |
| 28 | face                            | Someoneelse      |
| 29 | back of the hands               | Present          |
</code></pre></div></div>

<h4 id="new-medicalbertfortokenclassifier-annotator">New MedicalBertForTokenClassifier Annotator</h4>

<p>We developed a new annotator called MedicalBertForTokenClassifier that can load BERT-Based clinical token classifier models head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</p>

<h4 id="new-bert-based-clinical-ner-models">New BERT-Based Clinical NER Models</h4>

<p>Here are the MedicalBertForTokenClassifier Models we have in the library at the moment:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_ade</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_anatomy</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_bionlp</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_cellular</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_chemprot</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_chemicals</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_jsl_slim</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_jsl</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_deid</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_drugs</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_bacteria</code></li>
</ul>

<p>In addition, we are releasing a new BERT-Based clinical NER model named <code class="language-plaintext highlighter-rouge">bert_token_classifier_drug_development_trials</code>. It is a <code class="language-plaintext highlighter-rouge">MedicalBertForTokenClassification</code> NER model to identify concepts related to drug development including <code class="language-plaintext highlighter-rouge">Trial Groups</code> , <code class="language-plaintext highlighter-rouge">End Points</code> , <code class="language-plaintext highlighter-rouge">Hazard Ratio</code>, and other entities in free text. It can detect the following entities: <code class="language-plaintext highlighter-rouge">Patient_Count</code>, <code class="language-plaintext highlighter-rouge">Duration</code>, <code class="language-plaintext highlighter-rouge">End_Point</code>, <code class="language-plaintext highlighter-rouge">Value</code>, <code class="language-plaintext highlighter-rouge">Trial_Group</code>, <code class="language-plaintext highlighter-rouge">Hazard_Ratio</code>, <code class="language-plaintext highlighter-rouge">Total_Patients</code></p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
<span class="nv">tokenClassifier</span><span class="o">=</span> MedicalBertForTokenClassifier.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_drug_development_trials"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
  .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"In June 2003, the median overall survival with and without topotecan were 4.0 and 3.6 months, respectively. The best complete response ( CR ) , partial response ( PR ) , stable disease and progressive disease were observed in 23, 63, 55 and 33 patients, respectively, with topotecan, and 11, 61, 66 and 32 patients, respectively, without topotecan."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>

</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk             | entity        |
|---:|:------------------|:--------------|
|  0 | median            | Duration      |
|  1 | overall survival  | End_Point     |
|  2 | with              | Trial_Group   |
|  3 | without topotecan | Trial_Group   |
|  4 | 4.0               | Value         |
|  5 | 3.6 months        | Value         |
|  6 | 23                | Patient_Count |
|  7 | 63                | Patient_Count |
|  8 | 55                | Patient_Count |
|  9 | 33 patients       | Patient_Count |
| 10 | topotecan         | Trial_Group   |
| 11 | 11                | Patient_Count |
| 12 | 61                | Patient_Count |
| 13 | 66                | Patient_Count |
| 14 | 32 patients       | Patient_Count |
| 15 | without topotecan | Trial_Group   |
</code></pre></div></div>

<h4 id="new-clinical-relation-extraction-models">New Clinical Relation Extraction Models</h4>

<p>We have two new clinical Relation Extraction models for detecting interactions between drugs and proteins. These models work hand-in-hand with the new <code class="language-plaintext highlighter-rouge">ner_drugprot_clinical</code> NER model and detect following relations between entities: <code class="language-plaintext highlighter-rouge">INHIBITOR</code>, <code class="language-plaintext highlighter-rouge">DIRECT-REGULATOR</code>, <code class="language-plaintext highlighter-rouge">SUBSTRATE</code>, <code class="language-plaintext highlighter-rouge">ACTIVATOR</code>, <code class="language-plaintext highlighter-rouge">INDIRECT-UPREGULATOR</code>, <code class="language-plaintext highlighter-rouge">INDIRECT-DOWNREGULATOR</code>, <code class="language-plaintext highlighter-rouge">ANTAGONIST</code>, <code class="language-plaintext highlighter-rouge">PRODUCT-OF</code>, <code class="language-plaintext highlighter-rouge">PART-OF</code>, <code class="language-plaintext highlighter-rouge">AGONIST</code>.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">redl_drugprot_biobert</code> : This model was trained using BERT and performs with higher accuracy.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">re_drugprot_clinical</code> : This model was trained using <code class="language-plaintext highlighter-rouge">RelationExtractionApproach()</code>.</p>
  </li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
drugprot_ner_tagger <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_drugprot_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"sentences"</span>, <span class="s2">"tokens"</span>, <span class="s2">"embeddings"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_tags"</span><span class="o">)</span>   
...

drugprot_re_biobert <span class="o">=</span> RelationExtractionDLModel<span class="o">()</span><span class="se">\</span>
    .pretrained<span class="o">(</span><span class="s1">'redl_drugprot_biobert'</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setPredictionThreshold<span class="o">(</span>0.9<span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"re_ner_chunks"</span>, <span class="s2">"sentences"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"relations"</span><span class="o">)</span>

drugprot_re_clinical <span class="o">=</span> RelationExtractionModel<span class="o">()</span><span class="se">\</span>
    .pretrained<span class="o">(</span><span class="s2">"re_drugprot_clinical"</span>, <span class="s2">"en"</span>, <span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"embeddings"</span>, <span class="s2">"pos_tags"</span>, <span class="s2">"ner_chunks"</span>, <span class="s2">"dependencies"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"relations"</span><span class="o">)</span><span class="se">\</span>
    .setMaxSyntacticDistance<span class="o">(</span>4<span class="o">)</span><span class="se">\</span>
    .setPredictionThreshold<span class="o">(</span>0.9<span class="o">)</span><span class="se">\</span>
    .setRelationPairs<span class="o">([</span><span class="s1">'CHEMICAL-GENE'</span><span class="o">])</span>
...

sample_text <span class="o">=</span> <span class="s2">"Lipid specific activation of the murine P4-ATPase Atp8a1 (ATPase II). The asymmetric transbilayer distribution of phosphatidylserine (PS) in the mammalian plasma membrane and secretory vesicles is maintained, in part, by an ATP-dependent transporter. This aminophospholipid "</span>flippase<span class="s2">" selectively transports PS to the cytosolic leaflet of the bilayer and is sensitive to vanadate, Ca(2+), and modification by sulfhydryl reagents. Although the flippase has not been positively identified, a subfamily of P-type ATPases has been proposed to function as transporters of amphipaths, including PS and other phospholipids. A candidate PS flippase ATP8A1 (ATPase II), originally isolated from bovine secretory vesicles, is a member of this subfamily based on sequence homology to the founding member of the subfamily, the yeast protein Drs2, which has been linked to ribosomal assembly, the formation of Golgi-coated vesicles, and the maintenance of PS asymmetry."</span>
result <span class="o">=</span> re_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------+--------+-------------+-----------+--------------------+-------+-------------+-----------+--------------------+----------+
| relation| entity1|entity1_begin|entity1_end|              chunk1|entity2|entity2_begin|entity2_end|              chunk2|confidence|
+---------+--------+-------------+-----------+--------------------+-------+-------------+-----------+--------------------+----------+
|SUBSTRATE|CHEMICAL|          308|        310|                  PS|   GENE|          275|        283|            flippase|  0.998399|
|ACTIVATOR|CHEMICAL|         1563|       1578|     sn-1,2-glycerol|   GENE|         1479|       1509|plasma membrane P...|  0.999304|
|ACTIVATOR|CHEMICAL|         1563|       1578|     sn-1,2-glycerol|   GENE|         1511|       1517|              Atp8a1|  0.979057|
+---------+--------+-------------+-----------+--------------------+-------+-------------+-----------+--------------------+----------+
</code></pre></div></div>

<h4 id="new-loinc-snomed-umls-and-clinical-abbreviation-entity-resolver-models">New LOINC, SNOMED, UMLS and Clinical Abbreviation Entity Resolver Models</h4>

<p>We have five new Sentence Entity Resolver models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_clinical_abbreviation_acronym</code> : This model maps clinical abbreviations and acronyms to their meanings using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings. It is a part of ongoing research we have been running in-house, and trained with a limited dataset. We’ll be updating &amp; enriching the model in the upcoming releases.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
abbr_resolver <span class="o">=</span> SentenceEntityResolverModel.pretraind<span class="o">(</span><span class="s2">"sbiobertresolve_clinical_abbreviation_acronym"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"merged_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"abbr_meaning"</span><span class="o">)</span><span class="se">\</span>
  .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

sample_text <span class="o">=</span> <span class="s2">"HISTORY OF PRESENT ILLNESS: The patient three weeks ago was seen at another clinic for upper respiratory infection-type symptoms. She was diagnosed with a viral infection and had used OTC medications including Tylenol, Sudafed, and Nyquil."</span>
results <span class="o">=</span> abb_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s1">'text'</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|   sent_id | ner_chunk   | entity   | abbr_meaning     | all_k_results                                                                      | all_k_resolutions          |
|----------:|:------------|:---------|:-----------------|:-----------------------------------------------------------------------------------|:---------------------------|
|         0 | OTC         | ABBR     | over the counter | <span class="o">[</span><span class="s1">'over the counter'</span>, <span class="s1">'ornithine transcarbamoylase'</span>, <span class="s1">'enteric-coated'</span>, <span class="s1">'thyroxine'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'OTC'</span>, <span class="s1">'OTC'</span>, <span class="s1">'EC'</span>, <span class="s1">'T4'</span><span class="o">]</span> |

</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_drug_substance</code> : This model maps clinical entities to UMLS CUI codes. It is trained on <code class="language-plaintext highlighter-rouge">2021AB</code> UMLS dataset. The complete dataset has 127 different categories, and this model is trained on the <code class="language-plaintext highlighter-rouge">Clinical Drug</code>, <code class="language-plaintext highlighter-rouge">Pharmacologic Substance</code>, <code class="language-plaintext highlighter-rouge">Antibiotic</code>, <code class="language-plaintext highlighter-rouge">Hazardous or Poisonous Substance</code> categories using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> embeddings.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
umls_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_umls_drug_substance"</span>,<span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"resolution"</span><span class="o">)</span><span class="se">\</span>
  .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

results <span class="o">=</span> model.fullAnnotate<span class="o">([</span><span class="s1">'Dilaudid'</span>, <span class="s1">'Hydromorphone'</span>, <span class="s1">'Exalgo'</span>, <span class="s1">'Palladone'</span>, <span class="s1">'Hydrogen peroxide 30 mg'</span>, <span class="s1">'Neosporin Cream'</span>, <span class="s1">'Magnesium hydroxide 100mg/1ml'</span>, <span class="s1">'Metformin 1000 mg'</span><span class="o">])</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                         | code     | code_description           | all_k_code_desc                                              | all_k_codes                                                                                                                                                                             |
|---:|:------------------------------|:---------|:---------------------------|:-------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | Dilaudid                      | C0728755 | dilaudid                   | <span class="o">[</span><span class="s1">'C0728755'</span>, <span class="s1">'C0719907'</span>, <span class="s1">'C1448344'</span>, <span class="s1">'C0305924'</span>, <span class="s1">'C1569295'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'dilaudid'</span>, <span class="s1">'Dilaudid HP'</span>, <span class="s1">'Disthelm'</span>, <span class="s1">'Dilaudid Injection'</span>, <span class="s1">'Distaph'</span><span class="o">]</span>                                                                                                                |
|  1 | Hydromorphone                 | C0012306 | HYDROMORPHONE              | <span class="o">[</span><span class="s1">'C0012306'</span>, <span class="s1">'C0700533'</span>, <span class="s1">'C1646274'</span>, <span class="s1">'C1170495'</span>, <span class="s1">'C0498841'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'HYDROMORPHONE'</span>, <span class="s1">'Hydromorphone HCl'</span>, <span class="s1">'Phl-HYDROmorphone'</span>, <span class="s1">'PMS HYDROmorphone'</span>, <span class="s1">'Hydromorphone injection'</span><span class="o">]</span>                                                                             |
|  2 | Exalgo                        | C2746500 | Exalgo                     | <span class="o">[</span><span class="s1">'C2746500'</span>, <span class="s1">'C0604734'</span>, <span class="s1">'C1707065'</span>, <span class="s1">'C0070591'</span>, <span class="s1">'C3660437'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'Exalgo'</span>, <span class="s1">'exaltolide'</span>, <span class="s1">'Exelgyn'</span>, <span class="s1">'Extacol'</span>, <span class="s1">'exserohilone'</span><span class="o">]</span>                                                                                                                          |
|  3 | Palladone                     | C0730726 | palladone                  | <span class="o">[</span><span class="s1">'C0730726'</span>, <span class="s1">'C0594402'</span>, <span class="s1">'C1655349'</span>, <span class="s1">'C0069952'</span>, <span class="s1">'C2742475'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'palladone'</span>, <span class="s1">'Palladone-SR'</span>, <span class="s1">'Palladone IR'</span>, <span class="s1">'palladiazo'</span>, <span class="s1">'palladia'</span><span class="o">]</span>                                                                                                                 |
|  4 | Hydrogen peroxide 30 mg       | C1126248 | hydrogen peroxide 30 MG/ML | <span class="o">[</span><span class="s1">'C1126248'</span>, <span class="s1">'C0304655'</span>, <span class="s1">'C1605252'</span>, <span class="s1">'C0304656'</span>, <span class="s1">'C1154260'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'hydrogen peroxide 30 MG/ML'</span>, <span class="s1">'Hydrogen peroxide solution 30%'</span>, <span class="s1">'hydrogen peroxide 30 MG/ML [Proxacol]'</span>, <span class="s1">'Hydrogen peroxide 30 mg/mL cutaneous solution'</span>, <span class="s1">'benzoyl peroxide 30 MG/ML'</span><span class="o">]</span> |
|  5 | Neosporin Cream               | C0132149 | Neosporin Cream            | <span class="o">[</span><span class="s1">'C0132149'</span>, <span class="s1">'C0306959'</span>, <span class="s1">'C4722788'</span>, <span class="s1">'C0704071'</span>, <span class="s1">'C0698988'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'Neosporin Cream'</span>, <span class="s1">'Neosporin Ointment'</span>, <span class="s1">'Neomycin Sulfate Cream'</span>, <span class="s1">'Neosporin Topical Ointment'</span>, <span class="s1">'Naseptin cream'</span><span class="o">]</span>                                                                     |
|  6 | Magnesium hydroxide 100mg/1ml | C1134402 | magnesium hydroxide 100 MG | <span class="o">[</span><span class="s1">'C1134402'</span>, <span class="s1">'C1126785'</span>, <span class="s1">'C4317023'</span>, <span class="s1">'C4051486'</span>, <span class="s1">'C4047137'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'magnesium hydroxide 100 MG'</span>, <span class="s1">'magnesium hydroxide 100 MG/ML'</span>, <span class="s1">'Magnesium sulphate 100mg/mL injection'</span>, <span class="s1">'magnesium sulfate 100 MG'</span>, <span class="s1">'magnesium sulfate 100 MG/ML'</span><span class="o">]</span>                     |
|  7 | Metformin 1000 mg             | C0987664 | metformin 1000 MG          | <span class="o">[</span><span class="s1">'C0987664'</span>, <span class="s1">'C2719784'</span>, <span class="s1">'C0978482'</span>, <span class="s1">'C2719786'</span>, <span class="s1">'C4282269'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'metformin 1000 MG'</span>, <span class="s1">'metFORMIN hydrochloride 1000 MG'</span>, <span class="s1">'METFORMIN HCL 1000MG TAB'</span>, <span class="s1">'metFORMIN hydrochloride 1000 MG [Fortamet]'</span>, <span class="s1">'METFORMIN HCL 1000MG SA TAB'</span><span class="o">]</span>                       |

</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_loinc_cased</code> : This model maps extracted clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings. It is trained with augmented <strong>cased</strong> concept names since sbiobert model is cased.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
loinc_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_loinc_cased"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"resolution"</span><span class="o">)</span><span class="se">\</span>
  .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

<span class="nv">sample_text</span><span class="o">=</span> <span class="s2">"""The patient is a 22-year-old female with a history of obesity. She has a BMI of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hemoglobin is 8.2%."""</span>
result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]], <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------------+------+-----------+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                            ner_chunk|entity| resolution|                                           all_codes|                                                                                                                                                                                             resolutions|
+-------------------------------------+------+-----------+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                  BMI|  Test|  LP35925-4|[LP35925-4, 59574-4, BDYCRC, 73964-9, 59574-4,...   |[Body mass index <span class="o">(</span>BMI<span class="o">)</span>, Body mass index, Body circumference, Body muscle mass, Body mass index <span class="o">(</span>BMI<span class="o">)</span> <span class="o">[</span>Percentile], ...                                                                                  |
|           aspartate aminotransferase|  Test|    14409-7|[14409-7, 1916-6, 16325-3, 16324-6, 43822-6, 308... |[Aspartate aminotransferase, Aspartate aminotransferase/Alanine aminotransferase, Alanine aminotransferase/Aspartate aminotransferase, Alanine aminotransferase, Aspartate aminotransferase <span class="o">[</span>Prese...   |
|             alanine aminotransferase|  Test|    16324-6|[16324-6, 16325-3, 14409-7, 1916-6, 59245-1, 30...  |[Alanine aminotransferase, Alanine aminotransferase/Aspartate aminotransferase, Aspartate aminotransferase, Aspartate aminotransferase/Alanine aminotransferase, Alanine glyoxylate aminotransfer,...   |
|                           hemoglobin|  Test|    14775-1|[14775-1, 16931-8, 12710-0, 29220-1, 15082-1, 72... |[Hemoglobin, Hematocrit/Hemoglobin, Hemoglobin pattern, Haptoglobin, Methemoglobin, Oxyhemoglobin, Hemoglobin <span class="nb">test </span>status, Verdohemoglobin, Hemoglobin A, Hemoglobin distribution width, Myoglobin,...  |
+-------------------------------------+------+-----------+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbluebertresolve_loinc_uncased</code> : This model maps extracted clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbluebert_base_uncased_mli</code> Sentence Bert Embeddings. It trained on the augmented version of the <strong>uncased (lowercased)</strong> dataset which is used in previous LOINC resolver models.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
loinc_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbluebertresolve_loinc_uncased"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"jsl_ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"resolution"</span><span class="o">)</span><span class="se">\</span>
  .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

<span class="nv">sample_text</span><span class="o">=</span> <span class="s2">"""The patient is a 22-year-old female with a history of obesity. She has a BMI of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hgba1c is 8.2%."""</span>
result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]], <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>
<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------------+------+-----------+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                            ner_chunk|entity| resolution|                                           all_codes|                                                                                                                                                                                             resolutions|
+-------------------------------------+------+-----------+----------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                                  BMI|  Test|    39156-5|[39156-5, LP35925-4, BDYCRC, 73964-9, 59574-4,...]  |[Body mass index, Body mass index <span class="o">(</span>BMI<span class="o">)</span>, Body circumference, Body muscle mass, Body mass index <span class="o">(</span>BMI<span class="o">)</span> <span class="o">[</span>Percentile], ...]                                                                                 |
|           aspartate aminotransferase|  Test|    14409-7|[<span class="s1">'14409-7'</span>, <span class="s1">'16325-3'</span>, <span class="s1">'1916-6'</span>, <span class="s1">'16324-6'</span>,...]     |[<span class="s1">'Aspartate aminotransferase'</span>, <span class="s1">'Alanine aminotransferase/Aspartate aminotransferase'</span>, <span class="s1">'Aspartate aminotransferase/Alanine aminotransferase'</span>, <span class="s1">'Alanine aminotransferase'</span>, ...]                           |
|             alanine aminotransferase|  Test|    16324-6|[<span class="s1">'16324-6'</span>, <span class="s1">'1916-6'</span>, <span class="s1">'16325-3'</span>, <span class="s1">'59245-1'</span>,...]     |[<span class="s1">'Alanine aminotransferase'</span>, <span class="s1">'Aspartate aminotransferase/Alanine aminotransferase'</span>, <span class="s1">'Alanine aminotransferase/Aspartate aminotransferase'</span>, <span class="s1">'Alanine glyoxylate aminotransferase'</span>,...]                   |
|                               hgba1c|  Test|    41995-2|[<span class="s1">'41995-2'</span>, <span class="s1">'LP35944-5'</span>, <span class="s1">'LP19717-5'</span>, <span class="s1">'43150-2'</span>,...]|[<span class="s1">'Hemoglobin A1c'</span>, <span class="s1">'HbA1c measurement device'</span>, <span class="s1">'HBA1 gene'</span>, <span class="s1">'HbA1c measurement device panel'</span>, ...]                                                                                                      |
+-------------------------------------+------+-----------+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_snomed_drug</code> : This model maps detected drug entities to SNOMED codes using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
snomed_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_snomed_drug"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"snomed_code"</span><span class="o">)</span><span class="se">\</span>
    .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

sample_text <span class="o">=</span> <span class="s2">"She is given Fragmin 5000 units subcutaneously daily, OxyContin 30 mg p.o. q.12 h., folic acid 1 mg daily, levothyroxine 0.1 mg p.o. daily, Avandia 4 mg daily, aspirin 81 mg daily, Neurontin 400 mg p.o. t.i.d., magnesium citrate 1 bottle p.o. p.r.n., sliding scale coverage insulin."</span>
results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s1">'text'</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------+------+-----------------+-----------------+------------------------------------------------------------+------------------------------------------------------------+
|        ner_chunk|entity|      snomed_code|    resolved_text|                                               all_k_results|                                           all_k_resolutions|
+-----------------+------+-----------------+-----------------+------------------------------------------------------------+------------------------------------------------------------+
|          Fragmin|  DRUG| 9487801000001106|          Fragmin|9487801000001106:::130752006:::28999000:::953500100000110...|Fragmin:::Fragilysin:::Fusarin:::Femulen:::Fumonisin:::Fr...|
|        OxyContin|  DRUG| 9296001000001100|        OxyCONTIN|9296001000001100:::373470001:::230091000001108:::55452001...|OxyCONTIN:::Oxychlorosene:::Oxyargin:::oxyCODONE:::Oxymor...|
|       folic acid|  DRUG|         63718003|       Folic acid|63718003:::6247001:::226316008:::432165000:::438451000124...|Folic acid:::Folic acid-containing product:::Folic acid s...|
|    levothyroxine|  DRUG|10071011000001106|    Levothyroxine|10071011000001106:::710809001:::768532006:::126202002:::7...|Levothyroxine:::Levothyroxine <span class="o">(</span>substance<span class="o">)</span>:::Levothyroxine...|
|          Avandia|  DRUG| 9217601000001109|          avandia|9217601000001109:::9217501000001105:::12226401000001108::...|avandia:::avandamet:::Anatera:::Intanza:::Avamys:::Aragam...|
|          aspirin|  DRUG|        387458008|          Aspirin|387458008:::7947003:::5145711000001107:::426365001:::4125...|Aspirin:::Aspirin-containing product:::Aspirin powder:::A...|
|        Neurontin|  DRUG| 9461401000001102|        neurontin|9461401000001102:::130694004:::86822004:::952840100000110...|neurontin:::Neurolysin:::Neurine <span class="o">(</span>substance<span class="o">)</span>:::Nebilet:::...|
|magnesium citrate|  DRUG|         12495006|Magnesium citrate|12495006:::387401007:::21691008:::15531411000001106:::408...|Magnesium citrate:::Magnesium carbonate:::Magnesium trisi...|
|          insulin|  DRUG|         67866001|          Insulin|67866001:::325072002:::414515005:::39487003:::411530000::...|Insulin:::Insulin aspart:::Insulin detemir:::Insulin-cont...|
+-----------------+------+-----------------+-----------------+------------------------------------------------------------+------------------------------------------------------------+

</code></pre></div></div>

<h4 id="new-icd10-to-icd9-code-mapping-pretrained-pipeline">New ICD10 to ICD9 Code Mapping Pretrained Pipeline</h4>

<p>We are releasing new <code class="language-plaintext highlighter-rouge">icd10_icd9_mapping</code> pretrained pipeline. This pretrained pipeline maps ICD10 codes to ICD9 codes without using any text data. You’ll just feed a comma or white space-delimited ICD10 codes and it will return the corresponding ICD9 codes as a list.</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"icd10_icd9_mapping"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>
pipeline.annotate<span class="o">(</span><span class="s1">'E669 R630 J988'</span><span class="o">)</span>
</code></pre></div></div>
<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span><span class="s1">'document'</span>: <span class="o">[</span><span class="s1">'E669 R630 J988'</span><span class="o">]</span>,
<span class="s1">'icd10'</span>: <span class="o">[</span><span class="s1">'E669'</span>, <span class="s1">'R630'</span>, <span class="s1">'J988'</span><span class="o">]</span>,
<span class="s1">'icd9'</span>: <span class="o">[</span><span class="s1">'27800'</span>, <span class="s1">'7830'</span>, <span class="s1">'5198'</span><span class="o">]}</span>

Code Descriptions:

|    | ICD10                | Details                               |
|---:|:---------------------|:--------------------------------------|
|  0 | E669                 | Obesity                               |
|  1 | R630                 | Anorexia                              |
|  2 | J988                 | Other specified respiratory disorders |

|    | ICD9                 | Details                               |
|---:|:---------------------|:--------------------------------------|
|  0 | 27800                | Obesity                               |
|  1 | 7830                 | Anorexia                              |
|  2 | 5198                 | Other diseases of respiratory system  |

</code></pre></div></div>

<h4 id="new-clinical-sentence-embedding-models">New Clinical Sentence Embedding Models</h4>

<p>We have two new clinical Sentence Embedding models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobert_jsl_rxnorm_cased</code> : This model maps sentences &amp; documents to a 768 dimensional dense vector space by using average pooling on top of BioBert model. It’s also fine-tuned on RxNorm dataset to help generalization over medication-related datasets.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
sentence_embeddings <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s2">"sbiobert_jsl_rxnorm_cased"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"sbioert_embeddings"</span><span class="o">)</span>
...
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_medium_rxnorm_uncased</code> : This model maps sentences &amp; documents to a 512-dimensional dense vector space by using average pooling on top of BERT model. It’s also fine-tuned on the RxNorm dataset to help generalization over medication-related datasets.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
sentence_embeddings <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s2">"sbert_jsl_medium_rxnorm_uncased"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>
...
</code></pre></div></div>

<h4 id="printingvalidation-and-testlogs-in-medicalnerapproach-and-assertiondlapproach">Printing Validation and Test Logs in MedicalNerApproach and AssertionDLApproach</h4>

<p>Now we can check validation loss and test loss for each epoch in the logs created during trainings of MedicalNerApproach and AssertionDLApproach.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 15/15 started, lr: 9.345794E-4, dataset size: 1330


Epoch 15/15 - 56.65s - loss: 37.58828 - avg training loss: 1.7899181 - batches: 21
Quality on validation dataset <span class="o">(</span>20.0%<span class="o">)</span>, validation examples <span class="o">=</span> 266
<span class="nb">time </span>to finish evaluation: 8.11s
Total validation loss: 15.1930	Avg validation loss: 2.5322
label	 tp	 fp	 fn	 prec	 rec	 f1
I-Disease	 707	 72	 121	 0.9075738	 0.8538647	 0.8799004
B-Disease	 657	 81	 60	 0.8902439	 0.916318	 0.90309274
tp: 1364 fp: 153 fn: 181 labels: 2
Macro-average	 prec: 0.89890885, rec: 0.88509136, f1: 0.8919466
Micro-average	 prec: 0.89914304, rec: 0.8828479, f1: 0.89092094
Quality on <span class="nb">test </span>dataset:
<span class="nb">time </span>to finish evaluation: 9.11s
Total <span class="nb">test </span>loss: 17.7705	Avg <span class="nb">test </span>loss: 1.6155
label	 tp	 fp	 fn	 prec	 rec	 f1
I-Disease	 663	 113	 126	 0.85438144	 0.8403042	 0.8472843
B-Disease	 631	 122	 77	 0.8379814	 0.8912429	 0.86379194
tp: 1294 fp: 235 fn: 203 labels: 2
Macro-average	 prec: 0.8461814, rec: 0.86577356, f1: 0.85586536
Micro-average	 prec: 0.8463048, rec: 0.86439544, f1: 0.8552544
</code></pre></div></div>

<h4 id="filter-only-the-regex-entities-feature-in-deidentification-annotator">Filter Only the Regex Entities Feature in Deidentification Annotator</h4>

<p>The <code class="language-plaintext highlighter-rouge">setBlackList()</code> method will be able to filter just the detected Regex Entities. Before this change we filtered the chunks and the regex entities.</p>

<h4 id="add-setmaskingpolicy-parameter-in-deidentification-annotator">Add <code class="language-plaintext highlighter-rouge">.setMaskingPolicy</code> Parameter in Deidentification Annotator</h4>

<p>Now we can have three modes to mask the entities in the Deidentification annotator.
You can select the modes using the <code class="language-plaintext highlighter-rouge">.setMaskingPolicy("entity_labels")</code>.</p>

<p>The methods are the followings:</p>
<ol>
  <li>“entity_labels”: Mask with the entity type of that chunk. (default)</li>
  <li>“same_length_chars”: Mask the deid entities with same length of asterix (<code class="language-plaintext highlighter-rouge">*</code>) with brackets (<code class="language-plaintext highlighter-rouge">[</code>,<code class="language-plaintext highlighter-rouge">]</code>) on both end.</li>
  <li>“fixed_length_chars”: Mask the deid entities with a fixed length of asterix (<code class="language-plaintext highlighter-rouge">*</code>). The length is setting up using the <code class="language-plaintext highlighter-rouge">setFixedMaskLength(4)</code> method.</li>
</ol>

<p>Given the following sentence <code class="language-plaintext highlighter-rouge">John Snow is a good guy.</code> the result will be:</p>

<ol>
  <li>“entity_labels”: <code class="language-plaintext highlighter-rouge">&lt;NAME&gt; is a good guy.</code></li>
  <li>“same_length_chars”: <code class="language-plaintext highlighter-rouge">[*******] is a good guy.</code></li>
  <li>“fixed_length_chars”: <code class="language-plaintext highlighter-rouge">**** is a good guy.</code></li>
</ol>

<p><em>Example</em></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Masked with entity labels
<span class="nt">------------------------------</span>
DATE &lt;DATE&gt;, &lt;DOCTOR&gt;,  The driver<span class="s1">'s license &lt;DLN&gt;.

Masked with chars
------------------------------
DATE [**********], [***********],  The driver'</span>s license <span class="o">[</span><span class="k">*********</span><span class="o">]</span><span class="nb">.</span>

Masked with fixed length chars
<span class="nt">------------------------------</span>
DATE <span class="k">****</span>, <span class="k">****</span>,  The driver<span class="s1">'s license ****.

Obfuscated
------------------------------
DATE 07-04-1981, Dr Vivian Irving,  The driver'</span>s license K272344712994.
</code></pre></div></div>

<h4 id="add-cache_folder-parameter-in-updatemodelsupdatecachemodels">Add <code class="language-plaintext highlighter-rouge">.cache_folder</code> Parameter in <code class="language-plaintext highlighter-rouge">UpdateModels.updateCacheModels()</code></h4>

<p>This parameter lets user to define custom local paths for the folder on which pretrained models are saved (rather than using default cached_pretrained folder).</p>

<p>This cache_folder must be a path (“hdfs:..”,”file:…”).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>UpdateModels.updateCacheModels<span class="o">(</span><span class="s2">"file:/home/jsl/cache_pretrained_2"</span><span class="o">)</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>UpdateModels.updateModels<span class="o">(</span><span class="s2">"12/01/2021"</span>,<span class="s2">"file:/home/jsl/cache_pretrained_2"</span><span class="o">)</span>
</code></pre></div></div>

<p>The cache folder used by default is the folder loaded in the spark configuration ` spark.jsl.settings.pretrained.cache_folder<code class="language-plaintext highlighter-rouge">.The default value for that property is </code>~/cache_pretrained`</p>

<h4 id="s3-access-credentials-no-longer-shipped-along-licenses">S3 Access Credentials No Longer Shipped Along Licenses</h4>

<p>S3 access credentials are no longer being shipped with licenses. Going forward, we’ll use temporal S3 access credentials which will be periodically refreshed. All this will happen automatically and will be transparent to the user.
Still, for those users who would need to perform manual tasks involving access to S3, there’s a mechanism to get access to the set of credentials being used by the library at any given time.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl import get_credentials
get_credentials<span class="o">(</span>spark<span class="o">)</span>
</code></pre></div></div>

<h4 id="enhanced-security-for-the-library-and-log4shell-update">Enhanced Security for the Library and log4shell Update</h4>

<p>On top of periodical security checks on the library code, 3rd party dependencies were analyzed, and some dependencies reported as containing vulnerabilities were replaced by more secure options.
Also, the library was analyzed in the context of the recently discovered threat(CVE-2021-45105) on the log4j library. Spark NLP for Healthcare does not depend on the log4j library by itself, but the library gets loaded through some of its dependencies.
It’s worth noting that the version of log4j dependency that will be in the classpath when running Spark NLP for Healthcare is 1.x, which would make the system vulnerable to CVE-2021-4104, instead of CVE-2021-45105. CVE-2021-4104 is related to the JMSAppender.
Spark NLP for Healthcare does not provide any log4j configuration, so it’s up to the user to follow the recommendation of avoiding the use of the JMSAppender.</p>

<h4 id="new-peer-reviewed-conference-paper-on-clinical-relation-extraction">New Peer-Reviewed Conference Paper on Clinical Relation Extraction</h4>

<p>We publish a new peer-reviewed conference paper titled <a href="https://arxiv.org/pdf/2112.13259.pdf">Deeper Clinical Document Understanding Using Relation Extraction</a> explaining the applications of Relation Extraction in a text mining framework comprising of Named Entity Recognition (NER) and Relation Extraction (RE) models. The paper is accepted to SDU (Scientific Document Understanding) workshop at AAAI-2022 conference and claims new SOTA scores on 5 out of 7 Biomedical &amp; Clinical Relation Extraction (RE) tasks.</p>

<table>
  <thead>
    <tr>
      <th>Dataset</th>
      <th>FCNN</th>
      <th>BioBERT</th>
      <th>Curr-SOTA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>i2b2-Temporal</td>
      <td>68.7</td>
      <td><strong>73.6</strong></td>
      <td>72.41</td>
    </tr>
    <tr>
      <td>i2b2-Clinical</td>
      <td>60.4</td>
      <td><strong>69.1</strong></td>
      <td>67.97</td>
    </tr>
    <tr>
      <td>DDI</td>
      <td>69.2</td>
      <td>72.1</td>
      <td><strong>84.1</strong></td>
    </tr>
    <tr>
      <td>CPI</td>
      <td>65.8</td>
      <td>74.3</td>
      <td><strong>88.9</strong></td>
    </tr>
    <tr>
      <td>PGR</td>
      <td>81.2</td>
      <td><strong>87.9</strong></td>
      <td>79.4</td>
    </tr>
    <tr>
      <td>ADE Corpus</td>
      <td>89.2</td>
      <td><strong>90.0</strong></td>
      <td>83.7</td>
    </tr>
    <tr>
      <td>Posology</td>
      <td>87.8</td>
      <td><strong>96.7</strong></td>
      <td>96.1</td>
    </tr>
  </tbody>
</table>

<p><em>Macro-averaged F1 scores of both RE models on public datasets. FCNN refers to the Speed-Optimized FCNN architecture, while BioBERT refers to the AccuracyOptimized BioBERT architecture. The SOTA metrics are obtained from (Guan et al. 2020), (Ningthoujam et al. 2019), (Asada, Miwa, and Sasaki 2020), (Phan et al. 2021), (Sousa
and Couto 2020), (Crone 2020), and (Yang et al. 2021) respectively.</em></p>

<h4 id="new-peer-reviewed-conference-paper-on-adverse-drug-events-extraction">New Peer-Reviewed Conference Paper on Adverse Drug Events Extraction</h4>

<p>We publish a new peer-reviewed conference paper titled <a href="https://arxiv.org/pdf/2201.01405.pdf">Mining Adverse Drug Reactions from Unstructured Mediums at Scale</a> proposing an end-to-end Adverse Drug Event mining solution using Classification, NER, and Relation Extraction Models. The paper is accepted to W3PHIAI (INTERNATIONAL WORKSHOP ON HEALTH INTELLIGENCE) workshop at AAAI-2022 conference, and claims new SOTA scores on 1 benchmark dataset for Classification, 3 benchmark datasets for NER, and 1 benchmark dataset for Relation Extraction.</p>

<table>
  <thead>
    <tr>
      <th>Task</th>
      <th>Dataset</th>
      <th>Spark NLP</th>
      <th>Curr-SOTA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Classification</td>
      <td>ADE</td>
      <td>85.96</td>
      <td><strong>87.0</strong></td>
    </tr>
    <tr>
      <td>Classification</td>
      <td>CADEC</td>
      <td><strong>86.69</strong></td>
      <td>81.5</td>
    </tr>
    <tr>
      <td>Entity Recognition</td>
      <td>ADE</td>
      <td><strong>91.75</strong></td>
      <td>91.3</td>
    </tr>
    <tr>
      <td>Entity Recognition</td>
      <td>CADEC</td>
      <td><strong>78.36</strong></td>
      <td>71.9</td>
    </tr>
    <tr>
      <td>Entity Recognition</td>
      <td>SMM4H</td>
      <td><strong>76.73</strong></td>
      <td>67.81</td>
    </tr>
    <tr>
      <td>Relation Extraction</td>
      <td>ADE</td>
      <td><strong>90.0</strong></td>
      <td>83.7</td>
    </tr>
  </tbody>
</table>

<p><em>All F1 scores are Macro-averaged</em></p>

<h4 id="new-and-updated-notebooks-1">New and Updated Notebooks</h4>

<ul>
  <li>We have two new Notebooks:
    <ul>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/18.Chunk_Sentence_Splitter.ipynb">Chunk Sentence Splitter Notebook</a> that involves usage of <code class="language-plaintext highlighter-rouge">ChunkSentenceSplitter</code> annotator.</li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.3.Clinical_RE_SparkNLP_Paper_Reproduce.ipynb">Clinical Relation Extraction Spark NLP Paper Reproduce Notebook</a> that can be used for reproducing the results in  <a href="https://arxiv.org/pdf/2112.13259.pdf">Deeper Clinical Document Understanding Using Relation Extraction</a> paper.</li>
    </ul>
  </li>
  <li>We have updated our existing notebooks by adding new features and functionalities. Here are updated notebooks:
    <ul>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb">Clinical Named Entity Recognition Model</a></li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb">Clinical Entity Resolver Models</a></li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb">Clinical DeIdentification</a></li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/7.Clinical_NER_Chunk_Merger.ipynb">Clinical NER Chunk Merger</a></li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb">Pretrained Clinical Pipelines</a></li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.1.Healthcare_Code_Mapping.ipynb">Healthcare Code Mapping</a></li>
      <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb">Improved Entity Resolvers in Spark NLP with sBert</a></li>
    </ul>
  </li>
</ul>

<p><strong>To see more, please check : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></strong></p>

<h2 id="334">3.3.4</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.3.4 has been released!</p>

<h4 id="highlights-6">Highlights</h4>

<ul>
  <li>New Clinical NER Models</li>
  <li>New NER Model Finder Pretrained Pipeline</li>
  <li>New Relation Extraction Model</li>
  <li>New LOINC, MeSH, NDC and SNOMED Entity Resolver Models</li>
  <li>Updated RxNorm Sentence Entity Resolver Model</li>
  <li>New Shift Days Feature in StructuredDeid Deidentification Module</li>
  <li>New Multiple Chunks Merge Ability in ChunkMergeApproach</li>
  <li>New setBlackList Feature in ChunkMergeApproach</li>
  <li>New setBlackList Feature in NerConverterInternal</li>
  <li>New setLabelCasing Feature in MedicalNerModel</li>
  <li>New Update Models Functionality</li>
  <li>New and Updated Notebooks</li>
</ul>

<h4 id="new-clinical-ner-models-1">New Clinical NER Models</h4>

<p>We have three new clinical NER models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented_i2b2</code> : This model annotates text to find protected health information(PHI) that may need to be removed. It is trained with 2014 i2b2 dataset (no augmentation applied) and can detect <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">HEALTHPLAN</code>, <code class="language-plaintext highlighter-rouge">URL</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">LOCATION-OTHER</code>, <code class="language-plaintext highlighter-rouge">STATE</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">DEVICE</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">EMAIL</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">SREET</code>, <code class="language-plaintext highlighter-rouge">BIOID</code>, <code class="language-plaintext highlighter-rouge">FAX</code>, <code class="language-plaintext highlighter-rouge">AGE</code> entities.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity_augmented_i2b2"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 years old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227. Patient's complaints first surfaced when he started working for Brothers Coal-Mine."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------+-------------+
|chunk                        |ner_label    |
+-----------------------------+-------------+
|2093-01-13                   |DATE         |
|David Hale                   |DOCTOR       |
|Hendrickson, Ora             |PATIENT      |
|7194334                      |MEDICALRECORD|
|01/13/93                     |DATE         |
|Oliveira                     |DOCTOR       |
|25                           |AGE          |
|1-11-2000                    |DATE         |
|Cocke County Baptist Hospital|HOSPITAL     |
|0295 Keats Street            |STREET       |
|<span class="o">(</span>302<span class="o">)</span> 786-5227               |PHONE        |
|Brothers Coal-Mine Corp      |ORGANIZATION |
+-----------------------------+-------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_biomarker</code> : This model is trained to extract biomarkers, therapies, oncological, and other general concepts from text. Following are the entities it can detect: <code class="language-plaintext highlighter-rouge">Oncogenes</code>, <code class="language-plaintext highlighter-rouge">Tumor_Finding</code>, <code class="language-plaintext highlighter-rouge">UnspecificTherapy</code>, <code class="language-plaintext highlighter-rouge">Ethnicity</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">ResponseToTreatment</code>, <code class="language-plaintext highlighter-rouge">Biomarker</code>, <code class="language-plaintext highlighter-rouge">HormonalTherapy</code>, <code class="language-plaintext highlighter-rouge">Staging</code>, <code class="language-plaintext highlighter-rouge">Drug</code>, <code class="language-plaintext highlighter-rouge">CancerDx</code>, <code class="language-plaintext highlighter-rouge">Radiotherapy</code>, <code class="language-plaintext highlighter-rouge">CancerSurgery</code>, <code class="language-plaintext highlighter-rouge">TargetedTherapy</code>, <code class="language-plaintext highlighter-rouge">PerformanceStatus</code>, <code class="language-plaintext highlighter-rouge">CancerModifier</code>, <code class="language-plaintext highlighter-rouge">Radiological_Test_Result</code>, <code class="language-plaintext highlighter-rouge">Biomarker_Measurement</code>, <code class="language-plaintext highlighter-rouge">Metastasis</code>, <code class="language-plaintext highlighter-rouge">Radiological_Test</code>, <code class="language-plaintext highlighter-rouge">Chemotherapy</code>, <code class="language-plaintext highlighter-rouge">Test</code>, <code class="language-plaintext highlighter-rouge">Dosage</code>, <code class="language-plaintext highlighter-rouge">Test_Result</code>, <code class="language-plaintext highlighter-rouge">Immunotherapy</code>, <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Gender</code>, <code class="language-plaintext highlighter-rouge">Prognostic_Biomarkers</code>, <code class="language-plaintext highlighter-rouge">Duration</code>, <code class="language-plaintext highlighter-rouge">Predictive_Biomarkers</code></li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_biomarker"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Here , we report the first case of an intraductal tubulopapillary neoplasm of the pancreas with clear cell morphology . Immunohistochemistry revealed positivity for Pan-CK , CK7 , CK8/18 , MUC1 , MUC6 , carbonic anhydrase IX , CD10 , EMA , β-catenin and e-cadherin ."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | ner_chunk                | entity                |   confidence |
|---:|:-------------------------|:----------------------|-------------:|
|  0 | intraductal              | CancerModifier        |     0.9934   |
|  1 | tubulopapillary          | CancerModifier        |     0.6403   |
|  2 | neoplasm of the pancreas | CancerDx              |     0.758825 |
|  3 | clear cell               | CancerModifier        |     0.9633   |
|  4 | Immunohistochemistry     | Test                  |     0.9534   |
|  5 | positivity               | Biomarker_Measurement |     0.8795   |
|  6 | Pan-CK                   | Biomarker             |     0.9975   |
|  7 | CK7                      | Biomarker             |     0.9975   |
|  8 | CK8/18                   | Biomarker             |     0.9987   |
|  9 | MUC1                     | Biomarker             |     0.9967   |
| 10 | MUC6                     | Biomarker             |     0.9972   |
| 11 | carbonic anhydrase IX    | Biomarker             |     0.937567 |
| 12 | CD10                     | Biomarker             |     0.9974   |
| 13 | EMA                      | Biomarker             |     0.9899   |
| 14 | β-catenin                | Biomarker             |     0.8059   |
| 15 | e-cadherin               | Biomarker             |     0.9806   |
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_nihss</code> : NER model that can identify entities according to NIHSS guidelines for clinical stroke assessment to evaluate neurological status in acute stroke patients. Here are the labels it can detect : <code class="language-plaintext highlighter-rouge">11_ExtinctionInattention</code>, <code class="language-plaintext highlighter-rouge">6b_RightLeg</code>, <code class="language-plaintext highlighter-rouge">1c_LOCCommands</code>, <code class="language-plaintext highlighter-rouge">10_Dysarthria</code>, <code class="language-plaintext highlighter-rouge">NIHSS</code>, <code class="language-plaintext highlighter-rouge">5_Motor</code>, <code class="language-plaintext highlighter-rouge">8_Sensory</code>, <code class="language-plaintext highlighter-rouge">4_FacialPalsy</code>, <code class="language-plaintext highlighter-rouge">6_Motor</code>, <code class="language-plaintext highlighter-rouge">2_BestGaze</code>, <code class="language-plaintext highlighter-rouge">Measurement</code>, <code class="language-plaintext highlighter-rouge">6a_LeftLeg</code>, <code class="language-plaintext highlighter-rouge">5b_RightArm</code>, <code class="language-plaintext highlighter-rouge">5a_LeftArm</code>, <code class="language-plaintext highlighter-rouge">1b_LOCQuestions</code>, <code class="language-plaintext highlighter-rouge">3_Visual</code>, <code class="language-plaintext highlighter-rouge">9_BestLanguage</code>, <code class="language-plaintext highlighter-rouge">7_LimbAtaxia</code>, <code class="language-plaintext highlighter-rouge">1a_LOC</code> .</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_nihss"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

results <span class="o">=</span> ner_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Abdomen , soft , nontender . NIH stroke scale on presentation was 23 to 24 for , one for consciousness , two for month and year and two for eye / grip , one to two for gaze , two for face , eight for motor , one for limited ataxia , one to two for sensory , three for best language and two for attention . On the neurologic examination the patient was intermittently"</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk              | entity                   |
|---:|:-------------------|:-------------------------|
|  0 | NIH stroke scale   | NIHSS                    |
|  1 | 23 to 24           | Measurement              |
|  2 | one                | Measurement              |
|  3 | consciousness      | 1a_LOC                   |
|  4 | two                | Measurement              |
|  5 | month and year and | 1b_LOCQuestions          |
|  6 | two                | Measurement              |
|  7 | eye / grip         | 1c_LOCCommands           |
|  8 | one to             | Measurement              |
|  9 | two                | Measurement              |
| 10 | gaze               | 2_BestGaze               |
| 11 | two                | Measurement              |
| 12 | face               | 4_FacialPalsy            |
| 13 | eight              | Measurement              |
| 14 | one                | Measurement              |
| 15 | limited            | 7_LimbAtaxia             |
| 16 | ataxia             | 7_LimbAtaxia             |
| 17 | one to two         | Measurement              |
| 18 | sensory            | 8_Sensory                |
| 19 | three              | Measurement              |
| 20 | best language      | 9_BestLanguage           |
| 21 | two                | Measurement              |
| 22 | attention          | 11_ExtinctionInattention |
</code></pre></div></div>

<h4 id="new-ner-model-finder-pretrained-pipeline">New NER Model Finder Pretrained Pipeline</h4>

<p>We are releasing new <code class="language-plaintext highlighter-rouge">ner_model_finder</code> pretrained pipeline trained with bert embeddings that can be used to find the most appropriate NER model given the entity name.</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
finder_pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"ner_model_finder"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>

result <span class="o">=</span> finder_pipeline.fullAnnotate<span class="o">(</span><span class="s2">"psychology"</span><span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<table>
  <thead>
    <tr>
      <th>entity</th>
      <th>top models</th>
      <th>all models</th>
      <th>resolutions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>psychology</td>
      <td>[‘ner_medmentions_coarse’, ‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical’, ‘ner_jsl_greedy’]</td>
      <td>[‘ner_medmentions_coarse’, ‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical’, ‘ner_jsl_greedy’]:::[‘jsl_rd_ner_wip_greedy_clinical’, ‘ner_jsl_enriched’, ‘ner_jsl_slim’, ‘ner_jsl’, ‘jsl_ner_wip_modifier_clinical,…</td>
      <td>psychological condition:::clinical department::: …</td>
    </tr>
  </tbody>
</table>

<h4 id="new-relation-extraction-model">New Relation Extraction Model</h4>

<p>We are releasing new <code class="language-plaintext highlighter-rouge">redl_nihss_biobert </code> relation extraction model that can relate scale items and their measurements according to NIHSS guidelines.</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
re_model <span class="o">=</span> RelationExtractionDLModel<span class="o">()</span><span class="se">\</span>
    .pretrained<span class="o">(</span><span class="s1">'redl_nihss_biobert'</span>, <span class="s1">'en'</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
    .setPredictionThreshold<span class="o">(</span>0.5<span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"re_ner_chunks"</span>, <span class="s2">"sentences"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"relations"</span><span class="o">)</span>
...

sample_text <span class="o">=</span> <span class="s2">"There , her initial NIHSS score was 4 , as recorded by the ED physicians . This included 2 for weakness in her left leg and 2 for what they felt was subtle ataxia in her left arm and leg ."</span>
result <span class="o">=</span> re_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| chunk1                                | entity1      |   entity1_begin |   entity1_end | entity2     |   chunk2 |   entity2_begin |   entity2_end | relation   |
|:--------------------------------------|:-------------|----------------:|--------------:|:------------|---------:|----------------:|--------------:|:-----------|
| initial NIHSS score                   | NIHSS        |              12 |            30 | Measurement |        4 |              36 |            36 | Has_Value  |
| left leg                              | 6a_LeftLeg   |             111 |           118 | Measurement |        2 |              89 |            89 | Has_Value  |
| subtle ataxia <span class="k">in </span>her left arm and leg | 7_LimbAtaxia |             149 |           185 | Measurement |        2 |             124 |           124 | Has_Value  |
| left leg                              | 6a_LeftLeg   |             111 |           118 | Measurement |        4 |              36 |            36 | 0          |
| initial NIHSS score                   | NIHSS        |              12 |            30 | Measurement |        2 |             124 |           124 | 0          |
| subtle ataxia <span class="k">in </span>her left arm and leg | 7_LimbAtaxia |             149 |           185 | Measurement |        4 |              36 |            36 | 0          |
| subtle ataxia <span class="k">in </span>her left arm and leg | 7_LimbAtaxia |             149 |           185 | Measurement |        2 |              89 |            89 | 0          |
</code></pre></div></div>

<h4 id="new-loinc-mesh-ndc-and-snomed-entity-resolver-models">New LOINC, MeSH, NDC and SNOMED Entity Resolver Models</h4>

<p>We have four new Sentence Entity Resolver Models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_mesh</code> : This model maps clinical entities to Medical Subject Heading (MeSH) codes using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
mesh_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_mesh"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"mesh_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span><span class="se">\</span>
      .setCaseSensitive<span class="o">(</span>False<span class="o">)</span>

...

sample_text <span class="o">=</span> <span class="s2">"""She was admitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed malignant mesothelioma."""</span>
result <span class="o">=</span> resolver_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------+---------+----------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+
|                 ner_chunk|   entity| mesh_code|                                                                                           all_codes|                                                                                         resolutions|                                                                                           distances|
+--------------------------+---------+----------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+
|                chest pain|  PROBLEM|   D002637|D002637:::D059350:::D019547:::D020069:::D015746:::D000072716:::D005157:::D059265:::D001416:::D048...|Chest Pain:::Chronic Pain:::Neck Pain:::Shoulder Pain:::Abdominal Pain:::Cancer Pain:::Facial Pai...|0.0000:::0.0577:::0.0587:::0.0601:::0.0658:::0.0704:::0.0712:::0.0741:::0.0766:::0.0778:::0.0794:...|
|bilateral pleural effusion|  PROBLEM|   D010996|D010996:::D010490:::D011654:::D016724:::D010995:::D016066:::D011001:::D007819:::D035422:::D004653...|Pleural Effusion:::Pericardial Effusion:::Pulmonary Edema:::Empyema, Pleural:::Pleural Diseases::...|0.0309:::0.1010:::0.1115:::0.1213:::0.1218:::0.1398:::0.1425:::0.1401:::0.1451:::0.1464:::0.1464:...|
|             the pathology|     TEST|   D010336|D010336:::D010335:::D001004:::D020969:::C001675:::C536472:::D004194:::D003951:::D013631:::C535329...|Pathology:::Pathologic Processes:::Anus Diseases:::Disease Attributes:::malformins:::Upington dis...|0.0788:::0.0977:::0.1364:::0.1396:::0.1419:::0.1459:::0.1418:::0.1393:::0.1514:::0.1541:::0.1491:...|
|        the pericardectomy|TREATMENT|   D010492|D010492:::D011670:::D018700:::D020884:::D011672:::D005927:::D064727:::D002431:::C000678968:::D011...|Pericardiectomy:::Pulpectomy:::Pleurodesis:::Colpotomy:::Pulpotomy:::Glossectomy:::Posterior Caps...|0.1098:::0.1448:::0.1801:::0.1852:::0.1871:::0.1923:::0.1901:::0.2023:::0.2075:::0.2010:::0.1996:...|
|              mesothelioma|  PROBLEM|D000086002|D000086002:::C535700:::D009208:::D032902:::D018301:::D018199:::C562740:::C000686536:::D018276:::D...|Mesothelioma, Malignant:::Malignant mesenchymal tumor:::Myoepithelioma:::Ganoderma:::Neoplasms, M...|0.0813:::0.1515:::0.1599:::0.1810:::0.1864:::0.1881:::0.1907:::0.1938:::0.1924:::0.1876:::0.2040:...|
|      chest tube placement|TREATMENT|   D015505|D015505:::D019616:::D013896:::D012124:::D013906:::D013510:::D020708:::D035423:::D013903:::D000066...|Chest Tubes:::Thoracic Surgical Procedures:::Thoracic Diseases:::Respiratory Care Units:::Thoraco...|0.0557:::0.1473:::0.1598:::0.1604:::0.1725:::0.1651:::0.1795:::0.1760:::0.1804:::0.1846:::0.1883:...|
|     drainage of the fluid|TREATMENT|   D004322|D004322:::D018495:::C045413:::D021061:::D045268:::D018508:::D005441:::D015633:::D014906:::D001834...|Drainage:::Fluid Shifts:::Bonain<span class="s1">'s liquid:::Liquid Ventilation:::Flowmeters:::Water Purification:...|0.1141:::0.1403:::0.1582:::0.1549:::0.1586:::0.1626:::0.1599:::0.1655:::0.1667:::0.1656:::0.1741:...|
|              thoracoscopy|TREATMENT|   D013906|D013906:::D020708:::D035423:::D013905:::D035441:::D013897:::D001468:::D000069258:::D013909:::D013...|Thoracoscopy:::Thoracoscopes:::Thoracic Cavity:::Thoracoplasty:::Thoracic Wall:::Thoracic Duct:::...|0.0000:::0.0359:::0.0744:::0.1007:::0.1070:::0.1143:::0.1186:::0.1257:::0.1228:::0.1356:::0.1354:...|
|            fluid biopsies|     TEST|D000073890|D000073890:::D010533:::D020420:::D011677:::D017817:::D001706:::D005441:::D005751:::D013582:::D000...|Liquid Biopsy:::Peritoneal Lavage:::Cyst Fluid:::Punctures:::Nasal Lavage Fluid:::Biopsy:::Fluids...|0.1408:::0.1612:::0.1763:::0.1744:::0.1744:::0.1810:::0.1744:::0.1828:::0.1896:::0.1909:::0.1950:...|
|    malignant mesothelioma|  PROBLEM|D000086002|D000086002:::C535700:::C562740:::D009236:::D007890:::D012515:::D009208:::C009823:::C000683999:::C...|Mesothelioma, Malignant:::Malignant mesenchymal tumor:::Hemangiopericytoma, Malignant:::Myxosarco...|0.0737:::0.1106:::0.1658:::0.1627:::0.1660:::0.1639:::0.1728:::0.1676:::0.1791:::0.1843:::0.1849:...|
+-------+--------------------------+---------+----------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+
</span></code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_ndc</code> : This model maps clinical entities and concepts (like drugs/ingredients) to <a href="https://www.fda.gov/drugs/drug-approvals-and-databases/national-drug-code-directory">National Drug Codes</a> using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings. Also, if a drug has more than one NDC code, it returns all available codes in the all_k_aux_label column separated by <code class="language-plaintext highlighter-rouge">|</code> symbol.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
ndc_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_ndc"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ndc_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span><span class="se">\</span>
      .setCaseSensitive<span class="o">(</span>False<span class="o">)</span>
...

sample_text <span class="o">=</span> <span class="s2">"""The patient was transferred secondary to inability and continue of her diabetes, the sacral decubitus, left foot pressure wound, and associated complications of diabetes.
She is given aspirin 81 mg, folic acid 1 g daily, insulin glargine 100 UNT/ML injection and metformin 500 mg p.o. p.r.n."""</span>
result <span class="o">=</span> resolver_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------------+------+-----------+------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                            ner_chunk|entity|   ndc_code|                                                                   description|                                                                                                                                                                                               all_codes|                                                                                                                                                                                         all_resolutions|                                                                                                                                                                                         other ndc codes|
+-------------------------------------+------+-----------+------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|                        aspirin 81 mg|  DRUG|73089008114|                               aspirin 81 mg/81mg, 81 mg <span class="k">in </span>1 carton , capsule|[73089008114, 71872708704, 71872715401, 68210101500, 69536028110, 63548086706, 71679001000, 68196090051, 00113400500, 69536018112, 73089008112, 63981056362, 63739043402, 63548086705, 00113046708, 7...|[aspirin 81 mg/81mg, 81 mg <span class="k">in </span>1 carton , capsule, aspirin 81 mg 81 mg/1, 4 blister pack <span class="k">in </span>1 bag , tablet, aspirin 81 mg/1, 1 blister pack <span class="k">in </span>1 bag , tablet, coated, aspirin 81 mg/1, 1 bag <span class="k">in </span>1 dru...|         <span class="o">[</span>-, -, -, -, -, -, -, -, -, -, -, 63940060962, -, -, -, -, -, -, -, -, 70000042002|00363021879|41250027408|36800046708|59779027408|49035027408|71476010131|81522046708|30142046708, -, -, -, -]|
|                       folic acid 1 g|  DRUG|43744015101|                                   folic acid 1 g/g, 1 g <span class="k">in </span>1 package , powder|[43744015101, 63238340000, 66326050555, 51552041802, 51552041805, 63238340001, 81919000204, 51552041804, 66326050556, 51552106301, 51927003300, 71092997701, 51927296300, 51552146602, 61281900002, 6...|[folic acid 1 g/g, 1 g <span class="k">in </span>1 package , powder, folic acid 1 kg/kg, 1 kg <span class="k">in </span>1 bottle , powder, folic acid 1 kg/kg, 1 kg <span class="k">in </span>1 drum , powder, folic acid 1 g/g, 5 g <span class="k">in </span>1 container , powder, folic acid 1...|                                                                                               <span class="o">[</span>-, -, -, -, -, -, -, -, -, -, -, 51552139201, -, -, -, 81919000203, -, 81919000201, -, -, -, -, -, -, -]|
|insulin glargine 100 UNT/ML injection|  DRUG|00088502101|insulin glargine 100 <span class="o">[</span>iu]/ml, 1 vial, glass <span class="k">in </span>1 package , injection, solution|[00088502101, 00088222033, 49502019580, 00002771563, 00169320111, 00088250033, 70518139000, 00169266211, 50090127600, 50090407400, 00002771559, 00002772899, 70518225200, 70518138800, 00024592410, 0...|[insulin glargine 100 <span class="o">[</span>iu]/ml, 1 vial, glass <span class="k">in </span>1 package , injection, solution, insulin glargine 100 <span class="o">[</span>iu]/ml, 1 vial, glass <span class="k">in </span>1 carton , injection, solution, insulin glargine 100 <span class="o">[</span>iu]/ml, 1 vial ...|[-, -, -, 00088221900, -, -, 50090139800|00088502005, -, 70518146200|00169368712, 00169368512|73070020011, 00088221905|49502019675|50090406800, -, 73070010011|00169750111|50090495500, 66733077301|0...|
|                     metformin 500 mg|  DRUG|70010006315|               metformin hydrochloride 500 mg/500mg, 500 mg <span class="k">in </span>1 drum , tablet|[70010006315, 62207041613, 71052050750, 62207049147, 71052091050, 25000010197, 25000013498, 25000010198, 71052063005, 51662139201, 70010049118, 70882012456, 71052011005, 71052065905, 71052050850, 1...|[metformin hydrochloride 500 mg/500mg, 500 mg <span class="k">in </span>1 drum , tablet, metformin hcl 500 mg/kg, 50 kg <span class="k">in </span>1 drum , powder, 5-fluorouracil 500 g/500g, 500 g <span class="k">in </span>1 container , powder, metformin er 500 mg 50...|                                                                                             <span class="o">[</span>-, -, -, 70010049105, -, -, -, -, -, -, -, -, -, -, -, 71800000801|42571036007, -, -, -, -, -, -, -, -, -]|
+-------------------------------------+------+-----------+------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_loinc_augmented</code> : This model maps extracted clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings. It is trained on the augmented version of the dataset which is used in previous LOINC resolver models.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
loinc_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_loinc_augmented"</span>,<span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
     .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
     .setOutputCol<span class="o">(</span><span class="s2">"loinc_code"</span><span class="o">)</span><span class="se">\</span>
     .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span><span class="se">\</span>
     .setCaseSensitive<span class="o">(</span>False<span class="o">)</span>
...

<span class="nv">sample_text</span><span class="o">=</span><span class="s2">"""The patient is a 22-year-old female with a history of obesity. She has a Body mass index (BMI) of 33.5 kg/m2, aspartate aminotransferase 64, and alanine aminotransferase 126. Her hgba1c is 8.2%."""</span>
result <span class="o">=</span> resolver_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>sample_text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------+-----+---+------+----------+--------------------------------------------------+--------------------------------------------------+
|                     chunk|begin|end|entity|Loinc_Code|                                         all_codes|                                       resolutions|
+--------------------------+-----+---+------+----------+--------------------------------------------------+--------------------------------------------------+
|           Body mass index|   74| 88|  Test| LP35925-4|LP35925-4:::BDYCRC:::LP172732-2:::39156-5:::LP7...|body mass index:::body circumference:::body mus...|
|aspartate aminotransferase|  111|136|  Test| LP15426-7|LP15426-7:::14409-7:::LP307348-5:::LP15333-5:::...|aspartate aminotransferase::: aspartate transam...|
|  alanine aminotransferase|  146|169|  Test| LP15333-5|LP15333-5:::LP307326-1:::16324-6:::LP307348-5::...|alanine aminotransferase:::alanine aminotransfe...|
|                    hgba1c|  180|185|  Test|   17855-8|17855-8:::4547-6:::55139-0:::72518-4:::45190-6:...| hba1c::: hgb a1::: hb1::: hcds1::: hhc1::: htr...|
+--------------------------+-----+---+------+----------+--------------------------------------------------+--------------------------------------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_clinical_snomed_procedures_measurements</code> : This model maps medical entities to SNOMED codes using <code class="language-plaintext highlighter-rouge">sent_biobert_clinical_base_cased</code> Sentence Bert Embeddings. The corpus of this model includes <code class="language-plaintext highlighter-rouge">Procedures</code> and <code class="language-plaintext highlighter-rouge">Measurement</code> domains.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
snomed_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_clinical_snomed_procedures_measurements"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"snomed_code"</span><span class="o">)</span>
...

light_model <span class="o">=</span> LightPipeline<span class="o">(</span>resolver_model<span class="o">)</span>
result <span class="o">=</span> light_model.fullAnnotate<span class="o">([</span><span class="s1">'coronary calcium score'</span>, <span class="s1">'heart surgery'</span>, <span class="s1">'ct scan'</span>, <span class="s1">'bp value'</span><span class="o">])</span>

</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                  |      code | code_description              | all_k_codes                                                                     | all_k_resolutions                                                                                                                                               |
|---:|:-----------------------|----------:|:------------------------------|:--------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | coronary calcium score | 450360000 | Coronary artery calcium score | <span class="o">[</span><span class="s1">'450360000'</span>, <span class="s1">'450734004'</span>, <span class="s1">'1086491000000104'</span>, <span class="s1">'1086481000000101'</span>, <span class="s1">'762241007'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'Coronary artery calcium score'</span>, <span class="s1">'Coronary artery calcium score'</span>, <span class="s1">'Dundee Coronary Risk Disk score'</span>, <span class="s1">'Dundee Coronary Risk rank'</span>, <span class="s1">'Dundee Coronary Risk Disk'</span><span class="o">]</span> |
|  1 | heart surgery          |   2598006 | Open heart surgery            | <span class="o">[</span><span class="s1">'2598006'</span>, <span class="s1">'64915003'</span>, <span class="s1">'119766003'</span>, <span class="s1">'34068001'</span>, <span class="s1">'233004008'</span><span class="o">]</span>                   | <span class="o">[</span><span class="s1">'Open heart surgery'</span>, <span class="s1">'Operation on heart'</span>, <span class="s1">'Heart reconstruction'</span>, <span class="s1">'Heart valve replacement'</span>, <span class="s1">'Coronary sinus operation'</span><span class="o">]</span>                                     |
|  2 | ct scan                | 303653007 | CT of <span class="nb">head</span>                    | <span class="o">[</span><span class="s1">'303653007'</span>, <span class="s1">'431864000'</span>, <span class="s1">'363023007'</span>, <span class="s1">'418272005'</span>, <span class="s1">'241577003'</span><span class="o">]</span>               | <span class="o">[</span><span class="s1">'CT of head'</span>, <span class="s1">'CT guided injection'</span>, <span class="s1">'CT of site'</span>, <span class="s1">'CT angiography'</span>, <span class="s1">'CT of spine'</span><span class="o">]</span>                                                                            |
|  3 | bp value               |  75367002 | Blood pressure                | <span class="o">[</span><span class="s1">'75367002'</span>, <span class="s1">'6797001'</span>, <span class="s1">'723232008'</span>, <span class="s1">'46973005'</span>, <span class="s1">'427732000'</span><span class="o">]</span>                   | <span class="o">[</span><span class="s1">'Blood pressure'</span>, <span class="s1">'Mean blood pressure'</span>, <span class="s1">'Average blood pressure'</span>, <span class="s1">'Blood pressure taking'</span>, <span class="s1">'Speed of blood pressure response'</span><span class="o">]</span>                                |
</code></pre></div></div>

<h4 id="updated-rxnorm-sentence-entity-resolver-model">Updated RxNorm Sentence Entity Resolver Model</h4>

<p>We have updated <code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_augmented</code> model training on an augmented version of the dataset used in previous versions of the model.</p>

<h4 id="new-shift-days-feature-in-structureddeid-deidentification-module">New Shift Days Feature in StructuredDeid Deidentification Module</h4>

<p>Now we can shift n days in the structured deidentification when the column is a Date.</p>

<p><em>Example</em> :</p>

<pre><code class="language-pyhton"> df = spark.createDataFrame([
            ["Juan García", "13/02/1977", "711 Nulla St.", "140", "673 431234"],
            ["Will Smith", "23/02/1977", "1 Green Avenue.", "140", "+23 (673) 431234"],
            ["Pedro Ximénez", "11/04/1900", "Calle del Libertador, 7", "100", "912 345623"]
        ]).toDF("NAME", "DOB", "ADDRESS", "SBP", "TEL")

 obfuscator = StructuredDeidentification(spark=spark, columns={"NAME": "ID", "DOB": "DATE"},
                                                      columnsSeed={"NAME": 23, "DOB": 23},
                                                      obfuscateRefSource="faker",
                                                      days=5
                                         )

result = obfuscator.obfuscateColumns(self.df)
result.show(truncate=False)                                             
</code></pre>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------+------------+-----------------------+---+----------------+
|NAME      |DOB         |ADDRESS                |SBP|TEL             |
+----------+------------+-----------------------+---+----------------+
|[T1825511]|[18/02/1977]|711 Nulla St.          |140|673 431234      |
|[G6835267]|[28/02/1977]|1 Green Avenue.        |140|+23 <span class="o">(</span>673<span class="o">)</span> 431234|
|[S2371443]|[16/04/1900]|Calle del Libertador, 7|100|912 345623      |
+----------+------------+-----------------------+---+----------------+
</code></pre></div></div>

<h4 id="new-multiple-chunks-merge-ability-in-chunkmergeapproach">New Multiple Chunks Merge Ability in ChunkMergeApproach</h4>

<p>Updated ChunkMergeApproach to admit N input cols (<code class="language-plaintext highlighter-rouge">.setInputCols("ner_chunk","ner_chunk_1","ner_chunk_2")</code>). The input columns must be chunk columns.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">deid_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_large"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">'DATE'</span><span class="p">,</span> <span class="s">'AGE'</span><span class="p">,</span> <span class="s">'NAME'</span><span class="p">,</span> <span class="s">'PROFESSION'</span><span class="p">,</span> <span class="s">'ID'</span><span class="p">])</span>

<span class="n">medical_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_events_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner2"</span><span class="p">)</span>

<span class="n">ner_converter_2</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner2"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_2"</span><span class="p">)</span>

<span class="n">ssn_parser</span> <span class="o">=</span> <span class="n">ContextualParserApproach</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity_ssn"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"../../src/test/resources/ssn.json"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunk_merge</span> <span class="o">=</span> <span class="n">ChunkMergeApproach</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"entity_ssn"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"ner_chunk_2"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setChunkPrecedence</span><span class="p">(</span><span class="s">"field"</span><span class="p">)</span>      
<span class="p">...</span>
</code></pre></div></div>

<h4 id="new-setblacklist-feature-in-chunkmergeapproach">New setBlackList Feature in ChunkMergeApproach</h4>

<p>Now we can filter out the entities in the ChunkMergeApproach using a black list <code class="language-plaintext highlighter-rouge">.setBlackList(["NAME","ID"])</code>. The entities specified in the blackList will be excluded from the final entity list.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chunk_merge</span> <span class="o">=</span> <span class="n">ChunkMergeApproach</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"entity_ssn"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setBlackList</span><span class="p">([</span><span class="s">"NAME"</span><span class="p">,</span><span class="s">"ID"</span><span class="p">])</span>
</code></pre></div></div>

<h4 id="new-setblacklist-feature-in-nerconverterinternal">New setBlackList Feature in NerConverterInternal</h4>

<p>Now we can filter out the entities in the NerConverterInternal using a black list <code class="language-plaintext highlighter-rouge">.setBlackList(["Drug","Treatment"])</code>. The entities specified in the blackList will be excluded from the final entity list.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl_slim"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">NerConverterInternal</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entities"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setBlackList</span><span class="p">([</span><span class="s">"Drug"</span><span class="p">,</span><span class="s">"Treatment"</span><span class="p">])</span>
</code></pre></div></div>

<h4 id="new-setlabelcasing-feature-in-medicalnermodel">New setLabelCasing Feature in MedicalNerModel</h4>

<p>Now we can decide if we want to return the tags in upper or lower case with <code class="language-plaintext highlighter-rouge">setLabelCasing()</code>. That method convert the I-tags and B-tags in lower or upper case during the inference. The values will be ‘lower’ for lower case and ‘upper’ for upper case.</p>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setLabelCasing</span><span class="p">(</span><span class="s">"lower"</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">pipelineModel</span><span class="p">).</span><span class="n">annotate</span><span class="p">(</span><span class="s">"A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus "</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s">"ner_tags"</span><span class="p">]</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span><span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'B-problem'</span>, <span class="s1">'I-problem'</span>, <span class="s1">'I-problem'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'O'</span>, <span class="s1">'B-problem'</span>, <span class="s1">'I-problem'</span>, <span class="s1">'I-problem'</span>, <span class="s1">'I-problem'</span>, <span class="s1">'I-problem'</span><span class="o">]</span>
</code></pre></div></div>

<h4 id="new-update-models-functionality">New Update Models Functionality</h4>

<p>We developed a new utility function called <code class="language-plaintext highlighter-rouge">UpdateModels</code> that allows you to refresh your <code class="language-plaintext highlighter-rouge">cache_pretrained</code> folder without running any annotator or manually checking. It has two methods;</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">UpdateModels.updateCacheModels()</code> : This method lets you update all the models existing in the <code class="language-plaintext highlighter-rouge">cache_pretrained</code> folder. It downloads the latest version of all the models existing in the <code class="language-plaintext highlighter-rouge">cache_pretrained</code>.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Models in /cache_pretrained</span>
<span class="nb">ls</span> ~/cache_pretrained
<span class="o">&gt;&gt;</span> ner_clinical_large_en_3.0.0_2.3_1617206114650/

<span class="c"># Update models in /cache_pretrained</span>
from sparknlp_jsl.updateModels import UpdateModels
UpdateModels.updateCacheModels<span class="o">()</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Updated models in /cache_pretrained</span>
<span class="nb">ls</span> ~/cache_pretrained
<span class="o">&gt;&gt;</span> ner_clinical_large_en_3.0.0_2.3_1617206114650/
   ner_clinical_large_en_3.0.0_3.0_1617206114650/
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">UpdateModels.updateModels("11/24/2021")</code> : This method lets you download all the new models uploaded to the Models Hub starting from a cut-off date (i.e. the last sync update).</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Models in /cache_pretrained</span>
<span class="nb">ls</span> ~/cache_pretrained
<span class="o">&gt;&gt;</span> ner_clinical_large_en_3.0.0_2.3_1617206114650/
   ner_clinical_large_en_3.0.0_3.0_1617206114650/

<span class="c"># Update models in /cache_pretrained according to date</span>
from sparknlp_jsl.updateModels import UpdateModels
UpdateModels.updateModels<span class="o">(</span><span class="s2">"11/24/2021"</span><span class="o">)</span>

</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Updated models in /cache_pretrained</span>
<span class="nb">ls</span> ~/cache_pretrained
<span class="o">&gt;&gt;</span>ner_clinical_large_en_3.0.0_2.3_1617206114650/
  ner_clinical_large_en_3.0.0_3.0_1617206114650/
  ner_model_finder_en_3.3.2_2.4_1637761259895/
  sbertresolve_ner_model_finder_en_3.3.2_2.4_1637764208798/
</code></pre></div></div>

<h4 id="new-and-updated-notebooks-2">New and Updated Notebooks</h4>

<ul>
  <li>
    <p>We have a new <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Annotation_Lab/AL_API_import_export_pre_annotate.ipynb">Connect to Annotation Lab via API Notebook</a> you can find how to;</p>

    <ul>
      <li>upload pre-annotations to ALAB</li>
      <li>import a project form ALAB and convert to CoNLL file</li>
      <li>upload tasks without pre-annotations</li>
    </ul>
  </li>
  <li>
    <p>We have updated <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb">Clinical Relation Extraction Notebook</a> by adding a Relation Extraction Model-NER Model-Relation Pairs table that can be used to get the most optimal results when using these models.</p>
  </li>
</ul>

<p><strong>To see more, please check : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></strong></p>

<h2 id="332">3.3.2</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.3.2 has been released!.</p>

<h4 id="highlights-7">Highlights</h4>

<ul>
  <li>New Clinical NER Models and Spanish NER Model</li>
  <li>New BERT-Based Clinical NER Models</li>
  <li>Updated Clinical NER Model</li>
  <li>New NER Model Class Distribution Feature</li>
  <li>New RxNorm Sentence Entity Resolver Model</li>
  <li>New Spanish SNOMED Sentence Entity Resolver Model</li>
  <li>New Clinical Question vs Statement BertForSequenceClassification model</li>
  <li>New Sentence Entity Resolver Fine-Tune Features (Overwriting and Drop Code)</li>
  <li>Updated ICD10CM Entity Resolver Models</li>
  <li>Updated NER Profiling Pretrained Pipelines</li>
  <li>New ChunkSentenceSplitter Annotator</li>
  <li>Updated Spark NLP For Healthcare Notebooks and New Notebooks</li>
</ul>

<h4 id="new-clinical-ner-models-including-a-new-spanish-one">New Clinical NER Models (including a new Spanish one)</h4>

<p>We are releasing three new clinical NER models trained by MedicalNerApproach().</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">roberta_ner_diag_proc</code> : This models leverages Spanish Roberta Biomedical Embeddings (<code class="language-plaintext highlighter-rouge">roberta_base_biomedical</code>) to extract two entities, Diagnosis and Procedures (<code class="language-plaintext highlighter-rouge">DIAGNOSTICO</code>, <code class="language-plaintext highlighter-rouge">PROCEDIMIENTO</code>). It’s a renewed version of <code class="language-plaintext highlighter-rouge">ner_diag_proc_es</code>, available <a href="https://nlp.johnsnowlabs.com/2020/07/08/ner_diag_proc_es.html">here</a>, that was trained with <code class="language-plaintext highlighter-rouge">embeddings_scielowiki_300d</code> embeddings instead.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings <span class="o">=</span>  RoBertaEmbeddings.pretrained<span class="o">(</span><span class="s2">"roberta_base_biomedical"</span>, <span class="s2">"es"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>

ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"roberta_ner_diag_proc"</span>, <span class="s2">"es"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s1">'sentence'</span>, <span class="s1">'token'</span>, <span class="s1">'ner'</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s1">'ner_chunk'</span><span class="o">)</span>

pipeline <span class="o">=</span> Pipeline<span class="o">(</span>stages <span class="o">=</span> <span class="o">[</span>
    documentAssembler,
    sentenceDetector,
    tokenizer,
    embeddings,
    ner,
    ner_converter]<span class="o">)</span>

empty <span class="o">=</span> spark.createDataFrame<span class="o">([[</span><span class="s1">''</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span>

p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>empty<span class="o">)</span>

test_sentence <span class="o">=</span> <span class="s1">'Mujer de 28 años con antecedentes de diabetes mellitus gestacional diagnosticada ocho años antes de la presentación y posterior diabetes mellitus tipo dos (DM2), un episodio previo de pancreatitis inducida por HTG tres años antes de la presentación, asociado con una hepatitis aguda, y obesidad con un índice de masa corporal (IMC) de 33,5 kg / m2, que se presentó con antecedentes de una semana de poliuria, polidipsia, falta de apetito y vómitos. Dos semanas antes de la presentación, fue tratada con un ciclo de cinco días de amoxicilina por una infección del tracto respiratorio. Estaba tomando metformina, glipizida y dapagliflozina para la DM2 y atorvastatina y gemfibrozil para la HTG. Había estado tomando dapagliflozina durante seis meses en el momento de la presentación. El examen físico al momento de la presentación fue significativo para la mucosa oral seca; significativamente, su examen abdominal fue benigno sin dolor a la palpación, protección o rigidez. Los hallazgos de laboratorio pertinentes al ingreso fueron: glucosa sérica 111 mg / dl, bicarbonato 18 mmol / l, anión gap 20, creatinina 0,4 mg / dl, triglicéridos 508 mg / dl, colesterol total 122 mg / dl, hemoglobina glucosilada (HbA1c) 10%. y pH venoso 7,27. La lipasa sérica fue normal a 43 U / L. Los niveles séricos de acetona no pudieron evaluarse ya que las muestras de sangre se mantuvieron hemolizadas debido a una lipemia significativa. La paciente ingresó inicialmente por cetosis por inanición, ya que refirió una ingesta oral deficiente durante los tres días previos a la admisión. Sin embargo, la química sérica obtenida seis horas después de la presentación reveló que su glucosa era de 186 mg / dL, la brecha aniónica todavía estaba elevada a 21, el bicarbonato sérico era de 16 mmol / L, el nivel de triglicéridos alcanzó un máximo de 2050 mg / dL y la lipasa fue de 52 U / L. Se obtuvo el nivel de β-hidroxibutirato y se encontró que estaba elevado a 5,29 mmol / L; la muestra original se centrifugó y la capa de quilomicrones se eliminó antes del análisis debido a la interferencia de la turbidez causada por la lipemia nuevamente. El paciente fue tratado con un goteo de insulina para euDKA y HTG con una reducción de la brecha aniónica a 13 y triglicéridos a 1400 mg / dL, dentro de las 24 horas. Se pensó que su euDKA fue precipitada por su infección del tracto respiratorio en el contexto del uso del inhibidor de SGLT2. La paciente fue atendida por el servicio de endocrinología y fue dada de alta con 40 unidades de insulina glargina por la noche, 12 unidades de insulina lispro con las comidas y metformina 1000 mg dos veces al día. Se determinó que todos los inhibidores de SGLT2 deben suspenderse indefinidamente. Tuvo un seguimiento estrecho con endocrinología post alta.'</span>
res <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------------------------------+------------+
|                             text|ner_label  |
+---------------------------------+------------+
|    diabetes mellitus gestacional|DIAGNOSTICO|
|       diabetes mellitus tipo dos|DIAGNOSTICO|
|                              DM2|DIAGNOSTICO|
|    pancreatitis inducida por HTG|DIAGNOSTICO|
|                  hepatitis aguda|DIAGNOSTICO|
|                         obesidad|DIAGNOSTICO|
|          índice de masa corporal|DIAGNOSTICO|
|                              IMC|DIAGNOSTICO|
|                         poliuria|DIAGNOSTICO|
|                       polidipsia|DIAGNOSTICO|
|                          vómitos|DIAGNOSTICO|
|infección del tracto respiratorio|DIAGNOSTICO|
|                              DM2|DIAGNOSTICO|
|                              HTG|DIAGNOSTICO|
|                            dolor|DIAGNOSTICO|
|                          rigidez|DIAGNOSTICO|
|                          cetosis|DIAGNOSTICO|
|infección del tracto respiratorio|DIAGNOSTICO|
+---------------------------------+-----------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_covid_trials</code> : This model is trained to extract covid-specific medical entities in clinical trials. It supports the following entities ranging from virus type to trial design: <code class="language-plaintext highlighter-rouge">Stage</code>, <code class="language-plaintext highlighter-rouge">Severity</code>, <code class="language-plaintext highlighter-rouge">Virus</code>, <code class="language-plaintext highlighter-rouge">Trial_Design</code>, <code class="language-plaintext highlighter-rouge">Trial_Phase</code>, <code class="language-plaintext highlighter-rouge">N_Patients</code>, <code class="language-plaintext highlighter-rouge">Institution</code>, <code class="language-plaintext highlighter-rouge">Statistical_Indicator</code>, <code class="language-plaintext highlighter-rouge">Section_Header</code>, <code class="language-plaintext highlighter-rouge">Cell_Type</code>, <code class="language-plaintext highlighter-rouge">Cellular_component</code>, <code class="language-plaintext highlighter-rouge">Viral_components</code>, <code class="language-plaintext highlighter-rouge">Physiological_reaction</code>, <code class="language-plaintext highlighter-rouge">Biological_molecules</code>, <code class="language-plaintext highlighter-rouge">Admission_Discharge</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Cerebrovascular_Disease</code>, <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Death_Entity</code>, <code class="language-plaintext highlighter-rouge">Diabetes</code>, <code class="language-plaintext highlighter-rouge">Disease_Syndrome_Disorder</code>, <code class="language-plaintext highlighter-rouge">Dosage</code>, <code class="language-plaintext highlighter-rouge">Drug_Ingredient</code>, <code class="language-plaintext highlighter-rouge">Employment</code>, <code class="language-plaintext highlighter-rouge">Frequency</code>, <code class="language-plaintext highlighter-rouge">Gender</code>, <code class="language-plaintext highlighter-rouge">Heart_Disease</code>, <code class="language-plaintext highlighter-rouge">Hypertension</code>, <code class="language-plaintext highlighter-rouge">Obesity</code>, <code class="language-plaintext highlighter-rouge">Pulse</code>, <code class="language-plaintext highlighter-rouge">Race_Ethnicity</code>, <code class="language-plaintext highlighter-rouge">Respiration</code>, <code class="language-plaintext highlighter-rouge">Route</code>, <code class="language-plaintext highlighter-rouge">Smoking</code>, <code class="language-plaintext highlighter-rouge">Time</code>, <code class="language-plaintext highlighter-rouge">Total_Cholesterol</code>, <code class="language-plaintext highlighter-rouge">Treatment</code>, <code class="language-plaintext highlighter-rouge">VS_Finding</code>, <code class="language-plaintext highlighter-rouge">Vaccine</code> .</li>
</ul>

<p><em>Example</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
covid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s1">'ner_covid_trials'</span>, <span class="s1">'en'</span>, <span class="s1">'clinical/models'</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>    
...

results <span class="o">=</span> covid_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s2">"text"</span>: <span class="o">[</span><span class="s2">"""In December 2019 , a group of patients with the acute respiratory disease was detected in Wuhan , Hubei Province of China . A month later , a new beta-coronavirus was identified as the cause of the 2019 coronavirus infection . SARS-CoV-2 is a coronavirus that belongs to the group of β-coronaviruses of the subgenus Coronaviridae . The SARS-CoV-2 is the third known zoonotic coronavirus disease after severe acute respiratory syndrome ( SARS ) and Middle Eastern respiratory syndrome ( MERS ). The diagnosis of SARS-CoV-2 recommended by the WHO , CDC is the collection of a sample from the upper respiratory tract ( nasal and oropharyngeal exudate ) or from the lower respiratory tract such as expectoration of endotracheal aspirate and bronchioloalveolar lavage and its analysis using the test of real-time polymerase chain reaction ( qRT-PCR )."""</span><span class="o">]})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
|    | chunk                               |   begin |   end | entity                    |
|---:|:------------------------------------|--------:|------:|:--------------------------|
|  0 | December 2019                       |       3 |    15 | Date                      |
|  1 | acute respiratory disease           |      48 |    72 | Disease_Syndrome_Disorder |
|  2 | beta-coronavirus                    |     146 |   161 | Virus                     |
|  3 | 2019 coronavirus infection          |     198 |   223 | Disease_Syndrome_Disorder |
|  4 | SARS-CoV-2                          |     227 |   236 | Virus                     |
|  5 | coronavirus                         |     243 |   253 | Virus                     |
|  6 | β-coronaviruses                     |     284 |   298 | Virus                     |
|  7 | subgenus Coronaviridae              |     307 |   328 | Virus                     |
|  8 | SARS-CoV-2                          |     336 |   345 | Virus                     |
|  9 | zoonotic coronavirus disease        |     366 |   393 | Disease_Syndrome_Disorder |
| 10 | severe acute respiratory syndrome   |     401 |   433 | Disease_Syndrome_Disorder |
| 11 | SARS                                |     437 |   440 | Disease_Syndrome_Disorder |
| 12 | Middle Eastern respiratory syndrome |     448 |   482 | Disease_Syndrome_Disorder |
| 13 | MERS                                |     486 |   489 | Disease_Syndrome_Disorder |
| 14 | SARS-CoV-2                          |     511 |   520 | Virus                     |
| 15 | WHO                                 |     541 |   543 | Institution               |
| 16 | CDC                                 |     547 |   549 | Institution               |
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_chemd_clinical</code> : This model extract the names of chemical compounds and drugs in medical texts. The entities that can be detected are as follows : <code class="language-plaintext highlighter-rouge">SYSTEMATIC</code>, <code class="language-plaintext highlighter-rouge">IDENTIFIERS</code>, <code class="language-plaintext highlighter-rouge">FORMULA</code>, <code class="language-plaintext highlighter-rouge">TRIVIAL</code>, <code class="language-plaintext highlighter-rouge">ABBREVIATION</code>, <code class="language-plaintext highlighter-rouge">FAMILY</code>, <code class="language-plaintext highlighter-rouge">MULTIPLE</code> . For reference <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4331685/">click here</a> .</li>
</ul>

<p><em>Example</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
chemd_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s1">'ner_chemd'</span>, <span class="s1">'en'</span>, <span class="s1">'clinical/models'</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>    
...

results <span class="o">=</span> chemd_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s2">"text"</span>: <span class="o">[</span><span class="s2">"""Isolation, Structure Elucidation, and Iron-Binding Properties of Lystabactins, Siderophores Isolated from a Marine Pseudoalteromonas sp. The marine bacterium Pseudoalteromonas sp. S2B, isolated from the Gulf of Mexico after the Deepwater Horizon oil spill, was found to produce lystabactins A, B, and C (1-3), three new siderophores. The structures were elucidated through mass spectrometry, amino acid analysis, and NMR. The lystabactins are composed of serine (Ser), asparagine (Asn), two formylated/hydroxylated ornithines (FOHOrn), dihydroxy benzoic acid (Dhb), and a very unusual nonproteinogenic amino acid, 4,8-diamino-3-hydroxyoctanoic acid (LySta). The iron-binding properties of the compounds were investigated through a spectrophotometric competition."""</span><span class="o">]})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------------------------+------------+
|chunk                             |ner_label   |
+----------------------------------+------------+
|Lystabactins                      |FAMILY      |
|lystabactins A, B, and C          |MULTIPLE    |
|amino acid                        |FAMILY      |
|lystabactins                      |FAMILY      |
|serine                            |TRIVIAL     |
|Ser                               |FORMULA     |
|asparagine                        |TRIVIAL     |
|Asn                               |FORMULA     |
|formylated/hydroxylated ornithines|FAMILY      |
|FOHOrn                            |FORMULA     |
|dihydroxy benzoic acid            |SYSTEMATIC  |
|amino acid                        |FAMILY      |
|4,8-diamino-3-hydroxyoctanoic acid|SYSTEMATIC  |
|LySta                             |ABBREVIATION|
+----------------------------------+------------+
</code></pre></div></div>

<h4 id="new-bert-based-clinical-ner-models-1">New BERT-Based Clinical NER Models</h4>

<p>We have two new BERT-Based token classifier NER models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_bionlp</code> : This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_bionlp</code> model and can detect biological and genetics terms in cancer-related texts. (<code class="language-plaintext highlighter-rouge">Amino_acid</code>, <code class="language-plaintext highlighter-rouge">Anatomical_system</code>, <code class="language-plaintext highlighter-rouge">Cancer</code>, <code class="language-plaintext highlighter-rouge">Cell</code>, <code class="language-plaintext highlighter-rouge">Cellular_component</code>, <code class="language-plaintext highlighter-rouge">Developing_anatomical_Structure</code>, <code class="language-plaintext highlighter-rouge">Gene_or_gene_product</code>, <code class="language-plaintext highlighter-rouge">Immaterial_anatomical_entity</code>, <code class="language-plaintext highlighter-rouge">Multi-tissue_structure</code>, <code class="language-plaintext highlighter-rouge">Organ</code>, <code class="language-plaintext highlighter-rouge">Organism</code>, <code class="language-plaintext highlighter-rouge">Organism_subdivision</code>, <code class="language-plaintext highlighter-rouge">Simple_chemical</code>, <code class="language-plaintext highlighter-rouge">Tissue</code>)</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_token_classifier_ner_bionlp"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">test_sentence</span> <span class="o">=</span> <span class="s">"""Both the erbA IRES and the erbA/myb virus constructs transformed erythroid cells after infection of bone marrow or blastoderm cultures. The erbA/myb IRES virus exhibited a 5-10-fold higher transformed colony forming efficiency than the erbA IRES virus in the blastoderm assay."""</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">p_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'text'</span><span class="p">:</span> <span class="p">[</span><span class="n">test_sentence</span><span class="p">]})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------+----------------------+
|chunk              |ner_label             |
+-------------------+----------------------+
|erbA IRES          |Organism              |
|erbA/myb virus     |Organism              |
|erythroid cells    |Cell                  |
|bone marrow        |Multi-tissue_structure|
|blastoderm cultures|Cell                  |
|erbA/myb IRES virus|Organism              |
|erbA IRES virus    |Organism              |
|blastoderm         |Cell                  |
+-------------------+----------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_cellular</code> : This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_cellular</code> model and can detect molecular biology-related terms (<code class="language-plaintext highlighter-rouge">DNA</code>, <code class="language-plaintext highlighter-rouge">Cell_type</code>, <code class="language-plaintext highlighter-rouge">Cell_line</code>, <code class="language-plaintext highlighter-rouge">RNA</code>, <code class="language-plaintext highlighter-rouge">Protein</code>) in medical texts.</li>
</ul>

<p><em>Metrics</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

       B-DNA       0.87      0.77      0.82      1056
       B-RNA       0.85      0.79      0.82       118
 B-cell_line       0.66      0.70      0.68       500
 B-cell_type       0.87      0.75      0.81      1921
   B-protein       0.90      0.85      0.88      5067
       I-DNA       0.93      0.86      0.90      1789
       I-RNA       0.92      0.84      0.88       187
 I-cell_line       0.67      0.76      0.71       989
 I-cell_type       0.92      0.76      0.84      2991
   I-protein       0.94      0.80      0.87      4774

    accuracy                           0.80     19392
   macro avg       0.76      0.81      0.78     19392
weighted avg       0.89      0.80      0.85     19392
</code></pre></div></div>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_token_classifier_ner_cellular"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
<span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">)</span>
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="p">...</span>

<span class="n">test_sentence</span> <span class="o">=</span> <span class="s">"""Detection of various other intracellular signaling proteins is also described. Genetic characterization of transactivation of the human T-cell leukemia virus type 1 promoter: Binding of Tax to Tax-responsive element 1 is mediated by the cyclic AMP-responsive members of the CREB/ATF family of transcription factors. To achieve a better understanding of the mechanism of transactivation by Tax of human T-cell leukemia virus type 1 Tax-responsive element 1 (TRE-1), we developed a genetic approach with Saccharomyces cerevisiae. We constructed a yeast reporter strain containing the lacZ gene under the control of the CYC1 promoter associated with three copies of TRE-1. Expression of either the cyclic AMP response element-binding protein (CREB) or CREB fused to the GAL4 activation domain (GAD) in this strain did not modify the expression of the reporter gene. Tax alone was also inactive."""</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">p_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'text'</span><span class="p">:</span> <span class="p">[</span><span class="n">test_sentence</span><span class="p">]})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------------------+---------+
|chunk                                      |ner_label|
+-------------------------------------------+---------+
|intracellular signaling proteins           |protein  |
|human T-cell leukemia virus <span class="nb">type </span>1 promoter|DNA      |
|Tax                                        |protein  |
|Tax-responsive element 1                   |DNA      |
|cyclic AMP-responsive members              |protein  |
|CREB/ATF family                            |protein  |
|transcription factors                      |protein  |
|Tax                                        |protein  |
|human T-cell leukemia virus <span class="nb">type </span>1         |DNA      |
|Tax-responsive element 1                   |DNA      |
|TRE-1                                      |DNA      |
|lacZ gene                                  |DNA      |
|CYC1 promoter                              |DNA      |
|TRE-1                                      |DNA      |
|cyclic AMP response element-binding protein|protein  |
|CREB                                       |protein  |
|CREB                                       |protein  |
|GAL4 activation domain                     |protein  |
|GAD                                        |protein  |
|reporter gene                              |DNA      |
|Tax                                        |protein  |
+-------------------------------------------+---------+
</code></pre></div></div>

<h4 id="updated-clinical-ner-model">Updated Clinical NER Model</h4>

<p>We have updated <code class="language-plaintext highlighter-rouge">ner_jsl_enriched</code> model by enriching the training data using clinical trials data to make it more robust. This model is capable of predicting up to <code class="language-plaintext highlighter-rouge">87</code> different entities and is based on <code class="language-plaintext highlighter-rouge">ner_jsl</code> model. Here are the entities this model can detect;</p>

<p><code class="language-plaintext highlighter-rouge">Social_History_Header</code>, <code class="language-plaintext highlighter-rouge">Oncology_Therapy</code>, <code class="language-plaintext highlighter-rouge">Blood_Pressure</code>, <code class="language-plaintext highlighter-rouge">Respiration</code>, <code class="language-plaintext highlighter-rouge">Performance_Status</code>, <code class="language-plaintext highlighter-rouge">Family_History_Header</code>, <code class="language-plaintext highlighter-rouge">Dosage</code>, <code class="language-plaintext highlighter-rouge">Clinical_Dept</code>, <code class="language-plaintext highlighter-rouge">Diet</code>, <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">HDL</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, <code class="language-plaintext highlighter-rouge">Admission_Discharge</code>, <code class="language-plaintext highlighter-rouge">LDL</code>, <code class="language-plaintext highlighter-rouge">Kidney_Disease</code>, <code class="language-plaintext highlighter-rouge">Oncological</code>, <code class="language-plaintext highlighter-rouge">Route</code>, <code class="language-plaintext highlighter-rouge">Imaging_Technique</code>, <code class="language-plaintext highlighter-rouge">Puerperium</code>, <code class="language-plaintext highlighter-rouge">Overweight</code>, <code class="language-plaintext highlighter-rouge">Temperature</code>, <code class="language-plaintext highlighter-rouge">Diabetes</code>, <code class="language-plaintext highlighter-rouge">Vaccine</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Test_Result</code>, <code class="language-plaintext highlighter-rouge">Employment</code>, <code class="language-plaintext highlighter-rouge">Time</code>, <code class="language-plaintext highlighter-rouge">Obesity</code>, <code class="language-plaintext highlighter-rouge">EKG_Findings</code>, <code class="language-plaintext highlighter-rouge">Pregnancy</code>, <code class="language-plaintext highlighter-rouge">Communicable_Disease</code>, <code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Strength</code>, <code class="language-plaintext highlighter-rouge">Tumor_Finding</code>, <code class="language-plaintext highlighter-rouge">Section_Header</code>, <code class="language-plaintext highlighter-rouge">RelativeDate</code>, <code class="language-plaintext highlighter-rouge">ImagingFindings</code>, <code class="language-plaintext highlighter-rouge">Death_Entity</code>, <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Cerebrovascular_Disease</code>, <code class="language-plaintext highlighter-rouge">Treatment</code>, <code class="language-plaintext highlighter-rouge">Labour_Delivery</code>, <code class="language-plaintext highlighter-rouge">Pregnancy_Delivery_Puerperium</code>, <code class="language-plaintext highlighter-rouge">Direction</code>, <code class="language-plaintext highlighter-rouge">Internal_organ_or_component</code>, <code class="language-plaintext highlighter-rouge">Psychological_Condition</code>, <code class="language-plaintext highlighter-rouge">Form</code>, <code class="language-plaintext highlighter-rouge">Medical_Device</code>, <code class="language-plaintext highlighter-rouge">Test</code>, <code class="language-plaintext highlighter-rouge">Symptom</code>, <code class="language-plaintext highlighter-rouge">Disease_Syndrome_Disorder</code>, <code class="language-plaintext highlighter-rouge">Staging</code>, <code class="language-plaintext highlighter-rouge">Birth_Entity</code>, <code class="language-plaintext highlighter-rouge">Hyperlipidemia</code>, <code class="language-plaintext highlighter-rouge">O2_Saturation</code>, <code class="language-plaintext highlighter-rouge">Frequency</code>, <code class="language-plaintext highlighter-rouge">External_body_part_or_region</code>, <code class="language-plaintext highlighter-rouge">Drug_Ingredient</code>, <code class="language-plaintext highlighter-rouge">Vital_Signs_Header</code>, <code class="language-plaintext highlighter-rouge">Substance_Quantity</code>, <code class="language-plaintext highlighter-rouge">Race_Ethnicity</code>, <code class="language-plaintext highlighter-rouge">VS_Finding</code>, <code class="language-plaintext highlighter-rouge">Injury_or_Poisoning</code>, <code class="language-plaintext highlighter-rouge">Medical_History_Header</code>, <code class="language-plaintext highlighter-rouge">Alcohol</code>, <code class="language-plaintext highlighter-rouge">Triglycerides</code>, <code class="language-plaintext highlighter-rouge">Total_Cholesterol</code>, <code class="language-plaintext highlighter-rouge">Sexually_Active_or_Sexual_Orientation</code>, <code class="language-plaintext highlighter-rouge">Female_Reproductive_Status</code>, <code class="language-plaintext highlighter-rouge">Relationship_Status</code>, <code class="language-plaintext highlighter-rouge">Drug_BrandName</code>, <code class="language-plaintext highlighter-rouge">RelativeTime</code>, <code class="language-plaintext highlighter-rouge">Duration</code>, <code class="language-plaintext highlighter-rouge">Hypertension</code>, <code class="language-plaintext highlighter-rouge">Metastasis</code>, <code class="language-plaintext highlighter-rouge">Gender</code>, <code class="language-plaintext highlighter-rouge">Oxygen_Therapy</code>, <code class="language-plaintext highlighter-rouge">Pulse</code>, <code class="language-plaintext highlighter-rouge">Heart_Disease</code>, <code class="language-plaintext highlighter-rouge">Modifier</code>, <code class="language-plaintext highlighter-rouge">Allergen</code>, <code class="language-plaintext highlighter-rouge">Smoking</code>, <code class="language-plaintext highlighter-rouge">Substance</code>, <code class="language-plaintext highlighter-rouge">Cancer_Modifier</code>, <code class="language-plaintext highlighter-rouge">Fetus_NewBorn</code>, <code class="language-plaintext highlighter-rouge">Height</code> .</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...  
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_jsl_enriched"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"The patient is a 21-day-old Caucasian male here for 2 days of congestion - mom has been suctioning yellow discharge from the patient's nares, plus she has noticed some mild problems with his breathing while feeding (but negative for any perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol. Baby also has had some decreased p.o. intake. His normal breast-feeding is down from 20 minutes q.2h. to 5 to 10 minutes secondary to his respiratory congestion. He sleeps well, but has been more tired and has been fussy over the past 2 days. The parents noticed no improvement with albuterol treatments given in the ER. His urine output has also decreased; normally he has 8 to 10 wet and 5 dirty diapers per 24 hours, now he has down to 4 wet diapers per 24 hours. Mom denies any diarrhea. His bowel movements are yellow colored and soft in nature."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>
<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                                     |   begin |   end | entity                       |
|---:|:------------------------------------------|--------:|------:|:-----------------------------|
|  0 | 21-day-old                                |      17 |    26 | Age                          |
|  1 | Caucasian                                 |      28 |    36 | Race_Ethnicity               |
|  2 | male                                      |      38 |    41 | Gender                       |
|  3 | 2 days                                    |      52 |    57 | Duration                     |
|  4 | congestion                                |      62 |    71 | Symptom                      |
|  5 | mom                                       |      75 |    77 | Gender                       |
|  6 | suctioning yellow discharge               |      88 |   114 | Symptom                      |
|  7 | nares                                     |     135 |   139 | External_body_part_or_region |
|  8 | she                                       |     147 |   149 | Gender                       |
|  9 | mild                                      |     168 |   171 | Modifier                     |
| 10 | problems with his breathing <span class="k">while </span>feeding |     173 |   213 | Symptom                      |
| 11 | perioral cyanosis                         |     237 |   253 | Symptom                      |
| 12 | retractions                               |     258 |   268 | Symptom                      |
| 13 | One day ago                               |     272 |   282 | RelativeDate                 |
| 14 | mom                                       |     285 |   287 | Gender                       |
| 15 | tactile temperature                       |     304 |   322 | Symptom                      |
| 16 | Tylenol                                   |     345 |   351 | Drug_BrandName               |
| 17 | Baby                                      |     354 |   357 | Age                          |
| 18 | decreased p.o. intake                     |     377 |   397 | Symptom                      |
| 19 | His                                       |     400 |   402 | Gender                       |
| 20 | q.2h                                      |     450 |   453 | Frequency                    |
| 21 | 5 to 10 minutes                           |     459 |   473 | Duration                     |
| 22 | his                                       |     488 |   490 | Gender                       |
| 23 | respiratory congestion                    |     492 |   513 | Symptom                      |
| 24 | He                                        |     516 |   517 | Gender                       |
| 25 | tired                                     |     550 |   554 | Symptom                      |
| 26 | fussy                                     |     569 |   573 | Symptom                      |
| 27 | over the past 2 days                      |     575 |   594 | RelativeDate                 |
| 28 | albuterol                                 |     637 |   645 | Drug_Ingredient              |
| 29 | ER                                        |     671 |   672 | Clinical_Dept                |
| 30 | His                                       |     675 |   677 | Gender                       |
| 31 | urine output has also decreased           |     679 |   709 | Symptom                      |
| 32 | he                                        |     721 |   722 | Gender                       |
| 33 | per 24 hours                              |     760 |   771 | Frequency                    |
| 34 | he                                        |     778 |   779 | Gender                       |
| 35 | per 24 hours                              |     807 |   818 | Frequency                    |
| 36 | Mom                                       |     821 |   823 | Gender                       |
| 37 | diarrhea                                  |     836 |   843 | Symptom                      |
| 38 | His                                       |     846 |   848 | Gender                       |
| 39 | bowel                                     |     850 |   854 | Internal_organ_or_component  |
</code></pre></div></div>

<h4 id="new-ner-model-class-distribution-feature">New NER Model Class Distribution Feature</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">getTrainingClassDistribution</code> : This parameter returns the distribution of labels used when training the NER model.</li>
</ul>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_model.getTrainingClassDistribution<span class="o">()</span>
<span class="o">&gt;&gt;</span> <span class="o">{</span><span class="s1">'B-Disease'</span>: 2536, <span class="s1">'O'</span>: 31659, <span class="s1">'I-Disease'</span>: 2960<span class="o">}</span>
</code></pre></div></div>

<h4 id="new-rxnorm-sentence-entity-resolver-model-1">New RxNorm Sentence Entity Resolver Model</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_augmented</code> : This model maps clinical entities and concepts (like drugs/ingredients) to RxNorm codes using sbiobert_base_cased_mli Sentence Bert Embeddings. It trained on the augmented version of the dataset which is used in previous RxNorm resolver models. Additionally, this model returns concept classes of the drugs in all_k_aux_labels column.</li>
</ul>

<h4 id="new-spanish-snomed-sentence-entity-resolver-model">New Spanish SNOMED Sentence Entity Resolver Model</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">robertaresolve_snomed</code> : This models leverages Spanish Roberta Biomedical Embeddings (<code class="language-plaintext highlighter-rouge">roberta_base_biomedical</code>) at sentence-level to map ner chunks into Spanish SNOMED codes.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
    .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>

sentenceDetector <span class="o">=</span> SentenceDetectorDLModel.pretrained<span class="o">()</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"document"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"sentence"</span><span class="o">)</span>

tokenizer <span class="o">=</span> Tokenizer<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"sentence"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"token"</span><span class="o">)</span>

word_embeddings <span class="o">=</span> RoBertaEmbeddings.pretrained<span class="o">(</span><span class="s2">"roberta_base_biomedical"</span>, <span class="s2">"es"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"roberta_embeddings"</span><span class="o">)</span>

ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"roberta_ner_diag_proc"</span>,<span class="s2">"es"</span>,<span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"roberta_embeddings"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"ner"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

c2doc <span class="o">=</span> Chunk2Doc<span class="o">()</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk_doc"</span><span class="o">)</span>

chunk_embeddings <span class="o">=</span> SentenceEmbeddings<span class="o">()</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk_doc"</span>, <span class="s2">"roberta_embeddings"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"chunk_embeddings"</span><span class="o">)</span> <span class="se">\</span>
    .setPoolingStrategy<span class="o">(</span><span class="s2">"AVERAGE"</span><span class="o">)</span>

er <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"robertaresolve_snomed"</span>, <span class="s2">"es"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk_doc"</span>, <span class="s2">"chunk_embeddings"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"snomed_code"</span><span class="o">)</span> <span class="se">\</span>
    .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>

snomed_training_pipeline <span class="o">=</span> Pipeline<span class="o">(</span>stages <span class="o">=</span> <span class="o">[</span>
    documentAssembler,
    sentenceDetector,
    tokenizer,
    word_embeddings,
    ner,
    ner_converter,
    c2doc,
    chunk_embeddings,
    er]<span class="o">)</span>

empty <span class="o">=</span> spark.createDataFrame<span class="o">([[</span><span class="s1">''</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span>

p_model <span class="o">=</span> snomed_pipeline .fit<span class="o">(</span>empty<span class="o">)</span>

test_sentence <span class="o">=</span> <span class="s1">'Mujer de 28 años con antecedentes de diabetes mellitus gestacional diagnosticada ocho años antes de la presentación y posterior diabetes mellitus tipo dos (DM2), un episodio previo de pancreatitis inducida por HTG tres años antes de la presentación, asociado con una hepatitis aguda, y obesidad con un índice de masa corporal (IMC) de 33,5 kg / m2, que se presentó con antecedentes de una semana de poliuria, polidipsia, falta de apetito y vómitos. Dos semanas antes de la presentación, fue tratada con un ciclo de cinco días de amoxicilina por una infección del tracto respiratorio. Estaba tomando metformina, glipizida y dapagliflozina para la DM2 y atorvastatina y gemfibrozil para la HTG. Había estado tomando dapagliflozina durante seis meses en el momento de la presentación. El examen físico al momento de la presentación fue significativo para la mucosa oral seca; significativamente, su examen abdominal fue benigno sin dolor a la palpación, protección o rigidez. Los hallazgos de laboratorio pertinentes al ingreso fueron: glucosa sérica 111 mg / dl, bicarbonato 18 mmol / l, anión gap 20, creatinina 0,4 mg / dl, triglicéridos 508 mg / dl, colesterol total 122 mg / dl, hemoglobina glucosilada (HbA1c) 10%. y pH venoso 7,27. La lipasa sérica fue normal a 43 U / L. Los niveles séricos de acetona no pudieron evaluarse ya que las muestras de sangre se mantuvieron hemolizadas debido a una lipemia significativa. La paciente ingresó inicialmente por cetosis por inanición, ya que refirió una ingesta oral deficiente durante los tres días previos a la admisión. Sin embargo, la química sérica obtenida seis horas después de la presentación reveló que su glucosa era de 186 mg / dL, la brecha aniónica todavía estaba elevada a 21, el bicarbonato sérico era de 16 mmol / L, el nivel de triglicéridos alcanzó un máximo de 2050 mg / dL y la lipasa fue de 52 U / L. Se obtuvo el nivel de β-hidroxibutirato y se encontró que estaba elevado a 5,29 mmol / L; la muestra original se centrifugó y la capa de quilomicrones se eliminó antes del análisis debido a la interferencia de la turbidez causada por la lipemia nuevamente. El paciente fue tratado con un goteo de insulina para euDKA y HTG con una reducción de la brecha aniónica a 13 y triglicéridos a 1400 mg / dL, dentro de las 24 horas. Se pensó que su euDKA fue precipitada por su infección del tracto respiratorio en el contexto del uso del inhibidor de SGLT2. La paciente fue atendida por el servicio de endocrinología y fue dada de alta con 40 unidades de insulina glargina por la noche, 12 unidades de insulina lispro con las comidas y metformina 1000 mg dos veces al día. Se determinó que todos los inhibidores de SGLT2 deben suspenderse indefinidamente. Tuvo un seguimiento estrecho con endocrinología post alta.'</span>

res <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----+-------------------------------+-------------+--------------+
|    | ner_chunk                     | entity      |   snomed_code|
|----+-------------------------------+-------------+--------------|
|  0 | diabetes mellitus gestacional | DIAGNOSTICO |     11687002 |
|  1 | diabetes mellitus tipo dos <span class="o">(</span>  | DIAGNOSTICO |     44054006 |
|  2 | pancreatitis                  | DIAGNOSTICO |     75694006 |
|  3 | HTG                           | DIAGNOSTICO |    266569009 |
|  4 | hepatitis aguda               | DIAGNOSTICO |     37871000 |
|  5 | obesidad                      | DIAGNOSTICO |      5476005 |
|  6 | índice de masa corporal       | DIAGNOSTICO |    162859006 |
|  7 | poliuria                      | DIAGNOSTICO |     56574000 |
|  8 | polidipsia                    | DIAGNOSTICO |     17173007 |
|  9 | falta de apetito              | DIAGNOSTICO |     49233005 |
| 10 | vómitos                       | DIAGNOSTICO |    422400008 |
| 11 | infección                     | DIAGNOSTICO |     40733004 |
| 12 | HTG                           | DIAGNOSTICO |    266569009 |
| 13 | dolor                         | DIAGNOSTICO |     22253000 |
| 14 | rigidez                       | DIAGNOSTICO |    271587009 |
| 15 | cetosis                       | DIAGNOSTICO |      2538008 |
| 16 | infección                     | DIAGNOSTICO |     40733004 |
+----+-------------------------------+-------------+--------------+
</code></pre></div></div>

<h4 id="new-clinical-question-vs-statement-bertforsequenceclassification-model">New Clinical Question vs Statement BertForSequenceClassification model</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_sequence_classifier_question_statement_clinical</code> : This model classifies sentences into one of these two classes: question (interrogative sentence) or statement (declarative sentence) and trained with BertForSequenceClassification. This model is at first trained on SQuAD and SPAADIA dataset and then fine tuned on the clinical visit documents and MIMIC-III dataset annotated in-house. Using this model, you can find the question statements and exclude &amp; utilize in the downstream tasks such as NER and relation extraction models.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
    .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>

sentenceDetector <span class="o">=</span> SentenceDetectorDLModel.pretrained<span class="o">()</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"document"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"sentence"</span><span class="o">)</span>

tokenizer <span class="o">=</span> Tokenizer<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"sentence"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"token"</span><span class="o">)</span>

<span class="nb">seq</span> <span class="o">=</span> BertForSequenceClassification.pretrained<span class="o">(</span><span class="s1">'bert_sequence_classifier_question_statement_clinical'</span>, <span class="s1">'en'</span>, <span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"token"</span>, <span class="s2">"sentence"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"label"</span><span class="o">)</span><span class="se">\</span>
  .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

pipeline <span class="o">=</span> Pipeline<span class="o">(</span>stages <span class="o">=</span> <span class="o">[</span>
    documentAssembler,
    sentenceDetector,
    tokenizer,
    <span class="nb">seq</span><span class="o">])</span>

test_sentences <span class="o">=</span> <span class="o">[</span><span class="s2">"""Hello I am going to be having a baby throughand have just received my medical results before I have my tubes tested. I had the tests on day 23 of my cycle. My progresterone level is 10. What does this mean? What does progesterone level of 10 indicate?
Your progesterone report is perfectly normal. We expect this result on day 23rd of the cycle.So there's nothing to worry as it's perfectly alright"""</span><span class="o">]</span>

res <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: test_sentences<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------------------------------------------------------------------------------------------------+---------+
|sentence                                                                                                            |label    |
+--------------------------------------------------------------------------------------------------------------------+---------+
|Hello I am going to be having a baby throughand have just received my medical results before I have my tubes tested.|statement|
|I had the tests on day 23 of my cycle.                                                                              |statement|
|My progresterone level is 10.                                                                                       |statement|
|What does this mean?                                                                                                |question |
|What does progesterone level of 10 indicate?                                                                        |question |
|Your progesterone report is perfectly normal. We expect this result on day 23rd of the cycle.                       |statement|
|So there<span class="s1">'s nothing to worry as it'</span>s perfectly alright                                                               |statement|
+--------------------------------------------------------------------------------------------------------------------+---------
</code></pre></div></div>

<p><em>Metrics</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

    question       0.97      0.94      0.96       243
   statement       0.98      0.99      0.99       729

    accuracy                           0.98       972
   macro avg       0.98      0.97      0.97       972
weighted avg       0.98      0.98      0.98       972
</code></pre></div></div>

<h4 id="new-sentence-entity-resolver-fine-tune-features-overwriting-and-drop-code">New Sentence Entity Resolver Fine-Tune Features (Overwriting and Drop Code)</h4>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.setOverwriteExistingCode()</code> : This parameter provides overwriting codes over the existing codes if in pretrained Sentence Entity Resolver Model. For example, you want to add a new term to a pretrained resolver model, and if the code of term already exists in the pretrained model, when you <code class="language-plaintext highlighter-rouge">.setOverwriteExistingCode(True)</code>, it removes all the same codes and their descriptions from the model, then you will have just the new term with its code in the fine-tuned model.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.setDropCodesList()</code> : This parameter drops list of codes from a pretrained Sentence Entity Resolver Model.</p>
  </li>
</ul>

<p>For more examples, please check <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.1.Finetuning_Sentence_Entity_Resolver_Model.ipynb">Fine-Tuning Sentence Entity Resolver Notebook</a></p>

<h4 id="updated-icd10cm-entity-resolver-models">Updated ICD10CM Entity Resolver Models</h4>

<p>We have updated <code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented</code> model with <a href="https://www.cdc.gov/nchs/icd/icd10cm.htm">ICD10CM 2022 Dataset</a> and <code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented_billable_hcc</code> model by dropping invalid codes.</p>

<h4 id="updated-ner-profiling-pretrained-pipelines">Updated NER Profiling Pretrained Pipelines</h4>

<p>We have updated <code class="language-plaintext highlighter-rouge">ner_profiling_clinical</code> and <code class="language-plaintext highlighter-rouge">ner_profiling_biobert</code> pretrained pipelines by adding new clinical NER models and NER model outputs to the previous versions. In this way, you can see all the NER labels of tokens. For examples, please check <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.2.Pretrained_NER_Profiling_Pipelines.ipynb">NER Profiling Pretrained Pipeline Notebook</a>.</p>

<h4 id="new-chunksentencesplitter-annotator">New ChunkSentenceSplitter Annotator</h4>

<ul>
  <li>We are releasing <code class="language-plaintext highlighter-rouge">ChunkSentenceSplitter</code> annotator that splits documents or sentences by chunks provided. Splitted parts can be named with the splitting chunks. By using this annotator, you can do some some tasks like splitting clinical documents according into sections in accordance with CDA (Clinical Document Architecture).</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Header"</span><span class="p">])</span>

<span class="n">chunkSentenceSplitter</span> <span class="o">=</span> <span class="n">ChunkSentenceSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"paragraphs"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGroupBySentences</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDefaultEntity</span><span class="p">(</span><span class="s">"Intro"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInsertChunk</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>        
<span class="p">...</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""INTRODUCTION: Right pleural effusion and suspected malignant mesothelioma.
PREOPERATIVE DIAGNOSIS:  Right pleural effusion and suspected malignant mesothelioma.
POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignant mesothelioma.
PROCEDURE:  Right VATS pleurodesis and pleural biopsy."""</span><span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------------------------------------------------------------+------+
|                                                                result|entity|
+----------------------------------------------------------------------+------+
|INTRODUCTION: Right pleural effusion and suspected malignant mesoth...|Header|
|PREOPERATIVE DIAGNOSIS:  Right pleural effusion and suspected malig...|Header|
|POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignan...|Header|
|                 PROCEDURE:  Right VATS pleurodesis and pleural biopsy|Header|
+----------------------------------------------------------------------+------+
</code></pre></div></div>

<ul>
  <li>By using <code class="language-plaintext highlighter-rouge">.setInsertChunk()</code> parameter you can remove the chunk from splitted parts.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chunkSentenceSplitter</span> <span class="o">=</span> <span class="n">ChunkSentenceSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"paragraphs"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGroupBySentences</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDefaultEntity</span><span class="p">(</span><span class="s">"Intro"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInsertChunk</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">paragraphs</span> <span class="o">=</span> <span class="n">chunkSentenceSplitter</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">paragraphs</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(paragraphs) as result"</span><span class="p">)</span>\
               <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"result.result"</span><span class="p">,</span>
                           <span class="s">"result.metadata.entity"</span><span class="p">,</span>
                           <span class="s">"result.metadata.splitter_chunk"</span><span class="p">)</span>

</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------------------------------+------+------------------------+
|                                            result|entity|          splitter_chunk|
+--------------------------------------------------+------+------------------------+
| Right pleural effusion and suspected malignant...|Header|           INTRODUCTION:|
|  Right pleural effusion and suspected malignan...|Header| PREOPERATIVE DIAGNOSIS:|
| Right pleural effusion, suspected malignant me...|Header|POSTOPERATIVE DIAGNOSIS:|
|         Right VATS pleurodesis and pleural biopsy|Header|              PROCEDURE:|
+--------------------------------------------------+------+------------------------+
</code></pre></div></div>

<h4 id="updated-spark-nlp-for-healthcare-notebooks">Updated Spark NLP For Healthcare Notebooks</h4>

<ul>
  <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.2.Pretrained_NER_Profiling_Pipelines.ipynb">NER Profiling Pretrained Pipeline Notebook</a> .</li>
  <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.1.Finetuning_Sentence_Entity_Resolver_Model.ipynb">Fine-Tuning Sentence Entity Resolver Notebook</a></li>
</ul>

<p><strong>To see more, please check : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></strong></p>

<h2 id="331">3.3.1</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.3.1 has been released!.</p>

<h4 id="highlights-8">Highlights</h4>
<ul>
  <li>New ChunkKeyPhraseExtraction Annotator</li>
  <li>New BERT-Based NER Models</li>
  <li>New UMLS Sentence Entity Resolver Models</li>
  <li>Updated RxNorm Entity Resolver Model (Dropping Invalid Codes)</li>
  <li>New showVersion() Method in Compatibility Class</li>
  <li>New Docker Images for Spark NLP for Healthcare and Spark OCR</li>
  <li>New and Updated Deidentification() Parameters</li>
  <li>New Python API Documentation</li>
  <li>Updated Spark NLP For Healthcare Notebooks and New Notebooks</li>
</ul>

<h4 id="new-chunkkeyphraseextraction-annotator">New ChunkKeyPhraseExtraction Annotator</h4>

<p>We are releasing <code class="language-plaintext highlighter-rouge">ChunkKeyPhraseExtraction</code> annotator that leverages Sentence BERT embeddings to select keywords and key phrases that are most similar to a document. This annotator can be fed by either the output of NER model, NGramGenerator or YAKE, and could be used to generate similarity scores for each NER chunk that is coming out of any (clinical) NER model. That is, you can now sort your clinical entities by the importance of them with respect to document or sentence that they live in. Additionally, you can also use this new annotator to grab new clinical chunks that are missed by a pretrained NER model as well as summarizing the whole document into a few important sentences or phrases.</p>

<p>You can find more examples in <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/9.Chunk_Key_Phrase_Extraction.ipynb">ChunkKeyPhraseExtraction notebook</a></p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
ngram_ner_key_phrase_extractor <span class="o">=</span> ChunkKeyPhraseExtraction.pretrained<span class="o">(</span><span class="s2">"sbert_jsl_medium_uncased "</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setTopN<span class="o">(</span>5<span class="o">)</span> <span class="se">\</span>
    .setDivergence<span class="o">(</span>0.4<span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentences"</span>, <span class="s2">"merged_chunks"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"key_phrases"</span><span class="o">)</span>
...

text <span class="o">=</span> <span class="s2">"A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly, her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were: serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27. Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia ."</span>


textDF <span class="o">=</span> spark.createDataFrame<span class="o">([[</span>text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span>
ngram_ner_results <span class="o">=</span>  ngram_ner_pipeline.transform<span class="o">(</span>textDF<span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------------+------+-------------------+-------------------+--------+
|key_phrase                |source|DocumentSimilarity |MMRScore           |sentence|
+--------------------------+------+-------------------+-------------------+--------+
|type two diabetes mellitus|NER   |0.7639750686118073 |0.4583850593816694 |0       |
|HTG-induced pancreatitis  |ngrams|0.66933222897749   |0.10416352343367463|0       |
|vomiting                  |ngrams|0.5824238088130589 |0.14864183399720493|0       |
|history polyuria          |ngrams|0.46337313737310987|0.0959500325843913 |0       |
|28-year-old female        |ngrams|0.31692529374916967|0.10043002919664669|0       |
+--------------------------+------+-------------------+-------------------+--------+
</code></pre></div></div>

<h4 id="new-bert-based-ner-models">New BERT-Based NER Models</h4>

<p>We have two new BERT-Based token classifier NER models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_chemicals</code> : This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_chemicals</code> model and can detect chemical compounds (<code class="language-plaintext highlighter-rouge">CHEM</code>) in the medical texts.</li>
</ul>

<p><em>Metrics</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support
      B-CHEM       0.94      0.92      0.93     30731
      I-CHEM       0.95      0.93      0.94     31270
    accuracy                           0.99     62001
   macro avg       0.96      0.95      0.96     62001
weighted avg       0.99      0.93      0.96     62001
</code></pre></div></div>

<p><em>Example</em> :</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">...</span>
<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_token_classifier_ner_chemicals"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="p">...</span>

<span class="n">test_sentence</span> <span class="o">=</span> <span class="s">"""The results have shown that the product p - choloroaniline is not a significant factor in chlorhexidine - digluconate associated erosive cystitis. A high percentage of kanamycin - colistin and povidone - iodine irrigations were associated with erosive cystitis."""</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">p_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">test_sentence</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------------------------+---------+
|chunk                      |ner_label|
+---------------------------+---------+
|p - choloroaniline         |CHEM     |
|chlorhexidine - digluconate|CHEM     |
|kanamycin                  |CHEM     |
|colistin                   |CHEM     |
|povidone - iodine          |CHEM     |
+---------------------------+---------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_chemprot</code> : This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_chemprot_clinical</code> model and can detect chemical compounds and genes (<code class="language-plaintext highlighter-rouge">CHEMICAL</code>, <code class="language-plaintext highlighter-rouge">GENE-Y</code>, <code class="language-plaintext highlighter-rouge">GENE-N</code>) in the medical texts.</li>
</ul>

<p><em>Metrics</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support
  B-CHEMICAL       0.80      0.79      0.80      8649
    B-GENE-N       0.53      0.56      0.54      2752
    B-GENE-Y       0.71      0.73      0.72      5490
  I-CHEMICAL       0.82      0.79      0.81      1313
    I-GENE-N       0.62      0.62      0.62      1993
    I-GENE-Y       0.75      0.72      0.74      2420
    accuracy                           0.96     22617
   macro avg       0.75      0.74      0.75     22617
weighted avg       0.83      0.73      0.78     22617
</code></pre></div></div>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_chemprot"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
    .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>
...

test_sentence <span class="o">=</span> <span class="s2">"Keratinocyte growth factor and acidic fibroblast growth factor are mitogens for primary cultures of mammary epithelium."</span>
result <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>test_sentence]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------+---------+
|chunk                          |ner_label|
+-------------------------------+---------+
|Keratinocyte growth <span class="nb">factor</span>     |GENE-Y   |
|acidic fibroblast growth <span class="nb">factor</span>|GENE-Y   |
+-------------------------------+---------+
</code></pre></div></div>

<h4 id="new-umls-sentence-entity-resolver-models">New UMLS Sentence Entity Resolver Models</h4>

<p>We are releasing two new UMLS Sentence Entity Resolver models trained on 2021AB UMLS dataset and map clinical entities to UMLS CUI codes.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_disease_syndrome</code> : This model is trained on the <code class="language-plaintext highlighter-rouge">Disease</code> or <code class="language-plaintext highlighter-rouge">Syndrome</code> category using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> embeddings.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_umls_disease_syndrome"</span>,<span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
     .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span> <span class="se">\</span>
     .setOutputCol<span class="o">(</span><span class="s2">"resolution"</span><span class="o">)</span><span class="se">\</span>
     .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

data <span class="o">=</span> spark.createDataFrame<span class="o">([[</span><span class="s2">"""A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, associated with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting."""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span>
results <span class="o">=</span> model.fit<span class="o">(</span>data<span class="o">)</span>.transform<span class="o">(</span>data<span class="o">)</span>

</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                                 | code     | code_description                      | all_k_codes                                                  | all_k_codes_desc                                                                                                                                                                                         |
|---:|:--------------------------------------|:---------|:--------------------------------------|:-------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | gestational diabetes mellitus         | C0085207 | gestational diabetes mellitus         | <span class="o">[</span><span class="s1">'C0085207'</span>, <span class="s1">'C0032969'</span>, <span class="s1">'C2063017'</span>, <span class="s1">'C1283034'</span>, <span class="s1">'C0271663'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'pregnancy diabetes mellitus'</span>, <span class="s1">'pregnancy complicated by diabetes mellitus'</span>, <span class="s1">'maternal diabetes mellitus'</span>, <span class="s1">'gestational diabetes mellitus, a2'</span><span class="o">]</span>                        |
|  1 | subsequent <span class="nb">type </span>two diabetes mellitus | C0348921 | pre-existing <span class="nb">type </span>2 diabetes mellitus | <span class="o">[</span><span class="s1">'C0348921'</span>, <span class="s1">'C1719939'</span>, <span class="s1">'C0011860'</span>, <span class="s1">'C0877302'</span>, <span class="s1">'C0271640'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'pre-existing type 2 diabetes mellitus'</span>, <span class="s1">'disorder associated with type 2 diabetes mellitus'</span>, <span class="s1">'diabetes mellitus, type 2'</span>, <span class="s1">'insulin-requiring type 2 diabetes mellitus'</span>, <span class="s1">'secondary diabetes mellitus'</span><span class="o">]</span> |
|  2 | HTG-induced pancreatitis              | C0376670 | alcohol-induced pancreatitis          | <span class="o">[</span><span class="s1">'C0376670'</span>, <span class="s1">'C1868971'</span>, <span class="s1">'C4302243'</span>, <span class="s1">'C0267940'</span>, <span class="s1">'C2350449'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'alcohol-induced pancreatitis'</span>, <span class="s1">'toxic pancreatitis'</span>, <span class="s1">'igg4-related pancreatitis'</span>, <span class="s1">'hemorrhage pancreatitis'</span>, <span class="s1">'graft pancreatitis'</span><span class="o">]</span>                                                                     |
|  3 | an acute hepatitis                    | C0019159 | acute hepatitis                       | <span class="o">[</span><span class="s1">'C0019159'</span>, <span class="s1">'C0276434'</span>, <span class="s1">'C0267797'</span>, <span class="s1">'C1386146'</span>, <span class="s1">'C2063407'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'acute hepatitis a'</span>, <span class="s1">'acute hepatitis a'</span>, <span class="s1">'acute hepatitis'</span>, <span class="s1">'acute infectious hepatitis'</span>, <span class="s1">'acute hepatitis e'</span><span class="o">]</span>                                                                                         |
|  4 | obesity                               | C0028754 | obesity                               | <span class="o">[</span><span class="s1">'C0028754'</span>, <span class="s1">'C0342940'</span>, <span class="s1">'C0342942'</span>, <span class="s1">'C0857116'</span>, <span class="s1">'C1561826'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'obesity'</span>, <span class="s1">'abdominal obesity'</span>, <span class="s1">'generalized obesity'</span>, <span class="s1">'obesity gross'</span>, <span class="s1">'overweight and obesity'</span><span class="o">]</span>                                                                                                       |
|  5 | polyuria                              | C0018965 | hematuria                             | <span class="o">[</span><span class="s1">'C0018965'</span>, <span class="s1">'C0151582'</span>, <span class="s1">'C3888890'</span>, <span class="s1">'C0268556'</span>, <span class="s1">'C2936921'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'hematuria'</span>, <span class="s1">'uricosuria'</span>, <span class="s1">'polyuria-polydipsia syndrome'</span>, <span class="s1">'saccharopinuria'</span>, <span class="s1">'saccharopinuria'</span><span class="o">]</span>                                                                                                        |
|  6 | polydipsia                            | C0268813 | primary polydipsia                    | <span class="o">[</span><span class="s1">'C0268813'</span>, <span class="s1">'C0030508'</span>, <span class="s1">'C3888890'</span>, <span class="s1">'C0393777'</span>, <span class="s1">'C0206085'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'primary polydipsia'</span>, <span class="s1">'parasomnia'</span>, <span class="s1">'polyuria-polydipsia syndrome'</span>, <span class="s1">'hypnogenic paroxysmal dystonias'</span>, <span class="s1">'periodic hypersomnias'</span><span class="o">]</span>                                                                         |
|  7 | poor appetite                         | C0003123 | lack of appetite                      | <span class="o">[</span><span class="s1">'C0003123'</span>, <span class="s1">'C0011168'</span>, <span class="s1">'C0162429'</span>, <span class="s1">'C1282895'</span>, <span class="s1">'C0039338'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'lack of appetite'</span>, <span class="s1">'poor swallowing'</span>, <span class="s1">'poor nutrition'</span>, <span class="s1">'neurologic unpleasant taste'</span>, <span class="s1">'taste dis'</span><span class="o">]</span>                                                                                                    |
|  8 | vomiting                              | C0152164 | periodic vomiting                     | <span class="o">[</span><span class="s1">'C0152164'</span>, <span class="s1">'C0267172'</span>, <span class="s1">'C0152517'</span>, <span class="s1">'C0011119'</span>, <span class="s1">'C0152227'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'periodic vomiting'</span>, <span class="s1">'habit vomiting'</span>, <span class="s1">'viral vomiting'</span>, <span class="s1">'choking'</span>, <span class="s1">'tearing'</span><span class="o">]</span>                                                                                                                          |
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_clinical_drugs</code> : This model is trained on the <code class="language-plaintext highlighter-rouge">Clinical Drug</code> category using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> embeddings.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_umls_clinical_drugs"</span>,<span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
     .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span> <span class="se">\</span>
     .setOutputCol<span class="o">(</span><span class="s2">"resolution"</span><span class="o">)</span><span class="se">\</span>
     .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
...

data <span class="o">=</span> spark.createDataFrame<span class="o">([[</span><span class="s2">"""She was immediately given hydrogen peroxide 30 mg to treat the infection on her leg, and has been advised Neosporin Cream for 5 days. She has a history of taking magnesium hydroxide 100mg/1ml and metformin 1000 mg."""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span>
results <span class="o">=</span> model.fit<span class="o">(</span>data<span class="o">)</span>.transform<span class="o">(</span>data<span class="o">)</span>

</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                         | code     | code_description           | all_k_codes                                                  | all_k_codes_desc                                                                                                                                                                        |
|---:|:------------------------------|:---------|:---------------------------|:-------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | hydrogen peroxide 30 mg       | C1126248 | hydrogen peroxide 30 mg/ml | <span class="o">[</span><span class="s1">'C1126248'</span>, <span class="s1">'C0304655'</span>, <span class="s1">'C1605252'</span>, <span class="s1">'C0304656'</span>, <span class="s1">'C1154260'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'hydrogen peroxide 30 mg/ml'</span>, <span class="s1">'hydrogen peroxide solution 30%'</span>, <span class="s1">'hydrogen peroxide 30 mg/ml [proxacol]'</span>, <span class="s1">'hydrogen peroxide 30 mg/ml cutaneous solution'</span>, <span class="s1">'benzoyl peroxide 30 mg/ml'</span><span class="o">]</span> |
|  1 | Neosporin Cream               | C0132149 | neosporin cream            | <span class="o">[</span><span class="s1">'C0132149'</span>, <span class="s1">'C0358174'</span>, <span class="s1">'C0357999'</span>, <span class="s1">'C0307085'</span>, <span class="s1">'C0698810'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'neosporin cream'</span>, <span class="s1">'nystan cream'</span>, <span class="s1">'nystadermal cream'</span>, <span class="s1">'nupercainal cream'</span>, <span class="s1">'nystaform cream'</span><span class="o">]</span>                                                                                        |
|  2 | magnesium hydroxide 100mg/1ml | C1134402 | magnesium hydroxide 100 mg | <span class="o">[</span><span class="s1">'C1134402'</span>, <span class="s1">'C1126785'</span>, <span class="s1">'C4317023'</span>, <span class="s1">'C4051486'</span>, <span class="s1">'C4047137'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'magnesium hydroxide 100 mg'</span>, <span class="s1">'magnesium hydroxide 100 mg/ml'</span>, <span class="s1">'magnesium sulphate 100mg/ml injection'</span>, <span class="s1">'magnesium sulfate 100 mg'</span>, <span class="s1">'magnesium sulfate 100 mg/ml'</span><span class="o">]</span>                     |
|  3 | metformin 1000 mg             | C0987664 | metformin 1000 mg          | <span class="o">[</span><span class="s1">'C0987664'</span>, <span class="s1">'C2719784'</span>, <span class="s1">'C0978482'</span>, <span class="s1">'C2719786'</span>, <span class="s1">'C4282269'</span><span class="o">]</span> | <span class="o">[</span><span class="s1">'metformin 1000 mg'</span>, <span class="s1">'metformin hydrochloride 1000 mg'</span>, <span class="s1">'metformin hcl 1000mg tab'</span>, <span class="s1">'metformin hydrochloride 1000 mg [fortamet]'</span>, <span class="s1">'metformin hcl 1000mg sa tab'</span><span class="o">]</span>                       |

</code></pre></div></div>

<h4 id="updated-rxnorm-entity-resolver-model-dropping-invalid-codes">Updated RxNorm Entity Resolver Model (Dropping Invalid Codes)</h4>

<p><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm</code> model was updated by dropping invalid codes using 02 August 2021 RxNorm dataset.</p>

<h4 id="new-showversion-method-in-compatibility-class">New showVersion() Method in Compatibility Class</h4>

<p>We added the <code class="language-plaintext highlighter-rouge">.showVersion()</code> method in our Compatibility class that shows the name of the models and the version in a pretty way.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">compatibility</span> <span class="o">=</span> <span class="n">Compatibility</span><span class="p">()</span>
<span class="n">compatibility</span><span class="p">.</span><span class="n">showVersion</span><span class="p">(</span><span class="s">'sentence_detector_dl_healthcare'</span><span class="p">)</span>
</code></pre></div></div>
<p>After the execution you will see the following table,</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+---------------------------------+------+---------+
| Pipeline/Model                  | lang | version |
+---------------------------------+------+---------+
| sentence_detector_dl_healthcare |  en  | 2.6.0   |
| sentence_detector_dl_healthcare |  en  | 2.7.0   |
| sentence_detector_dl_healthcare |  en  | 3.2.0   |
+---------------------------------+------+---------+
</code></pre></div></div>

<h4 id="new-docker-images-for-spark-nlp-for-healthcare-and-spark-ocr">New Docker Images for Spark NLP for Healthcare and Spark OCR</h4>

<p>We are releasing new Docker Images for Spark NLP for Healthcare and Spark OCR containing a jupyter environment. Users having a valid license can run the image on their local system, and connect to pre-configured jupyter instance without installing the library on their local system.</p>

<p><strong>Spark NLP for Healthcare Docker Image</strong></p>

<p>For running Spark NLP for Healthcare inside a container:</p>

<ul>
  <li>
    <p>Instructions: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/docker_image_nlp_hc">Spark NLP for Healthcare Docker Image</a></p>
  </li>
  <li>
    <p>Video Instructions: <a href="https://www.youtube.com/watch?v=tgN0GZGMVJk">Youtube Video</a></p>
  </li>
</ul>

<p><strong>Spark NLP for Healthcare &amp; OCR Docker Image</strong></p>

<p>For users who want to run Spark OCR and then feed the output of OCR pipeline to healthcare modules to process further:</p>

<ul>
  <li>Instructions: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/docker_image_ocr">Spark NLP for Healthcare &amp; OCR Docker Image</a></li>
</ul>

<h4 id="new-and-updated-deidentification-parameters">New and Updated Deidentification() Parameters</h4>

<p><em>New Parameter</em> :</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">setBlackList()</code> : List of entities <strong>ignored</strong> for masking or obfuscation.The default values are: <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">PASSPORT</code>, <code class="language-plaintext highlighter-rouge">DLN</code>, <code class="language-plaintext highlighter-rouge">NPI</code>, <code class="language-plaintext highlighter-rouge">C_CARD</code>, <code class="language-plaintext highlighter-rouge">IBAN</code>, <code class="language-plaintext highlighter-rouge">DEA</code>.</li>
</ul>

<p><em>Updated Parameter</em> :</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">.setObfuscateRefSource()</code> : It was set <code class="language-plaintext highlighter-rouge">faker</code> as default.</li>
</ul>

<h4 id="new-python-api-documentation">New Python API Documentation</h4>

<p>We have new Spark NLP for Healthcare <a href="https://nlp.johnsnowlabs.com/licensed/api/python/">Python API Documentation</a> . This page contains information how to use the library with Python examples.</p>

<h4 id="updated-spark-nlp-for-healthcare-notebooks-and-new-notebooks">Updated Spark NLP For Healthcare Notebooks and New Notebooks</h4>

<ul>
  <li>
    <p>New <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.6.BertForTokenClassification_NER_SparkNLP_with_Transformers.ipynb">BertForTokenClassification NER Model Training with Transformers Notebook</a> for showing how to train a BertForTokenClassification NER model with transformers and then import into Spark NLP.</p>
  </li>
  <li>
    <p>New <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/9.Chunk_Key_Phrase_Extraction.ipynb">ChunkKeyPhraseExtraction notebook</a> for showing how to get chunk key phrases using <code class="language-plaintext highlighter-rouge">ChunkKeyPhraseExtraction</code>.</p>
  </li>
  <li>
    <p>Updated all <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP For Healthcare Notebooks</a> with v3.3.0 by adding the new features.</p>
  </li>
</ul>

<p><strong>To see more, please check : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></strong></p>

<h2 id="330">3.3.0</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.3.0 has been released!.</p>

<h4 id="highlights-9">Highlights</h4>
<ul>
  <li>NER Finder Pretrained Pipelines to Run Run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text</li>
  <li>3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS)</li>
  <li>Updated UMLS Entity Resolvers (Dropping Invalid Codes)</li>
  <li>5 New Clinical NER Models (Trained By BertForTokenClassification Approach)</li>
  <li>Radiology NER Model Trained On cheXpert Dataset</li>
  <li>New Speed Benchmarks on Databricks</li>
  <li>NerConverterInternal Fixes</li>
  <li>Simplified Setup and Recommended Use of start() Function</li>
  <li>NER Evaluation Metrics Fix</li>
  <li>New Notebooks (Including How to Use SparkNLP with Neo4J)</li>
</ul>

<h4 id="ner-finder-pretrained-pipelines-to-run-run-48-different-clinical-ner-and-21-different-biobert-models-at-once-over-the-input-text">NER Finder Pretrained Pipelines to Run Run 48 different Clinical NER and 21 Different Biobert Models At Once Over the Input Text</h4>

<p>We are releasing two new NER Pretrained Pipelines that can be used to explore all the available pretrained NER models at once. You can check <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.2.Pretrained_NER_Profiling_Pipelines.ipynb">NER Profiling Notebook</a> to see how to use these pretrained pipelines.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_profiling_clinical</code> : When you run this pipeline over your text, you will end up with the predictions coming out of each of the 48 pretrained clinical NER models trained with <code class="language-plaintext highlighter-rouge">embeddings_clinical</code>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Clinical NER Model List</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ner_ade_clinical</td>
    </tr>
    <tr>
      <td>ner_posology_greedy</td>
    </tr>
    <tr>
      <td>ner_risk_factors</td>
    </tr>
    <tr>
      <td>jsl_ner_wip_clinical</td>
    </tr>
    <tr>
      <td>ner_human_phenotype_gene_clinical</td>
    </tr>
    <tr>
      <td>jsl_ner_wip_greedy_clinical</td>
    </tr>
    <tr>
      <td>ner_cellular</td>
    </tr>
    <tr>
      <td>ner_cancer_genetics</td>
    </tr>
    <tr>
      <td>jsl_ner_wip_modifier_clinical</td>
    </tr>
    <tr>
      <td>ner_drugs_greedy</td>
    </tr>
    <tr>
      <td>ner_deid_sd_large</td>
    </tr>
    <tr>
      <td>ner_diseases</td>
    </tr>
    <tr>
      <td>nerdl_tumour_demo</td>
    </tr>
    <tr>
      <td>ner_deid_subentity_augmented</td>
    </tr>
    <tr>
      <td>ner_jsl_enriched</td>
    </tr>
    <tr>
      <td>ner_genetic_variants</td>
    </tr>
    <tr>
      <td>ner_bionlp</td>
    </tr>
    <tr>
      <td>ner_measurements_clinical</td>
    </tr>
    <tr>
      <td>ner_diseases_large</td>
    </tr>
    <tr>
      <td>ner_radiology</td>
    </tr>
    <tr>
      <td>ner_deid_augmented</td>
    </tr>
    <tr>
      <td>ner_anatomy</td>
    </tr>
    <tr>
      <td>ner_chemprot_clinical</td>
    </tr>
    <tr>
      <td>ner_posology_experimental</td>
    </tr>
    <tr>
      <td>ner_drugs</td>
    </tr>
    <tr>
      <td>ner_deid_sd</td>
    </tr>
    <tr>
      <td>ner_posology_large</td>
    </tr>
    <tr>
      <td>ner_deid_large</td>
    </tr>
    <tr>
      <td>ner_posology</td>
    </tr>
    <tr>
      <td>ner_deidentify_dl</td>
    </tr>
    <tr>
      <td>ner_deid_enriched</td>
    </tr>
    <tr>
      <td>ner_bacterial_species</td>
    </tr>
    <tr>
      <td>ner_drugs_large</td>
    </tr>
    <tr>
      <td>ner_clinical_large</td>
    </tr>
    <tr>
      <td>jsl_rd_ner_wip_greedy_clinical</td>
    </tr>
    <tr>
      <td>ner_medmentions_coarse</td>
    </tr>
    <tr>
      <td>ner_radiology_wip_clinical</td>
    </tr>
    <tr>
      <td>ner_clinical</td>
    </tr>
    <tr>
      <td>ner_chemicals</td>
    </tr>
    <tr>
      <td>ner_deid_synthetic</td>
    </tr>
    <tr>
      <td>ner_events_clinical</td>
    </tr>
    <tr>
      <td>ner_posology_small</td>
    </tr>
    <tr>
      <td>ner_anatomy_coarse</td>
    </tr>
    <tr>
      <td>ner_human_phenotype_go_clinical</td>
    </tr>
    <tr>
      <td>ner_jsl_slim</td>
    </tr>
    <tr>
      <td>ner_jsl</td>
    </tr>
    <tr>
      <td>ner_jsl_greedy</td>
    </tr>
    <tr>
      <td>ner_events_admission_clinical</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_profiling_biobert</code> : When you run this pipeline over your text, you will end up with the predictions coming out of each of the 21 pretrained clinical NER models trained with <code class="language-plaintext highlighter-rouge">biobert_pubmed_base_cased</code>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>BioBert NER Model List</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ner_cellular_biobert</td>
    </tr>
    <tr>
      <td>ner_diseases_biobert</td>
    </tr>
    <tr>
      <td>ner_events_biobert</td>
    </tr>
    <tr>
      <td>ner_bionlp_biobert</td>
    </tr>
    <tr>
      <td>ner_jsl_greedy_biobert</td>
    </tr>
    <tr>
      <td>ner_jsl_biobert</td>
    </tr>
    <tr>
      <td>ner_anatomy_biobert</td>
    </tr>
    <tr>
      <td>ner_jsl_enriched_biobert</td>
    </tr>
    <tr>
      <td>ner_human_phenotype_go_biobert</td>
    </tr>
    <tr>
      <td>ner_deid_biobert</td>
    </tr>
    <tr>
      <td>ner_deid_enriched_biobert</td>
    </tr>
    <tr>
      <td>ner_clinical_biobert</td>
    </tr>
    <tr>
      <td>ner_anatomy_coarse_biobert</td>
    </tr>
    <tr>
      <td>ner_human_phenotype_gene_biobert</td>
    </tr>
    <tr>
      <td>ner_posology_large_biobert</td>
    </tr>
    <tr>
      <td>jsl_rd_ner_wip_greedy_biobert</td>
    </tr>
    <tr>
      <td>ner_posology_biobert</td>
    </tr>
    <tr>
      <td>jsl_ner_wip_greedy_biobert</td>
    </tr>
    <tr>
      <td>ner_chemprot_biobert</td>
    </tr>
    <tr>
      <td>ner_ade_biobert</td>
    </tr>
    <tr>
      <td>ner_risk_factors_biobert</td>
    </tr>
  </tbody>
</table>

<p>You can also check <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a> page for more information about all these NER models and more.</p>

<p><em>Example</em> :</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
ner_profiling_pipeline = PretrainedPipeline('ner_profiling_biobert', 'en', 'clinical/models')

result = ner_profiling_pipeline.annotate("A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .")
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sentence :  <span class="o">[</span><span class="s1">'A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .'</span><span class="o">]</span>
token :  <span class="o">[</span><span class="s1">'A'</span>, <span class="s1">'28-year-old'</span>, <span class="s1">'female'</span>, <span class="s1">'with'</span>, <span class="s1">'a'</span>, <span class="s1">'history'</span>, <span class="s1">'of'</span>, <span class="s1">'gestational'</span>, <span class="s1">'diabetes'</span>, <span class="s1">'mellitus'</span>, <span class="s1">'diagnosed'</span>, <span class="s1">'eight'</span>, <span class="s1">'years'</span>, <span class="s1">'prior'</span>, <span class="s1">'to'</span>, <span class="s1">'presentation'</span>, <span class="s1">'and'</span>, <span class="s1">'subsequent'</span>, <span class="s1">'type'</span>, <span class="s1">'two'</span>, <span class="s1">'diabetes'</span>, <span class="s1">'mellitus'</span>, <span class="s1">'('</span>, <span class="s1">'T2DM'</span>, <span class="s1">'),'</span>, <span class="s1">'one'</span>, <span class="s1">'prior'</span>, <span class="s1">'episode'</span>, <span class="s1">'of'</span>, <span class="s1">'HTG-induced'</span>, <span class="s1">'pancreatitis'</span>, <span class="s1">'three'</span>, <span class="s1">'years'</span>, <span class="s1">'prior'</span>, <span class="s1">'to'</span>, <span class="s1">'presentation'</span>, <span class="s1">','</span>, <span class="s1">'associated'</span>, <span class="s1">'with'</span>, <span class="s1">'an'</span>, <span class="s1">'acute'</span>, <span class="s1">'hepatitis'</span>, <span class="s1">','</span>, <span class="s1">'and'</span>, <span class="s1">'obesity'</span>, <span class="s1">'with'</span>, <span class="s1">'a'</span>, <span class="s1">'body'</span>, <span class="s1">'mass'</span>, <span class="s1">'index'</span>, <span class="s1">'('</span>, <span class="s1">'BMI'</span>, <span class="s1">')'</span>, <span class="s1">'of'</span>, <span class="s1">'33.5'</span>, <span class="s1">'kg/m2'</span>, <span class="s1">','</span>, <span class="s1">'presented'</span>, <span class="s1">'with'</span>, <span class="s1">'a'</span>, <span class="s1">'one-week'</span>, <span class="s1">'history'</span>, <span class="s1">'of'</span>, <span class="s1">'polyuria'</span>, <span class="s1">','</span>, <span class="s1">'polydipsia'</span>, <span class="s1">','</span>, <span class="s1">'poor'</span>, <span class="s1">'appetite'</span>, <span class="s1">','</span>, <span class="s1">'and'</span>, <span class="s1">'vomiting'</span>, <span class="s1">'.'</span><span class="o">]</span>
ner_cellular_biobert_chunks :  <span class="o">[]</span>
ner_diseases_biobert_chunks :  <span class="o">[</span><span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'type two diabetes mellitus'</span>, <span class="s1">'T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_events_biobert_chunks :  <span class="o">[</span><span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'eight years'</span>, <span class="s1">'presentation'</span>, <span class="s1">'type two diabetes mellitus ( T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'three years'</span>, <span class="s1">'presentation'</span>, <span class="s1">'an acute hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'a body mass index'</span>, <span class="s1">'BMI'</span>, <span class="s1">'presented'</span>, <span class="s1">'a one-week'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_bionlp_biobert_chunks :  <span class="o">[]</span>
ner_jsl_greedy_biobert_chunks :  <span class="o">[</span><span class="s1">'28-year-old'</span>, <span class="s1">'female'</span>, <span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'eight years prior'</span>, <span class="s1">'type two diabetes mellitus'</span>, <span class="s1">'T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'three years prior'</span>, <span class="s1">'acute hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'body mass index'</span>, <span class="s1">'BMI ) of 33.5 kg/m2'</span>, <span class="s1">'one-week'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_jsl_biobert_chunks :  <span class="o">[</span><span class="s1">'28-year-old'</span>, <span class="s1">'female'</span>, <span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'eight years prior'</span>, <span class="s1">'type two diabetes mellitus'</span>, <span class="s1">'T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'three years prior'</span>, <span class="s1">'acute'</span>, <span class="s1">'hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'body mass index'</span>, <span class="s1">'BMI ) of 33.5 kg/m2'</span>, <span class="s1">'one-week'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_anatomy_biobert_chunks :  <span class="o">[</span><span class="s1">'body'</span><span class="o">]</span>
ner_jsl_enriched_biobert_chunks :  <span class="o">[</span><span class="s1">'28-year-old'</span>, <span class="s1">'female'</span>, <span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'type two diabetes mellitus'</span>, <span class="s1">'T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'acute'</span>, <span class="s1">'hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_human_phenotype_go_biobert_chunks :  <span class="o">[</span><span class="s1">'obesity'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span><span class="o">]</span>
ner_deid_biobert_chunks :  <span class="o">[</span><span class="s1">'eight years'</span>, <span class="s1">'three years'</span><span class="o">]</span>
ner_deid_enriched_biobert_chunks :  <span class="o">[]</span>
ner_clinical_biobert_chunks :  <span class="o">[</span><span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'subsequent type two diabetes mellitus ( T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'an acute hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'a body mass index ( BMI )'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_anatomy_coarse_biobert_chunks :  <span class="o">[</span><span class="s1">'body'</span><span class="o">]</span>
ner_human_phenotype_gene_biobert_chunks :  <span class="o">[</span><span class="s1">'obesity'</span>, <span class="s1">'mass'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_posology_large_biobert_chunks :  <span class="o">[]</span>
jsl_rd_ner_wip_greedy_biobert_chunks :  <span class="o">[</span><span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'type two diabetes mellitus'</span>, <span class="s1">'T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'acute hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'body mass index'</span>, <span class="s1">'33.5'</span>, <span class="s1">'kg/m2'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_posology_biobert_chunks :  <span class="o">[]</span>
jsl_ner_wip_greedy_biobert_chunks :  <span class="o">[</span><span class="s1">'28-year-old'</span>, <span class="s1">'female'</span>, <span class="s1">'gestational diabetes mellitus'</span>, <span class="s1">'eight years prior'</span>, <span class="s1">'type two diabetes mellitus'</span>, <span class="s1">'T2DM'</span>, <span class="s1">'HTG-induced pancreatitis'</span>, <span class="s1">'three years prior'</span>, <span class="s1">'acute hepatitis'</span>, <span class="s1">'obesity'</span>, <span class="s1">'body mass index'</span>, <span class="s1">'BMI ) of 33.5 kg/m2'</span>, <span class="s1">'one-week'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_chemprot_biobert_chunks :  <span class="o">[]</span>
ner_ade_biobert_chunks :  <span class="o">[</span><span class="s1">'pancreatitis'</span>, <span class="s1">'acute hepatitis'</span>, <span class="s1">'polyuria'</span>, <span class="s1">'polydipsia'</span>, <span class="s1">'poor appetite'</span>, <span class="s1">'vomiting'</span><span class="o">]</span>
ner_risk_factors_biobert_chunks :  <span class="o">[</span><span class="s1">'diabetes mellitus'</span>, <span class="s1">'subsequent type two diabetes mellitus'</span>, <span class="s1">'obesity'</span><span class="o">]</span>
</code></pre></div></div>

<h4 id="3-new-sentence-entity-resolver-models-3-char-icd10cm-rxnorm_ndc-hcpcs">3 New Sentence Entity Resolver Models (3-char ICD10CM, RxNorm_NDC, HCPCS)</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_hcpcs</code> : This model maps extracted medical entities to <a href="https://www.nlm.nih.gov/research/umls/sourcereleasedocs/current/HCPCS/index.html#:~:text=The%20Healthcare%20Common%20Procedure%20Coding,%2C%20supplies%2C%20products%20and%20services.">Healthcare Common Procedure Coding System (HCPCS)</a>
 codes using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> sentence embeddings. It also returns the domain information of the codes in the <code class="language-plaintext highlighter-rouge">all_k_aux_labels</code> parameter in the metadata of the result.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
      .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>
sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s1">'sbiobert_base_cased_mli'</span>, <span class="s1">'en'</span>,<span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"sentence_embeddings"</span><span class="o">)</span>

hcpcs_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_hcpcs"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"hcpcs_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>
hcpcs_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span>
    stages <span class="o">=</span> <span class="o">[</span>
        documentAssembler,
        sbert_embedder,
        hcpcs_resolver]<span class="o">)</span>

res <span class="o">=</span> hcpcs_pipelineModel.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type"</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<table>
  <thead>
    <tr>
      <th>ner_chunk</th>
      <th>hcpcs_code</th>
      <th>all_codes</th>
      <th>all_resolutions</th>
      <th>domain</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type</td>
      <td>L8001</td>
      <td>[L8001, L8002, L8000, L8033, L8032, …]</td>
      <td>‘Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, unilateral, any size, any type’, ‘Breast prosthesis, mastectomy bra, with integrated breast prosthesis form, bilateral, any size, any type’, ‘Breast prosthesis, mastectomy bra, without integrated breast prosthesis form, any size, any type’, ‘Nipple prosthesis, custom fabricated, reusable, any material, any type, each’, …</td>
      <td>Device, Device, Device, Device, Device, …</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_generalised</code> : This model maps medical entities to 3 digit ICD10CM codes (according to ICD10 code structure the first three characters represent general type of the injury or disease). Difference in results (compared with <code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm</code>) can be observed in the example below.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
      .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>
sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s1">'sbiobert_base_cased_mli'</span>, <span class="s1">'en'</span>,<span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"sentence_embeddings"</span><span class="o">)</span>

icd_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_icd10cm_generalised"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"icd_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>

icd_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span>
    stages <span class="o">=</span> <span class="o">[</span>
        documentAssembler,
        sbert_embedder,
        icd_resolver]<span class="o">)</span>

res <span class="o">=</span> icd_pipelineModel.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"82 - year-old male with a history of hypertension , chronic renal insufficiency , COPD , and gastritis"</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                       | entity  | code_3char | code_desc_3char                               | code_full | code_full_description                     |  distance | all_k_resolutions_3char                                                    | all_k_codes_3char                              |
|---:|:----------------------------|:--------|:-----------|:----------------------------------------------|:----------|:------------------------------------------|----------:|:---------------------------------------------------------------------------|:-----------------------------------------------|
|  0 | hypertension                | SYMPTOM | I10        | hypertension                                  | I150      | Renovascular hypertension                 |    0      | <span class="o">[</span>hypertension, hypertension <span class="o">(</span>high blood pressure<span class="o">)</span>, h/o: hypertension, ...] | <span class="o">[</span>I10, I15, Z86, Z82, I11, R03, Z87, E27]       |
|  1 | chronic renal insufficiency | SYMPTOM | N18        | chronic renal impairment                      | N186      | End stage renal disease                   |    0.014  | <span class="o">[</span>chronic renal impairment, renal insufficiency, renal failure, anaemi ...] | <span class="o">[</span>N18, P96, N19, D63, N28, Z87, N17, N25, R94]  |
|  2 | COPD                        | SYMPTOM | J44        | chronic obstructive lung disease <span class="o">(</span>disorder<span class="o">)</span>   | I2781     | Cor pulmonale <span class="o">(</span>chronic<span class="o">)</span>                   |    0.1197 | <span class="o">[</span>chronic obstructive lung disease <span class="o">(</span>disorder<span class="o">)</span>, chronic obstructive pul ...] | <span class="o">[</span>J44, Z76, J81, J96, R06, I27, Z87]            |
|  3 | gastritis                   | SYMPTOM | K29        | gastritis                                     | K5281     | Eosinophilic gastritis or gastroenteritis |    0      | gastritis:::bacterial gastritis:::parasitic gastritis                      | <span class="o">[</span>K29, B96, K93]                                |
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_ndc</code> : This model maps <code class="language-plaintext highlighter-rouge">DRUG</code> entities to rxnorm codes and their <a href="https://www.drugs.com/ndc.html#:~:text=The%20NDC%2C%20or%20National%20Drug,and%20the%20commercial%20package%20size.">National Drug Codes (NDC)</a>
 using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> sentence embeddings. You can find all NDC codes of drugs seperated by <code class="language-plaintext highlighter-rouge">|</code> in the <code class="language-plaintext highlighter-rouge">all_k_aux_labels</code> parameter of the metadata.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
      .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s1">'sbiobert_base_cased_mli'</span>, <span class="s1">'en'</span>,<span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"sentence_embeddings"</span><span class="o">)</span>

rxnorm_ndc_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_rxnorm_ndc"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sentence_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"rxnorm_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>

rxnorm_ndc_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span>
    stages <span class="o">=</span> <span class="o">[</span>
        documentAssembler,
        sbert_embedder,
        rxnorm_ndc_resolver]<span class="o">)</span>

res <span class="o">=</span> rxnorm_ndc_pipelineModel.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"activated charcoal 30000 mg powder for oral suspension"</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<table>
  <thead>
    <tr>
      <th>chunk</th>
      <th>rxnorm_code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>all_k_aux_labels</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>activated charcoal 30000 mg powder for oral suspension</td>
      <td>1440919</td>
      <td>1440919, 808917, 1088194, 1191772, 808921,…</td>
      <td>activated charcoal 30000 MG Powder for Oral Suspension, Activated Charcoal 30000 MG Powder for Oral Suspension, wheat dextrin 3000 MG Powder for Oral Solution [Benefiber], cellulose 3000 MG Oral Powder [Unifiber], fosfomycin 3000 MG Powder for Oral Solution [Monurol] …</td>
      <td>69784030828, 00395052791, 08679001362|86790016280|00067004490, 46017004408|68220004416, 00456430001,…</td>
      <td>0.0000, 0.0000, 0.1128, 0.1148, 0.1201,…</td>
    </tr>
  </tbody>
</table>

<h4 id="updated-umls-entity-resolvers-dropping-invalid-codes">Updated UMLS Entity Resolvers (Dropping Invalid Codes)</h4>

<p>UMLS model <code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_findings</code> and <code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_major_concepts</code> were updated by dropping the invalid codes using the <a href="https://www.nlm.nih.gov/pubs/techbull/mj21/mj21_umls_2021aa_release.html">latest UMLS release</a> done May 2021.</p>

<h4 id="5-new-clinical-ner-models-trained-by-bertfortokenclassification-approach">5 New Clinical NER Models (Trained By BertForTokenClassification Approach)</h4>

<p>We are releasing four new BERT-based NER models.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_ade</code> : This model is BERT-Based version of <code class="language-plaintext highlighter-rouge">ner_ade_clinical</code> model and performs 5% better. It can detect drugs and adverse reactions of drugs in reviews, tweets, and medical texts using <code class="language-plaintext highlighter-rouge">DRUG</code> and <code class="language-plaintext highlighter-rouge">ADE</code> labels.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_ade"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
    .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"document"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span>  Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, tokenizer, tokenClassifier, ner_converter]<span class="o">)</span>
p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span><span class="s1">''</span><span class="o">]})))</span>

test_sentence <span class="o">=</span> <span class="s2">"""Been taking Lipitor for 15 years , have experienced severe fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps"""</span>
result <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------+---------+
|chunk         |ner_label|
+--------------+---------+
|Lipitor       |DRUG     |
|severe fatigue|ADE      |
|voltaren      |DRUG     |
|cramps        |ADE      |
+--------------+---------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_jsl_slim</code> : This model is BERT-Based version of <code class="language-plaintext highlighter-rouge">ner_jsl_slim</code> model and 2% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture. It can detect <code class="language-plaintext highlighter-rouge">Death_Entity</code>, <code class="language-plaintext highlighter-rouge">Medical_Device</code>, <code class="language-plaintext highlighter-rouge">Vital_Sign</code>, <code class="language-plaintext highlighter-rouge">Alergen</code>, <code class="language-plaintext highlighter-rouge">Drug</code>, <code class="language-plaintext highlighter-rouge">Clinical_Dept</code>, <code class="language-plaintext highlighter-rouge">Lifestyle</code>, <code class="language-plaintext highlighter-rouge">Symptom</code>, <code class="language-plaintext highlighter-rouge">Body_Part</code>, <code class="language-plaintext highlighter-rouge">Physical_Measurement</code>, <code class="language-plaintext highlighter-rouge">Admission_Discharge</code>, <code class="language-plaintext highlighter-rouge">Date_Time</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Birth_Entity</code>, <code class="language-plaintext highlighter-rouge">Header</code>, <code class="language-plaintext highlighter-rouge">Oncological</code>, <code class="language-plaintext highlighter-rouge">Substance_Quantity</code>, <code class="language-plaintext highlighter-rouge">Test_Result</code>, <code class="language-plaintext highlighter-rouge">Test</code>, <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">Treatment</code>, <code class="language-plaintext highlighter-rouge">Disease_Syndrome_Disorder</code>, <code class="language-plaintext highlighter-rouge">Pregnancy_Newborn</code>, <code class="language-plaintext highlighter-rouge">Demographics</code> entities.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_jsl_slim"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
    .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, sentence_detector, tokenizer, tokenClassifier, ner_converter]<span class="o">)</span>
p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span><span class="s1">''</span><span class="o">]})))</span>

test_sentence <span class="o">=</span> <span class="s2">"""HISTORY: 30-year-old female presents for digital bilateral mammography secondary to a soft tissue lump palpated by the patient in the upper right shoulder. The patient has a family history of breast cancer within her mother at age 58. Patient denies personal history of breast cancer."""</span>
result <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------------+------------+
|chunk           |ner_label   |
+----------------+------------+
|HISTORY:        |Header      |
|30-year-old     |Age         |
|female          |Demographics|
|mammography     |Test        |
|soft tissue lump|Symptom     |
|shoulder        |Body_Part   |
|breast cancer   |Oncological |
|her mother      |Demographics|
|age 58          |Age         |
|breast cancer   |Oncological |
+----------------+------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_drugs</code> : This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_drugs</code> model and detects drug chemicals. This new model is 3% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_drugs"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"sentence"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
  .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span>  Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter]<span class="o">)</span>
model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span><span class="s1">''</span><span class="o">]})))</span>

test_sentence <span class="o">=</span> <span class="s2">"""The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family. Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II diabetes mellitus in the Pima Indian population. The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons separated byapproximately 2.2 and approximately 2.6 kb introns, respectively. We identified14 single nucleotide polymorphisms (SNPs), including one that predicts aVal366Ala substitution, and an 8 base-pair (bp) insertion/deletion. Ourexpression studies revealed the presence of the transcript in various humantissues including pancreas, and two major insulin-responsive tissues: fat andskeletal muscle. The characterization of the KCNJ9 gene should facilitate furtherstudies on the function of the KCNJ9 protein and allow evaluation of thepotential role of the locus in Type II diabetes.BACKGROUND: At present, it is one of the most important issues for the treatment of breast cancer to develop the standard therapy for patients previously treated with anthracyclines and taxanes. With the objective of determining the usefulnessof vinorelbine monotherapy in patients with advanced or recurrent breast cancerafter standard therapy, we evaluated the efficacy and safety of vinorelbine inpatients previously treated with anthracyclines and taxanes."""</span>
result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>
<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------+---------+
|chunk         |ner_label|
+--------------+---------+
|potassium     |DrugChem |
|nucleotide    |DrugChem |
|anthracyclines|DrugChem |
|taxanes       |DrugChem |
|vinorelbine   |DrugChem |
|vinorelbine   |DrugChem |
|anthracyclines|DrugChem |
|taxanes       |DrugChem |
+--------------+---------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_anatomy</code> : This model is BERT-Based version of <code class="language-plaintext highlighter-rouge">ner_anatomy</code> model and 3% better. It can detect <code class="language-plaintext highlighter-rouge">Anatomical_system</code>, <code class="language-plaintext highlighter-rouge">Cell</code>, <code class="language-plaintext highlighter-rouge">Cellular_component</code>, <code class="language-plaintext highlighter-rouge">Developing_anatomical_structure</code>, <code class="language-plaintext highlighter-rouge">Immaterial_anatomical_entity</code>, <code class="language-plaintext highlighter-rouge">Multi-tissue_structure</code>, <code class="language-plaintext highlighter-rouge">Organ</code>, <code class="language-plaintext highlighter-rouge">Organism_subdivision</code>, <code class="language-plaintext highlighter-rouge">Organism_substance</code>, <code class="language-plaintext highlighter-rouge">Pathological_formation</code>, <code class="language-plaintext highlighter-rouge">Tissue</code> entities.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_anatomy"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"sentence"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
    .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span>  Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, sentenceDetector, tokenizer, tokenClassifier, ner_converter]<span class="o">)</span>
pp_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span><span class="s1">''</span><span class="o">]})))</span>

test_sentence <span class="o">=</span> <span class="s2">"""This is an 11-year-old female who comes in for two different things. 1. She was seen by the allergist. No allergies present, so she stopped her Allegra, but she is still real congested and does a lot of snorting. They do not notice a lot of snoring at night though, but she seems to be always like that. 2. On her right great toe, she has got some redness and erythema. Her skin is kind of peeling a little bit, but it has been like that for about a week and a half now.</span><span class="se">\n</span><span class="s2">General: Well-developed female, in no acute distress, afebrile.</span><span class="se">\n</span><span class="s2">HEENT: Sclerae and conjunctivae clear. Extraocular muscles intact. TMs clear. Nares patent. A little bit of swelling of the turbinates on the left. Oropharynx is essentially clear. Mucous membranes are moist.</span><span class="se">\n</span><span class="s2">Neck: No lymphadenopathy.</span><span class="se">\n</span><span class="s2">Chest: Clear.</span><span class="se">\n</span><span class="s2">Abdomen: Positive bowel sounds and soft.</span><span class="se">\n</span><span class="s2">Dermatologic: She has got redness along her right great toe, but no bleeding or oozing. Some dryness of her skin. Her toenails themselves are very short and even on her left foot and her left great toe the toenails are very short."""</span>
result <span class="o">=</span> pp_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------+----------------------+
|chunk              |ner_label             |
+-------------------+----------------------+
|great toe          |Multi-tissue_structure|
|skin               |Organ                 |
|conjunctivae       |Multi-tissue_structure|
|Extraocular muscles|Multi-tissue_structure|
|Nares              |Multi-tissue_structure|
|turbinates         |Multi-tissue_structure|
|Oropharynx         |Multi-tissue_structure|
|Mucous membranes   |Tissue                |
|Neck               |Organism_subdivision  |
|bowel              |Organ                 |
|great toe          |Multi-tissue_structure|
|skin               |Organ                 |
|toenails           |Organism_subdivision  |
|foot               |Organism_subdivision  |
|great toe          |Multi-tissue_structure|
|toenails           |Organism_subdivision  |
+-------------------+----------------------+
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_bacteria</code> : This model is BERT-Based version of <code class="language-plaintext highlighter-rouge">ner_bacterial_species</code> model and detects different types of species of bacteria in clinical texts using <code class="language-plaintext highlighter-rouge">SPECIES</code> label.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_bacteria"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
    .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"document"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span>  Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, tokenizer, tokenClassifier, ner_converter]<span class="o">)</span>
p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span><span class="s1">''</span><span class="o">]})))</span>

test_sentence <span class="o">=</span> <span class="s2">"""Based on these genetic and phenotypic properties, we propose that strain SMSP (T) represents </span><span class="se">\</span><span class="s2">
a novel species of the genus Methanoregula, for which we propose the name Methanoregula formicica </span><span class="se">\</span><span class="s2">
sp. nov., with the type strain SMSP (T) (= NBRC 105244 (T) = DSM 22288 (T))."""</span>
result <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>test_sentence]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------+---------+
|chunk                  |ner_label|
+-----------------------+---------+
|SMSP <span class="o">(</span>T<span class="o">)</span>               |SPECIES  |
|Methanoregula formicica|SPECIES  |
|SMSP <span class="o">(</span>T<span class="o">)</span>               |SPECIES  |
+-----------------------+---------+
</code></pre></div></div>

<h4 id="radiology-ner-model-trained-on-chexpert-dataset">Radiology NER Model Trained On cheXpert Dataset</h4>

<ul>
  <li>Ner NER model <code class="language-plaintext highlighter-rouge">ner_chexpert</code> trained on Radiology Chest reports to extract anatomical sites and observation entities. The model achieves 92.8% and 77.4% micro and macro f1 scores on the cheXpert dataset.</li>
</ul>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings_clinical <span class="o">=</span> WordEmbeddingsModel.pretrained<span class="o">(</span><span class="s2">"embeddings_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span>  .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_chexpert"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>   .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span>   .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...
nlpPipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>document_assembler, sentence_detector, tokenizer, embeddings_clinical, clinical_ner, ner_converter]<span class="o">)</span>
model <span class="o">=</span> nlpPipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
EXAMPLE_TEXT <span class="o">=</span> <span class="s2">"""FINAL REPORT HISTORY : Chest tube leak , to assess for pneumothorax .
FINDINGS : In comparison with study of ___ , the endotracheal tube and Swan - Ganz catheter have been removed . The left chest tube remains in place and there is no evidence of pneumothorax. Mild atelectatic changes are seen at the left base."""</span>
results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>EXAMPLE_TEXT]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                    | label   |
|---:|:-------------------------|:--------|
|  0 | endotracheal tube        | OBS     |
|  1 | Swan - Ganz catheter     | OBS     |
|  2 | left chest               | ANAT    |
|  3 | tube                     | OBS     |
|  4 | <span class="k">in </span>place                 | OBS     |
|  5 | pneumothorax             | OBS     |
|  6 | Mild atelectatic changes | OBS     |
|  7 | left base                | ANAT    |
</code></pre></div></div>

<h4 id="new-speed-benchmarks-on-databricks">New Speed Benchmarks on Databricks</h4>

<p>We prepared a speed benchmark table by running a NER pipeline on various number of cluster configurations (worker number, driver node, specs etc) and also writing the results to parquet or delta formats. You can find all the details of these tries in here : <a href="https://nlp.johnsnowlabs.com/docs/en/benchmark">Speed Benchmark Table</a></p>

<h4 id="nerconverterinternal-fixes">NerConverterInternal Fixes</h4>
<p>Now NerConverterInternal can deal with tags that have some dash (<code class="language-plaintext highlighter-rouge">-</code>) charachter like B-GENE-N and B-GENE-Y.</p>

<h4 id="simplified-setup-and-recommended-use-of-start-function">Simplified Setup and Recommended Use of start() Function</h4>
<p>Starting with this release, we are shipping AWS credentials inside Spark NLP Healthcare’s license. This removes the requirement of setting the <code class="language-plaintext highlighter-rouge">AWS_ACCESS_KEY_ID</code> and <code class="language-plaintext highlighter-rouge">AWS_SECRET_ACCESS_KEY</code> environment variables.
To use this feature, you just need to make sure that you always call the start() function at the beginning of your program,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp_jsl</span> <span class="kn">import</span> <span class="n">start</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">start</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.util.start</span>
<span class="k">val</span> <span class="nv">spark</span> <span class="k">=</span> <span class="nf">start</span><span class="o">()</span>
</code></pre></div></div>

<p>If for some reason you don’t want to use this mechanism, the keys will continue to be shipped separately, and the environment variables will continue to work as they did in the past.</p>

<h4 id="ner-evaluation-metrics-fix">Ner Evaluation Metrics Fix</h4>

<p>Bug fixed in the <code class="language-plaintext highlighter-rouge">NerDLMetrics</code> package. Previously, the <code class="language-plaintext highlighter-rouge">full_chunk</code> option was using greedy approach to merge chunks for a strict evaluation, which has been fixed to merge chunks using IOB scheme to get accurate entities boundaries and metrics. Also, the <code class="language-plaintext highlighter-rouge">tag</code> option has been fixed to get metrics that align with the default NER logs.</p>

<h4 id="new-notebooks">New Notebooks</h4>

<ul>
  <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.2.Clinical_RE_Knowledge_Graph_with_Neo4j.ipynb">Clinical Relation Extraction Knowledge Graph with Neo4j Notebook</a></li>
  <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.2.Pretrained_NER_Profiling_Pipelines.ipynb">NER Profiling Pretrained Pipelines Notebook</a></li>
  <li>New Databricks <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/databricks/python/healthcare_case_studies/Detecting%20Adverse%20Drug%20Events%20From%20Conversational%20Texts.ipynb">Detecting Adverse Drug Events From Conversational Texts</a> case study notebook.</li>
</ul>

<p><strong>To see more, please check :</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></p>

<h2 id="323">3.2.3</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.2.3 has been released!.</p>

<h4 id="highlights-10">Highlights</h4>
<ul>
  <li>New BERT-Based Deidentification NER Model</li>
  <li>New Sentence Entity Resolver Models For German Language</li>
  <li>New Spell Checker Model For Drugs</li>
  <li>Allow To Use Disambiguator Pretrained Model</li>
  <li>Allow To Use Seeds in StructuredDeidentification</li>
  <li>Added Compatibility with Tensorflow 1.15 For Graph Generation.</li>
  <li>New Setup Videos</li>
</ul>

<h4 id="new-bert-based-deidentification-ner-model">New BERT-Based Deidentification NER Model</h4>

<p>We have a new <code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_deid</code> model that is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code> and annotates text to find protected health information that may need to be de-identified. It can detect 23 different entities (<code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">HEALTHPLAN</code>, <code class="language-plaintext highlighter-rouge">URL</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">LOCATION-OTHER</code>, <code class="language-plaintext highlighter-rouge">STATE</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">DEVICE</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">EMAIL</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">SREET</code>, <code class="language-plaintext highlighter-rouge">BIOID</code>, <code class="language-plaintext highlighter-rouge">FAX</code>, <code class="language-plaintext highlighter-rouge">AGE</code>).</p>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
  .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>

tokenizer <span class="o">=</span> Tokenizer<span class="o">()</span><span class="se">\</span>
  .setInputCols<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"token"</span><span class="o">)</span>

tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_deid"</span>, <span class="s2">"en"</span><span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
  .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"document"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span>  Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, tokenizer, tokenClassifier, ner_converter]<span class="o">)</span>
p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span><span class="s1">''</span><span class="o">]})))</span>

text <span class="o">=</span> <span class="s2">"""A. Record date : 2093-01-13, David Hale, M.D. Name : Hendrickson, Ora MR. # 7194334. PCP : Oliveira, non-smoking. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227. Patient's complaints first surfaced when he started working for Brothers Coal-Mine."""</span>
result <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s1">'text'</span>: <span class="o">[</span>text]<span class="o">})))</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------+-------------+
|chunk                        |ner_label    |
+-----------------------------+-------------+
|2093-01-13                   |DATE         |
|David Hale                   |DOCTOR       |
|Hendrickson, Ora             |PATIENT      |
|7194334                      |MEDICALRECORD|
|Oliveira                     |PATIENT      |
|Cocke County Baptist Hospital|HOSPITAL     |
|0295 Keats Street            |STREET       |
|302<span class="o">)</span> 786-5227                |PHONE        |
|Brothers Coal-Mine           |ORGANIZATION |
+-----------------------------+-------------+
</code></pre></div></div>

<h4 id="new-sentence-entity-resolver-models-for-german-language">New Sentence Entity Resolver Models For German Language</h4>

<p>We are releasing two new Sentence Entity Resolver Models for German language that use <code class="language-plaintext highlighter-rouge">sent_bert_base_cased</code> (de) embeddings.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbertresolve_icd10gm</code> : This model maps extracted medical entities to ICD10-GM codes for the German language.</li>
</ul>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
    .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s2">"sent_bert_base_cased"</span>, <span class="s2">"de"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>

icd10gm_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbertresolve_icd10gm"</span>, <span class="s2">"de"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"icd10gm_code"</span><span class="o">)</span>

icd10gm_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span> stages <span class="o">=</span> <span class="o">[</span>documentAssembler, sbert_embedder, icd10gm_resolver]<span class="o">)</span>

icd_lp <span class="o">=</span> LightPipeline<span class="o">(</span>icd10gm_pipelineModel<span class="o">)</span>
icd_lp.fullAnnotate<span class="o">(</span><span class="s2">"Dyspnoe"</span><span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<table>
  <thead>
    <tr>
      <th>chunk</th>
      <th>code</th>
      <th>resolutions</th>
      <th>all_codes</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Dyspnoe</td>
      <td>C671</td>
      <td>Dyspnoe, Schlafapnoe, Dysphonie, Frühsyphilis, Hyperzementose, Hypertrichose, …</td>
      <td>[R06.0, G47.3, R49.0, A51, K03.4, L68, …]</td>
      <td>[0.0000, 2.5602, 3.0529, 3.3310, 3.4645, 3.7148, …]</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbertresolve_snomed</code> : This model maps extracted medical entities to SNOMED codes for the German language.</li>
</ul>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
    .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s2">"sent_bert_base_cased"</span>, <span class="s2">"de"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>

snomed_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbertresolve_snomed"</span>, <span class="s2">"de"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"snomed_code"</span><span class="o">)</span>

snomed_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span> stages <span class="o">=</span> <span class="o">[</span> documentAssembler, sbert_embedder, snomed_resolver]<span class="o">)</span>

snomed_lp <span class="o">=</span> LightPipeline<span class="o">(</span>snomed_pipelineModel<span class="o">)</span>
snomed_lp.fullAnnotate<span class="o">(</span><span class="s2">"Bronchialkarzinom "</span><span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<table>
  <thead>
    <tr>
      <th>chunk</th>
      <th>code</th>
      <th>resolutions</th>
      <th>all_codes</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Bronchialkarzinom</td>
      <td>22628</td>
      <td>Bronchialkarzinom, Bronchuskarzinom, Rektumkarzinom, Klavikulakarzinom, Lippenkarzinom, Urothelkarzinom, …</td>
      <td>[22628, 111139, 18116, 107569, 18830, 22909, …]</td>
      <td>[0.0000, 0.0073, 0.0090, 0.0098, 0.0098, 0.0102, …]</td>
    </tr>
  </tbody>
</table>

<h4 id="new-spell-checker-model-for-drugs">New Spell Checker Model For Drugs</h4>

<p>We are releasing new <code class="language-plaintext highlighter-rouge">spellcheck_drug_norvig</code> model that detects and corrects spelling errors of drugs in a text based on the Norvig’s approach.</p>

<p><em>Example</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
    .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>

tokenizer <span class="o">=</span> Tokenizer<span class="o">()</span>
    .setInputCols<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span><span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"token"</span><span class="o">)</span>

spell <span class="o">=</span> NorvigSweetingModel.pretrained<span class="o">(</span><span class="s2">"spellcheck_drug_norvig"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
    .setInputCols<span class="o">(</span><span class="s2">"token"</span><span class="o">)</span>
    .setOutputCol<span class="o">(</span><span class="s2">"spell"</span><span class="o">)</span><span class="se">\</span>

pipeline <span class="o">=</span> Pipeline<span class="o">(</span> stages <span class="o">=</span> <span class="o">[</span>documentAssembler,
tokenizer, spell]<span class="o">)</span>

model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s1">''</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s1">'text'</span><span class="o">))</span>
lp <span class="o">=</span> LightPipeline<span class="o">(</span>model<span class="o">)</span>

lp.annotate<span class="o">(</span><span class="s2">"You have to take Neutrcare and colfosrinum and a bit of Fluorometholne &amp; Ribotril"</span><span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em> :</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original text  : You have to take Neutrcare and colfosrinum and a bit of fluorometholne &amp; Ribotril
Corrected text : You have to take Neutracare and colforsinum and a bit of fluorometholone &amp; Rivotril

</code></pre></div></div>

<h4 id="allow-to-use-disambiguator-pretrained-model">Allow to use Disambiguator pretrained model.</h4>

<p>Now we can use the NerDisambiguatorModel as a pretrained model to disambiguate person entities.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">text</span> <span class="o">=</span> <span class="s">"The show also had a contestant named Brad Pitt"</span> \
        <span class="o">+</span> <span class="s">"who later defeated Christina Aguilera on the way to become Female Vocalist Champion in the 1989 edition of Star Search in the United States. "</span>
 <span class="n">data</span> <span class="o">=</span> <span class="n">SparkContextForTest</span><span class="p">.</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
     <span class="p">[</span><span class="n">text</span><span class="p">]])</span> \
     <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
 <span class="n">da</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sd</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

 <span class="n">tk</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

 <span class="n">emb</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">().</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>

 <span class="n">semb</span> <span class="o">=</span> <span class="n">SentenceEmbeddings</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

 <span class="n">ner</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

 <span class="n">nc</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">).</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PER"</span><span class="p">])</span>

 <span class="n">NerDisambiguatorModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">)</span>

 <span class="n">pl</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">da</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">tk</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">semb</span><span class="p">,</span> <span class="n">ner</span><span class="p">,</span> <span class="n">nc</span><span class="p">,</span> <span class="n">disambiguator</span><span class="p">])</span>

 <span class="n">data</span> <span class="o">=</span> <span class="n">pl</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
 <span class="n">data</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|disambiguation                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|[[disambiguation, 65, 82, http://en.wikipedia.org/?curid<span class="o">=</span>144171, http://en.wikipedia.org/?curid<span class="o">=</span>6636454, <span class="o">[</span>chunk -&gt; Christina Aguilera, titles -&gt; christina aguilera ::::: christina aguilar, links -&gt; http://en.wikipedia.org/?curid<span class="o">=</span>144171 ::::: http://en.wikipedia.org/?curid<span class="o">=</span>6636454, beginInText -&gt; 65, scores -&gt; 0.9764155197864447, 0.9727793647472524, categories -&gt; Musicians, Singers, Actors, Businesspeople, Musicians, Singers, ids -&gt; 144171, 6636454, endInText -&gt; 82], <span class="o">[]]]</span>|
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

<span class="nt">----------------------</span>

</code></pre></div></div>
<h4 id="allow-to-use-seeds-in-structureddeidentification">Allow to use seeds in StructuredDeidentification</h4>

<p>Now, we can use a seed for a specific column. The seed is used to randomly select the entities used during obfuscation mode. By providing the same seed, you can replicate the same mapping multiple times.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
            <span class="p">[</span><span class="s">"12"</span><span class="p">,</span> <span class="s">"12"</span><span class="p">,</span> <span class="s">"Juan García"</span><span class="p">],</span>
            <span class="p">[</span><span class="s">"24"</span><span class="p">,</span> <span class="s">"56"</span><span class="p">,</span> <span class="s">"Will Smith"</span><span class="p">],</span>
            <span class="p">[</span><span class="s">"56"</span><span class="p">,</span> <span class="s">"32"</span><span class="p">,</span> <span class="s">"Pedro Ximénez"</span><span class="p">]</span>
        <span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"ID1"</span><span class="p">,</span> <span class="s">"ID2"</span><span class="p">,</span> <span class="s">"NAME"</span><span class="p">)</span>

<span class="n">obfuscator</span> <span class="o">=</span> <span class="n">StructuredDeidentification</span><span class="p">(</span><span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">"ID1"</span><span class="p">:</span> <span class="s">"ID"</span><span class="p">,</span> <span class="s">"ID2"</span><span class="p">:</span> <span class="s">"ID"</span><span class="p">,</span> <span class="s">"NAME"</span><span class="p">:</span> <span class="s">"PATIENT"</span><span class="p">},</span>
                                                <span class="n">columnsSeed</span><span class="o">=</span><span class="p">{</span><span class="s">"ID1"</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span> <span class="s">"ID2"</span><span class="p">:</span> <span class="mi">23</span><span class="p">},</span>
                                                <span class="n">obfuscateRefSource</span><span class="o">=</span><span class="s">"faker"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">obfuscator</span><span class="p">.</span><span class="n">obfuscateColumns</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>      
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------+----------+----------------+
|ID1       |ID2       |NAME            |
+----------+----------+----------------+
|[D3379888]|[D3379888]|[Raina Cleaves] |
|[R8448971]|[M8851891]|[Jennell Barre] |
|[M8851891]|[L5448098]|[Norene Salines]|
+----------+----------+----------------+

Here, you can see that as we have provided the same seed <span class="sb">`</span>23<span class="sb">`</span> <span class="k">for </span>columns <span class="sb">`</span>ID1<span class="sb">`</span>, and <span class="sb">`</span>ID2<span class="sb">`</span>, the number <span class="sb">`</span>12<span class="sb">`</span> which is appears twice <span class="k">in </span>the first row is mapped to the same randomly generated <span class="nb">id</span> <span class="sb">`</span>D3379888<span class="sb">`</span> each time.
</code></pre></div></div>
<h4 id="added-compatibility-with-tensorflow-115-for-graph-generation">Added compatibility with Tensorflow 1.15 for graph generation</h4>
<p>Some users reported problems while using graphs generated by Tensorflow 2.x. We provide compatibility with Tensorflow 1.15 in the <code class="language-plaintext highlighter-rouge">tf_graph_1x</code> module, that can be used like this,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.training import tf_graph_1x

</code></pre></div></div>

<p>In next releases, we will provide full support for graph generation using Tensorflow 2.x.</p>

<h4 id="new-setup-videos">New Setup Videos</h4>

<p>Now we have videos showing how to setup Spark NLP, Spark NLP for Healthcare and Spark OCR on UBUNTU.</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=ZnFENM-yNfQ">How to Setup Spark NLP on UBUNTU</a></li>
  <li><a href="https://www.youtube.com/watch?v=yKnF-_oz0GE">How to Setup Spark NLP for HEALTHCARE on UBUNTU</a></li>
  <li><a href="https://www.youtube.com/watch?v=cmt4WIcL0nI">How to Setup Spark OCR on UBUNTU</a></li>
</ul>

<p><strong>To see more, please check</strong>: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></p>

<h2 id="322">3.2.2</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.2.2 has been released!.</p>

<h4 id="highlights-11">Highlights</h4>
<ul>
  <li>New NER Model For Detecting Drugs, Posology, and Administration Cycles</li>
  <li>New Sentence Entity Resolver Models</li>
  <li>New Router Annotator To Use Multiple Resolvers Optimally In the Same Pipeline</li>
  <li>Re-Augmented Deidentification NER Model</li>
</ul>

<h4 id="new-ner-model-for-detecting-drugs-posology-and-administration-cycles">New NER Model For Detecting Drugs, Posology, and Administration Cycles</h4>

<p>We are releasing a new NER posology model <code class="language-plaintext highlighter-rouge">ner_posology_experimental</code>. This model is based on the original <code class="language-plaintext highlighter-rouge">ner_posology_large</code> model, but trained with additional clinical trials data to detect experimental drugs, experiment cycles, cycle counts, and cycles numbers. Supported Entities: <code class="language-plaintext highlighter-rouge">Administration</code>, <code class="language-plaintext highlighter-rouge">Cyclenumber</code>, <code class="language-plaintext highlighter-rouge">Strength</code>, <code class="language-plaintext highlighter-rouge">Cycleday</code>, <code class="language-plaintext highlighter-rouge">Duration</code>, <code class="language-plaintext highlighter-rouge">Cyclecount</code>, <code class="language-plaintext highlighter-rouge">Route</code>, <code class="language-plaintext highlighter-rouge">Form</code>, <code class="language-plaintext highlighter-rouge">Frequency</code>, <code class="language-plaintext highlighter-rouge">Cyclelength</code>, <code class="language-plaintext highlighter-rouge">Drug</code>, <code class="language-plaintext highlighter-rouge">Dosage</code></p>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
word_embeddings <span class="o">=</span> WordEmbeddingsModel.pretrained<span class="o">(</span><span class="s2">"embeddings_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
   .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span><span class="o">])</span><span class="se">\</span>
   .setOutputCol<span class="o">(</span><span class="s2">"embeddings"</span><span class="o">)</span>
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_posology_experimental"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
   .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
   .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...
nlp_pipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter]<span class="o">)</span>
model <span class="o">=</span> nlp_pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"Y-90 Humanized Anti-Tac: 10 mCi (if a bone marrow transplant was part of the patient's previous therapy) or 15 mCi of yttrium labeled anti-TAC; followed by calcium trisodium Inj (Ca DTPA)..</span><span class="se">\n\n</span><span class="s2">Calcium-DTPA: Ca-DTPA will be administered intravenously on Days 1-3 to clear the radioactive agent from the body."</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
</code></pre></div></div>

<p><em>Results</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                    |   begin |   end | entity   |
|---:|:-------------------------|--------:|------:|:---------|
|  0 | Y-90 Humanized Anti-Tac  |       0 |    22 | Drug     |
|  1 | 10 mCi                   |      25 |    30 | Dosage   |
|  2 | 15 mCi                   |     108 |   113 | Dosage   |
|  3 | yttrium labeled anti-TAC |     118 |   141 | Drug     |
|  4 | calcium trisodium Inj    |     156 |   176 | Drug     |
|  5 | Calcium-DTPA             |     191 |   202 | Drug     |
|  6 | Ca-DTPA                  |     205 |   211 | Drug     |
|  7 | intravenously            |     234 |   246 | Route    |
|  8 | Days 1-3                 |     251 |   258 | Cycleday |
</code></pre></div></div>

<h4 id="new-sentence-entity-resolver-models">New Sentence Entity Resolver Models</h4>

<p>We have two new sentence entity resolver models trained with using <code class="language-plaintext highlighter-rouge">sbert_jsl_medium_uncased</code> embeddings.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbertresolve_rxnorm_disposition</code> : This model maps medication entities (like drugs/ingredients) to RxNorm codes and their dispositions using <code class="language-plaintext highlighter-rouge">sbert_jsl_medium_uncased</code> Sentence Bert Embeddings. If you look for a faster inference with just drug names (excluding dosage and strength), this version of RxNorm model would be a better alternative. In the result, look for the aux_label parameter in the metadata to get dispositions divided by <code class="language-plaintext highlighter-rouge">|</code>.</li>
</ul>

<p><em>Example</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
      .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s1">'sbert_jsl_medium_uncased'</span>, <span class="s1">'en'</span>,<span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>

rxnorm_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbertresolve_rxnorm_disposition"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"rxnorm_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>

rxnorm_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span>
    stages <span class="o">=</span> <span class="o">[</span>
        documentAssembler,
        sbert_embedder,
        rxnorm_resolver]<span class="o">)</span>

rxnorm_lp <span class="o">=</span> LightPipeline<span class="o">(</span>rxnorm_pipelineModel<span class="o">)</span>
rxnorm_lp <span class="o">=</span> LightPipeline<span class="o">(</span>pipelineModel<span class="o">)</span> result <span class="o">=</span> rxnorm_lp.fullAnnotate<span class="o">(</span><span class="s2">"alizapride 25 mg/ml"</span><span class="o">)</span>
</code></pre></div></div>
<p><em>Result</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunks             | code   | resolutions                                                                                                                                                                            | all_codes                                                       | all_k_aux_labels                                                                                            | all_distances                                                 |
|---:|:-------------------|:-------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|
|  0 |alizapride 25 mg/ml | 330948 | <span class="o">[</span>alizapride 25 mg/ml, alizapride 50 mg, alizapride 25 mg/ml oral solution, adalimumab 50 mg/ml, adalimumab 100 mg/ml <span class="o">[</span>humira], adalimumab 50 mg/ml <span class="o">[</span>humira], alirocumab 150 mg/ml, ...]| <span class="o">[</span>330948, 330949, 249531, 358817, 1726845, 576023, 1659153, ...] | <span class="o">[</span>Dopamine receptor antagonist, Dopamine receptor antagonist, Dopamine receptor antagonist, -, -, -, -, ...] | <span class="o">[</span>0.0000, 0.0936, 0.1166, 0.1525, 0.1584, 0.1567, 0.1631, ...] |
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbertresolve_snomed_conditions</code> : This model maps clinical entities (domain: Conditions) to Snomed codes using <code class="language-plaintext highlighter-rouge">sbert_jsl_medium_uncased</code> Sentence Bert Embeddings.</li>
</ul>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
      .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s1">'sbert_jsl_medium_uncased'</span>, <span class="s1">'en'</span>,<span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>

snomed_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbertresolve_snomed_conditions"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"snomed_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>

snomed_pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span>
    stages <span class="o">=</span> <span class="o">[</span>
        documentAssembler,
        sbert_embedder,
        snomed_resolver
        <span class="o">])</span>

snomed_lp <span class="o">=</span> LightPipeline<span class="o">(</span>snomed_pipelineModel<span class="o">)</span>
result <span class="o">=</span> snomed_lp.fullAnnotate<span class="o">(</span><span class="s2">"schizophrenia"</span><span class="o">)</span>
</code></pre></div></div>
<p><em>Result</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunks        | code     | resolutions                                                                                                              | all_codes                                                            | all_distances                                        |
|---:|:--------------|:---------|:-------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------|:-----------------------------------------------------|
|  0 | schizophrenia | 58214004 | <span class="o">[</span>schizophrenia, chronic schizophrenia, borderline schizophrenia, schizophrenia, catatonic, subchronic schizophrenia, ...]| <span class="o">[</span>58214004, 83746006, 274952002, 191542003, 191529003, 16990005, ...] | 0.0000, 0.0774, 0.0838, 0.0927, 0.0970, 0.0970, ...] |
</code></pre></div></div>

<h4 id="new-router-annotator-to-use-multiple-resolvers-optimally-in-the-same-pipeline">New Router Annotator To Use Multiple Resolvers Optimally In the Same Pipeline</h4>

<p>Normally, when we need to use more than one sentence entity resolver models in the same pipeline, we used to hit <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotator more than once given the number of different resolver models in the same pipeline. Now we are introducing a solution with the help of <code class="language-plaintext highlighter-rouge">Router</code> annotator that could allow us to feed all the NER chunks to <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> at once and then route the output of Sentence Embeddings to different resolver models needed.</p>

<p>You can find an example of how to use this annotator in the updated <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb">3.Clinical_Entity_Resolvers.ipynb Notebook</a></p>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
<span class="c"># to get PROBLEM entitis</span>
clinical_ner <span class="o">=</span> MedicalNerModel<span class="o">()</span>.pretrained<span class="o">(</span><span class="s2">"ner_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"word_embeddings"</span><span class="o">])</span> <span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"clinical_ner"</span><span class="o">)</span>

clinical_ner_chunk <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
        .setInputCols<span class="o">(</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"clinical_ner"</span><span class="o">)</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"clinical_ner_chunk"</span><span class="o">)</span><span class="se">\</span>
        .setWhiteList<span class="o">([</span><span class="s2">"PROBLEM"</span><span class="o">])</span>

<span class="c"># to get DRUG entities</span>
posology_ner <span class="o">=</span> MedicalNerModel<span class="o">()</span>.pretrained<span class="o">(</span><span class="s2">"ner_posology"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"word_embeddings"</span><span class="o">])</span> <span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"posology_ner"</span><span class="o">)</span>

posology_ner_chunk <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
        .setInputCols<span class="o">(</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"posology_ner"</span><span class="o">)</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"posology_ner_chunk"</span><span class="o">)</span><span class="se">\</span>
        .setWhiteList<span class="o">([</span><span class="s2">"DRUG"</span><span class="o">])</span>

<span class="c"># merge the chunks into a single ner_chunk</span>
chunk_merger <span class="o">=</span> ChunkMergeApproach<span class="o">()</span><span class="se">\</span>
        .setInputCols<span class="o">(</span><span class="s2">"clinical_ner_chunk"</span>,<span class="s2">"posology_ner_chunk"</span><span class="o">)</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"final_ner_chunk"</span><span class="o">)</span><span class="se">\</span>
        .setMergeOverlapping<span class="o">(</span>False<span class="o">)</span>


<span class="c"># convert chunks to doc to get sentence embeddings of them</span>
chunk2doc <span class="o">=</span> Chunk2Doc<span class="o">()</span>.setInputCols<span class="o">(</span><span class="s2">"final_ner_chunk"</span><span class="o">)</span>.setOutputCol<span class="o">(</span><span class="s2">"final_chunk_doc"</span><span class="o">)</span>


sbiobert_embeddings <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s2">"sbiobert_base_cased_mli"</span>,<span class="s2">"en"</span>,<span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"final_chunk_doc"</span><span class="o">])</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>

<span class="c"># filter PROBLEM entity embeddings</span>
router_sentence_icd10 <span class="o">=</span> Router<span class="o">()</span> <span class="se">\</span>
        .setInputCols<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span> <span class="se">\</span>
        .setFilterFieldsElements<span class="o">([</span><span class="s2">"PROBLEM"</span><span class="o">])</span> <span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"problem_embeddings"</span><span class="o">)</span>

<span class="c"># filter DRUG entity embeddings</span>
router_sentence_rxnorm <span class="o">=</span> Router<span class="o">()</span> <span class="se">\</span>
        .setInputCols<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span> <span class="se">\</span>
        .setFilterFieldsElements<span class="o">([</span><span class="s2">"DRUG"</span><span class="o">])</span> <span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"drug_embeddings"</span><span class="o">)</span>

<span class="c"># use problem_embeddings only</span>
icd_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_icd10cm_slim_billable_hcc"</span>,<span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"clinical_ner_chunk"</span>, <span class="s2">"problem_embeddings"</span><span class="o">])</span> <span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"icd10cm_code"</span><span class="o">)</span><span class="se">\</span>
        .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>


<span class="c"># use drug_embeddings only</span>
rxnorm_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_rxnorm"</span>,<span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"posology_ner_chunk"</span>, <span class="s2">"drug_embeddings"</span><span class="o">])</span> <span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"rxnorm_code"</span><span class="o">)</span><span class="se">\</span>
        .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>


pipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>
    documentAssembler,
    sentenceDetector,
    tokenizer,
    word_embeddings,
    clinical_ner,
    clinical_ner_chunk,
    posology_ner,
    posology_ner_chunk,
    chunk_merger,
    chunk2doc,
    sbiobert_embeddings,
    router_sentence_icd10,
    router_sentence_rxnorm,
    icd_resolver,
    rxnorm_resolver
<span class="o">])</span>

</code></pre></div></div>

<h4 id="re-augmented-deidentification-ner-model">Re-Augmented Deidentification NER Model</h4>

<p>We re-augmented <code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code> deidentification NER model improving the previous metrics by 2%.</p>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity_augmented"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...
nlpPipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter]<span class="o">)</span>
model <span class="o">=</span> nlpPipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>

results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s2">"text"</span>: <span class="o">[</span><span class="s2">"""A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227."""</span><span class="o">]})))</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------+-------------+
|chunk                        |ner_label    |
+-----------------------------+-------------+
|2093-01-13                   |DATE         |
|David Hale                   |DOCTOR       |
|Hendrickson, Ora             |PATIENT      |
|7194334                      |MEDICALRECORD|
|01/13/93                     |DATE         |
|Oliveira                     |DOCTOR       |
|25-year-old                  |AGE          |
|1-11-2000                    |DATE         |
|Cocke County Baptist Hospital|HOSPITAL     |
|0295 Keats Street.           |STREET       |
|<span class="o">(</span>302<span class="o">)</span> 786-5227               |PHONE        |
|Brothers Coal-Mine           |ORGANIZATION |
+-----------------------------+-------------+
</code></pre></div></div>

<p><strong>To see more, please check:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></p>

<h2 id="321">3.2.1</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.2.1 has been released!.</p>

<h4 id="highlights-12">Highlights</h4>

<ul>
  <li>Deprecated ChunkEntityResolver.</li>
  <li>New BERT-Based NER Models</li>
  <li>HCC module added support for versions v22 and v23.</li>
  <li>Updated Notebooks for resolvers and graph builders.</li>
  <li>New TF Graph Builder.</li>
</ul>

<h4 id="new-bert-based-ner-models-1">New BERT-Based NER Models</h4>

<p>We have two new BERT-based token classifier NER models. These models are the first clinical NER models that use the BertForTokenCLassification approach that was introduced in Spark NLP 3.2.0.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_clinical</code>: This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_clinical</code> model. This new model is 4% better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture.</li>
</ul>

<p><em>Metrics</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

     PROBLEM       0.88      0.92      0.90     30276
        TEST       0.91      0.86      0.88     17237
   TREATMENT       0.87      0.88      0.88     17298
           O       0.97      0.97      0.97    202438

    accuracy                           0.95    267249
   macro avg       0.91      0.91      0.91    267249
weighted avg       0.95      0.95      0.95    267249

</code></pre></div></div>

<p><em>Example</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
  .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>

sentenceDetector <span class="o">=</span> SentenceDetectorDLModel.pretrained<span class="o">(</span><span class="s2">"sentence_detector_dl_healthcare"</span>,<span class="s2">"en"</span>,<span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
       .setInputCols<span class="o">([</span><span class="s2">"document"</span><span class="o">])</span><span class="se">\</span>
       .setOutputCol<span class="o">(</span><span class="s2">"sentence"</span><span class="o">)</span>

tokenizer <span class="o">=</span> Tokenizer<span class="o">()</span><span class="se">\</span>
       .setInputCols<span class="o">(</span><span class="s2">"sentence"</span><span class="o">)</span><span class="se">\</span>
       .setOutputCol<span class="o">(</span><span class="s2">"token"</span><span class="o">)</span>

tokenClassifier <span class="o">=</span> BertForTokenClassification.pretrained<span class="o">(</span><span class="s2">"bert_token_classifier_ner_clinical"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span><span class="se">\</span>
       .setInputCols<span class="o">(</span><span class="s2">"token"</span>, <span class="s2">"sentence"</span><span class="o">)</span><span class="se">\</span>
       .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span><span class="se">\</span>
       .setCaseSensitive<span class="o">(</span>True<span class="o">)</span>

ner_converter <span class="o">=</span> NerConverter<span class="o">()</span><span class="se">\</span>
        .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>,<span class="s2">"token"</span>,<span class="s2">"ner"</span><span class="o">])</span><span class="se">\</span>
        .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

pipeline <span class="o">=</span>  Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>
       documentAssembler,
       sentenceDetector,
       tokenizer,
       tokenClassifier,
       ner_converter
  <span class="o">])</span>

p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>

text <span class="o">=</span> <span class="s1">'A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .'</span>

res <span class="o">=</span> p_model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>.collect<span class="o">()</span>

res[0][<span class="s1">'label'</span><span class="o">]</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bert_token_classifier_ner_jsl</code>: This model is BERT-based version of <code class="language-plaintext highlighter-rouge">ner_jsl</code> model. This new model is better than the legacy NER model (MedicalNerModel) that is based on BiLSTM-CNN-Char architecture.</li>
</ul>

<p><em>Metrics</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                                    precision    recall  f1-score   support

                    Admission_Discharge       0.84      0.97      0.90       415
                                    Age       0.96      0.96      0.96      2434
                                Alcohol       0.75      0.83      0.79       145
                               Allergen       0.33      0.16      0.22        25
                                    BMI       1.00      0.77      0.87        26
                           Birth_Entity       1.00      0.17      0.29        12
                         Blood_Pressure       0.86      0.88      0.87       597
                Cerebrovascular_Disease       0.74      0.77      0.75       266
                          Clinical_Dept       0.90      0.92      0.91      2385
                   Communicable_Disease       0.70      0.59      0.64        85
                                   Date       0.95      0.98      0.96      1438
                           Death_Entity       0.83      0.83      0.83        59
                               Diabetes       0.95      0.95      0.95       350
                                   Diet       0.60      0.49      0.54       229
                              Direction       0.88      0.90      0.89      6187
              Disease_Syndrome_Disorder       0.90      0.89      0.89     13236
                                 Dosage       0.57      0.49      0.53       263
                                   Drug       0.91      0.93      0.92     15926
                               Duration       0.82      0.85      0.83      1218
                           EKG_Findings       0.64      0.70      0.67       325
                             Employment       0.79      0.85      0.82       539
           External_body_part_or_region       0.84      0.84      0.84      4805
                  Family_History_Header       1.00      1.00      1.00       889
                          Fetus_NewBorn       0.57      0.56      0.56       341
                                   Form       0.53      0.43      0.48        81
                              Frequency       0.87      0.90      0.88      1718
                                 Gender       0.98      0.98      0.98      5666
                                    HDL       0.60      1.00      0.75         6
                          Heart_Disease       0.88      0.88      0.88      2295
                                 Height       0.89      0.96      0.92       134
                         Hyperlipidemia       1.00      0.95      0.97       194
                           Hypertension       0.95      0.98      0.97       566
                        ImagingFindings       0.66      0.64      0.65       601
                      Imaging_Technique       0.62      0.67      0.64       108
                    Injury_or_Poisoning       0.85      0.83      0.84      1680
            Internal_organ_or_component       0.90      0.91      0.90     21318
                         Kidney_Disease       0.89      0.89      0.89       446
                                    LDL       0.88      0.97      0.92        37
                        Labour_Delivery       0.82      0.71      0.76       306
                         Medical_Device       0.89      0.93      0.91     12852
                 Medical_History_Header       0.96      0.97      0.96      1013
                               Modifier       0.68      0.60      0.64      1398
                          O2_Saturation       0.84      0.82      0.83       199
                                Obesity       0.96      0.98      0.97       130
                            Oncological       0.88      0.96      0.92      1635
                             Overweight       0.80      0.80      0.80        10
                         Oxygen_Therapy       0.91      0.92      0.92       231
                              Pregnancy       0.81      0.83      0.82       439
                              Procedure       0.91      0.91      0.91     14410
                Psychological_Condition       0.81      0.81      0.81       354
                                  Pulse       0.85      0.95      0.89       389
                         Race_Ethnicity       1.00      1.00      1.00       163
                    Relationship_Status       0.93      0.91      0.92        57
                           RelativeDate       0.83      0.86      0.84      1562
                           RelativeTime       0.74      0.79      0.77       431
                            Respiration       0.99      0.95      0.97       221
                                  Route       0.68      0.69      0.69       597
                         Section_Header       0.97      0.98      0.98     28580
  Sexually_Active_or_Sexual_Orientation       1.00      0.64      0.78        14
                                Smoking       0.83      0.90      0.86       225
                  Social_History_Header       0.95      0.99      0.97       825
                               Strength       0.71      0.55      0.62       227
                              Substance       0.85      0.81      0.83       193
                     Substance_Quantity       0.00      0.00      0.00        28
                                Symptom       0.84      0.86      0.85     23092
                            Temperature       0.94      0.97      0.96       410
                                   Test       0.84      0.88      0.86      9050
                            Test_Result       0.84      0.84      0.84      2766
                                   Time       0.90      0.81      0.86       140
                      Total_Cholesterol       0.69      0.95      0.80        73
                              Treatment       0.73      0.72      0.73       506
                          Triglycerides       0.83      0.80      0.81        30
                             VS_Finding       0.76      0.77      0.76       588
                                Vaccine       0.70      0.84      0.76        92
                     Vital_Signs_Header       0.95      0.98      0.97      2223
                                 Weight       0.88      0.89      0.88       306
                                      O       0.97      0.96      0.97    253164

                               accuracy                           0.94    445974
                              macro avg       0.82      0.82      0.81    445974
                           weighted avg       0.94      0.94      0.94    445974
</code></pre></div></div>

<p><em>Example</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler = DocumentAssembler()\
       .setInputCol("text")\
       .setOutputCol("document")

sentenceDetector = SentenceDetectorDLModel.pretrained("sentence_detector_dl_healthcare","en","clinical/models")\
       .setInputCols(["document"])\
       .setOutputCol("sentence")

tokenizer = Tokenizer()\
       .setInputCols("sentence")\
       .setOutputCol("token")

tokenClassifier = BertForTokenClassification.pretrained("bert_token_classifier_ner_jsl", "en", "clinical/models")\
       .setInputCols("token", "sentence")\
       .setOutputCol("ner")\
       .setCaseSensitive(True)

ner_converter = NerConverter()\
        .setInputCols(["sentence","token","ner"])\
        .setOutputCol("ner_chunk")

pipeline =  Pipeline(stages=[
       documentAssembler,
       sentenceDetector,
       tokenizer,
       tokenClassifier,
       ner_converter
  ])

p_model = pipeline.fit(spark.createDataFrame([[""]]).toDF("text"))

text = 'A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .'

res = p_model.transform(spark.createDataFrame([[text]]).toDF("text")).collect()

res[0]['label']
</code></pre></div></div>

<h4 id="hcc-module-added-support-for-versions-v22-and-v23">HCC module added support for versions v22 and v23</h4>

<p>Now we can use the version 22 and the version 23 for the new HCC module to calculate CMS-HCC Risk Adjustment score.</p>

<p>Added the following parameters <code class="language-plaintext highlighter-rouge">elig</code>, <code class="language-plaintext highlighter-rouge">orec</code> and <code class="language-plaintext highlighter-rouge">medicaid</code> on the profiles functions. These parameters may not be stored in clinical notes, and may require to be imported from other sources.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>elig : The eligibility segment of the patient.
       Allowed values are as follows:
       - "CFA": Community Full Benefit Dual Aged
       - "CFD": Community Full Benefit Dual Disabled
       - "CNA": Community NonDual Aged
       - "CND": Community NonDual Disabled
       - "CPA": Community Partial Benefit Dual Aged
       - "CPD": Community Partial Benefit Dual Disabled
       - "INS": Long Term Institutional
       - "NE": New Enrollee
       - "SNPNE": SNP NE

orec: Original reason for entitlement code.
      - "0": Old age and survivor's insurance
      - "1": Disability insurance benefits
      - "2": End-stage renal disease
      - "3": Both DIB and ESRD

medicaid: If the patient is in Medicaid or not.

</code></pre></div></div>

<p>Required parameters should be stored in Spark dataframe.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">df</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------------+------------------------------+---+------+-----------+----+--------+</span>
<span class="o">|</span><span class="n">hcc_profileV24</span> <span class="o">|</span><span class="n">icd10_code</span>                    <span class="o">|</span><span class="n">age</span><span class="o">|</span><span class="n">gender</span><span class="o">|</span><span class="n">eligibility</span><span class="o">|</span><span class="n">orec</span><span class="o">|</span><span class="n">medicaid</span><span class="o">|</span>
<span class="o">+---------------+------------------------------+---+------+-----------+----+--------+</span>
<span class="o">|</span><span class="p">{</span><span class="s">"hcc_lst"</span><span class="p">:[...</span><span class="o">|</span><span class="p">[</span><span class="n">E1169</span><span class="p">,</span> <span class="n">I5030</span><span class="p">,</span> <span class="n">I509</span><span class="p">,</span> <span class="n">E852</span><span class="p">]</span>    <span class="o">|</span><span class="mi">64</span> <span class="o">|</span><span class="n">F</span>     <span class="o">|</span><span class="n">CFA</span>        <span class="o">|</span><span class="mi">0</span>   <span class="o">|</span><span class="n">true</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="s">"hcc_lst"</span><span class="p">:[...</span><span class="o">|</span><span class="p">[</span><span class="n">G629</span><span class="p">,</span> <span class="n">D469</span><span class="p">,</span> <span class="n">D6181</span><span class="p">]</span>           <span class="o">|</span><span class="mi">77</span> <span class="o">|</span><span class="n">M</span>     <span class="o">|</span><span class="n">CND</span>        <span class="o">|</span><span class="mi">1</span>   <span class="o">|</span><span class="n">false</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="s">"hcc_lst"</span><span class="p">:[...</span><span class="o">|</span><span class="p">[</span><span class="n">D473</span><span class="p">,</span> <span class="n">D473</span><span class="p">,</span> <span class="n">D473</span><span class="p">,</span> <span class="n">M069</span><span class="p">,</span> <span class="n">C969</span><span class="p">]</span><span class="o">|</span><span class="mi">16</span> <span class="o">|</span><span class="n">F</span>     <span class="o">|</span><span class="n">CPA</span>        <span class="o">|</span><span class="mi">3</span>   <span class="o">|</span><span class="n">true</span>    <span class="o">|</span>
<span class="o">+---------------+------------------------------+---+------+-----------+----+--------+</span>

<span class="n">The</span> <span class="n">content</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hcc_profileV24</span> <span class="n">column</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">JSON</span><span class="o">-</span><span class="n">parsable</span> <span class="n">string</span><span class="p">,</span> <span class="n">like</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">following</span> <span class="n">example</span><span class="p">,</span>
<span class="p">{</span>
    <span class="s">"hcc_lst"</span><span class="p">:</span> <span class="p">[</span>
        <span class="s">"HCC18"</span><span class="p">,</span>
        <span class="s">"HCC85_gDiabetesMellit"</span><span class="p">,</span>
        <span class="s">"HCC85"</span><span class="p">,</span>
        <span class="s">"HCC23"</span><span class="p">,</span>
        <span class="s">"D3"</span>
    <span class="p">],</span>
    <span class="s">"details"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"CNA_HCC18"</span><span class="p">:</span> <span class="mf">0.302</span><span class="p">,</span>
        <span class="s">"CNA_HCC85"</span><span class="p">:</span> <span class="mf">0.331</span><span class="p">,</span>
        <span class="s">"CNA_HCC23"</span><span class="p">:</span> <span class="mf">0.194</span><span class="p">,</span>
        <span class="s">"CNA_D3"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="s">"CNA_HCC85_gDiabetesMellit"</span><span class="p">:</span> <span class="mf">0.0</span>
    <span class="p">},</span>
    <span class="s">"hcc_map"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"E1169"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"HCC18"</span>
        <span class="p">],</span>
        <span class="s">"I5030"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"HCC85"</span>
        <span class="p">],</span>
        <span class="s">"I509"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"HCC85"</span>
        <span class="p">],</span>
        <span class="s">"E852"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"HCC23"</span>
        <span class="p">]</span>
    <span class="p">},</span>
    <span class="s">"risk_score"</span><span class="p">:</span> <span class="mf">0.827</span><span class="p">,</span>
    <span class="s">"parameters"</span><span class="p">:</span> <span class="p">{</span>
        <span class="s">"elig"</span><span class="p">:</span> <span class="s">"CNA"</span><span class="p">,</span>
        <span class="s">"age"</span><span class="p">:</span> <span class="mi">56</span><span class="p">,</span>
        <span class="s">"sex"</span><span class="p">:</span> <span class="s">"F"</span><span class="p">,</span>
        <span class="s">"origds"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
        <span class="s">"disabled"</span><span class="p">:</span> <span class="n">false</span><span class="p">,</span>
        <span class="s">"medicaid"</span><span class="p">:</span> <span class="n">false</span>
    <span class="p">}</span>
<span class="p">}</span>


</code></pre></div></div>
<p>We can import different CMS-HCC model versions as seperate functions and use them in the same program.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.functions</span> <span class="kn">import</span> <span class="n">profile</span><span class="p">,</span><span class="n">profileV22</span><span class="p">,</span><span class="n">profileV23</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"hcc_profileV24"</span><span class="p">,</span> <span class="n">profile</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">icd10_code</span><span class="p">,</span>
                                          <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span>
                                          <span class="n">df</span><span class="p">.</span><span class="n">gender</span><span class="p">,</span>
                                          <span class="n">df</span><span class="p">.</span><span class="n">eligibility</span><span class="p">,</span>
                                          <span class="n">df</span><span class="p">.</span><span class="n">orec</span><span class="p">,</span>
                                          <span class="n">df</span><span class="p">.</span><span class="n">medicaid</span>
                                          <span class="p">))</span>

<span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"hcc_profileV22"</span><span class="p">,</span> <span class="n">profileV22</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">codes</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">sex</span><span class="p">,</span><span class="n">df</span><span class="p">.</span><span class="n">elig</span><span class="p">,</span><span class="n">df</span><span class="p">.</span><span class="n">orec</span><span class="p">,</span><span class="n">df</span><span class="p">.</span><span class="n">medicaid</span><span class="p">))</span>
<span class="n">df</span><span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"hcc_profileV23"</span><span class="p">,</span> <span class="n">profileV23</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">codes</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">sex</span><span class="p">,</span><span class="n">df</span><span class="p">.</span><span class="n">elig</span><span class="p">,</span><span class="n">df</span><span class="p">.</span><span class="n">orec</span><span class="p">,</span><span class="n">df</span><span class="p">.</span><span class="n">medicaid</span><span class="p">))</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+----------+------------------------------+---+------+-----------+----+--------+</span>
<span class="o">|</span><span class="n">risk_score</span><span class="o">|</span><span class="n">icd10_code</span>                    <span class="o">|</span><span class="n">age</span><span class="o">|</span><span class="n">gender</span><span class="o">|</span><span class="n">eligibility</span><span class="o">|</span><span class="n">orec</span><span class="o">|</span><span class="n">medicaid</span><span class="o">|</span>
<span class="o">+----------+------------------------------+---+------+-----------+----+--------+</span>
<span class="o">|</span><span class="mf">0.922</span>     <span class="o">|</span><span class="p">[</span><span class="n">E1169</span><span class="p">,</span> <span class="n">I5030</span><span class="p">,</span> <span class="n">I509</span><span class="p">,</span> <span class="n">E852</span><span class="p">]</span>    <span class="o">|</span><span class="mi">64</span> <span class="o">|</span><span class="n">F</span>     <span class="o">|</span><span class="n">CFA</span>        <span class="o">|</span><span class="mi">0</span>   <span class="o">|</span><span class="n">true</span>    <span class="o">|</span>
<span class="o">|</span><span class="mf">3.566</span>     <span class="o">|</span><span class="p">[</span><span class="n">G629</span><span class="p">,</span> <span class="n">D469</span><span class="p">,</span> <span class="n">D6181</span><span class="p">]</span>           <span class="o">|</span><span class="mi">77</span> <span class="o">|</span><span class="n">M</span>     <span class="o">|</span><span class="n">CND</span>        <span class="o">|</span><span class="mi">1</span>   <span class="o">|</span><span class="n">false</span>   <span class="o">|</span>
<span class="o">|</span><span class="mf">1.181</span>     <span class="o">|</span><span class="p">[</span><span class="n">D473</span><span class="p">,</span> <span class="n">D473</span><span class="p">,</span> <span class="n">D473</span><span class="p">,</span> <span class="n">M069</span><span class="p">,</span> <span class="n">C969</span><span class="p">]</span><span class="o">|</span><span class="mi">16</span> <span class="o">|</span><span class="n">F</span>     <span class="o">|</span><span class="n">CPA</span>        <span class="o">|</span><span class="mi">3</span>   <span class="o">|</span><span class="n">true</span>    <span class="o">|</span>
<span class="o">+----------+------------------------------+---+------+-----------+----+--------+</span>
</code></pre></div></div>

<h4 id="updated-notebooks-for-resolvers-and-graph-builders">Updated Notebooks for resolvers and graph builders</h4>

<ul>
  <li>We have updated the resolver notebooks on spark-nlp-workshop repo with new <code class="language-plaintext highlighter-rouge">BertSentenceChunkEmbeddings</code> annotator. This annotator lets users aggregate sentence embeddings and ner chunk embeddings to get more specific and accurate resolution codes. It works by averaging context and chunk embeddings to get contextual information. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The <code class="language-plaintext highlighter-rouge">setChunkWeight</code> parameter can be used to control the influence of surrounding context. Example below shows the comparison of old vs new approach.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>text</th>
      <th>ner_chunk</th>
      <th>entity</th>
      <th>icd10_code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>icd10_code_SCE</th>
      <th>all_codes_SCE</th>
      <th>resolutions_SCE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection.</td>
      <td>a respiratory tract infection</td>
      <td>PROBLEM</td>
      <td>J988</td>
      <td>[J988, J069, A499, J22, J209,…]</td>
      <td>[respiratory tract infection, upper respiratory tract infection, bacterial respiratory infection, acute respiratory infection, bronchial infection,…]</td>
      <td>Z870</td>
      <td>[Z870, Z8709, J470, J988, A499,…</td>
      <td>[history of acute lower respiratory tract infection (situation), history of acute lower respiratory tract infection, bronchiectasis with acute lower respiratory infection, rti - respiratory tract infection, bacterial respiratory infection,…</td>
    </tr>
  </tbody>
</table>

<p>Here are the updated resolver notebooks:</p>

<blockquote>
  <ul>
    <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb">3.Clinical_Entity_Resolvers.ipynb</a></li>
    <li><a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb">24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb</a></li>
  </ul>
</blockquote>

<p>You can also check for more examples of this annotator: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb">24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb</a></p>

<ul>
  <li>We have updated TF Graph builder notebook to show how to create TF graphs with TF2.x.</li>
</ul>

<blockquote>
  <p>Here is the updated notebook: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb">17.Graph_builder_for_DL_models.ipynb</a></p>
</blockquote>

<p><strong>To see more, please check: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></strong></p>

<h4 id="new-tf-graph-builder">New TF Graph Builder</h4>

<p>TF graph builder to create graphs and train DL models for licensed annotators (MedicalNer, Relation Extraction, Assertion and Generic Classifier) is made compatible with TF2.x.</p>

<p>To see how to create TF Graphs, you can check here: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb">17.Graph_builder_for_DL_models.ipynb</a></p>

<h2 id="320">3.2.0</h2>
<p>We are glad to announce that Spark NLP Healthcare 3.2.0 has been released!.</p>

<h4 id="highlights-13">Highlights</h4>

<ul>
  <li>New Sentence Boundary Detection Model for Healthcare text</li>
  <li>New Assertion Status Models</li>
  <li>New Sentence Entity Resolver Model</li>
  <li>Finetuning Sentence Entity Resolvers with Your Data</li>
  <li>New Clinical NER Models</li>
  <li>New CMS-HCC risk-adjustment score calculation module</li>
  <li>New Embedding generation module for entity resolution</li>
</ul>

<h5 id="new-sentence-boundary-detection-model-for-healthcare-text">New Sentence Boundary Detection Model for Healthcare text</h5>

<p>We are releasing an updated Sentence Boundary detection model to identify complex sentences containing multiple measurements, and punctuations. This model is trained on an in-house dataset.</p>

<p><em>Example</em>:</p>

<p><em>Python:</em></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
documenter <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
  .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>

sentencerDL <span class="o">=</span> SentenceDetectorDLModel
  .pretrained<span class="o">(</span><span class="s2">"sentence_detector_dl_healthcare"</span>,<span class="s2">"en"</span>,<span class="s2">"clinical/models"</span><span class="o">)</span>
  .setInputCols<span class="o">([</span><span class="s2">"document"</span><span class="o">])</span>
  .setOutputCol<span class="o">(</span><span class="s2">"sentences"</span><span class="o">)</span>

text <span class="o">=</span> <span class="s2">"""He was given boluses of MS04 with some effect.he has since been placed on a PCA . He takes 80 mg. of ativan at home ativan for anxiety,
with 20 meq kcl po, 30 mmol K-phos iv and 2 gms mag so4 iv.
Size: Prostate gland measures 10x1.1x 4.9 cm (LS x AP x TS). Estimated volume is
51.9 ml. and is mildly enlarged in size.Normal delineation pattern of the prostate gland is preserved.
"""</span>

sd_model <span class="o">=</span> LightPipeline<span class="o">(</span>PipelineModel<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documenter, sentencerDL]<span class="o">))</span>

result <span class="o">=</span> sd_model.fullAnnotate<span class="o">(</span>text<span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| s.no | sentences                                                      |
|-----:|:---------------------------------------------------------------|
|    0 | He was given boluses of MS04 with some effect.                 |
|    1 | he has since been placed on a PCA .                            |
|    2 | He takes 80 mg. of ativan at home ativan for anxiety,          |
|      | with 20 meq kcl po, 30 mmol K-phos iv and 2 gms mag so4 iv.    |
|    3 | Size: Prostate gland measures 10x1.1x 4.9 cm (LS x AP x TS).   |
|    4 | Estimated volume is                                            |
|      | 51.9 ml. and is mildly enlarged in size.                       |
|    5 | Normal delineation pattern of the prostate gland is preserved. |

</code></pre></div></div>

<h5 id="new-assertion-status-models">New Assertion Status Models</h5>

<p>We are releasing two new Assertion Status Models based on the BiLSTM architecture. Apart from what we released in other assertion models, an in-house annotations on a curated dataset (6K clinical notes) is used to augment the base assertion dataset (2010 i2b2/VA).</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">assertion_jsl</code>: This model can classify the assertions made on given medical concepts as being <code class="language-plaintext highlighter-rouge">Present</code>, <code class="language-plaintext highlighter-rouge">Absent</code>, <code class="language-plaintext highlighter-rouge">Possible</code>, <code class="language-plaintext highlighter-rouge">Planned</code>, <code class="language-plaintext highlighter-rouge">Someoneelse</code>, <code class="language-plaintext highlighter-rouge">Past</code>, <code class="language-plaintext highlighter-rouge">Family</code>, <code class="language-plaintext highlighter-rouge">None</code>, <code class="language-plaintext highlighter-rouge">Hypotetical</code>.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">assertion_jsl_large</code>: This model can classify the assertions made on given medical concepts as being <code class="language-plaintext highlighter-rouge">present</code>, <code class="language-plaintext highlighter-rouge">absent</code>, <code class="language-plaintext highlighter-rouge">possible</code>, <code class="language-plaintext highlighter-rouge">planned</code>, <code class="language-plaintext highlighter-rouge">someoneelse</code>, <code class="language-plaintext highlighter-rouge">past</code>.</p>
  </li>
</ul>

<p><em>assertion_dl vs assertion_jsl</em>:</p>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>entities</th>
      <th>assertion_dl</th>
      <th>assertion_jsl</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Mesothelioma</td>
      <td>PROBLEM</td>
      <td>present</td>
      <td>Present</td>
    </tr>
    <tr>
      <td>CVA</td>
      <td>PROBLEM</td>
      <td>absent</td>
      <td>Absent</td>
    </tr>
    <tr>
      <td>cancer</td>
      <td>PROBLEM</td>
      <td>associated_with_someone_else</td>
      <td>Family</td>
    </tr>
    <tr>
      <td>her INR</td>
      <td>TEST</td>
      <td>present</td>
      <td>Planned</td>
    </tr>
    <tr>
      <td>Amiodarone</td>
      <td>TREATMENT</td>
      <td>hypothetical</td>
      <td>Hypothetical</td>
    </tr>
    <tr>
      <td>lymphadenopathy</td>
      <td>PROBLEM</td>
      <td>absent</td>
      <td>Absent</td>
    </tr>
    <tr>
      <td>stage III disease</td>
      <td>PROBLEM</td>
      <td>possible</td>
      <td>Possible</td>
    </tr>
    <tr>
      <td>IV piggyback</td>
      <td>TREATMENT</td>
      <td>conditional</td>
      <td>Past</td>
    </tr>
  </tbody>
</table>

<p><em>Example</em>:</p>

<p><em>Python:</em></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
clinical_assertion <span class="o">=</span> AssertionDLModel.pretrained<span class="o">(</span><span class="s2">"assertion_jsl"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"ner_chunk"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s2">"assertion"</span><span class="o">)</span>

nlpPipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documentAssembler, sentenceDetector, tokenizer, word_embeddings, clinical_ner, ner_converter, clinical_assertion]<span class="o">)</span>
model <span class="o">=</span> nlpPipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>

result <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"The patient is a 41-year-old and has a nonproductive cough that started last week. She has had right-sided chest pain radiating to her back with fever starting today. She has no nausea. She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center and Chest x-ray revealed right-sided pleural effusion. In family history, her father has a colon cancer history."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">])</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------------+-----+---+-------------------------+-------+---------+
|chunk              |begin|end|ner_label                |sent_id|assertion|
+-------------------+-----+---+-------------------------+-------+---------+
|nonproductive cough|35   |53 |Symptom                  |0      |Present  |
|last week          |68   |76 |RelativeDate             |0      |Past     |
|chest pain         |103  |112|Symptom                  |1      |Present  |
|fever              |141  |145|VS_Finding               |1      |Present  |
|today              |156  |160|RelativeDate             |1      |Present  |
|nausea             |174  |179|Symptom                  |2      |Absent   |
|pericarditis       |203  |214|Disease_Syndrome_Disorder|3      |Past     |
|pericardectomy     |220  |233|Procedure                |3      |Past     |
|May 2006           |238  |245|Date                     |3      |Past     |
|cough              |261  |265|Symptom                  |3      |Past     |
|chest pain         |284  |293|Symptom                  |3      |Past     |
|Chest x-ray        |334  |344|Test                     |3      |Past     |
|pleural effusion   |367  |382|Disease_Syndrome_Disorder|3      |Past     |
|colon cancer       |421  |432|Oncological              |4      |Family   |
+-------------------+-----+---+-------------------------+-------+---------+
</code></pre></div></div>

<h4 id="new-sentence-entity-resolver-model">New Sentence Entity Resolver Model</h4>

<p>We are releasing <code class="language-plaintext highlighter-rouge">sbiobertresolve_rxnorm_disposition</code> model that maps medication entities (like drugs/ingredients) to RxNorm codes and their dispositions using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> Sentence Bert Embeddings. In the result, look for the aux_label parameter in the metadata to get dispositions that were divided by <code class="language-plaintext highlighter-rouge">|</code>.</p>

<p><em>Example</em>:</p>

<p><em>Python</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
documentAssembler <span class="o">=</span> DocumentAssembler<span class="o">()</span><span class="se">\</span>
      .setInputCol<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner_chunk"</span><span class="o">)</span>

sbert_embedder <span class="o">=</span> BertSentenceEmbeddings.pretrained<span class="o">(</span><span class="s1">'sbiobert_base_cased_mli'</span>, <span class="s1">'en'</span>,<span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span><span class="o">])</span><span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"sbert_embeddings"</span><span class="o">)</span>

rxnorm_resolver <span class="o">=</span> SentenceEntityResolverModel.pretrained<span class="o">(</span><span class="s2">"sbiobertresolve_rxnorm_disposition"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"ner_chunk"</span>, <span class="s2">"sbert_embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"rxnorm_code"</span><span class="o">)</span><span class="se">\</span>
      .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span>

pipelineModel <span class="o">=</span> PipelineModel<span class="o">(</span>
    stages <span class="o">=</span> <span class="o">[</span>
        documentAssembler,
        sbert_embedder,
        rxnorm_resolver
    <span class="o">])</span>

rxnorm_lp <span class="o">=</span> LightPipeline<span class="o">(</span>pipelineModel<span class="o">)</span>

result <span class="o">=</span> rxnorm_lp.fullAnnotate<span class="o">(</span><span class="s2">"belimumab 80 mg/ml injectable solution"</span><span class="o">)</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunks                                | code    | resolutions                                                                                                                                                                                 | all_codes                                         | all_k_aux_labels                                                                            | all_distances                                 |
|---:|:--------------------------------------|:--------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------|:--------------------------------------------------------------------------------------------|:----------------------------------------------|
|  0 |belimumab 80 mg/ml injectable solution | 1092440 | [belimumab 80 mg/ml injectable solution, belimumab 80 mg/ml injectable solution [benlysta], ifosfamide 80 mg/ml injectable solution, belimumab 80 mg/ml [benlysta], belimumab 80 mg/ml, ...]| [1092440, 1092444, 107034, 1092442, 1092438, ...] | [Immunomodulator, Immunomodulator, Alkylating agent, Immunomodulator, Immunomodulator, ...] | [0.0000, 0.0145, 0.0479, 0.0619, 0.0636, ...] |
</code></pre></div></div>

<h4 id="finetuning-sentence-entity-resolvers-with-your-data">Finetuning Sentence Entity Resolvers with Your Data</h4>

<p>Instead of starting from scratch when training a new Sentence Entity Resolver model, you can train a new model by adding your new data to the pretrained model.</p>

<p>There’s a new method <code class="language-plaintext highlighter-rouge">setPretrainedModelPath(path)</code>, which allows you to point the training process to an existing model, and allows you to initialize your model with the data from the pretrained model.</p>

<p>When both the new data and the pretrained model contain the same code, you will see both of the results at the top.</p>

<p>Here is a sample notebook : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.1.Finetuning_Sentence_Entity_Resolver_Model.ipynb">Finetuning Sentence Entity Resolver Model Notebook</a></p>

<p><em>Example:</em></p>

<p>In the example below, we changed the code of <code class="language-plaintext highlighter-rouge">sepsis</code> to <code class="language-plaintext highlighter-rouge">X1234</code> and re-retrain the main ICD10-CM model with this new dataset. So we want to see the <code class="language-plaintext highlighter-rouge">X1234</code> code as a result in the all_codes.</p>

<p><em>Python:</em></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
bertExtractor <span class="o">=</span> SentenceEntityResolverApproach<span class="o">()</span><span class="se">\</span>
  .setNeighbours<span class="o">(</span>50<span class="o">)</span><span class="se">\</span>
  .setThreshold<span class="o">(</span>1000<span class="o">)</span><span class="se">\</span>
  .setInputCols<span class="o">(</span><span class="s2">"sentence_embeddings"</span><span class="o">)</span><span class="se">\</span>
  .setNormalizedCol<span class="o">(</span><span class="s2">"description_normalized"</span><span class="o">)</span><span class="se">\ </span>  <span class="c"># concept_name</span>
  .setLabelCol<span class="o">(</span><span class="s2">"code"</span><span class="o">)</span><span class="se">\ </span>    <span class="c"># concept_code</span>
  .setOutputCol<span class="o">(</span><span class="s2">"recognized_code"</span><span class="o">)</span><span class="se">\</span>
  .setDistanceFunction<span class="o">(</span><span class="s2">"EUCLIDEAN"</span><span class="o">)</span><span class="se">\</span>
  .setCaseSensitive<span class="o">(</span>False<span class="o">)</span><span class="se">\ </span>        
  .setUseAuxLabel<span class="o">(</span>True<span class="o">)</span><span class="se">\ </span>        <span class="c"># if exist  </span>
  .setPretrainedModelPath<span class="o">(</span><span class="s2">"path_to_a_pretrained_model"</span><span class="o">)</span>


new_model <span class="o">=</span> bertExtractor.fit<span class="o">(</span><span class="s2">"new_dataset"</span><span class="o">)</span>
new_model.save<span class="o">(</span><span class="s2">"models/new_resolver_model"</span><span class="o">)</span>  <span class="c"># save and use later</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
resolver_model = SentenceEntityResolverModel.load("models/new_resolver_model") \
      .setInputCols(["ner_chunk", "sentence_embeddings"]) \
      .setOutputCol("output_code")

pipelineModel = PipelineModel(
    stages = [
        documentAssembler,
        sentence_embedder,
        resolver_model])

light_model = LightPipeline(pipelineModel)
light_model.fullAnnotate("sepsis")
</code></pre></div></div>

<p><em>Main Model Results</em>:</p>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>begin</th>
      <th>end</th>
      <th>code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>all_k_aux_labels</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sepsis</td>
      <td>0</td>
      <td>5</td>
      <td>A4189</td>
      <td>[A4189, L419, A419, A267, E771, …]</td>
      <td>[sepsis [Other specified sepsis], parapsoriasis [Parapsoriasis, unspecified], postprocedural sepsis [Sepsis, unspecified organism], erysipelothrix sepsis [Erysipelothrix sepsis], fucosidosis [Defects in glycoprotein degradation], … ]</td>
      <td>[1|1|2, 1|1|2, 1|1|2, 1|1|2, 1|1|23, …]</td>
      <td>[0.0000, 0.2079, 0.2256, 0.2359, 0.2399,…]</td>
    </tr>
  </tbody>
</table>

<p><em>Re-Trained Model Results</em>:</p>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>begin</th>
      <th>end</th>
      <th>code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>all_k_aux_labels</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sepsis</td>
      <td>0</td>
      <td>5</td>
      <td>X1234</td>
      <td>[X1234, A4189, A419, L419, A267, …]</td>
      <td>[sepsis [Sepsis, new resolution], sepsis [Other specified sepsis], SEPSIS [Sepsis, unspecified organism], parapsoriasis [Parapsoriasis, unspecified], erysipelothrix sepsis [Erysipelothrix sepsis], … ]</td>
      <td>[1|1|74, 1|1|2, 1|1|2, 1|1|2, 1|1|2, …]</td>
      <td>[0.0000, 0.0000, 0.0000, 0.2079, 0.2359, …]</td>
    </tr>
  </tbody>
</table>

<h4 id="new-clinical-ner-models-2">New Clinical NER Models</h4>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_jsl_slim</code>: This model is trained based on <code class="language-plaintext highlighter-rouge">ner_jsl</code> model with more generalized entities.</p>

    <p>(<code class="language-plaintext highlighter-rouge">Death_Entity</code>, <code class="language-plaintext highlighter-rouge">Medical_Device</code>, <code class="language-plaintext highlighter-rouge">Vital_Sign</code>, <code class="language-plaintext highlighter-rouge">Alergen</code>, <code class="language-plaintext highlighter-rouge">Drug</code>, <code class="language-plaintext highlighter-rouge">Clinical_Dept</code>, <code class="language-plaintext highlighter-rouge">Lifestyle</code>, <code class="language-plaintext highlighter-rouge">Symptom</code>, <code class="language-plaintext highlighter-rouge">Body_Part</code>, <code class="language-plaintext highlighter-rouge">Physical_Measurement</code>, <code class="language-plaintext highlighter-rouge">Admission_Discharge</code>, <code class="language-plaintext highlighter-rouge">Date_Time</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Birth_Entity</code>, <code class="language-plaintext highlighter-rouge">Header</code>, <code class="language-plaintext highlighter-rouge">Oncological</code>, <code class="language-plaintext highlighter-rouge">Substance_Quantity</code>, <code class="language-plaintext highlighter-rouge">Test_Result</code>, <code class="language-plaintext highlighter-rouge">Test</code>, <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">Treatment</code>, <code class="language-plaintext highlighter-rouge">Disease_Syndrome_Disorder</code>, <code class="language-plaintext highlighter-rouge">Pregnancy_Newborn</code>, <code class="language-plaintext highlighter-rouge">Demographics</code>)</p>
  </li>
</ul>

<p><em>ner_jsl vs ner_jsl_slim</em>:</p>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>ner_jsl</th>
      <th>ner_jsl_slim</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Description:</td>
      <td>Section_Header</td>
      <td>Header</td>
    </tr>
    <tr>
      <td>atrial fibrillation</td>
      <td>Heart_Disease</td>
      <td>Disease_Syndrome_Disorder</td>
    </tr>
    <tr>
      <td>August 24, 2007</td>
      <td>Date</td>
      <td>Date_Time</td>
    </tr>
    <tr>
      <td>transpleural fluoroscopy</td>
      <td>Procedure</td>
      <td>Test</td>
    </tr>
    <tr>
      <td>last week</td>
      <td>RelativeDate</td>
      <td>Date_Time</td>
    </tr>
    <tr>
      <td>She</td>
      <td>Gender</td>
      <td>Demographics</td>
    </tr>
    <tr>
      <td>fever</td>
      <td>VS_Finding</td>
      <td>Vital_Sign</td>
    </tr>
    <tr>
      <td>PAST MEDICAL HISTORY:</td>
      <td>Medical_History_Header</td>
      <td>Header</td>
    </tr>
    <tr>
      <td>Pericardial window</td>
      <td>Internal_organ_or_component</td>
      <td>Body_Part</td>
    </tr>
    <tr>
      <td>FAMILY HISTORY:</td>
      <td>Family_History_Header</td>
      <td>Header</td>
    </tr>
    <tr>
      <td>CVA</td>
      <td>Cerebrovascular_Disease</td>
      <td>Disease_Syndrome_Disorder</td>
    </tr>
    <tr>
      <td>diabetes</td>
      <td>Diabetes</td>
      <td>Disease_Syndrome_Disorder</td>
    </tr>
    <tr>
      <td>married</td>
      <td>Relationship_Status</td>
      <td>Demographics</td>
    </tr>
    <tr>
      <td>alcohol</td>
      <td>Alcohol</td>
      <td>Lifestyle</td>
    </tr>
    <tr>
      <td>illicit drug</td>
      <td>Substance</td>
      <td>Lifestyle</td>
    </tr>
    <tr>
      <td>Coumadin</td>
      <td>Drug_BrandName</td>
      <td>Drug</td>
    </tr>
    <tr>
      <td>Blood pressure 123/95</td>
      <td>Blood_Pressure</td>
      <td>Vital_Sign</td>
    </tr>
    <tr>
      <td>heart rate 83</td>
      <td>Pulse</td>
      <td>Vital_Sign</td>
    </tr>
    <tr>
      <td>anticoagulated</td>
      <td>Drug_Ingredient</td>
      <td>Drug</td>
    </tr>
  </tbody>
</table>

<p><em>Example</em>:</p>

<p><em>Python</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings_clinical <span class="o">=</span> WordEmbeddingsModel<span class="o">()</span>.pretrained<span class="o">(</span><span class="s1">'embeddings_clinical'</span>, <span class="s1">'en'</span>, <span class="s1">'clinical/models'</span><span class="o">)</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s1">'sentence'</span>, <span class="s1">'token'</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s1">'embeddings'</span><span class="o">)</span>

clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_jsl_slim"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...

nlpPipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>document_assembler, sentence_detector, tokenizer, embeddings_clinical,  clinical_ner, ner_converter]<span class="o">)</span>
model <span class="o">=</span> nlpPipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>

results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"HISTORY: 30-year-old female presents for digital bilateral mammography secondary to a soft tissue lump palpated by the patient in the upper right shoulder. The patient has a family history of breast cancer within her mother at age 58. Patient denies personal history of breast cancer."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk            | entity       |
|---:|:-----------------|:-------------|
|  0 | HISTORY:         | Header       |
|  1 | 30-year-old      | Age          |
|  2 | female           | Demographics |
|  3 | mammography      | Test         |
|  4 | soft tissue lump | Symptom      |
|  5 | shoulder         | Body_Part    |
|  6 | breast cancer    | Oncological  |
|  7 | her mother       | Demographics |
|  8 | age 58           | Age          |
|  9 | breast cancer    | Oncological  |
</code></pre></div></div>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_jsl_biobert</code> : This model is the BioBert version of <code class="language-plaintext highlighter-rouge">ner_jsl</code> model and trained with <code class="language-plaintext highlighter-rouge">biobert_pubmed_base_cased</code> embeddings.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ner_jsl_greedy_biobert</code> : This model is the BioBert version of <code class="language-plaintext highlighter-rouge">ner_jsl_greedy</code> models and trained with <code class="language-plaintext highlighter-rouge">biobert_pubmed_base_cased</code> embeddings.</p>
  </li>
</ul>

<p><em>Example</em>:</p>

<p><em>Python</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
embeddings_clinical <span class="o">=</span> BertEmbeddings.pretrained<span class="o">(</span><span class="s1">'biobert_pubmed_base_cased'</span><span class="o">)</span> <span class="se">\</span>
    .setInputCols<span class="o">([</span><span class="s1">'sentence'</span>, <span class="s1">'token'</span><span class="o">])</span> <span class="se">\</span>
    .setOutputCol<span class="o">(</span><span class="s1">'embeddings'</span><span class="o">)</span>
clinical_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_jsl_greedy_biobert"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
  .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
  .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...
nlpPipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>document_assembler, sentence_detector, tokenizer, embeddings_clinical,  clinical_ner, ner_converter]<span class="o">)</span>
model <span class="o">=</span> nlpPipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>
results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">"The patient is a 21-day-old Caucasian male here for 2 days of congestion - mom has been suctioning yellow discharge from the patient's nares, plus she has noticed some mild problems with his breathing while feeding (but negative for any perioral cyanosis or retractions). One day ago, mom also noticed a tactile temperature and gave the patient Tylenol. Baby also has had some decreased p.o. intake. His normal breast-feeding is down from 20 minutes q.2h. to 5 to 10 minutes secondary to his respiratory congestion. He sleeps well, but has been more tired and has been fussy over the past 2 days. The parents noticed no improvement with albuterol treatments given in the ER. His urine output has also decreased; normally he has 8 to 10 wet and 5 dirty diapers per 24 hours, now he has down to 4 wet diapers per 24 hours. Mom denies any diarrhea. His bowel movements are yellow colored and soft in nature."</span><span class="o">]]</span>, <span class="o">[</span><span class="s2">"text"</span><span class="o">]))</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk                                          | entity                       |
|---:|:-----------------------------------------------|:-----------------------------|
|  0 | 21-day-old                                     | Age                          |
|  1 | Caucasian                                      | Race_Ethnicity               |
|  2 | male                                           | Gender                       |
|  3 | <span class="k">for </span>2 days                                     | Duration                     |
|  4 | congestion                                     | Symptom                      |
|  5 | mom                                            | Gender                       |
|  6 | suctioning yellow discharge                    | Symptom                      |
|  7 | nares                                          | External_body_part_or_region |
|  8 | she                                            | Gender                       |
|  9 | mild problems with his breathing <span class="k">while </span>feeding | Symptom                      |
| 10 | perioral cyanosis                              | Symptom                      |
| 11 | retractions                                    | Symptom                      |
| 12 | One day ago                                    | RelativeDate                 |
| 13 | mom                                            | Gender                       |
| 14 | tactile temperature                            | Symptom                      |
| 15 | Tylenol                                        | Drug                         |
| 16 | Baby                                           | Age                          |
| 17 | decreased p.o. intake                          | Symptom                      |
| 18 | His                                            | Gender                       |
| 19 | breast-feeding                                 | External_body_part_or_region |
| 20 | q.2h                                           | Frequency                    |
| 21 | to 5 to 10 minutes                             | Duration                     |
| 22 | his                                            | Gender                       |
| 23 | respiratory congestion                         | Symptom                      |
| 24 | He                                             | Gender                       |
| 25 | tired                                          | Symptom                      |
| 26 | fussy                                          | Symptom                      |
| 27 | over the past 2 days                           | RelativeDate                 |
| 28 | albuterol                                      | Drug                         |
| 29 | ER                                             | Clinical_Dept                |
| 30 | His                                            | Gender                       |
| 31 | urine output has also decreased                | Symptom                      |
| 32 | he                                             | Gender                       |
| 33 | per 24 hours                                   | Frequency                    |
| 34 | he                                             | Gender                       |
| 35 | per 24 hours                                   | Frequency                    |
| 36 | Mom                                            | Gender                       |
| 37 | diarrhea                                       | Symptom                      |
| 38 | His                                            | Gender                       |
| 39 | bowel                                          | Internal_organ_or_component  |
</code></pre></div></div>

<h4 id="new-cms-hcc-risk-adjustment-score-calculation-module">New CMS-HCC risk-adjustment score calculation module</h4>

<p>We are releasing a new module to calculate medical risk adjusment score by using the Centers for Medicare &amp; Medicaid Service (CMS) risk adjustment model. The main input to this model are ICD codes of the diseases. After getting ICD codes of diseases by Spark NLP Healthcare ICD resolvers, risk score can be calculated by this module in spark environment.
Current supported version for the model is CMS-HCC V24.</p>

<p>The model needs following parameters in order to calculate the risk score:</p>
<ul>
  <li>ICD Codes</li>
  <li>Age</li>
  <li>Gender</li>
  <li>The eligibility segment of the patient</li>
  <li>Original reason for entitlement</li>
  <li>If the patient is in Medicaid or not</li>
  <li>If the patient is disabled or not</li>
</ul>

<p><em>Example</em>:</p>

<p><em>Python:</em></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sample_patients.show()
</code></pre></div></div>
<p><em>Results</em>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+----------+------------------------------+---+------+
|Patient_ID|ICD_codes                     |Age|Gender|
+----------+------------------------------+---+------+
|101       |[E1169, I5030, I509, E852]    |64 |F     |
|102       |[G629, D469, D6181]           |77 |M     |
|103       |[D473, D473, D473, M069, C969]|16 |F     |
+----------+------------------------------+---+------+
</code></pre></div></div>

<p><em>Python:</em></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.functions import profile
df = df.withColumn("hcc_profile", profile(df.ICD_codes, df.Age, df.Gender))

df = df.withColumn("hcc_profile", F.from_json(F.col("hcc_profile"), schema))
df= df.withColumn("risk_score", df.hcc_profile.getItem("risk_score"))\
      .withColumn("hcc_lst", df.hcc_profile.getItem("hcc_map"))\
      .withColumn("parameters", df.hcc_profile.getItem("parameters"))\
      .withColumn("details", df.hcc_profile.getItem("details"))\

df.select('Patient_ID', 'risk_score','ICD_codes', 'Age', 'Gender').show(truncate=False )

df.show(truncate=100, vertical=True)

</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
+----------+----------+------------------------------+---+------+
|Patient_ID|risk_score|ICD_codes                     |Age|Gender|
+----------+----------+------------------------------+---+------+
|101       |0.827     |[E1169, I5030, I509, E852]    |64 |F     |
|102       |1.845     |[G629, D469, D6181]           |77 |M     |
|103       |1.288     |[D473, D473, D473, M069, C969]|16 |F     |
+----------+----------+------------------------------+---+------+

RECORD 0-------------------------------------------------------------------------------------------------------------------
 Patient_ID          | 101                                                                                                  
 ICD_codes           | [E1169, I5030, I509, E852]                                                                           
 Age                 | 64                                                                                                   
 Gender              | F                                                                                                    
 Eligibility_Segment | CNA                                                                                                  
 OREC                | 0                                                                                                    
 Medicaid            | false                                                                                                 
 Disabled            | false                                                                                                
 hcc_profile         | {{"CNA_HCC18":0.302,"CNA_HCC85":0.331,"CNA_HCC23":0.194,"CNA_D3":0.0,"CNA_HCC85_gDiabetesMellit":...
 risk_score          | 0.827                                                                                                
 hcc_lst             | {"E1169":["HCC18"],"I5030":["HCC85"],"I509":["HCC85"],"E852":["HCC23"]}                              
 parameters          | {"elig":"CNA","age":64,"sex":"F","origds":'0',"disabled":false,"medicaid":false}                   
 details             | {"CNA_HCC18":0.302,"CNA_HCC85":0.331,"CNA_HCC23":0.194,"CNA_D3":0.0,"CNA_HCC85_gDiabetesMellit":0.0}
-RECORD 1-------------------------------------------------------------------------------------------------------------------
 Patient_ID          | 102                                                                                                  
 ICD_codes           | [G629, D469, D6181]                                                                                  
 Age                 | 77                                                                                                   
 Gender              | M                                                                                                    
 Eligibility_Segment | CNA                                                                                                  
 OREC                | 0                                                                                                    
 Medicaid            | false                                                                                                 
 Disabled            | false                                                                                                 
 hcc_profile         | {{"CNA_M75_79":0.473,"CNA_D1":0.0,"CNA_HCC46":1.372}, ["D1","HCC46"], {"D469":["HCC46"]}, {"elig"...
 risk_score          | 1.845                                                                                                
 hcc_lst             | {"D469":["HCC46"]}                                                                                   
 parameters          | {"elig":"CNA","age":77,"sex":"M","origds":'0',"disabled":false,"medicaid":false}                   
 details             | {"CNA_M75_79":0.473,"CNA_D1":0.0,"CNA_HCC46":1.372}                                                  
-RECORD 2-------------------------------------------------------------------------------------------------------------------
 Patient_ID          | 103                                                                                                  
 ICD_codes           | [D473, D473, D473, M069, C969]                                                                       
 Age                 | 16                                                                                                   
 Gender              | F                                                                                                    
 Eligibility_Segment | CNA                                                                                                  
 OREC                | 0                                                                                                    
 Medicaid            | false                                                                                                
 Disabled            | false                                                                                                
 hcc_profile         | {{"CNA_HCC10":0.675,"CNA_HCC40":0.421,"CNA_HCC48":0.192,"CNA_D3":0.0}, ["HCC10","HCC40","HCC48","...
 risk_score          | 1.288                                                                                                
 hcc_lst             | {"D473":["HCC48"],"M069":["HCC40"],"C969":["HCC10"]}                                                 
 parameters          | {"elig":"CNA","age":16,"sex":"F","origds":'0',"disabled":false,"medicaid":false}                   
 details             | {"CNA_HCC10":0.675,"CNA_HCC40":0.421,"CNA_HCC48":0.192,"CNA_D3":0.0}
</code></pre></div></div>

<p>Here is a sample notebook : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.1.Calculate_Medicare_Risk_Adjustment_Score.ipynb">Calculating Medicare Risk Adjustment Score</a></p>

<h4 id="new-embedding-generation-module-for-entity-resolution">New Embedding generation module for entity resolution</h4>

<p>We are releasing a new annotator <code class="language-plaintext highlighter-rouge">BertSentenceChunkEmbeddings</code> to let users aggregate sentence embeddings and ner chunk embeddings to get more specific and accurate resolution codes. It works by averaging context and chunk embeddings to get contextual information. This is specially helpful when ner chunks do not have additional information (like body parts or severity) as explained in the example below. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model. The <code class="language-plaintext highlighter-rouge">setChunkWeight</code> parameter can be used to control the influence of surrounding context. Example below shows the comparison of old vs new approach.</p>

<p>Sample Notebook: <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb">Improved_Entity_Resolution_with_SentenceChunkEmbeddings</a></p>

<p><em>Example</em>:</p>

<p><em>Python:</em></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
sentence_chunk_embeddings = BertSentenceChunkEmbeddings\
    .pretrained("sbiobert_base_cased_mli", "en", "clinical/models")\
    .setInputCols(["sentences", "ner_chunk"])\
    .setOutputCol("sentence_chunk_embeddings")\
    .setChunkWeight(0.5)

resolver = SentenceEntityResolverModel.pretrained('sbiobertresolve_icd10cm', 'en', 'clinical/models')\
            .setInputCols(["ner_chunk", "sentence_chunk_embeddings"]) \
              .setOutputCol("resolution")

text = """A 20 year old female patient badly tripped while going down stairs. She complains of right leg pain.
Her x-ray showed right hip fracture. Hair line fractures also seen on the left knee joint.
She also suffered from trauma and slight injury on the head.

OTHER CONDITIONS: She was also recently diagnosed with diabetes, which is of type 2.
"""

nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings_clinical,  clinical_ner, ner_converter, sentence_chunk_embeddings, resolver])
model = nlpPipeline.fit(spark.createDataFrame([[""]]).toDF("text"))
results = model.transform(spark.createDataFrame([[text]], ["text"]))
</code></pre></div></div>

<p><em>Results</em>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk               | entity              | code_with_old_approach | resolutions_with_old_approach                              | code_with_new_approach | resolutions_with_new_approach                                                                 |
|---:|:--------------------|:--------------------|:-----------------------|:-----------------------------------------------------------|:-----------------------|:----------------------------------------------------------------------------------------------|
|  0 | leg pain            | Symptom             | R1033                  | Periumbilical pain                                         | M79661                 | Pain in right lower leg                                                                       |
|  1 | hip fracture        | Injury_or_Poisoning | M84459S                | Pathological fracture, hip, unspecified, sequela           | M84451S                | Pathological fracture, right femur, sequela                                                   |
|  2 | Hair line fractures | Injury_or_Poisoning | S070XXS                | Crushing injury of face, sequela                           | S92592P                | Other fracture of left lesser toe(s), subsequent encounter for fracture with malunion         |
|  3 | trauma              | Injury_or_Poisoning | T794XXS                | Traumatic shock, sequela                                   | S0083XS                | Contusion of other part of head, sequela                                                      |
|  4 | slight injury       | Injury_or_Poisoning | B03                    | Smallpox                                                   | S0080XD                | Unspecified superficial injury of other part of head, subsequent encounter                    |
|  5 | diabetes            | Diabetes            | E118                   | Type 2 diabetes mellitus with unspecified complications    | E1169                  | Type 2 diabetes mellitus with other specified complication                                    |
</code></pre></div></div>

<p><strong>To see more, please check :</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop Repo</a></p>

<h2 id="313">3.1.3</h2>
<p>We are glad to announce that Spark NLP for Healthcare 3.1.3 has been released!.
This release comes with new features, new models, bug fixes, and examples.</p>

<h4 id="highlights-14">Highlights</h4>
<ul>
  <li>New Relation Extraction model and a Pretrained pipeline for extracting and linking ADEs</li>
  <li>New Entity Resolver model for SNOMED codes</li>
  <li>ChunkConverter Annotator</li>
  <li>BugFix: getAnchorDateMonth method in DateNormalizer.</li>
  <li>BugFix: character map in MedicalNerModel fine-tuning.</li>
</ul>

<h5 id="new-relation-extraction-model-and-a-pretrained-pipeline-for-extracting-and-linking-ades">New Relation Extraction model and a Pretrained pipeline for extracting and linking ADEs</h5>

<p>We are releasing a new Relation Extraction Model for ADEs. This model is trained using Bert Word embeddings (<code class="language-plaintext highlighter-rouge">biobert_pubmed_base_cased</code>), and is capable of linking ADEs and Drugs.</p>

<p><em>Example</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">re_model</span> <span class="o">=</span> <span class="n">RelationExtractionModel</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_ade_biobert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\ <span class="c1">#default: 0
</span>        <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\ <span class="c1">#default: 0.5
</span>        <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"ade-drug"</span><span class="p">,</span> <span class="s">"drug-ade"</span><span class="p">])</span> <span class="c1"># Possible relation pairs. Default: All Relations.
</span>
<span class="n">nlp_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">documenter</span><span class="p">,</span> <span class="n">sentencer</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">words_embedder</span><span class="p">,</span> <span class="n">pos_tagger</span><span class="p">,</span> <span class="n">ner_tagger</span><span class="p">,</span> <span class="n">ner_chunker</span><span class="p">,</span> <span class="n">dependency_parser</span><span class="p">,</span> <span class="n">re_model</span><span class="p">])</span>

<span class="n">light_pipeline</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">nlp_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">''</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)))</span>

<span class="n">text</span> <span class="o">=</span><span class="s">"""Been taking Lipitor for 15 years , have experienced sever fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps"""</span>

<span class="n">annotations</span> <span class="o">=</span> <span class="n">light_pipeline</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre></div></div>

<p>We also have a new pipeline comprising of all models related to ADE(Adversal Drug Event) as part of this release. This pipeline includes classification, NER, assertion and relation extraction models. Users can now use this pipeline to get classification result, ADE and Drug entities, assertion status for ADE entities, and relations between ADE and Drug entities.</p>

<p>Example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">pretrained_ade_pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">'explain_clinical_doc_ade'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">pretrained_ade_pipeline</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">(</span><span class="s">"""Been taking Lipitor for 15 years , have experienced sever fatigue a lot!!! . Doctor moved me to voltaren 2 months ago , so far , have only experienced cramps"""</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Class: True

NER_Assertion:
|    | chunk                   | entitiy    | assertion   |
|----|-------------------------|------------|-------------|
| 0  | Lipitor                 | DRUG       | -           |
| 1  | sever fatigue           | ADE        | Conditional |
| 2  | voltaren                | DRUG       | -           |
| 3  | cramps                  | ADE        | Conditional |

Relations:
|    | chunk1                        | entitiy1   | chunk2      | entity2 | relation |
|----|-------------------------------|------------|-------------|---------|----------|
| 0  | sever fatigue                 | ADE        | Lipitor     | DRUG    |        1 |
| 1  | cramps                        | ADE        | Lipitor     | DRUG    |        0 |
| 2  | sever fatigue                 | ADE        | voltaren    | DRUG    |        0 |
| 3  | cramps                        | ADE        | voltaren    | DRUG    |        1 |

</code></pre></div></div>
<h5 id="new-entity-resolver-model-for-snomed-codes">New Entity Resolver model for SNOMED codes</h5>

<p>We are releasing a new SentenceEntityResolver model for SNOMED codes. This model also includes AUX SNOMED concepts and can find codes for Morph Abnormality, Procedure, Substance, Physical Object, and Body Structure entities. In the metadata, the <code class="language-plaintext highlighter-rouge">all_k_aux_labels</code> can be divided to get further information: <code class="language-plaintext highlighter-rouge">ground truth</code>, <code class="language-plaintext highlighter-rouge">concept</code>, and <code class="language-plaintext highlighter-rouge">aux</code> . In the example shared below the ground truth is <code class="language-plaintext highlighter-rouge">Atherosclerosis</code>, concept is <code class="language-plaintext highlighter-rouge">Observation</code>, and aux is <code class="language-plaintext highlighter-rouge">Morph Abnormality</code>.</p>

<p><em>Example</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">snomed_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_snomed_findings_aux_concepts"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">snomed_pipelineModel</span> <span class="o">=</span> <span class="n">PipelineModel</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sbert_embedder</span><span class="p">,</span>
        <span class="n">snomed_resolver</span><span class="p">])</span>

<span class="n">snomed_lp</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">snomed_pipelineModel</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">snomed_lp</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">(</span><span class="s">"atherosclerosis"</span><span class="p">)</span>

</code></pre></div></div>

<p><em>Results</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunks          | code     | resolutions                                                                                                                                                                                                                                                                                                                                                                                                                    | all_codes                                                                                                                                                                                          | all_k_aux_labels                                      | all_distances                                                                                                                                   |
|---:|:----------------|:---------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------|
|  0 | atherosclerosis | 38716007 | <span class="o">[</span>atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis, atherosclerosis artery, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, coronary atherosclerosis, arteriosclerosis, carotid atherosclerosis, cardiovascular arteriosclerosis, aortic atherosclerosis, aortic atherosclerosis, atherosclerotic ischemic disease] | <span class="o">[</span>38716007, 155382007, 155414001, 195251000, 266318005, 194848007, 441574008, 443502000, 41702007, 266231003, 155316000, 194841001, 28960008, 300920004, 39468009, 155415000, 195252007, 129573006] | <span class="s1">'Atherosclerosis'</span>, <span class="s1">'Observation'</span>, <span class="s1">'Morph Abnormality'</span> | <span class="o">[</span>0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0280, 0.0451, 0.0451, 0.0451, 0.0451, 0.0451, 0.0462, 0.0477, 0.0466, 0.0490, 0.0490, 0.0485 |
</code></pre></div></div>

<h5 id="chunkconverter-annotator">ChunkConverter Annotator</h5>

<p>Allows to use RegexMather chunks as NER chunks and feed the output to the downstream annotators like RE or Deidentification.</p>

<pre><code class="language-Python">        document_assembler = DocumentAssembler().setInputCol('text').setOutputCol('document')

        sentence_detector = SentenceDetector().setInputCols(["document"]).setOutputCol("sentence")

        regex_matcher = RegexMatcher()\
            .setInputCols("sentence")\
            .setOutputCol("regex")\
            .setExternalRules(path="../src/test/resources/regex-matcher/rules.txt",delimiter=",")

        chunkConverter = ChunkConverter().setInputCols("regex").setOutputCol("chunk")


</code></pre>

<h2 id="312">3.1.2</h2>
<p>We are glad to announce that Spark NLP for Healthcare 3.1.2 has been released!.
This release comes with new features, new models, bug fixes, and examples.</p>

<h4 id="highlights-15">Highlights</h4>
<ul>
  <li>Support for Fine-tuning of Ner models.</li>
  <li>More builtin(pre-defined) graphs for MedicalNerApproach.</li>
  <li>Date Normalizer.</li>
  <li>New Relation Extraction Models for ADE.</li>
  <li>Bug Fixes.</li>
  <li>Support for user-defined Custom Transformer.</li>
  <li>Java Workshop Examples.</li>
  <li>Deprecated Compatibility class in Python.</li>
</ul>

<h5 id="support-for-fine-tuning-of-ner-models">Support for Fine Tuning of Ner models</h5>

<p>Users can now resume training/fine-tune existing(already trained) Spark NLP MedicalNer models on new data. Users can simply provide the path to any existing MedicalNer model and train it further on the new dataset:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_tagger = MedicalNerApproach().setPretrainedModelPath("/path/to/trained/medicalnermodel")
</code></pre></div></div>

<p>If the new dataset contains new tags/labels/entities, users can choose to override existing tags with the new ones. The default behaviour is to reset the list of existing tags and generate a new list from the new dataset. It is also possible to preserve the existing tags by setting the ‘overrideExistingTags’ parameter:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_tagger = MedicalNerApproach()\
  .setPretrainedModelPath("/path/to/trained/medicalnermodel")\
  .setOverrideExistingTags(False)
</code></pre></div></div>

<p>Setting overrideExistingTags to false is intended to be used when resuming trainig on the same, or very similar dataset (i.e. with the same tags or with just a few different ones).</p>

<p>If tags overriding is disabled, and new tags are found in the training set, then the approach will try to allocate them to unused output nodes, if any. It is also possible to override specific tags of the old model by mapping them to new tags:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_tagger <span class="o">=</span> MedicalNerApproach<span class="o">()</span><span class="se">\</span>
  .setPretrainedModelPath<span class="o">(</span><span class="s2">"/path/to/trained/medicalnermodel"</span><span class="o">)</span><span class="se">\</span>
  .setOverrideExistingTags<span class="o">(</span>False<span class="o">)</span><span class="se">\</span>
  .setTagsMapping<span class="o">(</span><span class="s2">"B-PER,B-VIP"</span>, <span class="s2">"I-PER,I-VIP"</span><span class="o">)</span>
</code></pre></div></div>

<p>In this case, the new tags <code class="language-plaintext highlighter-rouge">B-VIP</code> and <code class="language-plaintext highlighter-rouge">I-VIP</code> will replace the already trained tags ‘B-PER’ and ‘I-PER’. Unmapped old tags will remain in use and unmapped new tags will be allocated to new outpout nodes, if any.</p>

<p>Jupyter Notebook: [Finetuning Medical NER Model Notebook] (https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.5.Resume_MedicalNer_Model_Training.ipynb)</p>

<h5 id="more-builtin-graphs-for-medicalnerapproach">More builtin graphs for MedicalNerApproach</h5>

<p>Seventy new TensorFlow graphs have been added to the library of available graphs which are used to train MedicalNer models. The graph with the optimal set of parameters is automatically chosen by MedicalNerApproach.</p>

<h5 id="datenormalizer">DateNormalizer</h5>

<p>New annotator that normalize dates to the format YYYY/MM/DD.
This annotator identifies dates in chunk annotations, and transform these dates to the format YYYY/MM/DD.
Both the input and output formats for the annotator are <code class="language-plaintext highlighter-rouge">chunk</code>.</p>

<p>Example:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	sentences <span class="o">=</span> <span class="o">[</span>
		    <span class="o">[</span><span class="s1">'08/02/2018'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'11/2018'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'11/01/2018'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'12Mar2021'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'Jan 30, 2018'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'13.04.1999'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'3April 2020'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'next monday'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'today'</span><span class="o">]</span>,
		    <span class="o">[</span><span class="s1">'next week'</span><span class="o">]</span>,
	<span class="o">]</span>
	<span class="nb">df</span> <span class="o">=</span> spark.createDataFrame<span class="o">(</span>sentences<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">)</span>
	document_assembler <span class="o">=</span> DocumentAssembler<span class="o">()</span>.setInputCol<span class="o">(</span><span class="s1">'text'</span><span class="o">)</span>.setOutputCol<span class="o">(</span><span class="s1">'document'</span><span class="o">)</span>
	chunksDF <span class="o">=</span> document_assembler.transform<span class="o">(</span><span class="nb">df</span><span class="o">)</span>
	aa <span class="o">=</span> map_annotations_col<span class="o">(</span>chunksDF.select<span class="o">(</span><span class="s2">"document"</span><span class="o">)</span>,
				    lambda x: <span class="o">[</span>Annotation<span class="o">(</span><span class="s1">'chunk'</span>, a.begin, a.end, a.result, a.metadata, a.embeddings<span class="o">)</span> <span class="k">for </span>a <span class="k">in </span>x], <span class="s2">"document"</span>,
				    <span class="s2">"chunk_date"</span>, <span class="s2">"chunk"</span><span class="o">)</span>
	dateNormalizer <span class="o">=</span> DateNormalizer<span class="o">()</span>.setInputCols<span class="o">(</span><span class="s1">'chunk_date'</span><span class="o">)</span>.setOutputCol<span class="o">(</span><span class="s1">'date'</span><span class="o">)</span>.setAnchorDateYear<span class="o">(</span>2021<span class="o">)</span>.setAnchorDateMonth<span class="o">(</span>2<span class="o">)</span>.setAnchorDateDay<span class="o">(</span>27<span class="o">)</span>
	dateDf <span class="o">=</span> dateNormalizer.transform<span class="o">(</span>aa<span class="o">)</span>
	dateDf.select<span class="o">(</span><span class="s2">"date.result"</span>,<span class="s2">"text"</span><span class="o">)</span>.show<span class="o">()</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
+-----------+----------+
|text        |  <span class="nb">date</span>    |
+-----------+----------+
|08/02/2018  |2018/08/02|
|11/2018     |2018/11/DD|
|11/01/2018  |2018/11/01|
|12Mar2021   |2021/03/12|
|Jan 30, 2018|2018/01/30|
|13.04.1999  |1999/04/13|
|3April 2020 |2020/04/03|
|next Monday |2021/06/19|
|today       |2021/06/12|
|next week   |2021/06/19|
+-----------+----------+
</code></pre></div></div>

<h5 id="new-relation-extraction-models-for-ade">New Relation Extraction Models for ADE</h5>

<p>We are releasing new Relation Extraction models for ADE (Adverse Drug Event). This model is available in both <code class="language-plaintext highlighter-rouge">RelationExtraction</code> and Bert based <code class="language-plaintext highlighter-rouge">RelationExtractionDL</code> versions, and is capabale of linking drugs with ADE mentions.</p>

<p>Example</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ade_re_model <span class="o">=</span> new RelationExtractionModel<span class="o">()</span>.pretrained<span class="o">(</span><span class="s1">'ner_ade_clinical'</span>, <span class="s1">'en'</span>, <span class="s1">'clinical/models'</span><span class="o">)</span><span class="se">\</span>
                                     .setInputCols<span class="o">([</span><span class="s2">"embeddings"</span>, <span class="s2">"pos_tags"</span>, <span class="s2">"ner_chunk"</span>, <span class="s2">"dependencies"</span><span class="o">])</span><span class="se">\</span>
                                     .setOutputCol<span class="o">(</span><span class="s2">"relations"</span><span class="o">)</span><span class="se">\</span>
                                     .setPredictionThreshold<span class="o">(</span>0.5<span class="o">)</span><span class="se">\</span>
                                     .setRelationPairs<span class="o">([</span><span class="s1">'ade-drug'</span>, <span class="s1">'drug-ade'</span><span class="o">])</span>
    pipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>documenter, sentencer, tokenizer, pos_tagger, words_embedder, ner_tagger, ner_converter,
                                                   dependency_parser, re_ner_chunk_filter, re_model]<span class="o">)</span>
    text <span class="o">=</span><span class="s2">"""A 30 year old female presented with tense bullae due to excessive use of naproxin, and leg cramps relating to oxaprozin."""</span>

    p_model <span class="o">=</span> pipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span>text]]<span class="o">)</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>

    result <span class="o">=</span> p_model.transform<span class="o">(</span>data<span class="o">)</span>

</code></pre></div></div>

<p>Results</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunk1        | entity1    |  chunk2       | entity2   |    result  |
|---:|:--------------|:-----------|:--------------|:----------|-----------:|
|  0 | tense bullae  | ADE        | naproxin      | DRUG      |          1 |
|  1 | tense bullae  | ADE        | oxaprozin     | DRUG      |          0 |
|  2 | naproxin      | DRUG       | leg cramps    | ADE       |          0 |
|  3 | leg cramps    | ADE        | oxaprozin     | DRUG      |          1 |

</code></pre></div></div>

<p>Benchmarking
Model: <code class="language-plaintext highlighter-rouge">re_ade_clinical</code></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
              precision    recall  f1-score   support
           0       0.85      0.89      0.87      1670
           1       0.88      0.84      0.86      1673
   micro avg       0.87      0.87      0.87      3343
   macro avg       0.87      0.87      0.87      3343
weighted avg       0.87      0.87      0.87      3343
</code></pre></div></div>

<p>Model: <code class="language-plaintext highlighter-rouge">redl_ade_biobert</code></p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Relation           Recall Precision        F1   Support
0                   0.894     0.946     0.919      1011
1                   0.963     0.926     0.944      1389
Avg.                0.928     0.936     0.932
Weighted Avg.       0.934     0.934     0.933
</code></pre></div></div>

<h5 id="bug-fixes-1">Bug Fixes</h5>
<ul>
  <li>RelationExtractionDLModel had an issue(BufferOverflowException) on versions 3.1.0 and 3.1.1, which is fixed with this release.</li>
  <li>Some pretrained RelationExtractionDLModels got outdated after release 3.0.3, new updated models were created, tested and made available to be used with versions 3.0.3, and later.</li>
  <li>Some SentenceEntityResolverModels which did not work with Spark 2.4/2.3 were fixed.</li>
</ul>

<h5 id="support-for-user-defined-custom-transformer">Support for user-defined Custom Transformer.</h5>
<p>Utility classes to define custom transformers in python are included in this release. This allows users to define functions in Python to manipulate Spark-NLP annotations. This new Transformers can be added to pipelines like any of the other models you’re already familiar with.
Example how to use the custom transformer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="k">def</span> <span class="nf">myFunction</span><span class="p">(</span><span class="n">annotations</span><span class="p">):</span>
            <span class="c1"># lower case the content of the annotations
</span>            <span class="k">return</span> <span class="p">[</span><span class="n">a</span><span class="p">.</span><span class="n">copy</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">result</span><span class="p">.</span><span class="n">lower</span><span class="p">())</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">annotations</span><span class="p">]</span>

        <span class="n">custom_transformer</span> <span class="o">=</span> <span class="n">CustomTransformer</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="n">myFunction</span><span class="p">).</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"custom"</span><span class="p">)</span>
        <span class="n">outputDf</span> <span class="o">=</span> <span class="n">custom_transformer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">outdf</span><span class="p">).</span><span class="n">select</span><span class="p">(</span><span class="s">"custom"</span><span class="p">).</span><span class="n">toPandas</span><span class="p">()</span>
</code></pre></div></div>

<h5 id="java-workshop-examples">Java Workshop Examples</h5>

<p>Add Java examples in the workshop repository.
https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/java/healthcare</p>

<h5 id="deprecated-compatibility-class-in-python">Deprecated Compatibility class in Python</h5>

<p>Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models and versions, especially for the users using our models locally in air-gapped networks.</p>

<p>We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This new class is now replacing the previous Compatibility class written in Python and CompatibilityBeta class written in Scala.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.compatibility import Compatibility

compatibility = Compatibility(spark)

print(compatibility.findVersion('sentence_detector_dl_healthcare'))
</code></pre></div></div>

<p>Output</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'name': 'sentence_detector_dl_healthcare', 'sparkVersion': '2.4', 'version': '2.6.0', 'language': 'en', 'date': '2020-09-13T14:44:42.565', 'readyToUse': 'true'}, {'name': 'sentence_detector_dl_healthcare', 'sparkVersion': '2.4', 'version': '2.7.0', 'language': 'en', 'date': '2021-03-16T08:42:34.391', 'readyToUse': 'true'}]
</code></pre></div></div>

<h2 id="311">3.1.1</h2>
<p>We are glad to announce that Spark NLP for Healthcare 3.1.1 has been released!</p>

<h4 id="highlights-16">Highlights</h4>
<ul>
  <li>MedicalNerModel new parameter <code class="language-plaintext highlighter-rouge">includeAllConfidenceScores</code>.</li>
  <li>MedicalNerModel new parameter <code class="language-plaintext highlighter-rouge">inferenceBatchSize</code>.</li>
  <li>New Resolver Models</li>
  <li>Updated Resolver Models</li>
  <li>Getting Started with Spark NLP for Healthcare Notebook in Databricks</li>
</ul>

<h4 id="medicalner-new-parameter-includeallconfidencescores">MedicalNer new parameter <code class="language-plaintext highlighter-rouge">includeAllConfidenceScores</code></h4>
<p>You can now customize whether you will require confidence score for every token(both entities and non-entities) at the output of the MedicalNerModel, or just for the tokens recognized as entities.</p>

<h4 id="medicalnermodel-new-parameter-inferencebatchsize">MedicalNerModel new parameter <code class="language-plaintext highlighter-rouge">inferenceBatchSize</code></h4>
<p>You can now control the batch size used during inference as a separate parameter from the one you used during training of the model. This can be useful in the situation in which the hardware on which you run inference has different capacity. For example, when you have lower available memory during inference, you can reduce the batch size.</p>

<h4 id="new-resolver-models">New Resolver Models</h4>
<p>We trained three new sentence entity resolver models.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbertresolve_snomed_bodyStructure_med</code> and <code class="language-plaintext highlighter-rouge">sbiobertresolve_snomed_bodyStructure</code> models map extracted medical (anatomical structures) entities to Snomed codes (body structure version).</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">sbertresolve_snomed_bodyStructure_med</code> : Trained  with using <code class="language-plaintext highlighter-rouge">sbert_jsl_medium_uncased</code> embeddings.</li>
      <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_snomed_bodyStructure</code>  : Trained with using <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code> embeddings.</li>
    </ul>
  </li>
</ul>

<p><em>Example</em> :</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>documentAssembler = DocumentAssembler()\
      .setInputCol("text")\
      .setOutputCol("ner_chunk")
jsl_sbert_embedder = BertSentenceEmbeddings.pretrained('sbert_jsl_medium_uncased','en','clinical/models')\
      .setInputCols(["ner_chunk"])\
      .setOutputCol("sbert_embeddings")
snomed_resolver = SentenceEntityResolverModel.pretrained("sbertresolve_snomed_bodyStructure_med, "en", "clinical/models) \
      .setInputCols(["ner_chunk", "sbert_embeddings"]) \
      .setOutputCol("snomed_code")
snomed_pipelineModel = PipelineModel(
    stages = [
        documentAssembler,
        jsl_sbert_embedder,
        snomed_resolver])
snomed_lp = LightPipeline(snomed_pipelineModel)
result = snomed_lp.fullAnnotate("Amputation stump")
</code></pre></div></div>

<p><em>Result</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|    | chunks           | code     | resolutions                                                                                                                                                                                                                                  | all_codes                                                                                       | all_distances                                                               |
|---:|:-----------------|:---------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------|
|  0 | amputation stump | 38033009 | <span class="o">[</span>Amputation stump, Amputation stump of upper limb, Amputation stump of left upper limb, Amputation stump of lower limb, Amputation stump of left lower limb, Amputation stump of right upper limb, Amputation stump of right lower limb, ...]| <span class="o">[</span><span class="s1">'38033009'</span>, <span class="s1">'771359009'</span>, <span class="s1">'771364008'</span>, <span class="s1">'771358001'</span>, <span class="s1">'771367001'</span>, <span class="s1">'771365009'</span>, <span class="s1">'771368006'</span>, ...] | <span class="o">[</span><span class="s1">'0.0000'</span>, <span class="s1">'0.0773'</span>, <span class="s1">'0.0858'</span>, <span class="s1">'0.0863'</span>, <span class="s1">'0.0905'</span>, <span class="s1">'0.0911'</span>, <span class="s1">'0.0972'</span>, ...] |
</code></pre></div></div>
<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_icdo_augmented</code> : This model maps extracted medical entities to ICD-O codes using sBioBert sentence embeddings. This model is augmented using the site information coming from ICD10 and synonyms coming from SNOMED vocabularies. It is trained with a dataset that is 20x larger than the previous version of ICDO resolver. Given the oncological entity found in the text (via NER models like ner_jsl), it returns top terms and resolutions along with the corresponding ICD-10 codes to present more granularity with respect to body parts mentioned. It also returns the original histological behavioral codes and descriptions in the aux metadata.</li>
</ul>

<p><em>Example</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
chunk2doc = Chunk2Doc().setInputCols("ner_chunk").setOutputCol("ner_chunk_doc")

sbert_embedder = BertSentenceEmbeddings\
     .pretrained("sbiobert_base_cased_mli","en","clinical/models")\
     .setInputCols(["ner_chunk_doc"])\
     .setOutputCol("sbert_embeddings")

icdo_resolver = SentenceEntityResolverModel.pretrained("sbiobertresolve_icdo_augmented","en", "clinical/models") \
     .setInputCols(["ner_chunk", "sbert_embeddings"]) \
     .setOutputCol("resolution")\
     .setDistanceFunction("EUCLIDEAN")
nlpPipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, word_embeddings, clinical_ner, ner_converter, chunk2doc, sbert_embedder, icdo_resolver])
empty_data = spark.createDataFrame([[""]]).toDF("text")
model = nlpPipeline.fit(empty_data)
results = model.transform(spark.createDataFrame([["The patient is a very pleasant 61-year-old female with a strong family history of colon polyps. The patient reports her first polyps noted at the age of 50. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. She also has history of several malignancies in the family. Her father died of a brain tumor at the age of 81. Her sister died at the age of 65 breast cancer. She has two maternal aunts with history of lung cancer both of whom were smoker. Also a paternal grandmother who was diagnosed with leukemia at 86 and a paternal grandfather who had B-cell lymphoma."]]).toDF("text"))
</code></pre></div></div>

<p><em>Result</em>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+--------------------+-----+---+-----------+-------------+-------------------------+-------------------------+
|               chunk|begin|end|     entity|         code|        all_k_resolutions|              all_k_codes|
+--------------------+-----+---+-----------+-------------+-------------------------+-------------------------+
|        mesothelioma|  255|266|Oncological|9971/3||C38.3|malignant mediastinal ...|9971/3||C38.3:::8854/3...|
|several malignancies|  293|312|Oncological|8894/3||C39.8|overlapping malignant ...|8894/3||C39.8:::8070/2...|
|         brain tumor|  350|360|Oncological|9562/0||C71.9|cancer of the brain:::...|9562/0||C71.9:::9070/3...|
|       breast cancer|  413|425|Oncological|9691/3||C50.9|carcinoma of breast:::...|9691/3||C50.9:::8070/2...|
|         lung cancer|  471|481|Oncological|8814/3||C34.9|malignant tumour of lu...|8814/3||C34.9:::8550/3...|
|            leukemia|  560|567|Oncological|9670/3||C80.9|anemia in neoplastic d...|9670/3||C80.9:::9714/3...|
|     B-cell lymphoma|  610|624|Oncological|9818/3||C77.9|secondary malignant ne...|9818/3||C77.9:::9655/3...|
+--------------------+-----+---+-----------+-------------+-------------------------+-------------------------+
</code></pre></div></div>

<h4 id="updated-resolver-models">Updated Resolver Models</h4>
<p>We updated <code class="language-plaintext highlighter-rouge">sbiobertresolve_snomed_findings</code> and <code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_procedures_augmented</code> resolver models to reflect the latest changes in the official terminologies.</p>

<h4 id="getting-started-with-spark-nlp-for-healthcare-notebook-in-databricks">Getting Started with Spark NLP for Healthcare Notebook in Databricks</h4>
<p>We prepared a new notebook for those who want to get started with Spark NLP for Healthcare in Databricks : <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/databricks/python/healthcare_case_studies/Get_Started_Spark_NLP_for_Healthcare.ipynb">Getting Started with Spark NLP for Healthcare Notebook</a></p>

<h2 id="310">3.1.0</h2>
<p>We are glad to announce that Spark NLP for Healthcare 3.1.0 has been released!</p>
<h4 id="highlights-17">Highlights</h4>
<ul>
  <li>Improved load time &amp; memory consumption for SentenceResolver models.</li>
  <li>New JSL Bert Models.</li>
  <li>JSL SBert Model Speed Benchmark.</li>
  <li>New ICD10CM resolver models.</li>
  <li>New Deidentification NER models.</li>
  <li>New column returned in DeidentificationModel</li>
  <li>New Reidentification feature</li>
  <li>New Deidentification Pretrained Pipelines</li>
  <li>Chunk filtering based on confidence</li>
  <li>Extended regex dictionary fuctionallity in Deidentification</li>
  <li>Enhanced RelationExtractionDL Model to create and identify relations between entities across the entire document</li>
  <li>MedicalNerApproach can now accept a graph file directly.</li>
  <li>MedicalNerApproach can now accept a user-defined name for log file.</li>
  <li>More improvements in Scaladocs.</li>
  <li>Bug fixes in Deidentification module.</li>
  <li>New notebooks.</li>
</ul>

<h4 id="sentence-resolver-models-load-time-improvement">Sentence Resolver Models load time improvement</h4>
<p>Sentence resolver models now have faster load times, with a speedup of about 6X when compared to previous versions.
Also, the load process now is more  memory friendly meaning that the maximum memory required during load time is smaller, reducing the chances of OOM exceptions, and thus relaxing hardware requirements.</p>

<h4 id="new-jsl-sbert-models">New JSL SBert Models</h4>
<p>We trained new sBert models in TF2 and fined tuned on MedNLI, NLI and UMLS datasets with various parameters to cover common NLP tasks in medical domain. You can find the details in the following table.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobert_jsl_cased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbiobert_jsl_umls_cased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_medium_uncased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_medium_umls_uncased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_mini_uncased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_mini_umls_uncased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_tiny_uncased</code></li>
  <li><code class="language-plaintext highlighter-rouge">sbert_jsl_tiny_umls_uncased</code></li>
</ul>

<h4 id="jsl-sbert-model-speed-benchmark">JSL SBert Model Speed Benchmark</h4>

<table>
  <thead>
    <tr>
      <th>JSL SBert Model</th>
      <th>Base Model</th>
      <th>Is Cased</th>
      <th>Train Datasets</th>
      <th>Inference speed (100 rows)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>sbiobert_jsl_cased</td>
      <td>biobert_v1.1_pubmed</td>
      <td>Cased</td>
      <td>medNLI, allNLI</td>
      <td>274,53</td>
    </tr>
    <tr>
      <td>sbiobert_jsl_umls_cased</td>
      <td>biobert_v1.1_pubmed</td>
      <td>Cased</td>
      <td>medNLI, allNLI, umls</td>
      <td>274,52</td>
    </tr>
    <tr>
      <td>sbert_jsl_medium_uncased</td>
      <td>uncased_L-8_H-512_A-8</td>
      <td>Uncased</td>
      <td>medNLI, allNLI</td>
      <td>80,40</td>
    </tr>
    <tr>
      <td>sbert_jsl_medium_umls_uncased</td>
      <td>uncased_L-8_H-512_A-8</td>
      <td>Uncased</td>
      <td>medNLI, allNLI, umls</td>
      <td>78,35</td>
    </tr>
    <tr>
      <td>sbert_jsl_mini_uncased</td>
      <td>uncased_L-4_H-256_A-4</td>
      <td>Uncased</td>
      <td>medNLI, allNLI</td>
      <td>10,68</td>
    </tr>
    <tr>
      <td>sbert_jsl_mini_umls_uncased</td>
      <td>uncased_L-4_H-256_A-4</td>
      <td>Uncased</td>
      <td>medNLI, allNLI, umls</td>
      <td>10,29</td>
    </tr>
    <tr>
      <td>sbert_jsl_tiny_uncased</td>
      <td>uncased_L-2_H-128_A-2</td>
      <td>Uncased</td>
      <td>medNLI, allNLI</td>
      <td>4,54</td>
    </tr>
    <tr>
      <td>sbert_jsl_tiny_umls_uncased</td>
      <td>uncased_L-2_H-128_A-2</td>
      <td>Uncased</td>
      <td>medNLI, allNL, umls</td>
      <td>4,54</td>
    </tr>
  </tbody>
</table>

<h4 id="new-icd10cm-resolver-models">New ICD10CM resolver models:</h4>
<p>These models map clinical entities and concepts to ICD10 CM codes using sentence bert embeddings. They also return the official resolution text within the brackets inside the metadata. Both models are augmented with synonyms, and previous augmentations are flexed according to cosine distances to unnormalized terms (ground truths).</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_slim_billable_hcc</code>: Trained with classic sbiobert mli. (<code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code>)</li>
</ul>

<p>Models Hub Page : https://nlp.johnsnowlabs.com/2021/05/25/sbiobertresolve_icd10cm_slim_billable_hcc_en.html</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbertresolve_icd10cm_slim_billable_hcc_med</code>: Trained with new jsl sbert(<code class="language-plaintext highlighter-rouge">sbert_jsl_medium_uncased</code>)</li>
</ul>

<p>Models Hub Page : https://nlp.johnsnowlabs.com/2021/05/25/sbertresolve_icd10cm_slim_billable_hcc_med_en.html</p>

<p><em>Example</em>: ‘bladder cancer’</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented_billable_hcc</code></li>
</ul>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>all_distances</th>
      <th>100x Loop(sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bladder cancer</td>
      <td>C679</td>
      <td>[C679, Z126, D090, D494, C7911]</td>
      <td>[bladder cancer, suspected bladder cancer, cancer in situ of urinary bladder, tumor of bladder neck, malignant tumour of bladder neck]</td>
      <td>[0.0000, 0.0904, 0.0978, 0.1080, 0.1281]</td>
      <td>26,9</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>` sbiobertresolve_icd10cm_slim_billable_hcc`</li>
</ul>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>all_distances</th>
      <th>100x Loop(sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bladder cancer</td>
      <td>D090</td>
      <td>[D090, D494, C7911, C680, C679]</td>
      <td>[cancer in situ of urinary bladder [Carcinoma in situ of bladder], tumor of bladder neck [Neoplasm of unspecified behavior of bladder], malignant tumour of bladder neck [Secondary malignant neoplasm of bladder], carcinoma of urethra [Malignant neoplasm of urethra], malignant tumor of urinary bladder [Malignant neoplasm of bladder, unspecified]]</td>
      <td>[0.0978, 0.1080, 0.1281, 0.1314, 0.1284]</td>
      <td>20,9</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbertresolve_icd10cm_slim_billable_hcc_med</code></li>
</ul>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>code</th>
      <th>all_codes</th>
      <th>resolutions</th>
      <th>all_distances</th>
      <th>100x Loop(sec)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bladder cancer</td>
      <td>C671</td>
      <td>[C671, C679, C61, C672, C673]</td>
      <td>[bladder cancer, dome [Malignant neoplasm of dome of bladder], cancer of the urinary bladder [Malignant neoplasm of bladder, unspecified], prostate cancer [Malignant neoplasm of prostate], cancer of the urinary bladder]</td>
      <td>[0.0894, 0.1051, 0.1184, 0.1180, 0.1200]</td>
      <td>12,8</td>
    </tr>
  </tbody>
</table>

<h4 id="new-deidentification-ner-models">New Deidentification NER Models</h4>

<p>We trained four new NER models to find PHI data (protected health information) that may need to be deidentified. <code class="language-plaintext highlighter-rouge">ner_deid_generic_augmented</code> and <code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code> models are trained with a combination of 2014 i2b2 Deid dataset and in-house annotations as well as some augmented version of them. Compared to the same test set coming from 2014 i2b2 Deid dataset, we achieved a better accuracy and generalisation on some entity labels as summarised in the following tables. We also trained the same models with <code class="language-plaintext highlighter-rouge">glove_100d</code> embeddings to get more memory friendly versions.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_augmented</code>  : Detects PHI 7 entities (<code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">NAME</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">ID</code>).</li>
</ul>

<p>Models Hub Page : https://nlp.johnsnowlabs.com/2021/06/01/ner_deid_generic_augmented_en.html</p>

<table>
  <thead>
    <tr>
      <th>entity</th>
      <th style="text-align: center">ner_deid_large (v3.0.3 and before)</th>
      <th style="text-align: center">ner_deid_generic_augmented (v3.1.0)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CONTACT</td>
      <td style="text-align: center">0.8695</td>
      <td style="text-align: center">0.9592</td>
    </tr>
    <tr>
      <td>NAME</td>
      <td style="text-align: center">0.9452</td>
      <td style="text-align: center">0.9648</td>
    </tr>
    <tr>
      <td>DATE</td>
      <td style="text-align: center">0.9778</td>
      <td style="text-align: center">0.9855</td>
    </tr>
    <tr>
      <td>LOCATION</td>
      <td style="text-align: center">0.8755</td>
      <td style="text-align: center">0.923</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code>: Detects PHI 23 entities (<code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">HEALTHPLAN</code>, <code class="language-plaintext highlighter-rouge">URL</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">LOCATION-OTHER</code>, <code class="language-plaintext highlighter-rouge">STATE</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">DEVICE</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">EMAIL</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">SREET</code>, <code class="language-plaintext highlighter-rouge">BIOID</code>, <code class="language-plaintext highlighter-rouge">FAX</code>, <code class="language-plaintext highlighter-rouge">AGE</code>)</li>
</ul>

<p>Models Hub Page : https://nlp.johnsnowlabs.com/2021/06/01/ner_deid_subentity_augmented_en.html</p>

<table>
  <thead>
    <tr>
      <th>entity</th>
      <th style="text-align: center">ner_deid_enriched (v3.0.3 and before)</th>
      <th style="text-align: center">ner_deid_subentity_augmented (v3.1.0)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>HOSPITAL</td>
      <td style="text-align: center">0.8519</td>
      <td style="text-align: center">0.8983</td>
    </tr>
    <tr>
      <td>DATE</td>
      <td style="text-align: center">0.9766</td>
      <td style="text-align: center">0.9854</td>
    </tr>
    <tr>
      <td>CITY</td>
      <td style="text-align: center">0.7493</td>
      <td style="text-align: center">0.8075</td>
    </tr>
    <tr>
      <td>STREET</td>
      <td style="text-align: center">0.8902</td>
      <td style="text-align: center">0.9772</td>
    </tr>
    <tr>
      <td>ZIP</td>
      <td style="text-align: center">0.8</td>
      <td style="text-align: center">0.9504</td>
    </tr>
    <tr>
      <td>PHONE</td>
      <td style="text-align: center">0.8615</td>
      <td style="text-align: center">0.9502</td>
    </tr>
    <tr>
      <td>DOCTOR</td>
      <td style="text-align: center">0.9191</td>
      <td style="text-align: center">0.9347</td>
    </tr>
    <tr>
      <td>AGE</td>
      <td style="text-align: center">0.9416</td>
      <td style="text-align: center">0.9469</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_generic_glove</code>: Small version of <code class="language-plaintext highlighter-rouge">ner_deid_generic_augmented</code> and detects 7 entities.</li>
  <li><code class="language-plaintext highlighter-rouge">ner_deid_subentity_glove</code>: Small version of <code class="language-plaintext highlighter-rouge">ner_deid_subentity_augmented</code> and detects 23 entities.</li>
</ul>

<p><em>Example</em>:</p>

<p>Scala</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">...</span>
<span class="k">val</span> <span class="nv">deid_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span> <span class="o">\</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> <span class="o">\</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">...</span>
<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document_assembler</span><span class="o">,</span> <span class="n">sentence_detector</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">word_embeddings</span><span class="o">,</span> <span class="n">deid_ner</span><span class="o">,</span> <span class="n">ner_converter</span><span class="o">))</span>
<span class="n">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">([[</span><span class="err">""</span><span class="o">]]).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="nv">Seq</span><span class="o">.</span><span class="py">empty</span><span class="o">[</span><span class="err">"</span><span class="kt">A.</span> <span class="kt">Record</span> <span class="kt">date</span> <span class="kt">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span>, <span class="kt">David</span> <span class="kt">Hale</span>, <span class="kt">M.D.</span>, <span class="kt">Name</span> <span class="kt">:</span> <span class="kt">Hendrickson</span>, <span class="kt">Ora</span> <span class="kt">MR.</span> <span class="k">#</span> <span class="err">7194334</span> <span class="kt">Date</span> <span class="kt">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span>, <span class="err">25</span> <span class="kt">-year-old</span>, <span class="kt">Record</span> <span class="kt">date</span> <span class="kt">:</span> <span class="err">1</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">2000</span><span class="kt">.</span> <span class="kt">Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital.</span> <span class="err">0295</span> <span class="kt">Keats</span> <span class="kt">Street.</span> <span class="kt">Phone</span> <span class="kt">+</span><span class="err">1</span> <span class="o">(</span><span class="err">302</span><span class="o">)</span> <span class="err">786</span><span class="kt">-</span><span class="err">5227</span><span class="kt">.</span><span class="err">"</span><span class="o">].</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div></div>

<p>Python</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
deid_ner <span class="o">=</span> MedicalNerModel.pretrained<span class="o">(</span><span class="s2">"ner_deid_subentity_augmented"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span> <span class="se">\</span>
      .setInputCols<span class="o">([</span><span class="s2">"sentence"</span>, <span class="s2">"token"</span>, <span class="s2">"embeddings"</span><span class="o">])</span> <span class="se">\</span>
      .setOutputCol<span class="o">(</span><span class="s2">"ner"</span><span class="o">)</span>
...
nlpPipeline <span class="o">=</span> Pipeline<span class="o">(</span><span class="nv">stages</span><span class="o">=[</span>document_assembler, sentence_detector, tokenizer, word_embeddings, deid_ner, ner_converter]<span class="o">)</span>
model <span class="o">=</span> nlpPipeline.fit<span class="o">(</span>spark.createDataFrame<span class="o">([[</span><span class="s2">""</span><span class="o">]])</span>.toDF<span class="o">(</span><span class="s2">"text"</span><span class="o">))</span>

results <span class="o">=</span> model.transform<span class="o">(</span>spark.createDataFrame<span class="o">(</span>pd.DataFrame<span class="o">({</span><span class="s2">"text"</span>: <span class="o">[</span><span class="s2">"""A. Record date : 2093-01-13, David Hale, M.D., Name : Hendrickson, Ora MR. # 7194334 Date : 01/13/93 PCP : Oliveira, 25 -year-old, Record date : 1-11-2000. Cocke County Baptist Hospital. 0295 Keats Street. Phone +1 (302) 786-5227."""</span><span class="o">]})))</span>
</code></pre></div></div>
<p><em>Results</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-----------------------------+-------------+
|chunk                        |ner_label    |
+-----------------------------+-------------+
|2093-01-13                   |DATE         |
|David Hale                   |DOCTOR       |
|Hendrickson, Ora             |PATIENT      |
|7194334                      |MEDICALRECORD|
|01/13/93                     |DATE         |
|Oliveira                     |DOCTOR       |
|25-year-old                  |AGE          |
|1-11-2000                    |DATE         |
|Cocke County Baptist Hospital|HOSPITAL     |
|0295 Keats Street.           |STREET       |
|<span class="o">(</span>302<span class="o">)</span> 786-5227               |PHONE        |
|Brothers Coal-Mine           |ORGANIZATION |
+-----------------------------+-------------+
</code></pre></div></div>

<h4 id="new-column-returned-in-deidentificationmodel">New column returned in DeidentificationModel</h4>

<p>DeidentificationModel now can return a new column to save the mappings between the mask/obfuscated entities and original entities.
This column is optional and you can set it up with the <code class="language-plaintext highlighter-rouge">.setReturnEntityMappings(True)</code> method. The default value is False.
Also, the name for the column can be changed using the following method; <code class="language-plaintext highlighter-rouge">.setMappingsColumn("newAlternativeName")</code>
The new column will produce annotations with the following structure,</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Annotation(
  type: chunk,
  begin: 17,
  end: 25,
  result: 47,
    metadata:{
        originalChunk -&gt; 01/13/93  //Original text of the chunk
        chunk -&gt; 0  // The number of the chunk in the sentence
        beginOriginalChunk -&gt; 95 // Start index of the original chunk
        endOriginalChunk -&gt; 102  // End index of the original chunk
        entity -&gt; AGE // Entity of the chunk
        sentence -&gt; 2 // Number of the sentence
    }
)
</code></pre></div></div>

<h4 id="new-reidentification-feature">New Reidentification feature</h4>

<p>With the new ReidetificationModel, the user can go back to the original sentences using the mappings columns and the deidentification sentences.</p>

<p><em>Example:</em></p>

<p>Scala</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">redeidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ReIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">,</span> <span class="s">"deid_chunks"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>
</code></pre></div></div>

<p>Python</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reDeidentification</span> <span class="k">=</span> <span class="nc">ReIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">mappings</span><span class="err">"</span>,<span class="err">"</span><span class="kt">deid_chunks</span><span class="err">"</span><span class="o">])</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>
</code></pre></div></div>

<h4 id="new-deidentification-pretrained-pipelines">New Deidentification Pretrained Pipelines</h4>
<p>We developed a <code class="language-plaintext highlighter-rouge">clinical_deidentification</code> pretrained pipeline that can be used to deidentify PHI information from medical texts. The PHI information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate <code class="language-plaintext highlighter-rouge">AGE</code>, <code class="language-plaintext highlighter-rouge">CONTACT</code>, <code class="language-plaintext highlighter-rouge">DATE</code>, <code class="language-plaintext highlighter-rouge">ID</code>, <code class="language-plaintext highlighter-rouge">LOCATION</code>, <code class="language-plaintext highlighter-rouge">NAME</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>, <code class="language-plaintext highlighter-rouge">CITY</code>, <code class="language-plaintext highlighter-rouge">COUNTRY</code>, <code class="language-plaintext highlighter-rouge">DOCTOR</code>, <code class="language-plaintext highlighter-rouge">HOSPITAL</code>, <code class="language-plaintext highlighter-rouge">IDNUM</code>, <code class="language-plaintext highlighter-rouge">MEDICALRECORD</code>, <code class="language-plaintext highlighter-rouge">ORGANIZATION</code>, <code class="language-plaintext highlighter-rouge">PATIENT</code>, <code class="language-plaintext highlighter-rouge">PHONE</code>, <code class="language-plaintext highlighter-rouge">PROFESSION</code>,  <code class="language-plaintext highlighter-rouge">STREET</code>, <code class="language-plaintext highlighter-rouge">USERNAME</code>, <code class="language-plaintext highlighter-rouge">ZIP</code>, <code class="language-plaintext highlighter-rouge">ACCOUNT</code>, <code class="language-plaintext highlighter-rouge">LICENSE</code>, <code class="language-plaintext highlighter-rouge">VIN</code>, <code class="language-plaintext highlighter-rouge">SSN</code>, <code class="language-plaintext highlighter-rouge">DLN</code>, <code class="language-plaintext highlighter-rouge">PLATE</code>, <code class="language-plaintext highlighter-rouge">IPADDR</code> entities.</p>

<p>Models Hub Page : <a href="https://nlp.johnsnowlabs.com/2021/05/27/clinical_deidentification_en.html">clinical_deidentification</a></p>

<p>There is also a lightweight version of the same pipeline trained with memory efficient <code class="language-plaintext highlighter-rouge">glove_100d</code>embeddings.
Here are the model names:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">clinical_deidentification</code></li>
  <li><code class="language-plaintext highlighter-rouge">clinical_deidentification_glove</code></li>
</ul>

<p><em>Example:</em></p>

<p>Python:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp.pretrained import PretrainedPipeline
deid_pipeline <span class="o">=</span> PretrainedPipeline<span class="o">(</span><span class="s2">"clinical_deidentification"</span>, <span class="s2">"en"</span>, <span class="s2">"clinical/models"</span><span class="o">)</span>

deid_pipeline.annotate<span class="o">(</span><span class="s2">"Record date : 2093-01-13, David Hale, M.D. IP: 203.120.223.13. The driver's license no:A334455B. the SSN:324598674 and e-mail: hale@gmail.com. Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93. PCP : Oliveira, 25 years-old. Record date : 2079-11-09, Patient's VIN : 1HGBH41JXMN109286."</span><span class="o">)</span>
</code></pre></div></div>
<p>Scala:</p>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.pretrained.PretrainedPipeline</span>
<span class="k">val</span> <span class="nv">deid_pipeline</span> <span class="k">=</span> <span class="nc">PretrainedPipeline</span><span class="o">(</span><span class="s">"clinical_deidentification"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">deid_pipeline</span><span class="o">.</span><span class="py">annotate</span><span class="o">(</span><span class="s">"Record date : 2093-01-13, David Hale, M.D. IP: 203.120.223.13. The driver's license no:A334455B. the SSN:324598674 and e-mail: hale@gmail.com. Name : Hendrickson, Ora MR. # 719435 Date : 01/13/93. PCP : Oliveira, 25 years-old. Record date : 2079-11-09, Patient's VIN : 1HGBH41JXMN109286."</span><span class="o">)</span>
</code></pre></div></div>
<p><em>Result</em>:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">{</span><span class="s1">'sentence'</span>: <span class="o">[</span><span class="s1">'Record date : 2093-01-13, David Hale, M.D.'</span>,
   <span class="s1">'IP: 203.120.223.13.'</span>,
   <span class="s1">'The driver'</span>s license no:A334455B.<span class="s1">',
   '</span>the SSN:324598674 and e-mail: hale@gmail.com.<span class="s1">',
   '</span>Name : Hendrickson, Ora MR. <span class="c"># 719435 Date : 01/13/93.',</span>
   <span class="s1">'PCP : Oliveira, 25 years-old.'</span>,
   <span class="s1">'Record date : 2079-11-09, Patient'</span>s VIN : 1HGBH41JXMN109286.<span class="s1">'],
'</span>masked<span class="s1">': ['</span>Record <span class="nb">date</span> : &lt;DATE&gt;, &lt;DOCTOR&gt;, M.D.<span class="s1">',
   '</span>IP: &lt;IPADDR&gt;.<span class="s1">',
   '</span>The driver<span class="s1">'s license &lt;DLN&gt;.'</span>,
   <span class="s1">'the &lt;SSN&gt; and e-mail: &lt;EMAIL&gt;.'</span>,
   <span class="s1">'Name : &lt;PATIENT&gt; MR. # &lt;MEDICALRECORD&gt; Date : &lt;DATE&gt;.'</span>,
   <span class="s1">'PCP : &lt;DOCTOR&gt;, &lt;AGE&gt; years-old.'</span>,
   <span class="s1">'Record date : &lt;DATE&gt;, Patient'</span>s VIN : &lt;VIN&gt;.<span class="s1">'],
'</span>obfuscated<span class="s1">': ['</span>Record <span class="nb">date</span> : 2093-01-18, Dr Alveria Eden, M.D.<span class="s1">',
   '</span>IP: 001.001.001.001.<span class="s1">',
   '</span>The driver<span class="s1">'s license K783518004444.'</span>,
   <span class="s1">'the SSN-400-50-8849 and e-mail: Merilynn@hotmail.com.'</span>,
   <span class="s1">'Name : Charls Danger MR. # J3366417 Date : 01-18-1974.'</span>,
   <span class="s1">'PCP : Dr Sina Sewer, 55 years-old.'</span>,
   <span class="s1">'Record date : 2079-11-23, Patient'</span>s VIN : 6ffff55gggg666777.<span class="s1">'],
'</span>ner_chunk<span class="s1">': ['</span>2093-01-13<span class="s1">',
   '</span>David Hale<span class="s1">',
   '</span>no:A334455B<span class="s1">',
   '</span>SSN:324598674<span class="s1">',
   '</span>Hendrickson, Ora<span class="s1">',
   '</span>719435<span class="s1">',
   '</span>01/13/93<span class="s1">',
   '</span>Oliveira<span class="s1">',
   '</span>25<span class="s1">',
   '</span>2079-11-09<span class="s1">',
   '</span>1HGBH41JXMN109286<span class="s1">']}
</span></code></pre></div></div>

<h4 id="chunk-filtering-based-on-confidence">Chunk filtering based on confidence</h4>

<p>We added a new annotator ChunkFiltererApproach that allows to load a csv with both entities and confidence thresholds.
This annotator will produce a ChunkFilterer model.</p>

<p>You can load the dictionary with the following property <code class="language-plaintext highlighter-rouge">setEntitiesConfidenceResource()</code>.</p>

<p>An example dictionary is:</p>

<pre><code class="language-CSV">TREATMENT,0.7
</code></pre>

<p>With that dictionary, the user can filter the chunks corresponding to treatment entities which have confidence lower than 0.7.</p>

<p>Example:</p>

<p>We have a ner_chunk column and sentence column with the following data:</p>

<p>Ner_chunk</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|[{chunk, 141, 163, the genomicorganization, {entity -&gt; TREATMENT, sentence -&gt; 0, chunk -&gt; 0, confidence -&gt; 0.57785}, []}, {chunk, 209, 267, a candidate gene forType II
           diabetes mellitus, {entity -&gt; PROBLEM, sentence -&gt; 0, chunk -&gt; 1, confidence -&gt; 0.6614286}, []}, {chunk, 394, 408, byapproximately, {entity -&gt; TREATMENT, sentence -&gt; 1, chunk -&gt; 2, confidence -&gt; 0.7705}, []}, {chunk, 478, 508, single nucleotide polymorphisms, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 3, confidence -&gt; 0.7204666}, []}, {chunk, 559, 581, aVal366Ala substitution, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 4, confidence -&gt; 0.61505}, []}, {chunk, 588, 601, an 8 base-pair, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 5, confidence -&gt; 0.29226667}, []}, {chunk, 608, 625, insertion/deletion, {entity -&gt; PROBLEM, sentence -&gt; 3, chunk -&gt; 6, confidence -&gt; 0.9841}, []}]|
+-------
</code></pre></div></div>
<p>Sentence</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{document, 0, 298, The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activated inwardly rectifying potassium (GIRK) channel family.Here we describe the genomicorganization of the KCNJ9 locus on chromosome 1q21-23 as a candidate gene forType II
             diabetes mellitus in the Pima Indian population., {sentence -&gt; 0}, []}, {document, 300, 460, The gene spansapproximately 7.6 kb and contains one noncoding and two coding exons ,separated byapproximately 2.2 and approximately 2.6 kb introns, respectively., {sentence -&gt; 1}, []}, {document, 462, 601, We identified14 single nucleotide polymorphisms (SNPs),
             including one that predicts aVal366Ala substitution, and an 8 base-pair, {sentence -&gt; 2}, []}, {document, 603, 626, (bp) insertion/deletion., {sentence -&gt; 3}, []}]
</code></pre></div></div>

<p>We can filter the entities using the following annotator:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">chunker_filter</span> <span class="o">=</span> <span class="n">ChunkFiltererApproach</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"regex"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setRegex</span><span class="p">([</span><span class="s">".*"</span><span class="p">])</span> \         
            <span class="p">.</span><span class="n">setEntitiesConfidenceResource</span><span class="p">(</span><span class="s">"entities_confidence.csv"</span><span class="p">)</span>

</code></pre></div></div>
<p>Where entities-confidence.csv has the following data:</p>

<pre><code class="language-csv">TREATMENT,0.7
PROBLEM,0.9
</code></pre>
<p>We can use that chunk_filter:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chunker_filter.fit(data).transform(data)
</code></pre></div></div>
<p>Producing the following entities:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|[{chunk, 394, 408, byapproximately, {entity -&gt; TREATMENT, sentence -&gt; 1, chunk -&gt; 2, confidence -&gt; 0.7705}, []}, {chunk, 478, 508, single nucleotide polymorphisms, {entity -&gt; TREATMENT, sentence -&gt; 2, chunk -&gt; 3, confidence -&gt; 0.7204666}, []}, {chunk, 608, 625, insertion/deletion, {entity -&gt; PROBLEM, sentence -&gt; 3, chunk -&gt; 6, confidence -&gt; 0.9841}, []}]|

</code></pre></div></div>
<p>As you can see, only the treatment entities with confidence score of more than 0.7, and the problem entities with confidence score of more than 0.9 have been kept in the output.</p>

<h4 id="extended-regex-dictionary-fuctionallity-in-deidentification">Extended regex dictionary fuctionallity in Deidentification</h4>

<p>The RegexPatternsDictionary can now use a regex that spawns the 2 previous token and the 2 next tokens.
That feature is implemented using regex groups.</p>

<p>Examples:</p>

<p>Given the sentence <code class="language-plaintext highlighter-rouge">The patient with ssn 123123123</code> we can use the following regex to capture the entitty <code class="language-plaintext highlighter-rouge">ssn (\d{9})</code>
Given the sentence <code class="language-plaintext highlighter-rouge">The patient has 12 years</code> we can use the following regex to capture the entitty <code class="language-plaintext highlighter-rouge">(\d{2}) years</code></p>

<h4 id="enhanced-relationextractiondl-model-to-create-and-identify-relations-between-entities-across-the-entire-document">Enhanced RelationExtractionDL Model to create and identify relations between entities across the entire document</h4>

<p>A new option has been added to <code class="language-plaintext highlighter-rouge">RENerChunksFilter</code> to support pairing entities from different sentences using <code class="language-plaintext highlighter-rouge">.setDocLevelRelations(True)</code>, to pass to the Relation Extraction Model. The RelationExtractionDL Model has also been updated to process document-level relations.</p>

<p>How to use:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">re_dl_chunks</span> <span class="o">=</span> <span class="n">RENerChunksFilter</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
            <span class="p">.</span><span class="n">setDocLevelRelations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
            <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>\
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"redl_ner_chunks"</span><span class="p">)</span>  
</code></pre></div></div>

<p>Examples:</p>

<p>Given a document containing multiple sentences: <code class="language-plaintext highlighter-rouge">John somkes cigrettes. He also consumes alcohol.</code>, now we can generate relation pairs across sentences and relate <code class="language-plaintext highlighter-rouge">alcohol</code> with <code class="language-plaintext highlighter-rouge">John</code> .</p>

<h4 id="set-ner-graph-explicitely-in-medicalnerapproach">Set NER graph explicitely in MedicalNerApproach</h4>
<p>Now MedicalNerApproach can receives the path to the graph directly. When a graph location is provided through this method, previous graph search behavior is disabled.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MedicalNerApproach.setGraphFile(graphFilePath)
</code></pre></div></div>

<h4 id="medicalnerapproach-can-now-accept-a-user-defined-name-for-log-file">MedicalNerApproach can now accept a user-defined name for log file.</h4>
<p>Now MedicalNerApproach can accept a user-defined name for the log file. If not such a name is provided, the conventional naming will take place.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MedicalNerApproach.setLogPrefix("oncology_ner")
</code></pre></div></div>
<p>This will result in <code class="language-plaintext highlighter-rouge">oncology_ner_20210605_141701.log</code> filename being used, in which the <code class="language-plaintext highlighter-rouge">20210605_141701</code> is a timestamp.</p>

<h4 id="new-notebooks-1">New Notebooks</h4>

<ul>
  <li>A <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.4.Biomedical_NER_SparkNLP_paper_reproduce.ipynb">new notebook</a>  to reproduce our peer-reviewed NER paper (https://arxiv.org/abs/2011.06315)</li>
  <li>New databricks <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/databricks/python/healthcare_case_studies">case study notebooks</a>. In these notebooks, we showed the examples of how to work with oncology notes dataset and OCR on databricks for both DBr and community edition versions.</li>
</ul>

<h3 id="303">3.0.3</h3>

<p>We are glad to announce that Spark NLP for Healthcare 3.0.3 has been released!</p>

<h4 id="highlights-18">Highlights</h4>

<ul>
  <li>Five new entity resolution models to cover UMLS, HPO and LIONC terminologies.</li>
  <li>New feature for random displacement of dates on deidentification model.</li>
  <li>Five new pretrained pipelines to map terminologies across each other (from UMLS to ICD10, from RxNorm to MeSH etc.)</li>
  <li>AnnotationToolReader support for Spark 2.3. The tool that helps model training on Spark-NLP to leverage data annotated using JSL Annotation Tool now has support for Spark 2.3.</li>
  <li>Updated documentation (Scaladocs) covering more APIs, and examples.</li>
</ul>

<h4 id="five-new-resolver-models">Five new resolver models:</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_major_concepts</code>: This model returns CUI (concept unique identifier) codes for Clinical Findings, Medical Devices, Anatomical Structures and Injuries &amp; Poisoning terms.</li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_findings</code>: This model returns CUI (concept unique identifier) codes for 200K concepts from clinical findings.</li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_loinc</code>: Map clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbiobert</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">sbluebertresolve_loinc</code>: Map clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbluebert</code>.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_HPO</code>: This model returns Human Phenotype Ontology (HPO) codes for phenotypic abnormalities encountered in human diseases. It also returns associated codes from the following vocabularies for each HPO code:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  * MeSH (Medical Subject Headings)
  * SNOMED
  * UMLS (Unified Medical Language System )
  * ORPHA (international reference resource for information on rare diseases and orphan drugs)
  * OMIM (Online Mendelian Inheritance in Man)
</code></pre></div>    </div>

    <p><em>Related Notebook</em>: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb">Resolver Models</a></p>
  </li>
</ul>

<h4 id="new-feature-on-deidentification-module">New feature on Deidentification Module</h4>
<ul>
  <li>isRandomDateDisplacement(True): Be able to apply a random displacement on obfuscation dates. The randomness is based on the seed.</li>
  <li>Fix random dates when the format is not correct. Now you can repeat an execution using a seed for dates. Random dates will be based on the seed.</li>
</ul>

<h4 id="five-new-healthcare-code-mapping-pipelines">Five new healthcare code mapping pipelines:</h4>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">icd10cm_umls_mapping</code>: This pretrained pipeline maps ICD10CM codes to UMLS codes without using any text data. You’ll just feed white space-delimited ICD10CM codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'icd10cm': ['M89.50', 'R82.2', 'R09.01'],
    'umls': ['C4721411', 'C0159076', 'C0004044']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">mesh_umls_mapping</code>: This pretrained pipeline maps MeSH codes to UMLS codes without using any text data. You’ll just feed white space-delimited MeSH codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mesh': ['C028491', 'D019326', 'C579867'],
   'umls': ['C0970275', 'C0886627', 'C3696376']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">rxnorm_umls_mapping</code>: This pretrained pipeline maps RxNorm codes to UMLS codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'rxnorm': ['1161611', '315677', '343663'],
   'umls': ['C3215948', 'C0984912', 'C1146501']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">rxnorm_mesh_mapping</code>: This pretrained pipeline maps RxNorm codes to MeSH codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding MeSH codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'rxnorm': ['1191', '6809', '47613'],
   'mesh': ['D001241', 'D008687', 'D019355']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">snomed_umls_mapping</code>: This pretrained pipeline maps SNOMED codes to UMLS codes without using any text data. You’ll just feed white space-delimited SNOMED codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'snomed': ['733187009', '449433008', '51264003'],
   'umls': ['C4546029', 'C3164619', 'C0271267']}
</code></pre></div>    </div>

    <p><em>Related Notebook</em>: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.1.Healthcare_Code_Mapping.ipynb">Healthcare Code Mapping</a></p>
  </li>
</ul>

<h3 id="302">3.0.2</h3>

<p>We are very excited to announce that <strong>Spark NLP for Healthcare 3.0.2</strong> has been released! This release includes bug fixes and some compatibility improvements.</p>

<h4 id="highlights-19">Highlights</h4>

<ul>
  <li>Dictionaries for Obfuscator were augmented with more than 10K names.</li>
  <li>Improved support for spark 2.3 and spark 2.4.</li>
  <li>Bug fixes in <code class="language-plaintext highlighter-rouge">DrugNormalizer</code>.</li>
</ul>

<h4 id="new-features-1">New Features</h4>
<p>Provide confidence scores for all available tags in <code class="language-plaintext highlighter-rouge">MedicalNerModel</code>,</p>

<h5 id="medicalnermodel-before-302">MedicalNerModel before 3.0.2</h5>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[named_entity, 0, 9, B-PROBLEM, [word -&gt; Pneumonia, confidence -&gt; 0.9998], []]
</code></pre></div></div>
<h5 id="now-in-spark-nlp-for-healthcare-302">Now in Spark NLP for Healthcare 3.0.2</h5>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[named_entity, 0, 9, B-PROBLEM, [B-PROBLEM -&gt; 0.9998, I-TREATMENT -&gt; 0.0, I-PROBLEM -&gt; 0.0, I-TEST -&gt; 0.0, B-TREATMENT -&gt; 1.0E-4, word -&gt; Pneumonia, B-TEST -&gt; 0.0], []]
</code></pre></div></div>

<h3 id="301">3.0.1</h3>

<p>We are very excited to announce that <strong>Spark NLP for Healthcare 3.0.1</strong> has been released!</p>

<h4 id="highlights-20">Highlights:</h4>

<ul>
  <li>Fixed problem in Assertion Status internal tokenization (reported in Spark-NLP #2470).</li>
  <li>Fixes in the internal implementation of DeIdentificationModel/Obfuscator.</li>
  <li>Being able to disable the use of regexes in the Deidentification process</li>
  <li>Other minor bug fixes &amp; general improvements.</li>
</ul>

<h4 id="deidentificationmodel-annotator">DeIdentificationModel Annotator</h4>

<h5 id="new-seed-parameter">New <code class="language-plaintext highlighter-rouge">seed</code> parameter.</h5>
<p>Now we have the possibility of using a seed to guide the process of obfuscating entities and returning the same result across different executions. To make that possible a new method setSeed(seed:Int) was introduced.</p>

<p><strong>Example:</strong>
Return obfuscated documents in a repeatable manner based on the same seed.</p>
<h5 id="scala">Scala</h5>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">deIdentification</span> <span class="k">=</span> <span class="nc">DeIdentification</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setSeed</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>
<h5 id="python">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<p>This seed controls how the obfuscated values are picked from a set of obfuscation candidates. Fixing the seed allows the process to be replicated.</p>

<p><strong>Example:</strong></p>

<p>Given the following input to the deidentification:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"David Hale was in Cocke County Baptist Hospital. David Hale"
</code></pre></div></div>

<p>If the annotator is set up with a seed of 10:</p>
<h5 id="scala-1">Scala</h5>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val deIdentification = new DeIdentification()
      .setInputCols(Array("ner_chunk", "token", "sentence"))
      .setOutputCol("dei")
      .setMode("obfuscate")
      .setObfuscateRefSource("faker")
      .setSeed(10)
      .setIgnoreRegex(true)
</code></pre></div></div>
<h5 id="python-1">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<p>The result will be the following for any execution,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Brendan Kitten was in New Megan.Brendan Kitten"
</code></pre></div></div>
<p>Now if we set up a seed of 32,</p>
<h5 id="scala-2">Scala</h5>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setSeed</span><span class="o">(</span><span class="mi">32</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>
<h5 id="python-2">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The result will be the following for any execution,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Louise Pear was in Lake Edward.Louise Pear"
</code></pre></div></div>

<h5 id="new-ignoreregex-parameter">New <code class="language-plaintext highlighter-rouge">ignoreRegex</code> parameter.</h5>
<p>You can now choose to completely disable the use of regexes in the deidentification process by setting the setIgnoreRegex param to True.
<strong>Example:</strong></p>
<h5 id="scala-3">Scala</h5>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">DeIdentificationModel</span><span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>
<h5 id="python-3">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DeIdentificationModel</span><span class="p">().</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The default value for this param is <code class="language-plaintext highlighter-rouge">False</code> meaning that regexes will be used by default.</p>

<h5 id="new-supported-entities-for-deidentification--obfuscation">New supported entities for Deidentification &amp; Obfuscation:</h5>

<p>We added new entities to the default supported regexes:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">SSN - Social security number.</code></li>
  <li><code class="language-plaintext highlighter-rouge">PASSPORT - Passport id.</code></li>
  <li><code class="language-plaintext highlighter-rouge">DLN - Department of Labor Number.</code></li>
  <li><code class="language-plaintext highlighter-rouge">NPI - National Provider Identifier.</code></li>
  <li><code class="language-plaintext highlighter-rouge">C_CARD - The id number for credits card.</code></li>
  <li><code class="language-plaintext highlighter-rouge">IBAN - International Bank Account Number.</code></li>
  <li><code class="language-plaintext highlighter-rouge">DEA - DEA Registration Number, which is an identifier assigned to a health care provider by the United States Drug Enforcement Administration.</code></li>
</ul>

<p>We also introduced new Obfuscator cases for these new entities.</p>

<h3 id="300">3.0.0</h3>

<p>We are very excited to announce that <strong>Spark NLP for Healthcare 3.0.0</strong> has been released! This has been one of the biggest releases we have ever done and we are so proud to share this with our customers.</p>

<h4 id="highlights-21">Highlights:</h4>

<p>Spark NLP for Healthcare 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We now support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x helping the customers to migrate from earlier Apache Spark versions to newer releases without being worried about Spark NLP support.</p>

<h4 id="highlights-22">Highlights:</h4>
<ul>
  <li>Support for Apache Spark and PySpark 3.0.x on Scala 2.12</li>
  <li>Support for Apache Spark and PySpark 3.1.x on Scala 2.12</li>
  <li>Migrate to TensorFlow v2.3.1 with native support for Java to take advantage of many optimizations for CPU/GPU and new features/models introduced in TF v2.x</li>
  <li>A brand new <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> annotator to train &amp; load the licensed clinical NER models.</li>
  <li><strong>Two times faster NER and Entity Resolution</strong> due to new batch annotation technique.</li>
  <li>Welcoming 9x new Databricks runtimes to our Spark NLP family:
    <ul>
      <li>Databricks 7.3</li>
      <li>Databricks 7.3 ML GPU</li>
      <li>Databricks 7.4</li>
      <li>Databricks 7.4 ML GPU</li>
      <li>Databricks 7.5</li>
      <li>Databricks 7.5 ML GPU</li>
      <li>Databricks 7.6</li>
      <li>Databricks 7.6 ML GPU</li>
      <li>Databricks 8.0</li>
      <li>Databricks 8.0 ML (there is no GPU in 8.0)</li>
      <li>Databricks 8.1 Beta</li>
    </ul>
  </li>
  <li>Welcoming 2x new EMR 6.x series to our Spark NLP family:
    <ul>
      <li>EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1)</li>
      <li>EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1)</li>
    </ul>
  </li>
  <li>Starting Spark NLP for Healthcare 3.0.0 the default packages  for CPU and GPU will be based on Apache Spark 3.x and Scala 2.12.</li>
</ul>

<h5 id="deprecated">Deprecated</h5>

<p>Text2SQL annotator is deprecated and will not be maintained going forward. We are working on a better and faster version of Text2SQL at the moment and will announce soon.</p>

<h4 id="1-medicalnermodel-annotator">1. MedicalNerModel Annotator</h4>

<p>Starting Spark NLP for Healthcare 3.0.0, the licensed clinical and biomedical pretrained NER models will only work with this brand new annotator called <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> and will not work with <code class="language-plaintext highlighter-rouge">NerDLModel</code> in open source version.</p>

<p>In order to make this happen, we retrained all the clinical NER models (more than 80) and uploaded to models hub.</p>

<p>Example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clinical_ner = MedicalNerModel.pretrained("ner_clinical", "en", "clinical/models") \
.setInputCols(["sentence", "token", "embeddings"])\
.setOutputCol("ner")
</code></pre></div></div>

<h4 id="2-speed-improvements">2. Speed Improvements</h4>

<p>A new batch annotation technique implemented in Spark NLP 3.0.0 for <code class="language-plaintext highlighter-rouge">NerDLModel</code>,<code class="language-plaintext highlighter-rouge">BertEmbeddings</code>, and <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotators will be reflected in <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> and it improves prediction/inferencing performance radically. From now on the <code class="language-plaintext highlighter-rouge">batchSize</code> for these annotators means the number of rows that can be fed into the models for prediction instead of sentences per row. You can control the throughput when you are on accelerated hardware such as GPU to fully utilise it. Here are the overall speed comparison:</p>

<p>Now, NER inference and Entity Resolution are <strong>two times faster</strong> on CPU and three times faster on GPU.</p>

<h4 id="3-jsl-clinical-ner-model">3. JSL Clinical NER Model</h4>

<p>We are releasing the richest clinical NER model ever, spanning over 80 entities. It has been under development for the last 6 months and we manually annotated more than 4000 clinical notes to cover such a high number of entities in a single model. It has 4 variants at the moment:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">jsl_ner_wip_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">jsl_ner_wip_greedy_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">jsl_ner_wip_modifier_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">jsl_rd_ner_wip_greedy_clinical</code></li>
</ul>

<h5 id="entities">Entities:</h5>

<p><code class="language-plaintext highlighter-rouge">Kidney_Disease</code>, <code class="language-plaintext highlighter-rouge">HDL</code>, <code class="language-plaintext highlighter-rouge">Diet</code>, <code class="language-plaintext highlighter-rouge">Test</code>, <code class="language-plaintext highlighter-rouge">Imaging_Technique</code>, <code class="language-plaintext highlighter-rouge">Triglycerides</code>, <code class="language-plaintext highlighter-rouge">Obesity</code>, <code class="language-plaintext highlighter-rouge">Duration</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, <code class="language-plaintext highlighter-rouge">Social_History_Header</code>, <code class="language-plaintext highlighter-rouge">ImagingTest</code>, <code class="language-plaintext highlighter-rouge">Labour_Delivery</code>, <code class="language-plaintext highlighter-rouge">Disease_Syndrome_Disorder</code>, <code class="language-plaintext highlighter-rouge">Communicable_Disease</code>, <code class="language-plaintext highlighter-rouge">Overweight</code>, <code class="language-plaintext highlighter-rouge">Units</code>, <code class="language-plaintext highlighter-rouge">Smoking</code>, <code class="language-plaintext highlighter-rouge">Score</code>, <code class="language-plaintext highlighter-rouge">Substance_Quantity</code>, <code class="language-plaintext highlighter-rouge">Form</code>, <code class="language-plaintext highlighter-rouge">Race_Ethnicity</code>, <code class="language-plaintext highlighter-rouge">Modifier</code>, <code class="language-plaintext highlighter-rouge">Hyperlipidemia</code>, <code class="language-plaintext highlighter-rouge">ImagingFindings</code>, <code class="language-plaintext highlighter-rouge">Psychological_Condition</code>, <code class="language-plaintext highlighter-rouge">OtherFindings</code>, <code class="language-plaintext highlighter-rouge">Cerebrovascular_Disease</code>, <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Test_Result</code>, <code class="language-plaintext highlighter-rouge">VS_Finding</code>, <code class="language-plaintext highlighter-rouge">Employment</code>, <code class="language-plaintext highlighter-rouge">Death_Entity</code>, <code class="language-plaintext highlighter-rouge">Gender</code>, <code class="language-plaintext highlighter-rouge">Oncological</code>, <code class="language-plaintext highlighter-rouge">Heart_Disease</code>, <code class="language-plaintext highlighter-rouge">Medical_Device</code>, <code class="language-plaintext highlighter-rouge">Total_Cholesterol</code>, <code class="language-plaintext highlighter-rouge">ManualFix</code>, <code class="language-plaintext highlighter-rouge">Time</code>, <code class="language-plaintext highlighter-rouge">Route</code>, <code class="language-plaintext highlighter-rouge">Pulse</code>, <code class="language-plaintext highlighter-rouge">Admission_Discharge</code>, <code class="language-plaintext highlighter-rouge">RelativeDate</code>, <code class="language-plaintext highlighter-rouge">O2_Saturation</code>, <code class="language-plaintext highlighter-rouge">Frequency</code>, <code class="language-plaintext highlighter-rouge">RelativeTime</code>, <code class="language-plaintext highlighter-rouge">Hypertension</code>, <code class="language-plaintext highlighter-rouge">Alcohol</code>, <code class="language-plaintext highlighter-rouge">Allergen</code>, <code class="language-plaintext highlighter-rouge">Fetus_NewBorn</code>, <code class="language-plaintext highlighter-rouge">Birth_Entity</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Respiration</code>, <code class="language-plaintext highlighter-rouge">Medical_History_Header</code>, <code class="language-plaintext highlighter-rouge">Oxygen_Therapy</code>, <code class="language-plaintext highlighter-rouge">Section_Header</code>, <code class="language-plaintext highlighter-rouge">LDL</code>, <code class="language-plaintext highlighter-rouge">Treatment</code>, <code class="language-plaintext highlighter-rouge">Vital_Signs_Header</code>, <code class="language-plaintext highlighter-rouge">Direction</code>, <code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Pregnancy</code>, <code class="language-plaintext highlighter-rouge">Sexually_Active_or_Sexual_Orientation</code>, <code class="language-plaintext highlighter-rouge">Symptom</code>, <code class="language-plaintext highlighter-rouge">Clinical_Dept</code>, <code class="language-plaintext highlighter-rouge">Measurements</code>, <code class="language-plaintext highlighter-rouge">Height</code>, <code class="language-plaintext highlighter-rouge">Family_History_Header</code>, <code class="language-plaintext highlighter-rouge">Substance</code>, <code class="language-plaintext highlighter-rouge">Strength</code>, <code class="language-plaintext highlighter-rouge">Injury_or_Poisoning</code>, <code class="language-plaintext highlighter-rouge">Relationship_Status</code>, <code class="language-plaintext highlighter-rouge">Blood_Pressure</code>, <code class="language-plaintext highlighter-rouge">Drug</code>, <code class="language-plaintext highlighter-rouge">Temperature</code>, <code class="language-plaintext highlighter-rouge">EKG_Findings</code>, <code class="language-plaintext highlighter-rouge">Diabetes</code>, <code class="language-plaintext highlighter-rouge">BodyPart</code>, <code class="language-plaintext highlighter-rouge">Vaccine</code>, <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">Dosage</code></p>

<h4 id="4-jsl-clinical-assertion-model">4. JSL Clinical Assertion Model</h4>

<p>We are releasing a brand new clinical assertion model, supporting 8 assertion statuses.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">jsl_assertion_wip</code></li>
</ul>

<h5 id="assertion-labels-">Assertion Labels :</h5>

<p><code class="language-plaintext highlighter-rouge">Present</code>, <code class="language-plaintext highlighter-rouge">Absent</code>, <code class="language-plaintext highlighter-rouge">Possible</code>, <code class="language-plaintext highlighter-rouge">Planned</code>, <code class="language-plaintext highlighter-rouge">Someoneelse</code>, <code class="language-plaintext highlighter-rouge">Past</code>, <code class="language-plaintext highlighter-rouge">Family</code>, <code class="language-plaintext highlighter-rouge">Hypotetical</code></p>

<h4 id="5-library-version-compatibility-table-">5. Library Version Compatibility Table :</h4>

<p>Spark NLP for Healthcare 3.0.0 is compatible with Spark NLP 3.0.1</p>

<h4 id="6-pretrained-models-version-control-beta">6. Pretrained Models Version Control (Beta):</h4>

<p>Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks.</p>

<p>We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This is the second version of the model checker we released with 2.7.6 and will replace that soon.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.compatibility_beta import CompatibilityBeta

compatibility = CompatibilityBeta(spark)

print(compatibility.findVersion("ner_deid"))
</code></pre></div></div>

<h4 id="7-updated-pretrained-models">7. Updated Pretrained Models:</h4>

<p>(requires fresh <code class="language-plaintext highlighter-rouge">.pretraned()</code>)</p>

<p>None</p>

<h3 id="276">2.7.6</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.6 has been released!</p>

<h4 id="highlights-23">Highlights:</h4>

<ul>
  <li>
    <p>New pretrained <strong>Radiology Assertion Status</strong> model to assign <code class="language-plaintext highlighter-rouge">Confirmed</code>, <code class="language-plaintext highlighter-rouge">Suspected</code>, <code class="language-plaintext highlighter-rouge">Negative</code> assertion scopes to imaging findings or any clinical tests.</p>
  </li>
  <li>
    <p><strong>Obfuscating</strong> the same sensitive information (patient or doctor name) with the same fake names across the same clinical note.</p>
  </li>
  <li>
    <p>Version compatibility checker for the pretrained clinical models and builds to keep up with the latest development efforts in production.</p>
  </li>
  <li>
    <p>Adding more English names to faker module in <strong>Deidentification</strong>.</p>
  </li>
  <li>
    <p>Updated &amp; improved clinical <strong>SentenceDetectorDL</strong> model.</p>
  </li>
  <li>
    <p>New upgrades on <code class="language-plaintext highlighter-rouge">ner_deid_large</code> and <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> NER models to cover more use cases with better resolutions.</p>
  </li>
  <li>
    <p>Adding more <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/scala/healthcare">examples</a> to workshop repo for <em>Scala</em> users to practice more on healthcare annotators.</p>
  </li>
  <li>
    <p>Bug fixes &amp; general improvements.</p>
  </li>
</ul>

<h4 id="1-radiology-assertion-status-model">1. Radiology Assertion Status Model</h4>

<p>We trained a new assertion model to assign <code class="language-plaintext highlighter-rouge">Confirmed</code>, <code class="language-plaintext highlighter-rouge">Suspected</code>, <code class="language-plaintext highlighter-rouge">Negative</code> assertion scopes to imaging findings or any clinical tests. It will try to assign these statuses to any named entity you would feed to the assertion annotater in the same pipeline.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> radiology_assertion = AssertionDLModel.pretrained("assertion_dl_radiology", "en", "clinical/models")\
 .setInputCols(["sentence", "ner_chunk", "embeddings"])\
 .setOutputCol("assertion")
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">text = Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. No right-sided pleural effusion or pneumothorax is definitively seen. There are mildly displaced fractures of the left lateral 8th and likely 9th ribs.</code></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">sentences</th>
      <th style="text-align: center">chunk</th>
      <th style="text-align: center">ner_label</th>
      <th style="text-align: center">sent_id</th>
      <th style="text-align: left">assertion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion.</td>
      <td style="text-align: center">Blunting</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">0</td>
      <td style="text-align: left">Confirmed</td>
    </tr>
    <tr>
      <td style="text-align: right">Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion.</td>
      <td style="text-align: center">effusion</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">0</td>
      <td style="text-align: left">Suspected</td>
    </tr>
    <tr>
      <td style="text-align: right">No right-sided pleural effusion or pneumothorax is definitively seen.</td>
      <td style="text-align: center">effusion</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">1</td>
      <td style="text-align: left">Negative</td>
    </tr>
    <tr>
      <td style="text-align: right">No right-sided pleural effusion or pneumothorax is definitively seen.</td>
      <td style="text-align: center">pneumothorax</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">1</td>
      <td style="text-align: left">Negative</td>
    </tr>
    <tr>
      <td style="text-align: right">There are mildly displaced fractures of the left lateral 8th and likely 9th ribs.</td>
      <td style="text-align: center">displaced fractures</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">2</td>
      <td style="text-align: left">Confirmed</td>
    </tr>
  </tbody>
</table>

<p>You can also use this with <code class="language-plaintext highlighter-rouge">AssertionFilterer</code> to return clinical findings from a note only when it is i.e. <code class="language-plaintext highlighter-rouge">confirmed</code> or <code class="language-plaintext highlighter-rouge">suspected</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> assertion_filterer = AssertionFilterer()\
 .setInputCols("sentence","ner_chunk","assertion")\
 .setOutputCol("assertion_filtered")\
 .setWhiteList(["confirmed","suspected"])

 &gt;&gt; ["displaced fractures", "effusion"]
</code></pre></div></div>

<h4 id="2-obfuscating-with-the-same-fake-name-across-the-same-note">2. <strong>Obfuscating</strong> with the same fake name across the same note:</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> obfuscation = DeIdentification()\
  .setInputCols(["sentence", "token", "ner_chunk"]) \
  .setOutputCol("deidentified") \
  .setMode("obfuscate")\
  .setObfuscateDate(True)\
  .setSameEntityThreshold(0.8)\
  .setObfuscateRefSource("faker")


text =''' Provider: David Hale, M.D.
          Pt: Jessica Parker
          David told  Jessica that she will need to visit the clinic next month.'''
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">sentence</th>
      <th style="text-align: left">obfuscated</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Provider: <code class="language-plaintext highlighter-rouge">David Hale</code>, M.D.</td>
      <td style="text-align: left">Provider: <code class="language-plaintext highlighter-rouge">Dennis Perez</code>, M.D.</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Pt: <code class="language-plaintext highlighter-rouge">Jessica Parker</code></td>
      <td style="text-align: left">Pt: <code class="language-plaintext highlighter-rouge">Gerth Bayer</code></td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">David</code> told  <code class="language-plaintext highlighter-rouge">Jessica</code> that she will need to visit the clinic next month.</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Dennis</code> told  <code class="language-plaintext highlighter-rouge">Gerth</code> that she will need to visit the clinic next month.</td>
    </tr>
  </tbody>
</table>

<h4 id="3-library-version-compatibility-table-">3. Library Version Compatibility Table :</h4>

<p>We are releasing the version compatibility table to help users get to see which Spark NLP licensed version is built against which core (open source) version. We are going to release a detailed one after running some tests across the jars from each library.</p>

<table>
  <thead>
    <tr>
      <th>Healthcare</th>
      <th>Public</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2.7.6</td>
      <td>2.7.4</td>
    </tr>
    <tr>
      <td>2.7.5</td>
      <td>2.7.4</td>
    </tr>
    <tr>
      <td>2.7.4</td>
      <td>2.7.3</td>
    </tr>
    <tr>
      <td>2.7.3</td>
      <td>2.7.3</td>
    </tr>
    <tr>
      <td>2.7.2</td>
      <td>2.6.5</td>
    </tr>
    <tr>
      <td>2.7.1</td>
      <td>2.6.4</td>
    </tr>
    <tr>
      <td>2.7.0</td>
      <td>2.6.3</td>
    </tr>
    <tr>
      <td>2.6.2</td>
      <td>2.6.2</td>
    </tr>
    <tr>
      <td>2.6.0</td>
      <td>2.6.0</td>
    </tr>
    <tr>
      <td>2.5.5</td>
      <td>2.5.5</td>
    </tr>
    <tr>
      <td>2.5.3</td>
      <td>2.5.3</td>
    </tr>
    <tr>
      <td>2.5.2</td>
      <td>2.5.2</td>
    </tr>
    <tr>
      <td>2.5.0</td>
      <td>2.5.0</td>
    </tr>
    <tr>
      <td>2.4.7</td>
      <td>2.4.5</td>
    </tr>
    <tr>
      <td>2.4.6</td>
      <td>2.4.5</td>
    </tr>
    <tr>
      <td>2.4.5</td>
      <td>2.4.5</td>
    </tr>
    <tr>
      <td>2.4.2</td>
      <td>2.4.2</td>
    </tr>
    <tr>
      <td>2.4.1</td>
      <td>2.4.1</td>
    </tr>
    <tr>
      <td>2.4.0</td>
      <td>2.4.0</td>
    </tr>
    <tr>
      <td>2.3.6</td>
      <td>2.3.6</td>
    </tr>
    <tr>
      <td>2.3.5</td>
      <td>2.3.5</td>
    </tr>
    <tr>
      <td>2.3.4</td>
      <td>2.3.4</td>
    </tr>
  </tbody>
</table>

<h4 id="4-pretrained-models-version-control-">4. Pretrained Models Version Control :</h4>

<p>Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks.</p>

<p>We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. This is an highly experimental feature of which we plan to improve and add more capability later on.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.check_compatibility import Compatibility

 checker = sparknlp_jsl.Compatibility()

 result = checker.find_version(aws_access_key_id=license_keys['AWS_ACCESS_KEY_ID'],
                        aws_secret_access_key=license_keys['AWS_SECRET_ACCESS_KEY'],
                        metadata_path=None,
                        model = 'all' , # or a specific model name
                        target_version='all',
                        cache_pretrained_path='/home/ubuntu/cache_pretrained')

 &gt;&gt; result['outdated_models']

  [{'model_name': 'clinical_ner_assertion',
    'current_version': '2.4.0',
    'latest_version': '2.6.4'},
   {'model_name': 'jsl_rd_ner_wip_greedy_clinical',
    'current_version': '2.6.1',
    'latest_version': '2.6.2'},
   {'model_name': 'ner_anatomy',
    'current_version': '2.4.2',
    'latest_version': '2.6.4'},
   {'model_name': 'ner_aspect_based_sentiment',
    'current_version': '2.6.2',
    'latest_version': '2.7.2'},
   {'model_name': 'ner_bionlp',
    'current_version': '2.4.0',
    'latest_version': '2.7.0'},
   {'model_name': 'ner_cellular',
    'current_version': '2.4.2',
    'latest_version': '2.5.0'}]

  &gt;&gt; result['version_comparison_dict']

  [{'clinical_ner_assertion': {'current_version': '2.4.0', 'latest_version': '2.6.4'}}, {'jsl_ner_wip_clinical': {'current_version': '2.6.5', 'latest_version': '2.6.1'}}, {'jsl_ner_wip_greedy_clinical': {'current_version': '2.6.5', 'latest_version': '2.6.5'}}, {'jsl_ner_wip_modifier_clinical': {'current_version': '2.6.4', 'latest_version': '2.6.4'}}, {'jsl_rd_ner_wip_greedy_clinical': {'current_version': '2.6.1','latest_version': '2.6.2'}}]
</code></pre></div></div>

<h4 id="5-updated-pretrained-models">5. Updated Pretrained Models:</h4>

<p>(requires fresh <code class="language-plaintext highlighter-rouge">.pretraned()</code>)</p>

<ul>
  <li>ner_deid_large</li>
  <li>ner_deid_enriched</li>
</ul>

<h3 id="275">2.7.5</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.5 has been released!</p>

<h4 id="highlights-24">Highlights:</h4>

<ul>
  <li>New pretrained <strong>Relation Extraction</strong> model to link clinical tests to test results and dates to clinical entities: <code class="language-plaintext highlighter-rouge">re_test_result_date</code></li>
  <li>Adding two new <code class="language-plaintext highlighter-rouge">Admission</code> and <code class="language-plaintext highlighter-rouge">Discharge</code> entities to <code class="language-plaintext highlighter-rouge">ner_events_clinical</code> and renaming it to <code class="language-plaintext highlighter-rouge">ner_events_admission_clinical</code></li>
  <li>Improving <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> NER model to cover <code class="language-plaintext highlighter-rouge">Doctor</code> and <code class="language-plaintext highlighter-rouge">Patient</code> name entities in various context and notations.</li>
  <li>Bug fixes &amp; general improvements.</li>
</ul>

<h4 id="1-re_test_result_date-">1. re_test_result_date :</h4>

<p>text = “Hospitalized with pneumonia in June, confirmed by a positive PCR of any specimen, evidenced by SPO2 &lt;/= 93% or PaO2/FiO2 &lt; 300 mmHg”</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Chunk-1</th>
      <th style="text-align: left">Entity-1</th>
      <th style="text-align: left">Chunk-2</th>
      <th style="text-align: left">Entity-2</th>
      <th style="text-align: left">Relation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">pneumonia</td>
      <td style="text-align: left">Problem</td>
      <td style="text-align: left">june</td>
      <td style="text-align: left">Date</td>
      <td style="text-align: left">is_date_of</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">PCR</td>
      <td style="text-align: left">Test</td>
      <td style="text-align: left">positive</td>
      <td style="text-align: left">Test_Result</td>
      <td style="text-align: left">is_result_of</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">SPO2</td>
      <td style="text-align: left">Test</td>
      <td style="text-align: left">93%</td>
      <td style="text-align: left">Test_Result</td>
      <td style="text-align: left">is_result_of</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">PaO2/FiO2</td>
      <td style="text-align: left">Test</td>
      <td style="text-align: left">300 mmHg</td>
      <td style="text-align: left">Test_Result</td>
      <td style="text-align: left">is_result_of</td>
    </tr>
  </tbody>
</table>

<h4 id="2-ner_events_admission_clinical-">2. <code class="language-plaintext highlighter-rouge">ner_events_admission_clinical</code> :</h4>

<p><code class="language-plaintext highlighter-rouge">ner_events_clinical</code> NER model is updated &amp; improved to include <code class="language-plaintext highlighter-rouge">Admission</code> and <code class="language-plaintext highlighter-rouge">Discharge</code> entities.</p>

<p>text =”She is diagnosed as cancer in 1991. Then she was admitted to Mayo Clinic in May 2000 and discharged in October 2001”</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: left">entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">diagnosed</td>
      <td style="text-align: left">OCCURRENCE</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">cancer</td>
      <td style="text-align: left">PROBLEM</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">1991</td>
      <td style="text-align: left">DATE</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">admitted</td>
      <td style="text-align: left">ADMISSION</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">Mayo Clinic</td>
      <td style="text-align: left">CLINICAL_DEPT</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">May 2000</td>
      <td style="text-align: left">DATE</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">discharged</td>
      <td style="text-align: left">DISCHARGE</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">October 2001</td>
      <td style="text-align: left">DATE</td>
    </tr>
  </tbody>
</table>

<h4 id="3-improved-ner_deid_enriched-">3. Improved <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> :</h4>

<p>PHI NER model is retrained to cover <code class="language-plaintext highlighter-rouge">Doctor</code> and <code class="language-plaintext highlighter-rouge">Patient</code> name entities even there is a punctuation between tokens as well as all upper case or lowercased.</p>

<p>text =”A . Record date : 2093-01-13 , DAVID HALE , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01/13/93 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street”</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: left">entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">2093-01-13</td>
      <td style="text-align: left">MEDICALRECORD</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">DAVID HALE</td>
      <td style="text-align: left">DOCTOR</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Hendrickson , Ora</td>
      <td style="text-align: left">PATIENT</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">7194334</td>
      <td style="text-align: left">MEDICALRECORD</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">01/13/93</td>
      <td style="text-align: left">DATE</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">Oliveira</td>
      <td style="text-align: left">DOCTOR</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">25</td>
      <td style="text-align: left">AGE</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">2079-11-09</td>
      <td style="text-align: left">MEDICALRECORD</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">Cocke County Baptist Hospital</td>
      <td style="text-align: left">HOSPITAL</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">0295 Keats Street</td>
      <td style="text-align: left">STREET</td>
    </tr>
  </tbody>
</table>

<h3 id="274">2.7.4</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.4 has been released!</p>

<h4 id="highlights-25">Highlights:</h4>

<ul>
  <li>Introducing a new annotator to extract chunks with NER tags using regex-like patterns: <strong>NerChunker</strong>.</li>
  <li>Introducing two new annotators to filter chunks: <strong>ChunkFilterer</strong> and <strong>AssertionFilterer</strong>.</li>
  <li>Ability to change the entity type in <strong>NerConverterInternal</strong> without using ChunkMerger (<code class="language-plaintext highlighter-rouge">setReplaceDict</code>).</li>
  <li>In <strong>DeIdentification</strong> model, ability to use <code class="language-plaintext highlighter-rouge">faker</code> and static look-up lists at the same time randomly in <code class="language-plaintext highlighter-rouge">Obfuscation</code> mode.</li>
  <li>New <strong>De-Identification NER</strong> model, augmented with synthetic datasets to detect uppercased name entities.</li>
  <li>Bug fixes &amp; general improvements.</li>
</ul>

<h4 id="1-nerchunker">1. NerChunker:</h4>

<p>Similar to what we used to do in <strong>POSChunker</strong> with POS tags, now we can also extract phrases that fits into a known pattern using the NER tags. <strong>NerChunker</strong> would be quite handy to extract entity groups with neighboring tokens when there is no pretrained NER model to address certain issues. Lets say we want to extract clinical findings and body parts together as a single chunk even if there are some unwanted tokens between.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_model = NerDLModel.pretrained("ner_radiology", "en", "clinical/models")\
    .setInputCols("sentence","token","embeddings")\
    .setOutputCol("ner")

ner_chunker = NerChunker().\
    .setInputCols(["sentence","ner"])\
    .setOutputCol("ner_chunk")\
    .setRegexParsers(["&lt;IMAGINGFINDINGS&gt;*&lt;BODYPART&gt;"])

text = 'She has cystic cyst on her kidney.'

&gt;&gt; ner tags: [(cystic, B-IMAGINGFINDINGS), (cyst,I-IMAGINGFINDINGS), (kidney, B-BODYPART)
&gt;&gt; ner_chunk: ['cystic cyst on her kidney']
</code></pre></div></div>

<h4 id="2-chunkfilterer">2. ChunkFilterer:</h4>

<p><strong>ChunkFilterer</strong> will allow you to filter out named entities by some conditions or predefined look-up lists, so that you can feed these entities to other annotators like Assertion Status or Entity Resolvers.  It can be used with two criteria: <strong>isin</strong> and <strong>regex</strong>.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_model = NerDLModel.pretrained("ner_clinical", "en", "clinical/models")\
      .setInputCols("sentence","token","embeddings")\
      .setOutputCol("ner")

ner_converter = NerConverter() \
      .setInputCols(["sentence", "token", "ner"]) \
      .setOutputCol("ner_chunk")

chunk_filterer = ChunkFilterer()\
      .setInputCols("sentence","ner_chunk")\
      .setOutputCol("chunk_filtered")\
      .setCriteria("isin") \
      .setWhiteList(['severe fever','sore throat'])

text = 'Patient with severe fever, sore throat, stomach pain, and a headache.'

&gt;&gt; ner_chunk: ['severe fever','sore throat','stomach pain','headache']
&gt;&gt; chunk_filtered: ['severe fever','sore throat']
</code></pre></div></div>

<h4 id="3-assertionfilterer">3. AssertionFilterer:</h4>

<p><strong>AssertionFilterer</strong> will allow you to filter out the named entities by the list of acceptable assertion statuses. This annotator would be quite handy if you want to set a white list for the acceptable assertion statuses like <code class="language-plaintext highlighter-rouge">present</code> or <code class="language-plaintext highlighter-rouge">conditional</code>; and do not want <code class="language-plaintext highlighter-rouge">absent</code> conditions get out of your pipeline.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clinical_assertion = AssertionDLModel.pretrained("assertion_dl", "en", "clinical/models") \
  .setInputCols(["sentence", "ner_chunk", "embeddings"]) \
  .setOutputCol("assertion")

assertion_filterer = AssertionFilterer()\
  .setInputCols("sentence","ner_chunk","assertion")\
  .setOutputCol("assertion_filtered")\
  .setWhiteList(["present"])


text = 'Patient with severe fever and sore throat, but no stomach pain.'

&gt;&gt; ner_chunk: ['severe fever','sore throat','stomach pain','headache']
&gt;&gt; assertion_filtered: ['severe fever','sore throat']
</code></pre></div></div>

<h3 id="273">2.7.3</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.3 has been released!</p>

<h4 id="highlights-26">Highlights:</h4>

<ul>
  <li>Introducing a brand-new <strong>RelationExtractionDL Annotator</strong> – Achieving SOTA results in clinical relation extraction using <strong>BioBert</strong>.</li>
  <li>Massive Improvements &amp; feature enhancements in <strong>De-Identification</strong> module:
    <ul>
      <li>Introduction of <strong>faker</strong> augmentation in Spark NLP for Healthcare to generate random data for obfuscation in de-identification module.</li>
      <li>Brand-new annotator for <strong>Structured De-Identification</strong>.</li>
    </ul>
  </li>
  <li><strong>Drug Normalizer:</strong>  Normalize medication-related phrases (dosage, form and strength) and abbreviations in text and named entities extracted by NER models.</li>
  <li><strong>Confidence scores</strong> in <strong>assertion</strong> output : just like NER output, assertion models now also support confidence scores for each prediction.</li>
  <li><strong>Cosine similarity</strong> metrics in entity resolvers to get more informative and semantically correct results.</li>
  <li><strong>AuxLabel</strong> in the metadata of entity resolvers to return additional mappings.</li>
  <li>New <strong>Relation Extraction</strong> models to extract relations between <strong>body parts</strong> and clinical entities.</li>
  <li>New <strong>Entity Resolver</strong> models to extract billable medical codes.</li>
  <li>New <strong>Clinical Pretrained NER</strong> models.</li>
  <li>Bug fixes &amp; general improvements.</li>
  <li>Matching the version with Spark NLP open-source v2.7.3.</li>
</ul>

<h4 id="1-improvements-in-de-identification-module">1. Improvements in De-Identification Module:</h4>

<p>Integration of <code class="language-plaintext highlighter-rouge">faker</code> library to automatically generate random data like names, dates, addresses etc so users dont have to specify dummy data (custom obfuscation files can still be used). It also improves the obfuscation results due to a bigger pool of random values.</p>

<p><strong>How to use:</strong></p>

<p>Set the flag <code class="language-plaintext highlighter-rouge">setObfuscateRefSource</code> to <code class="language-plaintext highlighter-rouge">faker</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>deidentification = DeIdentification()
    .setInputCols(["sentence", "token", "ner_chunk"])\
	.setOutputCol("deidentified")\
	.setMode("obfuscate") \
	.setObfuscateRefSource("faker")
</code></pre></div></div>

<p>For more details: Check out this <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb">notebook </a></p>

<h4 id="2-structured-de-identification-module">2. Structured De-Identification Module:</h4>

<p>Introduction of a new annotator to handle de-identification of structured data. it  allows users to define a mapping of columns and their obfuscation policy. Users can also provide dummy data and map them to columns they want to replace values in.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>obfuscator = StructuredDeidentification \
	(spark,{"NAME":"PATIENT","AGE":"AGE"},
	obfuscateRefSource = "faker")

obfuscator_df = obfuscator.obfuscateColumns(df)

obfuscator_df.select("NAME","AGE").show(truncate=False)
</code></pre></div></div>

<p><strong>Example:</strong></p>

<p>Input Data:</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cecilia Chapman</td>
      <td>83</td>
    </tr>
    <tr>
      <td>Iris Watson</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Bryar Pitts</td>
      <td>98</td>
    </tr>
    <tr>
      <td>Theodore Lowe</td>
      <td>16</td>
    </tr>
    <tr>
      <td>Calista Wise</td>
      <td>76</td>
    </tr>
  </tbody>
</table>

<p>Deidentified:</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Menne Erdôs</td>
      <td>20</td>
    </tr>
    <tr>
      <td>Longin Robinson</td>
      <td>31</td>
    </tr>
    <tr>
      <td>Flynn Fiedlerová</td>
      <td>50</td>
    </tr>
    <tr>
      <td>John Wakeland</td>
      <td>21</td>
    </tr>
    <tr>
      <td>Vanessa Andersson</td>
      <td>12</td>
    </tr>
  </tbody>
</table>

<p>For more details: Check out this <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb">notebook</a>.</p>

<h4 id="3-introducing-sota-relation-extraction-model-using-biobert">3. Introducing SOTA relation extraction model using BioBert</h4>

<p>A brand-new end-to-end trained BERT model, resulting in massive improvements. Another new annotator (<code class="language-plaintext highlighter-rouge">ReChunkFilter</code>) is also developed for this new model to allow syntactic features work well with BioBert to extract relations.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re_ner_chunk_filter = RENerChunksFilter()\
    .setInputCols(["ner_chunks", "dependencies"])\
    .setOutputCol("re_ner_chunks")\
    .setRelationPairs(pairs)\
    .setMaxSyntacticDistance(4)

re_model = RelationExtractionDLModel()\
    .pretrained(“redl_temporal_events_biobert”, "en", "clinical/models")\
    .setPredictionThreshold(0.9)\
    .setInputCols(["re_ner_chunks", "sentences"])\
    .setOutputCol("relations")
</code></pre></div></div>

<h5 id="benchmarks">Benchmarks:</h5>

<p><strong>on benchmark datasets</strong></p>

<table>
  <thead>
    <tr>
      <th>model</th>
      <th>Spark NLP ML model</th>
      <th>Spark NLP DL model</th>
      <th>benchmark</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>re_temporal_events_clinical</td>
      <td>68.29</td>
      <td>71.0</td>
      <td>80.2 <a href="https://arxiv.org/pdf/2012.08790.pdf">1</a></td>
    </tr>
    <tr>
      <td>re_clinical</td>
      <td>56.45</td>
      <td><strong>69.2</strong></td>
      <td>68.2      <a href="ncbi.nlm.nih.gov/pmc/articles/PMC7153059/">2</a></td>
    </tr>
    <tr>
      <td>re_human_pheotype_gene_clinical</td>
      <td>-</td>
      <td><strong>87.9</strong></td>
      <td>67.2 <a href="https://arxiv.org/pdf/1903.10728.pdf">3</a></td>
    </tr>
    <tr>
      <td>re_drug_drug_interaction</td>
      <td>-</td>
      <td>72.1</td>
      <td>83.8 <a href="https://www.aclweb.org/anthology/2020.knlp-1.4.pdf">4</a></td>
    </tr>
    <tr>
      <td>re_chemprot</td>
      <td>76.69</td>
      <td><strong>94.1</strong></td>
      <td>83.64 <a href="https://www.aclweb.org/anthology/D19-1371.pdf">5</a></td>
    </tr>
  </tbody>
</table>

<p><strong>on in-house annotations</strong></p>

<table>
  <thead>
    <tr>
      <th>model</th>
      <th>Spark NLP ML model</th>
      <th>Spark NLP DL model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>re_bodypart_problem</td>
      <td>84.58</td>
      <td>85.7</td>
    </tr>
    <tr>
      <td>re_bodypart_procedure</td>
      <td>61.0</td>
      <td>63.3</td>
    </tr>
    <tr>
      <td>re_date_clinical</td>
      <td>83.0</td>
      <td>84.0</td>
    </tr>
    <tr>
      <td>re_bodypart_direction</td>
      <td>93.5</td>
      <td>92.5</td>
    </tr>
  </tbody>
</table>

<p>For more details: Check out the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.1.Clinical_Relation_Extraction_BodyParts_Models.ipynb">notebook</a> or <a href="https://nlp.johnsnowlabs.com/models?tag=relation_extraction">modelshub</a>.</p>

<h4 id="4-drug-normalizer">4. Drug Normalizer:</h4>

<p>Standardize units of drugs and handle abbreviations in raw text or drug chunks identified by any NER model. This normalization significantly improves performance of entity resolvers.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drug_normalizer = DrugNormalizer()\
    .setInputCols("document")\
    .setOutputCol("document_normalized")\
    .setPolicy("all") #all/abbreviations/dosages
</code></pre></div></div>

<p><strong>Examples:</strong></p>

<p><code class="language-plaintext highlighter-rouge">drug_normalizer.transform("adalimumab 54.5 + 43.2 gm”)</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; "adalimumab 97700 mg"
</code></pre></div></div>

<p><strong>Changes:</strong> <em>combine</em> <code class="language-plaintext highlighter-rouge">54.5</code> + <code class="language-plaintext highlighter-rouge">43.2</code> and <em>normalize</em> <code class="language-plaintext highlighter-rouge">gm</code> to <code class="language-plaintext highlighter-rouge">mg</code></p>

<p><code class="language-plaintext highlighter-rouge">drug_normalizer.transform("Agnogenic one half cup”)</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; "Agnogenic 0.5 oral solution"
</code></pre></div></div>

<p><strong>Changes:</strong> <em>replace</em> <code class="language-plaintext highlighter-rouge">one half</code> to the <code class="language-plaintext highlighter-rouge">0.5</code>, <em>normalize</em> <code class="language-plaintext highlighter-rouge">cup</code> to the <code class="language-plaintext highlighter-rouge">oral solution</code></p>

<p><code class="language-plaintext highlighter-rouge">drug_normalizer.transform("interferon alfa-2b 10 million unit ( 1 ml ) injec”)</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; "interferon alfa - 2b 10000000 unt ( 1 ml ) injection "
</code></pre></div></div>

<p><strong>Changes:</strong> <em>convert</em> <code class="language-plaintext highlighter-rouge">10 million unit</code> to the <code class="language-plaintext highlighter-rouge">10000000 unt</code>, <em>replace</em> <code class="language-plaintext highlighter-rouge">injec</code> with <code class="language-plaintext highlighter-rouge">injection</code></p>

<p>For more details: Check out this <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/23.Drug_Normalizer.ipynb">notebook</a></p>

<h4 id="5-assertion-models-to-support-confidence-in-output">5. Assertion models to support confidence in output:</h4>

<p>Just like NER output, assertion models now also provides <em>confidence scores</em> for each prediction.</p>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>entities</th>
      <th>assertion</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>a headache</td>
      <td>PROBLEM</td>
      <td>present</td>
      <td>0.9992</td>
    </tr>
    <tr>
      <td>anxious</td>
      <td>PROBLEM</td>
      <td>conditional</td>
      <td>0.9039</td>
    </tr>
    <tr>
      <td>alopecia</td>
      <td>PROBLEM</td>
      <td>absent</td>
      <td>0.9992</td>
    </tr>
    <tr>
      <td>pain</td>
      <td>PROBLEM</td>
      <td>absent</td>
      <td>0.9238</td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">.setClasses()</code> method is deprecated in <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code>  and users do not need to specify number of classes while training, as it will be inferred from the dataset.</p>

<h4 id="6-new-relation-extraction-models">6. New Relation Extraction Models:</h4>

<p>We are also releasing new relation extraction models to link the clinical entities to body parts and dates. These models are trained using binary relation extraction approach for better accuracy.</p>

<p><strong>- re_bodypart_direction :</strong>  Relation Extraction between <code class="language-plaintext highlighter-rouge">Body Part</code> and <code class="language-plaintext highlighter-rouge">Direction</code> entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia”</em></p>

<table>
  <thead>
    <tr>
      <th>relations</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Direction</td>
      <td>upper</td>
      <td>bodyPart</td>
      <td>brain stem</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>Direction</td>
      <td>upper</td>
      <td>bodyPart</td>
      <td>cerebellum</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>Direction</td>
      <td>upper</td>
      <td>bodyPart</td>
      <td>basil ganglia</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>bodyPart</td>
      <td>brain stem</td>
      <td>Direction</td>
      <td>left</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>bodyPart</td>
      <td>brain stem</td>
      <td>Direction</td>
      <td>right</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Direction</td>
      <td>left</td>
      <td>bodyPart</td>
      <td>cerebellum</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>0</td>
      <td>Direction</td>
      <td>left</td>
      <td>bodyPart</td>
      <td>basil ganglia</td>
      <td>0.976</td>
    </tr>
    <tr>
      <td>0</td>
      <td>bodyPart</td>
      <td>cerebellum</td>
      <td>Direction</td>
      <td>right</td>
      <td>0.953</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Direction</td>
      <td>right</td>
      <td>bodyPart</td>
      <td>basil ganglia</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>

<p><strong>- re_bodypart_problem :</strong> Relation Extraction between <code class="language-plaintext highlighter-rouge">Body Part</code> and <code class="language-plaintext highlighter-rouge">Problem</code> entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“No neurologic deficits other than some numbness in his left hand.”</em></p>

<table>
  <thead>
    <tr>
      <th>relation</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Symptom</td>
      <td>neurologic deficits</td>
      <td>bodyPart</td>
      <td>hand</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Symptom</td>
      <td>numbness</td>
      <td>bodyPart</td>
      <td>hand</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<p><strong>- re_bodypart_proceduretest :</strong>  Relation Extraction between <code class="language-plaintext highlighter-rouge">Body Part</code> and <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">Test</code> entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“TECHNIQUE IN DETAIL: After informed consent was obtained from the patient and his mother, the chest was scanned with portable ultrasound.”</em></p>

<table>
  <thead>
    <tr>
      <th>relation</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>bodyPart</td>
      <td>chest</td>
      <td>Test</td>
      <td>portable ultrasound</td>
      <td>0.999</td>
    </tr>
  </tbody>
</table>

<p><strong>-re_date_clinical :</strong> Relation Extraction between <code class="language-plaintext highlighter-rouge">Date</code> and different clinical entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“This 73 y/o patient had CT on 1/12/95, with progressive memory and cognitive decline since 8/11/94.”</em></p>

<table>
  <thead>
    <tr>
      <th>relations</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Test</td>
      <td>CT</td>
      <td>Date</td>
      <td>1/12/95</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Symptom</td>
      <td>progressive memory and cognitive decline</td>
      <td>Date</td>
      <td>8/11/94</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re_model = RelationExtractionModel()\
    .pretrained("re_bodypart_direction","en","clinical/models")\
    .setInputCols(["embeddings", "pos_tags", "ner_chunks", "dependencies"])\
    .setOutputCol("relations")\
    .setMaxSyntacticDistance(4)\
    .setRelationPairs([‘Internal_organ_or_component’, ‘Direction’])
</code></pre></div></div>

<p>For more details: Check out the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.1.Clinical_Relation_Extraction_BodyParts_Models.ipynb">notebook</a> or <a href="https://nlp.johnsnowlabs.com/models?tag=relation_extraction">modelshub</a>.</p>

<p><strong>New matching scheme for entity resolvers - improved accuracy:</strong> Adding the option to use <code class="language-plaintext highlighter-rouge">cosine similarity</code> to resolve entities and find closest matches, resulting in better, more semantically correct results.</p>

<h4 id="7-new-resolver-models-using-jsl-sbert">7. New Resolver Models using <code class="language-plaintext highlighter-rouge">JSL SBERT</code>:</h4>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_augmented</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_procedures_augmented</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented_billable_hcc</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_hcc_augmented</code></p>
  </li>
</ul>

<p><strong>Returning auxilary columns mapped to resolutions:</strong>  Chunk entity resolver and sentence entity resolver now returns auxilary data that is mapped the resolutions during training. This will allow users to get multiple resolutions with single model without using any other annotator in the pipeline (In order to get billable codes otherwise there needs to be other modules in the same pipeline)</p>

<p><strong>Example:</strong></p>

<p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented_billable_hcc</code>
<strong>Input Text:</strong> <em>“bladder cancer”</em></p>

<table>
  <thead>
    <tr>
      <th>idx</th>
      <th>chunks</th>
      <th>code</th>
      <th>resolutions</th>
      <th>all_codes</th>
      <th>billable</th>
      <th>hcc_status</th>
      <th>hcc_score</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>bladder cancer</td>
      <td>C679</td>
      <td>[‘bladder cancer’, ‘suspected bladder cancer’, ‘cancer in situ of urinary bladder’, ‘tumor of bladder neck’, ‘malignant tumour of bladder neck’]</td>
      <td>[‘C679’, ‘Z126’, ‘D090’, ‘D494’, ‘C7911’]</td>
      <td>[‘1’, ‘1’, ‘1’, ‘1’, ‘1’]</td>
      <td>[‘1’, ‘0’, ‘0’, ‘0’, ‘1’]</td>
      <td>[‘11’, ‘0’, ‘0’, ‘0’, ‘8’]</td>
      <td>[‘0.0000’, ‘0.0904’, ‘0.0978’, ‘0.1080’, ‘0.1281’]</td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_augmented</code><br />
<strong>Input Text:</strong> <em>“ct abdomen without contrast”</em></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">idx</th>
      <th style="text-align: right">cpt code</th>
      <th style="text-align: right">distance</th>
      <th style="text-align: left">resolutions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">74150</td>
      <td style="text-align: right">0.0802</td>
      <td style="text-align: left">Computed tomography, abdomen; without contrast material</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">65091</td>
      <td style="text-align: right">0.1312</td>
      <td style="text-align: left">Evisceration of ocular contents; without implant</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">70450</td>
      <td style="text-align: right">0.1323</td>
      <td style="text-align: left">Computed tomography, head or brain; without contrast material</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">74176</td>
      <td style="text-align: right">0.1333</td>
      <td style="text-align: left">Computed tomography, abdomen and pelvis; without contrast material</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">74185</td>
      <td style="text-align: right">0.1343</td>
      <td style="text-align: left">Magnetic resonance imaging without contrast</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: right">77059</td>
      <td style="text-align: right">0.1343</td>
      <td style="text-align: left">Magnetic resonance imaging without contrast</td>
    </tr>
  </tbody>
</table>

<h4 id="8-new-pretrained-clinical-ner-models">8. New Pretrained Clinical NER Models</h4>

<ul>
  <li>NER Radiology
<strong>Input Text:</strong> <em>“Bilateral breast ultrasound was subsequently performed, which demonstrated an ovoid mass measuring approximately 0.5 x 0.5 x 0.4 cm in diameter located within the anteromedial aspect of the left shoulder. This mass demonstrates isoechoic echotexture to the adjacent muscle, with no evidence of internal color flow. This may represent benign fibrous tissue or a lipoma.”</em></li>
</ul>

<table>
  <thead>
    <tr>
      <th>idx</th>
      <th>chunks</th>
      <th>entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Bilateral</td>
      <td>Direction</td>
    </tr>
    <tr>
      <td>1</td>
      <td>breast</td>
      <td>BodyPart</td>
    </tr>
    <tr>
      <td>2</td>
      <td>ultrasound</td>
      <td>ImagingTest</td>
    </tr>
    <tr>
      <td>3</td>
      <td>ovoid mass</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.5 x 0.5 x 0.4</td>
      <td>Measurements</td>
    </tr>
    <tr>
      <td>5</td>
      <td>cm</td>
      <td>Units</td>
    </tr>
    <tr>
      <td>6</td>
      <td>anteromedial aspect</td>
      <td>Direction</td>
    </tr>
    <tr>
      <td>7</td>
      <td>left</td>
      <td>Direction</td>
    </tr>
    <tr>
      <td>8</td>
      <td>shoulder</td>
      <td>BodyPart</td>
    </tr>
    <tr>
      <td>9</td>
      <td>mass</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>10</td>
      <td>isoechoic echotexture</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>11</td>
      <td>muscle</td>
      <td>BodyPart</td>
    </tr>
    <tr>
      <td>12</td>
      <td>internal color flow</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>13</td>
      <td>benign fibrous tissue</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>14</td>
      <td>lipoma</td>
      <td>Disease_Syndrome_Disorder</td>
    </tr>
  </tbody>
</table>

<h3 id="272">2.7.2</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.2 has been released !</p>

<p>In this release, we introduce the following features:</p>

<ul>
  <li>
    <p>Far better accuracy for resolving medication terms to RxNorm codes:</p>

    <p><code class="language-plaintext highlighter-rouge">ondansetron 8 mg tablet' -&gt; '312086</code></p>
  </li>
  <li>
    <p>Far better accuracy for resolving diagnosis terms to ICD-10-CM codes:</p>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">TIA -&gt; transient ischemic attack (disorder)	‘S0690’</code></p>
<ul>
  <li>
    <p>New ability to map medications to pharmacological actions (PA):</p>

    <p><code class="language-plaintext highlighter-rouge">'metformin' -&gt; ‘Hypoglycemic Agents’ </code></p>
  </li>
  <li>
    <p>2 new <em>greedy</em> named entity recognition models for medication details:</p>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">ner_drugs_greedy: ‘magnesium hydroxide 100mg/1ml PO’</code></p>

<p>` ner_posology _greedy: ‘12 units of insulin lispro’ `</p>

<ul>
  <li>New model to <em>classify the gender</em> of a patient in a given medical note:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">'58yo patient with a family history of breast cancer' -&gt; ‘female’ </code></p>
<ul>
  <li>And starting customized spark sessions with rich parameters</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"spark.driver.memory"</span><span class="p">:</span><span class="s">"32G"</span><span class="p">,</span>
        <span class="s">"spark.kryoserializer.buffer.max"</span><span class="p">:</span><span class="s">"2000M"</span><span class="p">,</span>
        <span class="s">"spark.driver.maxResultSize"</span><span class="p">:</span><span class="s">"2000M"</span><span class="p">}</span>

        <span class="n">spark</span> <span class="o">=</span> <span class="n">sparknlp_jsl</span><span class="p">.</span><span class="n">start</span><span class="p">(</span><span class="n">secret</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
</code></pre></div></div>
<p>State-of-the-art accuracy is achieved using new healthcare-tuned BERT Sentence Embeddings (s-Bert). The following sections include more details, metrics, and examples.</p>

<h4 id="named-entity-recognizers-for-medications">Named Entity Recognizers for Medications</h4>

<ul>
  <li>A new medication NER (<code class="language-plaintext highlighter-rouge">ner_drugs_greedy</code>) that joins the drug entities with neighboring entities such as  <code class="language-plaintext highlighter-rouge">dosage</code>, <code class="language-plaintext highlighter-rouge">route</code>, <code class="language-plaintext highlighter-rouge">form</code> and <code class="language-plaintext highlighter-rouge">strength</code>; and returns a single entity <code class="language-plaintext highlighter-rouge">drug</code>.  This greedy NER model would be highly useful if you want to extract a drug with its context and then use it to get a RxNorm code (drugs may get different RxNorm codes based on the dosage and strength information).</li>
</ul>

<h6 id="metrics">Metrics</h6>

<table>
  <thead>
    <tr>
      <th>label</th>
      <th>tp</th>
      <th>fp</th>
      <th>fn</th>
      <th>prec</th>
      <th>rec</th>
      <th>f1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I-DRUG</td>
      <td>37423</td>
      <td>4179</td>
      <td>3773</td>
      <td>0.899</td>
      <td>0.908</td>
      <td>0.904</td>
    </tr>
    <tr>
      <td>B-DRUG</td>
      <td>29699</td>
      <td>2090</td>
      <td>1983</td>
      <td>0.934</td>
      <td>0.937</td>
      <td>0.936</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>A new medication NER (<code class="language-plaintext highlighter-rouge">ner_posology_greedy</code>) that joins the drug entities with neighboring entities such as  <code class="language-plaintext highlighter-rouge">dosage</code>, <code class="language-plaintext highlighter-rouge">route</code>, <code class="language-plaintext highlighter-rouge">form</code> and <code class="language-plaintext highlighter-rouge">strength</code>.  It also returns all the other medication entities even if not related to (or joined with) a drug.</li>
</ul>

<p>Now we have five different medication-related NER models. You can see the outputs from each model below:</p>

<p>Text = ‘‘<em>The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.</em>’’</p>

<p>a. <strong>ner_drugs_greedy</strong></p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>chunks</th>
      <th>begin</th>
      <th>end</th>
      <th>entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1 capsule of Advil 10 mg</td>
      <td>27</td>
      <td>50</td>
      <td>DRUG</td>
    </tr>
    <tr>
      <td>1</td>
      <td>magnesium hydroxide 100mg/1ml PO</td>
      <td>67</td>
      <td>98</td>
      <td>DRUG</td>
    </tr>
    <tr>
      <td>2</td>
      <td>40 units of insulin glargine</td>
      <td>168</td>
      <td>195</td>
      <td>DRUG</td>
    </tr>
    <tr>
      <td>3</td>
      <td>12 units of insulin lispro</td>
      <td>207</td>
      <td>232</td>
      <td>DRUG</td>
    </tr>
  </tbody>
</table>

<p>b. <strong>ner_posology_greedy</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">1 capsule of Advil 10 mg</td>
      <td style="text-align: right">27</td>
      <td style="text-align: right">50</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">magnesium hydroxide 100mg/1ml PO</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">98</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">for 5 days</td>
      <td style="text-align: right">52</td>
      <td style="text-align: right">61</td>
      <td style="text-align: left">DURATION</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">40 units of insulin glargine</td>
      <td style="text-align: right">168</td>
      <td style="text-align: right">195</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">at night</td>
      <td style="text-align: right">197</td>
      <td style="text-align: right">204</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">12 units of insulin lispro</td>
      <td style="text-align: right">207</td>
      <td style="text-align: right">232</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">with meals</td>
      <td style="text-align: right">234</td>
      <td style="text-align: right">243</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">metformin 1000 mg</td>
      <td style="text-align: right">250</td>
      <td style="text-align: right">266</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">two times a day</td>
      <td style="text-align: right">268</td>
      <td style="text-align: right">282</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
  </tbody>
</table>

<p>c. <strong>ner_drugs</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Advil</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">44</td>
      <td style="text-align: left">DrugChem</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">magnesium hydroxide</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">85</td>
      <td style="text-align: left">DrugChem</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">metformin</td>
      <td style="text-align: right">261</td>
      <td style="text-align: right">269</td>
      <td style="text-align: left">DrugChem</td>
    </tr>
  </tbody>
</table>

<p>d.<strong>ner_posology</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">1</td>
      <td style="text-align: right">27</td>
      <td style="text-align: right">27</td>
      <td style="text-align: left">DOSAGE</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">capsule</td>
      <td style="text-align: right">29</td>
      <td style="text-align: right">35</td>
      <td style="text-align: left">FORM</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Advil</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">44</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">10 mg</td>
      <td style="text-align: right">46</td>
      <td style="text-align: right">50</td>
      <td style="text-align: left">STRENGTH</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">for 5 days</td>
      <td style="text-align: right">52</td>
      <td style="text-align: right">61</td>
      <td style="text-align: left">DURATION</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">magnesium hydroxide</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">85</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">100mg/1ml</td>
      <td style="text-align: right">87</td>
      <td style="text-align: right">95</td>
      <td style="text-align: left">STRENGTH</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">PO</td>
      <td style="text-align: right">97</td>
      <td style="text-align: right">98</td>
      <td style="text-align: left">ROUTE</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">40 units</td>
      <td style="text-align: right">168</td>
      <td style="text-align: right">175</td>
      <td style="text-align: left">DOSAGE</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">insulin glargine</td>
      <td style="text-align: right">180</td>
      <td style="text-align: right">195</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: left">at night</td>
      <td style="text-align: right">197</td>
      <td style="text-align: right">204</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: left">12 units</td>
      <td style="text-align: right">207</td>
      <td style="text-align: right">214</td>
      <td style="text-align: left">DOSAGE</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: left">insulin lispro</td>
      <td style="text-align: right">219</td>
      <td style="text-align: right">232</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">13</td>
      <td style="text-align: left">with meals</td>
      <td style="text-align: right">234</td>
      <td style="text-align: right">243</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">14</td>
      <td style="text-align: left">metformin</td>
      <td style="text-align: right">250</td>
      <td style="text-align: right">258</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">15</td>
      <td style="text-align: left">1000 mg</td>
      <td style="text-align: right">260</td>
      <td style="text-align: right">266</td>
      <td style="text-align: left">STRENGTH</td>
    </tr>
    <tr>
      <td style="text-align: right">16</td>
      <td style="text-align: left">two times a day</td>
      <td style="text-align: right">268</td>
      <td style="text-align: right">282</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
  </tbody>
</table>

<p>e. <strong>ner_drugs_large</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Advil 10 mg</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">50</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">magnesium hydroxide 100mg/1ml PO.</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">99</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">insulin glargine</td>
      <td style="text-align: right">180</td>
      <td style="text-align: right">195</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">insulin lispro</td>
      <td style="text-align: right">219</td>
      <td style="text-align: right">232</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">metformin 1000 mg</td>
      <td style="text-align: right">250</td>
      <td style="text-align: right">266</td>
      <td style="text-align: left">DRUG</td>
    </tr>
  </tbody>
</table>

<h4 id="patient-gender-classification">Patient Gender Classification</h4>

<p>This model detects the gender of the patient in the clinical document. It can classify the documents into <code class="language-plaintext highlighter-rouge">Female</code>, <code class="language-plaintext highlighter-rouge">Male</code> and <code class="language-plaintext highlighter-rouge">Unknown</code>.</p>

<p>We release two models:</p>

<ul>
  <li>
    <p>‘Classifierdl_gender_sbert’ (more accurate, works with licensed <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code>)</p>
  </li>
  <li>
    <p>‘Classifierdl_gender_biobert’ (works with <code class="language-plaintext highlighter-rouge">biobert_pubmed_base_cased</code>)</p>
  </li>
</ul>

<p>The models are trained on more than four thousands clinical documents (radiology reports, pathology reports, clinical visits etc.), annotated internally.</p>

<h6 id="metrics-classifierdl_gender_sbert">Metrics <code class="language-plaintext highlighter-rouge">(Classifierdl_gender_sbert)</code></h6>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>precision</th>
      <th>recall</th>
      <th>f1-score</th>
      <th>support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Female</td>
      <td>0.9224</td>
      <td>0.8954</td>
      <td>0.9087</td>
      <td>239</td>
    </tr>
    <tr>
      <td>Male</td>
      <td>0.7895</td>
      <td>0.8468</td>
      <td>0.8171</td>
      <td>124</td>
    </tr>
  </tbody>
</table>

<p>Text= ‘‘<em>social history: shows that  does not smoke cigarettes or drink alcohol, lives in a nursing home.
family history: shows a family history of breast cancer.</em>’’</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gender_classifier</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="p">)[</span><span class="s">'class'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="sb">`Female`</span>
</code></pre></div></div>

<p>See this <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/21_Gender_Classifier.ipynb">Colab</a> notebook for further details.</p>

<p>a. <strong>classifierdl_gender_sbert</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">gender_classifier</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'classifierdl_gender_sbert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">gender_pred_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
       <span class="n">document</span><span class="p">,</span>
       <span class="n">sbert_embedder</span><span class="p">,</span>
       <span class="n">gender_classifier</span>
            <span class="p">])</span>
</code></pre></div></div>
<p>b. <strong>classifierdl_gender_biobert</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">clf_tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="n">biobert_embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'biobert_pubmed_base_cased'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">'token'</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">biobert_embeddings_avg</span> <span class="o">=</span> <span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_bert_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">genderClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'classifierdl_gender_biobert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"sentence_bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"gender"</span><span class="p">)</span>

<span class="n">gender_pred_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
   <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
       <span class="n">documentAssembler</span><span class="p">,</span>
       <span class="n">clf_tokenizer</span><span class="p">,</span>
       <span class="n">biobert_embeddings</span><span class="p">,</span>
       <span class="n">biobert_embeddings_avg</span><span class="p">,</span>
       <span class="n">genderClassifier</span>
   <span class="p">])</span>

</code></pre></div></div>
<h4 id="new-icd10cm-and-rxcui-resolvers-powered-by-s-bert-embeddings">New ICD10CM and RxCUI resolvers powered by s-Bert embeddings</h4>

<p>The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on <a href="https://physionet.org/content/mednli/">MedNLI</a> (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before.</p>

<p>We now release two new resolvers:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented</code> (augmented with synonyms, four times richer than previous resolver accuracy:</p>

    <p><code class="language-plaintext highlighter-rouge">73% for top-1 (exact match), 89% for top-5 (previous accuracy was 59% and 64% respectively)</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxcui</code> (extract RxNorm concept unique identifiers to map with ATC or durg families)
accuracy:</p>

    <p><code class="language-plaintext highlighter-rouge">71% for top-1 (exact match), 72% for top-5
(previous accuracy was 22% and 41% respectively)</code></p>
  </li>
</ul>

<p>a. <strong>ICD10CM augmented resolver</strong></p>

<p>Text = “<em>This is an 82 year old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret's Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .</em> “</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">code</th>
      <th style="text-align: left">term</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">hypertension</td>
      <td style="text-align: right">66</td>
      <td style="text-align: right">77</td>
      <td style="text-align: left">I10</td>
      <td style="text-align: left">hypertension</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">chronic renal insufficiency</td>
      <td style="text-align: right">81</td>
      <td style="text-align: right">107</td>
      <td style="text-align: left">N189</td>
      <td style="text-align: left">chronic renal insufficiency</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">COPD</td>
      <td style="text-align: right">111</td>
      <td style="text-align: right">114</td>
      <td style="text-align: left">J449</td>
      <td style="text-align: left">copd - chronic obstructive pulmonary disease</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">gastritis</td>
      <td style="text-align: right">118</td>
      <td style="text-align: right">126</td>
      <td style="text-align: left">K2970</td>
      <td style="text-align: left">gastritis</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">TIA</td>
      <td style="text-align: right">134</td>
      <td style="text-align: right">136</td>
      <td style="text-align: left">S0690</td>
      <td style="text-align: left">transient ischemic attack (disorder)</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">a non-ST elevation MI</td>
      <td style="text-align: right">180</td>
      <td style="text-align: right">200</td>
      <td style="text-align: left">I219</td>
      <td style="text-align: left">silent myocardial infarction (disorder)</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">Guaiac positive stools</td>
      <td style="text-align: right">206</td>
      <td style="text-align: right">227</td>
      <td style="text-align: left">K921</td>
      <td style="text-align: left">guaiac-positive stools</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">mid LAD lesion</td>
      <td style="text-align: right">330</td>
      <td style="text-align: right">343</td>
      <td style="text-align: left">I2102</td>
      <td style="text-align: left">stemi involving left anterior descending coronary artery</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">hypotension</td>
      <td style="text-align: right">360</td>
      <td style="text-align: right">370</td>
      <td style="text-align: left">I959</td>
      <td style="text-align: left">hypotension</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">bradycardia</td>
      <td style="text-align: right">376</td>
      <td style="text-align: right">386</td>
      <td style="text-align: left">O9941</td>
      <td style="text-align: left">bradycardia</td>
    </tr>
  </tbody>
</table>

<p>b. <strong>RxCUI resolver</strong></p>

<p>Text= “<em>He was seen by the endocrinology service and she was discharged on 50 mg of eltrombopag oral at night, 5 mg amlodipine with meals, and metformin 1000 mg two times a day .</em> “</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: right">code</th>
      <th style="text-align: left">term</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">50 mg of eltrombopag oral</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">91</td>
      <td style="text-align: right">825427</td>
      <td style="text-align: left">eltrombopag 50 MG Oral Tablet</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">5 mg amlodipine</td>
      <td style="text-align: right">103</td>
      <td style="text-align: right">117</td>
      <td style="text-align: right">197361</td>
      <td style="text-align: left">amlodipine 5 MG Oral Tablet</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">metformin 1000 mg</td>
      <td style="text-align: right">135</td>
      <td style="text-align: right">151</td>
      <td style="text-align: right">861004</td>
      <td style="text-align: left">metformin hydrochloride 1000 MG Oral Tablet</td>
    </tr>
  </tbody>
</table>

<p>Using this new resolver and some other resources like Snomed Resolver, RxTerm, MESHPA and ATC dictionary, you can link the drugs to the pharmacological actions (PA), ingredients and the disease treated with that.</p>

<h6 id="code-sample">Code sample:</h6>

<p>(after getting the chunk from ChunkConverter)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">c2doc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="n">icd10_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_icd10cm_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icd10cm_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
</code></pre></div></div>
<p>See the <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb#scrollTo=VtDWAlnDList">notebook</a> for details.</p>

<h3 id="271">2.7.1</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.1 has been released !</p>

<p>In this release, we introduce the following features:</p>

<h4 id="1-sentence-biobert-and-bluebert-transformers-that-are-fine-tuned-on-mednli-dataset">1. Sentence BioBert and Bluebert Transformers that are fine tuned on <a href="https://physionet.org/content/mednli/">MedNLI</a> dataset.</h4>

<p>Sentence Transformers offers a framework that provides an easy method to compute dense vector representations for sentences and paragraphs (also known as sentence embeddings). The models are based on BioBert and BlueBert, and are tuned specifically to meaningful sentence embeddings such that sentences with similar meanings are close in vector space. These are the first PyTorch based models we managed to port into Spark NLP.</p>

<p>Here is how you can load these:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sbiobert_embeddins</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
     <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sbluebert_embeddins</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
     <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbluebert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="2-sentenceentityresolvers-powered-by-s-bert-embeddings">2. SentenceEntityResolvers powered by s-Bert embeddings.</h4>

<p>The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on MedNLI (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before.</p>

<p>Using sbiobert_base_cased_mli, we trained the following Clinical Entity Resolvers:</p>

<p>sbiobertresolve_icd10cm<br />
sbiobertresolve_icd10pcs<br />
sbiobertresolve_snomed_findings (with clinical_findings concepts from CT version)<br />
sbiobertresolve_snomed_findings_int  (with clinical_findings concepts from INT version)<br />
sbiobertresolve_snomed_auxConcepts (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from CT version)<br />
sbiobertresolve_snomed_auxConcepts_int  (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from INT version)<br />
sbiobertresolve_rxnorm<br />
sbiobertresolve_icdo<br />
sbiobertresolve_cpt</p>

<p>Code sample:</p>

<p>(after getting the chunk from ChunkConverter)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">c2doc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>
<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
     <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="n">snomed_ct_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span>
 <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_snomed_findings"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_ct_code"</span><span class="p">)</span>\
 <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
</code></pre></div></div>

<p>Output:</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td>chunks</td>
      <td>begin</td>
      <td>end</td>
      <td>code</td>
      <td>resolutions</td>
    </tr>
    <tr>
      <td>2</td>
      <td>COPD</td>
      <td>113</td>
      <td>116</td>
      <td>13645005</td>
      <td>copd - chronic obstructive pulmonary disease</td>
    </tr>
    <tr>
      <td>8</td>
      <td>PTCA</td>
      <td>324</td>
      <td>327</td>
      <td>373108000</td>
      <td>post percutaneous transluminal coronary angioplasty (finding)</td>
    </tr>
    <tr>
      <td>16</td>
      <td>close monitoring</td>
      <td>519</td>
      <td>534</td>
      <td>417014005</td>
      <td>on examination - vigilance</td>
    </tr>
  </tbody>
</table>

<p>See the <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb#scrollTo=VtDWAlnDList">notebook</a> for details.</p>

<h4 id="3-we-are-releasing-the-following-pretrained-clinical-ner-models">3. We are releasing the following pretrained clinical NER models:</h4>

<p>ner_drugs_large <br />
(trained with medications dataset, and extracts drugs with the dosage, strength, form and route at once as a single entity; entities: drug)<br />
ner_deid_sd_large<br />
(extracts PHI entities, trained with augmented dataset)<br />
ner_anatomy_coarse<br />
(trained with enriched anatomy NER dataset; entities: anatomy)<br />
ner_anatomy_coarse_biobert<br />
chunkresolve_ICD10GM_2021 (German ICD10GM resolver)</p>

<p>We are also releasing two new NER models:</p>

<p>ner_aspect_based_sentiment<br />
(extracts positive, negative and neutral aspects about restaurants from the written feedback given by reviewers. )<br />
ner_financial_contract<br />
(extract financial entities from contracts. See the <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/19.Financial_Contract_NER.ipynb">notebook</a> for details.)</p>

<h3 id="270">2.7.0</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7 has been released !</p>

<p>In this release, we introduce the following features:</p>

<h4 id="1-text2sql">1. Text2SQL</h4>

<p>Text2SQL Annotator that translates natural language text into SQL queries against a predefined database schema, which is one of the
most sought-after features of NLU. With the help of a pretrained text2SQL model, you will be able to query your database without writing a SQL query:</p>

<p>Example 1</p>

<p>Query:
What is the name of the nurse who has the most appointments?</p>

<p>Generated
SQL query from the model:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">T1</span><span class="p">.</span><span class="n">Name</span>  
<span class="k">FROM</span> <span class="n">Nurse</span> <span class="k">AS</span> <span class="n">T1</span>  
<span class="k">JOIN</span> <span class="n">Appointment</span> <span class="k">AS</span> <span class="n">T2</span> <span class="k">ON</span> <span class="n">T1</span><span class="p">.</span><span class="n">EmployeeID</span> <span class="o">=</span> <span class="n">T2</span><span class="p">.</span><span class="n">PrepNurse</span>  
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">T2</span><span class="p">.</span><span class="n">prepnurse</span>  
<span class="k">ORDER</span> <span class="k">BY</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">DESC</span>  
<span class="k">LIMIT</span> <span class="mi">1</span>  
</code></pre></div></div>

<p>Response:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Carla Espinosa</td>
    </tr>
  </tbody>
</table>

<p>Example 2</p>

<p>Query:
How many patients do each physician take care of? List their names and number of patients they take care of.</p>

<p>Generated
SQL query from the model:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">T1</span><span class="p">.</span><span class="n">Name</span><span class="p">,</span>  
<span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>  
<span class="k">FROM</span> <span class="n">Physician</span> <span class="k">AS</span> <span class="n">T1</span>  
<span class="k">JOIN</span> <span class="n">Patient</span> <span class="k">AS</span> <span class="n">T2</span> <span class="k">ON</span> <span class="n">T1</span><span class="p">.</span><span class="n">EmployeeID</span> <span class="o">=</span> <span class="n">T2</span><span class="p">.</span><span class="n">PCP</span>  
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">T1</span><span class="p">.</span><span class="n">Name</span>  
</code></pre></div></div>

<p>Response:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Name</th>
      <th style="text-align: right">count(*)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Christopher Turk</td>
      <td style="text-align: right">1</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Elliot Reid</td>
      <td style="text-align: right">2</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">John Dorian</td>
      <td style="text-align: right">1</td>
    </tr>
  </tbody>
</table>

<p>For now, it only comes with one pretrained model (trained on Spider
dataset) and new pretrained models will be released soon.</p>

<p>Check out the
Colab notebook to  see more examples and run on your data.</p>

<h4 id="2-sentenceentityresolvers">2. SentenceEntityResolvers</h4>

<p>In addition to ChunkEntityResolvers, we now release our first BioBert-based entity resolvers using the SentenceEntityResolver
annotator. It’s
fully trainable and comes with several pretrained entity resolvers for the following medical terminologies:</p>

<p>CPT: <code class="language-plaintext highlighter-rouge">biobertresolve_cpt</code><br />
ICDO: <code class="language-plaintext highlighter-rouge">biobertresolve_icdo</code><br />
ICD10CM: <code class="language-plaintext highlighter-rouge">biobertresolve_icd10cm</code><br />
ICD10PCS: <code class="language-plaintext highlighter-rouge">biobertresolve_icd10pcs</code><br />
LOINC: <code class="language-plaintext highlighter-rouge">biobertresolve_loinc</code><br />
SNOMED_CT (findings): <code class="language-plaintext highlighter-rouge">biobertresolve_snomed_findings</code><br />
SNOMED_INT (clinical_findings): <code class="language-plaintext highlighter-rouge">biobertresolve_snomed_findings_int</code>  <br />
RXNORM (branded and clinical drugs): <code class="language-plaintext highlighter-rouge">biobertresolve_rxnorm_bdcd</code></p>

<p>Example:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="s">'He has a starvation ketosis but nothing significant for dry oral mucosa'</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">get_icd10_codes</span> <span class="p">(</span><span class="n">light_pipeline_icd10</span><span class="p">,</span> <span class="s">'icd10cm_code'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">a starvation ketosis</td>
      <td style="text-align: right">7</td>
      <td style="text-align: right">26</td>
      <td style="text-align: left">E71121</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">dry oral mucosa</td>
      <td style="text-align: right">66</td>
      <td style="text-align: right">80</td>
      <td style="text-align: left">K136</td>
    </tr>
  </tbody>
</table>

<p>Check out the Colab notebook to  see more examples and run on your data.</p>

<p>You can also train your own entity resolver using any medical terminology like MedRa and UMLS. Check this notebook to
learn more about training from scratch.</p>

<h4 id="3-chunkmerge-annotator">3. ChunkMerge Annotator</h4>

<p>In order to use multiple NER models in the same pipeline, Spark NLP Healthcare has ChunkMerge Annotator that is used to return entities from each NER
model by overlapping. Now it has a new parameter to avoid merging overlapping entities (setMergeOverlapping)
to return all the entities regardless of char indices. It will be quite useful to analyze what every NER module returns on the same text.</p>

<h4 id="4-starting-sparksession">4. Starting SparkSession</h4>

<p>We now support starting SparkSession with a different version of the open source jar and not only the one it was built
against by <code class="language-plaintext highlighter-rouge">sparknlp_jsl.start(secret, public="x.x.x")</code> for extreme cases.</p>

<h4 id="5-biomedical-ners">5. Biomedical NERs</h4>

<p>We are releasing 3 new biomedical NER models trained with clinical embeddings (all one single entity models)</p>

<p><code class="language-plaintext highlighter-rouge">ner_bacterial_species</code> (comprising of Linneaus and Species800 datasets)<br />
<code class="language-plaintext highlighter-rouge">ner_chemicals</code> (general purpose and bio chemicals, comprising of BC4Chem and BN5CDR-Chem)<br />
<code class="language-plaintext highlighter-rouge">ner_diseases_large</code> (comprising of ner_disease, NCBI_Disease and BN5CDR-Disease)</p>

<p>We are also releasing the biobert versions of the several clinical NER models stated below:<br />
<code class="language-plaintext highlighter-rouge">ner_clinical_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_anatomy_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_bionlp_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_cellular_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_deid_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_diseases_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_events_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_jsl_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_chemprot_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_human_phenotype_gene_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_human_phenotype_go_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_posology_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_risk_factors_biobert</code></p>

<p>Metrics (micro averages excluding O’s):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">model_name</th>
      <th style="text-align: right">clinical_glove_micro</th>
      <th style="text-align: right">biobert_micro</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">ner_chemprot_clinical</td>
      <td style="text-align: right">0.816</td>
      <td style="text-align: right">0.803</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">ner_bionlp</td>
      <td style="text-align: right">0.748</td>
      <td style="text-align: right">0.808</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">ner_deid_enriched</td>
      <td style="text-align: right">0.934</td>
      <td style="text-align: right">0.918</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">ner_posology</td>
      <td style="text-align: right">0.915</td>
      <td style="text-align: right">0.911</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">ner_events_clinical</td>
      <td style="text-align: right">0.801</td>
      <td style="text-align: right">0.809</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">ner_clinical</td>
      <td style="text-align: right">0.873</td>
      <td style="text-align: right">0.884</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">ner_posology_small</td>
      <td style="text-align: right">0.941</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">ner_human_phenotype_go_clinical</td>
      <td style="text-align: right">0.922</td>
      <td style="text-align: right">0.932</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">ner_drugs</td>
      <td style="text-align: right">0.964</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">ner_human_phenotype_gene_clinical</td>
      <td style="text-align: right">0.876</td>
      <td style="text-align: right">0.870</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: left">ner_risk_factors</td>
      <td style="text-align: right">0.728</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: left">ner_cellular</td>
      <td style="text-align: right">0.813</td>
      <td style="text-align: right">0.812</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: left">ner_posology_large</td>
      <td style="text-align: right">0.921</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">13</td>
      <td style="text-align: left">ner_anatomy</td>
      <td style="text-align: right">0.851</td>
      <td style="text-align: right">0.831</td>
    </tr>
    <tr>
      <td style="text-align: right">14</td>
      <td style="text-align: left">ner_deid_large</td>
      <td style="text-align: right">0.942</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">15</td>
      <td style="text-align: left">ner_diseases</td>
      <td style="text-align: right">0.960</td>
      <td style="text-align: right">0.966</td>
    </tr>
  </tbody>
</table>

<p>In addition to these, we release two new German NER models:</p>

<p><code class="language-plaintext highlighter-rouge">ner_healthcare_slim</code> (‘TIME_INFORMATION’, ‘MEDICAL_CONDITION’,  ‘BODY_PART’,  ‘TREATMENT’, ‘PERSON’, ‘BODY_PART’)<br />
<code class="language-plaintext highlighter-rouge">ner_traffic</code> (extract entities regarding traffic accidents e.g. date, trigger, location etc.)</p>

<h4 id="6-pico-classifier">6. PICO Classifier</h4>

<p>Successful evidence-based medicine (EBM) applications rely on answering clinical questions by analyzing large medical literature databases. In order to formulate
a well-defined, focused clinical question, a framework called PICO is widely used, which identifies the sentences in a given medical text that belong to the four components: Participants/Problem (P)  (e.g., diabetic patients), Intervention (I) (e.g., insulin),
Comparison (C) (e.g., placebo)  and Outcome (O) (e.g., blood glucose levels).</p>

<p>Spark NLP now introduces a pretrained PICO Classifier that
is trained with Biobert embeddings.</p>

<p>Example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="err">“</span><span class="n">There</span> <span class="n">appears</span> <span class="n">to</span> <span class="n">be</span> <span class="n">no</span> <span class="n">difference</span> <span class="ow">in</span> <span class="n">smoking</span> <span class="n">cessation</span> <span class="n">effectiveness</span> <span class="n">between</span> <span class="mi">1</span><span class="n">mg</span> <span class="ow">and</span> <span class="mf">0.5</span><span class="n">mg</span> <span class="n">varenicline</span><span class="p">.</span><span class="err">”</span>
<span class="n">pico_lp_pipeline</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="p">)[</span><span class="s">'class'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ans</span><span class="p">:</span> <span class="n">CONCLUSIONS</span>
</code></pre></div></div>

<h3 id="262">2.6.2</h3>

<h4 id="overview">Overview</h4>
<p>We are very happy to announce that version 2.6.2 of Spark NLP Enterprise is ready to be installed and used.
We are making available Named Entity Recognition, Sentence Classification and Entity Resolution models to analyze Adverse Drug Events in natural language text from clinical domains.</p>

<h4 id="models">Models</h4>

<h5 id="ners">NERs</h5>
<p>We are pleased to announce that we have a brand new named entity recognition (NER) model for Adverse Drug Events (ADE) to extract ADE and DRUG entities from a given text.</p>

<p>ADE NER will have four versions in the library, trained with different size of word embeddings:</p>

<p><code class="language-plaintext highlighter-rouge">ner_ade_bioert</code> (768d Bert embeddings)<br />
<code class="language-plaintext highlighter-rouge">ner_ade_clinicalbert</code> (768d Bert embeddings)<br />
<code class="language-plaintext highlighter-rouge">ner_ade_clinical</code> (200d clinical embeddings)<br />
<code class="language-plaintext highlighter-rouge">ner_ade_healthcare</code> (100d healthcare embeddings)</p>

<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/16.Adverse_Drug_Event_ADE_NER_and_Classifier.ipynb">here</a></p>

<p>We are also releasing our first clinical pretrained classifier for ADE classification tasks. This new ADE classifier is trained on various ADE datasets, including the mentions in tweets to represent the daily life conversations as well. So it works well on the texts coming from academic context, social media and clinical notes. It’s trained with <code class="language-plaintext highlighter-rouge">Clinical Biobert</code> embeddings, which is the most powerful contextual language model in the clinical domain out there.</p>

<h5 id="classifiers">Classifiers</h5>
<p>ADE classifier will have two versions in the library, trained with different Bert embeddings:</p>

<p><code class="language-plaintext highlighter-rouge">classifierdl_ade_bioert</code> (768d BioBert embeddings)<br />
<code class="language-plaintext highlighter-rouge">classifierdl_adee_clinicalbert</code> (768d ClinicalBert embeddings)</p>

<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/16.Adverse_Drug_Event_ADE_NER_and_Classifier.ipynb">here</a></p>

<h5 id="pipeline">Pipeline</h5>
<p>By combining ADE NER and Classifier, we are releasing a new pretrained clinical pipeline for ADE tasks to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">'explain_clinical_doc_ade'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>

<span class="n">pipeline</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'my string'</span><span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">explain_clinical_doc_ade</code> is bundled with <code class="language-plaintext highlighter-rouge">ner_ade_clinicalBert</code>, and <code class="language-plaintext highlighter-rouge">classifierdl_ade_clinicalBert</code>. It can extract ADE and DRUG clinical entities, and then assign ADE status to a text (<code class="language-plaintext highlighter-rouge">True</code> means ADE, <code class="language-plaintext highlighter-rouge">False</code> means not related to ADE).</p>

<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb">here</a></p>

<h5 id="entity-resolver">Entity Resolver</h5>
<p>We are releasing the first Entity Resolver for <code class="language-plaintext highlighter-rouge">Athena</code> (Automated Terminology Harmonization, Extraction and Normalization for Analytics, http://athena.ohdsi.org/) to extract concept ids via standardized medical vocabularies. For now, it only supports <code class="language-plaintext highlighter-rouge">conditions</code> section and can be used to map the clinical conditions with the corresponding standard terminology and then get the concept ids to store them in various database schemas.
It is named as <code class="language-plaintext highlighter-rouge">chunkresolve_athena_conditions_healthcare</code>.</p>

<p>We added slim versions of several clinical NER models that are trained with 100d healthcare word embeddings, which is lighter and smaller in size.</p>

<p><code class="language-plaintext highlighter-rouge">ner_healthcare</code>
<code class="language-plaintext highlighter-rouge">assertion_dl_healthcare</code>
<code class="language-plaintext highlighter-rouge">ner_posology_healthcare</code>
<code class="language-plaintext highlighter-rouge">ner_events_healthcare</code></p>

<h5 id="graph-builder">Graph Builder</h5>
<p>Spark NLP Licensed version has several DL based annotators (modules) such as NerDL, AssertionDL, RelationExtraction and GenericClassifier, and they are all based on Tensorflow (tf) with custom graphs. In order to make the creating and customizing the tf graphs for these models easier for our licensed users, we added a graph builder to the Python side of the library. Now you can customize your graphs and use them in the respected models while training a new DL model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp_jsl.training</span> <span class="kn">import</span> <span class="n">tf_graph</span>

<span class="n">tf_graph</span><span class="p">.</span><span class="n">build</span><span class="p">(</span><span class="s">"relation_extraction"</span><span class="p">,</span><span class="n">build_params</span><span class="o">=</span><span class="p">{</span><span class="s">"input_dim"</span><span class="p">:</span> <span class="mi">6000</span><span class="p">,</span> <span class="s">"output_dim"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'batch_norm'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"hidden_layers"</span><span class="p">:</span> <span class="p">[</span><span class="mi">300</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s">"hidden_act"</span><span class="p">:</span> <span class="s">"relu"</span><span class="p">,</span> <span class="s">'hidden_act_l2'</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">model_location</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">model_filename</span><span class="o">=</span><span class="s">"re_with_BN"</span><span class="p">)</span>
</code></pre></div></div>
<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb">here</a></p>

<h3 id="260">2.6.0</h3>

<h4 id="overview-1">Overview</h4>

<p>We are honored to announce that Spark NLP Enterprise 2.6.0 has been released.
The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases.
The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="models-1">Models</h4>

<h5 id="pretrained-pipelines">Pretrained Pipelines:</h5>

<p>The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch.
Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">'explain_clinical_doc_carp'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>

<span class="n">pipeline</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'my string'</span><span class="p">)</span>
</code></pre></div></div>

<p>Pipeline descriptions:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">explain_clinical_doc_carp</code> a pipeline with ner_clinical, assertion_dl, re_clinical and ner_posology. It will extract clinical and medication entities, assign assertion status and find relationships between clinical entities.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">explain_clinical_doc_era</code> a pipeline with ner_clinical_events, assertion_dl and re_temporal_events_clinical. It will extract clinical entities, assign assertion status and find temporal relationships between clinical entities.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">recognize_entities_posology</code> a pipeline with ner_posology. It will only extract medication entities.</p>
  </li>
</ul>

<p>More information and examples are available here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="pretrained-named-entity-recognition-and-relationship-extraction-models-english">Pretrained Named Entity Recognition and Relationship Extraction Models (English)</h4>

<p>RE models:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re_temporal_events_clinical
re_temporal_events_enriched_clinical
re_human_phenotype_gene_clinical
re_drug_drug_interaction_clinical
re_chemprot_clinical
</code></pre></div></div>
<p>NER models:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_human_phenotype_gene_clinical
ner_human_phenotype_go_clinical
ner_chemprot_clinical
</code></pre></div></div>
<p>More information and examples here:
https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="pretrained-named-entity-recognition-and-relationship-extraction-models-german">Pretrained Named Entity Recognition and Relationship Extraction Models (German)</h4>

<p>The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">German Clinical NER</code> model for 19 clinical entities</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">German Legal NER</code> model for 19 legal entities</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">German ICD-10GM</code></p>
  </li>
</ul>

<p>More information and examples here:</p>

<p>https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/14.German_Healthcare_Models.ipynb</p>

<p>https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/15.German_Legal_Model.ipynb</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="other-pretrained-models">Other Pretrained Models</h4>

<p>We now have Named Entity Disambiguation model out of the box.</p>

<p>Disambiguation models map words of interest, such as names of persons, locations and companies, from an input text document to corresponding unique entities in a target Knowledge Base (KB).</p>

<p>https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/12.Named_Entity_Disambiguation.ipynb</p>

<p>Due to ongoing requests about Clinical Entity Resolvers, we release a notebook to let you see how to train an entity resolver using an open source dataset based on Snomed.</p>

<p>https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="255">2.5.5</h3>

<h4 id="overview-2">Overview</h4>

<p>We are very happy to release Spark NLP for Healthcare 2.5.5 with a new state-of-the-art RelationExtraction annotator to identify relationships between entities coming from our pretrained NER models.
This is also the first release to support Relation Extraction with the following two (2) models: <code class="language-plaintext highlighter-rouge">re_clinical</code> and <code class="language-plaintext highlighter-rouge">re_posology</code> in the <code class="language-plaintext highlighter-rouge">clinical/models</code> repository.
We also include multiple bug fixes as usual.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-2">New Features</h4>

<ul>
  <li>RelationExtraction annotator that receives <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code>, <code class="language-plaintext highlighter-rouge">POS</code>, <code class="language-plaintext highlighter-rouge">CHUNK</code>, <code class="language-plaintext highlighter-rouge">DEPENDENCY</code> and returns the CATEGORY of the relationship and a confidence score.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements">Enhancements</h4>

<ul>
  <li>AssertionDL Annotator now keeps logs of the metrics while training</li>
  <li>DeIdentification now has a default behavior of merging entities close in Levenshtein distance with <code class="language-plaintext highlighter-rouge">setConsistentObfuscation</code> and <code class="language-plaintext highlighter-rouge">setSameEntityThreshold</code> params.</li>
  <li>DeIdentification now has a specific parameter <code class="language-plaintext highlighter-rouge">setObfuscateDate</code> to obfuscate dates (which will be otherwise just masked). The only formats obfuscated when the param is true will be the ones present in <code class="language-plaintext highlighter-rouge">dateFormats</code> param.</li>
  <li>NerConverterInternal now has a <code class="language-plaintext highlighter-rouge">greedyMode</code> param that will merge all contiguous tags of the same type regardless of boundary tags like “B”,”E”,”S”.</li>
  <li>AnnotationToolJsonReader includes <code class="language-plaintext highlighter-rouge">mergeOverlapping</code> parameter to merge (or not) overlapping entities from the Annotator jsons i.e. not included in the assertion list.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes">Bugfixes</h4>

<ul>
  <li>DeIdentification documentation bug fix (typo)</li>
  <li>DeIdentification training bug fix in obfuscation dictionary</li>
  <li>IOBTagger now has the correct output type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="deprecations">Deprecations</h4>

<ul>
  <li>EnsembleEntityResolver has been deprecated</li>
</ul>

<p>Models</p>

<ul>
  <li>We have 2 new <code class="language-plaintext highlighter-rouge">english</code> Relationship Extraction model for Clinical and Posology NERs:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">re_clinical</code>: with <code class="language-plaintext highlighter-rouge">ner_clinical</code> and <code class="language-plaintext highlighter-rouge">embeddings_clinical</code></li>
      <li><code class="language-plaintext highlighter-rouge">re_posology</code>: with <code class="language-plaintext highlighter-rouge">ner_posology</code> and <code class="language-plaintext highlighter-rouge">embeddings_clinical</code></li>
    </ul>
  </li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="253">2.5.3</h3>

<h4 id="overview-3">Overview</h4>

<p>We are pleased to announce the release of Spark NLP for Healthcare 2.5.3.
This time we include four (4) new Annotators: FeatureAssembler, GenericClassifier, Yake Keyword Extractor and NerConverterInternal.
We also include helper classes to read datasets from CodiEsp and Cantemist Spanish NER Challenges.
This is also the first release to support the following models: <code class="language-plaintext highlighter-rouge">ner_diag_proc</code> (spanish), <code class="language-plaintext highlighter-rouge">ner_neoplasms</code> (spanish), <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> (english).
We have also included Bugifxes and Enhancements for AnnotationToolJsonReader and ChunkMergeModel.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-3">New Features</h4>

<ul>
  <li>FeatureAssembler Transformer: Receives a list of column names containing numerical arrays and concatenates them to form one single <code class="language-plaintext highlighter-rouge">feature_vector</code> annotation</li>
  <li>GenericClassifier Annotator: Receives a <code class="language-plaintext highlighter-rouge">feature_vector</code> annotation and outputs a <code class="language-plaintext highlighter-rouge">category</code> annotation</li>
  <li>Yake Keyword Extraction Annotator: Receives a <code class="language-plaintext highlighter-rouge">token</code> annotation and outputs multi-token <code class="language-plaintext highlighter-rouge">keyword</code> annotations</li>
  <li>NerConverterInternal Annotator: Similar to it’s open source counterpart in functionality, performs smarter extraction for complex tokenizations and confidence calculation</li>
  <li>Readers for CodiEsp and Cantemist Challenges</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-1">Enhancements</h4>

<ul>
  <li>AnnotationToolJsonReader includes parameter for preprocessing pipeline (from Document Assembling to Tokenization)</li>
  <li>AnnotationToolJsonReader includes parameter to discard specific entity types</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-1">Bugfixes</h4>

<ul>
  <li>ChunkMergeModel now prioritizes highest number of different entities when coverage is the same</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="models-2">Models</h4>

<ul>
  <li>We have 2 new <code class="language-plaintext highlighter-rouge">spanish</code> models for Clinical Entity Recognition: <code class="language-plaintext highlighter-rouge">ner_diag_proc</code> and <code class="language-plaintext highlighter-rouge">ner_neoplasms</code></li>
  <li>We have a new <code class="language-plaintext highlighter-rouge">english</code> Named Entity Recognition model for deidentification: <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code></li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="252">2.5.2</h3>

<h4 id="overview-4">Overview</h4>

<p>We are really happy to bring you Spark NLP for Healthcare 2.5.2, with a couple new features and several enhancements in our existing annotators.
This release was mainly dedicated to generate adoption in our AnnotationToolJsonReader, a connector that provide out-of-the-box support for out Annotation Tool and our practices.
Also the ChunkMerge annotator has ben provided with extra functionality to remove entire entity types and to modify some chunk’s entity type
We also dedicated some time in finalizing some refactorization in DeIdentification annotator, mainly improving type consistency and case insensitive entity dictionary for obfuscation.
Thanks to the community for all the feedback and suggestions, it’s really comfortable to navigate together towards common functional goals that keep us agile in the SotA.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-4">New Features</h4>

<ul>
  <li>Brand new IOBTagger Annotator</li>
  <li>NerDL Metrics provides an intuitive DataFrame API to calculate NER metrics at tag (token) and entity (chunk) level</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-2">Enhancements</h4>

<ul>
  <li>AnnotationToolJsonReader includes parameters for document cleanup, sentence boundaries and tokenizer split chars</li>
  <li>AnnotationToolJsonReader uses the task title if present and uses IOBTagger annotator</li>
  <li>AnnotationToolJsonReader has improved alignment in assertion train set generation by using an <code class="language-plaintext highlighter-rouge">alignTol</code> parameter as tollerance in chunk char alignment</li>
  <li>DeIdentification refactorization: Improved typing and replacement logic, case insensitive entities for obfuscation</li>
  <li>ChunkMerge Annotator now handles:</li>
  <li>Drop all chunks for an entity</li>
  <li>Replace entity name</li>
  <li>Change entity type for a specific (chunk, entity) pair</li>
  <li>Drop specific (chunk, entity) pairs</li>
  <li><code class="language-plaintext highlighter-rouge">caseSensitive</code> param to EnsembleEntityResolver</li>
  <li>Output logs for AssertionDLApproach loss</li>
  <li>Disambiguator is back with improved dependency management</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-2">Bugfixes</h4>

<ul>
  <li>Bugfix in python when Annotators shared domain parts across public and internal</li>
  <li>Bugfix in python when ChunkMerge annotator was loaded from disk</li>
  <li>ChunkMerge now weights the token coverage correctly when multiple multi-token entities overlap</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="250">2.5.0</h3>

<h4 id="overview-5">Overview</h4>

<p>We are happy to bring you Spark NLP for Healthcare 2.5.0 with new Annotators, Models and Data Readers.
Model composition and iteration is now faster with readers and annotators designed for real world tasks.
We introduce ChunkMerge annotator to combine all CHUNKS extracted by different Entity Extraction Annotators.
We also introduce an Annotation Reader for JSL AI Platform’s Annotation Tool.
This release is also the first one to support the models: <code class="language-plaintext highlighter-rouge">ner_large_clinical</code>, <code class="language-plaintext highlighter-rouge">ner_events_clinical</code>, <code class="language-plaintext highlighter-rouge">assertion_dl_large</code>, <code class="language-plaintext highlighter-rouge">chunkresolve_loinc_clinical</code>, <code class="language-plaintext highlighter-rouge">deidentify_large</code>
And of course we have fixed some bugs.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-5">New Features</h4>

<ul>
  <li>AnnotationToolJsonReader is a new class that imports a JSON from AI Platform’s Annotation Tool an generates NER and Assertion training datasets</li>
  <li>ChunkMerge Annotator is a new functionality that merges two columns of CHUNKs handling overlaps with a very straightforward logic: max coverage, max # entities</li>
  <li>ChunkMerge Annotator handles inputs from NerDLModel, RegexMatcher, ContextualParser, TextMatcher</li>
  <li>A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-3">Enhancements</h4>

<ul>
  <li>DeIdentification Annotator has a more consistent API:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">mode</code> param with values (‘mask’l’obfuscate’) to drive its behavior</li>
      <li><code class="language-plaintext highlighter-rouge">dateFormats</code> param a list of string values to to select which <code class="language-plaintext highlighter-rouge">dateFormats</code> to obfuscate (and which to just mask)</li>
    </ul>
  </li>
  <li>DeIdentification Annotator no longer automatically obfuscates dates. Obfuscation is now driven by <code class="language-plaintext highlighter-rouge">mode</code> and <code class="language-plaintext highlighter-rouge">dateFormats</code> params</li>
  <li>A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-3">Bugfixes</h4>

<ul>
  <li>DeIdentification Annotator now correctly deduplicates protected entities coming from NER / Regex</li>
  <li>DeIdentification Annotator now indexes chunks correctly after merging them</li>
  <li>AssertionDLApproach Annotator can now be trained with the graph in any folder specified by setting <code class="language-plaintext highlighter-rouge">graphFolder</code> param</li>
  <li>AssertionDLApproach now has the <code class="language-plaintext highlighter-rouge">setClasses</code> param setter in Python wrapper</li>
  <li>JVM Memory and Kryo Max Buffer size increased to 32G and 2000M respectively in <code class="language-plaintext highlighter-rouge">sparknlp_jsl.start(secret)</code> function</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="246">2.4.6</h3>

<h4 id="overview-6">Overview</h4>

<p>We release Spark NLP for Healthcare 2.4.6 to fix some minor bugs.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-4">Bugfixes</h4>

<ul>
  <li>Updated IDF value calculation to be probabilistic based log[(N - df_t) / df_t + 1] as opposed to log[N / df_t]</li>
  <li>TFIDF cosine distance was being calculated with the rooted norms rather than with the original squared norms</li>
  <li>Validation of label cols is now performed at the beginning of EnsembleEntityResolver</li>
  <li>Environment Variable for License value named jsl.settings.license</li>
  <li>Now DocumentLogRegClassifier can be serialized from Python (bug introduced with the implementation of RecursivePipelines, LazyAnnotator attribute)</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="245">2.4.5</h3>

<h4 id="overview-7">Overview</h4>

<p>We are glad to announce Spark NLP for Healthcare 2.4.5. As a new feature we are happy to introduce our new EnsembleEntityResolver which allows our Entity Resolution architecture to scale up in multiple orders of magnitude and handle datasets of millions of records on a sub-log computation increase
We also enhanced our ChunkEntityResolverModel with 5 new distance calculations with weighting-array and aggregation-strategy params that results in more levers to finetune its performance against a given dataset.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-6">New Features</h4>

<ul>
  <li>EnsembleEntityResolver consisting of an integrated TFIDF-Logreg classifier in the first layer + Multiple ChunkEntityResolvers in the second layer (one per each class)</li>
  <li>Five (5) new distances calculations for ChunkEntityResolver, namely:
    <ul>
      <li>Token Based: TFIDF-Cosine, Jaccard, SorensenDice</li>
      <li>Character Based: JaroWinkler and Levenshtein</li>
    </ul>
  </li>
  <li>Weight parameter that works as a multiplier for each distance result to be considered during their aggregation</li>
  <li>Three (3) aggregation strategies for the enabled distance in a particular instance, namely: AVERAGE, MAX and MIN</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-4">Enhancements</h4>

<ul>
  <li>ChunkEntityResolver can now compute distances over all the <code class="language-plaintext highlighter-rouge">neighbours</code> found and return the metadata just for the best <code class="language-plaintext highlighter-rouge">alternatives</code> that meet the <code class="language-plaintext highlighter-rouge">threshold</code>;
before it would calculate them over the neighbours and return them all in the metadata</li>
  <li>ChunkEntityResolver now has an <code class="language-plaintext highlighter-rouge">extramassPenalty</code> parameter to accoun for penalization of token-length difference in compared strings</li>
  <li>Metadata for the ChunkEntityResolver has been updated accordingly to reflect all new features</li>
  <li>StringDistances class has been included in utils to aid in the calculation and organization of different types of distances for Strings</li>
  <li>HasFeaturesJsl trait has been included to support the serialization of Features including [T] &lt;: AnnotatorModel[T] types</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-5">Bugfixes</h4>

<ul>
  <li>Frequency calculation for WMD in ChunkEntityResolver has been adjusted to account for real word count representation</li>
  <li>AnnotatorType for DocumentLogRegClassifier has been changed to CATEGORY to align with classifiers in Open Source library</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="deprecations-1">Deprecations</h4>

<ul>
  <li>Legacy EntityResolver{Approach, Model} classes have been deprecated in favor of ChunkEntityResolver classes</li>
  <li>ChunkEntityResolverSelector classes has been deprecated in favor of EnsembleEntityResolver</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="242">2.4.2</h3>

<h4 id="overview-8">Overview</h4>

<p>We are glad to announce Spark NLP for Healthcare 2.4.2. As a new feature we are happy to introduce our new Disambiguation Annotator,
which will let the users resolve different kind of entities based on Knowledge bases provided in the form of Records in a RocksDB database.
We also enhanced / fixed DocumentLogRegClassifier, ChunkEntityResolverModel and ChunkEntityResolverSelector Annotators.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-7">New Features</h4>

<ul>
  <li>Disambiguation Annotator (NerDisambiguator and NerDisambiguatorModel) which accepts annotator types CHUNK and SENTENCE_EMBEDDINGS and
returns DISAMBIGUATION annotator type. This output annotation type includes all the matches in the result and their similarity scores in the metadata.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-5">Enhancements</h4>

<ul>
  <li>ChunkEntityResolver Annotator now supports both EUCLIDEAN and COSINE distance for the KNN search and WMD calculation.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-6">Bugfixes</h4>

<ul>
  <li>Fixed a bug in DocumentLogRegClassifier Annotator to support its serialization to disk.</li>
  <li>Fixed a bug in ChunkEntityResolverSelector Annotator to group by both SENTENCE and CHUNK at the time of forwarding tokens and embeddings to the lazy annotators.</li>
  <li>Fixed a bug in ChunkEntityResolverModel in which the same exact embeddings was not included in the neighbours.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="241">2.4.1</h3>

<h4 id="overview-9">Overview</h4>

<p>Introducing Spark NLP for Healthcare 2.4.1 after all the feedback we received in the form of issues and suggestions on our different communication channels.
Even though 2.4.0 was very stable, version 2.4.1 is here to address minor bug fixes that we summarize in the following lines.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-7">Bugfixes</h4>

<ul>
  <li>Changing the license Spark property key to be “jsl” instead of “sparkjsl” as the latter generates inconsistencies</li>
  <li>Fix the alignment logic for tokens and chunks in the ChunkEntityResolverSelector because when tokens and chunks did not have the same begin-end indexes the resolution was not executed</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="240">2.4.0</h3>

<h4 id="overview-10">Overview</h4>

<p>We are glad to announce Spark NLP for Healthcare 2.4.0. This is an important release because of several refactorizations achieved in the core library, plus the introduction of several state of the art algorithms, new features and enhancements.
We have included several architecture and performance improvements, that aim towards making the library more robust in terms of storage handling for Big Data.
In the NLP aspect, we have introduced a ContextualParser, DocumentLogRegClassifier and a ChunkEntityResolverSelector.
These last two Annotators also target performance time and memory consumption by lowering the order of computation and data loaded to memory in each step when designed following a hierarchical pattern.
We have put a big effort on this one, so please enjoy and share your comments. Your words are always welcome through all our different channels.
Thank you very much for your important doubts, bug reports and feedback; they are always welcome and much appreciated.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-8">New Features</h4>

<ul>
  <li>BigChunkEntityResolver Annotator: New experimental approach to reduce memory consumption at expense of disk IO.</li>
  <li>ContextualParser Annotator: New entity parser that works based on context parameters defined in a JSON file.</li>
  <li>ChunkEntityResolverSelector Annotator: New AnnotatorModel that takes advantage of the RecursivePipelineModel + LazyAnnotator pattern to annotate with different LazyAnnotators at runtime.</li>
  <li>DocumentLogregClassifier Annotator: New Annotator that provides a wrapped TFIDF Vectorizer + LogReg Classifier for TOKEN AnnotatorTypes (either at Document level or Chunk level)</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-6">Enhancements</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">normalizedColumn</code> Param is no longer required in ChunkEntityResolver Annotator (defaults to the <code class="language-plaintext highlighter-rouge">labelCol</code> Param value).</li>
  <li>ChunkEntityResolverMetadata now has more data to infer whether the match is meaningful or not.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-8">Bugfixes</h4>

<ul>
  <li>Fixed a bug on ContextSpellChecker Annotator where unrecognized tokens would cause an exception if not in vocabulary.</li>
  <li>Fixed a bug on ChunkEntityResolver Annotator where undetermined results were coming out of negligible confidence scores for matches.</li>
  <li>Fixed a bug on ChunkEntityResolver Annotator where search would fail if the <code class="language-plaintext highlighter-rouge">neighbours</code> Param was grater than the number of nodes in the tree. Now it returns up to the number of nodes in the tree.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="deprecations-2">Deprecations</h4>

<ul>
  <li>OCR Moves to its own JSL Spark OCR project.</li>
</ul>

<p>&lt;/div&gt;</p>

<h4 id="infrastructure">Infrastructure</h4>

<ul>
  <li>Spark NLP License is now required to utilize the library. Please follow the instructions on the shared email.</li>
</ul>
</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2021-07-14T00:00:00+00:00">Jul 14, 2021</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>


jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
});

function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show() 
    $( ".tabs-box .nlu-block" ).hide()
    $( ".tabs-box .language-scala" ).hide()
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method) }, 15);
    }
}

defer(function () { // load inital language
    togglePython1()
});




</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/licensed_version_compatibility">Version Compatibility</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/benchmark">Cluster Speed Benchmarks</a></div></div></div>

</div>
</div>

<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();
</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© 2022 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demopage-sidemenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*TABS*/
function openTabCall(cityName){
  // Declare all variables
  var i, tabcontent, tablinks;

  // Get all elements with class="tabcontent" and hide them
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }

  // Get all elements with class="tablinks" and remove the class "active"
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }

  // Show the current tab, and add an "active" class to the button that opened the tab
  document.getElementById(cityName).style.display = "block";
}

function openTab(evt, cityName) {
  openTabCall(cityName);
  evt.currentTarget.className += " active";
}

/*OPen by URL*/
$(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

jQuery(document).ready(function(){
	jQuery('.tab-item').click(function(event) {		
		if (($(window).width() > 400) && ($(window).width() < 1199))
	    {
	    	jQuery('.tab-item').removeClass('open');
	        jQuery(this).toggleClass('open');
	    }
  });
  

});


 

</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3', container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName').toLowerCase())
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script><script>
  window.Lazyload.js(['https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js', 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js'], function() {
    var $canvas = null, $this = null, _ctx = null, _text = '';
    $('.language-chart').each(function(){
      $this = $(this);
      $canvas = $('<canvas></canvas>');
      _text = $this.text();
      $this.text('').append($canvas);
      _ctx = $canvas.get(0).getContext('2d');
      (_ctx && _text) && (new Chart(_ctx, JSON.parse(_text)) && $this.attr('data-processed', true));
    });
  });
</script><script type="text/x-mathjax-config">
	var _config = { tex2jax: {
		inlineMath: [['$','$'], ['\\(','\\)']]
	}};_config.TeX = { equationNumbers: { autoNumber: "all" } };MathJax.Hub.Config(_config);
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script>
  window.Lazyload.js('https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js', function() {
    mermaid.initialize({
      startOnLoad: true
    });
    mermaid.init(undefined, '.language-mermaid');
  });
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>