<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Spark NLP for Healthcare Release Notes - Spark NLP</title><meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/licensed_release_notes"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" ><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP</li><li class="toc-h2"><a href="/docs/en/quickstart">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/install">Install Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/concepts">General Concepts</a></li><li class="toc-h2"><a href="/docs/en/transformers">Transformers</a></li><li class="toc-h2"><a href="/docs/en/annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/auxiliary">Helpers</a></li><li class="toc-h2"><a href="/docs/en/pipelines">Pipelines</a></li><li class="toc-h2"><a href="/models">Models</a></li><li class="toc-h2"><a href="/docs/en/training">Training</a></li><li class="toc-h2"><a href="/api/">Scaladoc</a></li><li class="toc-h2"><a href="/docs/en/display">Spark NLP Display</a></li><li class="toc-h2"><a href="/docs/en/developers">Developers</a></li><li class="toc-h2"><a href="/docs/en/release_notes">Release Notes</a></li><li class="toc-h1">Annotation Lab</li><li class="toc-h2"><a href="/docs/en/alab">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/start_page">Start Page</a></li><li class="toc-h2"><a href="/docs/en/user_management">User Management</a></li><li class="toc-h2"><a href="/docs/en/project_setup">Project Setup</a></li><li class="toc-h2"><a href="/docs/en/preannotations">Preannotations with Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/active_learning">Active Learning</a></li><li class="toc-h2"><a href="/docs/en/import">Import Documents</a></li><li class="toc-h2"><a href="/docs/en/tasks">Tasks</a></li><li class="toc-h2"><a href="/docs/en/annotation">Annotate</a></li><li class="toc-h2"><a href="/docs/en/export">Export Data</a></li><li class="toc-h2"><a href="/docs/en/workflow">Workflow Setup</a></li><li class="toc-h2"><a href="/docs/en/tutorials">Video Tutorials</a></li><li class="toc-h1">Spark NLP for Healthcare</li><li class="toc-h2"><a href="/docs/en/licensed_install">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/licensed_annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/licensed_models">Models</a></li><li class="toc-h2"><a href="/docs/en/evaluation">Evaluation</a></li><li class="toc-h2"><a href="/licensed/api/">Scaladoc</a></li><li class="toc-h2 active"><a href="/docs/en/licensed_release_notes">Release Notes</a></li><li class="toc-h1">Spark OCR</li><li class="toc-h2"><a href="/docs/en/ocr">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/ocr_install">Installation</a></li><li class="toc-h2"><a href="/docs/en/ocr_pipeline_components">Pipeline components</a></li><li class="toc-h2"><a href="/docs/en/ocr_structures">Structures and helpers</a></li><li class="toc-h2"><a href="/docs/en/ocr_release_notes">Release notes</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) --><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs/en/quickstart">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/classify_documents">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class="fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://www.johnsnowlabs.com/slack-redirect/"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><header><h1>Spark NLP for Healthcare Release Notes</h1></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/licensed_release_notes.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Spark NLP for Healthcare Release Notes"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><h3 id="303">3.0.3</h3>

<p>We are glad to announce that Spark NLP for Healthcare 3.0.3 has been released!</p>

<h4 id="highlights">Highlights</h4>

<ul>
  <li>Five new entity resolution models to cover UMLS, HPO and LIONC terminologies.</li>
  <li>New feature for random displacement of dates on deidentification model.</li>
  <li>Five new pretrained pipelines to map terminologies across each other (from UMLS to ICD10, from RxNorm to MeSH etc.)</li>
  <li>AnnotationToolReader support for Spark 2.3. The tool that helps model training on Spark-NLP to leverage data annotated using JSL Annotation Tool now has support for Spark 2.3.</li>
  <li>Updated documentation (Scaladocs) covering more APIs, and examples.</li>
</ul>

<h4 id="five-new-resolver-models">Five new resolver models:</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_major_concepts</code>: This model returns CUI (concept unique identifier) codes for Clinical Findings, Medical Devices, Anatomical Structures and Injuries &amp; Poisoning terms.</li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_umls_findings</code>: This model returns CUI (concept unique identifier) codes for 200K concepts from clinical findings.</li>
  <li><code class="language-plaintext highlighter-rouge">sbiobertresolve_loinc</code>: Map clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbiobert</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">sbluebertresolve_loinc</code>: Map clinical NER entities to LOINC codes using <code class="language-plaintext highlighter-rouge">sbluebert</code>.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_HPO</code>: This model returns Human Phenotype Ontology (HPO) codes for phenotypic abnormalities encountered in human diseases. It also returns associated codes from the following vocabularies for each HPO code:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  * MeSH (Medical Subject Headings)
  * SNOMED
  * UMLS (Unified Medical Language System )
  * ORPHA (international reference resource for information on rare diseases and orphan drugs)
  * OMIM (Online Mendelian Inheritance in Man)
</code></pre></div>    </div>

    <p><em>Related Notebook</em>: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.Improved_Entity_Resolvers_in_SparkNLP_with_sBert.ipynb">Resolver Models</a></p>
  </li>
</ul>

<h4 id="new-feature-on-deidentification-module">New feature on Deidentification Module</h4>
<ul>
  <li>isRandomDateDisplacement(True): Be able to apply a random displacement on obfuscation dates. The randomness is based on the seed.</li>
  <li>Fix random dates when the format is not correct. Now you can repeat an execution using a seed for dates. Random dates will be based on the seed.</li>
</ul>

<h4 id="five-new-healthcare-code-mapping-pipelines">Five new healthcare code mapping pipelines:</h4>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">icd10cm_umls_mapping</code>: This pretrained pipeline maps ICD10CM codes to UMLS codes without using any text data. You’ll just feed white space-delimited ICD10CM codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'icd10cm': ['M89.50', 'R82.2', 'R09.01'], 
    'umls': ['C4721411', 'C0159076', 'C0004044']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">mesh_umls_mapping</code>: This pretrained pipeline maps MeSH codes to UMLS codes without using any text data. You’ll just feed white space-delimited MeSH codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'mesh': ['C028491', 'D019326', 'C579867'],
   'umls': ['C0970275', 'C0886627', 'C3696376']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">rxnorm_umls_mapping</code>: This pretrained pipeline maps RxNorm codes to UMLS codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'rxnorm': ['1161611', '315677', '343663'],
   'umls': ['C3215948', 'C0984912', 'C1146501']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">rxnorm_mesh_mapping</code>: This pretrained pipeline maps RxNorm codes to MeSH codes without using any text data. You’ll just feed white space-delimited RxNorm codes and it will return the corresponding MeSH codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'rxnorm': ['1191', '6809', '47613'],
   'mesh': ['D001241', 'D008687', 'D019355']}
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">snomed_umls_mapping</code>: This pretrained pipeline maps SNOMED codes to UMLS codes without using any text data. You’ll just feed white space-delimited SNOMED codes and it will return the corresponding UMLS codes as a list. If there is no mapping, the original code is returned with no mapping.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'snomed': ['733187009', '449433008', '51264003'],
   'umls': ['C4546029', 'C3164619', 'C0271267']}
</code></pre></div>    </div>

    <p><em>Related Notebook</em>: <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.1.Healthcare_Code_Mapping.ipynb">Healthcare Code Mapping</a></p>
  </li>
</ul>

<h3 id="302">3.0.2</h3>

<p>We are very excited to announce that <strong>Spark NLP for Healthcare 3.0.2</strong> has been released! This release includes bug fixes and some compatibility improvements.</p>

<h4 id="highlights-1">Highlights</h4>

<ul>
  <li>Dictionaries for Obfuscator were augmented with more than 10K names.</li>
  <li>Improved support for spark 2.3 and spark 2.4.</li>
  <li>Bug fixes in <code class="language-plaintext highlighter-rouge">DrugNormalizer</code>.</li>
</ul>

<h4 id="new-features">New Features</h4>
<p>Provide confidence scores for all available tags in <code class="language-plaintext highlighter-rouge">MedicalNerModel</code>,</p>

<h5 id="medicalnermodel-before-302">MedicalNerModel before 3.0.2</h5>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[named_entity, 0, 9, B-PROBLEM, [word -&gt; Pneumonia, confidence -&gt; 0.9998], []]
</code></pre></div></div>
<h5 id="now-in-spark-nlp-for-healthcare-302">Now in Spark NLP for Healthcare 3.0.2</h5>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[named_entity, 0, 9, B-PROBLEM, [B-PROBLEM -&gt; 0.9998, I-TREATMENT -&gt; 0.0, I-PROBLEM -&gt; 0.0, I-TEST -&gt; 0.0, B-TREATMENT -&gt; 1.0E-4, word -&gt; Pneumonia, B-TEST -&gt; 0.0], []]
</code></pre></div></div>

<h3 id="301">3.0.1</h3>

<p>We are very excited to announce that <strong>Spark NLP for Healthcare 3.0.1</strong> has been released!</p>

<h4 id="highlights-2">Highlights:</h4>

<ul>
  <li>Fixed problem in Assertion Status internal tokenization (reported in Spark-NLP #2470).</li>
  <li>Fixes in the internal implementation of DeIdentificationModel/Obfuscator.</li>
  <li>Being able to disable the use of regexes in the Deidentification process</li>
  <li>Other minor bug fixes &amp; general improvements.</li>
</ul>

<h4 id="deidentificationmodel-annotator">DeIdentificationModel Annotator</h4>

<h5 id="new-seed-parameter">New <code class="language-plaintext highlighter-rouge">seed</code> parameter.</h5>
<p>Now we have the possibility of using a seed to guide the process of obfuscating entities and returning the same result across different executions. To make that possible a new method setSeed(seed:Int) was introduced.</p>

<p><strong>Example:</strong>
Return obfuscated documents in a repeatable manner based on the same seed.</p>
<h5 id="scala">Scala</h5>
<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">deIdentification</span> <span class="k">=</span> <span class="nc">DeIdentification</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setSeed</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>
<h5 id="python">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<p>This seed controls how the obfuscated values are picked from a set of obfuscation candidates. Fixing the seed allows the process to be replicated.</p>

<p><strong>Example:</strong></p>

<p>Given the following input to the deidentification:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"David Hale was in Cocke County Baptist Hospital. David Hale"
</code></pre></div></div>

<p>If the annotator is set up with a seed of 10:</p>
<h5 id="scala-1">Scala</h5>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val deIdentification = new DeIdentification()
      .setInputCols(Array("ner_chunk", "token", "sentence"))
      .setOutputCol("dei")
      .setMode("obfuscate")
      .setObfuscateRefSource("faker")
      .setSeed(10)
      .setIgnoreRegex(true)
</code></pre></div></div>
<h5 id="python-1">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<p>The result will be the following for any execution,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Brendan Kitten was in New Megan.Brendan Kitten"
</code></pre></div></div>
<p>Now if we set up a seed of 32,</p>
<h5 id="scala-2">Scala</h5>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setSeed</span><span class="o">(</span><span class="mi">32</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>
<h5 id="python-2">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
            <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
            <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
            <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The result will be the following for any execution,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Louise Pear was in Lake Edward.Louise Pear"
</code></pre></div></div>

<h5 id="new-ignoreregex-parameter">New <code class="language-plaintext highlighter-rouge">ignoreRegex</code> parameter.</h5>
<p>You can now choose to completely disable the use of regexes in the deidentification process by setting the setIgnoreRegex param to True.
<strong>Example:</strong></p>
<h5 id="scala-3">Scala</h5>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">DeIdentificationModel</span><span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
</code></pre></div></div>
<h5 id="python-3">Python</h5>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DeIdentificationModel</span><span class="p">().</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The default value for this param is <code class="language-plaintext highlighter-rouge">False</code> meaning that regexes will be used by default.</p>

<h5 id="new-supported-entities-for-deidentification--obfuscation">New supported entities for Deidentification &amp; Obfuscation:</h5>

<p>We added new entities to the default supported regexes:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">SSN - Social security number.</code></li>
  <li><code class="language-plaintext highlighter-rouge">PASSPORT - Passport id.</code></li>
  <li><code class="language-plaintext highlighter-rouge">DLN - Department of Labor Number.</code></li>
  <li><code class="language-plaintext highlighter-rouge">NPI - National Provider Identifier.</code></li>
  <li><code class="language-plaintext highlighter-rouge">C_CARD - The id number for credits card.</code></li>
  <li><code class="language-plaintext highlighter-rouge">IBAN - International Bank Account Number.</code></li>
  <li><code class="language-plaintext highlighter-rouge">DEA - DEA Registration Number, which is an identifier assigned to a health care provider by the United States Drug Enforcement Administration.</code></li>
</ul>

<p>We also introduced new Obfuscator cases for these new entities.</p>

<h3 id="300">3.0.0</h3>

<p>We are very excited to announce that <strong>Spark NLP for Healthcare 3.0.0</strong> has been released! This has been one of the biggest releases we have ever done and we are so proud to share this with our customers.</p>

<h4 id="highlights-3">Highlights:</h4>

<p>Spark NLP for Healthcare 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We now support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x helping the customers to migrate from earlier Apache Spark versions to newer releases without being worried about Spark NLP support.</p>

<h4 id="highlights-4">Highlights:</h4>
<ul>
  <li>Support for Apache Spark and PySpark 3.0.x on Scala 2.12</li>
  <li>Support for Apache Spark and PySpark 3.1.x on Scala 2.12</li>
  <li>Migrate to TensorFlow v2.3.1 with native support for Java to take advantage of many optimizations for CPU/GPU and new features/models introduced in TF v2.x</li>
  <li>A brand new <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> annotator to train &amp; load the licensed clinical NER models.</li>
  <li><strong>Two times faster NER and Entity Resolution</strong> due to new batch annotation technique.</li>
  <li>Welcoming 9x new Databricks runtimes to our Spark NLP family:
    <ul>
      <li>Databricks 7.3</li>
      <li>Databricks 7.3 ML GPU</li>
      <li>Databricks 7.4</li>
      <li>Databricks 7.4 ML GPU</li>
      <li>Databricks 7.5</li>
      <li>Databricks 7.5 ML GPU</li>
      <li>Databricks 7.6</li>
      <li>Databricks 7.6 ML GPU</li>
      <li>Databricks 8.0</li>
      <li>Databricks 8.0 ML (there is no GPU in 8.0)</li>
      <li>Databricks 8.1 Beta</li>
    </ul>
  </li>
  <li>Welcoming 2x new EMR 6.x series to our Spark NLP family:
    <ul>
      <li>EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1)</li>
      <li>EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1)</li>
    </ul>
  </li>
  <li>Starting Spark NLP for Healthcare 3.0.0 the default packages  for CPU and GPU will be based on Apache Spark 3.x and Scala 2.12.</li>
</ul>

<h5 id="deprecated">Deprecated</h5>

<p>Text2SQL annotator is deprecated and will not be maintained going forward. We are working on a better and faster version of Text2SQL at the moment and will announce soon.</p>

<h4 id="1-medicalnermodel-annotator">1. MedicalNerModel Annotator</h4>

<p>Starting Spark NLP for Healthcare 3.0.0, the licensed clinical and biomedical pretrained NER models will only work with this brand new annotator called <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> and will not work with <code class="language-plaintext highlighter-rouge">NerDLModel</code> in open source version.</p>

<p>In order to make this happen, we retrained all the clinical NER models (more than 80) and uploaded to models hub.</p>

<p>Example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clinical_ner = MedicalNerModel.pretrained("ner_clinical", "en", "clinical/models") \
.setInputCols(["sentence", "token", "embeddings"])\
.setOutputCol("ner")
</code></pre></div></div>

<h4 id="2-speed-improvements">2. Speed Improvements</h4>

<p>A new batch annotation technique implemented in Spark NLP 3.0.0 for <code class="language-plaintext highlighter-rouge">NerDLModel</code>,<code class="language-plaintext highlighter-rouge">BertEmbeddings</code>, and <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotators will be reflected in <code class="language-plaintext highlighter-rouge">MedicalNerModel</code> and it improves prediction/inferencing performance radically. From now on the <code class="language-plaintext highlighter-rouge">batchSize</code> for these annotators means the number of rows that can be fed into the models for prediction instead of sentences per row. You can control the throughput when you are on accelerated hardware such as GPU to fully utilise it. Here are the overall speed comparison:</p>

<p>Now, NER inference and Entity Resolution are <strong>two times faster</strong> on CPU and three times faster on GPU.</p>

<h4 id="3-jsl-clinical-ner-model">3. JSL Clinical NER Model</h4>

<p>We are releasing the richest clinical NER model ever, spanning over 80 entities. It has been under development for the last 6 months and we manually annotated more than 4000 clinical notes to cover such a high number of entities in a single model. It has 4 variants at the moment:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">jsl_ner_wip_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">jsl_ner_wip_greedy_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">jsl_ner_wip_modifier_clinical</code></li>
  <li><code class="language-plaintext highlighter-rouge">jsl_rd_ner_wip_greedy_clinical</code></li>
</ul>

<h5 id="entities">Entities:</h5>

<p><code class="language-plaintext highlighter-rouge">Kidney_Disease</code>, <code class="language-plaintext highlighter-rouge">HDL</code>, <code class="language-plaintext highlighter-rouge">Diet</code>, <code class="language-plaintext highlighter-rouge">Test</code>, <code class="language-plaintext highlighter-rouge">Imaging_Technique</code>, <code class="language-plaintext highlighter-rouge">Triglycerides</code>, <code class="language-plaintext highlighter-rouge">Obesity</code>, <code class="language-plaintext highlighter-rouge">Duration</code>, <code class="language-plaintext highlighter-rouge">Weight</code>, <code class="language-plaintext highlighter-rouge">Social_History_Header</code>, <code class="language-plaintext highlighter-rouge">ImagingTest</code>, <code class="language-plaintext highlighter-rouge">Labour_Delivery</code>, <code class="language-plaintext highlighter-rouge">Disease_Syndrome_Disorder</code>, <code class="language-plaintext highlighter-rouge">Communicable_Disease</code>, <code class="language-plaintext highlighter-rouge">Overweight</code>, <code class="language-plaintext highlighter-rouge">Units</code>, <code class="language-plaintext highlighter-rouge">Smoking</code>, <code class="language-plaintext highlighter-rouge">Score</code>, <code class="language-plaintext highlighter-rouge">Substance_Quantity</code>, <code class="language-plaintext highlighter-rouge">Form</code>, <code class="language-plaintext highlighter-rouge">Race_Ethnicity</code>, <code class="language-plaintext highlighter-rouge">Modifier</code>, <code class="language-plaintext highlighter-rouge">Hyperlipidemia</code>, <code class="language-plaintext highlighter-rouge">ImagingFindings</code>, <code class="language-plaintext highlighter-rouge">Psychological_Condition</code>, <code class="language-plaintext highlighter-rouge">OtherFindings</code>, <code class="language-plaintext highlighter-rouge">Cerebrovascular_Disease</code>, <code class="language-plaintext highlighter-rouge">Date</code>, <code class="language-plaintext highlighter-rouge">Test_Result</code>, <code class="language-plaintext highlighter-rouge">VS_Finding</code>, <code class="language-plaintext highlighter-rouge">Employment</code>, <code class="language-plaintext highlighter-rouge">Death_Entity</code>, <code class="language-plaintext highlighter-rouge">Gender</code>, <code class="language-plaintext highlighter-rouge">Oncological</code>, <code class="language-plaintext highlighter-rouge">Heart_Disease</code>, <code class="language-plaintext highlighter-rouge">Medical_Device</code>, <code class="language-plaintext highlighter-rouge">Total_Cholesterol</code>, <code class="language-plaintext highlighter-rouge">ManualFix</code>, <code class="language-plaintext highlighter-rouge">Time</code>, <code class="language-plaintext highlighter-rouge">Route</code>, <code class="language-plaintext highlighter-rouge">Pulse</code>, <code class="language-plaintext highlighter-rouge">Admission_Discharge</code>, <code class="language-plaintext highlighter-rouge">RelativeDate</code>, <code class="language-plaintext highlighter-rouge">O2_Saturation</code>, <code class="language-plaintext highlighter-rouge">Frequency</code>, <code class="language-plaintext highlighter-rouge">RelativeTime</code>, <code class="language-plaintext highlighter-rouge">Hypertension</code>, <code class="language-plaintext highlighter-rouge">Alcohol</code>, <code class="language-plaintext highlighter-rouge">Allergen</code>, <code class="language-plaintext highlighter-rouge">Fetus_NewBorn</code>, <code class="language-plaintext highlighter-rouge">Birth_Entity</code>, <code class="language-plaintext highlighter-rouge">Age</code>, <code class="language-plaintext highlighter-rouge">Respiration</code>, <code class="language-plaintext highlighter-rouge">Medical_History_Header</code>, <code class="language-plaintext highlighter-rouge">Oxygen_Therapy</code>, <code class="language-plaintext highlighter-rouge">Section_Header</code>, <code class="language-plaintext highlighter-rouge">LDL</code>, <code class="language-plaintext highlighter-rouge">Treatment</code>, <code class="language-plaintext highlighter-rouge">Vital_Signs_Header</code>, <code class="language-plaintext highlighter-rouge">Direction</code>, <code class="language-plaintext highlighter-rouge">BMI</code>, <code class="language-plaintext highlighter-rouge">Pregnancy</code>, <code class="language-plaintext highlighter-rouge">Sexually_Active_or_Sexual_Orientation</code>, <code class="language-plaintext highlighter-rouge">Symptom</code>, <code class="language-plaintext highlighter-rouge">Clinical_Dept</code>, <code class="language-plaintext highlighter-rouge">Measurements</code>, <code class="language-plaintext highlighter-rouge">Height</code>, <code class="language-plaintext highlighter-rouge">Family_History_Header</code>, <code class="language-plaintext highlighter-rouge">Substance</code>, <code class="language-plaintext highlighter-rouge">Strength</code>, <code class="language-plaintext highlighter-rouge">Injury_or_Poisoning</code>, <code class="language-plaintext highlighter-rouge">Relationship_Status</code>, <code class="language-plaintext highlighter-rouge">Blood_Pressure</code>, <code class="language-plaintext highlighter-rouge">Drug</code>, <code class="language-plaintext highlighter-rouge">Temperature</code>, <code class="language-plaintext highlighter-rouge">EKG_Findings</code>, <code class="language-plaintext highlighter-rouge">Diabetes</code>, <code class="language-plaintext highlighter-rouge">BodyPart</code>, <code class="language-plaintext highlighter-rouge">Vaccine</code>, <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">Dosage</code></p>

<h4 id="4-jsl-clinical-assertion-model">4. JSL Clinical Assertion Model</h4>

<p>We are releasing a brand new clinical assertion model, supporting 8 assertion statuses.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">jsl_assertion_wip</code></li>
</ul>

<h5 id="assertion-labels-">Assertion Labels :</h5>

<p><code class="language-plaintext highlighter-rouge">Present</code>, <code class="language-plaintext highlighter-rouge">Absent</code>, <code class="language-plaintext highlighter-rouge">Possible</code>, <code class="language-plaintext highlighter-rouge">Planned</code>, <code class="language-plaintext highlighter-rouge">Someoneelse</code>, <code class="language-plaintext highlighter-rouge">Past</code>, <code class="language-plaintext highlighter-rouge">Family</code>, <code class="language-plaintext highlighter-rouge">Hypotetical</code></p>

<h4 id="5-library-version-compatibility-table-">5. Library Version Compatibility Table :</h4>

<p>Spark NLP for Healthcare 3.0.0 is compatible with Spark NLP 3.0.1</p>

<h4 id="6-pretrained-models-version-control-beta">6. Pretrained Models Version Control (Beta):</h4>

<p>Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks.</p>

<p>We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. You will not need to specify your AWS credentials from now on. This is the second version of the model checker we released with 2.7.6 and will replace that soon.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.compatibility_beta import CompatibilityBeta

compatibility = CompatibilityBeta(spark)

print(compatibility.findVersion("ner_deid"))
</code></pre></div></div>

<h4 id="7-updated-pretrained-models">7. Updated Pretrained Models:</h4>

<p>(requires fresh <code class="language-plaintext highlighter-rouge">.pretraned()</code>)</p>

<p>None</p>

<h3 id="276">2.7.6</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.6 has been released!</p>

<h4 id="highlights-5">Highlights:</h4>

<ul>
  <li>
    <p>New pretrained <strong>Radiology Assertion Status</strong> model to assign <code class="language-plaintext highlighter-rouge">Confirmed</code>, <code class="language-plaintext highlighter-rouge">Suspected</code>, <code class="language-plaintext highlighter-rouge">Negative</code> assertion scopes to imaging findings or any clinical tests.</p>
  </li>
  <li>
    <p><strong>Obfuscating</strong> the same sensitive information (patient or doctor name) with the same fake names across the same clinical note.</p>
  </li>
  <li>
    <p>Version compatibility checker for the pretrained clinical models and builds to keep up with the latest development efforts in production.</p>
  </li>
  <li>
    <p>Adding more English names to faker module in <strong>Deidentification</strong>.</p>
  </li>
  <li>
    <p>Updated &amp; improved clinical <strong>SentenceDetectorDL</strong> model.</p>
  </li>
  <li>
    <p>New upgrades on <code class="language-plaintext highlighter-rouge">ner_deid_large</code> and <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> NER models to cover more use cases with better resolutions.</p>
  </li>
  <li>
    <p>Adding more <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/scala/healthcare">examples</a> to workshop repo for <em>Scala</em> users to practice more on healthcare annotators.</p>
  </li>
  <li>
    <p>Bug fixes &amp; general improvements.</p>
  </li>
</ul>

<h4 id="1-radiology-assertion-status-model">1. Radiology Assertion Status Model</h4>

<p>We trained a new assertion model to assign <code class="language-plaintext highlighter-rouge">Confirmed</code>, <code class="language-plaintext highlighter-rouge">Suspected</code>, <code class="language-plaintext highlighter-rouge">Negative</code> assertion scopes to imaging findings or any clinical tests. It will try to assign these statuses to any named entity you would feed to the assertion annotater in the same pipeline.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> radiology_assertion = AssertionDLModel.pretrained("assertion_dl_radiology", "en", "clinical/models")\
 .setInputCols(["sentence", "ner_chunk", "embeddings"])\
 .setOutputCol("assertion")
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">text = Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion. No right-sided pleural effusion or pneumothorax is definitively seen. There are mildly displaced fractures of the left lateral 8th and likely 9th ribs.</code></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">sentences</th>
      <th style="text-align: center">chunk</th>
      <th style="text-align: center">ner_label</th>
      <th style="text-align: center">sent_id</th>
      <th style="text-align: left">assertion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion.</td>
      <td style="text-align: center">Blunting</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">0</td>
      <td style="text-align: left">Confirmed</td>
    </tr>
    <tr>
      <td style="text-align: right">Blunting of the left costophrenic angle on the lateral view posteriorly suggests a small left pleural effusion.</td>
      <td style="text-align: center">effusion</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">0</td>
      <td style="text-align: left">Suspected</td>
    </tr>
    <tr>
      <td style="text-align: right">No right-sided pleural effusion or pneumothorax is definitively seen.</td>
      <td style="text-align: center">effusion</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">1</td>
      <td style="text-align: left">Negative</td>
    </tr>
    <tr>
      <td style="text-align: right">No right-sided pleural effusion or pneumothorax is definitively seen.</td>
      <td style="text-align: center">pneumothorax</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">1</td>
      <td style="text-align: left">Negative</td>
    </tr>
    <tr>
      <td style="text-align: right">There are mildly displaced fractures of the left lateral 8th and likely 9th ribs.</td>
      <td style="text-align: center">displaced fractures</td>
      <td style="text-align: center">ImagingFindings</td>
      <td style="text-align: center">2</td>
      <td style="text-align: left">Confirmed</td>
    </tr>
  </tbody>
</table>

<p>You can also use this with <code class="language-plaintext highlighter-rouge">AssertionFilterer</code> to return clinical findings from a note only when it is i.e. <code class="language-plaintext highlighter-rouge">confirmed</code> or <code class="language-plaintext highlighter-rouge">suspected</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> assertion_filterer = AssertionFilterer()\
 .setInputCols("sentence","ner_chunk","assertion")\
 .setOutputCol("assertion_filtered")\
 .setWhiteList(["confirmed","suspected"])

 &gt;&gt; ["displaced fractures", "effusion"]
</code></pre></div></div>

<h4 id="2-obfuscating-with-the-same-fake-name-across-the-same-note">2. <strong>Obfuscating</strong> with the same fake name across the same note:</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> obfuscation = DeIdentification()\
  .setInputCols(["sentence", "token", "ner_chunk"]) \
  .setOutputCol("deidentified") \
  .setMode("obfuscate")\
  .setObfuscateDate(True)\
  .setSameEntityThreshold(0.8)\
  .setObfuscateRefSource("faker")

  
text =''' Provider: David Hale, M.D.
          Pt: Jessica Parker 
          David told  Jessica that she will need to visit the clinic next month.'''
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">sentence</th>
      <th style="text-align: left">obfuscated</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Provider: <code class="language-plaintext highlighter-rouge">David Hale</code>, M.D.</td>
      <td style="text-align: left">Provider: <code class="language-plaintext highlighter-rouge">Dennis Perez</code>, M.D.</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Pt: <code class="language-plaintext highlighter-rouge">Jessica Parker</code></td>
      <td style="text-align: left">Pt: <code class="language-plaintext highlighter-rouge">Gerth Bayer</code></td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">David</code> told  <code class="language-plaintext highlighter-rouge">Jessica</code> that she will need to visit the clinic next month.</td>
      <td style="text-align: left"><code class="language-plaintext highlighter-rouge">Dennis</code> told  <code class="language-plaintext highlighter-rouge">Gerth</code> that she will need to visit the clinic next month.</td>
    </tr>
  </tbody>
</table>

<h4 id="3-library-version-compatibility-table-">3. Library Version Compatibility Table :</h4>

<p>We are releasing the version compatibility table to help users get to see which Spark NLP licensed version is built against which core (open source) version. We are going to release a detailed one after running some tests across the jars from each library.</p>

<table>
  <thead>
    <tr>
      <th>Healthcare</th>
      <th>Public</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2.7.6</td>
      <td>2.7.4</td>
    </tr>
    <tr>
      <td>2.7.5</td>
      <td>2.7.4</td>
    </tr>
    <tr>
      <td>2.7.4</td>
      <td>2.7.3</td>
    </tr>
    <tr>
      <td>2.7.3</td>
      <td>2.7.3</td>
    </tr>
    <tr>
      <td>2.7.2</td>
      <td>2.6.5</td>
    </tr>
    <tr>
      <td>2.7.1</td>
      <td>2.6.4</td>
    </tr>
    <tr>
      <td>2.7.0</td>
      <td>2.6.3</td>
    </tr>
    <tr>
      <td>2.6.2</td>
      <td>2.6.2</td>
    </tr>
    <tr>
      <td>2.6.0</td>
      <td>2.6.0</td>
    </tr>
    <tr>
      <td>2.5.5</td>
      <td>2.5.5</td>
    </tr>
    <tr>
      <td>2.5.3</td>
      <td>2.5.3</td>
    </tr>
    <tr>
      <td>2.5.2</td>
      <td>2.5.2</td>
    </tr>
    <tr>
      <td>2.5.0</td>
      <td>2.5.0</td>
    </tr>
    <tr>
      <td>2.4.7</td>
      <td>2.4.5</td>
    </tr>
    <tr>
      <td>2.4.6</td>
      <td>2.4.5</td>
    </tr>
    <tr>
      <td>2.4.5</td>
      <td>2.4.5</td>
    </tr>
    <tr>
      <td>2.4.2</td>
      <td>2.4.2</td>
    </tr>
    <tr>
      <td>2.4.1</td>
      <td>2.4.1</td>
    </tr>
    <tr>
      <td>2.4.0</td>
      <td>2.4.0</td>
    </tr>
    <tr>
      <td>2.3.6</td>
      <td>2.3.6</td>
    </tr>
    <tr>
      <td>2.3.5</td>
      <td>2.3.5</td>
    </tr>
    <tr>
      <td>2.3.4</td>
      <td>2.3.4</td>
    </tr>
  </tbody>
</table>

<h4 id="4-pretrained-models-version-control-">4. Pretrained Models Version Control :</h4>

<p>Due to active release cycle, we are adding &amp; training new pretrained models at each release and it might be tricky to maintain the backward compatibility or keep up with the latest models, especially for the users using our models locally in air-gapped networks.</p>

<p>We are releasing a new utility class to help you check your local &amp; existing models with the latest version of everything we have up to date. This is an highly experimental feature of which we plan to improve and add more capability later on.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from sparknlp_jsl.check_compatibility import Compatibility

 checker = sparknlp_jsl.Compatibility()

 result = checker.find_version(aws_access_key_id=license_keys['AWS_ACCESS_KEY_ID'],
                        aws_secret_access_key=license_keys['AWS_SECRET_ACCESS_KEY'],
                        metadata_path=None,
                        model = 'all' , # or a specific model name
                        target_version='all',
                        cache_pretrained_path='/home/ubuntu/cache_pretrained')

 &gt;&gt; result['outdated_models']
 
  [{'model_name': 'clinical_ner_assertion',
    'current_version': '2.4.0',
    'latest_version': '2.6.4'},
   {'model_name': 'jsl_rd_ner_wip_greedy_clinical',
    'current_version': '2.6.1',
    'latest_version': '2.6.2'},
   {'model_name': 'ner_anatomy',
    'current_version': '2.4.2',
    'latest_version': '2.6.4'},
   {'model_name': 'ner_aspect_based_sentiment',
    'current_version': '2.6.2',
    'latest_version': '2.7.2'},
   {'model_name': 'ner_bionlp',
    'current_version': '2.4.0',
    'latest_version': '2.7.0'},
   {'model_name': 'ner_cellular',
    'current_version': '2.4.2',
    'latest_version': '2.5.0'}]

  &gt;&gt; result['version_comparison_dict']
  
  [{'clinical_ner_assertion': {'current_version': '2.4.0', 'latest_version': '2.6.4'}}, {'jsl_ner_wip_clinical': {'current_version': '2.6.5', 'latest_version': '2.6.1'}}, {'jsl_ner_wip_greedy_clinical': {'current_version': '2.6.5', 'latest_version': '2.6.5'}}, {'jsl_ner_wip_modifier_clinical': {'current_version': '2.6.4', 'latest_version': '2.6.4'}}, {'jsl_rd_ner_wip_greedy_clinical': {'current_version': '2.6.1','latest_version': '2.6.2'}}]
</code></pre></div></div>

<h4 id="5-updated-pretrained-models">5. Updated Pretrained Models:</h4>

<p>(requires fresh <code class="language-plaintext highlighter-rouge">.pretraned()</code>)</p>

<ul>
  <li>ner_deid_large</li>
  <li>ner_deid_enriched</li>
</ul>

<h3 id="275">2.7.5</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.5 has been released!</p>

<h4 id="highlights-6">Highlights:</h4>

<ul>
  <li>New pretrained <strong>Relation Extraction</strong> model to link clinical tests to test results and dates to clinical entities: <code class="language-plaintext highlighter-rouge">re_test_result_date</code></li>
  <li>Adding two new <code class="language-plaintext highlighter-rouge">Admission</code> and <code class="language-plaintext highlighter-rouge">Discharge</code> entities to <code class="language-plaintext highlighter-rouge">ner_events_clinical</code> and renaming it to <code class="language-plaintext highlighter-rouge">ner_events_admission_clinical</code></li>
  <li>Improving <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> NER model to cover <code class="language-plaintext highlighter-rouge">Doctor</code> and <code class="language-plaintext highlighter-rouge">Patient</code> name entities in various context and notations.</li>
  <li>Bug fixes &amp; general improvements.</li>
</ul>

<h4 id="1-re_test_result_date-">1. re_test_result_date :</h4>

<p>text = “Hospitalized with pneumonia in June, confirmed by a positive PCR of any specimen, evidenced by SPO2 &lt;/= 93% or PaO2/FiO2 &lt; 300 mmHg”</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Chunk-1</th>
      <th style="text-align: left">Entity-1</th>
      <th style="text-align: left">Chunk-2</th>
      <th style="text-align: left">Entity-2</th>
      <th style="text-align: left">Relation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">pneumonia</td>
      <td style="text-align: left">Problem</td>
      <td style="text-align: left">june</td>
      <td style="text-align: left">Date</td>
      <td style="text-align: left">is_date_of</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">PCR</td>
      <td style="text-align: left">Test</td>
      <td style="text-align: left">positive</td>
      <td style="text-align: left">Test_Result</td>
      <td style="text-align: left">is_result_of</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">SPO2</td>
      <td style="text-align: left">Test</td>
      <td style="text-align: left">93%</td>
      <td style="text-align: left">Test_Result</td>
      <td style="text-align: left">is_result_of</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">PaO2/FiO2</td>
      <td style="text-align: left">Test</td>
      <td style="text-align: left">300 mmHg</td>
      <td style="text-align: left">Test_Result</td>
      <td style="text-align: left">is_result_of</td>
    </tr>
  </tbody>
</table>

<h4 id="2-ner_events_admission_clinical-">2. <code class="language-plaintext highlighter-rouge">ner_events_admission_clinical</code> :</h4>

<p><code class="language-plaintext highlighter-rouge">ner_events_clinical</code> NER model is updated &amp; improved to include <code class="language-plaintext highlighter-rouge">Admission</code> and <code class="language-plaintext highlighter-rouge">Discharge</code> entities.</p>

<p>text =”She is diagnosed as cancer in 1991. Then she was admitted to Mayo Clinic in May 2000 and discharged in October 2001”</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: left">entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">diagnosed</td>
      <td style="text-align: left">OCCURRENCE</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">cancer</td>
      <td style="text-align: left">PROBLEM</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">1991</td>
      <td style="text-align: left">DATE</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">admitted</td>
      <td style="text-align: left">ADMISSION</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">Mayo Clinic</td>
      <td style="text-align: left">CLINICAL_DEPT</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">May 2000</td>
      <td style="text-align: left">DATE</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">discharged</td>
      <td style="text-align: left">DISCHARGE</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">October 2001</td>
      <td style="text-align: left">DATE</td>
    </tr>
  </tbody>
</table>

<h4 id="3-improved-ner_deid_enriched-">3. Improved <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> :</h4>

<p>PHI NER model is retrained to cover <code class="language-plaintext highlighter-rouge">Doctor</code> and <code class="language-plaintext highlighter-rouge">Patient</code> name entities even there is a punctuation between tokens as well as all upper case or lowercased.</p>

<p>text =”A . Record date : 2093-01-13 , DAVID HALE , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01/13/93 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street”</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: left">entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">2093-01-13</td>
      <td style="text-align: left">MEDICALRECORD</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">DAVID HALE</td>
      <td style="text-align: left">DOCTOR</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Hendrickson , Ora</td>
      <td style="text-align: left">PATIENT</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">7194334</td>
      <td style="text-align: left">MEDICALRECORD</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">01/13/93</td>
      <td style="text-align: left">DATE</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">Oliveira</td>
      <td style="text-align: left">DOCTOR</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">25</td>
      <td style="text-align: left">AGE</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">2079-11-09</td>
      <td style="text-align: left">MEDICALRECORD</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">Cocke County Baptist Hospital</td>
      <td style="text-align: left">HOSPITAL</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">0295 Keats Street</td>
      <td style="text-align: left">STREET</td>
    </tr>
  </tbody>
</table>

<h3 id="274">2.7.4</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.4 has been released!</p>

<h4 id="highlights-7">Highlights:</h4>

<ul>
  <li>Introducing a new annotator to extract chunks with NER tags using regex-like patterns: <strong>NerChunker</strong>.</li>
  <li>Introducing two new annotators to filter chunks: <strong>ChunkFilterer</strong> and <strong>AssertionFilterer</strong>.</li>
  <li>Ability to change the entity type in <strong>NerConverterInternal</strong> without using ChunkMerger (<code class="language-plaintext highlighter-rouge">setReplaceDict</code>).</li>
  <li>In <strong>DeIdentification</strong> model, ability to use <code class="language-plaintext highlighter-rouge">faker</code> and static look-up lists at the same time randomly in <code class="language-plaintext highlighter-rouge">Obfuscation</code> mode.</li>
  <li>New <strong>De-Identification NER</strong> model, augmented with synthetic datasets to detect uppercased name entities.</li>
  <li>Bug fixes &amp; general improvements.</li>
</ul>

<h4 id="1-nerchunker">1. NerChunker:</h4>

<p>Similar to what we used to do in <strong>POSChunker</strong> with POS tags, now we can also extract phrases that fits into a known pattern using the NER tags. <strong>NerChunker</strong> would be quite handy to extract entity groups with neighboring tokens when there is no pretrained NER model to address certain issues. Lets say we want to extract clinical findings and body parts together as a single chunk even if there are some unwanted tokens between.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_model = NerDLModel.pretrained("ner_radiology", "en", "clinical/models")\
    .setInputCols("sentence","token","embeddings")\
    .setOutputCol("ner")
            
ner_chunker = NerChunker().\
    .setInputCols(["sentence","ner"])\
    .setOutputCol("ner_chunk")\
    .setRegexParsers(["&lt;IMAGINGFINDINGS&gt;*&lt;BODYPART&gt;"])

text = 'She has cystic cyst on her kidney.'

&gt;&gt; ner tags: [(cystic, B-IMAGINGFINDINGS), (cyst,I-IMAGINGFINDINGS), (kidney, B-BODYPART)
&gt;&gt; ner_chunk: ['cystic cyst on her kidney']
</code></pre></div></div>

<h4 id="2-chunkfilterer">2. ChunkFilterer:</h4>

<p><strong>ChunkFilterer</strong> will allow you to filter out named entities by some conditions or predefined look-up lists, so that you can feed these entities to other annotators like Assertion Status or Entity Resolvers.  It can be used with two criteria: <strong>isin</strong> and <strong>regex</strong>.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_model = NerDLModel.pretrained("ner_clinical", "en", "clinical/models")\
      .setInputCols("sentence","token","embeddings")\
      .setOutputCol("ner")

ner_converter = NerConverter() \
      .setInputCols(["sentence", "token", "ner"]) \
      .setOutputCol("ner_chunk")
      
chunk_filterer = ChunkFilterer()\
      .setInputCols("sentence","ner_chunk")\
      .setOutputCol("chunk_filtered")\
      .setCriteria("isin") \ 
      .setWhiteList(['severe fever','sore throat'])

text = 'Patient with severe fever, sore throat, stomach pain, and a headache.'

&gt;&gt; ner_chunk: ['severe fever','sore throat','stomach pain','headache']
&gt;&gt; chunk_filtered: ['severe fever','sore throat']
</code></pre></div></div>

<h4 id="3-assertionfilterer">3. AssertionFilterer:</h4>

<p><strong>AssertionFilterer</strong> will allow you to filter out the named entities by the list of acceptable assertion statuses. This annotator would be quite handy if you want to set a white list for the acceptable assertion statuses like <code class="language-plaintext highlighter-rouge">present</code> or <code class="language-plaintext highlighter-rouge">conditional</code>; and do not want <code class="language-plaintext highlighter-rouge">absent</code> conditions get out of your pipeline.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clinical_assertion = AssertionDLModel.pretrained("assertion_dl", "en", "clinical/models") \
  .setInputCols(["sentence", "ner_chunk", "embeddings"]) \
  .setOutputCol("assertion")

assertion_filterer = AssertionFilterer()\
  .setInputCols("sentence","ner_chunk","assertion")\
  .setOutputCol("assertion_filtered")\
  .setWhiteList(["present"])


text = 'Patient with severe fever and sore throat, but no stomach pain.'

&gt;&gt; ner_chunk: ['severe fever','sore throat','stomach pain','headache']
&gt;&gt; assertion_filtered: ['severe fever','sore throat']
</code></pre></div></div>

<h3 id="273">2.7.3</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.3 has been released!</p>

<h4 id="highlights-8">Highlights:</h4>

<ul>
  <li>Introducing a brand-new <strong>RelationExtractionDL Annotator</strong> – Achieving SOTA results in clinical relation extraction using <strong>BioBert</strong>.</li>
  <li>Massive Improvements &amp; feature enhancements in <strong>De-Identification</strong> module:
    <ul>
      <li>Introduction of <strong>faker</strong> augmentation in Spark NLP for Healthcare to generate random data for obfuscation in de-identification module.</li>
      <li>Brand-new annotator for <strong>Structured De-Identification</strong>.</li>
    </ul>
  </li>
  <li><strong>Drug Normalizer:</strong>  Normalize medication-related phrases (dosage, form and strength) and abbreviations in text and named entities extracted by NER models.</li>
  <li><strong>Confidence scores</strong> in <strong>assertion</strong> output : just like NER output, assertion models now also support confidence scores for each prediction.</li>
  <li><strong>Cosine similarity</strong> metrics in entity resolvers to get more informative and semantically correct results.</li>
  <li><strong>AuxLabel</strong> in the metadata of entity resolvers to return additional mappings.</li>
  <li>New <strong>Relation Extraction</strong> models to extract relations between <strong>body parts</strong> and clinical entities.</li>
  <li>New <strong>Entity Resolver</strong> models to extract billable medical codes.</li>
  <li>New <strong>Clinical Pretrained NER</strong> models.</li>
  <li>Bug fixes &amp; general improvements.</li>
  <li>Matching the version with Spark NLP open-source v2.7.3.</li>
</ul>

<h4 id="1-improvements-in-de-identification-module">1. Improvements in De-Identification Module:</h4>

<p>Integration of <code class="language-plaintext highlighter-rouge">faker</code> library to automatically generate random data like names, dates, addresses etc so users dont have to specify dummy data (custom obfuscation files can still be used). It also improves the obfuscation results due to a bigger pool of random values.</p>

<p><strong>How to use:</strong></p>

<p>Set the flag <code class="language-plaintext highlighter-rouge">setObfuscateRefSource</code> to <code class="language-plaintext highlighter-rouge">faker</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>deidentification = DeIdentification()
    .setInputCols(["sentence", "token", "ner_chunk"])\
	.setOutputCol("deidentified")\
	.setMode("obfuscate") \
	.setObfuscateRefSource("faker")
</code></pre></div></div>

<p>For more details: Check out this <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb">notebook </a></p>

<h4 id="2-structured-de-identification-module">2. Structured De-Identification Module:</h4>

<p>Introduction of a new annotator to handle de-identification of structured data. it  allows users to define a mapping of columns and their obfuscation policy. Users can also provide dummy data and map them to columns they want to replace values in.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>obfuscator = StructuredDeidentification \
	(spark,{"NAME":"PATIENT","AGE":"AGE"},
	obfuscateRefSource = "faker")

obfuscator_df = obfuscator.obfuscateColumns(df)

obfuscator_df.select("NAME","AGE").show(truncate=False)
</code></pre></div></div>

<p><strong>Example:</strong></p>

<p>Input Data:</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cecilia Chapman</td>
      <td>83</td>
    </tr>
    <tr>
      <td>Iris Watson</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Bryar Pitts</td>
      <td>98</td>
    </tr>
    <tr>
      <td>Theodore Lowe</td>
      <td>16</td>
    </tr>
    <tr>
      <td>Calista Wise</td>
      <td>76</td>
    </tr>
  </tbody>
</table>

<p>Deidentified:</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Menne Erdôs</td>
      <td>20</td>
    </tr>
    <tr>
      <td>Longin Robinson</td>
      <td>31</td>
    </tr>
    <tr>
      <td>Flynn Fiedlerová</td>
      <td>50</td>
    </tr>
    <tr>
      <td>John Wakeland</td>
      <td>21</td>
    </tr>
    <tr>
      <td>Vanessa Andersson</td>
      <td>12</td>
    </tr>
  </tbody>
</table>

<p>For more details: Check out this <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb">notebook</a>.</p>

<h4 id="3-introducing-sota-relation-extraction-model-using-biobert">3. Introducing SOTA relation extraction model using BioBert</h4>

<p>A brand-new end-to-end trained BERT model, resulting in massive improvements. Another new annotator (<code class="language-plaintext highlighter-rouge">ReChunkFilter</code>) is also developed for this new model to allow syntactic features work well with BioBert to extract relations.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re_ner_chunk_filter = RENerChunksFilter()\
    .setInputCols(["ner_chunks", "dependencies"])\
    .setOutputCol("re_ner_chunks")\
    .setRelationPairs(pairs)\
    .setMaxSyntacticDistance(4)

re_model = RelationExtractionDLModel()\
    .pretrained(“redl_temporal_events_biobert”, "en", "clinical/models")\
    .setPredictionThreshold(0.9)\
    .setInputCols(["re_ner_chunks", "sentences"])\
    .setOutputCol("relations")
</code></pre></div></div>

<h5 id="benchmarks">Benchmarks:</h5>

<p><strong>on benchmark datasets</strong></p>

<table>
  <thead>
    <tr>
      <th>model</th>
      <th>Spark NLP ML model</th>
      <th>Spark NLP DL model</th>
      <th>benchmark</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>re_temporal_events_clinical</td>
      <td>68.29</td>
      <td>71.0</td>
      <td>80.2 <a href="https://arxiv.org/pdf/2012.08790.pdf">1</a></td>
    </tr>
    <tr>
      <td>re_clinical</td>
      <td>56.45</td>
      <td><strong>69.2</strong></td>
      <td>68.2      <a href="ncbi.nlm.nih.gov/pmc/articles/PMC7153059/">2</a></td>
    </tr>
    <tr>
      <td>re_human_pheotype_gene_clinical</td>
      <td>-</td>
      <td><strong>87.9</strong></td>
      <td>67.2 <a href="https://arxiv.org/pdf/1903.10728.pdf">3</a></td>
    </tr>
    <tr>
      <td>re_drug_drug_interaction</td>
      <td>-</td>
      <td>72.1</td>
      <td>83.8 <a href="https://www.aclweb.org/anthology/2020.knlp-1.4.pdf">4</a></td>
    </tr>
    <tr>
      <td>re_chemprot</td>
      <td>76.69</td>
      <td><strong>94.1</strong></td>
      <td>83.64 <a href="https://www.aclweb.org/anthology/D19-1371.pdf">5</a></td>
    </tr>
  </tbody>
</table>

<p><strong>on in-house annotations</strong></p>

<table>
  <thead>
    <tr>
      <th>model</th>
      <th>Spark NLP ML model</th>
      <th>Spark NLP DL model</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>re_bodypart_problem</td>
      <td>84.58</td>
      <td>85.7</td>
    </tr>
    <tr>
      <td>re_bodypart_procedure</td>
      <td>61.0</td>
      <td>63.3</td>
    </tr>
    <tr>
      <td>re_date_clinical</td>
      <td>83.0</td>
      <td>84.0</td>
    </tr>
    <tr>
      <td>re_bodypart_direction</td>
      <td>93.5</td>
      <td>92.5</td>
    </tr>
  </tbody>
</table>

<p>For more details: Check out the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.1.Clinical_Relation_Extraction_BodyParts_Models.ipynb">notebook</a> or <a href="https://nlp.johnsnowlabs.com/models?tag=relation_extraction">modelshub</a>.</p>

<h4 id="4-drug-normalizer">4. Drug Normalizer:</h4>

<p>Standardize units of drugs and handle abbreviations in raw text or drug chunks identified by any NER model. This normalization significantly improves performance of entity resolvers.</p>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drug_normalizer = DrugNormalizer()\
    .setInputCols("document")\
    .setOutputCol("document_normalized")\
    .setPolicy("all") #all/abbreviations/dosages
</code></pre></div></div>

<p><strong>Examples:</strong></p>

<p><code class="language-plaintext highlighter-rouge">drug_normalizer.transform("adalimumab 54.5 + 43.2 gm”)</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; "adalimumab 97700 mg"
</code></pre></div></div>

<p><strong>Changes:</strong> <em>combine</em> <code class="language-plaintext highlighter-rouge">54.5</code> + <code class="language-plaintext highlighter-rouge">43.2</code> and <em>normalize</em> <code class="language-plaintext highlighter-rouge">gm</code> to <code class="language-plaintext highlighter-rouge">mg</code></p>

<p><code class="language-plaintext highlighter-rouge">drug_normalizer.transform("Agnogenic one half cup”)</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; "Agnogenic 0.5 oral solution"
</code></pre></div></div>

<p><strong>Changes:</strong> <em>replace</em> <code class="language-plaintext highlighter-rouge">one half</code> to the <code class="language-plaintext highlighter-rouge">0.5</code>, <em>normalize</em> <code class="language-plaintext highlighter-rouge">cup</code> to the <code class="language-plaintext highlighter-rouge">oral solution</code></p>

<p><code class="language-plaintext highlighter-rouge">drug_normalizer.transform("interferon alfa-2b 10 million unit ( 1 ml ) injec”)</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; "interferon alfa - 2b 10000000 unt ( 1 ml ) injection "
</code></pre></div></div>

<p><strong>Changes:</strong> <em>convert</em> <code class="language-plaintext highlighter-rouge">10 million unit</code> to the <code class="language-plaintext highlighter-rouge">10000000 unt</code>, <em>replace</em> <code class="language-plaintext highlighter-rouge">injec</code> with <code class="language-plaintext highlighter-rouge">injection</code></p>

<p>For more details: Check out this <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/23.Drug_Normalizer.ipynb">notebook</a></p>

<h4 id="5-assertion-models-to-support-confidence-in-output">5. Assertion models to support confidence in output:</h4>

<p>Just like NER output, assertion models now also provides <em>confidence scores</em> for each prediction.</p>

<table>
  <thead>
    <tr>
      <th>chunks</th>
      <th>entities</th>
      <th>assertion</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>a headache</td>
      <td>PROBLEM</td>
      <td>present</td>
      <td>0.9992</td>
    </tr>
    <tr>
      <td>anxious</td>
      <td>PROBLEM</td>
      <td>conditional</td>
      <td>0.9039</td>
    </tr>
    <tr>
      <td>alopecia</td>
      <td>PROBLEM</td>
      <td>absent</td>
      <td>0.9992</td>
    </tr>
    <tr>
      <td>pain</td>
      <td>PROBLEM</td>
      <td>absent</td>
      <td>0.9238</td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">.setClasses()</code> method is deprecated in <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code>  and users do not need to specify number of classes while training, as it will be inferred from the dataset.</p>

<h4 id="6-new-relation-extraction-models">6. New Relation Extraction Models:</h4>

<p>We are also releasing new relation extraction models to link the clinical entities to body parts and dates. These models are trained using binary relation extraction approach for better accuracy.</p>

<p><strong>- re_bodypart_direction :</strong>  Relation Extraction between <code class="language-plaintext highlighter-rouge">Body Part</code> and <code class="language-plaintext highlighter-rouge">Direction</code> entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“MRI demonstrated infarction in the upper brain stem , left cerebellum and right basil ganglia”</em></p>

<table>
  <thead>
    <tr>
      <th>relations</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Direction</td>
      <td>upper</td>
      <td>bodyPart</td>
      <td>brain stem</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>Direction</td>
      <td>upper</td>
      <td>bodyPart</td>
      <td>cerebellum</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>Direction</td>
      <td>upper</td>
      <td>bodyPart</td>
      <td>basil ganglia</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>bodyPart</td>
      <td>brain stem</td>
      <td>Direction</td>
      <td>left</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>0</td>
      <td>bodyPart</td>
      <td>brain stem</td>
      <td>Direction</td>
      <td>right</td>
      <td>0.999</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Direction</td>
      <td>left</td>
      <td>bodyPart</td>
      <td>cerebellum</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>0</td>
      <td>Direction</td>
      <td>left</td>
      <td>bodyPart</td>
      <td>basil ganglia</td>
      <td>0.976</td>
    </tr>
    <tr>
      <td>0</td>
      <td>bodyPart</td>
      <td>cerebellum</td>
      <td>Direction</td>
      <td>right</td>
      <td>0.953</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Direction</td>
      <td>right</td>
      <td>bodyPart</td>
      <td>basil ganglia</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>

<p><strong>- re_bodypart_problem :</strong> Relation Extraction between <code class="language-plaintext highlighter-rouge">Body Part</code> and <code class="language-plaintext highlighter-rouge">Problem</code> entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“No neurologic deficits other than some numbness in his left hand.”</em></p>

<table>
  <thead>
    <tr>
      <th>relation</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Symptom</td>
      <td>neurologic deficits</td>
      <td>bodyPart</td>
      <td>hand</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Symptom</td>
      <td>numbness</td>
      <td>bodyPart</td>
      <td>hand</td>
      <td>1</td>
    </tr>
  </tbody>
</table>

<p><strong>- re_bodypart_proceduretest :</strong>  Relation Extraction between <code class="language-plaintext highlighter-rouge">Body Part</code> and <code class="language-plaintext highlighter-rouge">Procedure</code>, <code class="language-plaintext highlighter-rouge">Test</code> entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“TECHNIQUE IN DETAIL: After informed consent was obtained from the patient and his mother, the chest was scanned with portable ultrasound.”</em></p>

<table>
  <thead>
    <tr>
      <th>relation</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>bodyPart</td>
      <td>chest</td>
      <td>Test</td>
      <td>portable ultrasound</td>
      <td>0.999</td>
    </tr>
  </tbody>
</table>

<p><strong>-re_date_clinical :</strong> Relation Extraction between <code class="language-plaintext highlighter-rouge">Date</code> and different clinical entities.</p>

<p><strong>Example:</strong></p>

<p><strong>Text:</strong> <em>“This 73 y/o patient had CT on 1/12/95, with progressive memory and cognitive decline since 8/11/94.”</em></p>

<table>
  <thead>
    <tr>
      <th>relations</th>
      <th>entity1</th>
      <th>chunk1</th>
      <th>entity2</th>
      <th>chunk2</th>
      <th>confidence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>Test</td>
      <td>CT</td>
      <td>Date</td>
      <td>1/12/95</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Symptom</td>
      <td>progressive memory and cognitive decline</td>
      <td>Date</td>
      <td>8/11/94</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>

<p><strong>How to use:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re_model = RelationExtractionModel()\
    .pretrained("re_bodypart_direction","en","clinical/models")\
    .setInputCols(["embeddings", "pos_tags", "ner_chunks", "dependencies"])\
    .setOutputCol("relations")\
    .setMaxSyntacticDistance(4)\
    .setRelationPairs([‘Internal_organ_or_component’, ‘Direction’])
</code></pre></div></div>

<p>For more details: Check out the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.1.Clinical_Relation_Extraction_BodyParts_Models.ipynb">notebook</a> or <a href="https://nlp.johnsnowlabs.com/models?tag=relation_extraction">modelshub</a>.</p>

<p><strong>New matching scheme for entity resolvers - improved accuracy:</strong> Adding the option to use <code class="language-plaintext highlighter-rouge">cosine similarity</code> to resolve entities and find closest matches, resulting in better, more semantically correct results.</p>

<h4 id="7-new-resolver-models-using-jsl-sbert">7. New Resolver Models using <code class="language-plaintext highlighter-rouge">JSL SBERT</code>:</h4>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_augmented</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_procedures_augmented</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented_billable_hcc</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_hcc_augmented</code></p>
  </li>
</ul>

<p><strong>Returning auxilary columns mapped to resolutions:</strong>  Chunk entity resolver and sentence entity resolver now returns auxilary data that is mapped the resolutions during training. This will allow users to get multiple resolutions with single model without using any other annotator in the pipeline (In order to get billable codes otherwise there needs to be other modules in the same pipeline)</p>

<p><strong>Example:</strong></p>

<p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented_billable_hcc</code>
<strong>Input Text:</strong> <em>“bladder cancer”</em></p>

<table>
  <thead>
    <tr>
      <th>idx</th>
      <th>chunks</th>
      <th>code</th>
      <th>resolutions</th>
      <th>all_codes</th>
      <th>billable</th>
      <th>hcc_status</th>
      <th>hcc_score</th>
      <th>all_distances</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>bladder cancer</td>
      <td>C679</td>
      <td>[‘bladder cancer’, ‘suspected bladder cancer’, ‘cancer in situ of urinary bladder’, ‘tumor of bladder neck’, ‘malignant tumour of bladder neck’]</td>
      <td>[‘C679’, ‘Z126’, ‘D090’, ‘D494’, ‘C7911’]</td>
      <td>[‘1’, ‘1’, ‘1’, ‘1’, ‘1’]</td>
      <td>[‘1’, ‘0’, ‘0’, ‘0’, ‘1’]</td>
      <td>[‘11’, ‘0’, ‘0’, ‘0’, ‘8’]</td>
      <td>[‘0.0000’, ‘0.0904’, ‘0.0978’, ‘0.1080’, ‘0.1281’]</td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">sbiobertresolve_cpt_augmented</code><br />
<strong>Input Text:</strong> <em>“ct abdomen without contrast”</em></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">idx</th>
      <th style="text-align: right">cpt code</th>
      <th style="text-align: right">distance</th>
      <th style="text-align: left">resolutions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">74150</td>
      <td style="text-align: right">0.0802</td>
      <td style="text-align: left">Computed tomography, abdomen; without contrast material</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">65091</td>
      <td style="text-align: right">0.1312</td>
      <td style="text-align: left">Evisceration of ocular contents; without implant</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">70450</td>
      <td style="text-align: right">0.1323</td>
      <td style="text-align: left">Computed tomography, head or brain; without contrast material</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">74176</td>
      <td style="text-align: right">0.1333</td>
      <td style="text-align: left">Computed tomography, abdomen and pelvis; without contrast material</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">74185</td>
      <td style="text-align: right">0.1343</td>
      <td style="text-align: left">Magnetic resonance imaging without contrast</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: right">77059</td>
      <td style="text-align: right">0.1343</td>
      <td style="text-align: left">Magnetic resonance imaging without contrast</td>
    </tr>
  </tbody>
</table>

<h4 id="8-new-pretrained-clinical-ner-models">8. New Pretrained Clinical NER Models</h4>

<ul>
  <li>NER Radiology
<strong>Input Text:</strong> <em>“Bilateral breast ultrasound was subsequently performed, which demonstrated an ovoid mass measuring approximately 0.5 x 0.5 x 0.4 cm in diameter located within the anteromedial aspect of the left shoulder. This mass demonstrates isoechoic echotexture to the adjacent muscle, with no evidence of internal color flow. This may represent benign fibrous tissue or a lipoma.”</em></li>
</ul>

<table>
  <thead>
    <tr>
      <th>idx</th>
      <th>chunks</th>
      <th>entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Bilateral</td>
      <td>Direction</td>
    </tr>
    <tr>
      <td>1</td>
      <td>breast</td>
      <td>BodyPart</td>
    </tr>
    <tr>
      <td>2</td>
      <td>ultrasound</td>
      <td>ImagingTest</td>
    </tr>
    <tr>
      <td>3</td>
      <td>ovoid mass</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.5 x 0.5 x 0.4</td>
      <td>Measurements</td>
    </tr>
    <tr>
      <td>5</td>
      <td>cm</td>
      <td>Units</td>
    </tr>
    <tr>
      <td>6</td>
      <td>anteromedial aspect</td>
      <td>Direction</td>
    </tr>
    <tr>
      <td>7</td>
      <td>left</td>
      <td>Direction</td>
    </tr>
    <tr>
      <td>8</td>
      <td>shoulder</td>
      <td>BodyPart</td>
    </tr>
    <tr>
      <td>9</td>
      <td>mass</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>10</td>
      <td>isoechoic echotexture</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>11</td>
      <td>muscle</td>
      <td>BodyPart</td>
    </tr>
    <tr>
      <td>12</td>
      <td>internal color flow</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>13</td>
      <td>benign fibrous tissue</td>
      <td>ImagingFindings</td>
    </tr>
    <tr>
      <td>14</td>
      <td>lipoma</td>
      <td>Disease_Syndrome_Disorder</td>
    </tr>
  </tbody>
</table>

<h3 id="272">2.7.2</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.2 has been released !</p>

<p>In this release, we introduce the following features:</p>

<ul>
  <li>
    <p>Far better accuracy for resolving medication terms to RxNorm codes:</p>

    <p><code class="language-plaintext highlighter-rouge">ondansetron 8 mg tablet' -&gt; '312086</code></p>
  </li>
  <li>
    <p>Far better accuracy for resolving diagnosis terms to ICD-10-CM codes:</p>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">TIA -&gt; transient ischemic attack (disorder)	‘S0690’</code></p>
<ul>
  <li>
    <p>New ability to map medications to pharmacological actions (PA):</p>

    <p><code class="language-plaintext highlighter-rouge">'metformin' -&gt; ‘Hypoglycemic Agents’ </code></p>
  </li>
  <li>
    <p>2 new <em>greedy</em> named entity recognition models for medication details:</p>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">ner_drugs_greedy: ‘magnesium hydroxide 100mg/1ml PO’</code></p>

<p>` ner_posology _greedy: ‘12 units of insulin lispro’ `</p>

<ul>
  <li>New model to <em>classify the gender</em> of a patient in a given medical note:</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">'58yo patient with a family history of breast cancer' -&gt; ‘female’ </code></p>
<ul>
  <li>And starting customized spark sessions with rich parameters</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">"spark.driver.memory"</span><span class="p">:</span><span class="s">"32G"</span><span class="p">,</span>
        <span class="s">"spark.kryoserializer.buffer.max"</span><span class="p">:</span><span class="s">"2000M"</span><span class="p">,</span>
        <span class="s">"spark.driver.maxResultSize"</span><span class="p">:</span><span class="s">"2000M"</span><span class="p">}</span>

        <span class="n">spark</span> <span class="o">=</span> <span class="n">sparknlp_jsl</span><span class="p">.</span><span class="n">start</span><span class="p">(</span><span class="n">secret</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
</code></pre></div></div>
<p>State-of-the-art accuracy is achieved using new healthcare-tuned BERT Sentence Embeddings (s-Bert). The following sections include more details, metrics, and examples.</p>

<h4 id="named-entity-recognizers-for-medications">Named Entity Recognizers for Medications</h4>

<ul>
  <li>A new medication NER (<code class="language-plaintext highlighter-rouge">ner_drugs_greedy</code>) that joins the drug entities with neighboring entities such as  <code class="language-plaintext highlighter-rouge">dosage</code>, <code class="language-plaintext highlighter-rouge">route</code>, <code class="language-plaintext highlighter-rouge">form</code> and <code class="language-plaintext highlighter-rouge">strength</code>; and returns a single entity <code class="language-plaintext highlighter-rouge">drug</code>.  This greedy NER model would be highly useful if you want to extract a drug with its context and then use it to get a RxNorm code (drugs may get different RxNorm codes based on the dosage and strength information).</li>
</ul>

<h6 id="metrics">Metrics</h6>

<table>
  <thead>
    <tr>
      <th>label</th>
      <th>tp</th>
      <th>fp</th>
      <th>fn</th>
      <th>prec</th>
      <th>rec</th>
      <th>f1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I-DRUG</td>
      <td>37423</td>
      <td>4179</td>
      <td>3773</td>
      <td>0.899</td>
      <td>0.908</td>
      <td>0.904</td>
    </tr>
    <tr>
      <td>B-DRUG</td>
      <td>29699</td>
      <td>2090</td>
      <td>1983</td>
      <td>0.934</td>
      <td>0.937</td>
      <td>0.936</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>A new medication NER (<code class="language-plaintext highlighter-rouge">ner_posology_greedy</code>) that joins the drug entities with neighboring entities such as  <code class="language-plaintext highlighter-rouge">dosage</code>, <code class="language-plaintext highlighter-rouge">route</code>, <code class="language-plaintext highlighter-rouge">form</code> and <code class="language-plaintext highlighter-rouge">strength</code>.  It also returns all the other medication entities even if not related to (or joined with) a drug.</li>
</ul>

<p>Now we have five different medication-related NER models. You can see the outputs from each model below:</p>

<p>Text = ‘‘<em>The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.</em>’’</p>

<p>a. <strong>ner_drugs_greedy</strong></p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>chunks</th>
      <th>begin</th>
      <th>end</th>
      <th>entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1 capsule of Advil 10 mg</td>
      <td>27</td>
      <td>50</td>
      <td>DRUG</td>
    </tr>
    <tr>
      <td>1</td>
      <td>magnesium hydroxide 100mg/1ml PO</td>
      <td>67</td>
      <td>98</td>
      <td>DRUG</td>
    </tr>
    <tr>
      <td>2</td>
      <td>40 units of insulin glargine</td>
      <td>168</td>
      <td>195</td>
      <td>DRUG</td>
    </tr>
    <tr>
      <td>3</td>
      <td>12 units of insulin lispro</td>
      <td>207</td>
      <td>232</td>
      <td>DRUG</td>
    </tr>
  </tbody>
</table>

<p>b. <strong>ner_posology_greedy</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">1 capsule of Advil 10 mg</td>
      <td style="text-align: right">27</td>
      <td style="text-align: right">50</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">magnesium hydroxide 100mg/1ml PO</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">98</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">for 5 days</td>
      <td style="text-align: right">52</td>
      <td style="text-align: right">61</td>
      <td style="text-align: left">DURATION</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">40 units of insulin glargine</td>
      <td style="text-align: right">168</td>
      <td style="text-align: right">195</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">at night</td>
      <td style="text-align: right">197</td>
      <td style="text-align: right">204</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">12 units of insulin lispro</td>
      <td style="text-align: right">207</td>
      <td style="text-align: right">232</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">with meals</td>
      <td style="text-align: right">234</td>
      <td style="text-align: right">243</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">metformin 1000 mg</td>
      <td style="text-align: right">250</td>
      <td style="text-align: right">266</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">two times a day</td>
      <td style="text-align: right">268</td>
      <td style="text-align: right">282</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
  </tbody>
</table>

<p>c. <strong>ner_drugs</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Advil</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">44</td>
      <td style="text-align: left">DrugChem</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">magnesium hydroxide</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">85</td>
      <td style="text-align: left">DrugChem</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">metformin</td>
      <td style="text-align: right">261</td>
      <td style="text-align: right">269</td>
      <td style="text-align: left">DrugChem</td>
    </tr>
  </tbody>
</table>

<p>d.<strong>ner_posology</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">1</td>
      <td style="text-align: right">27</td>
      <td style="text-align: right">27</td>
      <td style="text-align: left">DOSAGE</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">capsule</td>
      <td style="text-align: right">29</td>
      <td style="text-align: right">35</td>
      <td style="text-align: left">FORM</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">Advil</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">44</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">10 mg</td>
      <td style="text-align: right">46</td>
      <td style="text-align: right">50</td>
      <td style="text-align: left">STRENGTH</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">for 5 days</td>
      <td style="text-align: right">52</td>
      <td style="text-align: right">61</td>
      <td style="text-align: left">DURATION</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">magnesium hydroxide</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">85</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">100mg/1ml</td>
      <td style="text-align: right">87</td>
      <td style="text-align: right">95</td>
      <td style="text-align: left">STRENGTH</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">PO</td>
      <td style="text-align: right">97</td>
      <td style="text-align: right">98</td>
      <td style="text-align: left">ROUTE</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">40 units</td>
      <td style="text-align: right">168</td>
      <td style="text-align: right">175</td>
      <td style="text-align: left">DOSAGE</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">insulin glargine</td>
      <td style="text-align: right">180</td>
      <td style="text-align: right">195</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: left">at night</td>
      <td style="text-align: right">197</td>
      <td style="text-align: right">204</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: left">12 units</td>
      <td style="text-align: right">207</td>
      <td style="text-align: right">214</td>
      <td style="text-align: left">DOSAGE</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: left">insulin lispro</td>
      <td style="text-align: right">219</td>
      <td style="text-align: right">232</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">13</td>
      <td style="text-align: left">with meals</td>
      <td style="text-align: right">234</td>
      <td style="text-align: right">243</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
    <tr>
      <td style="text-align: right">14</td>
      <td style="text-align: left">metformin</td>
      <td style="text-align: right">250</td>
      <td style="text-align: right">258</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">15</td>
      <td style="text-align: left">1000 mg</td>
      <td style="text-align: right">260</td>
      <td style="text-align: right">266</td>
      <td style="text-align: left">STRENGTH</td>
    </tr>
    <tr>
      <td style="text-align: right">16</td>
      <td style="text-align: left">two times a day</td>
      <td style="text-align: right">268</td>
      <td style="text-align: right">282</td>
      <td style="text-align: left">FREQUENCY</td>
    </tr>
  </tbody>
</table>

<p>e. <strong>ner_drugs_large</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">entities</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Advil 10 mg</td>
      <td style="text-align: right">40</td>
      <td style="text-align: right">50</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">magnesium hydroxide 100mg/1ml PO.</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">99</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">insulin glargine</td>
      <td style="text-align: right">180</td>
      <td style="text-align: right">195</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">insulin lispro</td>
      <td style="text-align: right">219</td>
      <td style="text-align: right">232</td>
      <td style="text-align: left">DRUG</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">metformin 1000 mg</td>
      <td style="text-align: right">250</td>
      <td style="text-align: right">266</td>
      <td style="text-align: left">DRUG</td>
    </tr>
  </tbody>
</table>

<h4 id="patient-gender-classification">Patient Gender Classification</h4>

<p>This model detects the gender of the patient in the clinical document. It can classify the documents into <code class="language-plaintext highlighter-rouge">Female</code>, <code class="language-plaintext highlighter-rouge">Male</code> and <code class="language-plaintext highlighter-rouge">Unknown</code>.</p>

<p>We release two models:</p>

<ul>
  <li>
    <p>‘Classifierdl_gender_sbert’ (more accurate, works with licensed <code class="language-plaintext highlighter-rouge">sbiobert_base_cased_mli</code>)</p>
  </li>
  <li>
    <p>‘Classifierdl_gender_biobert’ (works with <code class="language-plaintext highlighter-rouge">biobert_pubmed_base_cased</code>)</p>
  </li>
</ul>

<p>The models are trained on more than four thousands clinical documents (radiology reports, pathology reports, clinical visits etc.), annotated internally.</p>

<h6 id="metrics-classifierdl_gender_sbert">Metrics <code class="language-plaintext highlighter-rouge">(Classifierdl_gender_sbert)</code></h6>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>precision</th>
      <th>recall</th>
      <th>f1-score</th>
      <th>support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Female</td>
      <td>0.9224</td>
      <td>0.8954</td>
      <td>0.9087</td>
      <td>239</td>
    </tr>
    <tr>
      <td>Male</td>
      <td>0.7895</td>
      <td>0.8468</td>
      <td>0.8171</td>
      <td>124</td>
    </tr>
  </tbody>
</table>

<p>Text= ‘‘<em>social history: shows that  does not smoke cigarettes or drink alcohol, lives in a nursing home.
family history: shows a family history of breast cancer.</em>’’</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gender_classifier</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="p">)[</span><span class="s">'class'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="o">&gt;&gt;</span> <span class="sb">`Female`</span>
</code></pre></div></div>

<p>See this <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/21_Gender_Classifier.ipynb">Colab</a> notebook for further details.</p>

<p>a. <strong>classifierdl_gender_sbert</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">gender_classifier</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'classifierdl_gender_sbert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">gender_pred_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
       <span class="n">document</span><span class="p">,</span>
       <span class="n">sbert_embedder</span><span class="p">,</span>
       <span class="n">gender_classifier</span>
            <span class="p">])</span>
</code></pre></div></div>
<p>b. <strong>classifierdl_gender_biobert</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">clf_tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="n">biobert_embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'biobert_pubmed_base_cased'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">'token'</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">biobert_embeddings_avg</span> <span class="o">=</span> <span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_bert_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">genderClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'classifierdl_gender_biobert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"sentence_bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"gender"</span><span class="p">)</span>

<span class="n">gender_pred_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
   <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
       <span class="n">documentAssembler</span><span class="p">,</span>
       <span class="n">clf_tokenizer</span><span class="p">,</span>
       <span class="n">biobert_embeddings</span><span class="p">,</span>
       <span class="n">biobert_embeddings_avg</span><span class="p">,</span>
       <span class="n">genderClassifier</span>
   <span class="p">])</span>

</code></pre></div></div>
<h4 id="new-icd10cm-and-rxcui-resolvers-powered-by-s-bert-embeddings">New ICD10CM and RxCUI resolvers powered by s-Bert embeddings</h4>

<p>The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on <a href="https://physionet.org/content/mednli/">MedNLI</a> (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before.</p>

<p>We now release two new resolvers:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_icd10cm_augmented</code> (augmented with synonyms, four times richer than previous resolver accuracy:</p>

    <p><code class="language-plaintext highlighter-rouge">73% for top-1 (exact match), 89% for top-5 (previous accuracy was 59% and 64% respectively)</code></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sbiobertresolve_rxcui</code> (extract RxNorm concept unique identifiers to map with ATC or durg families)
accuracy:</p>

    <p><code class="language-plaintext highlighter-rouge">71% for top-1 (exact match), 72% for top-5
(previous accuracy was 22% and 41% respectively)</code></p>
  </li>
</ul>

<p>a. <strong>ICD10CM augmented resolver</strong></p>

<p>Text = “<em>This is an 82 year old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret's Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .</em> “</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">code</th>
      <th style="text-align: left">term</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">hypertension</td>
      <td style="text-align: right">66</td>
      <td style="text-align: right">77</td>
      <td style="text-align: left">I10</td>
      <td style="text-align: left">hypertension</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">chronic renal insufficiency</td>
      <td style="text-align: right">81</td>
      <td style="text-align: right">107</td>
      <td style="text-align: left">N189</td>
      <td style="text-align: left">chronic renal insufficiency</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">COPD</td>
      <td style="text-align: right">111</td>
      <td style="text-align: right">114</td>
      <td style="text-align: left">J449</td>
      <td style="text-align: left">copd - chronic obstructive pulmonary disease</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">gastritis</td>
      <td style="text-align: right">118</td>
      <td style="text-align: right">126</td>
      <td style="text-align: left">K2970</td>
      <td style="text-align: left">gastritis</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">TIA</td>
      <td style="text-align: right">134</td>
      <td style="text-align: right">136</td>
      <td style="text-align: left">S0690</td>
      <td style="text-align: left">transient ischemic attack (disorder)</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">a non-ST elevation MI</td>
      <td style="text-align: right">180</td>
      <td style="text-align: right">200</td>
      <td style="text-align: left">I219</td>
      <td style="text-align: left">silent myocardial infarction (disorder)</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">Guaiac positive stools</td>
      <td style="text-align: right">206</td>
      <td style="text-align: right">227</td>
      <td style="text-align: left">K921</td>
      <td style="text-align: left">guaiac-positive stools</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">mid LAD lesion</td>
      <td style="text-align: right">330</td>
      <td style="text-align: right">343</td>
      <td style="text-align: left">I2102</td>
      <td style="text-align: left">stemi involving left anterior descending coronary artery</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">hypotension</td>
      <td style="text-align: right">360</td>
      <td style="text-align: right">370</td>
      <td style="text-align: left">I959</td>
      <td style="text-align: left">hypotension</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">bradycardia</td>
      <td style="text-align: right">376</td>
      <td style="text-align: right">386</td>
      <td style="text-align: left">O9941</td>
      <td style="text-align: left">bradycardia</td>
    </tr>
  </tbody>
</table>

<p>b. <strong>RxCUI resolver</strong></p>

<p>Text= “<em>He was seen by the endocrinology service and she was discharged on 50 mg of eltrombopag oral at night, 5 mg amlodipine with meals, and metformin 1000 mg two times a day .</em> “</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunk</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: right">code</th>
      <th style="text-align: left">term</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">50 mg of eltrombopag oral</td>
      <td style="text-align: right">67</td>
      <td style="text-align: right">91</td>
      <td style="text-align: right">825427</td>
      <td style="text-align: left">eltrombopag 50 MG Oral Tablet</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">5 mg amlodipine</td>
      <td style="text-align: right">103</td>
      <td style="text-align: right">117</td>
      <td style="text-align: right">197361</td>
      <td style="text-align: left">amlodipine 5 MG Oral Tablet</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">metformin 1000 mg</td>
      <td style="text-align: right">135</td>
      <td style="text-align: right">151</td>
      <td style="text-align: right">861004</td>
      <td style="text-align: left">metformin hydrochloride 1000 MG Oral Tablet</td>
    </tr>
  </tbody>
</table>

<p>Using this new resolver and some other resources like Snomed Resolver, RxTerm, MESHPA and ATC dictionary, you can link the drugs to the pharmacological actions (PA), ingredients and the disease treated with that.</p>

<h6 id="code-sample">Code sample:</h6>

<p>(after getting the chunk from ChunkConverter)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">c2doc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="n">icd10_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_icd10cm_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icd10cm_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
</code></pre></div></div>
<p>See the <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb#scrollTo=VtDWAlnDList">notebook</a> for details.</p>

<h3 id="271">2.7.1</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7.1 has been released !</p>

<p>In this release, we introduce the following features:</p>

<h4 id="1-sentence-biobert-and-bluebert-transformers-that-are-fine-tuned-on-mednli-dataset">1. Sentence BioBert and Bluebert Transformers that are fine tuned on <a href="https://physionet.org/content/mednli/">MedNLI</a> dataset.</h4>

<p>Sentence Transformers offers a framework that provides an easy method to compute dense vector representations for sentences and paragraphs (also known as sentence embeddings). The models are based on BioBert and BlueBert, and are tuned specifically to meaningful sentence embeddings such that sentences with similar meanings are close in vector space. These are the first PyTorch based models we managed to port into Spark NLP.</p>

<p>Here is how you can load these:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sbiobert_embeddins</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
     <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sbluebert_embeddins</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
     <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbluebert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="2-sentenceentityresolvers-powered-by-s-bert-embeddings">2. SentenceEntityResolvers powered by s-Bert embeddings.</h4>

<p>The advent of s-Bert sentence embeddings changed the landscape of Clinical Entity Resolvers completely in Spark NLP. Since s-Bert is already tuned on MedNLI (medical natural language inference) dataset, it is now capable of populating the chunk embeddings in a more precise way than before.</p>

<p>Using sbiobert_base_cased_mli, we trained the following Clinical Entity Resolvers:</p>

<p>sbiobertresolve_icd10cm<br />
sbiobertresolve_icd10pcs<br />
sbiobertresolve_snomed_findings (with clinical_findings concepts from CT version)<br />
sbiobertresolve_snomed_findings_int  (with clinical_findings concepts from INT version)<br />
sbiobertresolve_snomed_auxConcepts (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from CT version)<br />
sbiobertresolve_snomed_auxConcepts_int  (with Morph Abnormality, Procedure, Substance, Physical Object, Body Structure concepts from INT version)<br />
sbiobertresolve_rxnorm<br />
sbiobertresolve_icdo<br />
sbiobertresolve_cpt</p>

<p>Code sample:</p>

<p>(after getting the chunk from ChunkConverter)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">c2doc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>
<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
     <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
     <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
     <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="n">snomed_ct_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span>
 <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_snomed_findings"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_ct_code"</span><span class="p">)</span>\
 <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
</code></pre></div></div>

<p>Output:</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td>chunks</td>
      <td>begin</td>
      <td>end</td>
      <td>code</td>
      <td>resolutions</td>
    </tr>
    <tr>
      <td>2</td>
      <td>COPD</td>
      <td>113</td>
      <td>116</td>
      <td>13645005</td>
      <td>copd - chronic obstructive pulmonary disease</td>
    </tr>
    <tr>
      <td>8</td>
      <td>PTCA</td>
      <td>324</td>
      <td>327</td>
      <td>373108000</td>
      <td>post percutaneous transluminal coronary angioplasty (finding)</td>
    </tr>
    <tr>
      <td>16</td>
      <td>close monitoring</td>
      <td>519</td>
      <td>534</td>
      <td>417014005</td>
      <td>on examination - vigilance</td>
    </tr>
  </tbody>
</table>

<p>See the <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/3.Clinical_Entity_Resolvers.ipynb#scrollTo=VtDWAlnDList">notebook</a> for details.</p>

<h4 id="3-we-are-releasing-the-following-pretrained-clinical-ner-models">3. We are releasing the following pretrained clinical NER models:</h4>

<p>ner_drugs_large <br />
(trained with medications dataset, and extracts drugs with the dosage, strength, form and route at once as a single entity; entities: drug)<br />
ner_deid_sd_large<br />
(extracts PHI entities, trained with augmented dataset)<br />
ner_anatomy_coarse<br />
(trained with enriched anatomy NER dataset; entities: anatomy)<br />
ner_anatomy_coarse_biobert<br />
chunkresolve_ICD10GM_2021 (German ICD10GM resolver)</p>

<p>We are also releasing two new NER models:</p>

<p>ner_aspect_based_sentiment<br />
(extracts positive, negative and neutral aspects about restaurants from the written feedback given by reviewers. )<br />
ner_financial_contract<br />
(extract financial entities from contracts. See the <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/19.Financial_Contract_NER.ipynb">notebook</a> for details.)</p>

<h3 id="270">2.7.0</h3>

<p>We are glad to announce that Spark NLP for Healthcare 2.7 has been released !</p>

<p>In this release, we introduce the following features:</p>

<h4 id="1-text2sql">1. Text2SQL</h4>

<p>Text2SQL Annotator that translates natural language text into SQL queries against a predefined database schema, which is one of the
most sought-after features of NLU. With the help of a pretrained text2SQL model, you will be able to query your database without writing a SQL query:</p>

<p>Example 1</p>

<p>Query:
What is the name of the nurse who has the most appointments?</p>

<p>Generated
SQL query from the model:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">T1</span><span class="p">.</span><span class="n">Name</span>  
<span class="k">FROM</span> <span class="n">Nurse</span> <span class="k">AS</span> <span class="n">T1</span>  
<span class="k">JOIN</span> <span class="n">Appointment</span> <span class="k">AS</span> <span class="n">T2</span> <span class="k">ON</span> <span class="n">T1</span><span class="p">.</span><span class="n">EmployeeID</span> <span class="o">=</span> <span class="n">T2</span><span class="p">.</span><span class="n">PrepNurse</span>  
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">T2</span><span class="p">.</span><span class="n">prepnurse</span>  
<span class="k">ORDER</span> <span class="k">BY</span> <span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">DESC</span>  
<span class="k">LIMIT</span> <span class="mi">1</span>  
</code></pre></div></div>

<p>Response:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Carla Espinosa</td>
    </tr>
  </tbody>
</table>

<p>Example 2</p>

<p>Query:
How many patients do each physician take care of? List their names and number of patients they take care of.</p>

<p>Generated
SQL query from the model:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">T1</span><span class="p">.</span><span class="n">Name</span><span class="p">,</span>  
<span class="k">count</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>  
<span class="k">FROM</span> <span class="n">Physician</span> <span class="k">AS</span> <span class="n">T1</span>  
<span class="k">JOIN</span> <span class="n">Patient</span> <span class="k">AS</span> <span class="n">T2</span> <span class="k">ON</span> <span class="n">T1</span><span class="p">.</span><span class="n">EmployeeID</span> <span class="o">=</span> <span class="n">T2</span><span class="p">.</span><span class="n">PCP</span>  
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">T1</span><span class="p">.</span><span class="n">Name</span>  
</code></pre></div></div>

<p>Response:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">Name</th>
      <th style="text-align: right">count(*)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">Christopher Turk</td>
      <td style="text-align: right">1</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">Elliot Reid</td>
      <td style="text-align: right">2</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">John Dorian</td>
      <td style="text-align: right">1</td>
    </tr>
  </tbody>
</table>

<p>For now, it only comes with one pretrained model (trained on Spider
dataset) and new pretrained models will be released soon.</p>

<p>Check out the
Colab notebook to  see more examples and run on your data.</p>

<h4 id="2-sentenceentityresolvers">2. SentenceEntityResolvers</h4>

<p>In addition to ChunkEntityResolvers, we now release our first BioBert-based entity resolvers using the SentenceEntityResolver
annotator. It’s
fully trainable and comes with several pretrained entity resolvers for the following medical terminologies:</p>

<p>CPT: <code class="language-plaintext highlighter-rouge">biobertresolve_cpt</code><br />
ICDO: <code class="language-plaintext highlighter-rouge">biobertresolve_icdo</code><br />
ICD10CM: <code class="language-plaintext highlighter-rouge">biobertresolve_icd10cm</code><br />
ICD10PCS: <code class="language-plaintext highlighter-rouge">biobertresolve_icd10pcs</code><br />
LOINC: <code class="language-plaintext highlighter-rouge">biobertresolve_loinc</code><br />
SNOMED_CT (findings): <code class="language-plaintext highlighter-rouge">biobertresolve_snomed_findings</code><br />
SNOMED_INT (clinical_findings): <code class="language-plaintext highlighter-rouge">biobertresolve_snomed_findings_int</code>  <br />
RXNORM (branded and clinical drugs): <code class="language-plaintext highlighter-rouge">biobertresolve_rxnorm_bdcd</code></p>

<p>Example:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="s">'He has a starvation ketosis but nothing significant for dry oral mucosa'</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">get_icd10_codes</span> <span class="p">(</span><span class="n">light_pipeline_icd10</span><span class="p">,</span> <span class="s">'icd10cm_code'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">chunks</th>
      <th style="text-align: right">begin</th>
      <th style="text-align: right">end</th>
      <th style="text-align: left">code</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">a starvation ketosis</td>
      <td style="text-align: right">7</td>
      <td style="text-align: right">26</td>
      <td style="text-align: left">E71121</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">dry oral mucosa</td>
      <td style="text-align: right">66</td>
      <td style="text-align: right">80</td>
      <td style="text-align: left">K136</td>
    </tr>
  </tbody>
</table>

<p>Check out the Colab notebook to  see more examples and run on your data.</p>

<p>You can also train your own entity resolver using any medical terminology like MedRa and UMLS. Check this notebook to
learn more about training from scratch.</p>

<h4 id="3-chunkmerge-annotator">3. ChunkMerge Annotator</h4>

<p>In order to use multiple NER models in the same pipeline, Spark NLP Healthcare has ChunkMerge Annotator that is used to return entities from each NER
model by overlapping. Now it has a new parameter to avoid merging overlapping entities (setMergeOverlapping)
to return all the entities regardless of char indices. It will be quite useful to analyze what every NER module returns on the same text.</p>

<h4 id="4-starting-sparksession">4. Starting SparkSession</h4>

<p>We now support starting SparkSession with a different version of the open source jar and not only the one it was built
against by <code class="language-plaintext highlighter-rouge">sparknlp_jsl.start(secret, public="x.x.x")</code> for extreme cases.</p>

<h4 id="5-biomedical-ners">5. Biomedical NERs</h4>

<p>We are releasing 3 new biomedical NER models trained with clinical embeddings (all one single entity models)</p>

<p><code class="language-plaintext highlighter-rouge">ner_bacterial_species</code> (comprising of Linneaus and Species800 datasets)<br />
<code class="language-plaintext highlighter-rouge">ner_chemicals</code> (general purpose and bio chemicals, comprising of BC4Chem and BN5CDR-Chem)<br />
<code class="language-plaintext highlighter-rouge">ner_diseases_large</code> (comprising of ner_disease, NCBI_Disease and BN5CDR-Disease)</p>

<p>We are also releasing the biobert versions of the several clinical NER models stated below:<br />
<code class="language-plaintext highlighter-rouge">ner_clinical_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_anatomy_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_bionlp_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_cellular_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_deid_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_diseases_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_events_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_jsl_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_chemprot_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_human_phenotype_gene_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_human_phenotype_go_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_posology_biobert</code><br />
<code class="language-plaintext highlighter-rouge">ner_risk_factors_biobert</code></p>

<p>Metrics (micro averages excluding O’s):</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right"> </th>
      <th style="text-align: left">model_name</th>
      <th style="text-align: right">clinical_glove_micro</th>
      <th style="text-align: right">biobert_micro</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: left">ner_chemprot_clinical</td>
      <td style="text-align: right">0.816</td>
      <td style="text-align: right">0.803</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: left">ner_bionlp</td>
      <td style="text-align: right">0.748</td>
      <td style="text-align: right">0.808</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: left">ner_deid_enriched</td>
      <td style="text-align: right">0.934</td>
      <td style="text-align: right">0.918</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: left">ner_posology</td>
      <td style="text-align: right">0.915</td>
      <td style="text-align: right">0.911</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: left">ner_events_clinical</td>
      <td style="text-align: right">0.801</td>
      <td style="text-align: right">0.809</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: left">ner_clinical</td>
      <td style="text-align: right">0.873</td>
      <td style="text-align: right">0.884</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: left">ner_posology_small</td>
      <td style="text-align: right">0.941</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: left">ner_human_phenotype_go_clinical</td>
      <td style="text-align: right">0.922</td>
      <td style="text-align: right">0.932</td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: left">ner_drugs</td>
      <td style="text-align: right">0.964</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: left">ner_human_phenotype_gene_clinical</td>
      <td style="text-align: right">0.876</td>
      <td style="text-align: right">0.870</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: left">ner_risk_factors</td>
      <td style="text-align: right">0.728</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: left">ner_cellular</td>
      <td style="text-align: right">0.813</td>
      <td style="text-align: right">0.812</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: left">ner_posology_large</td>
      <td style="text-align: right">0.921</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">13</td>
      <td style="text-align: left">ner_anatomy</td>
      <td style="text-align: right">0.851</td>
      <td style="text-align: right">0.831</td>
    </tr>
    <tr>
      <td style="text-align: right">14</td>
      <td style="text-align: left">ner_deid_large</td>
      <td style="text-align: right">0.942</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">15</td>
      <td style="text-align: left">ner_diseases</td>
      <td style="text-align: right">0.960</td>
      <td style="text-align: right">0.966</td>
    </tr>
  </tbody>
</table>

<p>In addition to these, we release two new German NER models:</p>

<p><code class="language-plaintext highlighter-rouge">ner_healthcare_slim</code> (‘TIME_INFORMATION’, ‘MEDICAL_CONDITION’,  ‘BODY_PART’,  ‘TREATMENT’, ‘PERSON’, ‘BODY_PART’)<br />
<code class="language-plaintext highlighter-rouge">ner_traffic</code> (extract entities regarding traffic accidents e.g. date, trigger, location etc.)</p>

<h4 id="6-pico-classifier">6. PICO Classifier</h4>

<p>Successful evidence-based medicine (EBM) applications rely on answering clinical questions by analyzing large medical literature databases. In order to formulate
a well-defined, focused clinical question, a framework called PICO is widely used, which identifies the sentences in a given medical text that belong to the four components: Participants/Problem (P)  (e.g., diabetic patients), Intervention (I) (e.g., insulin),
Comparison (C) (e.g., placebo)  and Outcome (O) (e.g., blood glucose levels).</p>

<p>Spark NLP now introduces a pretrained PICO Classifier that
is trained with Biobert embeddings.</p>

<p>Example:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span> <span class="o">=</span> <span class="err">“</span><span class="n">There</span> <span class="n">appears</span> <span class="n">to</span> <span class="n">be</span> <span class="n">no</span> <span class="n">difference</span> <span class="ow">in</span> <span class="n">smoking</span> <span class="n">cessation</span> <span class="n">effectiveness</span> <span class="n">between</span> <span class="mi">1</span><span class="n">mg</span> <span class="ow">and</span> <span class="mf">0.5</span><span class="n">mg</span> <span class="n">varenicline</span><span class="p">.</span><span class="err">”</span>
<span class="n">pico_lp_pipeline</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="p">)[</span><span class="s">'class'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ans</span><span class="p">:</span> <span class="n">CONCLUSIONS</span>
</code></pre></div></div>

<h3 id="262">2.6.2</h3>

<h4 id="overview">Overview</h4>
<p>We are very happy to announce that version 2.6.2 of Spark NLP Enterprise is ready to be installed and used.
We are making available Named Entity Recognition, Sentence Classification and Entity Resolution models to analyze Adverse Drug Events in natural language text from clinical domains.</p>

<h4 id="models">Models</h4>

<h5 id="ners">NERs</h5>
<p>We are pleased to announce that we have a brand new named entity recognition (NER) model for Adverse Drug Events (ADE) to extract ADE and DRUG entities from a given text.</p>

<p>ADE NER will have four versions in the library, trained with different size of word embeddings:</p>

<p><code class="language-plaintext highlighter-rouge">ner_ade_bioert</code> (768d Bert embeddings)<br />
<code class="language-plaintext highlighter-rouge">ner_ade_clinicalbert</code> (768d Bert embeddings)<br />
<code class="language-plaintext highlighter-rouge">ner_ade_clinical</code> (200d clinical embeddings)<br />
<code class="language-plaintext highlighter-rouge">ner_ade_healthcare</code> (100d healthcare embeddings)</p>

<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/16.Adverse_Drug_Event_ADE_NER_and_Classifier.ipynb">here</a></p>

<p>We are also releasing our first clinical pretrained classifier for ADE classification tasks. This new ADE classifier is trained on various ADE datasets, including the mentions in tweets to represent the daily life conversations as well. So it works well on the texts coming from academic context, social media and clinical notes. It’s trained with <code class="language-plaintext highlighter-rouge">Clinical Biobert</code> embeddings, which is the most powerful contextual language model in the clinical domain out there.</p>

<h5 id="classifiers">Classifiers</h5>
<p>ADE classifier will have two versions in the library, trained with different Bert embeddings:</p>

<p><code class="language-plaintext highlighter-rouge">classifierdl_ade_bioert</code> (768d BioBert embeddings)<br />
<code class="language-plaintext highlighter-rouge">classifierdl_adee_clinicalbert</code> (768d ClinicalBert embeddings)</p>

<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/16.Adverse_Drug_Event_ADE_NER_and_Classifier.ipynb">here</a></p>

<h5 id="pipeline">Pipeline</h5>
<p>By combining ADE NER and Classifier, we are releasing a new pretrained clinical pipeline for ADE tasks to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">'explain_clinical_doc_ade'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>

<span class="n">pipeline</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'my string'</span><span class="p">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">explain_clinical_doc_ade</code> is bundled with <code class="language-plaintext highlighter-rouge">ner_ade_clinicalBert</code>, and <code class="language-plaintext highlighter-rouge">classifierdl_ade_clinicalBert</code>. It can extract ADE and DRUG clinical entities, and then assign ADE status to a text (<code class="language-plaintext highlighter-rouge">True</code> means ADE, <code class="language-plaintext highlighter-rouge">False</code> means not related to ADE).</p>

<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb">here</a></p>

<h5 id="entity-resolver">Entity Resolver</h5>
<p>We are releasing the first Entity Resolver for <code class="language-plaintext highlighter-rouge">Athena</code> (Automated Terminology Harmonization, Extraction and Normalization for Analytics, http://athena.ohdsi.org/) to extract concept ids via standardized medical vocabularies. For now, it only supports <code class="language-plaintext highlighter-rouge">conditions</code> section and can be used to map the clinical conditions with the corresponding standard terminology and then get the concept ids to store them in various database schemas.
It is named as <code class="language-plaintext highlighter-rouge">chunkresolve_athena_conditions_healthcare</code>.</p>

<p>We added slim versions of several clinical NER models that are trained with 100d healthcare word embeddings, which is lighter and smaller in size.</p>

<p><code class="language-plaintext highlighter-rouge">ner_healthcare</code>
<code class="language-plaintext highlighter-rouge">assertion_dl_healthcare</code>
<code class="language-plaintext highlighter-rouge">ner_posology_healthcare</code>
<code class="language-plaintext highlighter-rouge">ner_events_healthcare</code></p>

<h5 id="graph-builder">Graph Builder</h5>
<p>Spark NLP Licensed version has several DL based annotators (modules) such as NerDL, AssertionDL, RelationExtraction and GenericClassifier, and they are all based on Tensorflow (tf) with custom graphs. In order to make the creating and customizing the tf graphs for these models easier for our licensed users, we added a graph builder to the Python side of the library. Now you can customize your graphs and use them in the respected models while training a new DL model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp_jsl.training</span> <span class="kn">import</span> <span class="n">tf_graph</span>

<span class="n">tf_graph</span><span class="p">.</span><span class="n">build</span><span class="p">(</span><span class="s">"relation_extraction"</span><span class="p">,</span><span class="n">build_params</span><span class="o">=</span><span class="p">{</span><span class="s">"input_dim"</span><span class="p">:</span> <span class="mi">6000</span><span class="p">,</span> <span class="s">"output_dim"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'batch_norm'</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"hidden_layers"</span><span class="p">:</span> <span class="p">[</span><span class="mi">300</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s">"hidden_act"</span><span class="p">:</span> <span class="s">"relu"</span><span class="p">,</span> <span class="s">'hidden_act_l2'</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">model_location</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">model_filename</span><span class="o">=</span><span class="s">"re_with_BN"</span><span class="p">)</span>
</code></pre></div></div>
<p>More information and examples <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb">here</a></p>

<h3 id="260">2.6.0</h3>

<h4 id="overview-1">Overview</h4>

<p>We are honored to announce that Spark NLP Enterprise 2.6.0 has been released.
The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch. Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases.
The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="models-1">Models</h4>

<h5 id="pretrained-pipelines">Pretrained Pipelines:</h5>

<p>The first time ever, we release three pretrained clinical pipelines to save you from building pipelines from scratch.
Pretrained pipelines are already fitted using certain annotators and transformers according to various use cases and you can use them as easy as follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">'explain_clinical_doc_carp'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>

<span class="n">pipeline</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">'my string'</span><span class="p">)</span>
</code></pre></div></div>

<p>Pipeline descriptions:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">explain_clinical_doc_carp</code> a pipeline with ner_clinical, assertion_dl, re_clinical and ner_posology. It will extract clinical and medication entities, assign assertion status and find relationships between clinical entities.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">explain_clinical_doc_era</code> a pipeline with ner_clinical_events, assertion_dl and re_temporal_events_clinical. It will extract clinical entities, assign assertion status and find temporal relationships between clinical entities.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">recognize_entities_posology</code> a pipeline with ner_posology. It will only extract medication entities.</p>
  </li>
</ul>

<p>More information and examples are available here: https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.Pretrained_Clinical_Pipelines.ipynb.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="pretrained-named-entity-recognition-and-relationship-extraction-models-english">Pretrained Named Entity Recognition and Relationship Extraction Models (English)</h4>

<p>RE models:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>re_temporal_events_clinical
re_temporal_events_enriched_clinical
re_human_phenotype_gene_clinical
re_drug_drug_interaction_clinical
re_chemprot_clinical
</code></pre></div></div>
<p>NER models:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ner_human_phenotype_gene_clinical
ner_human_phenotype_go_clinical
ner_chemprot_clinical
</code></pre></div></div>
<p>More information and examples here:
https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.Clinical_Relation_Extraction.ipynb</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="pretrained-named-entity-recognition-and-relationship-extraction-models-german">Pretrained Named Entity Recognition and Relationship Extraction Models (German)</h4>

<p>The first time ever, we are releasing 3 licensed German models for healthcare and Legal domains.</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">German Clinical NER</code> model for 19 clinical entities</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">German Legal NER</code> model for 19 legal entities</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">German ICD-10GM</code></p>
  </li>
</ul>

<p>More information and examples here:</p>

<p>https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/14.German_Healthcare_Models.ipynb</p>

<p>https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/15.German_Legal_Model.ipynb</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="other-pretrained-models">Other Pretrained Models</h4>

<p>We now have Named Entity Disambiguation model out of the box.</p>

<p>Disambiguation models map words of interest, such as names of persons, locations and companies, from an input text document to corresponding unique entities in a target Knowledge Base (KB).</p>

<p>https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/12.Named_Entity_Disambiguation.ipynb</p>

<p>Due to ongoing requests about Clinical Entity Resolvers, we release a notebook to let you see how to train an entity resolver using an open source dataset based on Snomed.</p>

<p>https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/13.Snomed_Entity_Resolver_Model_Training.ipynb</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="255">2.5.5</h3>

<h4 id="overview-2">Overview</h4>

<p>We are very happy to release Spark NLP for Healthcare 2.5.5 with a new state-of-the-art RelationExtraction annotator to identify relationships between entities coming from our pretrained NER models.
This is also the first release to support Relation Extraction with the following two (2) models: <code class="language-plaintext highlighter-rouge">re_clinical</code> and <code class="language-plaintext highlighter-rouge">re_posology</code> in the <code class="language-plaintext highlighter-rouge">clinical/models</code> repository.
We also include multiple bug fixes as usual.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-1">New Features</h4>

<ul>
  <li>RelationExtraction annotator that receives <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code>, <code class="language-plaintext highlighter-rouge">POS</code>, <code class="language-plaintext highlighter-rouge">CHUNK</code>, <code class="language-plaintext highlighter-rouge">DEPENDENCY</code> and returns the CATEGORY of the relationship and a confidence score.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements">Enhancements</h4>

<ul>
  <li>AssertionDL Annotator now keeps logs of the metrics while training</li>
  <li>DeIdentification now has a default behavior of merging entities close in Levenshtein distance with <code class="language-plaintext highlighter-rouge">setConsistentObfuscation</code> and <code class="language-plaintext highlighter-rouge">setSameEntityThreshold</code> params.</li>
  <li>DeIdentification now has a specific parameter <code class="language-plaintext highlighter-rouge">setObfuscateDate</code> to obfuscate dates (which will be otherwise just masked). The only formats obfuscated when the param is true will be the ones present in <code class="language-plaintext highlighter-rouge">dateFormats</code> param.</li>
  <li>NerConverterInternal now has a <code class="language-plaintext highlighter-rouge">greedyMode</code> param that will merge all contiguous tags of the same type regardless of boundary tags like “B”,”E”,”S”.</li>
  <li>AnnotationToolJsonReader includes <code class="language-plaintext highlighter-rouge">mergeOverlapping</code> parameter to merge (or not) overlapping entities from the Annotator jsons i.e. not included in the assertion list.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes">Bugfixes</h4>

<ul>
  <li>DeIdentification documentation bug fix (typo)</li>
  <li>DeIdentification training bug fix in obfuscation dictionary</li>
  <li>IOBTagger now has the correct output type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="deprecations">Deprecations</h4>

<ul>
  <li>EnsembleEntityResolver has been deprecated</li>
</ul>

<p>Models</p>

<ul>
  <li>We have 2 new <code class="language-plaintext highlighter-rouge">english</code> Relationship Extraction model for Clinical and Posology NERs:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">re_clinical</code>: with <code class="language-plaintext highlighter-rouge">ner_clinical</code> and <code class="language-plaintext highlighter-rouge">embeddings_clinical</code></li>
      <li><code class="language-plaintext highlighter-rouge">re_posology</code>: with <code class="language-plaintext highlighter-rouge">ner_posology</code> and <code class="language-plaintext highlighter-rouge">embeddings_clinical</code></li>
    </ul>
  </li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="253">2.5.3</h3>

<h4 id="overview-3">Overview</h4>

<p>We are pleased to announce the release of Spark NLP for Healthcare 2.5.3.
This time we include four (4) new Annotators: FeatureAssembler, GenericClassifier, Yake Keyword Extractor and NerConverterInternal.
We also include helper classes to read datasets from CodiEsp and Cantemist Spanish NER Challenges.
This is also the first release to support the following models: <code class="language-plaintext highlighter-rouge">ner_diag_proc</code> (spanish), <code class="language-plaintext highlighter-rouge">ner_neoplasms</code> (spanish), <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code> (english).
We have also included Bugifxes and Enhancements for AnnotationToolJsonReader and ChunkMergeModel.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-2">New Features</h4>

<ul>
  <li>FeatureAssembler Transformer: Receives a list of column names containing numerical arrays and concatenates them to form one single <code class="language-plaintext highlighter-rouge">feature_vector</code> annotation</li>
  <li>GenericClassifier Annotator: Receives a <code class="language-plaintext highlighter-rouge">feature_vector</code> annotation and outputs a <code class="language-plaintext highlighter-rouge">category</code> annotation</li>
  <li>Yake Keyword Extraction Annotator: Receives a <code class="language-plaintext highlighter-rouge">token</code> annotation and outputs multi-token <code class="language-plaintext highlighter-rouge">keyword</code> annotations</li>
  <li>NerConverterInternal Annotator: Similar to it’s open source counterpart in functionality, performs smarter extraction for complex tokenizations and confidence calculation</li>
  <li>Readers for CodiEsp and Cantemist Challenges</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-1">Enhancements</h4>

<ul>
  <li>AnnotationToolJsonReader includes parameter for preprocessing pipeline (from Document Assembling to Tokenization)</li>
  <li>AnnotationToolJsonReader includes parameter to discard specific entity types</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-1">Bugfixes</h4>

<ul>
  <li>ChunkMergeModel now prioritizes highest number of different entities when coverage is the same</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="models-2">Models</h4>

<ul>
  <li>We have 2 new <code class="language-plaintext highlighter-rouge">spanish</code> models for Clinical Entity Recognition: <code class="language-plaintext highlighter-rouge">ner_diag_proc</code> and <code class="language-plaintext highlighter-rouge">ner_neoplasms</code></li>
  <li>We have a new <code class="language-plaintext highlighter-rouge">english</code> Named Entity Recognition model for deidentification: <code class="language-plaintext highlighter-rouge">ner_deid_enriched</code></li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="252">2.5.2</h3>

<h4 id="overview-4">Overview</h4>

<p>We are really happy to bring you Spark NLP for Healthcare 2.5.2, with a couple new features and several enhancements in our existing annotators.
This release was mainly dedicated to generate adoption in our AnnotationToolJsonReader, a connector that provide out-of-the-box support for out Annotation Tool and our practices.
Also the ChunkMerge annotator has ben provided with extra functionality to remove entire entity types and to modify some chunk’s entity type
We also dedicated some time in finalizing some refactorization in DeIdentification annotator, mainly improving type consistency and case insensitive entity dictionary for obfuscation.
Thanks to the community for all the feedback and suggestions, it’s really comfortable to navigate together towards common functional goals that keep us agile in the SotA.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-3">New Features</h4>

<ul>
  <li>Brand new IOBTagger Annotator</li>
  <li>NerDL Metrics provides an intuitive DataFrame API to calculate NER metrics at tag (token) and entity (chunk) level</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-2">Enhancements</h4>

<ul>
  <li>AnnotationToolJsonReader includes parameters for document cleanup, sentence boundaries and tokenizer split chars</li>
  <li>AnnotationToolJsonReader uses the task title if present and uses IOBTagger annotator</li>
  <li>AnnotationToolJsonReader has improved alignment in assertion train set generation by using an <code class="language-plaintext highlighter-rouge">alignTol</code> parameter as tollerance in chunk char alignment</li>
  <li>DeIdentification refactorization: Improved typing and replacement logic, case insensitive entities for obfuscation</li>
  <li>ChunkMerge Annotator now handles:</li>
  <li>Drop all chunks for an entity</li>
  <li>Replace entity name</li>
  <li>Change entity type for a specific (chunk, entity) pair</li>
  <li>Drop specific (chunk, entity) pairs</li>
  <li><code class="language-plaintext highlighter-rouge">caseSensitive</code> param to EnsembleEntityResolver</li>
  <li>Output logs for AssertionDLApproach loss</li>
  <li>Disambiguator is back with improved dependency management</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-2">Bugfixes</h4>

<ul>
  <li>Bugfix in python when Annotators shared domain parts across public and internal</li>
  <li>Bugfix in python when ChunkMerge annotator was loaded from disk</li>
  <li>ChunkMerge now weights the token coverage correctly when multiple multi-token entities overlap</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="250">2.5.0</h3>

<h4 id="overview-5">Overview</h4>

<p>We are happy to bring you Spark NLP for Healthcare 2.5.0 with new Annotators, Models and Data Readers.
Model composition and iteration is now faster with readers and annotators designed for real world tasks.
We introduce ChunkMerge annotator to combine all CHUNKS extracted by different Entity Extraction Annotators.
We also introduce an Annotation Reader for JSL AI Platform’s Annotation Tool.
This release is also the first one to support the models: <code class="language-plaintext highlighter-rouge">ner_large_clinical</code>, <code class="language-plaintext highlighter-rouge">ner_events_clinical</code>, <code class="language-plaintext highlighter-rouge">assertion_dl_large</code>, <code class="language-plaintext highlighter-rouge">chunkresolve_loinc_clinical</code>, <code class="language-plaintext highlighter-rouge">deidentify_large</code>
And of course we have fixed some bugs.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-4">New Features</h4>

<ul>
  <li>AnnotationToolJsonReader is a new class that imports a JSON from AI Platform’s Annotation Tool an generates NER and Assertion training datasets</li>
  <li>ChunkMerge Annotator is a new functionality that merges two columns of CHUNKs handling overlaps with a very straightforward logic: max coverage, max # entities</li>
  <li>ChunkMerge Annotator handles inputs from NerDLModel, RegexMatcher, ContextualParser, TextMatcher</li>
  <li>A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-3">Enhancements</h4>

<ul>
  <li>DeIdentification Annotator has a more consistent API:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">mode</code> param with values (‘mask’l’obfuscate’) to drive its behavior</li>
      <li><code class="language-plaintext highlighter-rouge">dateFormats</code> param a list of string values to to select which <code class="language-plaintext highlighter-rouge">dateFormats</code> to obfuscate (and which to just mask)</li>
    </ul>
  </li>
  <li>DeIdentification Annotator no longer automatically obfuscates dates. Obfuscation is now driven by <code class="language-plaintext highlighter-rouge">mode</code> and <code class="language-plaintext highlighter-rouge">dateFormats</code> params</li>
  <li>A DeIdentification pretrained model can now work in ‘mask’ or ‘obfuscate’ mode</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-3">Bugfixes</h4>

<ul>
  <li>DeIdentification Annotator now correctly deduplicates protected entities coming from NER / Regex</li>
  <li>DeIdentification Annotator now indexes chunks correctly after merging them</li>
  <li>AssertionDLApproach Annotator can now be trained with the graph in any folder specified by setting <code class="language-plaintext highlighter-rouge">graphFolder</code> param</li>
  <li>AssertionDLApproach now has the <code class="language-plaintext highlighter-rouge">setClasses</code> param setter in Python wrapper</li>
  <li>JVM Memory and Kryo Max Buffer size increased to 32G and 2000M respectively in <code class="language-plaintext highlighter-rouge">sparknlp_jsl.start(secret)</code> function</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="246">2.4.6</h3>

<h4 id="overview-6">Overview</h4>

<p>We release Spark NLP for Healthcare 2.4.6 to fix some minor bugs.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-4">Bugfixes</h4>

<ul>
  <li>Updated IDF value calculation to be probabilistic based log[(N - df_t) / df_t + 1] as opposed to log[N / df_t]</li>
  <li>TFIDF cosine distance was being calculated with the rooted norms rather than with the original squared norms</li>
  <li>Validation of label cols is now performed at the beginning of EnsembleEntityResolver</li>
  <li>Environment Variable for License value named jsl.settings.license</li>
  <li>Now DocumentLogRegClassifier can be serialized from Python (bug introduced with the implementation of RecursivePipelines, LazyAnnotator attribute)</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="245">2.4.5</h3>

<h4 id="overview-7">Overview</h4>

<p>We are glad to announce Spark NLP for Healthcare 2.4.5. As a new feature we are happy to introduce our new EnsembleEntityResolver which allows our Entity Resolution architecture to scale up in multiple orders of magnitude and handle datasets of millions of records on a sub-log computation increase
We also enhanced our ChunkEntityResolverModel with 5 new distance calculations with weighting-array and aggregation-strategy params that results in more levers to finetune its performance against a given dataset.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-5">New Features</h4>

<ul>
  <li>EnsembleEntityResolver consisting of an integrated TFIDF-Logreg classifier in the first layer + Multiple ChunkEntityResolvers in the second layer (one per each class)</li>
  <li>Five (5) new distances calculations for ChunkEntityResolver, namely:
    <ul>
      <li>Token Based: TFIDF-Cosine, Jaccard, SorensenDice</li>
      <li>Character Based: JaroWinkler and Levenshtein</li>
    </ul>
  </li>
  <li>Weight parameter that works as a multiplier for each distance result to be considered during their aggregation</li>
  <li>Three (3) aggregation strategies for the enabled distance in a particular instance, namely: AVERAGE, MAX and MIN</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-4">Enhancements</h4>

<ul>
  <li>ChunkEntityResolver can now compute distances over all the <code class="language-plaintext highlighter-rouge">neighbours</code> found and return the metadata just for the best <code class="language-plaintext highlighter-rouge">alternatives</code> that meet the <code class="language-plaintext highlighter-rouge">threshold</code>;
before it would calculate them over the neighbours and return them all in the metadata</li>
  <li>ChunkEntityResolver now has an <code class="language-plaintext highlighter-rouge">extramassPenalty</code> parameter to accoun for penalization of token-length difference in compared strings</li>
  <li>Metadata for the ChunkEntityResolver has been updated accordingly to reflect all new features</li>
  <li>StringDistances class has been included in utils to aid in the calculation and organization of different types of distances for Strings</li>
  <li>HasFeaturesJsl trait has been included to support the serialization of Features including [T] &lt;: AnnotatorModel[T] types</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-5">Bugfixes</h4>

<ul>
  <li>Frequency calculation for WMD in ChunkEntityResolver has been adjusted to account for real word count representation</li>
  <li>AnnotatorType for DocumentLogRegClassifier has been changed to CATEGORY to align with classifiers in Open Source library</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="deprecations-1">Deprecations</h4>

<ul>
  <li>Legacy EntityResolver{Approach, Model} classes have been deprecated in favor of ChunkEntityResolver classes</li>
  <li>ChunkEntityResolverSelector classes has been deprecated in favor of EnsembleEntityResolver</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="242">2.4.2</h3>

<h4 id="overview-8">Overview</h4>

<p>We are glad to announce Spark NLP for Healthcare 2.4.2. As a new feature we are happy to introduce our new Disambiguation Annotator,
which will let the users resolve different kind of entities based on Knowledge bases provided in the form of Records in a RocksDB database.
We also enhanced / fixed DocumentLogRegClassifier, ChunkEntityResolverModel and ChunkEntityResolverSelector Annotators.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-6">New Features</h4>

<ul>
  <li>Disambiguation Annotator (NerDisambiguator and NerDisambiguatorModel) which accepts annotator types CHUNK and SENTENCE_EMBEDDINGS and
returns DISAMBIGUATION annotator type. This output annotation type includes all the matches in the result and their similarity scores in the metadata.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-5">Enhancements</h4>

<ul>
  <li>ChunkEntityResolver Annotator now supports both EUCLIDEAN and COSINE distance for the KNN search and WMD calculation.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-6">Bugfixes</h4>

<ul>
  <li>Fixed a bug in DocumentLogRegClassifier Annotator to support its serialization to disk.</li>
  <li>Fixed a bug in ChunkEntityResolverSelector Annotator to group by both SENTENCE and CHUNK at the time of forwarding tokens and embeddings to the lazy annotators.</li>
  <li>Fixed a bug in ChunkEntityResolverModel in which the same exact embeddings was not included in the neighbours.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="241">2.4.1</h3>

<h4 id="overview-9">Overview</h4>

<p>Introducing Spark NLP for Healthcare 2.4.1 after all the feedback we received in the form of issues and suggestions on our different communication channels.
Even though 2.4.0 was very stable, version 2.4.1 is here to address minor bug fixes that we summarize in the following lines.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-7">Bugfixes</h4>

<ul>
  <li>Changing the license Spark property key to be “jsl” instead of “sparkjsl” as the latter generates inconsistencies</li>
  <li>Fix the alignment logic for tokens and chunks in the ChunkEntityResolverSelector because when tokens and chunks did not have the same begin-end indexes the resolution was not executed</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h3 id="240">2.4.0</h3>

<h4 id="overview-10">Overview</h4>

<p>We are glad to announce Spark NLP for Healthcare 2.4.0. This is an important release because of several refactorizations achieved in the core library, plus the introduction of several state of the art algorithms, new features and enhancements.
We have included several architecture and performance improvements, that aim towards making the library more robust in terms of storage handling for Big Data.
In the NLP aspect, we have introduced a ContextualParser, DocumentLogRegClassifier and a ChunkEntityResolverSelector.
These last two Annotators also target performance time and memory consumption by lowering the order of computation and data loaded to memory in each step when designed following a hierarchical pattern.
We have put a big effort on this one, so please enjoy and share your comments. Your words are always welcome through all our different channels.
Thank you very much for your important doubts, bug reports and feedback; they are always welcome and much appreciated.</p>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="new-features-7">New Features</h4>

<ul>
  <li>BigChunkEntityResolver Annotator: New experimental approach to reduce memory consumption at expense of disk IO.</li>
  <li>ContextualParser Annotator: New entity parser that works based on context parameters defined in a JSON file.</li>
  <li>ChunkEntityResolverSelector Annotator: New AnnotatorModel that takes advantage of the RecursivePipelineModel + LazyAnnotator pattern to annotate with different LazyAnnotators at runtime.</li>
  <li>DocumentLogregClassifier Annotator: New Annotator that provides a wrapped TFIDF Vectorizer + LogReg Classifier for TOKEN AnnotatorTypes (either at Document level or Chunk level)</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="enhancements-6">Enhancements</h4>

<ul>
  <li><code class="language-plaintext highlighter-rouge">normalizedColumn</code> Param is no longer required in ChunkEntityResolver Annotator (defaults to the <code class="language-plaintext highlighter-rouge">labelCol</code> Param value).</li>
  <li>ChunkEntityResolverMetadata now has more data to infer whether the match is meaningful or not.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="bugfixes-8">Bugfixes</h4>

<ul>
  <li>Fixed a bug on ContextSpellChecker Annotator where unrecognized tokens would cause an exception if not in vocabulary.</li>
  <li>Fixed a bug on ChunkEntityResolver Annotator where undetermined results were coming out of negligible confidence scores for matches.</li>
  <li>Fixed a bug on ChunkEntityResolver Annotator where search would fail if the <code class="language-plaintext highlighter-rouge">neighbours</code> Param was grater than the number of nodes in the tree. Now it returns up to the number of nodes in the tree.</li>
</ul>

<p>&lt;/div&gt;&lt;div class="h3-box" markdown="1"&gt;</p>

<h4 id="deprecations-2">Deprecations</h4>

<ul>
  <li>OCR Moves to its own JSL Spark OCR project.</li>
</ul>

<p>&lt;/div&gt;</p>

<h4 id="infrastructure">Infrastructure</h4>

<ul>
  <li>Spark NLP License is now required to utilize the library. Please follow the instructions on the shared email.</li>
</ul>
</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2021-05-07T00:00:00+00:00">May 07, 2021</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>


jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
});

function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show() 
    $( ".tabs-box .nlu-block" ).hide()
    $( ".tabs-box .language-scala" ).hide()
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method) }, 15);
    }
}

defer(function () { // load inital language
    togglePython1()
});




</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/licensed/api/">Scaladoc</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/ocr">Getting Started</a></div></div></div>

</div>
</div>

<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();
</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© 2021 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demopage-sidemenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*TABS*/
function openTabCall(cityName){
  // Declare all variables
  var i, tabcontent, tablinks;

  // Get all elements with class="tabcontent" and hide them
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }

  // Get all elements with class="tablinks" and remove the class "active"
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }

  // Show the current tab, and add an "active" class to the button that opened the tab
  document.getElementById(cityName).style.display = "block";
}

function openTab(evt, cityName) {
  openTabCall(cityName);
  evt.currentTarget.className += " active";
}

/*OPen by URL*/
$(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

jQuery(document).ready(function(){
	jQuery('.tab-item').click(function(event) {		
		if (($(window).width() > 400) && ($(window).width() < 1199))
	    {
	    	jQuery('.tab-item').removeClass('open');
	        jQuery(this).toggleClass('open');
	    }
  });
  

});


 

</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3', container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName').toLowerCase())
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script><script>
  window.Lazyload.js(['https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js', 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js'], function() {
    var $canvas = null, $this = null, _ctx = null, _text = '';
    $('.language-chart').each(function(){
      $this = $(this);
      $canvas = $('<canvas></canvas>');
      _text = $this.text();
      $this.text('').append($canvas);
      _ctx = $canvas.get(0).getContext('2d');
      (_ctx && _text) && (new Chart(_ctx, JSON.parse(_text)) && $this.attr('data-processed', true));
    });
  });
</script><script type="text/x-mathjax-config">
	var _config = { tex2jax: {
		inlineMath: [['$','$'], ['\\(','\\)']]
	}};_config.TeX = { equationNumbers: { autoNumber: "all" } };MathJax.Hub.Config(_config);
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script>
  window.Lazyload.js('https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js', function() {
    mermaid.initialize({
      startOnLoad: true
    });
    mermaid.init(undefined, '.language-mermaid');
  });
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>