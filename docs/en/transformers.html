<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMNWXW7PZM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-NMNWXW7PZM');
</script><title>Spark NLP - Transformers</title><meta property="og:title" content="Spark NLP - Transformers"/>

<meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/transformers"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" >
<link rel="stylesheet" href="/static/models.css" /><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP</li><li class="toc-h2"><a href="/docs/en/quickstart">Spark NLP Getting Started</a></li><li class="toc-h2"><a href="/docs/en/install">Install Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/concepts">General Concepts</a></li><li class="toc-h2"><a href="/docs/en/annotators">Annotators</a></li><li class="toc-h2 active"><a href="/docs/en/transformers">Transformers</a></li><li class="toc-h2"><a href="/docs/en/training">Training</a></li><li class="toc-h2"><a href="/docs/en/display">Spark NLP Display</a></li><li class="toc-h2"><a href="/docs/en/mlflow">Experiment Tracking</a></li><li class="toc-h2"><a href="/docs/en/serving_spark_nlp_via_api_databricks_mlflow">Serving Spark NLP&#58 MLFlow on Databricks</a></li><li class="toc-h2"><a href="/docs/en/hardware_acceleration">Hardware Acceleration</a></li><li class="toc-h2"><a href="/docs/en/CPUvsGPUbenchmark">GPU vs CPU Training</a></li><li class="toc-h2"><a href="/docs/en/auxiliary">Helpers</a></li><li class="toc-h2"><a href="/api/">Scala API (Scaladoc)</a></li><li class="toc-h2"><a href="/api/python/">Python API (Sphinx)</a></li><li class="toc-h2"><a href="/docs/en/developers">Developers</a></li><li class="toc-h2"><a href="/docs/en/third-party-projects">Third Party Projects</a></li><li class="toc-h2"><a href="/docs/en/release_notes">Release Notes</a></li><li class="toc-h2"><a href="/docs/en/faq">Spark NLP FAQ</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="/"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a  href="/">Home</a></li><li class="navigation__item navigation__item--active"><a  href="/docs/en/quickstart">Docs</a></li><li class="navigation__item "><a  href="/models">Models</a></li><li class="navigation__item "><a  href="/infer_meaning_intent">Demo</a></li><li class="navigation__item "><a  target="_blank"  href="https://www.johnsnowlabs.com/spark-nlp-blog/">Blog</a></li><li class="f_inner"><a class="github-button" href="https://github.com/JohnSnowLabs/spark-nlp" data-color-scheme="no-preference: light; light: light; dark: dark;" data-size="large" data-show-count="true" aria-label="Star spark-nlp on GitHub">Star on GitHub</a></li>
        </ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><div class="header-nav"><div class="main-docs">
  <ul class="breadcrambs">
    <li><a href="/docs">Documentation</a></li>
    <li>Spark NLP - Transformers</li>
  </ul>
</div></div><header class="main-docs have_subtitle">
          <h1>Spark NLP - Transformers</h1><div class="top-subtitle mont"></div></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/transformers.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Spark NLP - Transformers"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><script> jQuery(document).ready(function () {
    $(".prediction-button").click(function () {
        $(this).closest(".tabs-box").find(".prediction-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        // remove active class from all other buttons
        $(this).closest(".tabs-box").find(".training-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest(".tabs-box").find(".embeddings-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".tabs-box.training-content").hide()
        $(this.parentNode).siblings(".tabs-box.embeddings-content").hide()
        $(this.parentNode).siblings(".tabs-box.prediction-content").show()
    });

    $(".training-button").click(function () {
        $(this).closest(".tabs-box").find(".training-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        // remove active class from all other buttons
        $(this).closest(".tabs-box").find(".prediction-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest(".tabs-box").find(".embeddings-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".tabs-box.prediction-content").hide()
        $(this.parentNode).siblings(".tabs-box.embeddings-content").hide()
        $(this.parentNode).siblings(".tabs-box.training-content").show()
    });

    $(".embeddings-button").click(function () {
        $(this).closest(".tabs-box").find(".embeddings-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        // remove active class from all other buttons
        $(this).closest(".tabs-box").find(".training-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest(".tabs-box").find(".prediction-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".tabs-box.training-content").hide()
        $(this.parentNode).siblings(".tabs-box.prediction-content").hide()
        $(this.parentNode).siblings(".tabs-box.embeddings-content").show()
    });
});
 </script>

<div class="h3-box">

  <h2 id="albertembeddings">AlbertEmbeddings</h2>

  <p>ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS - Google Research, Toyota Technological Institute at Chicago</p>

  <p>These word embeddings represent the outputs generated by the Albert model.
All official Albert releases by google in TF-HUB are supported with this Albert Wrapper:</p>

  <p><strong>Ported TF-Hub Models:</strong></p>

  <table>
    <thead>
      <tr>
        <th>Spark NLP Model</th>
        <th>TF-Hub Model</th>
        <th>Model Properties</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code class="language-plaintext highlighter-rouge">"albert_base_uncased"</code></td>
        <td><a href="https://tfhub.dev/google/albert_base/3">albert_base</a></td>
        <td>768-embed-dim,   12-layer,  12-heads, 12M parameters</td>
      </tr>
      <tr>
        <td><code class="language-plaintext highlighter-rouge">"albert_large_uncased"</code></td>
        <td><a href="https://tfhub.dev/google/albert_large/3">albert_large</a></td>
        <td>1024-embed-dim,  24-layer,  16-heads, 18M parameters</td>
      </tr>
      <tr>
        <td><code class="language-plaintext highlighter-rouge">"albert_xlarge_uncased"</code></td>
        <td><a href="https://tfhub.dev/google/albert_xlarge/3">albert_xlarge</a></td>
        <td>2048-embed-dim,  24-layer,  32-heads, 60M parameters</td>
      </tr>
      <tr>
        <td><code class="language-plaintext highlighter-rouge">"albert_xxlarge_uncased"</code></td>
        <td><a href="https://tfhub.dev/google/albert_xxlarge/3">albert_xxlarge</a></td>
        <td>4096-embed-dim,  12-layer,  64-heads, 235M parameters</td>
      </tr>
    </tbody>
  </table>

  <p>This model requires input tokenization with SentencePiece model, which is provided by Spark-NLP (See tokenizers package).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = AlbertEmbeddings.pretrained()
 .setInputCols("sentence", "token")
 .setOutputCol("embeddings")

# Offline - Download the pretrained model manually and extract it
albert = AlbertEmbeddings.load("/albert_base_uncased_en_2.5.0_2.4_1588073363475") \
        .setInputCols("sentence", "token") \
        .setOutputCol("albert")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"albert_base_uncased"</code>, if no name is provided.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/dl-ner/ner_albert.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddingsTestSpec.scala">AlbertEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources:</strong></p>

  <p><a href="https://arxiv.org/pdf/1909.11942.pdf">ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS</a></p>

  <p>https://github.com/google-research/ALBERT</p>

  <p>https://tfhub.dev/s?q=albert</p>

  <p><strong>Paper abstract:</strong></p>

  <p><em>Increasing model size when pretraining natural language representations often results in improved performance on
downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and
longer training times. To address these problems, we present two parameter reduction techniques to lower memory
consumption and increase the training speed of BERT (Devlin et al., 2019). Comprehensive empirical evidence shows
that our proposed methods lead to models that scale much better compared to
the original BERT. We also use a self-supervised loss that focuses on modeling
inter-sentence coherence, and show it consistently helps downstream tasks with
multi-sentence inputs. As a result, our best model establishes new state-of-the-art
results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large.</em></p>

  <p><strong>Tips:</strong>
ALBERT uses repeating layers which results in a small memory footprint,
however the computational cost remains similar to a BERT-like architecture with
the same number of hidden layers as it has to iterate through the same number of (repeating) layers.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.html#sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings">AlbertEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings">AlbertEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/AlbertEmbeddings.scala">AlbertEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">AlbertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"albert_base_uncased"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'embeddings'</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_conll_albert_base_uncased"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">AlbertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"albert_base_uncased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_conll_albert_base_uncased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">I-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">AlbertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">AlbertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">AlbertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">1.1342473030090332</span><span class="p">,</span><span class="o">-</span><span class="mf">1.3855540752410889</span><span class="p">,</span><span class="mf">0.9818322062492371</span><span class="p">,</span><span class="o">-</span><span class="mf">0.784737348556518</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.847029983997345</span><span class="p">,</span><span class="o">-</span><span class="mf">1.047153353691101</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1520637571811676</span><span class="p">,</span><span class="o">-</span><span class="mf">0.6245765686035156</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.009860038757324219</span><span class="p">,</span><span class="o">-</span><span class="mf">0.13450059294700623</span><span class="p">,</span><span class="mf">2.707749128341675</span><span class="p">,</span><span class="mf">1.2916892766952</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.04192575812339783</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5764210224151611</span><span class="p">,</span><span class="o">-</span><span class="mf">0.3196685314178467</span><span class="p">,</span><span class="o">-</span><span class="mf">0.527840495109</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.15583214163780212</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1614152491092682</span><span class="p">,</span><span class="o">-</span><span class="mf">0.28423872590065</span><span class="p">,</span><span class="o">-</span><span class="mf">0.135491415858268</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.AlbertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">AlbertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">1</span><span class="kt">.</span><span class="err">1342473030090332</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">3855540752410889</span>,<span class="err">0</span><span class="kt">.</span><span class="err">9818322062492371</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">784737348556518</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">847029983997345</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">047153353691101</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1520637571811676</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">6245765686035156</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">009860038757324219</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">13450059294700623</span>,<span class="err">2</span><span class="kt">.</span><span class="err">707749128341675</span>,<span class="err">1</span><span class="kt">.</span><span class="err">2916892766952</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">04192575812339783</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5764210224151611</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3196685314178467</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">527840495109</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">15583214163780212</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1614152491092682</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">28423872590065</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">135491415858268</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="albertforquestionanswering">AlbertForQuestionAnswering</h2>

  <p>AlbertForQuestionAnswering can load ALBERT Models with a span classification head on top for
extractive question-answering tasks like SQuAD (a linear layer on top of the hidden-states
output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = AlbertForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"albert_base_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnsweringTestSpec.scala">AlbertForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.albert_for_question_answering.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering">AlbertForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForQuestionAnswering.scala">AlbertForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">AlbertForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">AlbertForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="albertforsequenceclassification">AlbertForSequenceClassification</h2>

  <p>AlbertForSequenceClassification can load ALBERT Models with sequence classification/regression head on top
(a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = AlbertForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"albert_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassificationTestSpec.scala">AlbertForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.albert_for_sequence_classification.AlbertForSequenceClassification">AlbertForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification">AlbertForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForSequenceClassification.scala">AlbertForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">AlbertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">AlbertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="albertfortokenclassification">AlbertForTokenClassification</h2>

  <p>AlbertForTokenClassification can load ALBERT Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tokenClassifier = AlbertForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"albert_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassificationTestSpec.scala">AlbertForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification">AlbertForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification">AlbertForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/AlbertForTokenClassification.scala">AlbertForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">AlbertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">AlbertForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="bartforzeroshotclassification">BartForZeroShotClassification</h2>

  <p>BartForZeroShotClassification using a <code class="language-plaintext highlighter-rouge">ModelForSequenceClassification</code> trained on NLI (natural
language inference) tasks. Equivalent of <code class="language-plaintext highlighter-rouge">BartForZeroShotClassification </code> models, but these
models dont require a hardcoded number of potential classes, they can be chosen at runtime.
It usually means its slower but it is much more flexible.</p>

  <p>Note that the model will loop through all provided labels. So the more labels you have, the
longer this process will take.</p>

  <p>Any combination of sequences and labels can be passed and each combination will be posed as a
premise/hypothesis pair and passed to the pretrained model.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">BartForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"bart_large_zero_shot_classifier_mnli"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bart_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.bart_for_zero_shot_classification.BartForZeroShotClassification">BartForZeroShotClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BartForZeroShotClassification">BartForZeroShotClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BartForZeroShotClassification.scala">BartForZeroShotClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">BartForZeroShotClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">BartForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="barttransformer">BartTransformer</h2>

  <p>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,
Translation, and Comprehension Transformer</p>

  <p>The Facebook BART (Bidirectional and Auto-Regressive Transformer) model is a state-of-the-art
language generation model that was introduced by Facebook AI in 2019. It is based on the
transformer architecture and is designed to handle a wide range of natural language processing
tasks such as text generation, summarization, and machine translation.</p>

  <p>BART is unique in that it is both bidirectional and auto-regressive, meaning that it can
generate text both from left-to-right and from right-to-left. This allows it to capture
contextual information from both past and future tokens in a sentence,resulting in more
accurate and natural language generation.</p>

  <p>The model was trained on a large corpus of text data using a combination of unsupervised and
supervised learning techniques. It incorporates pretraining and fine-tuning phases, where the
model is first trained on a large unlabeled corpus of text, and then fine-tuned on specific
downstream tasks.</p>

  <p>BART has achieved state-of-the-art performance on a wide range of NLP tasks, including
summarization, question-answering, and language translation. Its ability to handle multiple
tasks and its high performance on each of these tasks make it a versatile and valuable tool
for natural language processing applications.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">bart</span> <span class="k">=</span> <span class="nv">BartTransformer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"generation"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"bart_large_cnn"</code>, if no name is provided. For available pretrained
models please see the <a href="https://nlp.johnsnowlabs.com/models?q=bart">Models Hub</a>.</p>

  <p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/BartTestSpec.scala">BartTestSpec</a>.</p>

  <p><strong>References:</strong></p>

  <ul>
    <li><a href="https://aclanthology.org/2020.acl-main.703.pdf">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></li>
    <li>https://github.com/pytorch/fairseq</li>
  </ul>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART
is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model
to reconstruct the original text. It uses a standard Tranformer-based neural machine
translation architecture which, despite its simplicity, can be seen as generalizing BERT (due
to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent
pretraining schemes. We evaluate a number of noising approaches, finding the best performance
by both randomly shuffling the order of sentences and using a novel in-filling scheme, where
spans of text are replaced with a single mask token. BART is particularly effective when fine
tuned for text generation but also works well for comprehension tasks. It matches the
performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range
of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5
ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine
translation, with only target language pretraining. We also replicate other pretraining
schemes within the BART framework, to understand their effect on end-task performance</em></p>

  <p><strong>Note:</strong></p>

  <p>This is a very computationally expensive module especially on larger sequence. The use of an
accelerator such as GPU is recommended.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index.html#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer">BartTransformer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/seq2seq/BartTransformer">BartTransformer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/seq2seq/BartTransformer.scala">BartTransformer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"documents"</span><span class="p">)</span>
<span class="n">bart</span> <span class="o">=</span> <span class="n">BartTransformer</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bart_large_cnn"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setTask</span><span class="p">(</span><span class="s">"summarize:"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"documents"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setMaxOutputLength</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"summaries"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">bart</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
    <span class="s">"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a "</span> <span class="o">+</span>
    <span class="s">"downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness"</span> <span class="o">+</span>
    <span class="s">" of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this "</span> <span class="o">+</span>
    <span class="s">"paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework "</span> <span class="o">+</span>
    <span class="s">"that converts all text-based language problems into a text-to-text format. Our systematic study compares "</span> <span class="o">+</span>
    <span class="s">"pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens "</span> <span class="o">+</span>
    <span class="s">"of language understanding tasks. By combining the insights from our exploration with scale and our new "</span> <span class="o">+</span>
    <span class="s">"Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering "</span> <span class="o">+</span>
    <span class="s">"summarization, question answering, text classification, and more. To facilitate future work on transfer "</span> <span class="o">+</span>
    <span class="s">"learning for NLP, we release our data set, pre-trained models, and code."</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"summaries.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">transfer</span> <span class="n">learning</span> <span class="n">has</span> <span class="n">emerged</span> <span class="k">as</span> <span class="n">a</span> <span class="n">powerful</span> <span class="n">technique</span> <span class="ow">in</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span> <span class="p">(</span><span class="n">NLP</span><span class="p">)</span> <span class="n">the</span> <span class="n">effectiveness</span> <span class="n">of</span> <span class="n">transfer</span> <span class="n">learning</span> <span class="n">has</span> <span class="n">given</span> <span class="n">rise</span> <span class="n">to</span> <span class="n">a</span> <span class="n">diversity</span> <span class="n">of</span> <span class="n">approaches</span><span class="p">,</span> <span class="n">methodologies</span><span class="p">,</span> <span class="ow">and</span> <span class="n">practice</span> <span class="p">.]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"documents"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">bart</span> <span class="k">=</span> <span class="nv">BartTransformer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bart_large_cnn"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"documents"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMinOutputLength</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxOutputLength</span><span class="o">(</span><span class="mi">30</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDoSample</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTopK</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"generation"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">bart</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"PG&amp;E stated it scheduled the blackouts in response to forecasts for high winds "</span> <span class="o">+</span>
  <span class="s">"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were "</span> <span class="o">+</span>
  <span class="s">"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">results</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"generation.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Nearly</span> <span class="err">800</span> <span class="kt">thousand</span> <span class="kt">customers</span> <span class="kt">were</span> <span class="kt">affected</span> <span class="kt">by</span> <span class="kt">the</span> <span class="kt">shutoffs.</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="bertembeddings">BertEmbeddings</h2>

  <p>Token-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense
vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = BertEmbeddings.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("bert_embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"small_bert_L2_768"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/dl-ner/ner_bert.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddingsTestSpec.scala">BertEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>

  <p>https://github.com/google-research/bert</p>

  <p><strong>Paper abstract</strong></p>

  <p><em>We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations
from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional
representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a
result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create
state-of-the-art models for a wide range of tasks, such as question answering and language inference, without
substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It
obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score
to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1
question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point
absolute improvement).</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.html#sparknlp.annotator.embeddings.bert_embeddings.BertEmbeddings">BertEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/BertEmbeddings">BertEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertEmbeddings.scala">BertEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'bert_base_cased'</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s">'en'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'embeddings'</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_dl_bert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="n">name</span> <span class="k">=</span> <span class="s">"bert_base_cased"</span><span class="o">,</span> <span class="n">lang</span> <span class="k">=</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_dl_bert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">I-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_base_cased"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"small_bert_L2_128"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">2.3497989177703857</span><span class="p">,</span><span class="mf">0.480538547039032</span><span class="p">,</span><span class="o">-</span><span class="mf">0.3238905668258667</span><span class="p">,</span><span class="o">-</span><span class="mf">1.612930893898010</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">2.1357314586639404</span><span class="p">,</span><span class="mf">0.32984697818756104</span><span class="p">,</span><span class="o">-</span><span class="mf">0.6032363176345825</span><span class="p">,</span><span class="o">-</span><span class="mf">1.6791689395904</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">1.8244884014129639</span><span class="p">,</span><span class="o">-</span><span class="mf">0.27088963985443115</span><span class="p">,</span><span class="o">-</span><span class="mf">1.059438943862915</span><span class="p">,</span><span class="o">-</span><span class="mf">0.9817547798156</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">1.1648050546646118</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4725411534309387</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5938255786895752</span><span class="p">,</span><span class="o">-</span><span class="mf">1.5780693292617</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.9125322699546814</span><span class="p">,</span><span class="mf">0.4563939869403839</span><span class="p">,</span><span class="o">-</span><span class="mf">0.3975459933280945</span><span class="p">,</span><span class="o">-</span><span class="mf">1.81611204147338</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"small_bert_L2_128"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">2</span><span class="kt">.</span><span class="err">3497989177703857</span>,<span class="err">0</span><span class="kt">.</span><span class="err">480538547039032</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3238905668258667</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">612930893898010</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">2</span><span class="kt">.</span><span class="err">1357314586639404</span>,<span class="err">0</span><span class="kt">.</span><span class="err">32984697818756104</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">6032363176345825</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">6791689395904</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">8244884014129639</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">27088963985443115</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">059438943862915</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">9817547798156</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">1648050546646118</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4725411534309387</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5938255786895752</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">5780693292617</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">9125322699546814</span>,<span class="err">0</span><span class="kt">.</span><span class="err">4563939869403839</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3975459933280945</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">81611204147338</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="bertforquestionanswering">BertForQuestionAnswering</h2>

  <p>BertForQuestionAnswering can load Bert Models with a span classification head on top for
extractive question-answering tasks like SQuAD (a linear layer on top of the hidden-states
output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = BertForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"bert_base_cased_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnsweringTestSpec.scala">BertForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering">BertForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering">BertForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering.scala">BertForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">BertForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">BertForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="bertforsequenceclassification">BertForSequenceClassification</h2>

  <p>BertForSequenceClassification can load Bert Models with sequence classification/regression head on top (a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = BertForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"bert_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassificationTestSpec.scala">BertForSequenceClassificationTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification">BertForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification">BertForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForSequenceClassification.scala">BertForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">BertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="bertfortokenclassification">BertForTokenClassification</h2>

  <p>BertForTokenClassification can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val labels = BertForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"bert_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassificationTestSpec.scala">BertForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification">BertForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification">BertForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForTokenClassification.scala">BertForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">BertForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="bertforzeroshotclassification">BertForZeroShotClassification</h2>

  <p>BertForZeroShotClassification using a <code class="language-plaintext highlighter-rouge">ModelForSequenceClassification</code> trained on NLI (natural
language inference) tasks. Equivalent of <code class="language-plaintext highlighter-rouge">BertForSequenceClassification</code> models, but these
models dont require a hardcoded number of potential classes, they can be chosen at runtime.
It usually means its slower but it is much more flexible.</p>

  <p>Note that the model will loop through all provided labels. So the more labels you have, the
longer this process will take.</p>

  <p>Any combination of sequences and labels can be passed and each combination will be posed as a
premise/hypothesis pair and passed to the pretrained model.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">BertForZeroShotClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"bert_base_cased_zero_shot_classifier_xnli"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForZeroShotClassification.scala">BertForZeroShotClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification">BertForZeroShotClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForZeroShotClassification">BertForZeroShotClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForZeroShotClassification.scala">BertForZeroShotClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">BertForZeroShotClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">BertForZeroShotClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="bertsentenceembeddings">BertSentenceEmbeddings</h2>

  <p>Sentence-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense
vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = BertSentenceEmbeddings.pretrained()
  .setInputCols("sentence")
  .setOutputCol("sentence_bert_embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"sent_small_bert_L2_768"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BERT%20Sentence.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddingsTestSpec.scala">BertSentenceEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>

  <p>https://github.com/google-research/bert</p>

  <p><strong>Paper abstract</strong></p>

  <p><em>We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations
from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional
representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a
result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create
state-of-the-art models for a wide range of tasks, such as question answering and language inference, without
substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It
obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score
to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1
question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point
absolute improvement).</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.html#sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings">BertSentenceEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings">BertSentenceEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.scala">BertSentenceEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the ClassifierDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span>\
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'sent_bert_multi_cased'</span><span class="p">,</span> <span class="s">'xx'</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">document_classifier</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"classifierdl_bert_news"</span><span class="p">,</span> <span class="s">"de"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">document_classifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Dressurreiterin Jessica von Bredow-Werndl hat ihr zweites Olympia-Gold gewonnen"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"class.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------+</span>
<span class="o">|</span><span class="n">result</span> <span class="o">|</span>
<span class="o">+-------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Sport</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.ClassifierDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the ClassifierDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span>
<span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_bert_multi_cased"</span><span class="o">,</span> <span class="s">"xx"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">document_classifier</span> <span class="k">=</span> <span class="nv">ClassifierDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"classifierdl_bert_news"</span><span class="o">,</span> <span class="s">"de"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"class"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">document_classifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Dressurreiterin Jessica von Bredow-Werndl hat ihr zweites Olympia-Gold gewonnen"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------+</span>
<span class="o">|</span><span class="n">result</span> <span class="o">|</span>
<span class="o">+-------+</span>
<span class="o">|[</span><span class="kt">Sport</span><span class="o">]|</span>
<span class="o">+-------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">smallCorpus</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"header"</span><span class="p">,</span><span class="s">"True"</span><span class="p">).</span><span class="n">csv</span><span class="p">(</span><span class="s">"sentiment.csv"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">docClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">docClassifier</span>
<span class="p">])</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">smallCorpus</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"sentiment.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClassifierDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">docClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_small_bert_L2_128"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_bert_embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John loves apples. Mary loves oranges. John loves Mary."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.8951074481010437</span><span class="p">,</span><span class="mf">0.13753940165042877</span><span class="p">,</span><span class="mf">0.3108254075050354</span><span class="p">,</span><span class="o">-</span><span class="mf">1.65693199634552</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.6180210709571838</span><span class="p">,</span><span class="o">-</span><span class="mf">0.12179657071828842</span><span class="p">,</span><span class="o">-</span><span class="mf">0.191165953874588</span><span class="p">,</span><span class="o">-</span><span class="mf">1.4497021436691</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.822715163230896</span><span class="p">,</span><span class="mf">0.7568016648292542</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1165061742067337</span><span class="p">,</span><span class="o">-</span><span class="mf">1.59048593044281</span><span class="p">,...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertSentenceEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_small_bert_L2_128"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_bert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John loves apples. Mary loves oranges. John loves Mary."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">8951074481010437</span>,<span class="err">0</span><span class="kt">.</span><span class="err">13753940165042877</span>,<span class="err">0</span><span class="kt">.</span><span class="err">3108254075050354</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">65693199634552</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">6180210709571838</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12179657071828842</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">191165953874588</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">4497021436691</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">822715163230896</span>,<span class="err">0</span><span class="kt">.</span><span class="err">7568016648292542</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1165061742067337</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">59048593044281</span>,<span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="camembertembeddings">CamemBertEmbeddings</h2>

  <p>The CamemBERT model was proposed in CamemBERT: a Tasty French Language Model by Louis Martin,
Benjamin Muller, Pedro Javier Ortiz Surez, Yoann Dupont, Laurent Romary, ric Villemonte de
la Clergerie, Djam Seddah, and Benot Sagot. It is based on Facebooks RoBERTa model released
in 2019. It is a model trained on 138GB of French text.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = CamemBertEmbeddings.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("camembert_embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"camembert_base"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/dl-ner/ner_bert.ipynb">Examples</a>
and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddingsTestSpec.scala">CamemBertEmbeddingsTestSpec</a>.
To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://arxiv.org/abs/1911.03894">CamemBERT: a Tasty French Language Model</a></p>

  <p>https://huggingface.co/camembert</p>

  <p><strong>Paper abstract</strong></p>

  <p><em>Pretrained language models are now ubiquitous in Natural Language Processing. Despite their
success, most available models have either been trained on English data or on the
concatenation of data in multiple languages. This makes practical use of such models in all
languages except English very limited. In this paper, we investigate the feasibility of
training monolingual Transformer-based language models for other languages, taking French as
an example and evaluating our language models on part-of-speech tagging, dependency parsing,
named entity recognition and natural language inference tasks. We show that the use of web
crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a
relatively small web crawled dataset (4GB) leads to results that are as good as those obtained
using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the
state of the art in all four downstream tasks.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/camembert_embeddings/index.html#sparknlp.annotator.embeddings.camembert_embeddings.CamemBertEmbeddings">CamemBertEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings">CamemBertEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/CamemBertEmbeddings.scala">CamemBertEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Coming Soon!
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Coming Soon!</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">CamemBertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlmRoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">CamemBertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">CamemBertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"camembert_embeddings"</span><span class="p">)</span>
<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"camembert_embeddings"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"C'est une phrase."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.08442357927560806</span><span class="p">,</span><span class="o">-</span><span class="mf">0.12863239645957947</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03835778683423996</span><span class="p">,</span><span class="mf">0.200479581952</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.048462312668561935</span><span class="p">,</span><span class="mf">0.12637358903884888</span><span class="p">,</span><span class="o">-</span><span class="mf">0.27429091930389404</span><span class="p">,</span><span class="o">-</span><span class="mf">0.07516729831</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.02690504491329193</span><span class="p">,</span><span class="mf">0.12104076147079468</span><span class="p">,</span><span class="mf">0.012526623904705048</span><span class="p">,</span><span class="o">-</span><span class="mf">0.031543646007</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.05877285450696945</span><span class="p">,</span><span class="o">-</span><span class="mf">0.08773420006036758</span><span class="p">,</span><span class="o">-</span><span class="mf">0.06381352990865707</span><span class="p">,</span><span class="mf">0.122621834278</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.CamemBertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">CamemBertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"camembert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"camembert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"C'est une phrase."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">08442357927560806</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12863239645957947</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03835778683423996</span>,<span class="err">0</span><span class="kt">.</span><span class="err">200479581952</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">048462312668561935</span>,<span class="err">0</span><span class="kt">.</span><span class="err">12637358903884888</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">27429091930389404</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07516729831</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">02690504491329193</span>,<span class="err">0</span><span class="kt">.</span><span class="err">12104076147079468</span>,<span class="err">0</span><span class="kt">.</span><span class="err">012526623904705048</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">031543646007</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">05877285450696945</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08773420006036758</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">06381352990865707</span>,<span class="err">0</span><span class="kt">.</span><span class="err">122621834278</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="camembertforquestionanswering">CamemBertForQuestionAnswering</h2>

  <p>CamemBertForQuestionAnswering can load CamemBERT Models with a span classification head on top
for extractive question-answering tasks like SQuAD (a linear layer on top of the hidden-states
output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">spanClassifier</span> <span class="k">=</span> <span class="nv">CamemBertForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"camembert_base_qa_fquad"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnsweringTestSpec.scala">CamemBertForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.camembert_for_question_answering.CamemBertForQuestionAnswering">CamemBertForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering">CamemBertForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForQuestionAnswering.scala">CamemBertForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>
<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">CamemBertForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="n">ontext</span><span class="s">")
result = pipeline.fit(data).transform(data)
result.select("</span><span class="n">answer</span><span class="p">.</span><span class="n">result</span><span class="s">").show(truncate=False)
+--------------------+
|result              |
+--------------------+
|[Clara]             |
+--------------------+
</span></code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">sparknlp</span>
<span class="n">from</span> <span class="nv">sparknlp</span><span class="o">.</span><span class="py">base</span> <span class="k">import</span> <span class="err">*
</span><span class="nn">from</span> <span class="nv">sparknlp</span><span class="o">.</span><span class="py">annotator</span> <span class="k">import</span> <span class="err">*
</span><span class="nn">from</span> <span class="nv">pyspark</span><span class="o">.</span><span class="py">ml</span> <span class="k">import</span> <span class="nn">Pipeline</span>

<span class="n">documentAssembler</span> <span class="k">=</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">question</span><span class="err">"</span>, <span class="err">"</span><span class="kt">context</span><span class="err">"</span><span class="o">])</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">([</span><span class="err">"</span><span class="kt">document_question</span><span class="err">"</span>, <span class="err">"</span><span class="kt">document_context</span><span class="err">"</span><span class="o">])</span>
<span class="n">spanClassifier</span> <span class="k">=</span> <span class="nv">CamemBertForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">document_question</span><span class="err">"</span>, <span class="err">"</span><span class="kt">document_context</span><span class="err">"</span><span class="o">])</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>
<span class="n">pipeline</span> <span class="k">=</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">([</span>
    <span class="kt">documentAssembler</span>,
    <span class="kt">spanClassifier</span>
<span class="o">])</span>

<span class="n">data</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">([[</span><span class="err">"</span><span class="kt">What's</span> <span class="kt">my</span> <span class="kt">name?</span><span class="err">"</span>, <span class="err">"</span><span class="kt">My</span> <span class="kt">name</span> <span class="kt">is</span> <span class="kt">Clara</span> <span class="kt">and</span> <span class="kt">I</span> <span class="kt">live</span> <span class="kt">in</span> <span class="kt">Berkeley.</span><span class="err">"</span><span class="o">]]).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="n">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"answer.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="nc">False</span><span class="o">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="camembertforsequenceclassification">CamemBertForSequenceClassification</h2>

  <p>CamemBertForSequenceClassification can load CamemBERT Models with sequence
classification/regression head on top (a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = CamemBertForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">camembert_base_sequence_classifier_allocine"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassificationTestSpec.scala">CamemBertForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.camembert_for_sequence_classification.CamemBertForSequenceClassification">CamemBertForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification">CamemBertForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForSequenceClassification.scala">CamemBertForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">CamemBertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"j'ai ador ce film lorsque j'tais enfant."</span><span class="p">,</span> <span class="s">"Je dteste a."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"class.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">CamemBertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"j'ai ador ce film lorsque j'tais enfant."</span><span class="o">,</span> <span class="s">"Je dteste a."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="camembertfortokenclassification">CamemBertForTokenClassification</h2>

  <p>CamemBertForTokenClassification can load CamemBERT Models with a token classification head on
top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition
(NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tokenClassifier = CamemBertForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"camembert_base_token_classifier_wikiner"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassificationTestSpec.scala">CamemBertForTokenClassificationTestSpec</a>.
To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification">CamemBertForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification">CamemBertForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/CamemBertForTokenClassification.scala">CamemBertForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">CamemBertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"george washington est all  washington"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                        <span class="o">|</span>
<span class="o">+------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">CamemBertForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"george washington est all  washington"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                        <span class="o">|</span>
<span class="o">+------------------------------+</span>
<span class="o">|[</span><span class="kt">I-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="convnextforimageclassification">ConvNextForImageClassification</h2>

  <p>ConvNextForImageClassification is an image classifier based on ConvNet models.</p>

  <p>The ConvNeXT model was proposed in A ConvNet for the 2020s by Zhuang Liu, Hanzi Mao, Chao-Yuan
Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie. ConvNeXT is a pure convolutional
model (ConvNet), inspired by the design of Vision Transformers, that claims to outperform
them.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">imageClassifier</span> <span class="k">=</span> <span class="nv">ConvNextForImageClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"class"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"image_classifier_convnext_tiny_224_local"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Image+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To
see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/cv/ConvNextForImageClassificationTestSpec.scala">ConvNextForImageClassificationTestSpec</a>.</p>

  <p><strong>References:</strong></p>

  <p><a href="https://arxiv.org/abs/2201.03545">A ConvNet for the 2020s</a></p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>The Roaring 20s of visual recognition began with the introduction of Vision Transformers
(ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model.
A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision
tasks such as object detection and semantic segmentation. It is the hierarchical Transformers
(e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers
practically viable as a generic vision backbone and demonstrating remarkable performance on a
wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still
largely credited to the intrinsic superiority of Transformers, rather than the inherent
inductive biases of convolutions. In this work, we reexamine the design spaces and test the
limits of what a pure ConvNet can achieve. We gradually modernize a standard ResNet toward
the design of a vision Transformer, and discover several key components that contribute to the
performance difference along the way. The outcome of this exploration is a family of pure
ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts
compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8%
ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K
segmentation, while maintaining the simplicity and efficiency of standard ConvNets.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">IMAGE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/cv/convnext_for_image_classification/index.html#sparknlp.annotator.cv.convnext_for_image_classification.ConvNextForImageClassification">ConvNextForImageClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/cv/ConvNextForImageClassification">ConvNextForImageClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/cv/ConvNextForImageClassification.scala">ConvNextForImageClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">imageDF</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span> \
    <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"dropInvalid"</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"src/test/resources/image/"</span><span class="p">)</span>
<span class="n">imageAssembler</span> <span class="o">=</span> <span class="n">ImageAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">)</span>
<span class="n">imageClassifier</span> <span class="o">=</span> <span class="n">ConvNextForImageClassification</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"image_assembler"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">imageAssembler</span><span class="p">,</span> <span class="n">imageClassifier</span><span class="p">])</span>
<span class="n">pipelineDF</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">imageDF</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">imageDF</span><span class="p">)</span>
<span class="n">pipelineDF</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="p">,</span> <span class="s">"class.result"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">bluetick</span><span class="p">.</span><span class="n">jpg</span>     <span class="o">|</span><span class="p">[</span><span class="n">bluetick</span><span class="p">]</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="n">chihuahua</span><span class="p">.</span><span class="n">jpg</span>    <span class="o">|</span><span class="p">[</span><span class="n">Chihuahua</span><span class="p">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="n">egyptian_cat</span><span class="p">.</span><span class="n">jpeg</span><span class="o">|</span><span class="p">[</span><span class="n">tabby</span><span class="p">,</span> <span class="n">tabby</span> <span class="n">cat</span><span class="p">]</span>                                        <span class="o">|</span>
<span class="o">|</span><span class="n">hen</span><span class="p">.</span><span class="n">JPEG</span>         <span class="o">|</span><span class="p">[</span><span class="n">hen</span><span class="p">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="n">hippopotamus</span><span class="p">.</span><span class="n">JPEG</span><span class="o">|</span><span class="p">[</span><span class="n">hippopotamus</span><span class="p">,</span> <span class="n">hippo</span><span class="p">,</span> <span class="n">river</span> <span class="n">horse</span><span class="p">,</span> <span class="n">Hippopotamus</span> <span class="n">amphibius</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">junco</span><span class="p">.</span><span class="n">JPEG</span>       <span class="o">|</span><span class="p">[</span><span class="n">junco</span><span class="p">,</span> <span class="n">snowbird</span><span class="p">]</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="n">ostrich</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">ostrich</span><span class="p">,</span> <span class="n">Struthio</span> <span class="n">camelus</span><span class="p">]</span>                               <span class="o">|</span>
<span class="o">|</span><span class="n">ox</span><span class="p">.</span><span class="n">JPEG</span>          <span class="o">|</span><span class="p">[</span><span class="n">ox</span><span class="p">]</span>                                                      <span class="o">|</span>
<span class="o">|</span><span class="n">palace</span><span class="p">.</span><span class="n">JPEG</span>      <span class="o">|</span><span class="p">[</span><span class="n">palace</span><span class="p">]</span>                                                  <span class="o">|</span>
<span class="o">|</span><span class="n">tractor</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">thresher</span><span class="p">,</span> <span class="n">thrasher</span><span class="p">,</span> <span class="n">threshing</span> <span class="n">machine</span>                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.ImageAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">imageDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span>
  <span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"dropInvalid"</span><span class="o">,</span> <span class="n">value</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"src/test/resources/image/"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ImageAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageClassifier</span> <span class="k">=</span> <span class="nc">ConvNextForImageClassification</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"class"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">imageAssembler</span><span class="o">,</span> <span class="n">imageClassifier</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineDF</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">imageDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">imageDF</span><span class="o">)</span>

<span class="n">pipelineDF</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="o">,</span> <span class="s">"class.result"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="nv">palace</span><span class="o">.</span><span class="py">JPEG</span>      <span class="o">|[</span><span class="kt">palace</span><span class="o">]</span>                                                  <span class="o">|</span>
<span class="o">|</span><span class="nv">egyptian_cat</span><span class="o">.</span><span class="py">jpeg</span><span class="o">|[</span><span class="kt">tabby</span>, <span class="kt">tabby</span> <span class="kt">cat</span><span class="o">]</span>                                        <span class="o">|</span>
<span class="o">|</span><span class="nv">hippopotamus</span><span class="o">.</span><span class="py">JPEG</span><span class="o">|[</span><span class="kt">hippopotamus</span>, <span class="kt">hippo</span>, <span class="kt">river</span> <span class="kt">horse</span>, <span class="kt">Hippopotamus</span> <span class="kt">amphibius</span><span class="o">]|</span>
<span class="o">|</span><span class="nv">hen</span><span class="o">.</span><span class="py">JPEG</span>         <span class="o">|[</span><span class="kt">hen</span><span class="o">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="nv">ostrich</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">ostrich</span>, <span class="kt">Struthio</span> <span class="kt">camelus</span><span class="o">]</span>                               <span class="o">|</span>
<span class="o">|</span><span class="nv">junco</span><span class="o">.</span><span class="py">JPEG</span>       <span class="o">|[</span><span class="kt">junco</span>, <span class="kt">snowbird</span><span class="o">]</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="nv">bluetick</span><span class="o">.</span><span class="py">jpg</span>     <span class="o">|[</span><span class="kt">bluetick</span><span class="o">]</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="nv">chihuahua</span><span class="o">.</span><span class="py">jpg</span>    <span class="o">|[</span><span class="kt">Chihuahua</span><span class="o">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="nv">tractor</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">tractor</span><span class="o">]</span>                                                 <span class="o">|</span>
<span class="o">|</span><span class="nv">ox</span><span class="o">.</span><span class="py">JPEG</span>          <span class="o">|[</span><span class="kt">ox</span><span class="o">]</span>                                                      <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="debertaembeddings">DeBertaEmbeddings</h2>

  <p>The DeBERTa model was proposed in <a href="https://arxiv.org/abs/2006.03654">DeBERTa: Decoding-enhanced BERT with Disentangled Attention</a> by Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen. It is based on Googles BERT model released in 2018 and Facebooks RoBERTa model released in 2019.</p>

  <p>This model requires input tokenization with SentencePiece model, which is provided by Spark NLP (See tokenizers package).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = DeBertaEmbeddings.pretrained()
 .setInputCols("sentence", "token")
 .setOutputCol("embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"deberta_v3_base"</code>, if no name is provided.</p>

  <p>For extended examples see <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddingsTestSpec.scala">DeBertaEmbeddingsTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are 
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p>It builds on RoBERTa with disentangled attention and enhanced mask decoder training with half of the data used in RoBERTa.</p>

  <p><strong>Sources:</strong></p>

  <p>https://github.com/microsoft/DeBERTa</p>

  <p>https://www.microsoft.com/en-us/research/blog/microsoft-deberta-surpasses-human-performance-on-the-superglue-benchmark/</p>

  <p><strong>Paper abstract:</strong></p>

  <p><em>Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions. Second, an enhanced mask decoder is used to replace the output softmax layer to predict the masked tokens for model pretraining. We show that these two techniques significantly improve the efficiency of model pretraining and performance of downstream tasks. Compared to RoBERTa-Large, a DeBERTa model trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%). The DeBERTa code and pre-trained models will be made publicly available at https://github.com/microsoft/DeBERTa.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/deberta_embeddings/index.html#sparknlp.annotator.embeddings.deberta_embeddings.DeBertaEmbeddings">DeBertaEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings">DeBertaEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/DeBertaEmbeddings.scala">DeBertaEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Coming Soon!
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Coming Soon!</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">DeBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">DeBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">DeBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">1.1342473030090332</span><span class="p">,</span><span class="o">-</span><span class="mf">1.3855540752410889</span><span class="p">,</span><span class="mf">0.9818322062492371</span><span class="p">,</span><span class="o">-</span><span class="mf">0.784737348556518</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.847029983997345</span><span class="p">,</span><span class="o">-</span><span class="mf">1.047153353691101</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1520637571811676</span><span class="p">,</span><span class="o">-</span><span class="mf">0.6245765686035156</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.009860038757324219</span><span class="p">,</span><span class="o">-</span><span class="mf">0.13450059294700623</span><span class="p">,</span><span class="mf">2.707749128341675</span><span class="p">,</span><span class="mf">1.2916892766952</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.04192575812339783</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5764210224151611</span><span class="p">,</span><span class="o">-</span><span class="mf">0.3196685314178467</span><span class="p">,</span><span class="o">-</span><span class="mf">0.527840495109</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.15583214163780212</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1614152491092682</span><span class="p">,</span><span class="o">-</span><span class="mf">0.28423872590065</span><span class="p">,</span><span class="o">-</span><span class="mf">0.135491415858268</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.DeBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">DeBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">1</span><span class="kt">.</span><span class="err">1342473030090332</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">3855540752410889</span>,<span class="err">0</span><span class="kt">.</span><span class="err">9818322062492371</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">784737348556518</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">847029983997345</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">047153353691101</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1520637571811676</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">6245765686035156</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">009860038757324219</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">13450059294700623</span>,<span class="err">2</span><span class="kt">.</span><span class="err">707749128341675</span>,<span class="err">1</span><span class="kt">.</span><span class="err">2916892766952</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">04192575812339783</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5764210224151611</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3196685314178467</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">527840495109</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">15583214163780212</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1614152491092682</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">28423872590065</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">135491415858268</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="debertaforquestionanswering">DeBertaForQuestionAnswering</h2>

  <p>DeBertaForQuestionAnswering can load DeBERTa Models with a span classification head on top for
extractive question-answering tasks like SQuAD (a linear layer on top of the hidden-states
output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = DeBertaForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"deverta_v3_xsmall_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnsweringTestSpec.scala">DeBertaForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering/index.html#sparknlp.annotator.classifier_dl.deberta_for_question_answering.DeBertaForQuestionAnswering">DeBertaForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering">DeBertaForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForQuestionAnswering.scala">DeBertaForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">DeBertaForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">DeBertaForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="debertaforsequenceclassification">DeBertaForSequenceClassification</h2>

  <p>DeBertaForSequenceClassification can load DeBerta v2 &amp; v3 Models with sequence
classification/regression head on top (a linear layer on top of the pooled output) e.g. for
multi-class document classification tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">DeBertaForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"deberta_v3_xsmall_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassificationTestSpec.scala">DeBertaForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.deberta_for_sequence_classification.DeBertaForSequenceClassification">DeBertaForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification">DeBertaForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForSequenceClassification.scala">DeBertaForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">DeBertaForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">DeBertaForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="debertafortokenclassification">DeBertaForTokenClassification</h2>

  <p>DeBertaForTokenClassification can load DeBERTA Models v2 and v3 with a token classification
head on top (a linear layer on top of the hidden-states output) e.g. for
Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">DeBertaForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"deberta_v3_xsmall_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassificationTestSpec.scala">DeBertaForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To
see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.deberta_for_token_classification.DeBertaForTokenClassification">DeBertaForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification">DeBertaForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DeBertaForTokenClassification.scala">DeBertaForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">DeBertaForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">DeBertaForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="distilbertembeddings">DistilBertEmbeddings</h2>

  <p>DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than
<code class="language-plaintext highlighter-rouge">bert-base-uncased</code>, runs 60% faster while preserving over 95% of BERTs performances as measured on the GLUE language understanding benchmark.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = DistilBertEmbeddings.pretrained()
  .setInputCols("document", "token")
  .setOutputCol("embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"distilbert_base_cased"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBERT.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddingsTestSpec.scala">DistilBertEmbeddingsTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p>The DistilBERT model was proposed in the paper
<a href="https://arxiv.org/abs/1910.01108">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a>.</p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP),
operating these large models in on-the-edge and/or under constrained computational training or inference budgets
remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation
model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger
counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage
knowledge distillation during the pretraining phase and show that it is possible to reduce the size of a BERT model by
40%, while retaining 97% of its language understanding capabilities and being 60% faster. To leverage the inductive
biases learned by larger models during pretraining, we introduce a triple loss combining language modeling,
distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we
demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device
study.</em></p>

  <p>Tips:</p>
  <ul>
    <li>DistilBERT doesnt have <code class="language-plaintext highlighter-rouge">:obj:token_type_ids</code>, you dont need to indicate which token belongs to which segment. Just
separate your segments with the separation token <code class="language-plaintext highlighter-rouge">:obj:tokenizer.sep_token</code> (or <code class="language-plaintext highlighter-rouge">:obj:[SEP]</code>).</li>
    <li>DistilBERT doesnt have options to select the input positions (<code class="language-plaintext highlighter-rouge">:obj:position_ids</code> input). This could be added if
necessary though, just let us know if you need this option.</li>
  </ul>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.html#sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings">DistilBertEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings">DistilBertEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/DistilBertEmbeddings.scala">DistilBertEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">DistilBertEmbeddings</span>\
      <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'distilbert_base_cased'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'ner_mit_movie_complex_distilbert_base_cased'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">,</span> <span class="s">'embeddings'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"The Grand Budapest Hotel is a 2014 comedy-drama film written and directed by Wes Anderson"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Year</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Genre</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Director</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Director</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.DistilBertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">DistilBertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"distilbert_base_cased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_mit_movie_complex_distilbert_base_cased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The Grand Budapest Hotel is a 2014 comedy-drama film written and directed by Wes Anderson"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">I-Plot</span>, <span class="kt">I-Plot</span>, <span class="kt">I-Plot</span>, <span class="kt">I-Plot</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-Year</span>, <span class="kt">B-Genre</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-Director</span>, <span class="kt">I-Director</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">DistilBertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.DistilBertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">DistilBertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">DistilBertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.1127224713563919</span><span class="p">,</span><span class="o">-</span><span class="mf">0.1982710212469101</span><span class="p">,</span><span class="mf">0.5360898375511169</span><span class="p">,</span><span class="o">-</span><span class="mf">0.272536993026733</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.35534414649009705</span><span class="p">,</span><span class="mf">0.13215228915214539</span><span class="p">,</span><span class="mf">0.40981462597846985</span><span class="p">,</span><span class="mf">0.14036104083061</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.328085333108902</span><span class="p">,</span><span class="o">-</span><span class="mf">0.06269335001707077</span><span class="p">,</span><span class="o">-</span><span class="mf">0.017595693469047546</span><span class="p">,</span><span class="o">-</span><span class="mf">0.024373905733</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.15617232024669647</span><span class="p">,</span><span class="mf">0.2967822253704071</span><span class="p">,</span><span class="mf">0.22324979305267334</span><span class="p">,</span><span class="o">-</span><span class="mf">0.04568954557180</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.45411425828933716</span><span class="p">,</span><span class="mf">0.01173491682857275</span><span class="p">,</span><span class="mf">0.190129816532135</span><span class="p">,</span><span class="mf">0.1178255230188369</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.DistilBertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">DistilBertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">1127224713563919</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1982710212469101</span>,<span class="err">0</span><span class="kt">.</span><span class="err">5360898375511169</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">272536993026733</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">35534414649009705</span>,<span class="err">0</span><span class="kt">.</span><span class="err">13215228915214539</span>,<span class="err">0</span><span class="kt">.</span><span class="err">40981462597846985</span>,<span class="err">0</span><span class="kt">.</span><span class="err">14036104083061</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">328085333108902</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">06269335001707077</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">017595693469047546</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">024373905733</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">15617232024669647</span>,<span class="err">0</span><span class="kt">.</span><span class="err">2967822253704071</span>,<span class="err">0</span><span class="kt">.</span><span class="err">22324979305267334</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">04568954557180</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">45411425828933716</span>,<span class="err">0</span><span class="kt">.</span><span class="err">01173491682857275</span>,<span class="err">0</span><span class="kt">.</span><span class="err">190129816532135</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1178255230188369</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="distilbertforquestionanswering">DistilBertForQuestionAnswering</h2>

  <p>DistilBertForQuestionAnswering can load DistilBert Models with a span classification head on
top for extractive question-answering tasks like SQuAD (a linear layer on top of the
hidden-states output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = DistilBertForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"distilbert_base_cased_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassificationTestSpec.scala">DistilBertForSequenceClassificationTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForQuestionAnswering.scala">DistilBertForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">DistilBertForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">DistilBertForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="distilbertforsequenceclassification">DistilBertForSequenceClassification</h2>

  <p>DistilBertForSequenceClassification can load DistilBERT Models with sequence classification/regression head on top
(a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = DistilBertForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"distilbert_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassificationTestSpec.scala">DistilBertForSequenceClassificationTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification">DistilBertForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForSequenceClassification.scala">DistilBertForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">DistilBertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"""John Lenon was born in London and lived
in Paris. My name is Sarah and I live in London"""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">DistilBertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="distilbertfortokenclassification">DistilBertForTokenClassification</h2>

  <p>DistilBertForTokenClassification can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val labels = DistilBertForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"distilbert_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassificationTestSpec.scala">DistilBertForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification">DistilBertForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification">DistilBertForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForTokenClassification.scala">DistilBertForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">DistilBertEmbeddings</span>\
      <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'distilbert_base_cased'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'ner_mit_movie_complex_distilbert_base_cased'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">,</span> <span class="s">'embeddings'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"The Grand Budapest Hotel is a 2014 comedy-drama film written and directed by Wes Anderson"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Plot</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Year</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Genre</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Director</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">Director</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.DistilBertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">DistilBertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"distilbert_base_cased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_mit_movie_complex_distilbert_base_cased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The Grand Budapest Hotel is a 2014 comedy-drama film written and directed by Wes Anderson"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">I-Plot</span>, <span class="kt">I-Plot</span>, <span class="kt">I-Plot</span>, <span class="kt">I-Plot</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-Year</span>, <span class="kt">B-Genre</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-Director</span>, <span class="kt">I-Director</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="distilbertforzeroshotclassification">DistilBertForZeroShotClassification</h2>

  <p>DistilBertForZeroShotClassification using a <code class="language-plaintext highlighter-rouge">ModelForSequenceClassification</code> trained on NLI
(natural language inference) tasks. Equivalent of <code class="language-plaintext highlighter-rouge">DistilBertForZeroShotClassification </code>
models, but these models dont require a hardcoded number of potential classes, they can be
chosen at runtime. It usually means its slower but it is much more flexible.</p>

  <p>Note that the model will loop through all provided labels. So the more labels you have, the
longer this process will take.</p>

  <p>Any combination of sequences and labels can be passed and each combination will be posed as a
premise/hypothesis pair and passed to the pretrained model.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">DistilBertForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"distilbert_base_zero_shot_classifier_uncased_mnli"</code>, if no name is
provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification">DistilBertForZeroShotClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForZeroShotClassification">DistilBertForZeroShotClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/DistilBertForZeroShotClassification.scala">DistilBertForZeroShotClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">BertForZeroShotClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">],</span> <span class="p">[</span><span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">DistilBertForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="e5embeddings">E5Embeddings</h2>

  <p>Sentence embeddings using E5.</p>

  <p>E5, an instruction-finetuned text embedding model that can generate text embeddings tailored
to any task (e.g., classification, retrieval, clustering, text evaluation, etc.)</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">E5Embeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"e5_embeddings"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"e5_small"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?q=E5">Models Hub</a>.</p>

  <p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/E5EmbeddingsTestSpec.scala">E5EmbeddingsTestSpec</a>.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://arxiv.org/pdf/2212.03533">Text Embeddings by Weakly-Supervised Contrastive Pre-training</a></p>

  <p><a href="https://github.com/microsoft/unilm/tree/master/e5">E5 Github Repository</a></p>

  <p><strong>Paper abstract</strong></p>

  <p><em>This paper presents E5, a family of state-of-the-art text embeddings that transfer well to a
wide range of tasks. The model is trained in a contrastive manner with weak supervision
signals from our curated large-scale text pair dataset (called CCPairs). E5 can be readily
used as a general-purpose embedding model for any tasks requiring a single-vector
representation of texts such as retrieval, clustering, and classification, achieving strong
performance in both zero-shot and fine-tuned settings. We conduct extensive evaluations on 56
datasets from the BEIR and MTEB benchmarks. For zero-shot settings, E5 is the first model that
outperforms the strong BM25 baseline on the BEIR retrieval benchmark without using any labeled
data. When fine-tuned, E5 obtains the best results on the MTEB benchmark, beating existing
embedding models with 40 more parameters.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/e5_embeddings/index.html#sparknlp.annotator.embeddings.e5_embeddings.E5Embeddings">E5Embeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/E5Embeddings">E5Embeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/E5Embeddings.scala">E5Embeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">E5Embeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"e5_embeddings"</span><span class="p">)</span>
<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"e5_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"query: how much protein should a female eat"</span><span class="p">,</span>
    <span class="s">"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day."</span> <span class="o">+</span> \
    <span class="s">"But, as you can see from this chart, you'll need to increase that if you're expecting or training for a"</span> <span class="o">+</span> \
    <span class="s">"marathon. Check out the chart below to see how much protein you should be eating each day."</span><span class="p">,</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[[</span><span class="mf">8.0190285E-4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.005974853</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.072875895</span><span class="p">,</span> <span class="mf">0.007944068</span><span class="p">,</span> <span class="mf">0.026059335</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0080</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[[</span><span class="mf">0.050514214</span><span class="p">,</span> <span class="mf">0.010061974</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.04340176</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.020937217</span><span class="p">,</span> <span class="mf">0.05170225</span><span class="p">,</span> <span class="mf">0.01157857</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.E5Embeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">E5Embeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"e5_small"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"e5_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"e5_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"query: how much protein should a female eat"</span><span class="o">,</span>
<span class="s">"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day."</span> <span class="o">+</span>
<span class="nc">But</span><span class="o">,</span> <span class="n">as</span> <span class="n">you</span> <span class="n">can</span> <span class="n">see</span> <span class="n">from</span> <span class="k">this</span> <span class="n">chart</span><span class="o">,</span> <span class="n">you</span><span class="ss">'ll</span> <span class="n">need</span> <span class="n">to</span> <span class="n">increase</span> <span class="n">that</span> <span class="k">if</span> <span class="n">you</span><span class="ss">'re</span> <span class="n">expecting</span> <span class="n">or</span> <span class="n">training</span> <span class="k">for</span> <span class="n">a</span><span class="s">" +
marathon. Check out the chart below to see how much protein you should be eating each day."</span>

<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="err">8</span><span class="kt">.</span><span class="err">0190285</span><span class="kt">E-</span><span class="err">4</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">005974853</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">072875895</span>, <span class="err">0</span><span class="kt">.</span><span class="err">007944068</span>, <span class="err">0</span><span class="kt">.</span><span class="err">026059335</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0080</span><span class="kt">...|</span>
<span class="o">[[</span><span class="err">0</span><span class="kt">.</span><span class="err">050514214</span>, <span class="err">0</span><span class="kt">.</span><span class="err">010061974</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">04340176</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">020937217</span>, <span class="err">0</span><span class="kt">.</span><span class="err">05170225</span>, <span class="err">0</span><span class="kt">.</span><span class="err">01157857</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="elmoembeddings">ElmoEmbeddings</h2>

  <p>Word embeddings from ELMo (Embeddings from Language Models), a language model trained on the 1 Billion Word Benchmark.</p>

  <p>Note that this is a very computationally expensive module compared to word embedding modules that only perform
embedding lookups. The use of an accelerator is recommended.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = ElmoEmbeddings.pretrained()
  .setInputCols("sentence", "token")
  .setOutputCol("elmo_embeddings")

# Offline - Download the pretrained model manually and extract it
elmo = ElmoEmbeddings.load("/elmo_en_2.4.0_2.4_1580488815299") \
        .setInputCols("sentence", "token") \
        .setOutputCol("elmo")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"elmo"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>The pooling layer can be set with <code class="language-plaintext highlighter-rouge">setPoolingLayer</code> to the following values:</p>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">"word_emb"</code>: the character-based word representations with shape <code class="language-plaintext highlighter-rouge">[batch_size, max_length, 512]</code>.</li>
    <li><code class="language-plaintext highlighter-rouge">"lstm_outputs1"</code>: the first LSTM hidden state with shape <code class="language-plaintext highlighter-rouge">[batch_size, max_length, 1024]</code>.</li>
    <li><code class="language-plaintext highlighter-rouge">"lstm_outputs2"</code>: the second LSTM hidden state with shape <code class="language-plaintext highlighter-rouge">[batch_size, max_length, 1024]</code>.</li>
    <li><code class="language-plaintext highlighter-rouge">"elmo"</code>: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape <code class="language-plaintext highlighter-rouge">[batch_size, max_length, 1024]</code>.</li>
  </ul>

  <p>For extended examples of usage, see the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/dl-ner/ner_elmo.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddingsTestSpec.scala">ElmoEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources:</strong></p>

  <p>https://tfhub.dev/google/elmo/3</p>

  <p><a href="https://arxiv.org/abs/1802.05365">Deep contextualized word representations</a></p>

  <p><strong>Paper abstract:</strong></p>

  <p><em>We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of
word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model
polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model
(biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to
existing models and significantly improve the state of the art across six challenging NLP problems, including
question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the
deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of
semi-supervision signals.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/elmo_embeddings/index.html#sparknlp.annotator.embeddings.elmo_embeddings.ElmoEmbeddings">ElmoEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings">ElmoEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/ElmoEmbeddings.scala">ElmoEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">ElmoEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'embeddings'</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_conll_elmo"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">ElmoEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_conll_elmo"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">I-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">ElmoEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setPoolingLayer</span><span class="p">(</span><span class="s">"word_emb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">ElmoEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setPoolingLayer</span><span class="o">(</span><span class="s">"word_emb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">ElmoEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setPoolingLayer</span><span class="p">(</span><span class="s">"word_emb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">6.662458181381226E-4</span><span class="p">,</span><span class="o">-</span><span class="mf">0.2541114091873169</span><span class="p">,</span><span class="o">-</span><span class="mf">0.6275503039360046</span><span class="p">,</span><span class="mf">0.5787073969841</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.19154725968837738</span><span class="p">,</span><span class="mf">0.22998669743537903</span><span class="p">,</span><span class="o">-</span><span class="mf">0.2894386649131775</span><span class="p">,</span><span class="mf">0.21524395048618</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.10400570929050446</span><span class="p">,</span><span class="mf">0.12288510054349899</span><span class="p">,</span><span class="o">-</span><span class="mf">0.07056470215320587</span><span class="p">,</span><span class="o">-</span><span class="mf">0.246389418840</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.49932169914245605</span><span class="p">,</span><span class="o">-</span><span class="mf">0.12706467509269714</span><span class="p">,</span><span class="mf">0.30969417095184326</span><span class="p">,</span><span class="mf">0.2643227577209</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.8871506452560425</span><span class="p">,</span><span class="o">-</span><span class="mf">0.20039963722229004</span><span class="p">,</span><span class="o">-</span><span class="mf">1.0601330995559692</span><span class="p">,</span><span class="mf">0.0348707810044</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.ElmoEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">ElmoEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setPoolingLayer</span><span class="o">(</span><span class="s">"word_emb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">6</span><span class="kt">.</span><span class="err">662458181381226</span><span class="kt">E-</span><span class="err">4</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2541114091873169</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">6275503039360046</span>,<span class="err">0</span><span class="kt">.</span><span class="err">5787073969841</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">19154725968837738</span>,<span class="err">0</span><span class="kt">.</span><span class="err">22998669743537903</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2894386649131775</span>,<span class="err">0</span><span class="kt">.</span><span class="err">21524395048618</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">10400570929050446</span>,<span class="err">0</span><span class="kt">.</span><span class="err">12288510054349899</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07056470215320587</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">246389418840</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">49932169914245605</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12706467509269714</span>,<span class="err">0</span><span class="kt">.</span><span class="err">30969417095184326</span>,<span class="err">0</span><span class="kt">.</span><span class="err">2643227577209</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">8871506452560425</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20039963722229004</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">0601330995559692</span>,<span class="err">0</span><span class="kt">.</span><span class="err">0348707810044</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="gpt2transformer">GPT2Transformer</h2>

  <p>GPT-2: the OpenAI Text-To-Text Transformer</p>

  <p>GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset of 8 million
web pages. GPT-2 is trained with a simple objective: predict the next word, given all of the previous words within
some text. The diversity of the dataset causes this simple goal to contain naturally occurring demonstrations of
many tasks across diverse domains. GPT-2 is a direct scale-up of GPT, with more than 10X the parameters and trained
on more than 10X the amount of data.</p>

  <p>GPT-2 displays a broad set of capabilities, including the ability to generate conditional synthetic text samples of
unprecedented quality, where we prime the model with an input and have it generate a lengthy continuation. In
addition, GPT-2 outperforms other language models trained on specific domains (like Wikipedia, news, or books)
without needing to use these domain-specific training datasets. On language tasks like question answering, reading
comprehension, summarization, and translation, GPT-2 begins to learn these tasks from the raw text, using no
task-specific training data. While scores on these downstream tasks are far from state-of-the-art, they suggest
that the tasks can benefit from unsupervised techniques, given sufficient (unlabeled) data and compute.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val gpt2 = GPT2Transformer.pretrained()
  .setInputCols("document")
  .setOutputCol("generation")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"gpt2"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?q=gpt2">Models Hub</a>.</p>

  <p>For extended examples of usage, see <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2TestSpec.scala">GPT2TestSpec</a>.</p>

  <p><strong>Sources:</strong></p>
  <ul>
    <li><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a></li>
    <li>https://github.com/openai/gpt-2</li>
  </ul>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>Natural language processing tasks, such as question answering, machine translation, reading comprehension, and
summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that
language models begin to learn these tasks without any explicit supervision when trained on a new dataset
of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by
the language model reach F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline
systems without using the 127,000+ training examples. The capacity of the language model is essential to the
success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks.
Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8
tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model
reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path
towards building language processing systems which learn to perform tasks from their naturally occurring
demonstrations.</em></p>

  <p><strong>Note:</strong></p>

  <p>This is a very computationally expensive module especially on larger sequence.
The use of an accelerator such as GPU is recommended.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.html#sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer">GPT2Transformer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer">GPT2Transformer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/seq2seq/GPT2Transformer.scala">GPT2Transformer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"documents"</span><span class="p">)</span>

<span class="n">gpt2</span> <span class="o">=</span> <span class="n">GPT2Transformer</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"gpt2"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"documents"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setMaxOutputLength</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"generation"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">gpt2</span><span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"My name is Leonardo."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"summaries.generation"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                              <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">My</span> <span class="n">name</span> <span class="ow">is</span> <span class="n">Leonardo</span><span class="p">.</span> <span class="n">I</span> <span class="n">am</span> <span class="n">a</span> <span class="n">man</span> <span class="n">of</span> <span class="n">letters</span><span class="p">.</span> <span class="n">I</span> <span class="n">have</span> <span class="n">been</span> <span class="n">a</span> <span class="n">man</span> <span class="k">for</span> <span class="n">many</span> <span class="n">years</span><span class="p">.</span> <span class="n">I</span> <span class="n">was</span> <span class="n">born</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">year</span> <span class="mf">1776.</span> <span class="n">I</span> <span class="n">came</span> <span class="n">to</span> <span class="n">the</span> <span class="n">United</span> <span class="n">States</span> <span class="ow">in</span> <span class="mi">1776</span><span class="p">,</span> <span class="ow">and</span> <span class="n">I</span> <span class="n">have</span> <span class="n">lived</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">United</span> <span class="n">Kingdom</span> <span class="n">since</span> <span class="mf">1776.</span><span class="p">]</span><span class="o">|</span>
<span class="o">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.seq2seq.GPT2Transformer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"documents"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gpt2</span> <span class="k">=</span> <span class="nv">GPT2Transformer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"gpt2"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"documents"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMinOutputLength</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxOutputLength</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDoSample</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTopK</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNoRepeatNgramSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"generation"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">gpt2</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"My name is Leonardo."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">results</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"generation.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                              <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span> <span class="kt">My</span> <span class="kt">name</span> <span class="kt">is</span> <span class="kt">Leonardo.</span> <span class="kt">I</span> <span class="kt">am</span> <span class="kt">a</span> <span class="kt">man</span> <span class="kt">of</span> <span class="kt">letters.</span> <span class="kt">I</span> <span class="kt">have</span> <span class="kt">been</span> <span class="kt">a</span> <span class="kt">man</span> <span class="kt">for</span> <span class="kt">many</span> <span class="kt">years.</span> <span class="kt">I</span> <span class="kt">was</span> <span class="kt">born</span> <span class="kt">in</span> <span class="kt">the</span> <span class="kt">year</span> <span class="err">1776</span><span class="kt">.</span> <span class="kt">I</span> <span class="kt">came</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">United</span> <span class="kt">States</span> <span class="kt">in</span> <span class="err">1776</span>, <span class="kt">and</span> <span class="kt">I</span> <span class="kt">have</span> <span class="kt">lived</span> <span class="kt">in</span> <span class="kt">the</span> <span class="kt">United</span> <span class="kt">Kingdom</span> <span class="kt">since</span> <span class="err">1776</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="hubertforctc">HubertForCTC</h2>

  <p>Hubert Model with a language modeling head on top for Connectionist Temporal Classification
(CTC). Hubert was proposed in HuBERT: Self-Supervised Speech Representation Learning by Masked
Prediction of Hidden Units by Wei-Ning Hsu, Benjamin Bolte, Yao-Hung Hubert Tsai, Kushal
Lakhotia, Ruslan Salakhutdinov, Abdelrahman Mohamed.</p>

  <p>The annotator takes audio files and transcribes it as text. The audio needs to be provided
pre-processed an array of floats.</p>

  <p>Note that this annotator is currently not supported on Apple Silicon processors such as the
M1. This is due to the processor not supporting instructions for XLA.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val speechToText = HubertForCTC.pretrained()
  .setInputCols("audio_assembler")
  .setOutputCol("text")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"asr_hubert_large_ls960"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/audio/HubertForCTCTest.scala">HubertForCTCTestSpec</a>.</p>

  <p><strong>References:</strong></p>

  <p><a href="https://arxiv.org/abs/2106.07447">HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</a></p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>Self-supervised approaches for speech representation learning are challenged by three unique
problems: (1) there are multiple sound units in each input utterance, (2) there is no lexicon
of input sound units during the pre-training phase, and (3) sound units have variable lengths
with no explicit segmentation. To deal with these three problems, we propose the Hidden-Unit
BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an
offline clustering step to provide aligned target labels for a BERT-like prediction loss. A
key ingredient of our approach is applying the prediction loss over the masked regions only,
which forces the model to learn a combined acoustic and language model over the continuous
inputs. HuBERT relies primarily on the consistency of the unsupervised clustering step rather
than the intrinsic quality of the assigned cluster labels. Starting with a simple k-means
teacher of 100 clusters, and using two iterations of clustering, the HuBERT model either
matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech
(960h) and Libri-light (60,000h) benchmarks with 10min, 1h, 10h, 100h, and 960h fine-tuning
subsets. Using a 1B parameter model, HuBERT shows up to 19% and 13% relative WER reduction on
the more challenging dev-other and test-other evaluation subsets.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">AUDIO</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/audio/hubert_for_ctc/index.html#python.sparknlp.annotator.audio.hubert_for_ctc.HubertForCTC">HubertForCTC</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC">HubertForCTC</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/audio/HubertForCTC.scala">HubertForCTC</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">audioAssembler</span> <span class="o">=</span> <span class="n">AudioAssembler</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"audio_content"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"audio_assembler"</span><span class="p">)</span>

<span class="n">speechToText</span> <span class="o">=</span> <span class="n">HubertForCTC</span> \\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"audio_assembler"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">audioAssembler</span><span class="p">,</span> <span class="n">speechToText</span><span class="p">])</span>
<span class="n">processedAudioFloats</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">rawFloats</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"audio_content"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">processedAudioFloats</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">processedAudioFloats</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">MISTER</span> <span class="n">QUILTER</span> <span class="n">IS</span> <span class="n">THE</span> <span class="n">APOSTLE</span> <span class="n">OF</span> <span class="n">THE</span> <span class="n">MIDLE</span> <span class="n">CLASES</span> <span class="n">AND</span> <span class="n">WE</span> <span class="n">ARE</span> <span class="n">GLAD</span> <span class="n">TO</span> <span class="n">WELCOME</span> <span class="n">HIS</span> <span class="n">GOSPEL</span> <span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.audio.HubertForCTC</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">audioAssembler</span><span class="k">:</span> <span class="kt">AudioAssembler</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AudioAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"audio_content"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">speechToText</span><span class="k">:</span> <span class="kt">HubertForCTC</span> <span class="o">=</span> <span class="nc">HubertForCTC</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">:</span> <span class="kt">Pipeline</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">audioAssembler</span><span class="o">,</span> <span class="n">speechToText</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">bufferedSource</span> <span class="k">=</span>
  <span class="nv">scala</span><span class="o">.</span><span class="py">io</span><span class="o">.</span><span class="py">Source</span><span class="o">.</span><span class="py">fromFile</span><span class="o">(</span><span class="s">"src/test/resources/audio/csv/audio_floats.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">rawFloats</span> <span class="k">=</span> <span class="n">bufferedSource</span>
  <span class="o">.</span><span class="py">getLines</span><span class="o">()</span>
  <span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">","</span><span class="o">).</span><span class="py">head</span><span class="o">.</span><span class="py">trim</span><span class="o">.</span><span class="py">toFloat</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toArray</span>
<span class="nv">bufferedSource</span><span class="o">.</span><span class="py">close</span>

<span class="k">val</span> <span class="nv">processedAudioFloats</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">rawFloats</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"audio_content"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">processedAudioFloats</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">processedAudioFloats</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">MISTER</span> <span class="kt">QUILTER</span> <span class="kt">IS</span> <span class="kt">THE</span> <span class="kt">APOSTLE</span> <span class="kt">OF</span> <span class="kt">THE</span> <span class="kt">MIDLE</span> <span class="kt">CLASES</span> <span class="kt">AND</span> <span class="kt">WE</span> <span class="kt">ARE</span> <span class="kt">GLAD</span> <span class="kt">TO</span> <span class="kt">WELCOME</span> <span class="kt">HIS</span> <span class="kt">GOSPEL</span> <span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="instructorembeddings">InstructorEmbeddings</h2>

  <p>Sentence embeddings using INSTRUCTOR.</p>

  <p>Instructor, an instruction-finetuned text embedding model that can generate text
embeddings tailored to any task (e.g., classification, retrieval, clustering, text evaluation,
etc.) and domains (e.g., science, finance, etc.) by simply providing the task instruction,
without any finetuning. Instructor achieves sota on 70 diverse embedding tasks!</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">InstructorEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"instructor_embeddings"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"instructor_base"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?q=Instructor">Models Hub</a>.</p>

  <p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/InstructorEmbeddingsTestSpec.scala">InstructorEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://arxiv.org/abs/2212.09741">One Embedder, Any Task: Instruction-Finetuned Text Embeddings</a></p>

  <p><a href="https://github.com/HKUNLP/instructor-embedding/">INSTRUCTOR Github Repository</a></p>

  <p><strong>Paper abstract</strong></p>

  <p><em>We introduce INSTRUCTOR, a new method for computing text embeddings given task instructions:
every text input is embedded together with instructions explaining the use case (e.g., task
and domain descriptions). Unlike encoders from prior work that are more specialized,
INSTRUCTOR is a single embedder that can generate text embeddings tailored to different
downstream tasks and domains, without any further training. We first annotate instructions for
330 diverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive loss. We
evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are unseen during training),
ranging from classification and information retrieval to semantic textual similarity and text
generation evaluation. INSTRUCTOR, while having an order of magnitude fewer parameters than
the previous best model, achieves state-of-the-art performance, with an average improvement of
3.4% compared to the previous best results on the 70 diverse datasets. Our analysis suggests
that INSTRUCTOR is robust to changes in instructions, and that instruction finetuning
mitigates the challenge of training a single model on diverse datasets. Our model, code, and
data are available at this https URL. https://instructor-embedding.github.io/</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/instructor_embeddings/index.html#sparknlp.annotator.embeddings.instructor_embeddings.InstructorEmbeddings">InstructorEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/InstructorEmbeddings">InstructorEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/InstructorEmbeddings.scala">InstructorEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">InstructorEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setInstruction</span><span class="p">(</span><span class="s">"Represent the Medicine sentence for clustering: "</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"instructor_embeddings"</span><span class="p">)</span>
<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"instructor_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Dynamical Scalar Degree of Freedom in Horava-Lifshitz Gravity"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">2.3497989177703857</span><span class="p">,</span><span class="mf">0.480538547039032</span><span class="p">,</span><span class="o">-</span><span class="mf">0.3238905668258667</span><span class="p">,</span><span class="o">-</span><span class="mf">1.612930893898010</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.InstructorEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">InstructorEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"instructor_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInstruction</span><span class="o">(</span><span class="s">"Represent the Medicine sentence for clustering: "</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"instructor_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"instructor_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Dynamical Scalar Degree of Freedom in Horava-Lifshitz Gravity"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">2</span><span class="kt">.</span><span class="err">3497989177703857</span>,<span class="err">0</span><span class="kt">.</span><span class="err">480538547039032</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3238905668258667</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">612930893898010</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="longformerembeddings">LongformerEmbeddings</h2>

  <p>Longformer is a transformer model for long documents. The Longformer model was presented in <a href="https://arxiv.org/pdf/2004.05150.pdf">Longformer: The Long-Document Transformer</a> by Iz Beltagy, Matthew E. Peters, Arman Cohan.
longformer-base-4096 is a BERT-like model started from the RoBERTa checkpoint and pretrained for MLM on long documents.
It supports sequences of length up to 4,096.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = LongformerEmbeddings.pretrained()
  .setInputCols("document", "token")
  .setOutputCol("embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"longformer_base_4096"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For some examples of usage, see <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddingsTestSpec.scala">LongformerEmbeddingsTestSpec</a>.
Models from the HuggingFace  Transformers library are compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length.
To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer.
Longformers attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention.
Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8.
In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks.
Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on WikiHop and TriviaQA.
We finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset.</em></p>

  <p>The original code can be found <code class="language-plaintext highlighter-rouge">here</code> https://github.com/allenai/longformer.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/longformer_embeddings/index.html#sparknlp.annotator.embeddings.longformer_embeddings.LongformerEmbeddings">LongformerEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings">LongformerEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/LongformerEmbeddings.scala">LongformerEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">LongformerEmbeddings</span> \
      <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"longformer_large_4096"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'ner_conll_longformer_large_4096'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">,</span> <span class="s">'embeddings'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.LongformerEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">LongformerEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"longformer_large_4096"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">4096</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_conll_longformer_large_4096"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-ORG</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">LongformerEmbeddings</span> \
      <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"longformer_base_4096"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.LongformerEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">LongformerEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">LongformerEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.18792399764060974</span><span class="p">,</span><span class="o">-</span><span class="mf">0.14591649174690247</span><span class="p">,</span><span class="mf">0.20547787845134735</span><span class="p">,</span><span class="mf">0.1468472778797</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.22845706343650818</span><span class="p">,</span><span class="mf">0.18073144555091858</span><span class="p">,</span><span class="mf">0.09725798666477203</span><span class="p">,</span><span class="o">-</span><span class="mf">0.0417917296290</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.07037967443466187</span><span class="p">,</span><span class="o">-</span><span class="mf">0.14801117777824402</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03603338822722435</span><span class="p">,</span><span class="o">-</span><span class="mf">0.17893412709</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.08734266459941864</span><span class="p">,</span><span class="mf">0.2486150562763214</span><span class="p">,</span><span class="o">-</span><span class="mf">0.009067727252840996</span><span class="p">,</span><span class="o">-</span><span class="mf">0.24408400058</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.22409197688102722</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4312366545200348</span><span class="p">,</span><span class="mf">0.1401449590921402</span><span class="p">,</span><span class="mf">0.356410235166549</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">LongformerEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">18792399764060974</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14591649174690247</span>,<span class="err">0</span><span class="kt">.</span><span class="err">20547787845134735</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1468472778797</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">22845706343650818</span>,<span class="err">0</span><span class="kt">.</span><span class="err">18073144555091858</span>,<span class="err">0</span><span class="kt">.</span><span class="err">09725798666477203</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0417917296290</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">07037967443466187</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14801117777824402</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03603338822722435</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">17893412709</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08734266459941864</span>,<span class="err">0</span><span class="kt">.</span><span class="err">2486150562763214</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">009067727252840996</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">24408400058</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">22409197688102722</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4312366545200348</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1401449590921402</span>,<span class="err">0</span><span class="kt">.</span><span class="err">356410235166549</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="longformerforquestionanswering">LongformerForQuestionAnswering</h2>

  <p>LongformerForQuestionAnswering can load Longformer Models with a span classification head on
top for extractive question-answering tasks like SQuAD (a linear layer on top of the
hidden-states output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = LongformerForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"longformer_base_base_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnsweringTestSpec.scala">LongformerForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_question_answering/index.html#sparknlp.annotator.classifier_dl.longformer_for_question_answering.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering">LongformerForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForQuestionAnswering.scala">LongformerForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">LongformerForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">LongformerForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="longformerforsequenceclassification">LongformerForSequenceClassification</h2>

  <p>LongformerForSequenceClassification can load Longformer Models with sequence classification/regression head on top
(a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = LongformerForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"longformer_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassificationTestSpec.scala">LongformerForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.longformer_for_sequence_classification.LongformerForSequenceClassification">LongformerForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification">LongformerForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForSequenceClassification.scala">LongformerForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">LongformerForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">LongformerForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="longformerfortokenclassification">LongformerForTokenClassification</h2>

  <p>LongformerForTokenClassification can load Longformer Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tokenClassifier = LongformerForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"longformer_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassificationTestSpec.scala">LongformerForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/longformer_for_token_classification/index.html#sparknlp.annotator.classifier_dl.longformer_for_token_classification.LongformerForTokenClassification">LongformerForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification">LongformerForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/LongformerForTokenClassification.scala">LongformerForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">LongformerForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">LongformerForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="mpnetembeddings">MPNetEmbeddings</h2>

  <p>Sentence embeddings using MPNet.</p>

  <p>The MPNet model was proposed in MPNet: Masked and Permuted Pre-training for Language
Understanding by Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu. MPNet adopts a novel
pre-training method, named masked and permuted language modeling, to inherit the advantages of
masked language modeling and permuted language modeling for natural language understanding.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">MPNetEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mpnet_embeddings"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"all_mpnet_base_v2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?q=MPNet">Models Hub</a>.</p>

  <p>For extended examples of usage, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/MPNetEmbeddingsTestSpec.scala">MPNetEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://arxiv.org/abs/2004.09297">MPNet: Masked and Permuted Pre-training for Language Understanding</a></p>

  <p><a href="https://github.com/microsoft/MPNet">MPNet Github Repository</a></p>

  <p><strong>Paper abstract</strong></p>

  <p><em>BERT adopts masked language modeling (MLM) for pre-training and is one of the most
successful pre-training models. Since BERT neglects dependency among predicted tokens, XLNet
introduces permuted language modeling (PLM) for pre-training to address this problem. However,
XLNet does not leverage the full position information of a sentence and thus suffers from
position discrepancy between pre-training and fine-tuning. In this paper, we propose MPNet, a
novel pre-training method that inherits the advantages of BERT and XLNet and avoids their
limitations. MPNet leverages the dependency among predicted tokens through permuted language
modeling (vs. MLM in BERT), and takes auxiliary position information as input to make the
model see a full sentence and thus reducing the position discrepancy (vs. PLM in XLNet). We
pre-train MPNet on a large-scale dataset (over 160GB text corpora) and fine-tune on a variety
of down-streaming tasks (GLUE, SQuAD, etc). Experimental results show that MPNet outperforms
MLM and PLM by a large margin, and achieves better results on these tasks compared with
previous state-of-the-art pre-trained methods (e.g., BERT, XLNet, RoBERTa) under the same
model setting.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/mpnet_embeddings/index.html#sparknlp.annotator.embeddings.mpnet_embeddings.MPNetEmbeddings">MPNetEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/MPNetEmbeddings">MPNetEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/MPNetEmbeddings.scala">MPNetEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">MPNetEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mpnet_embeddings"</span><span class="p">)</span>
<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"mpnet_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is an example sentence"</span><span class="p">,</span> <span class="s">"Each sentence is converted"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[[</span><span class="mf">0.022502584</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.078291744</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.023030775</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0051000593</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.080340415</span><span class="p">,</span> <span class="mf">0.039</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[[</span><span class="mf">0.041702367</span><span class="p">,</span> <span class="mf">0.0010974605</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.015534201</span><span class="p">,</span> <span class="mf">0.07092203</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0017729357</span><span class="p">,</span> <span class="mf">0.04661</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.MPNetEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">MPNetEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"all_mpnet_base_v2"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mpnet_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"mpnet_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is an example sentence"</span><span class="o">,</span> <span class="s">"Each sentence is converted"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="err">0</span><span class="kt">.</span><span class="err">022502584</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">078291744</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">023030775</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0051000593</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">080340415</span>, <span class="err">0</span><span class="kt">.</span><span class="err">039</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[[</span><span class="err">0</span><span class="kt">.</span><span class="err">041702367</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0010974605</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">015534201</span>, <span class="err">0</span><span class="kt">.</span><span class="err">07092203</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0017729357</span>, <span class="err">0</span><span class="kt">.</span><span class="err">04661</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="mariantransformer">MarianTransformer</h2>

  <p>MarianTransformer: Fast Neural Machine Translation</p>

  <p>Marian is an efficient, free Neural Machine Translation framework written in pure C++ with minimal dependencies.
It is mainly being developed by the Microsoft Translator team. Many academic (most notably the University of
Edinburgh and in the past the Adam Mickiewicz University in Pozna) and commercial contributors help with its
development. MarianTransformer uses the models trained by MarianNMT.</p>

  <p>It is currently the engine behind the Microsoft Translator Neural Machine Translation services and being deployed by
many companies, organizations and research projects.</p>

  <p>Note that this model only supports inputs up to 512 tokens. If you are working with longer 
inputs, consider splitting them first. For example, you can use the SentenceDetectorDL annotator to
split longer texts into sentences.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val marian = MarianTransformer.pretrained()
  .setInputCols("sentence")
  .setOutputCol("translation")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"opus_mt_en_fr"</code>, default language is <code class="language-plaintext highlighter-rouge">"xx"</code> (meaning multi-lingual), if no values are provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Translation">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/multilingual/Translation_Marian.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformerTestSpec.scala">MarianTransformerTestSpec</a>.</p>

  <p><strong>Sources</strong> :</p>

  <p><a href="https://marian-nmt.github.io/">MarianNMT at GitHub</a></p>

  <p><a href="https://www.aclweb.org/anthology/P18-4020/">Marian: Fast Neural Machine Translation in C++ </a></p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>We present Marian, an efficient and self-contained Neural Machine Translation framework with an integrated
automatic differentiation engine based on dynamic computation graphs. Marian is written entirely in C++. We describe
the design of the encoder-decoder framework and demonstrate that a research-friendly toolkit can achieve high
training and translation speed.</em></p>

  <p><strong>Note:</strong></p>

  <p>This is a very computationally expensive module especially on larger sequence.
The use of an accelerator such as GPU is recommended.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.html#sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer">MarianTransformer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer">MarianTransformer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer.scala">MarianTransformer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span> <span class="s">"xx"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">marian</span> <span class="o">=</span> <span class="n">MarianTransformer</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"translation"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxInputLength</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentence</span><span class="p">,</span>
      <span class="n">marian</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What is the capital of France? We should know this in french."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(translation.result) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                               <span class="o">|</span>
<span class="o">+-------------------------------------+</span>
<span class="o">|</span><span class="n">Quelle</span> <span class="n">est</span> <span class="n">la</span> <span class="n">capitale</span> <span class="n">de</span> <span class="n">la</span> <span class="n">France</span> <span class="err">?</span><span class="o">|</span>
<span class="o">|</span><span class="n">On</span> <span class="n">devrait</span> <span class="n">le</span> <span class="n">savoir</span> <span class="n">en</span> <span class="n">franais</span><span class="p">.</span>    <span class="o">|</span>
<span class="o">+-------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetectorDLModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.seq2seq.MarianTransformer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span> <span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">marian</span> <span class="k">=</span> <span class="nv">MarianTransformer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"translation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxInputLength</span><span class="o">(</span><span class="mi">30</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentence</span><span class="o">,</span>
    <span class="n">marian</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What is the capital of France? We should know this in french."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(translation.result) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                               <span class="o">|</span>
<span class="o">+-------------------------------------+</span>
<span class="o">|</span><span class="nc">Quelle</span> <span class="n">est</span> <span class="n">la</span> <span class="n">capitale</span> <span class="n">de</span> <span class="n">la</span> <span class="nc">France</span> <span class="o">?|</span>
<span class="o">|</span><span class="nc">On</span> <span class="n">devrait</span> <span class="n">le</span> <span class="n">savoir</span> <span class="n">en</span> <span class="n">franais</span><span class="o">.</span>    <span class="o">|</span>
<span class="o">+-------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="openaicompletion">OpenAICompletion</h2>

  <p>Transformer that makes a request for OpenAI Completion API for each executor.</p>

  <p>See the <a href="https://platform.openai.com/docs/api-reference/completions/create">OpenAI API Doc</a> for reference.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/openai/openai_completion/index.html#sparknlp.annotator.openai.openai_completion.OpenAICompletion">OpenAICompletion</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/ml/ai/OpenAICompletion">OpenAICompletion</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/ml/ai/OpenAICompletion.scala">OpenAICompletion</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">openai_completion</span> <span class="o">=</span> <span class="n">OpenAICompletion</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"completion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModel</span><span class="p">(</span><span class="s">"text-davinci-003"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxTokens</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">openai_completion</span>
<span class="p">])</span>

<span class="n">empty_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]],</span> <span class="p">[</span><span class="s">"text"</span><span class="p">])</span>
<span class="n">sample_text</span><span class="o">=</span> <span class="p">[[</span><span class="s">"Generate a restaurant review."</span><span class="p">],</span> <span class="p">[</span><span class="s">"Write a review for a local eatery."</span><span class="p">],</span> <span class="p">[</span><span class="s">"Create a JSON with a review of a dining experience."</span><span class="p">]]</span>
<span class="n">sample_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_text</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">sample_df</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">completion</span>                                                                                                                                                                                                                                                                                        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">258</span><span class="p">,</span> \<span class="n">n</span>\<span class="n">nI</span> <span class="n">had</span> <span class="n">the</span> <span class="n">pleasure</span> <span class="n">of</span> <span class="n">dining</span> <span class="n">at</span> <span class="n">La</span> <span class="n">Fiorita</span> <span class="n">recently</span><span class="p">,</span> <span class="ow">and</span> <span class="n">it</span> <span class="n">was</span> <span class="n">a</span> <span class="n">truly</span> <span class="n">delightful</span> <span class="n">experience</span><span class="err">!</span> <span class="n">The</span> <span class="n">menu</span> <span class="n">boasted</span> <span class="n">a</span> <span class="n">wonderful</span> <span class="n">selection</span> <span class="n">of</span> <span class="n">classic</span> <span class="n">Italian</span> <span class="n">dishes</span><span class="p">,</span> <span class="nb">all</span> <span class="n">exquisitely</span> <span class="n">prepared</span> <span class="ow">and</span> <span class="n">presented</span><span class="p">.</span> <span class="n">The</span> <span class="n">service</span> <span class="n">staff</span> <span class="n">was</span> <span class="n">friendly</span> <span class="ow">and</span> <span class="n">attentive</span> <span class="ow">and</span> <span class="n">really</span><span class="p">,</span> <span class="p">{},</span> <span class="p">[]}]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">227</span><span class="p">,</span> \<span class="n">n</span>\<span class="n">nI</span> <span class="n">recently</span> <span class="n">visited</span> <span class="n">Barbecue</span> <span class="n">Joe</span><span class="s">'s for dinner and it was amazing! The menu had so many items to choose from including pulled pork, smoked turkey, brisket, pork ribs, and sandwiches. I opted for the pulled pork sandwich and let, {}, []}]                               |
|[{document, 0, 172, </span><span class="se">\n\n</span><span class="s">{ </span><span class="se">\n</span><span class="s">   "review": { </span><span class="se">\n</span><span class="s">      "overallRating": 4, </span><span class="se">\n</span><span class="s">      "reviewBody": "I enjoyed my meal at this restaurant. The food was flavourful, well-prepared and beautifully presented., {}, []}]                                                                                   |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</span></code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.ml.ai.OpenAICompletion</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">openAICompletion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">OpenAICompletion</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"completion"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setModel</span><span class="o">(</span><span class="s">"text-davinci-003"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setMaxTokens</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">openAICompletion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">promptDF</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
 <span class="s">"Generate a restaurant review."</span><span class="o">,</span>
 <span class="s">"Write a review for a local eatery."</span><span class="o">,</span>
 <span class="s">"Create a JSON with a review of a dining experience."</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">completionDF</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">promptDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">promptDF</span><span class="o">)</span>

<span class="nv">completionDF</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"completion"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">completion</span>                                                                                                                                                                                                                                                                                        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">258</span>, <span class="kt">\n\nI</span> <span class="kt">had</span> <span class="kt">the</span> <span class="kt">pleasure</span> <span class="kt">of</span> <span class="kt">dining</span> <span class="kt">at</span> <span class="kt">La</span> <span class="kt">Fiorita</span> <span class="kt">recently</span>, <span class="kt">and</span> <span class="kt">it</span> <span class="kt">was</span> <span class="kt">a</span> <span class="kt">truly</span> <span class="kt">delightful</span> <span class="kt">experience!</span> <span class="kt">The</span> <span class="kt">menu</span> <span class="kt">boasted</span> <span class="kt">a</span> <span class="kt">wonderful</span> <span class="kt">selection</span> <span class="kt">of</span> <span class="kt">classic</span> <span class="kt">Italian</span> <span class="kt">dishes</span>, <span class="kt">all</span> <span class="kt">exquisitely</span> <span class="kt">prepared</span> <span class="kt">and</span> <span class="kt">presented.</span> <span class="kt">The</span> <span class="kt">service</span> <span class="kt">staff</span> <span class="kt">was</span> <span class="kt">friendly</span> <span class="kt">and</span> <span class="kt">attentive</span> <span class="kt">and</span> <span class="kt">really</span>, <span class="o">{}</span>, <span class="o">[]}]|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">227</span>, <span class="kt">\n\nI</span> <span class="kt">recently</span> <span class="kt">visited</span> <span class="kt">Barbecue</span> <span class="kt">Joe's</span> <span class="kt">for</span> <span class="kt">dinner</span> <span class="kt">and</span> <span class="kt">it</span> <span class="kt">was</span> <span class="kt">amazing!</span> <span class="kt">The</span> <span class="kt">menu</span> <span class="kt">had</span> <span class="kt">so</span> <span class="kt">many</span> <span class="kt">items</span> <span class="kt">to</span> <span class="kt">choose</span> <span class="kt">from</span> <span class="kt">including</span> <span class="kt">pulled</span> <span class="kt">pork</span>, <span class="kt">smoked</span> <span class="kt">turkey</span>, <span class="kt">brisket</span>, <span class="kt">pork</span> <span class="kt">ribs</span>, <span class="kt">and</span> <span class="kt">sandwiches.</span> <span class="kt">I</span> <span class="kt">opted</span> <span class="kt">for</span> <span class="kt">the</span> <span class="kt">pulled</span> <span class="kt">pork</span> <span class="kt">sandwich</span> <span class="kt">and</span> <span class="kt">let</span>, <span class="o">{}</span>, <span class="o">[]}]</span>                               <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">172</span>, <span class="kt">\n\n</span><span class="o">{</span> <span class="kt">\n</span>   <span class="err">"</span><span class="kt">review</span><span class="err">"</span><span class="kt">:</span> <span class="o">{</span> <span class="kt">\n</span>      <span class="err">"</span><span class="kt">overallRating</span><span class="err">"</span><span class="kt">:</span> <span class="err">4</span>, <span class="kt">\n</span>      <span class="err">"</span><span class="kt">reviewBody</span><span class="err">"</span><span class="kt">:</span> <span class="err">"</span><span class="kt">I</span> <span class="kt">enjoyed</span> <span class="kt">my</span> <span class="kt">meal</span> <span class="kt">at</span> <span class="kt">this</span> <span class="kt">restaurant.</span> <span class="kt">The</span> <span class="kt">food</span> <span class="kt">was</span> <span class="kt">flavourful</span>, <span class="kt">well-prepared</span> <span class="kt">and</span> <span class="kt">beautifully</span> <span class="kt">presented.</span>, <span class="o">{}</span>, <span class="o">[]}]</span>                                                                                   <span class="kt">|</span>
<span class="kt">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="robertaembeddings">RoBertaEmbeddings</h2>

  <p>The RoBERTa model was proposed in <a href="https://arxiv.org/abs/1907.11692">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a>
by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.
It is based on Googles BERT model released in 2018.</p>

  <p>It builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = RoBertaEmbeddings.pretrained()
  .setInputCols("document", "token")
  .setOutputCol("embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"roberta_base"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBERTa.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddingsTestSpec.scala">RoBertaEmbeddingsTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>Language model pretraining has led to significant performance gains but careful comparison between different
approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes,
and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication
study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and
training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every
model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results
highlight the importance of previously overlooked design choices, and raise questions about the source of recently
reported improvements. We release our models and code.</em></p>

  <p>Tips:</p>
  <ul>
    <li>RoBERTa has the same architecture as BERT, but uses a byte-level BPE as a tokenizer (same as GPT-2) and uses a different pretraining scheme.</li>
    <li>RoBERTa doesnt have :obj:<code class="language-plaintext highlighter-rouge">token_type_ids</code>, you dont need to indicate which token belongs to which segment. Just separate your segments with the separation token :obj:<code class="language-plaintext highlighter-rouge">tokenizer.sep_token</code> (or :obj:<code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code>)</li>
  </ul>

  <p>The original code can be found <code class="language-plaintext highlighter-rouge">here</code> https://github.com/pytorch/fairseq/tree/master/examples/roberta.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_embeddings/index.html#sparknlp.annotator.embeddings.roberta_embeddings.RoBertaEmbeddings">RoBertaEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings">RoBertaEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/RoBertaEmbeddings.scala">RoBertaEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'roberta_base'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'ner_conll_roberta_base'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">,</span> <span class="s">'embeddings'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_conll_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-ORG</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'roberta_base'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.18792399764060974</span><span class="p">,</span><span class="o">-</span><span class="mf">0.14591649174690247</span><span class="p">,</span><span class="mf">0.20547787845134735</span><span class="p">,</span><span class="mf">0.1468472778797</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.22845706343650818</span><span class="p">,</span><span class="mf">0.18073144555091858</span><span class="p">,</span><span class="mf">0.09725798666477203</span><span class="p">,</span><span class="o">-</span><span class="mf">0.0417917296290</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.07037967443466187</span><span class="p">,</span><span class="o">-</span><span class="mf">0.14801117777824402</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03603338822722435</span><span class="p">,</span><span class="o">-</span><span class="mf">0.17893412709</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.08734266459941864</span><span class="p">,</span><span class="mf">0.2486150562763214</span><span class="p">,</span><span class="o">-</span><span class="mf">0.009067727252840996</span><span class="p">,</span><span class="o">-</span><span class="mf">0.24408400058</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.22409197688102722</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4312366545200348</span><span class="p">,</span><span class="mf">0.1401449590921402</span><span class="p">,</span><span class="mf">0.356410235166549</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.RoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">18792399764060974</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14591649174690247</span>,<span class="err">0</span><span class="kt">.</span><span class="err">20547787845134735</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1468472778797</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">22845706343650818</span>,<span class="err">0</span><span class="kt">.</span><span class="err">18073144555091858</span>,<span class="err">0</span><span class="kt">.</span><span class="err">09725798666477203</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0417917296290</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">07037967443466187</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14801117777824402</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03603338822722435</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">17893412709</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08734266459941864</span>,<span class="err">0</span><span class="kt">.</span><span class="err">2486150562763214</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">009067727252840996</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">24408400058</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">22409197688102722</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4312366545200348</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1401449590921402</span>,<span class="err">0</span><span class="kt">.</span><span class="err">356410235166549</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="robertaforquestionanswering">RoBertaForQuestionAnswering</h2>

  <p>RoBertaForQuestionAnswering can load RoBERTa Models with a span classification head on top for
extractive question-answering tasks like SQuAD (a linear layer on top of the hidden-states
output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = RoBertaForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"roberta_base_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnsweringTestSpec.scala">RoBertaForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_question_answering/index.html#sparknlp.annotator.classifier_dl.roberta_for_question_answering.RoBertaForQuestionAnswering">RoBertaForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering">RoBertaForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForQuestionAnswering.scala">RoBertaForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">RoBertaForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">RoBertaForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="robertaforsequenceclassification">RoBertaForSequenceClassification</h2>

  <p>RoBertaForSequenceClassification can load RoBERTa Models with sequence classification/regression head on top
(a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = RoBertaForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"roberta_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassificationTestSpec.scala">RoBertaForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.roberta_for_sequence_classification.RoBertaForSequenceClassification">RoBertaForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification">RoBertaForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForSequenceClassification.scala">RoBertaForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">RoBertaForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">RoBertaForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="robertafortokenclassification">RoBertaForTokenClassification</h2>

  <p>RoBertaForTokenClassification can load RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tokenClassifier = RoBertaForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"roberta_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassificationTestSpec.scala">RoBertaForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification">RoBertaForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification">RoBertaForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForTokenClassification.scala">RoBertaForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">RoBertaForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">RoBertaForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="robertaforzeroshotclassification">RoBertaForZeroShotClassification</h2>

  <p>RoBertaForZeroShotClassification using a <code class="language-plaintext highlighter-rouge">ModelForSequenceClassification</code> trained on NLI
(natural language inference) tasks. Equivalent of <code class="language-plaintext highlighter-rouge">RoBertaForZeroShotClassification </code> models,
but these models dont require a hardcoded number of potential classes, they can be chosen at
runtime. It usually means its slower but it is much more flexible.</p>

  <p>Note that the model will loop through all provided labels. So the more labels you have, the
longer this process will take.</p>

  <p>Any combination of sequences and labels can be passed and each combination will be posed as a
premise/hypothesis pair and passed to the pretrained model.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">RoBertaForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"roberta_base_zero_shot_classifier_nli"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.roberta_bert_for_zero_shot_classification.RoBertaForZeroShotClassification">RoBertaForZeroShotClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForZeroShotClassification">RoBertaForZeroShotClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/RoBertaForZeroShotClassification.scala">RoBertaForZeroShotClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">RoBertaForZeroShotClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">],</span> <span class="p">[</span><span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">RoBertaForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="robertasentenceembeddings">RoBertaSentenceEmbeddings</h2>

  <p>Sentence-level embeddings using RoBERTa. The RoBERTa model was proposed in <a href="https://arxiv.org/abs/1907.11692">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a>
by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov.
It is based on Googles BERT model released in 2018.</p>

  <p>It builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = RoBertaSentenceEmbeddings.pretrained()
  .setInputCols("sentence")
  .setOutputCol("sentence_embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"sent_roberta_base"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>Language model pretraining has led to significant performance gains but careful comparison between different
approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes,
and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication
study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and
training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every
model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results
highlight the importance of previously overlooked design choices, and raise questions about the source of recently
reported improvements. We release our models and code.</em></p>

  <p>Tips:</p>
  <ul>
    <li>RoBERTa has the same architecture as BERT, but uses a byte-level BPE as a tokenizer (same as GPT-2) and uses a different pretraining scheme.</li>
    <li>RoBERTa doesnt have :obj:<code class="language-plaintext highlighter-rouge">token_type_ids</code>, you dont need to indicate which token belongs to which segment. Just separate your segments with the separation token :obj:<code class="language-plaintext highlighter-rouge">tokenizer.sep_token</code> (or :obj:<code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code>)</li>
  </ul>

  <p>The original code can be found <code class="language-plaintext highlighter-rouge">here</code> https://github.com/pytorch/fairseq/tree/master/examples/roberta.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.html#sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings">RoBertaSentenceEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings">RoBertaSentenceEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/RoBertaSentenceEmbeddings.scala">RoBertaSentenceEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Coming Soon!
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Coming Soon!</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">smallCorpus</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"header"</span><span class="p">,</span><span class="s">"True"</span><span class="p">).</span><span class="n">csv</span><span class="p">(</span><span class="s">"sentiment.csv"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">RoBertaSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">docClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">docClassifier</span>
<span class="p">])</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">smallCorpus</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.RoBertaSentenceEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/test/resources/classifier/sentiment.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClassifierDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">docClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sentenceEmbeddings</span> <span class="o">=</span> <span class="n">RoBertaSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># you can either use the output to train ClassifierDL, SentimentDL, or MultiClassifierDL
# or you can use EmbeddingsFinisher to prepare the results for Spark ML functions
</span>
<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">sentenceEmbeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.18792399764060974</span><span class="p">,</span><span class="o">-</span><span class="mf">0.14591649174690247</span><span class="p">,</span><span class="mf">0.20547787845134735</span><span class="p">,</span><span class="mf">0.1468472778797</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.22845706343650818</span><span class="p">,</span><span class="mf">0.18073144555091858</span><span class="p">,</span><span class="mf">0.09725798666477203</span><span class="p">,</span><span class="o">-</span><span class="mf">0.0417917296290</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.07037967443466187</span><span class="p">,</span><span class="o">-</span><span class="mf">0.14801117777824402</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03603338822722435</span><span class="p">,</span><span class="o">-</span><span class="mf">0.17893412709</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.08734266459941864</span><span class="p">,</span><span class="mf">0.2486150562763214</span><span class="p">,</span><span class="o">-</span><span class="mf">0.009067727252840996</span><span class="p">,</span><span class="o">-</span><span class="mf">0.24408400058</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.22409197688102722</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4312366545200348</span><span class="p">,</span><span class="mf">0.1401449590921402</span><span class="p">,</span><span class="mf">0.356410235166549</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceEmbeddings</span> <span class="k">=</span> <span class="nv">RoBertaSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="c1">// you can either use the output to train ClassifierDL, SentimentDL, or MultiClassifierDL</span>
<span class="c1">// or you can use EmbeddingsFinisher to prepare the results for Spark ML functions</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">sentenceEmbeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">18792399764060974</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14591649174690247</span>,<span class="err">0</span><span class="kt">.</span><span class="err">20547787845134735</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1468472778797</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">22845706343650818</span>,<span class="err">0</span><span class="kt">.</span><span class="err">18073144555091858</span>,<span class="err">0</span><span class="kt">.</span><span class="err">09725798666477203</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0417917296290</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">07037967443466187</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14801117777824402</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03603338822722435</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">17893412709</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08734266459941864</span>,<span class="err">0</span><span class="kt">.</span><span class="err">2486150562763214</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">009067727252840996</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">24408400058</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">22409197688102722</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4312366545200348</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1401449590921402</span>,<span class="err">0</span><span class="kt">.</span><span class="err">356410235166549</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="spanbertcoref">SpanBertCoref</h2>

  <p>A coreference resolution model based on SpanBert</p>

  <p>A coreference resolution model identifies expressions which refer to the same entity in a
text. For example, given a sentence John told Mary he would like to borrow a book from her.
the model will link he to John and her to Mary.</p>

  <p>This model is based on SpanBert, which is fine-tuned on the OntoNotes 5.0 data set.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val dependencyParserApproach = SpanBertCorefModel.pretrained()
  .setInputCols("sentence", "token")
  .setOutputCol("corefs")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"spanbert_base_coref"</code>, if no name is provided. For available pretrained
models please see the <a href="https://sparknlp.org/models">Models Hub</a>.</p>

  <p><strong>References:</strong>
https://github.com/mandarjoshi90/coref</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DEPENDENCY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.html#python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel">SpanBertCorefModel</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel">SpanBertCorefModel</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/coref/SpanBertCorefModel.scala">SpanBertCorefModel</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">corefResolution</span> <span class="o">=</span> <span class="n">SpanBertCorefModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"corefs"</span><span class="p">)</span> \

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">corefResolution</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"John told Mary he would like to borrow a book from her."</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">results</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(corefs) AS coref"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"coref.result as token"</span><span class="p">,</span> <span class="s">"coref.metadata"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">token</span><span class="o">|</span><span class="n">metadata</span>                                                                            <span class="o">|</span>
<span class="o">+-----+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">John</span> <span class="o">|</span><span class="p">{</span><span class="n">head</span><span class="p">.</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="n">ROOT</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">begin</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">end</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">}</span><span class="o">|</span>
<span class="o">|</span><span class="n">he</span>   <span class="o">|</span><span class="p">{</span><span class="n">head</span><span class="p">.</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="n">John</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">begin</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">end</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">}</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">Mary</span> <span class="o">|</span><span class="p">{</span><span class="n">head</span><span class="p">.</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="n">ROOT</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">begin</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">end</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">}</span><span class="o">|</span>
<span class="o">|</span><span class="n">her</span>  <span class="o">|</span><span class="p">{</span><span class="n">head</span><span class="p">.</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="n">Mary</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">begin</span> <span class="o">-&gt;</span> <span class="mi">10</span><span class="p">,</span> <span class="n">head</span><span class="p">.</span><span class="n">end</span> <span class="o">-&gt;</span> <span class="mi">13</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">}</span> <span class="o">|</span>
<span class="o">+-----+------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">corefResolution</span> <span class="k">=</span> <span class="nv">SpanBertCorefModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"corefs"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">corefResolution</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"John told Mary he would like to borrow a book from her."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">""</span><span class="nf">explode</span><span class="o">(</span><span class="n">corefs</span><span class="o">)</span> <span class="nc">AS</span> <span class="n">coref</span><span class="s">""</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"coref.result as token"</span><span class="o">,</span> <span class="s">"coref.metadata"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-----+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">token</span><span class="o">|</span><span class="n">metadata</span>                                                                            <span class="o">|</span>
<span class="o">+-----+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">John</span> <span class="o">|{</span><span class="nv">head</span><span class="o">.</span><span class="py">sentence</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="nc">ROOT</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">begin</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">end</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">}|</span>
<span class="o">|</span><span class="n">he</span>   <span class="o">|{</span><span class="nv">head</span><span class="o">.</span><span class="py">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="nc">John</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">begin</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">end</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">}</span>   <span class="o">|</span>
<span class="o">|</span><span class="nc">Mary</span> <span class="o">|{</span><span class="nv">head</span><span class="o">.</span><span class="py">sentence</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="nc">ROOT</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">begin</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">end</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">}|</span>
<span class="o">|</span><span class="n">her</span>  <span class="o">|{</span><span class="nv">head</span><span class="o">.</span><span class="py">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">head</span> <span class="o">-&gt;</span> <span class="nc">Mary</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">begin</span> <span class="o">-&gt;</span> <span class="mi">10</span><span class="o">,</span> <span class="nv">head</span><span class="o">.</span><span class="py">end</span> <span class="o">-&gt;</span> <span class="mi">13</span><span class="o">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">}</span> <span class="o">|</span>
<span class="o">+-----+------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="swinforimageclassification">SwinForImageClassification</h2>

  <p>SwinImageClassification is an image classifier based on Swin.</p>

  <p>The Swin Transformer was proposed in Swin Transformer: Hierarchical Vision Transformer using
Shifted Windows by Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin,
Baining Guo.</p>

  <p>It is basically a hierarchical Transformer whose representation is computed with shifted
windows. The shifted windowing scheme brings greater efficiency by limiting self-attention
computation to non-overlapping local windows while also allowing for cross-window connection.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val imageClassifier = SwinForImageClassification.pretrained()
  .setInputCols("image_assembler")
  .setOutputCol("class")
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"image_classifier_swin_base_patch_4_window_7_224"</code>, if no name is
provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Image+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassificationTest.scala">SwinForImageClassificationTest</a>.</p>

  <p><strong>References:</strong></p>

  <p><a href="https://arxiv.org/pdf/2103.14030.pdf">Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</a></p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>This paper presents a new vision Transformer, called Swin Transformer, that capably serves
as a general-purpose backbone for computer vision. Challenges in adapting Transformer from
language to vision arise from differences between the two domains, such as large variations in
the scale of visual entities and the high resolution of pixels in images compared to words in
text. To address these differences, we propose a hierarchical Transformer whose representation
is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by
limiting self-attention computation to non-overlapping local windows while also allowing for
cross-window connection. This hierarchical architecture has the flexibility to model at
various scales and has linear computational complexity with respect to image size. These
qualities of Swin Transformer make it compatible with a broad range of vision tasks, including
image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as
object detection (58.7 box AP and 51.1 mask AP on COCO test- dev) and semantic segmentation
(53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the- art by a large
margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the
potential of Transformer-based models as vision backbones. The hierarchical design and the
shifted window approach also prove beneficial for all-MLP architectures.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">IMAGE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.html#sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification">SwinForImageClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification">SwinForImageClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/cv/SwinForImageClassification.scala">SwinForImageClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">imageDF</span><span class="p">:</span> <span class="n">DataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span> \
    <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"dropInvalid"</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"src/test/resources/image/"</span><span class="p">)</span>

<span class="n">imageAssembler</span> <span class="o">=</span> <span class="n">ImageAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">)</span>

<span class="n">imageClassifier</span> <span class="o">=</span> <span class="n">SwinForImageClassification</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"image_assembler"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">imageAssembler</span><span class="p">,</span> <span class="n">imageClassifier</span><span class="p">])</span>
<span class="n">pipelineDF</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">imageDF</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">imageDF</span><span class="p">)</span>

<span class="n">pipelineDF</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="p">,</span> <span class="s">"class.result"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">palace</span><span class="p">.</span><span class="n">JPEG</span>      <span class="o">|</span><span class="p">[</span><span class="n">palace</span><span class="p">]</span>                                                  <span class="o">|</span>
<span class="o">|</span><span class="n">egyptian_cat</span><span class="p">.</span><span class="n">jpeg</span><span class="o">|</span><span class="p">[</span><span class="n">tabby</span><span class="p">,</span> <span class="n">tabby</span> <span class="n">cat</span><span class="p">]</span>                                        <span class="o">|</span>
<span class="o">|</span><span class="n">hippopotamus</span><span class="p">.</span><span class="n">JPEG</span><span class="o">|</span><span class="p">[</span><span class="n">hippopotamus</span><span class="p">,</span> <span class="n">hippo</span><span class="p">,</span> <span class="n">river</span> <span class="n">horse</span><span class="p">,</span> <span class="n">Hippopotamus</span> <span class="n">amphibius</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">hen</span><span class="p">.</span><span class="n">JPEG</span>         <span class="o">|</span><span class="p">[</span><span class="n">hen</span><span class="p">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="n">ostrich</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">ostrich</span><span class="p">,</span> <span class="n">Struthio</span> <span class="n">camelus</span><span class="p">]</span>                               <span class="o">|</span>
<span class="o">|</span><span class="n">junco</span><span class="p">.</span><span class="n">JPEG</span>       <span class="o">|</span><span class="p">[</span><span class="n">junco</span><span class="p">,</span> <span class="n">snowbird</span><span class="p">]</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="n">bluetick</span><span class="p">.</span><span class="n">jpg</span>     <span class="o">|</span><span class="p">[</span><span class="n">bluetick</span><span class="p">]</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="n">chihuahua</span><span class="p">.</span><span class="n">jpg</span>    <span class="o">|</span><span class="p">[</span><span class="n">Chihuahua</span><span class="p">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="n">tractor</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">tractor</span><span class="p">]</span>                                                 <span class="o">|</span>
<span class="o">|</span><span class="n">ox</span><span class="p">.</span><span class="n">JPEG</span>          <span class="o">|</span><span class="p">[</span><span class="n">ox</span><span class="p">]</span>                                                      <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.ImageAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">imageDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span>
  <span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"dropInvalid"</span><span class="o">,</span> <span class="n">value</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"src/test/resources/image/"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ImageAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageClassifier</span> <span class="k">=</span> <span class="nc">SwinForImageClassification</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"class"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">imageAssembler</span><span class="o">,</span> <span class="n">imageClassifier</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineDF</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">imageDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">imageDF</span><span class="o">)</span>

<span class="n">pipelineDF</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="o">,</span> <span class="s">"class.result"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="nv">palace</span><span class="o">.</span><span class="py">JPEG</span>      <span class="o">|[</span><span class="kt">palace</span><span class="o">]</span>                                                  <span class="o">|</span>
<span class="o">|</span><span class="nv">egyptian_cat</span><span class="o">.</span><span class="py">jpeg</span><span class="o">|[</span><span class="kt">tabby</span>, <span class="kt">tabby</span> <span class="kt">cat</span><span class="o">]</span>                                        <span class="o">|</span>
<span class="o">|</span><span class="nv">hippopotamus</span><span class="o">.</span><span class="py">JPEG</span><span class="o">|[</span><span class="kt">hippopotamus</span>, <span class="kt">hippo</span>, <span class="kt">river</span> <span class="kt">horse</span>, <span class="kt">Hippopotamus</span> <span class="kt">amphibius</span><span class="o">]|</span>
<span class="o">|</span><span class="nv">hen</span><span class="o">.</span><span class="py">JPEG</span>         <span class="o">|[</span><span class="kt">hen</span><span class="o">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="nv">ostrich</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">ostrich</span>, <span class="kt">Struthio</span> <span class="kt">camelus</span><span class="o">]</span>                               <span class="o">|</span>
<span class="o">|</span><span class="nv">junco</span><span class="o">.</span><span class="py">JPEG</span>       <span class="o">|[</span><span class="kt">junco</span>, <span class="kt">snowbird</span><span class="o">]</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="nv">bluetick</span><span class="o">.</span><span class="py">jpg</span>     <span class="o">|[</span><span class="kt">bluetick</span><span class="o">]</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="nv">chihuahua</span><span class="o">.</span><span class="py">jpg</span>    <span class="o">|[</span><span class="kt">Chihuahua</span><span class="o">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="nv">tractor</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">tractor</span><span class="o">]</span>                                                 <span class="o">|</span>
<span class="o">|</span><span class="nv">ox</span><span class="o">.</span><span class="py">JPEG</span>          <span class="o">|[</span><span class="kt">ox</span><span class="o">]</span>                                                      <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="t5transformer">T5Transformer</h2>

  <p>T5: the Text-To-Text Transfer Transformer</p>

  <p>T5 reconsiders all NLP tasks into a unified text-to-text-format where the input and output are always
text strings, in contrast to BERT-style models that can only output either a class label or a span of the input.
The text-to-text framework is able to use the same model, loss function, and hyper-parameters on any NLP task,
including machine translation, document summarization, question answering, and classification tasks
(e.g., sentiment analysis). T5 can even apply to regression tasks by training it to predict the string
representation of a number instead of the number itself.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val t5 = T5Transformer.pretrained()
  .setTask("summarize:")
  .setInputCols("document")
  .setOutputCol("summaries")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"t5_small"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?q=t5">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/question-answering/Question_Answering_and_Summarization_with_T5.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/seq2seq/T5TestSpec.scala">T5TestSpec</a>.</p>

  <p><strong>Sources:</strong></p>
  <ul>
    <li><a href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html">Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer</a></li>
    <li><a href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></li>
    <li>https://github.com/google-research/text-to-text-transfer-transformer</li>
  </ul>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream
task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer
learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the
landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based
language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures,
unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining
the insights from our exploration with scale and our new Colossal Clean Crawled Corpus, we achieve state-of-the-art
results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate
future work on transfer learning for NLP, we release our data set, pre-trained models, and code.</em></p>

  <p><strong>Note:</strong></p>

  <p>This is a very computationally expensive module especially on larger sequence.
The use of an accelerator such as GPU is recommended.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/seq2seq/t5_transformer/index.html#sparknlp.annotator.seq2seq.t5_transformer.T5Transformer">T5Transformer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer">T5Transformer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/seq2seq/T5Transformer.scala">T5Transformer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"documents"</span><span class="p">)</span>

<span class="n">t5</span> <span class="o">=</span> <span class="n">T5Transformer</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"t5_small"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setTask</span><span class="p">(</span><span class="s">"summarize:"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"documents"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setMaxOutputLength</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"summaries"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">t5</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
    <span class="s">"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a "</span> <span class="o">+</span>
      <span class="s">"downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness"</span> <span class="o">+</span>
      <span class="s">" of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this "</span> <span class="o">+</span>
      <span class="s">"paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework "</span> <span class="o">+</span>
      <span class="s">"that converts all text-based language problems into a text-to-text format. Our systematic study compares "</span> <span class="o">+</span>
      <span class="s">"pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens "</span> <span class="o">+</span>
      <span class="s">"of language understanding tasks. By combining the insights from our exploration with scale and our new "</span> <span class="o">+</span>
      <span class="s">"Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering "</span> <span class="o">+</span>
      <span class="s">"summarization, question answering, text classification, and more. To facilitate future work on transfer "</span> <span class="o">+</span>
      <span class="s">"learning for NLP, we release our data set, pre-trained models, and code."</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"summaries.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">transfer</span> <span class="n">learning</span> <span class="n">has</span> <span class="n">emerged</span> <span class="k">as</span> <span class="n">a</span> <span class="n">powerful</span> <span class="n">technique</span> <span class="ow">in</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span> <span class="p">(</span><span class="n">NLP</span><span class="p">)</span> <span class="n">the</span> <span class="n">effectiveness</span> <span class="n">of</span> <span class="n">transfer</span> <span class="n">learning</span> <span class="n">has</span> <span class="n">given</span> <span class="n">rise</span> <span class="n">to</span> <span class="n">a</span> <span class="n">diversity</span> <span class="n">of</span> <span class="n">approaches</span><span class="p">,</span> <span class="n">methodologies</span><span class="p">,</span> <span class="ow">and</span> <span class="n">practice</span> <span class="p">.]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.seq2seq.T5Transformer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"documents"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">t5</span> <span class="k">=</span> <span class="nv">T5Transformer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"t5_small"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTask</span><span class="o">(</span><span class="s">"summarize:"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"documents"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMaxOutputLength</span><span class="o">(</span><span class="mi">200</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"summaries"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">t5</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a "</span> <span class="o">+</span>
    <span class="s">"downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness"</span> <span class="o">+</span>
    <span class="s">" of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this "</span> <span class="o">+</span>
    <span class="s">"paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework "</span> <span class="o">+</span>
    <span class="s">"that converts all text-based language problems into a text-to-text format. Our systematic study compares "</span> <span class="o">+</span>
    <span class="s">"pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens "</span> <span class="o">+</span>
    <span class="s">"of language understanding tasks. By combining the insights from our exploration with scale and our new "</span> <span class="o">+</span>
    <span class="s">"Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering "</span> <span class="o">+</span>
    <span class="s">"summarization, question answering, text classification, and more. To facilitate future work on transfer "</span> <span class="o">+</span>
    <span class="s">"learning for NLP, we release our data set, pre-trained models, and code."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"summaries.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">transfer</span> <span class="kt">learning</span> <span class="kt">has</span> <span class="kt">emerged</span> <span class="kt">as</span> <span class="kt">a</span> <span class="kt">powerful</span> <span class="kt">technique</span> <span class="kt">in</span> <span class="kt">natural</span> <span class="kt">language</span> <span class="kt">processing</span> <span class="o">(</span><span class="kt">NLP</span><span class="o">)</span> <span class="kt">the</span> <span class="kt">effectiveness</span> <span class="kt">of</span> <span class="kt">transfer</span> <span class="kt">learning</span> <span class="kt">has</span> <span class="kt">given</span> <span class="kt">rise</span> <span class="kt">to</span> <span class="kt">a</span> <span class="kt">diversity</span> <span class="kt">of</span> <span class="kt">approaches</span>, <span class="kt">methodologies</span>, <span class="kt">and</span> <span class="kt">practice</span> <span class="kt">.</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="tapasforquestionanswering">TapasForQuestionAnswering</h2>

  <p>TapasForQuestionAnswering is an implementation of TaPas - a BERT-based model specifically
designed for answering questions about tabular data. It takes TABLE and DOCUMENT annotations
as input and tries to answer the questions in the document by using the data from the table.
The model is based in BertForQuestionAnswering and shares all its parameters with it.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tapas = TapasForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "table"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"table_qa_tapas_base_finetuned_wtq"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Table+Question+Understanding">Models Hub</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TABLE, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/tapas_for_question_answering/index.html?highlight=tapas#python.sparknlp.annotator.classifier_dl.tapas_for_question_answering.TapasForQuestionAnswering">TapasForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering">TapasForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/TapasForQuestionAnswering.scala">TapasForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"table_json"</span><span class="p">,</span> <span class="s">"questions"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"document_table"</span><span class="p">,</span> <span class="s">"document_questions"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_questions"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"questions"</span><span class="p">)</span>

<span class="n">table_assembler</span> <span class="o">=</span> <span class="n">TableAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_table"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"table"</span><span class="p">)</span>

<span class="n">tapas</span> <span class="o">=</span> <span class="n">TapasForQuestionAnswering</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"questions"</span><span class="p">,</span> <span class="s">"table"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answers"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">table_assembler</span><span class="p">,</span>
    <span class="n">tapas</span><span class="p">])</span>

<span class="n">json_data</span> <span class="o">=</span> \<span class="s">"</span><span class="se">\"\"</span><span class="s">
{
    "</span><span class="n">header</span><span class="s">": ["</span><span class="n">name</span><span class="s">", "</span><span class="n">money</span><span class="s">", "</span><span class="n">age</span><span class="s">"],
    "</span><span class="n">rows</span><span class="s">": [
    ["</span><span class="n">Donald</span> <span class="n">Trump</span><span class="s">", "</span><span class="err">$</span><span class="mi">100</span><span class="p">,</span><span class="mi">000</span><span class="p">,</span><span class="mi">000</span><span class="s">", "</span><span class="mi">75</span><span class="s">"],
    ["</span><span class="n">Elon</span> <span class="n">Musk</span><span class="s">", "</span><span class="err">$</span><span class="mi">20</span><span class="p">,</span><span class="mi">000</span><span class="p">,</span><span class="mi">000</span><span class="p">,</span><span class="mi">000</span><span class="p">,</span><span class="mi">000</span><span class="s">", "</span><span class="mi">55</span><span class="s">"]
    ]
}
</span><span class="se">\"\"\"</span><span class="s">
model = pipeline.fit(data)
model</span><span class="se">\
</span><span class="s">    .transform(data)</span><span class="se">\
</span><span class="s">    .selectExpr("</span><span class="n">explode</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span> <span class="n">AS</span> <span class="n">answer</span><span class="s">")</span><span class="se">\
</span><span class="s">    .select("</span><span class="n">answer</span><span class="p">.</span><span class="n">metadata</span><span class="p">.</span><span class="n">question</span><span class="s">", "</span><span class="n">answer</span><span class="p">.</span><span class="n">result</span><span class="s">")</span><span class="se">\
</span><span class="s">    .show(truncate=False)
+-----------------------+----------------------------------------+
|question               |result                                  |
+-----------------------+----------------------------------------+
|Who earns 100,000,000? |Donald Trump                            |
|Who has more money?    |Elon Musk                               |
|How much they all earn?|COUNT($100,000,000, $20,000,000,000,000)|
|How old are they?      |AVERAGE(75, 55)                         |
+-----------------------+----------------------------------------+
</span></code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

 <span class="k">val</span> <span class="nv">questions</span> <span class="k">=</span>
   <span class="s">"""
    |Who earns 100,000,000?
    |Who has more money?
    |How old are they?
    |"""</span><span class="o">.</span><span class="py">stripMargin</span><span class="o">.</span><span class="py">trim</span>

 <span class="k">val</span> <span class="nv">jsonData</span> <span class="k">=</span>
   <span class="s">"""
    |{
    | "header": ["name", "money", "age"],
    | "rows": [
    |   ["Donald Trump", "$100,000,000", "75"],
    |   ["Elon Musk", "$20,000,000,000,000", "55"]
    | ]
    |}
    |"""</span><span class="o">.</span><span class="py">stripMargin</span><span class="o">.</span><span class="py">trim</span>

 <span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="n">jsonData</span><span class="o">,</span> <span class="n">questions</span><span class="o">))</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"json_table"</span><span class="o">,</span> <span class="s">"questions"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">repartition</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"json_table"</span><span class="o">,</span> <span class="s">"questions"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_table"</span><span class="o">,</span> <span class="s">"document_questions"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nc">SentenceDetectorDLModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_questions"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"question"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tableAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TableAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputFormat</span><span class="o">(</span><span class="s">"json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_table"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"table"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tapas</span> <span class="k">=</span> <span class="nc">TapasForQuestionAnswering</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"table"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span>
    <span class="nc">Array</span><span class="o">(</span>
      <span class="n">docAssembler</span><span class="o">,</span>
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tableAssembler</span><span class="o">,</span>
       <span class="n">tapas</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="n">result</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(answer) as answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span>
    <span class="s">"answer.metadata.question"</span><span class="o">,</span>
    <span class="s">"answer.result"</span><span class="o">)</span>

<span class="o">+-----------------------+----------------------------------------+</span>
<span class="o">|</span><span class="n">question</span>               <span class="o">|</span><span class="n">result</span>                                  <span class="o">|</span>
<span class="o">+-----------------------+----------------------------------------+</span>
<span class="o">|</span><span class="nc">Who</span> <span class="n">earns</span> <span class="mi">100</span><span class="o">,</span><span class="mi">000</span><span class="o">,</span><span class="mi">000</span><span class="o">?</span> <span class="o">|</span><span class="nc">Donald</span> <span class="nc">Trump</span>                            <span class="o">|</span>
<span class="o">|</span><span class="nc">Who</span> <span class="n">has</span> <span class="n">more</span> <span class="n">money</span><span class="o">?</span>    <span class="o">|</span><span class="nc">Elon</span> <span class="nc">Musk</span>                               <span class="o">|</span>
<span class="o">|</span><span class="nc">How</span> <span class="n">much</span> <span class="n">they</span> <span class="n">all</span> <span class="n">earn</span><span class="o">?|</span><span class="nc">COUNT</span><span class="o">(</span><span class="n">$100</span><span class="o">,</span><span class="mi">000</span><span class="o">,</span><span class="mi">000</span><span class="o">,</span> <span class="n">$20</span><span class="o">,</span><span class="mi">000</span><span class="o">,</span><span class="mi">000</span><span class="o">,</span><span class="mi">000</span><span class="o">,</span><span class="mi">000</span><span class="o">)|</span>
<span class="o">|</span><span class="nc">How</span> <span class="n">old</span> <span class="n">are</span> <span class="n">they</span><span class="o">?</span>      <span class="o">|</span><span class="nc">AVERAGE</span><span class="o">(</span><span class="mi">75</span><span class="o">,</span> <span class="mi">55</span><span class="o">)</span>                         <span class="o">|</span>
<span class="o">+-----------------------+----------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="universalsentenceencoder">UniversalSentenceEncoder</h2>

  <p>The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val useEmbeddings = UniversalSentenceEncoder.pretrained()
  .setInputCols("sentence")
  .setOutputCol("sentence_embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"tfhub_use"</code>, if no name is provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/classification/ClassifierDL_Train_multi_class_news_category_classifier.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoderTestSpec.scala">UniversalSentenceEncoderTestSpec</a>.</p>

  <p><strong>Sources:</strong></p>

  <p><a href="https://arxiv.org/abs/1803.11175">Universal Sentence Encoder</a></p>

  <p>https://tfhub.dev/google/universal-sentence-encoder/2</p>

  <p><strong>Paper abstract:</strong></p>

  <p><em>We present models for encoding sentences into embedding vectors that specifically target transfer learning to other
NLP tasks. The models are efficient and result in accurate performance on diverse transfer tasks. Two variants of the
encoding models allow for trade-offs between accuracy and compute resources. For both variants, we investigate and
report the relationship between model complexity, resource consumption, the availability of transfer task training
data, and task performance. Comparisons are made with baselines that use word level transfer learning via pretrained
word embeddings as well as baselines do not use any transfer learning. We find that transfer learning using sentence
embeddings tends to outperform word level transfer. With transfer learning via sentence embeddings, we observe
surprisingly good performance with minimal amounts of supervised training data for a transfer task. We obtain
encouraging results on Word Embedding Association Tests (WEAT) targeted at detecting model bias. Our pre-trained
sentence encoding models are made freely available for download and on TF Hub.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/universal_sentence_encoder/index.html#sparknlp.annotator.embeddings.universal_sentence_encoder.UniversalSentenceEncoder">UniversalSentenceEncoder</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder">UniversalSentenceEncoder</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/UniversalSentenceEncoder.scala">UniversalSentenceEncoder</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'tfhub_use'</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">SentimentDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'sentimentdl_use_imdb'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentiment"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">classifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"That was a fantastic movie!"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"sentiment.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.SentimentDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"tfhub_use"</span><span class="o">,</span> <span class="n">lang</span> <span class="k">=</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">classifier</span> <span class="k">=</span> <span class="nv">SentimentDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentimentdl_use_imdb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentiment"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">classifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"That was a fantastic movie!"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"sentiment.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">SentimentDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentiment"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">classifier</span>
<span class="p">])</span>

<span class="n">smallCorpus</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"header"</span><span class="p">,</span> <span class="s">"True"</span><span class="p">).</span><span class="n">csv</span><span class="p">(</span><span class="s">"sentiment.csv"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">smallCorpus</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.</span><span class="o">{</span><span class="nc">SentimentDLApproach</span><span class="o">,</span> <span class="nc">SentimentDLModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">useEmbeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentimentDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentiment"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">32</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">useEmbeddings</span><span class="o">,</span>
  <span class="n">docClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"sentiment.csv"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentence</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.04616805538535118</span><span class="p">,</span><span class="mf">0.022307956591248512</span><span class="p">,</span><span class="o">-</span><span class="mf">0.044395286589860916</span><span class="p">,</span><span class="o">-</span><span class="mf">0.0016493503</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentence</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">04616805538535118</span>,<span class="err">0</span><span class="kt">.</span><span class="err">022307956591248512</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">044395286589860916</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0016493503</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="vitforimageclassification">ViTForImageClassification</h2>

  <p>Vision Transformer (ViT) for image classification.</p>

  <p>ViT is a transformer based alternative to the convolutional neural networks usually used for
image recognition tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val imageClassifier = ViTForImageClassification.pretrained()
  .setInputCols("image_assembler")
  .setOutputCol("class")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"image_classifier_vit_base_patch16_224"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Image+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/cv/ViTImageClassificationTestSpec.scala">ViTImageClassificationTestSpec</a>.</p>

  <p><strong>References:</strong></p>

  <p><a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>While the Transformer architecture has become the de-facto standard for natural language
processing tasks, its applications to computer vision remain limited. In vision, attention is
either applied in conjunction with convolutional networks, or used to replace certain
components of convolutional networks while keeping their overall structure in place. We show
that this reliance on CNNs is not necessary and a pure transformer applied directly to
sequences of image patches can perform very well on image classification tasks. When
pre-trained on large amounts of data and transferred to multiple mid-sized or small image
recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains
excellent results compared to state-of-the-art convolutional networks while requiring
substantially fewer computational resources to train.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">IMAGE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/cv/vit_for_image_classification/index.html#sparknlp.annotator.cv.vit_for_image_classification.ViTForImageClassification">ViTForImageClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification">ViTForImageClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/cv/ViTForImageClassification.scala">ViTForImageClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">imageDF</span><span class="p">:</span> <span class="n">DataFrame</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span> \\
    <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"dropInvalid"</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"src/test/resources/image/"</span><span class="p">)</span>
<span class="n">imageAssembler</span> <span class="o">=</span> <span class="n">ImageAssembler</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">)</span>
<span class="n">imageClassifier</span> <span class="o">=</span> <span class="n">ViTForImageClassification</span> \\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"image_assembler"</span><span class="p">])</span> \\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">imageAssembler</span><span class="p">,</span> <span class="n">imageClassifier</span><span class="p">])</span>
<span class="n">pipelineDF</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">imageDF</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">imageDF</span><span class="p">)</span>

<span class="n">pipelineDF</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="p">,</span> <span class="s">"class.result"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">palace</span><span class="p">.</span><span class="n">JPEG</span>      <span class="o">|</span><span class="p">[</span><span class="n">palace</span><span class="p">]</span>                                                  <span class="o">|</span>
<span class="o">|</span><span class="n">egyptian_cat</span><span class="p">.</span><span class="n">jpeg</span><span class="o">|</span><span class="p">[</span><span class="n">Egyptian</span> <span class="n">cat</span><span class="p">]</span>                                            <span class="o">|</span>
<span class="o">|</span><span class="n">hippopotamus</span><span class="p">.</span><span class="n">JPEG</span><span class="o">|</span><span class="p">[</span><span class="n">hippopotamus</span><span class="p">,</span> <span class="n">hippo</span><span class="p">,</span> <span class="n">river</span> <span class="n">horse</span><span class="p">,</span> <span class="n">Hippopotamus</span> <span class="n">amphibius</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">hen</span><span class="p">.</span><span class="n">JPEG</span>         <span class="o">|</span><span class="p">[</span><span class="n">hen</span><span class="p">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="n">ostrich</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">ostrich</span><span class="p">,</span> <span class="n">Struthio</span> <span class="n">camelus</span><span class="p">]</span>                               <span class="o">|</span>
<span class="o">|</span><span class="n">junco</span><span class="p">.</span><span class="n">JPEG</span>       <span class="o">|</span><span class="p">[</span><span class="n">junco</span><span class="p">,</span> <span class="n">snowbird</span><span class="p">]</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="n">bluetick</span><span class="p">.</span><span class="n">jpg</span>     <span class="o">|</span><span class="p">[</span><span class="n">bluetick</span><span class="p">]</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="n">chihuahua</span><span class="p">.</span><span class="n">jpg</span>    <span class="o">|</span><span class="p">[</span><span class="n">Chihuahua</span><span class="p">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="n">tractor</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">tractor</span><span class="p">]</span>                                                 <span class="o">|</span>
<span class="o">|</span><span class="n">ox</span><span class="p">.</span><span class="n">JPEG</span>          <span class="o">|</span><span class="p">[</span><span class="n">ox</span><span class="p">]</span>                                                      <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.ImageAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">imageDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span>
  <span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"dropInvalid"</span><span class="o">,</span> <span class="n">value</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"src/test/resources/image/"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ImageAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageClassifier</span> <span class="k">=</span> <span class="nc">ViTForImageClassification</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"class"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">imageAssembler</span><span class="o">,</span> <span class="n">imageClassifier</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineDF</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">imageDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">imageDF</span><span class="o">)</span>

<span class="n">pipelineDF</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="o">,</span> <span class="s">"class.result"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
<span class="o">|</span><span class="nv">palace</span><span class="o">.</span><span class="py">JPEG</span>      <span class="o">|[</span><span class="kt">palace</span><span class="o">]</span>                                                  <span class="o">|</span>
<span class="o">|</span><span class="nv">egyptian_cat</span><span class="o">.</span><span class="py">jpeg</span><span class="o">|[</span><span class="kt">Egyptian</span> <span class="kt">cat</span><span class="o">]</span>                                            <span class="o">|</span>
<span class="o">|</span><span class="nv">hippopotamus</span><span class="o">.</span><span class="py">JPEG</span><span class="o">|[</span><span class="kt">hippopotamus</span>, <span class="kt">hippo</span>, <span class="kt">river</span> <span class="kt">horse</span>, <span class="kt">Hippopotamus</span> <span class="kt">amphibius</span><span class="o">]|</span>
<span class="o">|</span><span class="nv">hen</span><span class="o">.</span><span class="py">JPEG</span>         <span class="o">|[</span><span class="kt">hen</span><span class="o">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="nv">ostrich</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">ostrich</span>, <span class="kt">Struthio</span> <span class="kt">camelus</span><span class="o">]</span>                               <span class="o">|</span>
<span class="o">|</span><span class="nv">junco</span><span class="o">.</span><span class="py">JPEG</span>       <span class="o">|[</span><span class="kt">junco</span>, <span class="kt">snowbird</span><span class="o">]</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="nv">bluetick</span><span class="o">.</span><span class="py">jpg</span>     <span class="o">|[</span><span class="kt">bluetick</span><span class="o">]</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="nv">chihuahua</span><span class="o">.</span><span class="py">jpg</span>    <span class="o">|[</span><span class="kt">Chihuahua</span><span class="o">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="nv">tractor</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">tractor</span><span class="o">]</span>                                                 <span class="o">|</span>
<span class="o">|</span><span class="nv">ox</span><span class="o">.</span><span class="py">JPEG</span>          <span class="o">|[</span><span class="kt">ox</span><span class="o">]</span>                                                      <span class="o">|</span>
<span class="o">+-----------------+----------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="visionencoderdecoderforimagecaptioning">VisionEncoderDecoderForImageCaptioning</h2>

  <p>VisionEncoderDecoder model that converts images into text captions. It allows for the use of
pretrained vision auto-encoding models, such as ViT, BEiT, or DeiT as the encoder, in
combination with pretrained language models, like RoBERTa, GPT2, or BERT as the decoder.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">imageClassifier</span> <span class="k">=</span> <span class="nv">VisionEncoderDecoderForImageCaptioning</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"caption"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"image_captioning_vit_gpt2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Image+Captioning">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To
see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/cv/VisionEncoderDecoderTestSpec.scala">VisionEncoderDecoderTestSpec</a>.</p>

  <p><em>Note:</em></p>

  <p>This is a very computationally expensive module especially on larger batch sizes. The use of an
accelerator such as GPU is recommended.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">IMAGE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/cv/vision_encoder_decoder_for_image_captioning/index.html#sparknlp.annotator.cv.vision_encoder_decoder_for_image_captioning.VisionEncoderDecoderForImageCaptioning">VisionEncoderDecoderForImageCaptioning</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/cv/VisionEncoderDecoderForImageCaptioning">VisionEncoderDecoderForImageCaptioning</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/cv/VisionEncoderDecoderForCaptioning.scala">VisionEncoderDecoderForImageCaptioning</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">imageDF</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span> \
    <span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"dropInvalid"</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"src/test/resources/image/"</span><span class="p">)</span>
<span class="n">imageAssembler</span> <span class="o">=</span> <span class="n">ImageAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">)</span>
<span class="n">imageCaptioning</span> <span class="o">=</span> <span class="n">VisionEncoderDecoderForImageCaptioning</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setBeamSize</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDoSample</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"image_assembler"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"caption"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">imageAssembler</span><span class="p">,</span> <span class="n">imageCaptioning</span><span class="p">])</span>
<span class="n">pipelineDF</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">imageDF</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">imageDF</span><span class="p">)</span>
<span class="n">pipelineDF</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="p">,</span> <span class="s">"caption.result"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                   <span class="o">|</span>
<span class="o">+-----------------+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">palace</span><span class="p">.</span><span class="n">JPEG</span>      <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">large</span> <span class="n">room</span> <span class="n">filled</span> <span class="k">with</span> <span class="n">furniture</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">large</span> <span class="n">window</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">egyptian_cat</span><span class="p">.</span><span class="n">jpeg</span><span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">cat</span> <span class="n">laying</span> <span class="n">on</span> <span class="n">a</span> <span class="n">couch</span> <span class="nb">next</span> <span class="n">to</span> <span class="n">another</span> <span class="n">cat</span><span class="p">]</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">hippopotamus</span><span class="p">.</span><span class="n">JPEG</span><span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">brown</span> <span class="n">bear</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">body</span> <span class="n">of</span> <span class="n">water</span><span class="p">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="n">hen</span><span class="p">.</span><span class="n">JPEG</span>         <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">flock</span> <span class="n">of</span> <span class="n">chickens</span> <span class="n">standing</span> <span class="nb">next</span> <span class="n">to</span> <span class="n">each</span> <span class="n">other</span><span class="p">]</span>        <span class="o">|</span>
<span class="o">|</span><span class="n">ostrich</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">large</span> <span class="n">bird</span> <span class="n">standing</span> <span class="n">on</span> <span class="n">top</span> <span class="n">of</span> <span class="n">a</span> <span class="n">lush</span> <span class="n">green</span> <span class="n">field</span><span class="p">]</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">junco</span><span class="p">.</span><span class="n">JPEG</span>       <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">small</span> <span class="n">bird</span> <span class="n">standing</span> <span class="n">on</span> <span class="n">a</span> <span class="n">wet</span> <span class="n">ground</span><span class="p">]</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">bluetick</span><span class="p">.</span><span class="n">jpg</span>     <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">small</span> <span class="n">dog</span> <span class="n">standing</span> <span class="n">on</span> <span class="n">a</span> <span class="n">wooden</span> <span class="n">floor</span><span class="p">]</span>                 <span class="o">|</span>
<span class="o">|</span><span class="n">chihuahua</span><span class="p">.</span><span class="n">jpg</span>    <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">small</span> <span class="n">brown</span> <span class="n">dog</span> <span class="n">wearing</span> <span class="n">a</span> <span class="n">blue</span> <span class="n">sweater</span><span class="p">]</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">tractor</span><span class="p">.</span><span class="n">JPEG</span>     <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">man</span> <span class="ow">is</span> <span class="n">standing</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">field</span> <span class="k">with</span> <span class="n">a</span> <span class="n">tractor</span><span class="p">]</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">ox</span><span class="p">.</span><span class="n">JPEG</span>          <span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">large</span> <span class="n">brown</span> <span class="n">cow</span> <span class="n">standing</span> <span class="n">on</span> <span class="n">top</span> <span class="n">of</span> <span class="n">a</span> <span class="n">lush</span> <span class="n">green</span> <span class="n">field</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------+---------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.ImageAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">imageDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span>
  <span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"dropInvalid"</span><span class="o">,</span> <span class="n">value</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"src/test/resources/image/"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageCaptioning</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ImageAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageClassifier</span> <span class="k">=</span> <span class="nc">VisionEncoderDecoderForImageCaptioning</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setBeamSize</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDoSample</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"caption"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">imageAssembler</span><span class="o">,</span> <span class="n">imageCaptioning</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineDF</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">imageDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">imageDF</span><span class="o">)</span>

<span class="n">pipelineDF</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"reverse(split(image.origin, '/'))[0] as image_name"</span><span class="o">,</span> <span class="s">"caption.result"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>

<span class="o">+-----------------+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">image_name</span>       <span class="o">|</span><span class="n">result</span>                                                   <span class="o">|</span>
<span class="o">+-----------------+---------------------------------------------------------+</span>
<span class="o">|</span><span class="nv">palace</span><span class="o">.</span><span class="py">JPEG</span>      <span class="o">|[</span><span class="kt">a</span> <span class="kt">large</span> <span class="kt">room</span> <span class="kt">filled</span> <span class="kt">with</span> <span class="kt">furniture</span> <span class="kt">and</span> <span class="kt">a</span> <span class="kt">large</span> <span class="kt">window</span><span class="o">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="nv">egyptian_cat</span><span class="o">.</span><span class="py">jpeg</span><span class="o">|[</span><span class="kt">a</span> <span class="kt">cat</span> <span class="kt">laying</span> <span class="kt">on</span> <span class="kt">a</span> <span class="kt">couch</span> <span class="kt">next</span> <span class="kt">to</span> <span class="kt">another</span> <span class="kt">cat</span><span class="o">]</span>            <span class="o">|</span>
<span class="o">|</span><span class="nv">hippopotamus</span><span class="o">.</span><span class="py">JPEG</span><span class="o">|[</span><span class="kt">a</span> <span class="kt">brown</span> <span class="kt">bear</span> <span class="kt">in</span> <span class="kt">a</span> <span class="kt">body</span> <span class="kt">of</span> <span class="kt">water</span><span class="o">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="nv">hen</span><span class="o">.</span><span class="py">JPEG</span>         <span class="o">|[</span><span class="kt">a</span> <span class="kt">flock</span> <span class="kt">of</span> <span class="kt">chickens</span> <span class="kt">standing</span> <span class="kt">next</span> <span class="kt">to</span> <span class="kt">each</span> <span class="kt">other</span><span class="o">]</span>        <span class="o">|</span>
<span class="o">|</span><span class="nv">ostrich</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">a</span> <span class="kt">large</span> <span class="kt">bird</span> <span class="kt">standing</span> <span class="kt">on</span> <span class="kt">top</span> <span class="kt">of</span> <span class="kt">a</span> <span class="kt">lush</span> <span class="kt">green</span> <span class="kt">field</span><span class="o">]</span>     <span class="o">|</span>
<span class="o">|</span><span class="nv">junco</span><span class="o">.</span><span class="py">JPEG</span>       <span class="o">|[</span><span class="kt">a</span> <span class="kt">small</span> <span class="kt">bird</span> <span class="kt">standing</span> <span class="kt">on</span> <span class="kt">a</span> <span class="kt">wet</span> <span class="kt">ground</span><span class="o">]</span>                  <span class="o">|</span>
<span class="o">|</span><span class="nv">bluetick</span><span class="o">.</span><span class="py">jpg</span>     <span class="o">|[</span><span class="kt">a</span> <span class="kt">small</span> <span class="kt">dog</span> <span class="kt">standing</span> <span class="kt">on</span> <span class="kt">a</span> <span class="kt">wooden</span> <span class="kt">floor</span><span class="o">]</span>                 <span class="o">|</span>
<span class="o">|</span><span class="nv">chihuahua</span><span class="o">.</span><span class="py">jpg</span>    <span class="o">|[</span><span class="kt">a</span> <span class="kt">small</span> <span class="kt">brown</span> <span class="kt">dog</span> <span class="kt">wearing</span> <span class="kt">a</span> <span class="kt">blue</span> <span class="kt">sweater</span><span class="o">]</span>               <span class="o">|</span>
<span class="o">|</span><span class="nv">tractor</span><span class="o">.</span><span class="py">JPEG</span>     <span class="o">|[</span><span class="kt">a</span> <span class="kt">man</span> <span class="kt">is</span> <span class="kt">standing</span> <span class="kt">in</span> <span class="kt">a</span> <span class="kt">field</span> <span class="kt">with</span> <span class="kt">a</span> <span class="kt">tractor</span><span class="o">]</span>            <span class="o">|</span>
<span class="o">|</span><span class="nv">ox</span><span class="o">.</span><span class="py">JPEG</span>          <span class="o">|[</span><span class="kt">a</span> <span class="kt">large</span> <span class="kt">brown</span> <span class="kt">cow</span> <span class="kt">standing</span> <span class="kt">on</span> <span class="kt">top</span> <span class="kt">of</span> <span class="kt">a</span> <span class="kt">lush</span> <span class="kt">green</span> <span class="kt">field</span><span class="o">]|</span>
<span class="o">+-----------------+---------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="wav2vec2forctc">Wav2Vec2ForCTC</h2>

  <p>Wav2Vec2 Model with a language modeling head on top for Connectionist Temporal Classification
(CTC). Wav2Vec2 was proposed in wav2vec 2.0: A Framework for Self-Supervised Learning of
Speech Representations by Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michael Auli.</p>

  <p>The annotator takes audio files and transcribes it as text. The audio needs to be provided
pre-processed an array of floats.</p>

  <p>Note that this annotator is currently not supported on Apple Silicon processors such as the
M1. This is due to the processor not supporting instructions for XLA.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val speechToText = Wav2Vec2ForCTC.pretrained()
  .setInputCols("audio_assembler")
  .setOutputCol("text")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"asr_wav2vec2_base_960h"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTCTestSpec.scala">Wav2Vec2ForCTCTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">AUDIO</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/audio/wav2vec2_for_ctc/index.html?highlight=wav2vec2forctc#python.sparknlp.annotator.audio.wav2vec2_for_ctc.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC">Wav2Vec2ForCTC</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/audio/Wav2Vec2ForCTC.scala">Wav2Vec2ForCTC</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">audioAssembler</span> <span class="o">=</span> <span class="n">AudioAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"audio_content"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"audio_assembler"</span><span class="p">)</span>
<span class="n">speechToText</span> <span class="o">=</span> <span class="n">Wav2Vec2ForCTC</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"audio_assembler"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">audioAssembler</span><span class="p">,</span> <span class="n">speechToText</span><span class="p">])</span>
<span class="n">processedAudioFloats</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">rawFloats</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"audio_content"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">processedAudioFloats</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">processedAudioFloats</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">MISTER</span> <span class="n">QUILTER</span> <span class="n">IS</span> <span class="n">THE</span> <span class="n">APOSTLE</span> <span class="n">OF</span> <span class="n">THE</span> <span class="n">MIDLE</span> <span class="n">CLASES</span> <span class="n">AND</span> <span class="n">WE</span> <span class="n">ARE</span> <span class="n">GLAD</span> <span class="n">TO</span> <span class="n">WELCOME</span> <span class="n">HIS</span> <span class="n">GOSPEL</span> <span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.audio.Wav2Vec2ForCTC</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">audioAssembler</span><span class="k">:</span> <span class="kt">AudioAssembler</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AudioAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"audio_content"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">speechToText</span><span class="k">:</span> <span class="kt">Wav2Vec2ForCTC</span> <span class="o">=</span> <span class="nc">Wav2Vec2ForCTC</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">:</span> <span class="kt">Pipeline</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">audioAssembler</span><span class="o">,</span> <span class="n">speechToText</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">bufferedSource</span> <span class="k">=</span>
  <span class="nv">scala</span><span class="o">.</span><span class="py">io</span><span class="o">.</span><span class="py">Source</span><span class="o">.</span><span class="py">fromFile</span><span class="o">(</span><span class="s">"src/test/resources/audio/csv/audi_floats.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">rawFloats</span> <span class="k">=</span> <span class="n">bufferedSource</span>
  <span class="o">.</span><span class="py">getLines</span><span class="o">()</span>
  <span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">","</span><span class="o">).</span><span class="py">head</span><span class="o">.</span><span class="py">trim</span><span class="o">.</span><span class="py">toFloat</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toArray</span>
<span class="nv">bufferedSource</span><span class="o">.</span><span class="py">close</span>

<span class="k">val</span> <span class="nv">processedAudioFloats</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">rawFloats</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"audio_content"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">processedAudioFloats</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">processedAudioFloats</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">MISTER</span> <span class="kt">QUILTER</span> <span class="kt">IS</span> <span class="kt">THE</span> <span class="kt">APOSTLE</span> <span class="kt">OF</span> <span class="kt">THE</span> <span class="kt">MIDLE</span> <span class="kt">CLASES</span> <span class="kt">AND</span> <span class="kt">WE</span> <span class="kt">ARE</span> <span class="kt">GLAD</span> <span class="kt">TO</span> <span class="kt">WELCOME</span> <span class="kt">HIS</span> <span class="kt">GOSPEL</span> <span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="whisperforctc">WhisperForCTC</h2>

  <p>Whisper Model with a language modeling head on top for Connectionist Temporal Classification
(CTC).</p>

  <p>Whisper is an automatic speech recognition (ASR) system trained on 680,000 hours of
multilingual and multitask supervised data collected from the web. It transcribe in multiple
languages, as well as translate from those languages into English.</p>

  <p>The audio needs to be provided pre-processed an array of floats.</p>

  <p>Note that at the moment, this annotator only supports greedy search and only Spark Versions
3.4 and up are supported.</p>

  <p>For multilingual models, the language and the task (transcribe or translate) can be set with
<code class="language-plaintext highlighter-rouge">setLanguage</code> and <code class="language-plaintext highlighter-rouge">setTask</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">speechToText</span> <span class="k">=</span> <span class="nv">WhisperForCTC</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"asr_whisper_tiny_opt"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669 and to see more extended
examples, see
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/audio/WhisperForCTCTest.scala">WhisperForCTCTestSpec</a>.</p>

  <p><strong>References:</strong></p>

  <p><a href="https://arxiv.org/abs/2212.04356">Robust Speech Recognition via Large-Scale Weak Supervision</a></p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>We study the capabilities of speech processing systems trained simply to predict large
amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual
and multitask supervision, the resulting models generalize well to standard benchmarks and are
often competitive with prior fully supervised results but in a zero- shot transfer setting
without the need for any fine- tuning. When compared to humans, the models approach their
accuracy and robustness. We are releasing models and inference code to serve as a foundation
for further work on robust speech processing.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">AUDIO</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/audio/whisper_for_ctc/index.html?highlight=whisperforctc#python.sparknlp.annotator.audio.whisper_for_ctc.WhisperForCTC">WhisperForCTC</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/audio/WhisperForCTC">WhisperForCTC</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/audio/WhisperForCTC.scala">WhisperForCTC</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">audioAssembler</span> <span class="o">=</span> <span class="n">AudioAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"audio_content"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"audio_assembler"</span><span class="p">)</span>

<span class="n">speechToText</span> <span class="o">=</span> <span class="n">WhisperForCTC</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"audio_assembler"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">audioAssembler</span><span class="p">,</span> <span class="n">speechToText</span><span class="p">])</span>
<span class="n">processedAudioFloats</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">rawFloats</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"audio_content"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">processedAudioFloats</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">processedAudioFloats</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span> <span class="n">Mr</span><span class="p">.</span> <span class="n">Quilter</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">apostle</span> <span class="n">of</span> <span class="n">the</span> <span class="n">middle</span> <span class="n">classes</span> <span class="ow">and</span> <span class="n">we</span> <span class="n">are</span> <span class="n">glad</span> <span class="n">to</span> <span class="n">welcome</span> <span class="n">his</span> <span class="n">gospel</span><span class="p">.]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.audio.WhisperForCTC</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">audioAssembler</span><span class="k">:</span> <span class="kt">AudioAssembler</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">AudioAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"audio_content"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">speechToText</span><span class="k">:</span> <span class="kt">WhisperForCTC</span> <span class="o">=</span> <span class="nc">WhisperForCTC</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"audio_assembler"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">:</span> <span class="kt">Pipeline</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">audioAssembler</span><span class="o">,</span> <span class="n">speechToText</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">bufferedSource</span> <span class="k">=</span>
  <span class="nv">scala</span><span class="o">.</span><span class="py">io</span><span class="o">.</span><span class="py">Source</span><span class="o">.</span><span class="py">fromFile</span><span class="o">(</span><span class="s">"src/test/resources/audio/txt/librispeech_asr_0.txt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">rawFloats</span> <span class="k">=</span> <span class="n">bufferedSource</span>
  <span class="o">.</span><span class="py">getLines</span><span class="o">()</span>
  <span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">","</span><span class="o">).</span><span class="py">head</span><span class="o">.</span><span class="py">trim</span><span class="o">.</span><span class="py">toFloat</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toArray</span>
<span class="nv">bufferedSource</span><span class="o">.</span><span class="py">close</span>

<span class="k">val</span> <span class="nv">processedAudioFloats</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">rawFloats</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"audio_content"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">processedAudioFloats</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">processedAudioFloats</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span> <span class="kt">Mr.</span> <span class="kt">Quilter</span> <span class="kt">is</span> <span class="kt">the</span> <span class="kt">apostle</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">middle</span> <span class="kt">classes</span> <span class="kt">and</span> <span class="kt">we</span> <span class="kt">are</span> <span class="kt">glad</span> <span class="kt">to</span> <span class="kt">welcome</span> <span class="kt">his</span> <span class="kt">gospel.</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="xlmrobertaembeddings">XlmRoBertaEmbeddings</h2>

  <p>The XLM-RoBERTa model was proposed in <a href="https://arxiv.org/abs/1911.02116">Unsupervised Cross-lingual Representation Learning at Scale</a>
by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmn, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov. It is based on Facebooks
RoBERTa model released in 2019. It is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl
data.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = XlmRoBertaEmbeddings.pretrained()
  .setInputCols("document", "token")
  .setOutputCol("embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlm_roberta_base"</code>, default language is <code class="language-plaintext highlighter-rouge">"xx"</code> (meaning multi-lingual), if no values are provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLM-RoBERTa.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddingsTestSpec.scala">XlmRoBertaEmbeddingsTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a
wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred
languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly
outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +13.8% average accuracy on
XNLI, +12.3% average F1 score on MLQA, and +2.1% average F1 score on NER. XLM-R performs particularly well on
low-resource languages, improving 11.8% in XNLI accuracy for Swahili and 9.2% for Urdu over the previous XLM model. We
also present a detailed empirical evaluation of the key factors that are required to achieve these gains, including the
trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource
languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing
per-language performance; XLM-Ris very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We
will make XLM-R code, data, and models publicly available.</em></p>

  <p><strong>Tips:</strong></p>
  <ul>
    <li>XLM-RoBERTa is a multilingual model trained on 100 different languages. Unlike some XLM multilingual models, it does
not require <strong>lang</strong> parameter to understand which language is used, and should be able to determine the correct
language from the input ids.</li>
    <li>This implementation is the same as RoBERTa. Refer to the RoBertaEmbeddings for usage examples
as well as the information relative to the inputs and outputs.</li>
  </ul>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_embeddings/index.html#sparknlp.annotator.embeddings.xlm_roberta_embeddings.XlmRoBertaEmbeddings">XlmRoBertaEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings">XlmRoBertaEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlmRoBertaEmbeddings.scala">XlmRoBertaEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlmRoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'xlm_roberta_base'</span><span class="p">,</span> <span class="s">'xx'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'ner_conll_xlm_roberta_base'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">,</span> <span class="s">'embeddings'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlmRoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlmRoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_conll_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-ORG</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlmRoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlmRoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlmRoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlmRoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.05969233065843582</span><span class="p">,</span><span class="o">-</span><span class="mf">0.030789051204919815</span><span class="p">,</span><span class="mf">0.04443822056055069</span><span class="p">,</span><span class="mf">0.09564960747</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.038839809596538544</span><span class="p">,</span><span class="mf">0.011712731793522835</span><span class="p">,</span><span class="mf">0.019954433664679527</span><span class="p">,</span><span class="mf">0.0667808502</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.03952755779027939</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03455188870429993</span><span class="p">,</span><span class="mf">0.019103847444057465</span><span class="p">,</span><span class="mf">0.04311436787</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.09579929709434509</span><span class="p">,</span><span class="mf">0.02494969218969345</span><span class="p">,</span><span class="o">-</span><span class="mf">0.014753809198737144</span><span class="p">,</span><span class="mf">0.10259044915</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.004710011184215546</span><span class="p">,</span><span class="o">-</span><span class="mf">0.022148698568344116</span><span class="p">,</span><span class="mf">0.011723337695002556</span><span class="p">,</span><span class="o">-</span><span class="mf">0.013356896</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlmRoBertaEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlmRoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">05969233065843582</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">030789051204919815</span>,<span class="err">0</span><span class="kt">.</span><span class="err">04443822056055069</span>,<span class="err">0</span><span class="kt">.</span><span class="err">09564960747</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">038839809596538544</span>,<span class="err">0</span><span class="kt">.</span><span class="err">011712731793522835</span>,<span class="err">0</span><span class="kt">.</span><span class="err">019954433664679527</span>,<span class="err">0</span><span class="kt">.</span><span class="err">0667808502</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03952755779027939</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03455188870429993</span>,<span class="err">0</span><span class="kt">.</span><span class="err">019103847444057465</span>,<span class="err">0</span><span class="kt">.</span><span class="err">04311436787</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09579929709434509</span>,<span class="err">0</span><span class="kt">.</span><span class="err">02494969218969345</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">014753809198737144</span>,<span class="err">0</span><span class="kt">.</span><span class="err">10259044915</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">004710011184215546</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">022148698568344116</span>,<span class="err">0</span><span class="kt">.</span><span class="err">011723337695002556</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">013356896</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="xlmrobertaforquestionanswering">XlmRoBertaForQuestionAnswering</h2>

  <p>XlmRoBertaForQuestionAnswering can load XLM-RoBERTa Models with a span classification head on
top for extractive question-answering tasks like SQuAD (a linear layer on top of the
hidden-states output to compute span start logits and span end logits).</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spanClassifier = XlmRoBertaForQuestionAnswering.pretrained()
  .setInputCols(Array("document_question", "document_context"))
  .setOutputCol("answer")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlm_roberta_base_qa_squad2"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Question+Answering">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669. and the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnsweringTestSpec.scala">XlmRoBertaForQuestionAnsweringTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_question_answering.XlmRoBertaForQuestionAnswering">XlmRoBertaForQuestionAnswering</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering">XlmRoBertaForQuestionAnswering</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForQuestionAnswering.scala">XlmRoBertaForQuestionAnswering</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>

<span class="n">spanClassifier</span> <span class="o">=</span> <span class="n">XlmRoBertaForQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">spanClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"What's my name?"</span><span class="p">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="n">result</span>              <span class="o">|</span>
<span class="o">+--------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Clara</span><span class="p">]</span>             <span class="o">|</span>
<span class="o">+--------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">questionAnswering</span> <span class="k">=</span> <span class="nv">XlmRoBertaForQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">questionAnswering</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What's my name?"</span><span class="o">,</span> <span class="s">"My name is Clara and I live in Berkeley."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+</span>
<span class="o">|</span><span class="n">result</span>               <span class="o">|</span>
<span class="o">+---------------------+</span>
<span class="o">|[</span><span class="kt">Clara</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">++--------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="xlmrobertaforsequenceclassification">XlmRoBertaForSequenceClassification</h2>

  <p>XlmRoBertaForSequenceClassification can load XLM-RoBERTa Models with sequence classification/regression head on top
(a linear layer on top of the pooled output), e.g. for document classification tasks.</p>

  <p>For multi-class, use <code class="language-plaintext highlighter-rouge">setActivation("softmax")</code>. For multi-label, use <code class="language-plaintext highlighter-rouge">setActivation("sigmoid")</code>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = XlmRoBertaForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlm_roberta_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassificationTestSpec.scala">XlmRoBertaForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_sequence_classification.XlmRoBertaForSequenceClassification">XlmRoBertaForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification">XlmRoBertaForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForSequenceClassification.scala">XlmRoBertaForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">XlmRoBertaForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">XlmRoBertaForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="xlmrobertafortokenclassification">XlmRoBertaForTokenClassification</h2>

  <p>XlmRoBertaForTokenClassification can load XLM-RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tokenClassifier = XlmRoBertaForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlm_roberta_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassificationTestSpec.scala">XlmRoBertaForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification">XlmRoBertaForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification">XlmRoBertaForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForTokenClassification.scala">XlmRoBertaForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">XlmRoBertaForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">XlmRoBertaForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="xlmrobertaforzeroshotclassification">XlmRoBertaForZeroShotClassification</h2>

  <p>XlmRoBertaForZeroShotClassification using a <code class="language-plaintext highlighter-rouge">ModelForSequenceClassification</code> trained on NLI
(natural language inference) tasks. Equivalent of <code class="language-plaintext highlighter-rouge">XlmRoBertaForZeroShotClassification </code>
models, but these models dont require a hardcoded number of potential classes, they can be
chosen at runtime. It usually means its slower but it is much more flexible.</p>

  <p>Note that the model will loop through all provided labels. So the more labels you have, the
longer this process will take.</p>

  <p>Any combination of sequences and labels can be passed and each combination will be posed as a
premise/hypothesis pair and passed to the pretrained model.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">XlmRoBertaForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlm_roberta_large_zero_shot_classifier_xnli_anli"</code>, if no name is
provided.</p>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>To see which models are compatible and how to import them see
https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_zero_shot_classification.XlmRoBertaForZeroShotClassification">XlmRoBertaForZeroShotClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForZeroShotClassification">XlmRoBertaForZeroShotClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlmRoBertaForZeroShotClassification.scala">XlmRoBertaForZeroShotClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">XlmRoBertaForZeroShotClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nc">XlmRoBertaForZeroShotClassification</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="xlmrobertasentenceembeddings">XlmRoBertaSentenceEmbeddings</h2>

  <p>Sentence-level embeddings using XLM-RoBERTa. The XLM-RoBERTa model was proposed in <a href="https://arxiv.org/abs/1911.02116">Unsupervised Cross-lingual Representation Learning at Scale</a>
by Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmn, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov. It is based on Facebooks
RoBERTa model released in 2019. It is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl
data.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = XlmRoBertaSentenceEmbeddings.pretrained()
  .setInputCols("document")
  .setOutputCol("sentence_embeddings")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"sent_xlm_roberta_base"</code>, default language is <code class="language-plaintext highlighter-rouge">"xx"</code> (meaning multi-lingual), if no values are provided.
For available pretrained models please see the <a href="https://sparknlp.org/models?task=Embeddings">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Paper Abstract:</strong></p>

  <p><em>This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a
wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred
languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly
outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +13.8% average accuracy on
XNLI, +12.3% average F1 score on MLQA, and +2.1% average F1 score on NER. XLM-R performs particularly well on
low-resource languages, improving 11.8% in XNLI accuracy for Swahili and 9.2% for Urdu over the previous XLM model. We
also present a detailed empirical evaluation of the key factors that are required to achieve these gains, including the
trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource
languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing
per-language performance; XLM-Ris very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We
will make XLM-R code, data, and models publicly available.</em></p>

  <p><strong>Tips:</strong></p>
  <ul>
    <li>XLM-RoBERTa is a multilingual model trained on 100 different languages. Unlike some XLM multilingual models, it does
not require <strong>lang</strong> parameter to understand which language is used, and should be able to determine the correct
language from the input ids.</li>
    <li>This implementation is the same as RoBERTa. Refer to the RoBertaEmbeddings for usage examples
as well as the information relative to the inputs and outputs.</li>
  </ul>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.html#sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings">XlmRoBertaSentenceEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings">XlmRoBertaSentenceEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlmRoBertaSentenceEmbeddings.scala">XlmRoBertaSentenceEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Coming Soon!
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Coming Soon!</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">smallCorpus</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"header"</span><span class="p">,</span><span class="s">"True"</span><span class="p">).</span><span class="n">csv</span><span class="p">(</span><span class="s">"sentiment.csv"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlmRoBertaSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">docClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">docClassifier</span>
<span class="p">])</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">smallCorpus</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.RoBertaSentenceEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/test/resources/classifier/sentiment.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlmRoBertaSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClassifierDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">docClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sentenceEmbeddings</span> <span class="o">=</span> <span class="n">XlmRoBertaSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># you can either use the output to train ClassifierDL, SentimentDL, or MultiClassifierDL
# or you can use EmbeddingsFinisher to prepare the results for Spark ML functions
</span>
<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">sentenceEmbeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.05969233065843582</span><span class="p">,</span><span class="o">-</span><span class="mf">0.030789051204919815</span><span class="p">,</span><span class="mf">0.04443822056055069</span><span class="p">,</span><span class="mf">0.09564960747</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.038839809596538544</span><span class="p">,</span><span class="mf">0.011712731793522835</span><span class="p">,</span><span class="mf">0.019954433664679527</span><span class="p">,</span><span class="mf">0.0667808502</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.03952755779027939</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03455188870429993</span><span class="p">,</span><span class="mf">0.019103847444057465</span><span class="p">,</span><span class="mf">0.04311436787</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.09579929709434509</span><span class="p">,</span><span class="mf">0.02494969218969345</span><span class="p">,</span><span class="o">-</span><span class="mf">0.014753809198737144</span><span class="p">,</span><span class="mf">0.10259044915</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.004710011184215546</span><span class="p">,</span><span class="o">-</span><span class="mf">0.022148698568344116</span><span class="p">,</span><span class="mf">0.011723337695002556</span><span class="p">,</span><span class="o">-</span><span class="mf">0.013356896</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceEmbeddings</span> <span class="k">=</span> <span class="nv">XlmRoBertaSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="c1">// you can either use the output to train ClassifierDL, SentimentDL, or MultiClassifierDL</span>
<span class="c1">// or you can use EmbeddingsFinisher to prepare the results for Spark ML functions</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">sentenceEmbeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">05969233065843582</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">030789051204919815</span>,<span class="err">0</span><span class="kt">.</span><span class="err">04443822056055069</span>,<span class="err">0</span><span class="kt">.</span><span class="err">09564960747</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">038839809596538544</span>,<span class="err">0</span><span class="kt">.</span><span class="err">011712731793522835</span>,<span class="err">0</span><span class="kt">.</span><span class="err">019954433664679527</span>,<span class="err">0</span><span class="kt">.</span><span class="err">0667808502</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03952755779027939</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03455188870429993</span>,<span class="err">0</span><span class="kt">.</span><span class="err">019103847444057465</span>,<span class="err">0</span><span class="kt">.</span><span class="err">04311436787</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09579929709434509</span>,<span class="err">0</span><span class="kt">.</span><span class="err">02494969218969345</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">014753809198737144</span>,<span class="err">0</span><span class="kt">.</span><span class="err">10259044915</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">004710011184215546</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">022148698568344116</span>,<span class="err">0</span><span class="kt">.</span><span class="err">011723337695002556</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">013356896</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="xlnetembeddings">XlnetEmbeddings</h2>

  <p>XlnetEmbeddings (XLNet): Generalized Autoregressive Pretraining for Language Understanding</p>

  <p>XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language
modeling objective. Additionally, XLNet employs Transformer-XL as the backbone model, exhibiting excellent performance
for language tasks involving long context. Overall, XLNet achieves state-of-the-art (SOTA) results on various
downstream language tasks including question answering, natural language inference, sentiment analysis, and document
ranking.</p>

  <p>These word embeddings represent the outputs generated by the XLNet models.</p>

  <p>Note that this is a very computationally expensive module compared to word embedding modules that only perform embedding lookups.
The use of an accelerator is recommended.</p>

  <table>
    <thead>
      <tr>
        <th>Spark NLP Model</th>
        <th>Google Model</th>
        <th>Model Properties</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><code class="language-plaintext highlighter-rouge">"xlnet_large_cased"</code></td>
        <td><a href="https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip">XLNet-Large</a></td>
        <td>24-layer, 1024-hidden, 16-heads</td>
      </tr>
      <tr>
        <td><code class="language-plaintext highlighter-rouge">"xlnet_base_cased"</code></td>
        <td><a href="https://storage.googleapis.com/xlnet/released_models/cased_L-12_H-768_A-12.zip">XLNet-Base</a></td>
        <td>12-layer, 768-hidden, 12-heads. This model is trained on full data (different from the one in the paper).</td>
      </tr>
    </tbody>
  </table>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = XlnetEmbeddings.pretrained()
  .setInputCols("sentence", "token")
  .setOutputCol("embeddings")

# Offline - Download the pretrained model manually and extract it
xlnet = XlnetEmbeddings.load("/xlnet_large_cased_en_2.5.0_2.4_1588074397954") \
        .setInputCols("sentence", "token") \
        .setOutputCol("xlnet")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlnet_base_cased"</code>, if no name is provided.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/training/english/dl-ner/ner_xlnet.ipynb">Examples</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddingsTestSpec.scala">XlnetEmbeddingsTestSpec</a>.</p>

  <p><strong>Sources :</strong></p>

  <p><a href="https://arxiv.org/abs/1906.08237">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a></p>

  <p>https://github.com/zihangdai/xlnet</p>

  <p><strong>Paper abstract:</strong></p>

  <p><em>With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves
better performance than pretraining approaches based on autoregressive language modeling. However, relying on
corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune
discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that
(1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the
factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore,
XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically,
under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question
answering, natural language inference, sentiment analysis, and document ranking.</em></p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.html#sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings">XlnetEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings">XlnetEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/XlnetEmbeddings.scala">XlnetEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLModel
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlnetEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"xlnet_base_cased"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'embeddings'</span><span class="p">)</span>

<span class="c1"># This pretrained model requires those specific transformer embeddings
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_conll_xlnet_base_cased"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLModel</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Use the transformer embeddings</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlnetEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"xlnet_base_cased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// This pretrained model requires those specific transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_conll_xlnet_base_cased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"U.N. official Ekeus heads for Baghdad."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"ner.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                              <span class="o">|</span>
<span class="o">+------------------------------------+</span>
<span class="o">|[</span><span class="kt">I-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">I-LOC</span>, <span class="kt">O</span><span class="o">]|</span>
<span class="o">+------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Use the transformer embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlnetEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Then the training can start with the transformer embeddings
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlnetEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start with the transformer embeddings</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">XlnetEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.6287205219268799</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4865287244319916</span><span class="p">,</span><span class="o">-</span><span class="mf">0.186111718416214</span><span class="p">,</span><span class="mf">0.234187275171279</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">1.1967450380325317</span><span class="p">,</span><span class="mf">0.2746637463569641</span><span class="p">,</span><span class="mf">0.9481253027915955</span><span class="p">,</span><span class="mf">0.3431355059146881</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">1.0777631998062134</span><span class="p">,</span><span class="o">-</span><span class="mf">2.092679977416992</span><span class="p">,</span><span class="o">-</span><span class="mf">1.5331977605819702</span><span class="p">,</span><span class="o">-</span><span class="mf">1.11190271377563</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.8349916934967041</span><span class="p">,</span><span class="o">-</span><span class="mf">0.45627787709236145</span><span class="p">,</span><span class="o">-</span><span class="mf">0.7890847325325012</span><span class="p">,</span><span class="o">-</span><span class="mf">1.028069257736</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.134845569729805</span><span class="p">,</span><span class="o">-</span><span class="mf">0.11672890186309814</span><span class="p">,</span><span class="mf">0.4945235550403595</span><span class="p">,</span><span class="o">-</span><span class="mf">0.66587203741073</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.XlnetEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">XlnetEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">6287205219268799</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4865287244319916</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">186111718416214</span>,<span class="err">0</span><span class="kt">.</span><span class="err">234187275171279</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">1967450380325317</span>,<span class="err">0</span><span class="kt">.</span><span class="err">2746637463569641</span>,<span class="err">0</span><span class="kt">.</span><span class="err">9481253027915955</span>,<span class="err">0</span><span class="kt">.</span><span class="err">3431355059146881</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">0777631998062134</span>,<span class="kt">-</span><span class="err">2</span><span class="kt">.</span><span class="err">092679977416992</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">5331977605819702</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">11190271377563</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">8349916934967041</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">45627787709236145</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">7890847325325012</span>,<span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">028069257736</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">134845569729805</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">11672890186309814</span>,<span class="err">0</span><span class="kt">.</span><span class="err">4945235550403595</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">66587203741073</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="xlnetforsequenceclassification">XlnetForSequenceClassification</h2>

  <p>XlnetForSequenceClassification can load XLNet Models with sequence classification/regression head on top
(a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sequenceClassifier = XlnetForSequenceClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlnet_base_sequence_classifier_imdb"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Text+Classification">Models Hub</a>.</p>

  <p>Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are
compatible and how to import them see https://github.com/JohnSnowLabs/spark-nlp/discussions/5669.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassificationTestSpec.scala">XlnetForSequenceClassification</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification">XlnetForSequenceClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification">XlnetForSequenceClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForSequenceClassification.scala">XlnetForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">XlnetForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I loved this movie when I was a child."</span><span class="p">,</span> <span class="s">"It was pretty boring."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">neg</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">XlnetForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">sequenceClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I loved this movie when I was a child."</span><span class="o">,</span> <span class="s">"It was pretty boring."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">pos</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">neg</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="xlnetfortokenclassification">XlnetForTokenClassification</h2>

  <p>XlnetForTokenClassification can load XLNet Models with a token classification head on top (a linear layer on top of the hidden-states output)
e.g. for Named-Entity-Recognition (NER) tasks.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val tokenClassifier = XlnetForTokenClassification.pretrained()
  .setInputCols("token", "document")
  .setOutputCol("label")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"xlnet_base_token_classifier_conll03"</code>, if no name is provided.</p>

  <p>For available pretrained models please see the <a href="https://sparknlp.org/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

  <p>and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassificationTestSpec.scala">XlnetForTokenClassificationTestSpec</a>.
Models from the HuggingFace  Transformers library are also compatible with Spark NLP . To see which models are compatible and how to import them see <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">Import Transformers into Spark NLP </a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.html#sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification">XlnetForTokenClassification</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification">XlnetForTokenClassification</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/XlnetForTokenClassification.scala">XlnetForTokenClassification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Examples</b></summary>

<div class="tabs-model-aproach">

      <div class="tabs-model-aproach-head">
    <button class="tab-li-model-aproach tabheader_active">Prediction</button>
    <button class="tab-li-model-aproach">Training</button>
    <button class="tab-li-model-aproach">Embeddings</button>
</div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to predict classes by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">XlnetForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"label.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">XlnetForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">tokenClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John Lenon was born in London and lived in Paris. My name is Sarah and I live in London"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"label.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">B-PER</span>, <span class="kt">I-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-PER</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-LOC</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to train an Approach Annotator by using the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator needs to be trained externally. Please see the training page
# for instructions.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator needs to be trained externally. Please see the training page</span>
<span class="c1">// for instructions.</span>
</code></pre></div>          </div>
        </div>

      </div>

      <div class="tabs-python-scala-box">

        <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

        <p>This example shows how to extract the embeddings generated by the Transformer.</p>

        <div class="tabs-mfl-box">
          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This annotator has a fully connected layer attached for classification. For
# embeddings see the base transformer annotator.
</span></code></pre></div>          </div>
        </div>

        <div class="tabs-mfl-box">
          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This annotator has a fully connected layer attached for classification. For</span>
<span class="c1">// embeddings see the base transformer annotator.</span>
</code></pre></div>          </div>
        </div>

      </div>

    </div>

</details>

</div>

<div class="h3-box tabs-python-scala-box">

  <h2 id="zeroshotner">ZeroShotNer</h2>

  <p>ZeroShotNerModel implements zero shot named entity recognition by utilizing RoBERTa
transformer models fine tuned on a question answering task.</p>

  <p>Its input is a list of document annotations and it automatically generates questions which are
used to recognize entities. The definitions of entities is given by a dictionary structures,
specifying a set of questions for each entity. The model is based on
RoBertaForQuestionAnswering.</p>

  <p>For more extended examples see the
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/named-entity-recognition/ZeroShot_NER.ipynb">Examples</a>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>

  <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">zeroShotNer</span> <span class="k">=</span> <span class="nv">ZeroShotNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zer_shot_ner"</span><span class="o">)</span>
</code></pre></div>  </div>

  <p>For available pretrained models please see the
<a href="https://sparknlp.org/models?task=Zero-Shot-NER">Models Hub</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.html#sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel">ZeroShotNerModel</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel">ZeroShotNerModel</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/ZeroShotNerModel.scala">ZeroShotNerModel</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="n">ZeroShotNerModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"NAME"</span><span class="p">:</span> <span class="p">[</span><span class="s">"What is his name?"</span><span class="p">,</span> <span class="s">"What is my name?"</span><span class="p">,</span> <span class="s">"What is her name?"</span><span class="p">],</span>
            <span class="s">"CITY"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which city?"</span><span class="p">,</span> <span class="s">"Which is the city?"</span><span class="p">]</span>
        <span class="p">})</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span> \
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
        <span class="p">[[</span><span class="s">"My name is Clara, I live in New York and Hellen lives in Paris."</span><span class="p">]]</span>
    <span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">sentence_detector</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">zero_shot_ner</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"explode(zero_shot_ner) AS entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">select</span><span class="p">(</span>
        <span class="s">"document.result"</span><span class="p">,</span>
        <span class="s">"entity.result"</span><span class="p">,</span>
        <span class="s">"entity.metadata.word"</span><span class="p">,</span>
        <span class="s">"entity.metadata.confidence"</span><span class="p">,</span>
        <span class="s">"entity.metadata.question"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">zeroShotNer</span> <span class="k">=</span> <span class="nc">ZeroShotNerModel</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setEntityDefinitions</span><span class="o">(</span>
     <span class="nc">Map</span><span class="o">(</span>
       <span class="s">"NAME"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"What is his name?"</span><span class="o">,</span> <span class="s">"What is her name?"</span><span class="o">),</span>
       <span class="s">"CITY"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Which city?"</span><span class="o">)))</span>
   <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.01f</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zero_shot_ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
     <span class="n">documentAssembler</span><span class="o">,</span>
     <span class="n">sentenceDetector</span><span class="o">,</span>
     <span class="n">zeroShotNer</span><span class="o">))</span>

 <span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>
 <span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span>
   <span class="nc">Seq</span><span class="o">(</span><span class="s">"Clara often travels between New York and Paris."</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>

 <span class="n">results</span>
   <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"explode(zero_shot_ner) AS entity"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">select</span><span class="o">(</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.result"</span><span class="o">),</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.word"</span><span class="o">),</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.sentence"</span><span class="o">),</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.begin"</span><span class="o">),</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.end"</span><span class="o">),</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.confidence"</span><span class="o">),</span>
     <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.question"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>

<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">word</span> <span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span><span class="n">question</span>          <span class="o">|</span>
<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
<span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">Paris</span><span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">41</span>   <span class="o">|</span><span class="mi">45</span> <span class="o">|</span><span class="mf">0.78655756</span><span class="o">|</span><span class="nc">Which</span> <span class="n">is</span> <span class="n">the</span> <span class="n">city</span><span class="o">?|</span>
<span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">New</span>  <span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">28</span>   <span class="o">|</span><span class="mi">30</span> <span class="o">|</span><span class="mf">0.29346612</span><span class="o">|</span><span class="nc">Which</span> <span class="n">city</span><span class="o">?</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">York</span> <span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">32</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="mf">0.29346612</span><span class="o">|</span><span class="nc">Which</span> <span class="n">city</span><span class="o">?</span>       <span class="o">|</span>
<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box">

  <h2 id="import-transformers-into-spark-nlp">Import Transformers into Spark NLP</h2>

  <h3 id="overview">Overview</h3>

  <p>We have extended support for <code class="language-plaintext highlighter-rouge">HuggingFace</code>    and <code class="language-plaintext highlighter-rouge">TF Hub</code> exported models since <code class="language-plaintext highlighter-rouge">3.1.0</code> to equivalent Spark NLP  annotators. Starting this release, you can easily use the <code class="language-plaintext highlighter-rouge">saved_model</code> feature in HuggingFace within a few lines of codes and import any <code class="language-plaintext highlighter-rouge">BERT</code>, <code class="language-plaintext highlighter-rouge">DistilBERT</code>, <code class="language-plaintext highlighter-rouge">CamemBERT</code>, <code class="language-plaintext highlighter-rouge">RoBERTa</code>, <code class="language-plaintext highlighter-rouge">DeBERTa</code>, <code class="language-plaintext highlighter-rouge">XLM-RoBERTa</code>, <code class="language-plaintext highlighter-rouge">Longformer</code>, <code class="language-plaintext highlighter-rouge">BertForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">DistilBertForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">AlbertForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">RoBertaForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">DeBertaForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">XlmRoBertaForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">XlnetForTokenClassification</code>,  <code class="language-plaintext highlighter-rouge">LongformerForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">CamemBertForTokenClassification</code>, <code class="language-plaintext highlighter-rouge">CamemBertForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">CamemBertForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">BertForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">DistilBertForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">AlbertForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">RoBertaForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">DeBertaForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">XlmRoBertaForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">XlnetForSequenceClassification</code>,  <code class="language-plaintext highlighter-rouge">LongformerForSequenceClassification</code>, <code class="language-plaintext highlighter-rouge">AlbertForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">BertForQuestionAnswering</code>,  <code class="language-plaintext highlighter-rouge">DeBertaForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">DistilBertForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">LongformerForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">RoBertaForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">XlmRoBertaForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">TapasForQuestionAnswering</code>, <code class="language-plaintext highlighter-rouge">Vision Transformers (ViT)</code>, <code class="language-plaintext highlighter-rouge">HubertForCTC</code>, <code class="language-plaintext highlighter-rouge">SwinForImageClassification</code>, and <code class="language-plaintext highlighter-rouge">ConvNextForImageClassification</code> models to Spark NLP. We will work on the remaining annotators and extend this support to the rest with each release </p>

</div>
<div class="h3-box">

  <h3 id="compatibility">Compatibility</h3>

  <p><strong>Spark NLP</strong>: The equivalent annotator in Spark NLP
<strong>TF Hub</strong>: Models from <a href="https://tfhub.dev/">TF Hub</a>
<strong>HuggingFace</strong>: Models from <a href="https://huggingface.co/models">HuggingFace</a>
<strong>ONNX</strong>: Models from HuggingFace in ONNX format
<strong>Model Architecture</strong>: Which architecture is compatible with that annotator
<strong>Flags</strong>:</p>

  <ul>
    <li>Fully supported </li>
    <li>Partially supported (requires workarounds) </li>
    <li>Under development </li>
    <li>Not supported </li>
  </ul>

  <table>
    <thead>
      <tr>
        <th style="text-align: left">Spark NLP</th>
        <th style="text-align: left">TF Hub</th>
        <th style="text-align: left">HuggingFace</th>
        <th style="text-align: left">ONNX</th>
        <th style="text-align: left">Model Architecture</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: left">AlbertEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">ALBERT</td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">Automatic Speech Recognition (Wav2Vec2ForCTC)</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.TFWav2Vec2ForCTC">TFWav2Vec2ForCTC</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BartForZeroShotClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/bart#transformers.TFBartForSequenceClassification">TFBartForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BartTransformer</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">BERT - Small BERT - ELECTRA</td>
      </tr>
      <tr>
        <td style="text-align: left">BertForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForZeroShotClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertSentenceEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">BERT - Small BERT - ELECTRA</td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">CamemBERT</td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamemBertForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamemBertForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">ConvNextForImageClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">DeBERTa-v2 - DeBERTa-v3</td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">DistilBERT</td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForZeroShotClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">E5Embeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://github.com/UKPLab/sentence-transformers">SentenceTransformer</a></td>
      </tr>
      <tr>
        <td style="text-align: left">ElmoEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
      </tr>
      <tr>
        <td style="text-align: left">HubertForCTC</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/hubert#transformers.TFHubertForCTC">TFHubertForCTC</a></td>
      </tr>
      <tr>
        <td style="text-align: left">InstructorEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">INSTRUCTOR</td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">Longformer</td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">MarianTransformer</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
      </tr>
      <tr>
        <td style="text-align: left">MPNetEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://github.com/UKPLab/sentence-transformers">SentenceTransformer</a></td>
      </tr>
      <tr>
        <td style="text-align: left">OpenAI GPT2</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">RoBERTa - DistilRoBERTa</td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForZeroShotClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaSentenceEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">RoBERTa - DistilRoBERTa</td>
      </tr>
      <tr>
        <td style="text-align: left">SwinForImageClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">T5Transformer</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
      </tr>
      <tr>
        <td style="text-align: left">TapasForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">UniversalSentenceEncoder</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
      </tr>
      <tr>
        <td style="text-align: left">VisionEncoderDecoderForImageCaptioning</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/vision-encoder-decoder#vision-encoder-decoder-models">VisionEncoderDecoderModel</a></td>
      </tr>
      <tr>
        <td style="text-align: left">ViTForImageClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">WhisperForCTC</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/v4.33.2/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">XLM-RoBERTa</td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaForQuestionAnswering</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/xlmroberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaForZeroShotClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaSentenceEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://github.com/UKPLab/sentence-transformers">SentenceTransformer</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlnetEmbeddings</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left">XLNet</td>
      </tr>
      <tr>
        <td style="text-align: left">XlnetForSequenceClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlnetForTokenClassification</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/xlnet#transformers.TFXLNetForTokenClassificationet">TFXLNetForTokenClassificationet</a></td>
      </tr>
      <tr>
        <td style="text-align: left">ZeroShotNerModel</td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"></td>
        <td style="text-align: left"><a href="https://huggingface.co/docs/transformers/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a></td>
      </tr>
    </tbody>
  </table>

</div>
<div class="h3-box">

  <h3 id="example-notebooks">Example Notebooks</h3>

  <h4 id="huggingface-optimum-pytorch-and-onnx-runtime-to-spark-nlp-onnx">HuggingFace, Optimum, PyTorch, and ONNX Runtime to Spark NLP (ONNX)</h4>

  <table>
    <thead>
      <tr>
        <th style="text-align: left">Spark NLP</th>
        <th style="text-align: left">Notebooks</th>
        <th style="text-align: left">Colab</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: left">AlbertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_AlbertForQuestionAnswering.ipynb">HuggingFace ONNX in Spark NLP AlbertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_AlbertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_AlbertForSequenceClassification.ipynb">HuggingFace ONNX in Spark NLP AlbertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_AlbertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_AlbertForTokenClassification.ipynb">HuggingFace ONNX in Spark NLP AlbertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_AlbertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForQuestionAnswering.ipynb">HuggingFace ONNX in Spark NLP BertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForSequenceClassification.ipynb">HuggingFace ONNX in Spark NLP BertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForTokenClassification.ipynb">HuggingFace ONNX in Spark NLP BertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BertForQuestionAnswering.ipynb">HuggingFace ONNX in Spark NLP DistilBertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBertForSequenceClassification.ipynb">HuggingFace ONNX in Spark NLP DistilBertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBertForTokenClassification.ipynb">HuggingFace ONNX in Spark NLP DistilBertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BERT.ipynb">HuggingFace ONNX in Spark NLP BERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_BERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DeBERTa.ipynb">HuggingFace ONNX in Spark NLP DeBERTa</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DeBERTa.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBERT.ipynb">HuggingFace ONNX in Spark NLP DistilBERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_DistilBERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">E5Embeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_E5.ipynb">HuggingFace ONNX in Spark NLP E5</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_E5.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">MPNet</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_MPNet.ipynb">HuggingFace ONNX in Spark NLP MPNet</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_MPNet.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_RoBERTa.ipynb">HuggingFace ONNX in Spark NLP RoBERTa</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_RoBERTa.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">WhisperForCTC</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_Whisper.ipynb">HuggingFace ONNX in Spark NLP MPNet</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/onnx/HuggingFace_ONNX_in_Spark_NLP_Whisper.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
    </tbody>
  </table>

</div>
<div class="h3-box">

  <h4 id="huggingface-to-spark-nlp-tensorflow">HuggingFace to Spark NLP (TensorFlow)</h4>

  <table>
    <thead>
      <tr>
        <th style="text-align: left">Spark NLP</th>
        <th style="text-align: left">Notebooks</th>
        <th style="text-align: left">Colab</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: left">AlbertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20ALBERT.ipynb">HuggingFace in Spark NLP - ALBERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20ALBERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20AlbertForQuestionAnswering.ipynb">HuggingFace in Spark NLP - AlbertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20AlbertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - AlbertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20AlbertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">AlbertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20AlbertForTokenClassification.ipynb">HuggingFace in Spark NLP - AlbertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20AlbertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BERT.ipynb">HuggingFace in Spark NLP - BERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForQuestionAnswering.ipynb">HuggingFace in Spark NLP - BertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - BertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForTokenClassification.ipynb">HuggingFace in Spark NLP - BertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertForZeroShotClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - BertForZeroShotClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForZeroShotClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertSentenceEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BERT%20Sentence.ipynb">HuggingFace in Spark NLP - BERT Sentence</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BERT%20Sentence.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBERT.ipynb">HuggingFace in Spark NLP - CamemBERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForSequenceClassification.ipynb">HuggingFace in Spark NLP - CamemBertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForSequenceClassification.ipynb">HuggingFace in Spark NLP - CamemBertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">CamemBertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForTokenClassification.ipynb">HuggingFace in Spark NLP - CamemBertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">ConvNextForImageClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20ConvNextForImageClassification.ipynb">HuggingFace in Spark NLP - ConvNextForImageClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20ConvNextForImageClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DeBERTa.ipynb">HuggingFace in Spark NLP - DeBERTa</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DeBERTa.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DeBertaForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DeBertaForQuestionAnswering.ipynb">HuggingFace in Spark NLP - DeBertaForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DeBertaForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBERT.ipynb">HuggingFace in Spark NLP - DistilBERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForQuestionAnswering.ipynb">HuggingFace in Spark NLP - DistilBertForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForSequenceClassification.ipynb">HuggingFace in Spark NLP - DistilBertForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForTokenClassification.ipynb">HuggingFace in Spark NLP - DistilBertForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">DistilBertForZeroShotClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForZeroClassification.ipynb">HuggingFace in Spark NLP - DistilBertForZeroShotClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20DistilBertForZeroShotClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20Longformer.ipynb">HuggingFace in Spark NLP - Longformer</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20Longformer.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20LongformerForQuestionAnswering.ipynb">HuggingFace in Spark NLP - LongformerForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20LongformerForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">LongformerForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - LongformerForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20LongformerForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBERTa.ipynb">HuggingFace in Spark NLP - RoBERTa</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBERTa.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForQuestionAnswering.ipynb">HuggingFace in Spark NLP - RoBertaForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - RoBertaForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForTokenClassification.ipynb">HuggingFace in Spark NLP - RoBertaForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">RoBertaForZeroShotClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForZeroShotClassification.ipynb">HuggingFace in Spark NLP - RoBertaForZeroShotClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForZeroShotClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">SwinForImageClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20SwinForImageClassification.ipynb">HuggingFace in Spark NLP - SwinForImageClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20SwinForImageClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">ViTForImageClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20ViTForImageClassification.ipynb">HuggingFace in Spark NLP - ViTForImageClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20ViTForImageClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">WhisperForCTC</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBertaForZeroShotClassification.ipynb">HuggingFace in Spark NLP - WhisperForCTC</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20WhisperForCTC.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLM-RoBERTa.ipynb">HuggingFace in Spark NLP - XLM-RoBERTa</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLM-RoBERTa.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRobertaForQuestionAnswering</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRobertaForQuestionAnswering.ipynb">HuggingFace in Spark NLP - XlmRobertaForQuestionAnswering</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRobertaForQuestionAnswering.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - XlmRoBertaForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRoBertaForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlmRoBertaForTokenClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRoBertaForTokenClassification.ipynb">HuggingFace in Spark NLP - XlmRoBertaForTokenClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRoBertaForTokenClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlnetEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLNet.ipynb">HuggingFace in Spark NLP - XLNet</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLNet.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">XlnetForSequenceClassification</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb">HuggingFace in Spark NLP - XlnetForSequenceClassification</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlnetForSequenceClassification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
    </tbody>
  </table>

</div>
<div class="h3-box">

  <h4 id="tf-hub-to-spark-nlp">TF Hub to Spark NLP</h4>

  <table>
    <thead>
      <tr>
        <th style="text-align: left">Spark NLP</th>
        <th style="text-align: left">TF Hub Notebooks</th>
        <th style="text-align: left">Colab</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td style="text-align: left">AlbertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/TF%20Hub%20in%20Spark%20NLP%20-%20ALBERT.ipynb">TF Hub in Spark NLP - ALBERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/TF%20Hub%20in%20Spark%20NLP%20-%20ALBERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/TF%20Hub%20in%20Spark%20NLP%20-%20BERT.ipynb">TF Hub in Spark NLP - BERT</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/TF%20Hub%20in%20Spark%20NLP%20-%20BERT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
      <tr>
        <td style="text-align: left">BertSentenceEmbeddings</td>
        <td style="text-align: left"><a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/TF%20Hub%20in%20Spark%20NLP%20-%20BERT%20Sentence.ipynb">TF Hub in Spark NLP - BERT Sentence</a></td>
        <td style="text-align: left"><a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/TF%20Hub%20in%20Spark%20NLP%20-%20BERT%20Sentence.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></td>
      </tr>
    </tbody>
  </table>

</div>
</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2023-06-18T00:00:00+00:00">Jun 18, 2023</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>

'use strict';

function tabs({tabsWrapperSelector, tabsParentSelector, tabsSelector, tabsContentSelector, activeClass}) {
    //Tabs

    const tabsWrapper = document.querySelectorAll(tabsWrapperSelector);

    //Detecting all tabs
    tabsWrapper.forEach(tab => {
        const tabsParent = tab.querySelector(tabsParentSelector),
                tabsLi = tab.querySelectorAll(tabsSelector),
                tabsContent = tab.querySelectorAll(tabsContentSelector);

        //Hiding all tabs
        function hideTabsContent() {
            if(Array.from(tabsLi).length != 0) {
                tabsContent.forEach(item => {
                    item.style.display = 'none';
                }); 
            }
            
            if(Array.from(tabsLi).length != 0) {
                tabsLi.forEach(item => {
                    item.classList.remove(activeClass);
                }); 
            }
        }

        //Show active tabs
        function showTabContent(i = 0) {
            if(Array.from(tabsContent).length != 0) {
                tabsContent[i].style.display = "block";
            }
            if(Array.from(tabsLi).length != 0) {
                tabsLi[i].classList.add(activeClass);            
            }
        }

        //Changing the tabs
        if(tabsParent != null) {
            tabsParent.addEventListener('click', (event) => {
                const target = event.target;
    
                if(target && target.classList.contains(tabsSelector.slice(1))) {
                    tabsLi.forEach((item, i) => {
                        if(target == item) {
                            hideTabsContent();
                            try{showTabContent(i);}catch(e){}
                        }
                    });
                }
            });
        }        
        
        hideTabsContent();
        showTabContent();
    });
}

tabs({
    tabsWrapperSelector: '.tabs-model-aproach', 
    tabsParentSelector: '.tabs-model-aproach-head', 
    tabsSelector: '.tab-li-model-aproach', 
    tabsContentSelector: '.tabs-python-scala-box', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-python-scala-box', 
    tabsParentSelector: '.tabs-python-scala-head', 
    tabsSelector: '.tab-python-scala-li', 
    tabsContentSelector: '.tabs-mfl-box', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-mfl-box', 
    tabsParentSelector: '.tabs-mfl-head', 
    tabsSelector: '.tab-mfl-li', 
    tabsContentSelector: '.tab-mfl-content', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-box', 
    tabsParentSelector: '.tabs-python-scala-head', 
    tabsSelector: '.tab-python-scala-li', 
    tabsContentSelector: '.tabs-box .highlighter-rouge', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-box', 
    tabsParentSelector: '.tabs-model-aproach-head', 
    tabsSelector: '.tab-li-model-aproach', 
    tabsContentSelector: '.tabs-python-scala-box', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-box', 
    tabsParentSelector: '.tabs-model-aproach-head', 
    tabsSelector: '.tab-li-model-aproach', 
    tabsContentSelector: '.tabs-box .highlighter-rouge', 
    activeClass: 'tabheader_active'
});

</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/annotators">Annotators</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/training">Training</a></div></div></div>

</div>
</div>

<script>/*! jQuery v1.12.3 | (c) jQuery Foundation | jquery.org/license */
!function(a,b){"object"==typeof module&&"object"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error("jQuery requires a window with a document");return b(a)}:b(a)}("undefined"!=typeof window?window:this,function(a,b){var c=[],d=a.document,e=c.slice,f=c.concat,g=c.push,h=c.indexOf,i={},j=i.toString,k=i.hasOwnProperty,l={},m="1.12.3",n=function(a,b){return new n.fn.init(a,b)},o=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,p=/^-ms-/,q=/-([\da-z])/gi,r=function(a,b){return b.toUpperCase()};n.fn=n.prototype={jquery:m,constructor:n,selector:"",length:0,toArray:function(){return e.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:e.call(this)},pushStack:function(a){var b=n.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a){return n.each(this,a)},map:function(a){return this.pushStack(n.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(e.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor()},push:g,sort:c.sort,splice:c.splice},n.extend=n.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for("boolean"==typeof g&&(j=g,g=arguments[h]||{},h++),"object"==typeof g||n.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(n.isPlainObject(c)||(b=n.isArray(c)))?(b?(b=!1,f=a&&n.isArray(a)?a:[]):f=a&&n.isPlainObject(a)?a:{},g[d]=n.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},n.extend({expando:"jQuery"+(m+Math.random()).replace(/\D/g,""),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return"function"===n.type(a)},isArray:Array.isArray||function(a){return"array"===n.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){var b=a&&a.toString();return!n.isArray(a)&&b-parseFloat(b)+1>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||"object"!==n.type(a)||a.nodeType||n.isWindow(a))return!1;try{if(a.constructor&&!k.call(a,"constructor")&&!k.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}if(!l.ownFirst)for(b in a)return k.call(a,b);for(b in a);return void 0===b||k.call(a,b)},type:function(a){return null==a?a+"":"object"==typeof a||"function"==typeof a?i[j.call(a)]||"object":typeof a},globalEval:function(b){b&&n.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(p,"ms-").replace(q,r)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b){var c,d=0;if(s(a)){for(c=a.length;c>d;d++)if(b.call(a[d],d,a[d])===!1)break}else for(d in a)if(b.call(a[d],d,a[d])===!1)break;return a},trim:function(a){return null==a?"":(a+"").replace(o,"")},makeArray:function(a,b){var c=b||[];return null!=a&&(s(Object(a))?n.merge(c,"string"==typeof a?[a]:a):g.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(h)return h.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,e,g=0,h=[];if(s(a))for(d=a.length;d>g;g++)e=b(a[g],g,c),null!=e&&h.push(e);else for(g in a)e=b(a[g],g,c),null!=e&&h.push(e);return f.apply([],h)},guid:1,proxy:function(a,b){var c,d,f;return"string"==typeof b&&(f=a[b],b=a,a=f),n.isFunction(a)?(c=e.call(arguments,2),d=function(){return a.apply(b||this,c.concat(e.call(arguments)))},d.guid=a.guid=a.guid||n.guid++,d):void 0},now:function(){return+new Date},support:l}),"function"==typeof Symbol&&(n.fn[Symbol.iterator]=c[Symbol.iterator]),n.each("Boolean Number String Function Array Date RegExp Object Error Symbol".split(" "),function(a,b){i["[object "+b+"]"]=b.toLowerCase()});function s(a){var b=!!a&&"length"in a&&a.length,c=n.type(a);return"function"===c||n.isWindow(a)?!1:"array"===c||0===b||"number"==typeof b&&b>0&&b-1 in a}var t=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u="sizzle"+1*new Date,v=a.document,w=0,x=0,y=ga(),z=ga(),A=ga(),B=function(a,b){return a===b&&(l=!0),0},C=1<<31,D={}.hasOwnProperty,E=[],F=E.pop,G=E.push,H=E.push,I=E.slice,J=function(a,b){for(var c=0,d=a.length;d>c;c++)if(a[c]===b)return c;return-1},K="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",L="[\\x20\\t\\r\\n\\f]",M="(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+",N="\\["+L+"*("+M+")(?:"+L+"*([*^$|!~]?=)"+L+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+M+"))|)"+L+"*\\]",O=":("+M+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+N+")*)|.*)\\)|)",P=new RegExp(L+"+","g"),Q=new RegExp("^"+L+"+|((?:^|[^\\\\])(?:\\\\.)*)"+L+"+$","g"),R=new RegExp("^"+L+"*,"+L+"*"),S=new RegExp("^"+L+"*([>+~]|"+L+")"+L+"*"),T=new RegExp("="+L+"*([^\\]'\"]*?)"+L+"*\\]","g"),U=new RegExp(O),V=new RegExp("^"+M+"$"),W={ID:new RegExp("^#("+M+")"),CLASS:new RegExp("^\\.("+M+")"),TAG:new RegExp("^("+M+"|[*])"),ATTR:new RegExp("^"+N),PSEUDO:new RegExp("^"+O),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+L+"*(even|odd|(([+-]|)(\\d*)n|)"+L+"*(?:([+-]|)"+L+"*(\\d+)|))"+L+"*\\)|)","i"),bool:new RegExp("^(?:"+K+")$","i"),needsContext:new RegExp("^"+L+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+L+"*((?:-\\d)?\\d*)"+L+"*\\)|)(?=[^-]|$)","i")},X=/^(?:input|select|textarea|button)$/i,Y=/^h\d$/i,Z=/^[^{]+\{\s*\[native \w/,$=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,_=/[+~]/,aa=/'|\\/g,ba=new RegExp("\\\\([\\da-f]{1,6}"+L+"?|("+L+")|.)","ig"),ca=function(a,b,c){var d="0x"+b-65536;return d!==d||c?b:0>d?String.fromCharCode(d+65536):String.fromCharCode(d>>10|55296,1023&d|56320)},da=function(){m()};try{H.apply(E=I.call(v.childNodes),v.childNodes),E[v.childNodes.length].nodeType}catch(ea){H={apply:E.length?function(a,b){G.apply(a,I.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function fa(a,b,d,e){var f,h,j,k,l,o,r,s,w=b&&b.ownerDocument,x=b?b.nodeType:9;if(d=d||[],"string"!=typeof a||!a||1!==x&&9!==x&&11!==x)return d;if(!e&&((b?b.ownerDocument||b:v)!==n&&m(b),b=b||n,p)){if(11!==x&&(o=$.exec(a)))if(f=o[1]){if(9===x){if(!(j=b.getElementById(f)))return d;if(j.id===f)return d.push(j),d}else if(w&&(j=w.getElementById(f))&&t(b,j)&&j.id===f)return d.push(j),d}else{if(o[2])return H.apply(d,b.getElementsByTagName(a)),d;if((f=o[3])&&c.getElementsByClassName&&b.getElementsByClassName)return H.apply(d,b.getElementsByClassName(f)),d}if(c.qsa&&!A[a+" "]&&(!q||!q.test(a))){if(1!==x)w=b,s=a;else if("object"!==b.nodeName.toLowerCase()){(k=b.getAttribute("id"))?k=k.replace(aa,"\\$&"):b.setAttribute("id",k=u),r=g(a),h=r.length,l=V.test(k)?"#"+k:"[id='"+k+"']";while(h--)r[h]=l+" "+qa(r[h]);s=r.join(","),w=_.test(a)&&oa(b.parentNode)||b}if(s)try{return H.apply(d,w.querySelectorAll(s)),d}catch(y){}finally{k===u&&b.removeAttribute("id")}}}return i(a.replace(Q,"$1"),b,d,e)}function ga(){var a=[];function b(c,e){return a.push(c+" ")>d.cacheLength&&delete b[a.shift()],b[c+" "]=e}return b}function ha(a){return a[u]=!0,a}function ia(a){var b=n.createElement("div");try{return!!a(b)}catch(c){return!1}finally{b.parentNode&&b.parentNode.removeChild(b),b=null}}function ja(a,b){var c=a.split("|"),e=c.length;while(e--)d.attrHandle[c[e]]=b}function ka(a,b){var c=b&&a,d=c&&1===a.nodeType&&1===b.nodeType&&(~b.sourceIndex||C)-(~a.sourceIndex||C);if(d)return d;if(c)while(c=c.nextSibling)if(c===b)return-1;return a?1:-1}function la(a){return function(b){var c=b.nodeName.toLowerCase();return"input"===c&&b.type===a}}function ma(a){return function(b){var c=b.nodeName.toLowerCase();return("input"===c||"button"===c)&&b.type===a}}function na(a){return ha(function(b){return b=+b,ha(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function oa(a){return a&&"undefined"!=typeof a.getElementsByTagName&&a}c=fa.support={},f=fa.isXML=function(a){var b=a&&(a.ownerDocument||a).documentElement;return b?"HTML"!==b.nodeName:!1},m=fa.setDocument=function(a){var b,e,g=a?a.ownerDocument||a:v;return g!==n&&9===g.nodeType&&g.documentElement?(n=g,o=n.documentElement,p=!f(n),(e=n.defaultView)&&e.top!==e&&(e.addEventListener?e.addEventListener("unload",da,!1):e.attachEvent&&e.attachEvent("onunload",da)),c.attributes=ia(function(a){return a.className="i",!a.getAttribute("className")}),c.getElementsByTagName=ia(function(a){return a.appendChild(n.createComment("")),!a.getElementsByTagName("*").length}),c.getElementsByClassName=Z.test(n.getElementsByClassName),c.getById=ia(function(a){return o.appendChild(a).id=u,!n.getElementsByName||!n.getElementsByName(u).length}),c.getById?(d.find.ID=function(a,b){if("undefined"!=typeof b.getElementById&&p){var c=b.getElementById(a);return c?[c]:[]}},d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){return a.getAttribute("id")===b}}):(delete d.find.ID,d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){var c="undefined"!=typeof a.getAttributeNode&&a.getAttributeNode("id");return c&&c.value===b}}),d.find.TAG=c.getElementsByTagName?function(a,b){return"undefined"!=typeof b.getElementsByTagName?b.getElementsByTagName(a):c.qsa?b.querySelectorAll(a):void 0}:function(a,b){var c,d=[],e=0,f=b.getElementsByTagName(a);if("*"===a){while(c=f[e++])1===c.nodeType&&d.push(c);return d}return f},d.find.CLASS=c.getElementsByClassName&&function(a,b){return"undefined"!=typeof b.getElementsByClassName&&p?b.getElementsByClassName(a):void 0},r=[],q=[],(c.qsa=Z.test(n.querySelectorAll))&&(ia(function(a){o.appendChild(a).innerHTML="<a id='"+u+"'></a><select id='"+u+"-\r\\' msallowcapture=''><option selected=''></option></select>",a.querySelectorAll("[msallowcapture^='']").length&&q.push("[*^$]="+L+"*(?:''|\"\")"),a.querySelectorAll("[selected]").length||q.push("\\["+L+"*(?:value|"+K+")"),a.querySelectorAll("[id~="+u+"-]").length||q.push("~="),a.querySelectorAll(":checked").length||q.push(":checked"),a.querySelectorAll("a#"+u+"+*").length||q.push(".#.+[+~]")}),ia(function(a){var b=n.createElement("input");b.setAttribute("type","hidden"),a.appendChild(b).setAttribute("name","D"),a.querySelectorAll("[name=d]").length&&q.push("name"+L+"*[*^$|!~]?="),a.querySelectorAll(":enabled").length||q.push(":enabled",":disabled"),a.querySelectorAll("*,:x"),q.push(",.*:")})),(c.matchesSelector=Z.test(s=o.matches||o.webkitMatchesSelector||o.mozMatchesSelector||o.oMatchesSelector||o.msMatchesSelector))&&ia(function(a){c.disconnectedMatch=s.call(a,"div"),s.call(a,"[s!='']:x"),r.push("!=",O)}),q=q.length&&new RegExp(q.join("|")),r=r.length&&new RegExp(r.join("|")),b=Z.test(o.compareDocumentPosition),t=b||Z.test(o.contains)?function(a,b){var c=9===a.nodeType?a.documentElement:a,d=b&&b.parentNode;return a===d||!(!d||1!==d.nodeType||!(c.contains?c.contains(d):a.compareDocumentPosition&&16&a.compareDocumentPosition(d)))}:function(a,b){if(b)while(b=b.parentNode)if(b===a)return!0;return!1},B=b?function(a,b){if(a===b)return l=!0,0;var d=!a.compareDocumentPosition-!b.compareDocumentPosition;return d?d:(d=(a.ownerDocument||a)===(b.ownerDocument||b)?a.compareDocumentPosition(b):1,1&d||!c.sortDetached&&b.compareDocumentPosition(a)===d?a===n||a.ownerDocument===v&&t(v,a)?-1:b===n||b.ownerDocument===v&&t(v,b)?1:k?J(k,a)-J(k,b):0:4&d?-1:1)}:function(a,b){if(a===b)return l=!0,0;var c,d=0,e=a.parentNode,f=b.parentNode,g=[a],h=[b];if(!e||!f)return a===n?-1:b===n?1:e?-1:f?1:k?J(k,a)-J(k,b):0;if(e===f)return ka(a,b);c=a;while(c=c.parentNode)g.unshift(c);c=b;while(c=c.parentNode)h.unshift(c);while(g[d]===h[d])d++;return d?ka(g[d],h[d]):g[d]===v?-1:h[d]===v?1:0},n):n},fa.matches=function(a,b){return fa(a,null,null,b)},fa.matchesSelector=function(a,b){if((a.ownerDocument||a)!==n&&m(a),b=b.replace(T,"='$1']"),c.matchesSelector&&p&&!A[b+" "]&&(!r||!r.test(b))&&(!q||!q.test(b)))try{var d=s.call(a,b);if(d||c.disconnectedMatch||a.document&&11!==a.document.nodeType)return d}catch(e){}return fa(b,n,null,[a]).length>0},fa.contains=function(a,b){return(a.ownerDocument||a)!==n&&m(a),t(a,b)},fa.attr=function(a,b){(a.ownerDocument||a)!==n&&m(a);var e=d.attrHandle[b.toLowerCase()],f=e&&D.call(d.attrHandle,b.toLowerCase())?e(a,b,!p):void 0;return void 0!==f?f:c.attributes||!p?a.getAttribute(b):(f=a.getAttributeNode(b))&&f.specified?f.value:null},fa.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)},fa.uniqueSort=function(a){var b,d=[],e=0,f=0;if(l=!c.detectDuplicates,k=!c.sortStable&&a.slice(0),a.sort(B),l){while(b=a[f++])b===a[f]&&(e=d.push(f));while(e--)a.splice(d[e],1)}return k=null,a},e=fa.getText=function(a){var b,c="",d=0,f=a.nodeType;if(f){if(1===f||9===f||11===f){if("string"==typeof a.textContent)return a.textContent;for(a=a.firstChild;a;a=a.nextSibling)c+=e(a)}else if(3===f||4===f)return a.nodeValue}else while(b=a[d++])c+=e(b);return c},d=fa.selectors={cacheLength:50,createPseudo:ha,match:W,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(a){return a[1]=a[1].replace(ba,ca),a[3]=(a[3]||a[4]||a[5]||"").replace(ba,ca),"~="===a[2]&&(a[3]=" "+a[3]+" "),a.slice(0,4)},CHILD:function(a){return a[1]=a[1].toLowerCase(),"nth"===a[1].slice(0,3)?(a[3]||fa.error(a[0]),a[4]=+(a[4]?a[5]+(a[6]||1):2*("even"===a[3]||"odd"===a[3])),a[5]=+(a[7]+a[8]||"odd"===a[3])):a[3]&&fa.error(a[0]),a},PSEUDO:function(a){var b,c=!a[6]&&a[2];return W.CHILD.test(a[0])?null:(a[3]?a[2]=a[4]||a[5]||"":c&&U.test(c)&&(b=g(c,!0))&&(b=c.indexOf(")",c.length-b)-c.length)&&(a[0]=a[0].slice(0,b),a[2]=c.slice(0,b)),a.slice(0,3))}},filter:{TAG:function(a){var b=a.replace(ba,ca).toLowerCase();return"*"===a?function(){return!0}:function(a){return a.nodeName&&a.nodeName.toLowerCase()===b}},CLASS:function(a){var b=y[a+" "];return b||(b=new RegExp("(^|"+L+")"+a+"("+L+"|$)"))&&y(a,function(a){return b.test("string"==typeof a.className&&a.className||"undefined"!=typeof a.getAttribute&&a.getAttribute("class")||"")})},ATTR:function(a,b,c){return function(d){var e=fa.attr(d,a);return null==e?"!="===b:b?(e+="","="===b?e===c:"!="===b?e!==c:"^="===b?c&&0===e.indexOf(c):"*="===b?c&&e.indexOf(c)>-1:"$="===b?c&&e.slice(-c.length)===c:"~="===b?(" "+e.replace(P," ")+" ").indexOf(c)>-1:"|="===b?e===c||e.slice(0,c.length+1)===c+"-":!1):!0}},CHILD:function(a,b,c,d,e){var f="nth"!==a.slice(0,3),g="last"!==a.slice(-4),h="of-type"===b;return 1===d&&0===e?function(a){return!!a.parentNode}:function(b,c,i){var j,k,l,m,n,o,p=f!==g?"nextSibling":"previousSibling",q=b.parentNode,r=h&&b.nodeName.toLowerCase(),s=!i&&!h,t=!1;if(q){if(f){while(p){m=b;while(m=m[p])if(h?m.nodeName.toLowerCase()===r:1===m.nodeType)return!1;o=p="only"===a&&!o&&"nextSibling"}return!0}if(o=[g?q.firstChild:q.lastChild],g&&s){m=q,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n&&j[2],m=n&&q.childNodes[n];while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if(1===m.nodeType&&++t&&m===b){k[a]=[w,n,t];break}}else if(s&&(m=b,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n),t===!1)while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if((h?m.nodeName.toLowerCase()===r:1===m.nodeType)&&++t&&(s&&(l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),k[a]=[w,t]),m===b))break;return t-=e,t===d||t%d===0&&t/d>=0}}},PSEUDO:function(a,b){var c,e=d.pseudos[a]||d.setFilters[a.toLowerCase()]||fa.error("unsupported pseudo: "+a);return e[u]?e(b):e.length>1?(c=[a,a,"",b],d.setFilters.hasOwnProperty(a.toLowerCase())?ha(function(a,c){var d,f=e(a,b),g=f.length;while(g--)d=J(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return e(a,0,c)}):e}},pseudos:{not:ha(function(a){var b=[],c=[],d=h(a.replace(Q,"$1"));return d[u]?ha(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return b[0]=a,d(b,null,f,c),b[0]=null,!c.pop()}}),has:ha(function(a){return function(b){return fa(a,b).length>0}}),contains:ha(function(a){return a=a.replace(ba,ca),function(b){return(b.textContent||b.innerText||e(b)).indexOf(a)>-1}}),lang:ha(function(a){return V.test(a||"")||fa.error("unsupported lang: "+a),a=a.replace(ba,ca).toLowerCase(),function(b){var c;do if(c=p?b.lang:b.getAttribute("xml:lang")||b.getAttribute("lang"))return c=c.toLowerCase(),c===a||0===c.indexOf(a+"-");while((b=b.parentNode)&&1===b.nodeType);return!1}}),target:function(b){var c=a.location&&a.location.hash;return c&&c.slice(1)===b.id},root:function(a){return a===o},focus:function(a){return a===n.activeElement&&(!n.hasFocus||n.hasFocus())&&!!(a.type||a.href||~a.tabIndex)},enabled:function(a){return a.disabled===!1},disabled:function(a){return a.disabled===!0},checked:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&!!a.checked||"option"===b&&!!a.selected},selected:function(a){return a.parentNode&&a.parentNode.selectedIndex,a.selected===!0},empty:function(a){for(a=a.firstChild;a;a=a.nextSibling)if(a.nodeType<6)return!1;return!0},parent:function(a){return!d.pseudos.empty(a)},header:function(a){return Y.test(a.nodeName)},input:function(a){return X.test(a.nodeName)},button:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&"button"===a.type||"button"===b},text:function(a){var b;return"input"===a.nodeName.toLowerCase()&&"text"===a.type&&(null==(b=a.getAttribute("type"))||"text"===b.toLowerCase())},first:na(function(){return[0]}),last:na(function(a,b){return[b-1]}),eq:na(function(a,b,c){return[0>c?c+b:c]}),even:na(function(a,b){for(var c=0;b>c;c+=2)a.push(c);return a}),odd:na(function(a,b){for(var c=1;b>c;c+=2)a.push(c);return a}),lt:na(function(a,b,c){for(var d=0>c?c+b:c;--d>=0;)a.push(d);return a}),gt:na(function(a,b,c){for(var d=0>c?c+b:c;++d<b;)a.push(d);return a})}},d.pseudos.nth=d.pseudos.eq;for(b in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})d.pseudos[b]=la(b);for(b in{submit:!0,reset:!0})d.pseudos[b]=ma(b);function pa(){}pa.prototype=d.filters=d.pseudos,d.setFilters=new pa,g=fa.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+" "];if(k)return b?0:k.slice(0);h=a,i=[],j=d.preFilter;while(h){c&&!(e=R.exec(h))||(e&&(h=h.slice(e[0].length)||h),i.push(f=[])),c=!1,(e=S.exec(h))&&(c=e.shift(),f.push({value:c,type:e[0].replace(Q," ")}),h=h.slice(c.length));for(g in d.filter)!(e=W[g].exec(h))||j[g]&&!(e=j[g](e))||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return b?h.length:h?fa.error(a):z(a,i).slice(0)};function qa(a){for(var b=0,c=a.length,d="";c>b;b++)d+=a[b].value;return d}function ra(a,b,c){var d=b.dir,e=c&&"parentNode"===d,f=x++;return b.first?function(b,c,f){while(b=b[d])if(1===b.nodeType||e)return a(b,c,f)}:function(b,c,g){var h,i,j,k=[w,f];if(g){while(b=b[d])if((1===b.nodeType||e)&&a(b,c,g))return!0}else while(b=b[d])if(1===b.nodeType||e){if(j=b[u]||(b[u]={}),i=j[b.uniqueID]||(j[b.uniqueID]={}),(h=i[d])&&h[0]===w&&h[1]===f)return k[2]=h[2];if(i[d]=k,k[2]=a(b,c,g))return!0}}}function sa(a){return a.length>1?function(b,c,d){var e=a.length;while(e--)if(!a[e](b,c,d))return!1;return!0}:a[0]}function ta(a,b,c){for(var d=0,e=b.length;e>d;d++)fa(a,b[d],c);return c}function ua(a,b,c,d,e){for(var f,g=[],h=0,i=a.length,j=null!=b;i>h;h++)(f=a[h])&&(c&&!c(f,d,e)||(g.push(f),j&&b.push(h)));return g}function va(a,b,c,d,e,f){return d&&!d[u]&&(d=va(d)),e&&!e[u]&&(e=va(e,f)),ha(function(f,g,h,i){var j,k,l,m=[],n=[],o=g.length,p=f||ta(b||"*",h.nodeType?[h]:h,[]),q=!a||!f&&b?p:ua(p,m,a,h,i),r=c?e||(f?a:o||d)?[]:g:q;if(c&&c(q,r,h,i),d){j=ua(r,n),d(j,[],h,i),k=j.length;while(k--)(l=j[k])&&(r[n[k]]=!(q[n[k]]=l))}if(f){if(e||a){if(e){j=[],k=r.length;while(k--)(l=r[k])&&j.push(q[k]=l);e(null,r=[],j,i)}k=r.length;while(k--)(l=r[k])&&(j=e?J(f,l):m[k])>-1&&(f[j]=!(g[j]=l))}}else r=ua(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):H.apply(g,r)})}function wa(a){for(var b,c,e,f=a.length,g=d.relative[a[0].type],h=g||d.relative[" "],i=g?1:0,k=ra(function(a){return a===b},h,!0),l=ra(function(a){return J(b,a)>-1},h,!0),m=[function(a,c,d){var e=!g&&(d||c!==j)||((b=c).nodeType?k(a,c,d):l(a,c,d));return b=null,e}];f>i;i++)if(c=d.relative[a[i].type])m=[ra(sa(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[u]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return va(i>1&&sa(m),i>1&&qa(a.slice(0,i-1).concat({value:" "===a[i-2].type?"*":""})).replace(Q,"$1"),c,e>i&&wa(a.slice(i,e)),f>e&&wa(a=a.slice(e)),f>e&&qa(a))}m.push(c)}return sa(m)}function xa(a,b){var c=b.length>0,e=a.length>0,f=function(f,g,h,i,k){var l,o,q,r=0,s="0",t=f&&[],u=[],v=j,x=f||e&&d.find.TAG("*",k),y=w+=null==v?1:Math.random()||.1,z=x.length;for(k&&(j=g===n||g||k);s!==z&&null!=(l=x[s]);s++){if(e&&l){o=0,g||l.ownerDocument===n||(m(l),h=!p);while(q=a[o++])if(q(l,g||n,h)){i.push(l);break}k&&(w=y)}c&&((l=!q&&l)&&r--,f&&t.push(l))}if(r+=s,c&&s!==r){o=0;while(q=b[o++])q(t,u,g,h);if(f){if(r>0)while(s--)t[s]||u[s]||(u[s]=F.call(i));u=ua(u)}H.apply(i,u),k&&!f&&u.length>0&&r+b.length>1&&fa.uniqueSort(i)}return k&&(w=y,j=v),t};return c?ha(f):f}return h=fa.compile=function(a,b){var c,d=[],e=[],f=A[a+" "];if(!f){b||(b=g(a)),c=b.length;while(c--)f=wa(b[c]),f[u]?d.push(f):e.push(f);f=A(a,xa(e,d)),f.selector=a}return f},i=fa.select=function(a,b,e,f){var i,j,k,l,m,n="function"==typeof a&&a,o=!f&&g(a=n.selector||a);if(e=e||[],1===o.length){if(j=o[0]=o[0].slice(0),j.length>2&&"ID"===(k=j[0]).type&&c.getById&&9===b.nodeType&&p&&d.relative[j[1].type]){if(b=(d.find.ID(k.matches[0].replace(ba,ca),b)||[])[0],!b)return e;n&&(b=b.parentNode),a=a.slice(j.shift().value.length)}i=W.needsContext.test(a)?0:j.length;while(i--){if(k=j[i],d.relative[l=k.type])break;if((m=d.find[l])&&(f=m(k.matches[0].replace(ba,ca),_.test(j[0].type)&&oa(b.parentNode)||b))){if(j.splice(i,1),a=f.length&&qa(j),!a)return H.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,!b||_.test(a)&&oa(b.parentNode)||b),e},c.sortStable=u.split("").sort(B).join("")===u,c.detectDuplicates=!!l,m(),c.sortDetached=ia(function(a){return 1&a.compareDocumentPosition(n.createElement("div"))}),ia(function(a){return a.innerHTML="<a href='#'></a>","#"===a.firstChild.getAttribute("href")})||ja("type|href|height|width",function(a,b,c){return c?void 0:a.getAttribute(b,"type"===b.toLowerCase()?1:2)}),c.attributes&&ia(function(a){return a.innerHTML="<input/>",a.firstChild.setAttribute("value",""),""===a.firstChild.getAttribute("value")})||ja("value",function(a,b,c){return c||"input"!==a.nodeName.toLowerCase()?void 0:a.defaultValue}),ia(function(a){return null==a.getAttribute("disabled")})||ja(K,function(a,b,c){var d;return c?void 0:a[b]===!0?b.toLowerCase():(d=a.getAttributeNode(b))&&d.specified?d.value:null}),fa}(a);n.find=t,n.expr=t.selectors,n.expr[":"]=n.expr.pseudos,n.uniqueSort=n.unique=t.uniqueSort,n.text=t.getText,n.isXMLDoc=t.isXML,n.contains=t.contains;var u=function(a,b,c){var d=[],e=void 0!==c;while((a=a[b])&&9!==a.nodeType)if(1===a.nodeType){if(e&&n(a).is(c))break;d.push(a)}return d},v=function(a,b){for(var c=[];a;a=a.nextSibling)1===a.nodeType&&a!==b&&c.push(a);return c},w=n.expr.match.needsContext,x=/^<([\w-]+)\s*\/?>(?:<\/\1>|)$/,y=/^.[^:#\[\.,]*$/;function z(a,b,c){if(n.isFunction(b))return n.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodeType)return n.grep(a,function(a){return a===b!==c});if("string"==typeof b){if(y.test(b))return n.filter(b,a,c);b=n.filter(b,a)}return n.grep(a,function(a){return n.inArray(a,b)>-1!==c})}n.filter=function(a,b,c){var d=b[0];return c&&(a=":not("+a+")"),1===b.length&&1===d.nodeType?n.find.matchesSelector(d,a)?[d]:[]:n.find.matches(a,n.grep(b,function(a){return 1===a.nodeType}))},n.fn.extend({find:function(a){var b,c=[],d=this,e=d.length;if("string"!=typeof a)return this.pushStack(n(a).filter(function(){for(b=0;e>b;b++)if(n.contains(d[b],this))return!0}));for(b=0;e>b;b++)n.find(a,d[b],c);return c=this.pushStack(e>1?n.unique(c):c),c.selector=this.selector?this.selector+" "+a:a,c},filter:function(a){return this.pushStack(z(this,a||[],!1))},not:function(a){return this.pushStack(z(this,a||[],!0))},is:function(a){return!!z(this,"string"==typeof a&&w.test(a)?n(a):a||[],!1).length}});var A,B=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/,C=n.fn.init=function(a,b,c){var e,f;if(!a)return this;if(c=c||A,"string"==typeof a){if(e="<"===a.charAt(0)&&">"===a.charAt(a.length-1)&&a.length>=3?[null,a,null]:B.exec(a),!e||!e[1]&&b)return!b||b.jquery?(b||c).find(a):this.constructor(b).find(a);if(e[1]){if(b=b instanceof n?b[0]:b,n.merge(this,n.parseHTML(e[1],b&&b.nodeType?b.ownerDocument||b:d,!0)),x.test(e[1])&&n.isPlainObject(b))for(e in b)n.isFunction(this[e])?this[e](b[e]):this.attr(e,b[e]);return this}if(f=d.getElementById(e[2]),f&&f.parentNode){if(f.id!==e[2])return A.find(a);this.length=1,this[0]=f}return this.context=d,this.selector=a,this}return a.nodeType?(this.context=this[0]=a,this.length=1,this):n.isFunction(a)?"undefined"!=typeof c.ready?c.ready(a):a(n):(void 0!==a.selector&&(this.selector=a.selector,this.context=a.context),n.makeArray(a,this))};C.prototype=n.fn,A=n(d);var D=/^(?:parents|prev(?:Until|All))/,E={children:!0,contents:!0,next:!0,prev:!0};n.fn.extend({has:function(a){var b,c=n(a,this),d=c.length;return this.filter(function(){for(b=0;d>b;b++)if(n.contains(this,c[b]))return!0})},closest:function(a,b){for(var c,d=0,e=this.length,f=[],g=w.test(a)||"string"!=typeof a?n(a,b||this.context):0;e>d;d++)for(c=this[d];c&&c!==b;c=c.parentNode)if(c.nodeType<11&&(g?g.index(c)>-1:1===c.nodeType&&n.find.matchesSelector(c,a))){f.push(c);break}return this.pushStack(f.length>1?n.uniqueSort(f):f)},index:function(a){return a?"string"==typeof a?n.inArray(this[0],n(a)):n.inArray(a.jquery?a[0]:a,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(a,b){return this.pushStack(n.uniqueSort(n.merge(this.get(),n(a,b))))},addBack:function(a){return this.add(null==a?this.prevObject:this.prevObject.filter(a))}});function F(a,b){do a=a[b];while(a&&1!==a.nodeType);return a}n.each({parent:function(a){var b=a.parentNode;return b&&11!==b.nodeType?b:null},parents:function(a){return u(a,"parentNode")},parentsUntil:function(a,b,c){return u(a,"parentNode",c)},next:function(a){return F(a,"nextSibling")},prev:function(a){return F(a,"previousSibling")},nextAll:function(a){return u(a,"nextSibling")},prevAll:function(a){return u(a,"previousSibling")},nextUntil:function(a,b,c){return u(a,"nextSibling",c)},prevUntil:function(a,b,c){return u(a,"previousSibling",c)},siblings:function(a){return v((a.parentNode||{}).firstChild,a)},children:function(a){return v(a.firstChild)},contents:function(a){return n.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:n.merge([],a.childNodes)}},function(a,b){n.fn[a]=function(c,d){var e=n.map(this,b,c);return"Until"!==a.slice(-5)&&(d=c),d&&"string"==typeof d&&(e=n.filter(d,e)),this.length>1&&(E[a]||(e=n.uniqueSort(e)),D.test(a)&&(e=e.reverse())),this.pushStack(e)}});var G=/\S+/g;function H(a){var b={};return n.each(a.match(G)||[],function(a,c){b[c]=!0}),b}n.Callbacks=function(a){a="string"==typeof a?H(a):n.extend({},a);var b,c,d,e,f=[],g=[],h=-1,i=function(){for(e=a.once,d=b=!0;g.length;h=-1){c=g.shift();while(++h<f.length)f[h].apply(c[0],c[1])===!1&&a.stopOnFalse&&(h=f.length,c=!1)}a.memory||(c=!1),b=!1,e&&(f=c?[]:"")},j={add:function(){return f&&(c&&!b&&(h=f.length-1,g.push(c)),function d(b){n.each(b,function(b,c){n.isFunction(c)?a.unique&&j.has(c)||f.push(c):c&&c.length&&"string"!==n.type(c)&&d(c)})}(arguments),c&&!b&&i()),this},remove:function(){return n.each(arguments,function(a,b){var c;while((c=n.inArray(b,f,c))>-1)f.splice(c,1),h>=c&&h--}),this},has:function(a){return a?n.inArray(a,f)>-1:f.length>0},empty:function(){return f&&(f=[]),this},disable:function(){return e=g=[],f=c="",this},disabled:function(){return!f},lock:function(){return e=!0,c||j.disable(),this},locked:function(){return!!e},fireWith:function(a,c){return e||(c=c||[],c=[a,c.slice?c.slice():c],g.push(c),b||i()),this},fire:function(){return j.fireWith(this,arguments),this},fired:function(){return!!d}};return j},n.extend({Deferred:function(a){var b=[["resolve","done",n.Callbacks("once memory"),"resolved"],["reject","fail",n.Callbacks("once memory"),"rejected"],["notify","progress",n.Callbacks("memory")]],c="pending",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return n.Deferred(function(c){n.each(b,function(b,f){var g=n.isFunction(a[b])&&a[b];e[f[1]](function(){var a=g&&g.apply(this,arguments);a&&n.isFunction(a.promise)?a.promise().progress(c.notify).done(c.resolve).fail(c.reject):c[f[0]+"With"](this===d?c.promise():this,g?[a]:arguments)})}),a=null}).promise()},promise:function(a){return null!=a?n.extend(a,d):d}},e={};return d.pipe=d.then,n.each(b,function(a,f){var g=f[2],h=f[3];d[f[1]]=g.add,h&&g.add(function(){c=h},b[1^a][2].disable,b[2][2].lock),e[f[0]]=function(){return e[f[0]+"With"](this===e?d:this,arguments),this},e[f[0]+"With"]=g.fireWith}),d.promise(e),a&&a.call(e,e),e},when:function(a){var b=0,c=e.call(arguments),d=c.length,f=1!==d||a&&n.isFunction(a.promise)?d:0,g=1===f?a:n.Deferred(),h=function(a,b,c){return function(d){b[a]=this,c[a]=arguments.length>1?e.call(arguments):d,c===i?g.notifyWith(b,c):--f||g.resolveWith(b,c)}},i,j,k;if(d>1)for(i=new Array(d),j=new Array(d),k=new Array(d);d>b;b++)c[b]&&n.isFunction(c[b].promise)?c[b].promise().progress(h(b,j,i)).done(h(b,k,c)).fail(g.reject):--f;return f||g.resolveWith(k,c),g.promise()}});var I;n.fn.ready=function(a){return n.ready.promise().done(a),this},n.extend({isReady:!1,readyWait:1,holdReady:function(a){a?n.readyWait++:n.ready(!0)},ready:function(a){(a===!0?--n.readyWait:n.isReady)||(n.isReady=!0,a!==!0&&--n.readyWait>0||(I.resolveWith(d,[n]),n.fn.triggerHandler&&(n(d).triggerHandler("ready"),n(d).off("ready"))))}});function J(){d.addEventListener?(d.removeEventListener("DOMContentLoaded",K),a.removeEventListener("load",K)):(d.detachEvent("onreadystatechange",K),a.detachEvent("onload",K))}function K(){(d.addEventListener||"load"===a.event.type||"complete"===d.readyState)&&(J(),n.ready())}n.ready.promise=function(b){if(!I)if(I=n.Deferred(),"complete"===d.readyState||"loading"!==d.readyState&&!d.documentElement.doScroll)a.setTimeout(n.ready);else if(d.addEventListener)d.addEventListener("DOMContentLoaded",K),a.addEventListener("load",K);else{d.attachEvent("onreadystatechange",K),a.attachEvent("onload",K);var c=!1;try{c=null==a.frameElement&&d.documentElement}catch(e){}c&&c.doScroll&&!function f(){if(!n.isReady){try{c.doScroll("left")}catch(b){return a.setTimeout(f,50)}J(),n.ready()}}()}return I.promise(b)},n.ready.promise();var L;for(L in n(l))break;l.ownFirst="0"===L,l.inlineBlockNeedsLayout=!1,n(function(){var a,b,c,e;c=d.getElementsByTagName("body")[0],c&&c.style&&(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="display:inline;margin:0;border:0;padding:1px;width:1px;zoom:1",l.inlineBlockNeedsLayout=a=3===b.offsetWidth,a&&(c.style.zoom=1)),c.removeChild(e))}),function(){var a=d.createElement("div");l.deleteExpando=!0;try{delete a.test}catch(b){l.deleteExpando=!1}a=null}();var M=function(a){var b=n.noData[(a.nodeName+" ").toLowerCase()],c=+a.nodeType||1;return 1!==c&&9!==c?!1:!b||b!==!0&&a.getAttribute("classid")===b},N=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,O=/([A-Z])/g;function P(a,b,c){if(void 0===c&&1===a.nodeType){var d="data-"+b.replace(O,"-$1").toLowerCase();if(c=a.getAttribute(d),"string"==typeof c){try{c="true"===c?!0:"false"===c?!1:"null"===c?null:+c+""===c?+c:N.test(c)?n.parseJSON(c):c}catch(e){}n.data(a,b,c)}else c=void 0;
}return c}function Q(a){var b;for(b in a)if(("data"!==b||!n.isEmptyObject(a[b]))&&"toJSON"!==b)return!1;return!0}function R(a,b,d,e){if(M(a)){var f,g,h=n.expando,i=a.nodeType,j=i?n.cache:a,k=i?a[h]:a[h]&&h;if(k&&j[k]&&(e||j[k].data)||void 0!==d||"string"!=typeof b)return k||(k=i?a[h]=c.pop()||n.guid++:h),j[k]||(j[k]=i?{}:{toJSON:n.noop}),"object"!=typeof b&&"function"!=typeof b||(e?j[k]=n.extend(j[k],b):j[k].data=n.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void 0!==d&&(g[n.camelCase(b)]=d),"string"==typeof b?(f=g[b],null==f&&(f=g[n.camelCase(b)])):f=g,f}}function S(a,b,c){if(M(a)){var d,e,f=a.nodeType,g=f?n.cache:a,h=f?a[n.expando]:n.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){n.isArray(b)?b=b.concat(n.map(b,n.camelCase)):b in d?b=[b]:(b=n.camelCase(b),b=b in d?[b]:b.split(" ")),e=b.length;while(e--)delete d[b[e]];if(c?!Q(d):!n.isEmptyObject(d))return}(c||(delete g[h].data,Q(g[h])))&&(f?n.cleanData([a],!0):l.deleteExpando||g!=g.window?delete g[h]:g[h]=void 0)}}}n.extend({cache:{},noData:{"applet ":!0,"embed ":!0,"object ":"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"},hasData:function(a){return a=a.nodeType?n.cache[a[n.expando]]:a[n.expando],!!a&&!Q(a)},data:function(a,b,c){return R(a,b,c)},removeData:function(a,b){return S(a,b)},_data:function(a,b,c){return R(a,b,c,!0)},_removeData:function(a,b){return S(a,b,!0)}}),n.fn.extend({data:function(a,b){var c,d,e,f=this[0],g=f&&f.attributes;if(void 0===a){if(this.length&&(e=n.data(f),1===f.nodeType&&!n._data(f,"parsedAttrs"))){c=g.length;while(c--)g[c]&&(d=g[c].name,0===d.indexOf("data-")&&(d=n.camelCase(d.slice(5)),P(f,d,e[d])));n._data(f,"parsedAttrs",!0)}return e}return"object"==typeof a?this.each(function(){n.data(this,a)}):arguments.length>1?this.each(function(){n.data(this,a,b)}):f?P(f,a,n.data(f,a)):void 0},removeData:function(a){return this.each(function(){n.removeData(this,a)})}}),n.extend({queue:function(a,b,c){var d;return a?(b=(b||"fx")+"queue",d=n._data(a,b),c&&(!d||n.isArray(c)?d=n._data(a,b,n.makeArray(c)):d.push(c)),d||[]):void 0},dequeue:function(a,b){b=b||"fx";var c=n.queue(a,b),d=c.length,e=c.shift(),f=n._queueHooks(a,b),g=function(){n.dequeue(a,b)};"inprogress"===e&&(e=c.shift(),d--),e&&("fx"===b&&c.unshift("inprogress"),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queueHooks:function(a,b){var c=b+"queueHooks";return n._data(a,c)||n._data(a,c,{empty:n.Callbacks("once memory").add(function(){n._removeData(a,b+"queue"),n._removeData(a,c)})})}}),n.fn.extend({queue:function(a,b){var c=2;return"string"!=typeof a&&(b=a,a="fx",c--),arguments.length<c?n.queue(this[0],a):void 0===b?this:this.each(function(){var c=n.queue(this,a,b);n._queueHooks(this,a),"fx"===a&&"inprogress"!==c[0]&&n.dequeue(this,a)})},dequeue:function(a){return this.each(function(){n.dequeue(this,a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,b){var c,d=1,e=n.Deferred(),f=this,g=this.length,h=function(){--d||e.resolveWith(f,[f])};"string"!=typeof a&&(b=a,a=void 0),a=a||"fx";while(g--)c=n._data(f[g],a+"queueHooks"),c&&c.empty&&(d++,c.empty.add(h));return h(),e.promise(b)}}),function(){var a;l.shrinkWrapBlocks=function(){if(null!=a)return a;a=!1;var b,c,e;return c=d.getElementsByTagName("body")[0],c&&c.style?(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:1px;width:1px;zoom:1",b.appendChild(d.createElement("div")).style.width="5px",a=3!==b.offsetWidth),c.removeChild(e),a):void 0}}();var T=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,U=new RegExp("^(?:([+-])=|)("+T+")([a-z%]*)$","i"),V=["Top","Right","Bottom","Left"],W=function(a,b){return a=b||a,"none"===n.css(a,"display")||!n.contains(a.ownerDocument,a)};function X(a,b,c,d){var e,f=1,g=20,h=d?function(){return d.cur()}:function(){return n.css(a,b,"")},i=h(),j=c&&c[3]||(n.cssNumber[b]?"":"px"),k=(n.cssNumber[b]||"px"!==j&&+i)&&U.exec(n.css(a,b));if(k&&k[3]!==j){j=j||k[3],c=c||[],k=+i||1;do f=f||".5",k/=f,n.style(a,b,k+j);while(f!==(f=h()/i)&&1!==f&&--g)}return c&&(k=+k||+i||0,e=c[1]?k+(c[1]+1)*c[2]:+c[2],d&&(d.unit=j,d.start=k,d.end=e)),e}var Y=function(a,b,c,d,e,f,g){var h=0,i=a.length,j=null==c;if("object"===n.type(c)){e=!0;for(h in c)Y(a,b,h,c[h],!0,f,g)}else if(void 0!==d&&(e=!0,n.isFunction(d)||(g=!0),j&&(g?(b.call(a,d),b=null):(j=b,b=function(a,b,c){return j.call(n(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return e?a:j?b.call(a):i?b(a[0],c):f},Z=/^(?:checkbox|radio)$/i,$=/<([\w:-]+)/,_=/^$|\/(?:java|ecma)script/i,aa=/^\s+/,ba="abbr|article|aside|audio|bdi|canvas|data|datalist|details|dialog|figcaption|figure|footer|header|hgroup|main|mark|meter|nav|output|picture|progress|section|summary|template|time|video";function ca(a){var b=ba.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}!function(){var a=d.createElement("div"),b=d.createDocumentFragment(),c=d.createElement("input");a.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",l.leadingWhitespace=3===a.firstChild.nodeType,l.tbody=!a.getElementsByTagName("tbody").length,l.htmlSerialize=!!a.getElementsByTagName("link").length,l.html5Clone="<:nav></:nav>"!==d.createElement("nav").cloneNode(!0).outerHTML,c.type="checkbox",c.checked=!0,b.appendChild(c),l.appendChecked=c.checked,a.innerHTML="<textarea>x</textarea>",l.noCloneChecked=!!a.cloneNode(!0).lastChild.defaultValue,b.appendChild(a),c=d.createElement("input"),c.setAttribute("type","radio"),c.setAttribute("checked","checked"),c.setAttribute("name","t"),a.appendChild(c),l.checkClone=a.cloneNode(!0).cloneNode(!0).lastChild.checked,l.noCloneEvent=!!a.addEventListener,a[n.expando]=1,l.attributes=!a.getAttribute(n.expando)}();var da={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],area:[1,"<map>","</map>"],param:[1,"<object>","</object>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:l.htmlSerialize?[0,"",""]:[1,"X<div>","</div>"]};da.optgroup=da.option,da.tbody=da.tfoot=da.colgroup=da.caption=da.thead,da.th=da.td;function ea(a,b){var c,d,e=0,f="undefined"!=typeof a.getElementsByTagName?a.getElementsByTagName(b||"*"):"undefined"!=typeof a.querySelectorAll?a.querySelectorAll(b||"*"):void 0;if(!f)for(f=[],c=a.childNodes||a;null!=(d=c[e]);e++)!b||n.nodeName(d,b)?f.push(d):n.merge(f,ea(d,b));return void 0===b||b&&n.nodeName(a,b)?n.merge([a],f):f}function fa(a,b){for(var c,d=0;null!=(c=a[d]);d++)n._data(c,"globalEval",!b||n._data(b[d],"globalEval"))}var ga=/<|&#?\w+;/,ha=/<tbody/i;function ia(a){Z.test(a.type)&&(a.defaultChecked=a.checked)}function ja(a,b,c,d,e){for(var f,g,h,i,j,k,m,o=a.length,p=ca(b),q=[],r=0;o>r;r++)if(g=a[r],g||0===g)if("object"===n.type(g))n.merge(q,g.nodeType?[g]:g);else if(ga.test(g)){i=i||p.appendChild(b.createElement("div")),j=($.exec(g)||["",""])[1].toLowerCase(),m=da[j]||da._default,i.innerHTML=m[1]+n.htmlPrefilter(g)+m[2],f=m[0];while(f--)i=i.lastChild;if(!l.leadingWhitespace&&aa.test(g)&&q.push(b.createTextNode(aa.exec(g)[0])),!l.tbody){g="table"!==j||ha.test(g)?"<table>"!==m[1]||ha.test(g)?0:i:i.firstChild,f=g&&g.childNodes.length;while(f--)n.nodeName(k=g.childNodes[f],"tbody")&&!k.childNodes.length&&g.removeChild(k)}n.merge(q,i.childNodes),i.textContent="";while(i.firstChild)i.removeChild(i.firstChild);i=p.lastChild}else q.push(b.createTextNode(g));i&&p.removeChild(i),l.appendChecked||n.grep(ea(q,"input"),ia),r=0;while(g=q[r++])if(d&&n.inArray(g,d)>-1)e&&e.push(g);else if(h=n.contains(g.ownerDocument,g),i=ea(p.appendChild(g),"script"),h&&fa(i),c){f=0;while(g=i[f++])_.test(g.type||"")&&c.push(g)}return i=null,p}!function(){var b,c,e=d.createElement("div");for(b in{submit:!0,change:!0,focusin:!0})c="on"+b,(l[b]=c in a)||(e.setAttribute(c,"t"),l[b]=e.attributes[c].expando===!1);e=null}();var ka=/^(?:input|select|textarea)$/i,la=/^key/,ma=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,na=/^(?:focusinfocus|focusoutblur)$/,oa=/^([^.]*)(?:\.(.+)|)/;function pa(){return!0}function qa(){return!1}function ra(){try{return d.activeElement}catch(a){}}function sa(a,b,c,d,e,f){var g,h;if("object"==typeof b){"string"!=typeof c&&(d=d||c,c=void 0);for(h in b)sa(a,h,c,d,b[h],f);return a}if(null==d&&null==e?(e=c,d=c=void 0):null==e&&("string"==typeof c?(e=d,d=void 0):(e=d,d=c,c=void 0)),e===!1)e=qa;else if(!e)return a;return 1===f&&(g=e,e=function(a){return n().off(a),g.apply(this,arguments)},e.guid=g.guid||(g.guid=n.guid++)),a.each(function(){n.event.add(this,b,e,d,c)})}n.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=n.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return"undefined"==typeof n||a&&n.event.triggered===a.type?void 0:n.event.dispatch.apply(k.elem,arguments)},k.elem=a),b=(b||"").match(G)||[""],h=b.length;while(h--)f=oa.exec(b[h])||[],o=q=f[1],p=(f[2]||"").split(".").sort(),o&&(j=n.event.special[o]||{},o=(e?j.delegateType:j.bindType)||o,j=n.event.special[o]||{},l=n.extend({type:o,origType:q,data:d,handler:c,guid:c.guid,selector:e,needsContext:e&&n.expr.match.needsContext.test(e),namespace:p.join(".")},i),(m=g[o])||(m=g[o]=[],m.delegateCount=0,j.setup&&j.setup.call(a,d,p,k)!==!1||(a.addEventListener?a.addEventListener(o,k,!1):a.attachEvent&&a.attachEvent("on"+o,k))),j.add&&(j.add.call(a,l),l.handler.guid||(l.handler.guid=c.guid)),e?m.splice(m.delegateCount++,0,l):m.push(l),n.event.global[o]=!0);a=null}},remove:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n.hasData(a)&&n._data(a);if(r&&(k=r.events)){b=(b||"").match(G)||[""],j=b.length;while(j--)if(h=oa.exec(b[j])||[],o=q=h[1],p=(h[2]||"").split(".").sort(),o){l=n.event.special[o]||{},o=(d?l.delegateType:l.bindType)||o,m=k[o]||[],h=h[2]&&new RegExp("(^|\\.)"+p.join("\\.(?:.*\\.|)")+"(\\.|$)"),i=f=m.length;while(f--)g=m[f],!e&&q!==g.origType||c&&c.guid!==g.guid||h&&!h.test(g.namespace)||d&&d!==g.selector&&("**"!==d||!g.selector)||(m.splice(f,1),g.selector&&m.delegateCount--,l.remove&&l.remove.call(a,g));i&&!m.length&&(l.teardown&&l.teardown.call(a,p,r.handle)!==!1||n.removeEvent(a,o,r.handle),delete k[o])}else for(o in k)n.event.remove(a,o+b[j],c,d,!0);n.isEmptyObject(k)&&(delete r.handle,n._removeData(a,"events"))}},trigger:function(b,c,e,f){var g,h,i,j,l,m,o,p=[e||d],q=k.call(b,"type")?b.type:b,r=k.call(b,"namespace")?b.namespace.split("."):[];if(i=m=e=e||d,3!==e.nodeType&&8!==e.nodeType&&!na.test(q+n.event.triggered)&&(q.indexOf(".")>-1&&(r=q.split("."),q=r.shift(),r.sort()),h=q.indexOf(":")<0&&"on"+q,b=b[n.expando]?b:new n.Event(q,"object"==typeof b&&b),b.isTrigger=f?2:3,b.namespace=r.join("."),b.rnamespace=b.namespace?new RegExp("(^|\\.)"+r.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,b.result=void 0,b.target||(b.target=e),c=null==c?[b]:n.makeArray(c,[b]),l=n.event.special[q]||{},f||!l.trigger||l.trigger.apply(e,c)!==!1)){if(!f&&!l.noBubble&&!n.isWindow(e)){for(j=l.delegateType||q,na.test(j+q)||(i=i.parentNode);i;i=i.parentNode)p.push(i),m=i;m===(e.ownerDocument||d)&&p.push(m.defaultView||m.parentWindow||a)}o=0;while((i=p[o++])&&!b.isPropagationStopped())b.type=o>1?j:l.bindType||q,g=(n._data(i,"events")||{})[b.type]&&n._data(i,"handle"),g&&g.apply(i,c),g=h&&i[h],g&&g.apply&&M(i)&&(b.result=g.apply(i,c),b.result===!1&&b.preventDefault());if(b.type=q,!f&&!b.isDefaultPrevented()&&(!l._default||l._default.apply(p.pop(),c)===!1)&&M(e)&&h&&e[q]&&!n.isWindow(e)){m=e[h],m&&(e[h]=null),n.event.triggered=q;try{e[q]()}catch(s){}n.event.triggered=void 0,m&&(e[h]=m)}return b.result}},dispatch:function(a){a=n.event.fix(a);var b,c,d,f,g,h=[],i=e.call(arguments),j=(n._data(this,"events")||{})[a.type]||[],k=n.event.special[a.type]||{};if(i[0]=a,a.delegateTarget=this,!k.preDispatch||k.preDispatch.call(this,a)!==!1){h=n.event.handlers.call(this,a,j),b=0;while((f=h[b++])&&!a.isPropagationStopped()){a.currentTarget=f.elem,c=0;while((g=f.handlers[c++])&&!a.isImmediatePropagationStopped())a.rnamespace&&!a.rnamespace.test(g.namespace)||(a.handleObj=g,a.data=g.data,d=((n.event.special[g.origType]||{}).handle||g.handler).apply(f.elem,i),void 0!==d&&(a.result=d)===!1&&(a.preventDefault(),a.stopPropagation()))}return k.postDispatch&&k.postDispatch.call(this,a),a.result}},handlers:function(a,b){var c,d,e,f,g=[],h=b.delegateCount,i=a.target;if(h&&i.nodeType&&("click"!==a.type||isNaN(a.button)||a.button<1))for(;i!=this;i=i.parentNode||this)if(1===i.nodeType&&(i.disabled!==!0||"click"!==a.type)){for(d=[],c=0;h>c;c++)f=b[c],e=f.selector+" ",void 0===d[e]&&(d[e]=f.needsContext?n(e,this).index(i)>-1:n.find(e,this,null,[i]).length),d[e]&&d.push(f);d.length&&g.push({elem:i,handlers:d})}return h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[n.expando])return a;var b,c,e,f=a.type,g=a,h=this.fixHooks[f];h||(this.fixHooks[f]=h=ma.test(f)?this.mouseHooks:la.test(f)?this.keyHooks:{}),e=h.props?this.props.concat(h.props):this.props,a=new n.Event(g),b=e.length;while(b--)c=e[b],a[c]=g[c];return a.target||(a.target=g.srcElement||d),3===a.target.nodeType&&(a.target=a.target.parentNode),a.metaKey=!!a.metaKey,h.filter?h.filter(a,g):a},props:"altKey bubbles cancelable ctrlKey currentTarget detail eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){return null==a.which&&(a.which=null!=b.charCode?b.charCode:b.keyCode),a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,b){var c,e,f,g=b.button,h=b.fromElement;return null==a.pageX&&null!=b.clientX&&(e=a.target.ownerDocument||d,f=e.documentElement,c=e.body,a.pageX=b.clientX+(f&&f.scrollLeft||c&&c.scrollLeft||0)-(f&&f.clientLeft||c&&c.clientLeft||0),a.pageY=b.clientY+(f&&f.scrollTop||c&&c.scrollTop||0)-(f&&f.clientTop||c&&c.clientTop||0)),!a.relatedTarget&&h&&(a.relatedTarget=h===a.target?b.toElement:h),a.which||void 0===g||(a.which=1&g?1:2&g?3:4&g?2:0),a}},special:{load:{noBubble:!0},focus:{trigger:function(){if(this!==ra()&&this.focus)try{return this.focus(),!1}catch(a){}},delegateType:"focusin"},blur:{trigger:function(){return this===ra()&&this.blur?(this.blur(),!1):void 0},delegateType:"focusout"},click:{trigger:function(){return n.nodeName(this,"input")&&"checkbox"===this.type&&this.click?(this.click(),!1):void 0},_default:function(a){return n.nodeName(a.target,"a")}},beforeunload:{postDispatch:function(a){void 0!==a.result&&a.originalEvent&&(a.originalEvent.returnValue=a.result)}}},simulate:function(a,b,c){var d=n.extend(new n.Event,c,{type:a,isSimulated:!0});n.event.trigger(d,null,b),d.isDefaultPrevented()&&c.preventDefault()}},n.removeEvent=d.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c)}:function(a,b,c){var d="on"+b;a.detachEvent&&("undefined"==typeof a[d]&&(a[d]=null),a.detachEvent(d,c))},n.Event=function(a,b){return this instanceof n.Event?(a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||void 0===a.defaultPrevented&&a.returnValue===!1?pa:qa):this.type=a,b&&n.extend(this,b),this.timeStamp=a&&a.timeStamp||n.now(),void(this[n.expando]=!0)):new n.Event(a,b)},n.Event.prototype={constructor:n.Event,isDefaultPrevented:qa,isPropagationStopped:qa,isImmediatePropagationStopped:qa,preventDefault:function(){var a=this.originalEvent;this.isDefaultPrevented=pa,a&&(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){var a=this.originalEvent;this.isPropagationStopped=pa,a&&!this.isSimulated&&(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){var a=this.originalEvent;this.isImmediatePropagationStopped=pa,a&&a.stopImmediatePropagation&&a.stopImmediatePropagation(),this.stopPropagation()}},n.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(a,b){n.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c,d=this,e=a.relatedTarget,f=a.handleObj;return e&&(e===d||n.contains(d,e))||(a.type=f.origType,c=f.handler.apply(this,arguments),a.type=b),c}}}),l.submit||(n.event.special.submit={setup:function(){return n.nodeName(this,"form")?!1:void n.event.add(this,"click._submit keypress._submit",function(a){var b=a.target,c=n.nodeName(b,"input")||n.nodeName(b,"button")?n.prop(b,"form"):void 0;c&&!n._data(c,"submit")&&(n.event.add(c,"submit._submit",function(a){a._submitBubble=!0}),n._data(c,"submit",!0))})},postDispatch:function(a){a._submitBubble&&(delete a._submitBubble,this.parentNode&&!a.isTrigger&&n.event.simulate("submit",this.parentNode,a))},teardown:function(){return n.nodeName(this,"form")?!1:void n.event.remove(this,"._submit")}}),l.change||(n.event.special.change={setup:function(){return ka.test(this.nodeName)?("checkbox"!==this.type&&"radio"!==this.type||(n.event.add(this,"propertychange._change",function(a){"checked"===a.originalEvent.propertyName&&(this._justChanged=!0)}),n.event.add(this,"click._change",function(a){this._justChanged&&!a.isTrigger&&(this._justChanged=!1),n.event.simulate("change",this,a)})),!1):void n.event.add(this,"beforeactivate._change",function(a){var b=a.target;ka.test(b.nodeName)&&!n._data(b,"change")&&(n.event.add(b,"change._change",function(a){!this.parentNode||a.isSimulated||a.isTrigger||n.event.simulate("change",this.parentNode,a)}),n._data(b,"change",!0))})},handle:function(a){var b=a.target;return this!==b||a.isSimulated||a.isTrigger||"radio"!==b.type&&"checkbox"!==b.type?a.handleObj.handler.apply(this,arguments):void 0},teardown:function(){return n.event.remove(this,"._change"),!ka.test(this.nodeName)}}),l.focusin||n.each({focus:"focusin",blur:"focusout"},function(a,b){var c=function(a){n.event.simulate(b,a.target,n.event.fix(a))};n.event.special[b]={setup:function(){var d=this.ownerDocument||this,e=n._data(d,b);e||d.addEventListener(a,c,!0),n._data(d,b,(e||0)+1)},teardown:function(){var d=this.ownerDocument||this,e=n._data(d,b)-1;e?n._data(d,b,e):(d.removeEventListener(a,c,!0),n._removeData(d,b))}}}),n.fn.extend({on:function(a,b,c,d){return sa(this,a,b,c,d)},one:function(a,b,c,d){return sa(this,a,b,c,d,1)},off:function(a,b,c){var d,e;if(a&&a.preventDefault&&a.handleObj)return d=a.handleObj,n(a.delegateTarget).off(d.namespace?d.origType+"."+d.namespace:d.origType,d.selector,d.handler),this;if("object"==typeof a){for(e in a)this.off(e,b,a[e]);return this}return b!==!1&&"function"!=typeof b||(c=b,b=void 0),c===!1&&(c=qa),this.each(function(){n.event.remove(this,a,c,b)})},trigger:function(a,b){return this.each(function(){n.event.trigger(a,b,this)})},triggerHandler:function(a,b){var c=this[0];return c?n.event.trigger(a,b,c,!0):void 0}});var ta=/ jQuery\d+="(?:null|\d+)"/g,ua=new RegExp("<(?:"+ba+")[\\s/>]","i"),va=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:-]+)[^>]*)\/>/gi,wa=/<script|<style|<link/i,xa=/checked\s*(?:[^=]|=\s*.checked.)/i,ya=/^true\/(.*)/,za=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,Aa=ca(d),Ba=Aa.appendChild(d.createElement("div"));function Ca(a,b){return n.nodeName(a,"table")&&n.nodeName(11!==b.nodeType?b:b.firstChild,"tr")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function Da(a){return a.type=(null!==n.find.attr(a,"type"))+"/"+a.type,a}function Ea(a){var b=ya.exec(a.type);return b?a.type=b[1]:a.removeAttribute("type"),a}function Fa(a,b){if(1===b.nodeType&&n.hasData(a)){var c,d,e,f=n._data(a),g=n._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in h)for(d=0,e=h[c].length;e>d;d++)n.event.add(b,c,h[c][d])}g.data&&(g.data=n.extend({},g.data))}}function Ga(a,b){var c,d,e;if(1===b.nodeType){if(c=b.nodeName.toLowerCase(),!l.noCloneEvent&&b[n.expando]){e=n._data(b);for(d in e.events)n.removeEvent(b,d,e.handle);b.removeAttribute(n.expando)}"script"===c&&b.text!==a.text?(Da(b).text=a.text,Ea(b)):"object"===c?(b.parentNode&&(b.outerHTML=a.outerHTML),l.html5Clone&&a.innerHTML&&!n.trim(b.innerHTML)&&(b.innerHTML=a.innerHTML)):"input"===c&&Z.test(a.type)?(b.defaultChecked=b.checked=a.checked,b.value!==a.value&&(b.value=a.value)):"option"===c?b.defaultSelected=b.selected=a.defaultSelected:"input"!==c&&"textarea"!==c||(b.defaultValue=a.defaultValue)}}function Ha(a,b,c,d){b=f.apply([],b);var e,g,h,i,j,k,m=0,o=a.length,p=o-1,q=b[0],r=n.isFunction(q);if(r||o>1&&"string"==typeof q&&!l.checkClone&&xa.test(q))return a.each(function(e){var f=a.eq(e);r&&(b[0]=q.call(this,e,f.html())),Ha(f,b,c,d)});if(o&&(k=ja(b,a[0].ownerDocument,!1,a,d),e=k.firstChild,1===k.childNodes.length&&(k=e),e||d)){for(i=n.map(ea(k,"script"),Da),h=i.length;o>m;m++)g=k,m!==p&&(g=n.clone(g,!0,!0),h&&n.merge(i,ea(g,"script"))),c.call(a[m],g,m);if(h)for(j=i[i.length-1].ownerDocument,n.map(i,Ea),m=0;h>m;m++)g=i[m],_.test(g.type||"")&&!n._data(g,"globalEval")&&n.contains(j,g)&&(g.src?n._evalUrl&&n._evalUrl(g.src):n.globalEval((g.text||g.textContent||g.innerHTML||"").replace(za,"")));k=e=null}return a}function Ia(a,b,c){for(var d,e=b?n.filter(b,a):a,f=0;null!=(d=e[f]);f++)c||1!==d.nodeType||n.cleanData(ea(d)),d.parentNode&&(c&&n.contains(d.ownerDocument,d)&&fa(ea(d,"script")),d.parentNode.removeChild(d));return a}n.extend({htmlPrefilter:function(a){return a.replace(va,"<$1></$2>")},clone:function(a,b,c){var d,e,f,g,h,i=n.contains(a.ownerDocument,a);if(l.html5Clone||n.isXMLDoc(a)||!ua.test("<"+a.nodeName+">")?f=a.cloneNode(!0):(Ba.innerHTML=a.outerHTML,Ba.removeChild(f=Ba.firstChild)),!(l.noCloneEvent&&l.noCloneChecked||1!==a.nodeType&&11!==a.nodeType||n.isXMLDoc(a)))for(d=ea(f),h=ea(a),g=0;null!=(e=h[g]);++g)d[g]&&Ga(e,d[g]);if(b)if(c)for(h=h||ea(a),d=d||ea(f),g=0;null!=(e=h[g]);g++)Fa(e,d[g]);else Fa(a,f);return d=ea(f,"script"),d.length>0&&fa(d,!i&&ea(a,"script")),d=h=e=null,f},cleanData:function(a,b){for(var d,e,f,g,h=0,i=n.expando,j=n.cache,k=l.attributes,m=n.event.special;null!=(d=a[h]);h++)if((b||M(d))&&(f=d[i],g=f&&j[f])){if(g.events)for(e in g.events)m[e]?n.event.remove(d,e):n.removeEvent(d,e,g.handle);j[f]&&(delete j[f],k||"undefined"==typeof d.removeAttribute?d[i]=void 0:d.removeAttribute(i),c.push(f))}}}),n.fn.extend({domManip:Ha,detach:function(a){return Ia(this,a,!0)},remove:function(a){return Ia(this,a)},text:function(a){return Y(this,function(a){return void 0===a?n.text(this):this.empty().append((this[0]&&this[0].ownerDocument||d).createTextNode(a))},null,a,arguments.length)},append:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.appendChild(a)}})},prepend:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.insertBefore(a,b.firstChild)}})},before:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this)})},after:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this.nextSibling)})},empty:function(){for(var a,b=0;null!=(a=this[b]);b++){1===a.nodeType&&n.cleanData(ea(a,!1));while(a.firstChild)a.removeChild(a.firstChild);a.options&&n.nodeName(a,"select")&&(a.options.length=0)}return this},clone:function(a,b){return a=null==a?!1:a,b=null==b?a:b,this.map(function(){return n.clone(this,a,b)})},html:function(a){return Y(this,function(a){var b=this[0]||{},c=0,d=this.length;if(void 0===a)return 1===b.nodeType?b.innerHTML.replace(ta,""):void 0;if("string"==typeof a&&!wa.test(a)&&(l.htmlSerialize||!ua.test(a))&&(l.leadingWhitespace||!aa.test(a))&&!da[($.exec(a)||["",""])[1].toLowerCase()]){a=n.htmlPrefilter(a);try{for(;d>c;c++)b=this[c]||{},1===b.nodeType&&(n.cleanData(ea(b,!1)),b.innerHTML=a);b=0}catch(e){}}b&&this.empty().append(a)},null,a,arguments.length)},replaceWith:function(){var a=[];return Ha(this,arguments,function(b){var c=this.parentNode;n.inArray(this,a)<0&&(n.cleanData(ea(this)),c&&c.replaceChild(b,this))},a)}}),n.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){n.fn[a]=function(a){for(var c,d=0,e=[],f=n(a),h=f.length-1;h>=d;d++)c=d===h?this:this.clone(!0),n(f[d])[b](c),g.apply(e,c.get());return this.pushStack(e)}});var Ja,Ka={HTML:"block",BODY:"block"};function La(a,b){var c=n(b.createElement(a)).appendTo(b.body),d=n.css(c[0],"display");return c.detach(),d}function Ma(a){var b=d,c=Ka[a];return c||(c=La(a,b),"none"!==c&&c||(Ja=(Ja||n("<iframe frameborder='0' width='0' height='0'/>")).appendTo(b.documentElement),b=(Ja[0].contentWindow||Ja[0].contentDocument).document,b.write(),b.close(),c=La(a,b),Ja.detach()),Ka[a]=c),c}var Na=/^margin/,Oa=new RegExp("^("+T+")(?!px)[a-z%]+$","i"),Pa=function(a,b,c,d){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e},Qa=d.documentElement;!function(){var b,c,e,f,g,h,i=d.createElement("div"),j=d.createElement("div");if(j.style){j.style.cssText="float:left;opacity:.5",l.opacity="0.5"===j.style.opacity,l.cssFloat=!!j.style.cssFloat,j.style.backgroundClip="content-box",j.cloneNode(!0).style.backgroundClip="",l.clearCloneStyle="content-box"===j.style.backgroundClip,i=d.createElement("div"),i.style.cssText="border:0;width:8px;height:0;top:0;left:-9999px;padding:0;margin-top:1px;position:absolute",j.innerHTML="",i.appendChild(j),l.boxSizing=""===j.style.boxSizing||""===j.style.MozBoxSizing||""===j.style.WebkitBoxSizing,n.extend(l,{reliableHiddenOffsets:function(){return null==b&&k(),f},boxSizingReliable:function(){return null==b&&k(),e},pixelMarginRight:function(){return null==b&&k(),c},pixelPosition:function(){return null==b&&k(),b},reliableMarginRight:function(){return null==b&&k(),g},reliableMarginLeft:function(){return null==b&&k(),h}});function k(){var k,l,m=d.documentElement;m.appendChild(i),j.style.cssText="-webkit-box-sizing:border-box;box-sizing:border-box;position:relative;display:block;margin:auto;border:1px;padding:1px;top:1%;width:50%",b=e=h=!1,c=g=!0,a.getComputedStyle&&(l=a.getComputedStyle(j),b="1%"!==(l||{}).top,h="2px"===(l||{}).marginLeft,e="4px"===(l||{width:"4px"}).width,j.style.marginRight="50%",c="4px"===(l||{marginRight:"4px"}).marginRight,k=j.appendChild(d.createElement("div")),k.style.cssText=j.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:0",k.style.marginRight=k.style.width="0",j.style.width="1px",g=!parseFloat((a.getComputedStyle(k)||{}).marginRight),j.removeChild(k)),j.style.display="none",f=0===j.getClientRects().length,f&&(j.style.display="",j.innerHTML="<table><tr><td></td><td>t</td></tr></table>",k=j.getElementsByTagName("td"),k[0].style.cssText="margin:0;border:0;padding:0;display:none",f=0===k[0].offsetHeight,f&&(k[0].style.display="",k[1].style.display="none",f=0===k[0].offsetHeight)),m.removeChild(i)}}}();var Ra,Sa,Ta=/^(top|right|bottom|left)$/;a.getComputedStyle?(Ra=function(b){var c=b.ownerDocument.defaultView;return c&&c.opener||(c=a),c.getComputedStyle(b)},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c.getPropertyValue(b)||c[b]:void 0,""!==g&&void 0!==g||n.contains(a.ownerDocument,a)||(g=n.style(a,b)),c&&!l.pixelMarginRight()&&Oa.test(g)&&Na.test(b)&&(d=h.width,e=h.minWidth,f=h.maxWidth,h.minWidth=h.maxWidth=h.width=g,g=c.width,h.width=d,h.minWidth=e,h.maxWidth=f),void 0===g?g:g+""}):Qa.currentStyle&&(Ra=function(a){return a.currentStyle},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c[b]:void 0,null==g&&h&&h[b]&&(g=h[b]),Oa.test(g)&&!Ta.test(b)&&(d=h.left,e=a.runtimeStyle,f=e&&e.left,f&&(e.left=a.currentStyle.left),h.left="fontSize"===b?"1em":g,g=h.pixelLeft+"px",h.left=d,f&&(e.left=f)),void 0===g?g:g+""||"auto"});function Ua(a,b){return{get:function(){return a()?void delete this.get:(this.get=b).apply(this,arguments)}}}var Va=/alpha\([^)]*\)/i,Wa=/opacity\s*=\s*([^)]*)/i,Xa=/^(none|table(?!-c[ea]).+)/,Ya=new RegExp("^("+T+")(.*)$","i"),Za={position:"absolute",visibility:"hidden",display:"block"},$a={letterSpacing:"0",fontWeight:"400"},_a=["Webkit","O","Moz","ms"],ab=d.createElement("div").style;function bb(a){if(a in ab)return a;var b=a.charAt(0).toUpperCase()+a.slice(1),c=_a.length;while(c--)if(a=_a[c]+b,a in ab)return a}function cb(a,b){for(var c,d,e,f=[],g=0,h=a.length;h>g;g++)d=a[g],d.style&&(f[g]=n._data(d,"olddisplay"),c=d.style.display,b?(f[g]||"none"!==c||(d.style.display=""),""===d.style.display&&W(d)&&(f[g]=n._data(d,"olddisplay",Ma(d.nodeName)))):(e=W(d),(c&&"none"!==c||!e)&&n._data(d,"olddisplay",e?c:n.css(d,"display"))));for(g=0;h>g;g++)d=a[g],d.style&&(b&&"none"!==d.style.display&&""!==d.style.display||(d.style.display=b?f[g]||"":"none"));return a}function db(a,b,c){var d=Ya.exec(b);return d?Math.max(0,d[1]-(c||0))+(d[2]||"px"):b}function eb(a,b,c,d,e){for(var f=c===(d?"border":"content")?4:"width"===b?1:0,g=0;4>f;f+=2)"margin"===c&&(g+=n.css(a,c+V[f],!0,e)),d?("content"===c&&(g-=n.css(a,"padding"+V[f],!0,e)),"margin"!==c&&(g-=n.css(a,"border"+V[f]+"Width",!0,e))):(g+=n.css(a,"padding"+V[f],!0,e),"padding"!==c&&(g+=n.css(a,"border"+V[f]+"Width",!0,e)));return g}function fb(b,c,e){var f=!0,g="width"===c?b.offsetWidth:b.offsetHeight,h=Ra(b),i=l.boxSizing&&"border-box"===n.css(b,"boxSizing",!1,h);if(d.msFullscreenElement&&a.top!==a&&b.getClientRects().length&&(g=Math.round(100*b.getBoundingClientRect()[c])),0>=g||null==g){if(g=Sa(b,c,h),(0>g||null==g)&&(g=b.style[c]),Oa.test(g))return g;f=i&&(l.boxSizingReliable()||g===b.style[c]),g=parseFloat(g)||0}return g+eb(b,c,e||(i?"border":"content"),f,h)+"px"}n.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=Sa(a,"opacity");return""===c?"1":c}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":l.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,c,d){if(a&&3!==a.nodeType&&8!==a.nodeType&&a.style){var e,f,g,h=n.camelCase(b),i=a.style;if(b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],void 0===c)return g&&"get"in g&&void 0!==(e=g.get(a,!1,d))?e:i[b];if(f=typeof c,"string"===f&&(e=U.exec(c))&&e[1]&&(c=X(a,b,e),f="number"),null!=c&&c===c&&("number"===f&&(c+=e&&e[3]||(n.cssNumber[h]?"":"px")),l.clearCloneStyle||""!==c||0!==b.indexOf("background")||(i[b]="inherit"),!(g&&"set"in g&&void 0===(c=g.set(a,c,d)))))try{i[b]=c}catch(j){}}},css:function(a,b,c,d){var e,f,g,h=n.camelCase(b);return b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],g&&"get"in g&&(f=g.get(a,!0,c)),void 0===f&&(f=Sa(a,b,d)),"normal"===f&&b in $a&&(f=$a[b]),""===c||c?(e=parseFloat(f),c===!0||isFinite(e)?e||0:f):f}}),n.each(["height","width"],function(a,b){n.cssHooks[b]={get:function(a,c,d){return c?Xa.test(n.css(a,"display"))&&0===a.offsetWidth?Pa(a,Za,function(){return fb(a,b,d)}):fb(a,b,d):void 0},set:function(a,c,d){var e=d&&Ra(a);return db(a,c,d?eb(a,b,d,l.boxSizing&&"border-box"===n.css(a,"boxSizing",!1,e),e):0)}}}),l.opacity||(n.cssHooks.opacity={get:function(a,b){return Wa.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?.01*parseFloat(RegExp.$1)+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=n.isNumeric(b)?"alpha(opacity="+100*b+")":"",f=d&&d.filter||c.filter||"";c.zoom=1,(b>=1||""===b)&&""===n.trim(f.replace(Va,""))&&c.removeAttribute&&(c.removeAttribute("filter"),""===b||d&&!d.filter)||(c.filter=Va.test(f)?f.replace(Va,e):f+" "+e)}}),n.cssHooks.marginRight=Ua(l.reliableMarginRight,function(a,b){return b?Pa(a,{display:"inline-block"},Sa,[a,"marginRight"]):void 0}),n.cssHooks.marginLeft=Ua(l.reliableMarginLeft,function(a,b){
return b?(parseFloat(Sa(a,"marginLeft"))||(n.contains(a.ownerDocument,a)?a.getBoundingClientRect().left-Pa(a,{marginLeft:0},function(){return a.getBoundingClientRect().left}):0))+"px":void 0}),n.each({margin:"",padding:"",border:"Width"},function(a,b){n.cssHooks[a+b]={expand:function(c){for(var d=0,e={},f="string"==typeof c?c.split(" "):[c];4>d;d++)e[a+V[d]+b]=f[d]||f[d-2]||f[0];return e}},Na.test(a)||(n.cssHooks[a+b].set=db)}),n.fn.extend({css:function(a,b){return Y(this,function(a,b,c){var d,e,f={},g=0;if(n.isArray(b)){for(d=Ra(a),e=b.length;e>g;g++)f[b[g]]=n.css(a,b[g],!1,d);return f}return void 0!==c?n.style(a,b,c):n.css(a,b)},a,b,arguments.length>1)},show:function(){return cb(this,!0)},hide:function(){return cb(this)},toggle:function(a){return"boolean"==typeof a?a?this.show():this.hide():this.each(function(){W(this)?n(this).show():n(this).hide()})}});function gb(a,b,c,d,e){return new gb.prototype.init(a,b,c,d,e)}n.Tween=gb,gb.prototype={constructor:gb,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||n.easing._default,this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(n.cssNumber[c]?"":"px")},cur:function(){var a=gb.propHooks[this.prop];return a&&a.get?a.get(this):gb.propHooks._default.get(this)},run:function(a){var b,c=gb.propHooks[this.prop];return this.options.duration?this.pos=b=n.easing[this.easing](a,this.options.duration*a,0,1,this.options.duration):this.pos=b=a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):gb.propHooks._default.set(this),this}},gb.prototype.init.prototype=gb.prototype,gb.propHooks={_default:{get:function(a){var b;return 1!==a.elem.nodeType||null!=a.elem[a.prop]&&null==a.elem.style[a.prop]?a.elem[a.prop]:(b=n.css(a.elem,a.prop,""),b&&"auto"!==b?b:0)},set:function(a){n.fx.step[a.prop]?n.fx.step[a.prop](a):1!==a.elem.nodeType||null==a.elem.style[n.cssProps[a.prop]]&&!n.cssHooks[a.prop]?a.elem[a.prop]=a.now:n.style(a.elem,a.prop,a.now+a.unit)}}},gb.propHooks.scrollTop=gb.propHooks.scrollLeft={set:function(a){a.elem.nodeType&&a.elem.parentNode&&(a.elem[a.prop]=a.now)}},n.easing={linear:function(a){return a},swing:function(a){return.5-Math.cos(a*Math.PI)/2},_default:"swing"},n.fx=gb.prototype.init,n.fx.step={};var hb,ib,jb=/^(?:toggle|show|hide)$/,kb=/queueHooks$/;function lb(){return a.setTimeout(function(){hb=void 0}),hb=n.now()}function mb(a,b){var c,d={height:a},e=0;for(b=b?1:0;4>e;e+=2-b)c=V[e],d["margin"+c]=d["padding"+c]=a;return b&&(d.opacity=d.width=a),d}function nb(a,b,c){for(var d,e=(qb.tweeners[b]||[]).concat(qb.tweeners["*"]),f=0,g=e.length;g>f;f++)if(d=e[f].call(c,b,a))return d}function ob(a,b,c){var d,e,f,g,h,i,j,k,m=this,o={},p=a.style,q=a.nodeType&&W(a),r=n._data(a,"fxshow");c.queue||(h=n._queueHooks(a,"fx"),null==h.unqueued&&(h.unqueued=0,i=h.empty.fire,h.empty.fire=function(){h.unqueued||i()}),h.unqueued++,m.always(function(){m.always(function(){h.unqueued--,n.queue(a,"fx").length||h.empty.fire()})})),1===a.nodeType&&("height"in b||"width"in b)&&(c.overflow=[p.overflow,p.overflowX,p.overflowY],j=n.css(a,"display"),k="none"===j?n._data(a,"olddisplay")||Ma(a.nodeName):j,"inline"===k&&"none"===n.css(a,"float")&&(l.inlineBlockNeedsLayout&&"inline"!==Ma(a.nodeName)?p.zoom=1:p.display="inline-block")),c.overflow&&(p.overflow="hidden",l.shrinkWrapBlocks()||m.always(function(){p.overflow=c.overflow[0],p.overflowX=c.overflow[1],p.overflowY=c.overflow[2]}));for(d in b)if(e=b[d],jb.exec(e)){if(delete b[d],f=f||"toggle"===e,e===(q?"hide":"show")){if("show"!==e||!r||void 0===r[d])continue;q=!0}o[d]=r&&r[d]||n.style(a,d)}else j=void 0;if(n.isEmptyObject(o))"inline"===("none"===j?Ma(a.nodeName):j)&&(p.display=j);else{r?"hidden"in r&&(q=r.hidden):r=n._data(a,"fxshow",{}),f&&(r.hidden=!q),q?n(a).show():m.done(function(){n(a).hide()}),m.done(function(){var b;n._removeData(a,"fxshow");for(b in o)n.style(a,b,o[b])});for(d in o)g=nb(q?r[d]:0,d,m),d in r||(r[d]=g.start,q&&(g.end=g.start,g.start="width"===d||"height"===d?1:0))}}function pb(a,b){var c,d,e,f,g;for(c in a)if(d=n.camelCase(c),e=b[d],f=a[c],n.isArray(f)&&(e=f[1],f=a[c]=f[0]),c!==d&&(a[d]=f,delete a[c]),g=n.cssHooks[d],g&&"expand"in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function qb(a,b,c){var d,e,f=0,g=qb.prefilters.length,h=n.Deferred().always(function(){delete i.elem}),i=function(){if(e)return!1;for(var b=hb||lb(),c=Math.max(0,j.startTime+j.duration-b),d=c/j.duration||0,f=1-d,g=0,i=j.tweens.length;i>g;g++)j.tweens[g].run(f);return h.notifyWith(a,[j,f,c]),1>f&&i?c:(h.resolveWith(a,[j]),!1)},j=h.promise({elem:a,props:n.extend({},b),opts:n.extend(!0,{specialEasing:{},easing:n.easing._default},c),originalProperties:b,originalOptions:c,startTime:hb||lb(),duration:c.duration,tweens:[],createTween:function(b,c){var d=n.Tween(a,j.opts,b,c,j.opts.specialEasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var c=0,d=b?j.tweens.length:0;if(e)return this;for(e=!0;d>c;c++)j.tweens[c].run(1);return b?(h.notifyWith(a,[j,1,0]),h.resolveWith(a,[j,b])):h.rejectWith(a,[j,b]),this}}),k=j.props;for(pb(k,j.opts.specialEasing);g>f;f++)if(d=qb.prefilters[f].call(j,a,k,j.opts))return n.isFunction(d.stop)&&(n._queueHooks(j.elem,j.opts.queue).stop=n.proxy(d.stop,d)),d;return n.map(k,nb,j),n.isFunction(j.opts.start)&&j.opts.start.call(a,j),n.fx.timer(n.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}n.Animation=n.extend(qb,{tweeners:{"*":[function(a,b){var c=this.createTween(a,b);return X(c.elem,a,U.exec(b),c),c}]},tweener:function(a,b){n.isFunction(a)?(b=a,a=["*"]):a=a.match(G);for(var c,d=0,e=a.length;e>d;d++)c=a[d],qb.tweeners[c]=qb.tweeners[c]||[],qb.tweeners[c].unshift(b)},prefilters:[ob],prefilter:function(a,b){b?qb.prefilters.unshift(a):qb.prefilters.push(a)}}),n.speed=function(a,b,c){var d=a&&"object"==typeof a?n.extend({},a):{complete:c||!c&&b||n.isFunction(a)&&a,duration:a,easing:c&&b||b&&!n.isFunction(b)&&b};return d.duration=n.fx.off?0:"number"==typeof d.duration?d.duration:d.duration in n.fx.speeds?n.fx.speeds[d.duration]:n.fx.speeds._default,null!=d.queue&&d.queue!==!0||(d.queue="fx"),d.old=d.complete,d.complete=function(){n.isFunction(d.old)&&d.old.call(this),d.queue&&n.dequeue(this,d.queue)},d},n.fn.extend({fadeTo:function(a,b,c,d){return this.filter(W).css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=n.isEmptyObject(a),f=n.speed(b,c,d),g=function(){var b=qb(this,n.extend({},a),f);(e||n._data(this,"finish"))&&b.stop(!0)};return g.finish=g,e||f.queue===!1?this.each(g):this.queue(f.queue,g)},stop:function(a,b,c){var d=function(a){var b=a.stop;delete a.stop,b(c)};return"string"!=typeof a&&(c=b,b=a,a=void 0),b&&a!==!1&&this.queue(a||"fx",[]),this.each(function(){var b=!0,e=null!=a&&a+"queueHooks",f=n.timers,g=n._data(this);if(e)g[e]&&g[e].stop&&d(g[e]);else for(e in g)g[e]&&g[e].stop&&kb.test(e)&&d(g[e]);for(e=f.length;e--;)f[e].elem!==this||null!=a&&f[e].queue!==a||(f[e].anim.stop(c),b=!1,f.splice(e,1));!b&&c||n.dequeue(this,a)})},finish:function(a){return a!==!1&&(a=a||"fx"),this.each(function(){var b,c=n._data(this),d=c[a+"queue"],e=c[a+"queueHooks"],f=n.timers,g=d?d.length:0;for(c.finish=!0,n.queue(this,a,[]),e&&e.stop&&e.stop.call(this,!0),b=f.length;b--;)f[b].elem===this&&f[b].queue===a&&(f[b].anim.stop(!0),f.splice(b,1));for(b=0;g>b;b++)d[b]&&d[b].finish&&d[b].finish.call(this);delete c.finish})}}),n.each(["toggle","show","hide"],function(a,b){var c=n.fn[b];n.fn[b]=function(a,d,e){return null==a||"boolean"==typeof a?c.apply(this,arguments):this.animate(mb(b,!0),a,d,e)}}),n.each({slideDown:mb("show"),slideUp:mb("hide"),slideToggle:mb("toggle"),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){n.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),n.timers=[],n.fx.tick=function(){var a,b=n.timers,c=0;for(hb=n.now();c<b.length;c++)a=b[c],a()||b[c]!==a||b.splice(c--,1);b.length||n.fx.stop(),hb=void 0},n.fx.timer=function(a){n.timers.push(a),a()?n.fx.start():n.timers.pop()},n.fx.interval=13,n.fx.start=function(){ib||(ib=a.setInterval(n.fx.tick,n.fx.interval))},n.fx.stop=function(){a.clearInterval(ib),ib=null},n.fx.speeds={slow:600,fast:200,_default:400},n.fn.delay=function(b,c){return b=n.fx?n.fx.speeds[b]||b:b,c=c||"fx",this.queue(c,function(c,d){var e=a.setTimeout(c,b);d.stop=function(){a.clearTimeout(e)}})},function(){var a,b=d.createElement("input"),c=d.createElement("div"),e=d.createElement("select"),f=e.appendChild(d.createElement("option"));c=d.createElement("div"),c.setAttribute("className","t"),c.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",a=c.getElementsByTagName("a")[0],b.setAttribute("type","checkbox"),c.appendChild(b),a=c.getElementsByTagName("a")[0],a.style.cssText="top:1px",l.getSetAttribute="t"!==c.className,l.style=/top/.test(a.getAttribute("style")),l.hrefNormalized="/a"===a.getAttribute("href"),l.checkOn=!!b.value,l.optSelected=f.selected,l.enctype=!!d.createElement("form").enctype,e.disabled=!0,l.optDisabled=!f.disabled,b=d.createElement("input"),b.setAttribute("value",""),l.input=""===b.getAttribute("value"),b.value="t",b.setAttribute("type","radio"),l.radioValue="t"===b.value}();var rb=/\r/g,sb=/[\x20\t\r\n\f]+/g;n.fn.extend({val:function(a){var b,c,d,e=this[0];{if(arguments.length)return d=n.isFunction(a),this.each(function(c){var e;1===this.nodeType&&(e=d?a.call(this,c,n(this).val()):a,null==e?e="":"number"==typeof e?e+="":n.isArray(e)&&(e=n.map(e,function(a){return null==a?"":a+""})),b=n.valHooks[this.type]||n.valHooks[this.nodeName.toLowerCase()],b&&"set"in b&&void 0!==b.set(this,e,"value")||(this.value=e))});if(e)return b=n.valHooks[e.type]||n.valHooks[e.nodeName.toLowerCase()],b&&"get"in b&&void 0!==(c=b.get(e,"value"))?c:(c=e.value,"string"==typeof c?c.replace(rb,""):null==c?"":c)}}}),n.extend({valHooks:{option:{get:function(a){var b=n.find.attr(a,"value");return null!=b?b:n.trim(n.text(a)).replace(sb," ")}},select:{get:function(a){for(var b,c,d=a.options,e=a.selectedIndex,f="select-one"===a.type||0>e,g=f?null:[],h=f?e+1:d.length,i=0>e?h:f?e:0;h>i;i++)if(c=d[i],(c.selected||i===e)&&(l.optDisabled?!c.disabled:null===c.getAttribute("disabled"))&&(!c.parentNode.disabled||!n.nodeName(c.parentNode,"optgroup"))){if(b=n(c).val(),f)return b;g.push(b)}return g},set:function(a,b){var c,d,e=a.options,f=n.makeArray(b),g=e.length;while(g--)if(d=e[g],n.inArray(n.valHooks.option.get(d),f)>-1)try{d.selected=c=!0}catch(h){d.scrollHeight}else d.selected=!1;return c||(a.selectedIndex=-1),e}}}}),n.each(["radio","checkbox"],function(){n.valHooks[this]={set:function(a,b){return n.isArray(b)?a.checked=n.inArray(n(a).val(),b)>-1:void 0}},l.checkOn||(n.valHooks[this].get=function(a){return null===a.getAttribute("value")?"on":a.value})});var tb,ub,vb=n.expr.attrHandle,wb=/^(?:checked|selected)$/i,xb=l.getSetAttribute,yb=l.input;n.fn.extend({attr:function(a,b){return Y(this,n.attr,a,b,arguments.length>1)},removeAttr:function(a){return this.each(function(){n.removeAttr(this,a)})}}),n.extend({attr:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return"undefined"==typeof a.getAttribute?n.prop(a,b,c):(1===f&&n.isXMLDoc(a)||(b=b.toLowerCase(),e=n.attrHooks[b]||(n.expr.match.bool.test(b)?ub:tb)),void 0!==c?null===c?void n.removeAttr(a,b):e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:(a.setAttribute(b,c+""),c):e&&"get"in e&&null!==(d=e.get(a,b))?d:(d=n.find.attr(a,b),null==d?void 0:d))},attrHooks:{type:{set:function(a,b){if(!l.radioValue&&"radio"===b&&n.nodeName(a,"input")){var c=a.value;return a.setAttribute("type",b),c&&(a.value=c),b}}}},removeAttr:function(a,b){var c,d,e=0,f=b&&b.match(G);if(f&&1===a.nodeType)while(c=f[e++])d=n.propFix[c]||c,n.expr.match.bool.test(c)?yb&&xb||!wb.test(c)?a[d]=!1:a[n.camelCase("default-"+c)]=a[d]=!1:n.attr(a,c,""),a.removeAttribute(xb?c:d)}}),ub={set:function(a,b,c){return b===!1?n.removeAttr(a,c):yb&&xb||!wb.test(c)?a.setAttribute(!xb&&n.propFix[c]||c,c):a[n.camelCase("default-"+c)]=a[c]=!0,c}},n.each(n.expr.match.bool.source.match(/\w+/g),function(a,b){var c=vb[b]||n.find.attr;yb&&xb||!wb.test(b)?vb[b]=function(a,b,d){var e,f;return d||(f=vb[b],vb[b]=e,e=null!=c(a,b,d)?b.toLowerCase():null,vb[b]=f),e}:vb[b]=function(a,b,c){return c?void 0:a[n.camelCase("default-"+b)]?b.toLowerCase():null}}),yb&&xb||(n.attrHooks.value={set:function(a,b,c){return n.nodeName(a,"input")?void(a.defaultValue=b):tb&&tb.set(a,b,c)}}),xb||(tb={set:function(a,b,c){var d=a.getAttributeNode(c);return d||a.setAttributeNode(d=a.ownerDocument.createAttribute(c)),d.value=b+="","value"===c||b===a.getAttribute(c)?b:void 0}},vb.id=vb.name=vb.coords=function(a,b,c){var d;return c?void 0:(d=a.getAttributeNode(b))&&""!==d.value?d.value:null},n.valHooks.button={get:function(a,b){var c=a.getAttributeNode(b);return c&&c.specified?c.value:void 0},set:tb.set},n.attrHooks.contenteditable={set:function(a,b,c){tb.set(a,""===b?!1:b,c)}},n.each(["width","height"],function(a,b){n.attrHooks[b]={set:function(a,c){return""===c?(a.setAttribute(b,"auto"),c):void 0}}})),l.style||(n.attrHooks.style={get:function(a){return a.style.cssText||void 0},set:function(a,b){return a.style.cssText=b+""}});var zb=/^(?:input|select|textarea|button|object)$/i,Ab=/^(?:a|area)$/i;n.fn.extend({prop:function(a,b){return Y(this,n.prop,a,b,arguments.length>1)},removeProp:function(a){return a=n.propFix[a]||a,this.each(function(){try{this[a]=void 0,delete this[a]}catch(b){}})}}),n.extend({prop:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return 1===f&&n.isXMLDoc(a)||(b=n.propFix[b]||b,e=n.propHooks[b]),void 0!==c?e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:a[b]=c:e&&"get"in e&&null!==(d=e.get(a,b))?d:a[b]},propHooks:{tabIndex:{get:function(a){var b=n.find.attr(a,"tabindex");return b?parseInt(b,10):zb.test(a.nodeName)||Ab.test(a.nodeName)&&a.href?0:-1}}},propFix:{"for":"htmlFor","class":"className"}}),l.hrefNormalized||n.each(["href","src"],function(a,b){n.propHooks[b]={get:function(a){return a.getAttribute(b,4)}}}),l.optSelected||(n.propHooks.selected={get:function(a){var b=a.parentNode;return b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex),null},set:function(a){var b=a.parentNode;b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex)}}),n.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){n.propFix[this.toLowerCase()]=this}),l.enctype||(n.propFix.enctype="encoding");var Bb=/[\t\r\n\f]/g;function Cb(a){return n.attr(a,"class")||""}n.fn.extend({addClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).addClass(a.call(this,b,Cb(this)))});if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])d.indexOf(" "+f+" ")<0&&(d+=f+" ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},removeClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).removeClass(a.call(this,b,Cb(this)))});if(!arguments.length)return this.attr("class","");if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])while(d.indexOf(" "+f+" ")>-1)d=d.replace(" "+f+" "," ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},toggleClass:function(a,b){var c=typeof a;return"boolean"==typeof b&&"string"===c?b?this.addClass(a):this.removeClass(a):n.isFunction(a)?this.each(function(c){n(this).toggleClass(a.call(this,c,Cb(this),b),b)}):this.each(function(){var b,d,e,f;if("string"===c){d=0,e=n(this),f=a.match(G)||[];while(b=f[d++])e.hasClass(b)?e.removeClass(b):e.addClass(b)}else void 0!==a&&"boolean"!==c||(b=Cb(this),b&&n._data(this,"__className__",b),n.attr(this,"class",b||a===!1?"":n._data(this,"__className__")||""))})},hasClass:function(a){var b,c,d=0;b=" "+a+" ";while(c=this[d++])if(1===c.nodeType&&(" "+Cb(c)+" ").replace(Bb," ").indexOf(b)>-1)return!0;return!1}}),n.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){n.fn[b]=function(a,c){return arguments.length>0?this.on(b,null,a,c):this.trigger(b)}}),n.fn.extend({hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var Db=a.location,Eb=n.now(),Fb=/\?/,Gb=/(,)|(\[|{)|(}|])|"(?:[^"\\\r\n]|\\["\\\/bfnrt]|\\u[\da-fA-F]{4})*"\s*:?|true|false|null|-?(?!0\d)\d+(?:\.\d+|)(?:[eE][+-]?\d+|)/g;n.parseJSON=function(b){if(a.JSON&&a.JSON.parse)return a.JSON.parse(b+"");var c,d=null,e=n.trim(b+"");return e&&!n.trim(e.replace(Gb,function(a,b,e,f){return c&&b&&(d=0),0===d?a:(c=e||b,d+=!f-!e,"")}))?Function("return "+e)():n.error("Invalid JSON: "+b)},n.parseXML=function(b){var c,d;if(!b||"string"!=typeof b)return null;try{a.DOMParser?(d=new a.DOMParser,c=d.parseFromString(b,"text/xml")):(c=new a.ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b))}catch(e){c=void 0}return c&&c.documentElement&&!c.getElementsByTagName("parsererror").length||n.error("Invalid XML: "+b),c};var Hb=/#.*$/,Ib=/([?&])_=[^&]*/,Jb=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Kb=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Lb=/^(?:GET|HEAD)$/,Mb=/^\/\//,Nb=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,Ob={},Pb={},Qb="*/".concat("*"),Rb=Db.href,Sb=Nb.exec(Rb.toLowerCase())||[];function Tb(a){return function(b,c){"string"!=typeof b&&(c=b,b="*");var d,e=0,f=b.toLowerCase().match(G)||[];if(n.isFunction(c))while(d=f[e++])"+"===d.charAt(0)?(d=d.slice(1)||"*",(a[d]=a[d]||[]).unshift(c)):(a[d]=a[d]||[]).push(c)}}function Ub(a,b,c,d){var e={},f=a===Pb;function g(h){var i;return e[h]=!0,n.each(a[h]||[],function(a,h){var j=h(b,c,d);return"string"!=typeof j||f||e[j]?f?!(i=j):void 0:(b.dataTypes.unshift(j),g(j),!1)}),i}return g(b.dataTypes[0])||!e["*"]&&g("*")}function Vb(a,b){var c,d,e=n.ajaxSettings.flatOptions||{};for(d in b)void 0!==b[d]&&((e[d]?a:c||(c={}))[d]=b[d]);return c&&n.extend(!0,a,c),a}function Wb(a,b,c){var d,e,f,g,h=a.contents,i=a.dataTypes;while("*"===i[0])i.shift(),void 0===e&&(e=a.mimeType||b.getResponseHeader("Content-Type"));if(e)for(g in h)if(h[g]&&h[g].test(e)){i.unshift(g);break}if(i[0]in c)f=i[0];else{for(g in c){if(!i[0]||a.converters[g+" "+i[0]]){f=g;break}d||(d=g)}f=f||d}return f?(f!==i[0]&&i.unshift(f),c[f]):void 0}function Xb(a,b,c,d){var e,f,g,h,i,j={},k=a.dataTypes.slice();if(k[1])for(g in a.converters)j[g.toLowerCase()]=a.converters[g];f=k.shift();while(f)if(a.responseFields[f]&&(c[a.responseFields[f]]=b),!i&&d&&a.dataFilter&&(b=a.dataFilter(b,a.dataType)),i=f,f=k.shift())if("*"===f)f=i;else if("*"!==i&&i!==f){if(g=j[i+" "+f]||j["* "+f],!g)for(e in j)if(h=e.split(" "),h[1]===f&&(g=j[i+" "+h[0]]||j["* "+h[0]])){g===!0?g=j[e]:j[e]!==!0&&(f=h[0],k.unshift(h[1]));break}if(g!==!0)if(g&&a["throws"])b=g(b);else try{b=g(b)}catch(l){return{state:"parsererror",error:g?l:"No conversion from "+i+" to "+f}}}return{state:"success",data:b}}n.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:Rb,type:"GET",isLocal:Kb.test(Sb[1]),global:!0,processData:!0,async:!0,contentType:"application/x-www-form-urlencoded; charset=UTF-8",accepts:{"*":Qb,text:"text/plain",html:"text/html",xml:"application/xml, text/xml",json:"application/json, text/javascript"},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responseFields:{xml:"responseXML",text:"responseText",json:"responseJSON"},converters:{"* text":String,"text html":!0,"text json":n.parseJSON,"text xml":n.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(a,b){return b?Vb(Vb(a,n.ajaxSettings),b):Vb(n.ajaxSettings,a)},ajaxPrefilter:Tb(Ob),ajaxTransport:Tb(Pb),ajax:function(b,c){"object"==typeof b&&(c=b,b=void 0),c=c||{};var d,e,f,g,h,i,j,k,l=n.ajaxSetup({},c),m=l.context||l,o=l.context&&(m.nodeType||m.jquery)?n(m):n.event,p=n.Deferred(),q=n.Callbacks("once memory"),r=l.statusCode||{},s={},t={},u=0,v="canceled",w={readyState:0,getResponseHeader:function(a){var b;if(2===u){if(!k){k={};while(b=Jb.exec(g))k[b[1].toLowerCase()]=b[2]}b=k[a.toLowerCase()]}return null==b?null:b},getAllResponseHeaders:function(){return 2===u?g:null},setRequestHeader:function(a,b){var c=a.toLowerCase();return u||(a=t[c]=t[c]||a,s[a]=b),this},overrideMimeType:function(a){return u||(l.mimeType=a),this},statusCode:function(a){var b;if(a)if(2>u)for(b in a)r[b]=[r[b],a[b]];else w.always(a[w.status]);return this},abort:function(a){var b=a||v;return j&&j.abort(b),y(0,b),this}};if(p.promise(w).complete=q.add,w.success=w.done,w.error=w.fail,l.url=((b||l.url||Rb)+"").replace(Hb,"").replace(Mb,Sb[1]+"//"),l.type=c.method||c.type||l.method||l.type,l.dataTypes=n.trim(l.dataType||"*").toLowerCase().match(G)||[""],null==l.crossDomain&&(d=Nb.exec(l.url.toLowerCase()),l.crossDomain=!(!d||d[1]===Sb[1]&&d[2]===Sb[2]&&(d[3]||("http:"===d[1]?"80":"443"))===(Sb[3]||("http:"===Sb[1]?"80":"443")))),l.data&&l.processData&&"string"!=typeof l.data&&(l.data=n.param(l.data,l.traditional)),Ub(Ob,l,c,w),2===u)return w;i=n.event&&l.global,i&&0===n.active++&&n.event.trigger("ajaxStart"),l.type=l.type.toUpperCase(),l.hasContent=!Lb.test(l.type),f=l.url,l.hasContent||(l.data&&(f=l.url+=(Fb.test(f)?"&":"?")+l.data,delete l.data),l.cache===!1&&(l.url=Ib.test(f)?f.replace(Ib,"$1_="+Eb++):f+(Fb.test(f)?"&":"?")+"_="+Eb++)),l.ifModified&&(n.lastModified[f]&&w.setRequestHeader("If-Modified-Since",n.lastModified[f]),n.etag[f]&&w.setRequestHeader("If-None-Match",n.etag[f])),(l.data&&l.hasContent&&l.contentType!==!1||c.contentType)&&w.setRequestHeader("Content-Type",l.contentType),w.setRequestHeader("Accept",l.dataTypes[0]&&l.accepts[l.dataTypes[0]]?l.accepts[l.dataTypes[0]]+("*"!==l.dataTypes[0]?", "+Qb+"; q=0.01":""):l.accepts["*"]);for(e in l.headers)w.setRequestHeader(e,l.headers[e]);if(l.beforeSend&&(l.beforeSend.call(m,w,l)===!1||2===u))return w.abort();v="abort";for(e in{success:1,error:1,complete:1})w[e](l[e]);if(j=Ub(Pb,l,c,w)){if(w.readyState=1,i&&o.trigger("ajaxSend",[w,l]),2===u)return w;l.async&&l.timeout>0&&(h=a.setTimeout(function(){w.abort("timeout")},l.timeout));try{u=1,j.send(s,y)}catch(x){if(!(2>u))throw x;y(-1,x)}}else y(-1,"No Transport");function y(b,c,d,e){var k,s,t,v,x,y=c;2!==u&&(u=2,h&&a.clearTimeout(h),j=void 0,g=e||"",w.readyState=b>0?4:0,k=b>=200&&300>b||304===b,d&&(v=Wb(l,w,d)),v=Xb(l,v,w,k),k?(l.ifModified&&(x=w.getResponseHeader("Last-Modified"),x&&(n.lastModified[f]=x),x=w.getResponseHeader("etag"),x&&(n.etag[f]=x)),204===b||"HEAD"===l.type?y="nocontent":304===b?y="notmodified":(y=v.state,s=v.data,t=v.error,k=!t)):(t=y,!b&&y||(y="error",0>b&&(b=0))),w.status=b,w.statusText=(c||y)+"",k?p.resolveWith(m,[s,y,w]):p.rejectWith(m,[w,y,t]),w.statusCode(r),r=void 0,i&&o.trigger(k?"ajaxSuccess":"ajaxError",[w,l,k?s:t]),q.fireWith(m,[w,y]),i&&(o.trigger("ajaxComplete",[w,l]),--n.active||n.event.trigger("ajaxStop")))}return w},getJSON:function(a,b,c){return n.get(a,b,c,"json")},getScript:function(a,b){return n.get(a,void 0,b,"script")}}),n.each(["get","post"],function(a,b){n[b]=function(a,c,d,e){return n.isFunction(c)&&(e=e||d,d=c,c=void 0),n.ajax(n.extend({url:a,type:b,dataType:e,data:c,success:d},n.isPlainObject(a)&&a))}}),n._evalUrl=function(a){return n.ajax({url:a,type:"GET",dataType:"script",cache:!0,async:!1,global:!1,"throws":!0})},n.fn.extend({wrapAll:function(a){if(n.isFunction(a))return this.each(function(b){n(this).wrapAll(a.call(this,b))});if(this[0]){var b=n(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&1===a.firstChild.nodeType)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){return n.isFunction(a)?this.each(function(b){n(this).wrapInner(a.call(this,b))}):this.each(function(){var b=n(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=n.isFunction(a);return this.each(function(c){n(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){n.nodeName(this,"body")||n(this).replaceWith(this.childNodes)}).end()}});function Yb(a){return a.style&&a.style.display||n.css(a,"display")}function Zb(a){while(a&&1===a.nodeType){if("none"===Yb(a)||"hidden"===a.type)return!0;a=a.parentNode}return!1}n.expr.filters.hidden=function(a){return l.reliableHiddenOffsets()?a.offsetWidth<=0&&a.offsetHeight<=0&&!a.getClientRects().length:Zb(a)},n.expr.filters.visible=function(a){return!n.expr.filters.hidden(a)};var $b=/%20/g,_b=/\[\]$/,ac=/\r?\n/g,bc=/^(?:submit|button|image|reset|file)$/i,cc=/^(?:input|select|textarea|keygen)/i;function dc(a,b,c,d){var e;if(n.isArray(b))n.each(b,function(b,e){c||_b.test(a)?d(a,e):dc(a+"["+("object"==typeof e&&null!=e?b:"")+"]",e,c,d)});else if(c||"object"!==n.type(b))d(a,b);else for(e in b)dc(a+"["+e+"]",b[e],c,d)}n.param=function(a,b){var c,d=[],e=function(a,b){b=n.isFunction(b)?b():null==b?"":b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};if(void 0===b&&(b=n.ajaxSettings&&n.ajaxSettings.traditional),n.isArray(a)||a.jquery&&!n.isPlainObject(a))n.each(a,function(){e(this.name,this.value)});else for(c in a)dc(c,a[c],b,e);return d.join("&").replace($b,"+")},n.fn.extend({serialize:function(){return n.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var a=n.prop(this,"elements");return a?n.makeArray(a):this}).filter(function(){var a=this.type;return this.name&&!n(this).is(":disabled")&&cc.test(this.nodeName)&&!bc.test(a)&&(this.checked||!Z.test(a))}).map(function(a,b){var c=n(this).val();return null==c?null:n.isArray(c)?n.map(c,function(a){return{name:b.name,value:a.replace(ac,"\r\n")}}):{name:b.name,value:c.replace(ac,"\r\n")}}).get()}}),n.ajaxSettings.xhr=void 0!==a.ActiveXObject?function(){return this.isLocal?ic():d.documentMode>8?hc():/^(get|post|head|put|delete|options)$/i.test(this.type)&&hc()||ic()}:hc;var ec=0,fc={},gc=n.ajaxSettings.xhr();a.attachEvent&&a.attachEvent("onunload",function(){for(var a in fc)fc[a](void 0,!0)}),l.cors=!!gc&&"withCredentials"in gc,gc=l.ajax=!!gc,gc&&n.ajaxTransport(function(b){if(!b.crossDomain||l.cors){var c;return{send:function(d,e){var f,g=b.xhr(),h=++ec;if(g.open(b.type,b.url,b.async,b.username,b.password),b.xhrFields)for(f in b.xhrFields)g[f]=b.xhrFields[f];b.mimeType&&g.overrideMimeType&&g.overrideMimeType(b.mimeType),b.crossDomain||d["X-Requested-With"]||(d["X-Requested-With"]="XMLHttpRequest");for(f in d)void 0!==d[f]&&g.setRequestHeader(f,d[f]+"");g.send(b.hasContent&&b.data||null),c=function(a,d){var f,i,j;if(c&&(d||4===g.readyState))if(delete fc[h],c=void 0,g.onreadystatechange=n.noop,d)4!==g.readyState&&g.abort();else{j={},f=g.status,"string"==typeof g.responseText&&(j.text=g.responseText);try{i=g.statusText}catch(k){i=""}f||!b.isLocal||b.crossDomain?1223===f&&(f=204):f=j.text?200:404}j&&e(f,i,j,g.getAllResponseHeaders())},b.async?4===g.readyState?a.setTimeout(c):g.onreadystatechange=fc[h]=c:c()},abort:function(){c&&c(void 0,!0)}}}});function hc(){try{return new a.XMLHttpRequest}catch(b){}}function ic(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}n.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/\b(?:java|ecma)script\b/},converters:{"text script":function(a){return n.globalEval(a),a}}}),n.ajaxPrefilter("script",function(a){void 0===a.cache&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),n.ajaxTransport("script",function(a){if(a.crossDomain){var b,c=d.head||n("head")[0]||d.documentElement;return{send:function(e,f){b=d.createElement("script"),b.async=!0,a.scriptCharset&&(b.charset=a.scriptCharset),b.src=a.url,b.onload=b.onreadystatechange=function(a,c){(c||!b.readyState||/loaded|complete/.test(b.readyState))&&(b.onload=b.onreadystatechange=null,b.parentNode&&b.parentNode.removeChild(b),b=null,c||f(200,"success"))},c.insertBefore(b,c.firstChild)},abort:function(){b&&b.onload(void 0,!0)}}}});var jc=[],kc=/(=)\?(?=&|$)|\?\?/;n.ajaxSetup({jsonp:"callback",jsonpCallback:function(){var a=jc.pop()||n.expando+"_"+Eb++;return this[a]=!0,a}}),n.ajaxPrefilter("json jsonp",function(b,c,d){var e,f,g,h=b.jsonp!==!1&&(kc.test(b.url)?"url":"string"==typeof b.data&&0===(b.contentType||"").indexOf("application/x-www-form-urlencoded")&&kc.test(b.data)&&"data");return h||"jsonp"===b.dataTypes[0]?(e=b.jsonpCallback=n.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,h?b[h]=b[h].replace(kc,"$1"+e):b.jsonp!==!1&&(b.url+=(Fb.test(b.url)?"&":"?")+b.jsonp+"="+e),b.converters["script json"]=function(){return g||n.error(e+" was not called"),g[0]},b.dataTypes[0]="json",f=a[e],a[e]=function(){g=arguments},d.always(function(){void 0===f?n(a).removeProp(e):a[e]=f,b[e]&&(b.jsonpCallback=c.jsonpCallback,jc.push(e)),g&&n.isFunction(f)&&f(g[0]),g=f=void 0}),"script"):void 0}),n.parseHTML=function(a,b,c){if(!a||"string"!=typeof a)return null;"boolean"==typeof b&&(c=b,b=!1),b=b||d;var e=x.exec(a),f=!c&&[];return e?[b.createElement(e[1])]:(e=ja([a],b,f),f&&f.length&&n(f).remove(),n.merge([],e.childNodes))};var lc=n.fn.load;n.fn.load=function(a,b,c){if("string"!=typeof a&&lc)return lc.apply(this,arguments);var d,e,f,g=this,h=a.indexOf(" ");return h>-1&&(d=n.trim(a.slice(h,a.length)),a=a.slice(0,h)),n.isFunction(b)?(c=b,b=void 0):b&&"object"==typeof b&&(e="POST"),g.length>0&&n.ajax({url:a,type:e||"GET",dataType:"html",data:b}).done(function(a){f=arguments,g.html(d?n("<div>").append(n.parseHTML(a)).find(d):a)}).always(c&&function(a,b){g.each(function(){c.apply(this,f||[a.responseText,b,a])})}),this},n.each(["ajaxStart","ajaxStop","ajaxComplete","ajaxError","ajaxSuccess","ajaxSend"],function(a,b){n.fn[b]=function(a){return this.on(b,a)}}),n.expr.filters.animated=function(a){return n.grep(n.timers,function(b){return a===b.elem}).length};function mc(a){return n.isWindow(a)?a:9===a.nodeType?a.defaultView||a.parentWindow:!1}n.offset={setOffset:function(a,b,c){var d,e,f,g,h,i,j,k=n.css(a,"position"),l=n(a),m={};"static"===k&&(a.style.position="relative"),h=l.offset(),f=n.css(a,"top"),i=n.css(a,"left"),j=("absolute"===k||"fixed"===k)&&n.inArray("auto",[f,i])>-1,j?(d=l.position(),g=d.top,e=d.left):(g=parseFloat(f)||0,e=parseFloat(i)||0),n.isFunction(b)&&(b=b.call(a,c,n.extend({},h))),null!=b.top&&(m.top=b.top-h.top+g),null!=b.left&&(m.left=b.left-h.left+e),"using"in b?b.using.call(a,m):l.css(m)}},n.fn.extend({offset:function(a){if(arguments.length)return void 0===a?this:this.each(function(b){n.offset.setOffset(this,a,b)});var b,c,d={top:0,left:0},e=this[0],f=e&&e.ownerDocument;if(f)return b=f.documentElement,n.contains(b,e)?("undefined"!=typeof e.getBoundingClientRect&&(d=e.getBoundingClientRect()),c=mc(f),{top:d.top+(c.pageYOffset||b.scrollTop)-(b.clientTop||0),left:d.left+(c.pageXOffset||b.scrollLeft)-(b.clientLeft||0)}):d},position:function(){if(this[0]){var a,b,c={top:0,left:0},d=this[0];return"fixed"===n.css(d,"position")?b=d.getBoundingClientRect():(a=this.offsetParent(),b=this.offset(),n.nodeName(a[0],"html")||(c=a.offset()),c.top+=n.css(a[0],"borderTopWidth",!0),c.left+=n.css(a[0],"borderLeftWidth",!0)),{top:b.top-c.top-n.css(d,"marginTop",!0),left:b.left-c.left-n.css(d,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var a=this.offsetParent;while(a&&!n.nodeName(a,"html")&&"static"===n.css(a,"position"))a=a.offsetParent;return a||Qa})}}),n.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(a,b){var c=/Y/.test(b);n.fn[a]=function(d){return Y(this,function(a,d,e){var f=mc(a);return void 0===e?f?b in f?f[b]:f.document.documentElement[d]:a[d]:void(f?f.scrollTo(c?n(f).scrollLeft():e,c?e:n(f).scrollTop()):a[d]=e)},a,d,arguments.length,null)}}),n.each(["top","left"],function(a,b){n.cssHooks[b]=Ua(l.pixelPosition,function(a,c){return c?(c=Sa(a,b),Oa.test(c)?n(a).position()[b]+"px":c):void 0;
})}),n.each({Height:"height",Width:"width"},function(a,b){n.each({padding:"inner"+a,content:b,"":"outer"+a},function(c,d){n.fn[d]=function(d,e){var f=arguments.length&&(c||"boolean"!=typeof d),g=c||(d===!0||e===!0?"margin":"border");return Y(this,function(b,c,d){var e;return n.isWindow(b)?b.document.documentElement["client"+a]:9===b.nodeType?(e=b.documentElement,Math.max(b.body["scroll"+a],e["scroll"+a],b.body["offset"+a],e["offset"+a],e["client"+a])):void 0===d?n.css(b,c,g):n.style(b,c,d,g)},b,f?d:void 0,f,null)}})}),n.fn.extend({bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return 1===arguments.length?this.off(a,"**"):this.off(b,a||"**",c)}}),n.fn.size=function(){return this.length},n.fn.andSelf=n.fn.addBack,"function"==typeof define&&define.amd&&define("jquery",[],function(){return n});var nc=a.jQuery,oc=a.$;return n.noConflict=function(b){return a.$===n&&(a.$=oc),b&&a.jQuery===n&&(a.jQuery=nc),n},b||(a.jQuery=a.$=n),n});
/**
 * Owl Carousel v2.3.4
 * Copyright 2013-2018 David Deutsch
 * Licensed under: SEE LICENSE IN https://github.com/OwlCarousel2/OwlCarousel2/blob/master/LICENSE
 */
!function(a,b,c,d){function e(b,c){this.settings=null,this.options=a.extend({},e.Defaults,c),this.$element=a(b),this._handlers={},this._plugins={},this._supress={},this._current=null,this._speed=null,this._coordinates=[],this._breakpoint=null,this._width=null,this._items=[],this._clones=[],this._mergers=[],this._widths=[],this._invalidated={},this._pipe=[],this._drag={time:null,target:null,pointer:null,stage:{start:null,current:null},direction:null},this._states={current:{},tags:{initializing:["busy"],animating:["busy"],dragging:["interacting"]}},a.each(["onResize","onThrottledResize"],a.proxy(function(b,c){this._handlers[c]=a.proxy(this[c],this)},this)),a.each(e.Plugins,a.proxy(function(a,b){this._plugins[a.charAt(0).toLowerCase()+a.slice(1)]=new b(this)},this)),a.each(e.Workers,a.proxy(function(b,c){this._pipe.push({filter:c.filter,run:a.proxy(c.run,this)})},this)),this.setup(),this.initialize()}e.Defaults={items:3,loop:!1,center:!1,rewind:!1,checkVisibility:!0,mouseDrag:!0,touchDrag:!0,pullDrag:!0,freeDrag:!1,margin:0,stagePadding:0,merge:!1,mergeFit:!0,autoWidth:!1,startPosition:0,rtl:!1,smartSpeed:250,fluidSpeed:!1,dragEndSpeed:!1,responsive:{},responsiveRefreshRate:200,responsiveBaseElement:b,fallbackEasing:"swing",slideTransition:"",info:!1,nestedItemSelector:!1,itemElement:"div",stageElement:"div",refreshClass:"owl-refresh",loadedClass:"owl-loaded",loadingClass:"owl-loading",rtlClass:"owl-rtl",responsiveClass:"owl-responsive",dragClass:"owl-drag",itemClass:"owl-item",stageClass:"owl-stage",stageOuterClass:"owl-stage-outer",grabClass:"owl-grab"},e.Width={Default:"default",Inner:"inner",Outer:"outer"},e.Type={Event:"event",State:"state"},e.Plugins={},e.Workers=[{filter:["width","settings"],run:function(){this._width=this.$element.width()}},{filter:["width","items","settings"],run:function(a){a.current=this._items&&this._items[this.relative(this._current)]}},{filter:["items","settings"],run:function(){this.$stage.children(".cloned").remove()}},{filter:["width","items","settings"],run:function(a){var b=this.settings.margin||"",c=!this.settings.autoWidth,d=this.settings.rtl,e={width:"auto","margin-left":d?b:"","margin-right":d?"":b};!c&&this.$stage.children().css(e),a.css=e}},{filter:["width","items","settings"],run:function(a){var b=(this.width()/this.settings.items).toFixed(3)-this.settings.margin,c=null,d=this._items.length,e=!this.settings.autoWidth,f=[];for(a.items={merge:!1,width:b};d--;)c=this._mergers[d],c=this.settings.mergeFit&&Math.min(c,this.settings.items)||c,a.items.merge=c>1||a.items.merge,f[d]=e?b*c:this._items[d].width();this._widths=f}},{filter:["items","settings"],run:function(){var b=[],c=this._items,d=this.settings,e=Math.max(2*d.items,4),f=2*Math.ceil(c.length/2),g=d.loop&&c.length?d.rewind?e:Math.max(e,f):0,h="",i="";for(g/=2;g>0;)b.push(this.normalize(b.length/2,!0)),h+=c[b[b.length-1]][0].outerHTML,b.push(this.normalize(c.length-1-(b.length-1)/2,!0)),i=c[b[b.length-1]][0].outerHTML+i,g-=1;this._clones=b,a(h).addClass("cloned").appendTo(this.$stage),a(i).addClass("cloned").prependTo(this.$stage)}},{filter:["width","items","settings"],run:function(){for(var a=this.settings.rtl?1:-1,b=this._clones.length+this._items.length,c=-1,d=0,e=0,f=[];++c<b;)d=f[c-1]||0,e=this._widths[this.relative(c)]+this.settings.margin,f.push(d+e*a);this._coordinates=f}},{filter:["width","items","settings"],run:function(){var a=this.settings.stagePadding,b=this._coordinates,c={width:Math.ceil(Math.abs(b[b.length-1]))+2*a,"padding-left":a||"","padding-right":a||""};this.$stage.css(c)}},{filter:["width","items","settings"],run:function(a){var b=this._coordinates.length,c=!this.settings.autoWidth,d=this.$stage.children();if(c&&a.items.merge)for(;b--;)a.css.width=this._widths[this.relative(b)],d.eq(b).css(a.css);else c&&(a.css.width=a.items.width,d.css(a.css))}},{filter:["items"],run:function(){this._coordinates.length<1&&this.$stage.removeAttr("style")}},{filter:["width","items","settings"],run:function(a){a.current=a.current?this.$stage.children().index(a.current):0,a.current=Math.max(this.minimum(),Math.min(this.maximum(),a.current)),this.reset(a.current)}},{filter:["position"],run:function(){this.animate(this.coordinates(this._current))}},{filter:["width","position","items","settings"],run:function(){var a,b,c,d,e=this.settings.rtl?1:-1,f=2*this.settings.stagePadding,g=this.coordinates(this.current())+f,h=g+this.width()*e,i=[];for(c=0,d=this._coordinates.length;c<d;c++)a=this._coordinates[c-1]||0,b=Math.abs(this._coordinates[c])+f*e,(this.op(a,"<=",g)&&this.op(a,">",h)||this.op(b,"<",g)&&this.op(b,">",h))&&i.push(c);this.$stage.children(".active").removeClass("active"),this.$stage.children(":eq("+i.join("), :eq(")+")").addClass("active"),this.$stage.children(".center").removeClass("center"),this.settings.center&&this.$stage.children().eq(this.current()).addClass("center")}}],e.prototype.initializeStage=function(){this.$stage=this.$element.find("."+this.settings.stageClass),this.$stage.length||(this.$element.addClass(this.options.loadingClass),this.$stage=a("<"+this.settings.stageElement+">",{class:this.settings.stageClass}).wrap(a("<div/>",{class:this.settings.stageOuterClass})),this.$element.append(this.$stage.parent()))},e.prototype.initializeItems=function(){var b=this.$element.find(".owl-item");if(b.length)return this._items=b.get().map(function(b){return a(b)}),this._mergers=this._items.map(function(){return 1}),void this.refresh();this.replace(this.$element.children().not(this.$stage.parent())),this.isVisible()?this.refresh():this.invalidate("width"),this.$element.removeClass(this.options.loadingClass).addClass(this.options.loadedClass)},e.prototype.initialize=function(){if(this.enter("initializing"),this.trigger("initialize"),this.$element.toggleClass(this.settings.rtlClass,this.settings.rtl),this.settings.autoWidth&&!this.is("pre-loading")){var a,b,c;a=this.$element.find("img"),b=this.settings.nestedItemSelector?"."+this.settings.nestedItemSelector:d,c=this.$element.children(b).width(),a.length&&c<=0&&this.preloadAutoWidthImages(a)}this.initializeStage(),this.initializeItems(),this.registerEventHandlers(),this.leave("initializing"),this.trigger("initialized")},e.prototype.isVisible=function(){return!this.settings.checkVisibility||this.$element.is(":visible")},e.prototype.setup=function(){var b=this.viewport(),c=this.options.responsive,d=-1,e=null;c?(a.each(c,function(a){a<=b&&a>d&&(d=Number(a))}),e=a.extend({},this.options,c[d]),"function"==typeof e.stagePadding&&(e.stagePadding=e.stagePadding()),delete e.responsive,e.responsiveClass&&this.$element.attr("class",this.$element.attr("class").replace(new RegExp("("+this.options.responsiveClass+"-)\\S+\\s","g"),"$1"+d))):e=a.extend({},this.options),this.trigger("change",{property:{name:"settings",value:e}}),this._breakpoint=d,this.settings=e,this.invalidate("settings"),this.trigger("changed",{property:{name:"settings",value:this.settings}})},e.prototype.optionsLogic=function(){this.settings.autoWidth&&(this.settings.stagePadding=!1,this.settings.merge=!1)},e.prototype.prepare=function(b){var c=this.trigger("prepare",{content:b});return c.data||(c.data=a("<"+this.settings.itemElement+"/>").addClass(this.options.itemClass).append(b)),this.trigger("prepared",{content:c.data}),c.data},e.prototype.update=function(){for(var b=0,c=this._pipe.length,d=a.proxy(function(a){return this[a]},this._invalidated),e={};b<c;)(this._invalidated.all||a.grep(this._pipe[b].filter,d).length>0)&&this._pipe[b].run(e),b++;this._invalidated={},!this.is("valid")&&this.enter("valid")},e.prototype.width=function(a){switch(a=a||e.Width.Default){case e.Width.Inner:case e.Width.Outer:return this._width;default:return this._width-2*this.settings.stagePadding+this.settings.margin}},e.prototype.refresh=function(){this.enter("refreshing"),this.trigger("refresh"),this.setup(),this.optionsLogic(),this.$element.addClass(this.options.refreshClass),this.update(),this.$element.removeClass(this.options.refreshClass),this.leave("refreshing"),this.trigger("refreshed")},e.prototype.onThrottledResize=function(){b.clearTimeout(this.resizeTimer),this.resizeTimer=b.setTimeout(this._handlers.onResize,this.settings.responsiveRefreshRate)},e.prototype.onResize=function(){return!!this._items.length&&(this._width!==this.$element.width()&&(!!this.isVisible()&&(this.enter("resizing"),this.trigger("resize").isDefaultPrevented()?(this.leave("resizing"),!1):(this.invalidate("width"),this.refresh(),this.leave("resizing"),void this.trigger("resized")))))},e.prototype.registerEventHandlers=function(){a.support.transition&&this.$stage.on(a.support.transition.end+".owl.core",a.proxy(this.onTransitionEnd,this)),!1!==this.settings.responsive&&this.on(b,"resize",this._handlers.onThrottledResize),this.settings.mouseDrag&&(this.$element.addClass(this.options.dragClass),this.$stage.on("mousedown.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("dragstart.owl.core selectstart.owl.core",function(){return!1})),this.settings.touchDrag&&(this.$stage.on("touchstart.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("touchcancel.owl.core",a.proxy(this.onDragEnd,this)))},e.prototype.onDragStart=function(b){var d=null;3!==b.which&&(a.support.transform?(d=this.$stage.css("transform").replace(/.*\(|\)| /g,"").split(","),d={x:d[16===d.length?12:4],y:d[16===d.length?13:5]}):(d=this.$stage.position(),d={x:this.settings.rtl?d.left+this.$stage.width()-this.width()+this.settings.margin:d.left,y:d.top}),this.is("animating")&&(a.support.transform?this.animate(d.x):this.$stage.stop(),this.invalidate("position")),this.$element.toggleClass(this.options.grabClass,"mousedown"===b.type),this.speed(0),this._drag.time=(new Date).getTime(),this._drag.target=a(b.target),this._drag.stage.start=d,this._drag.stage.current=d,this._drag.pointer=this.pointer(b),a(c).on("mouseup.owl.core touchend.owl.core",a.proxy(this.onDragEnd,this)),a(c).one("mousemove.owl.core touchmove.owl.core",a.proxy(function(b){var d=this.difference(this._drag.pointer,this.pointer(b));a(c).on("mousemove.owl.core touchmove.owl.core",a.proxy(this.onDragMove,this)),Math.abs(d.x)<Math.abs(d.y)&&this.is("valid")||(b.preventDefault(),this.enter("dragging"),this.trigger("drag"))},this)))},e.prototype.onDragMove=function(a){var b=null,c=null,d=null,e=this.difference(this._drag.pointer,this.pointer(a)),f=this.difference(this._drag.stage.start,e);this.is("dragging")&&(a.preventDefault(),this.settings.loop?(b=this.coordinates(this.minimum()),c=this.coordinates(this.maximum()+1)-b,f.x=((f.x-b)%c+c)%c+b):(b=this.settings.rtl?this.coordinates(this.maximum()):this.coordinates(this.minimum()),c=this.settings.rtl?this.coordinates(this.minimum()):this.coordinates(this.maximum()),d=this.settings.pullDrag?-1*e.x/5:0,f.x=Math.max(Math.min(f.x,b+d),c+d)),this._drag.stage.current=f,this.animate(f.x))},e.prototype.onDragEnd=function(b){var d=this.difference(this._drag.pointer,this.pointer(b)),e=this._drag.stage.current,f=d.x>0^this.settings.rtl?"left":"right";a(c).off(".owl.core"),this.$element.removeClass(this.options.grabClass),(0!==d.x&&this.is("dragging")||!this.is("valid"))&&(this.speed(this.settings.dragEndSpeed||this.settings.smartSpeed),this.current(this.closest(e.x,0!==d.x?f:this._drag.direction)),this.invalidate("position"),this.update(),this._drag.direction=f,(Math.abs(d.x)>3||(new Date).getTime()-this._drag.time>300)&&this._drag.target.one("click.owl.core",function(){return!1})),this.is("dragging")&&(this.leave("dragging"),this.trigger("dragged"))},e.prototype.closest=function(b,c){var e=-1,f=30,g=this.width(),h=this.coordinates();return this.settings.freeDrag||a.each(h,a.proxy(function(a,i){return"left"===c&&b>i-f&&b<i+f?e=a:"right"===c&&b>i-g-f&&b<i-g+f?e=a+1:this.op(b,"<",i)&&this.op(b,">",h[a+1]!==d?h[a+1]:i-g)&&(e="left"===c?a+1:a),-1===e},this)),this.settings.loop||(this.op(b,">",h[this.minimum()])?e=b=this.minimum():this.op(b,"<",h[this.maximum()])&&(e=b=this.maximum())),e},e.prototype.animate=function(b){var c=this.speed()>0;this.is("animating")&&this.onTransitionEnd(),c&&(this.enter("animating"),this.trigger("translate")),a.support.transform3d&&a.support.transition?this.$stage.css({transform:"translate3d("+b+"px,0px,0px)",transition:this.speed()/1e3+"s"+(this.settings.slideTransition?" "+this.settings.slideTransition:"")}):c?this.$stage.animate({left:b+"px"},this.speed(),this.settings.fallbackEasing,a.proxy(this.onTransitionEnd,this)):this.$stage.css({left:b+"px"})},e.prototype.is=function(a){return this._states.current[a]&&this._states.current[a]>0},e.prototype.current=function(a){if(a===d)return this._current;if(0===this._items.length)return d;if(a=this.normalize(a),this._current!==a){var b=this.trigger("change",{property:{name:"position",value:a}});b.data!==d&&(a=this.normalize(b.data)),this._current=a,this.invalidate("position"),this.trigger("changed",{property:{name:"position",value:this._current}})}return this._current},e.prototype.invalidate=function(b){return"string"===a.type(b)&&(this._invalidated[b]=!0,this.is("valid")&&this.leave("valid")),a.map(this._invalidated,function(a,b){return b})},e.prototype.reset=function(a){(a=this.normalize(a))!==d&&(this._speed=0,this._current=a,this.suppress(["translate","translated"]),this.animate(this.coordinates(a)),this.release(["translate","translated"]))},e.prototype.normalize=function(a,b){var c=this._items.length,e=b?0:this._clones.length;return!this.isNumeric(a)||c<1?a=d:(a<0||a>=c+e)&&(a=((a-e/2)%c+c)%c+e/2),a},e.prototype.relative=function(a){return a-=this._clones.length/2,this.normalize(a,!0)},e.prototype.maximum=function(a){var b,c,d,e=this.settings,f=this._coordinates.length;if(e.loop)f=this._clones.length/2+this._items.length-1;else if(e.autoWidth||e.merge){if(b=this._items.length)for(c=this._items[--b].width(),d=this.$element.width();b--&&!((c+=this._items[b].width()+this.settings.margin)>d););f=b+1}else f=e.center?this._items.length-1:this._items.length-e.items;return a&&(f-=this._clones.length/2),Math.max(f,0)},e.prototype.minimum=function(a){return a?0:this._clones.length/2},e.prototype.items=function(a){return a===d?this._items.slice():(a=this.normalize(a,!0),this._items[a])},e.prototype.mergers=function(a){return a===d?this._mergers.slice():(a=this.normalize(a,!0),this._mergers[a])},e.prototype.clones=function(b){var c=this._clones.length/2,e=c+this._items.length,f=function(a){return a%2==0?e+a/2:c-(a+1)/2};return b===d?a.map(this._clones,function(a,b){return f(b)}):a.map(this._clones,function(a,c){return a===b?f(c):null})},e.prototype.speed=function(a){return a!==d&&(this._speed=a),this._speed},e.prototype.coordinates=function(b){var c,e=1,f=b-1;return b===d?a.map(this._coordinates,a.proxy(function(a,b){return this.coordinates(b)},this)):(this.settings.center?(this.settings.rtl&&(e=-1,f=b+1),c=this._coordinates[b],c+=(this.width()-c+(this._coordinates[f]||0))/2*e):c=this._coordinates[f]||0,c=Math.ceil(c))},e.prototype.duration=function(a,b,c){return 0===c?0:Math.min(Math.max(Math.abs(b-a),1),6)*Math.abs(c||this.settings.smartSpeed)},e.prototype.to=function(a,b){var c=this.current(),d=null,e=a-this.relative(c),f=(e>0)-(e<0),g=this._items.length,h=this.minimum(),i=this.maximum();this.settings.loop?(!this.settings.rewind&&Math.abs(e)>g/2&&(e+=-1*f*g),a=c+e,(d=((a-h)%g+g)%g+h)!==a&&d-e<=i&&d-e>0&&(c=d-e,a=d,this.reset(c))):this.settings.rewind?(i+=1,a=(a%i+i)%i):a=Math.max(h,Math.min(i,a)),this.speed(this.duration(c,a,b)),this.current(a),this.isVisible()&&this.update()},e.prototype.next=function(a){a=a||!1,this.to(this.relative(this.current())+1,a)},e.prototype.prev=function(a){a=a||!1,this.to(this.relative(this.current())-1,a)},e.prototype.onTransitionEnd=function(a){if(a!==d&&(a.stopPropagation(),(a.target||a.srcElement||a.originalTarget)!==this.$stage.get(0)))return!1;this.leave("animating"),this.trigger("translated")},e.prototype.viewport=function(){var d;return this.options.responsiveBaseElement!==b?d=a(this.options.responsiveBaseElement).width():b.innerWidth?d=b.innerWidth:c.documentElement&&c.documentElement.clientWidth?d=c.documentElement.clientWidth:console.warn("Can not detect viewport width."),d},e.prototype.replace=function(b){this.$stage.empty(),this._items=[],b&&(b=b instanceof jQuery?b:a(b)),this.settings.nestedItemSelector&&(b=b.find("."+this.settings.nestedItemSelector)),b.filter(function(){return 1===this.nodeType}).each(a.proxy(function(a,b){b=this.prepare(b),this.$stage.append(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)},this)),this.reset(this.isNumeric(this.settings.startPosition)?this.settings.startPosition:0),this.invalidate("items")},e.prototype.add=function(b,c){var e=this.relative(this._current);c=c===d?this._items.length:this.normalize(c,!0),b=b instanceof jQuery?b:a(b),this.trigger("add",{content:b,position:c}),b=this.prepare(b),0===this._items.length||c===this._items.length?(0===this._items.length&&this.$stage.append(b),0!==this._items.length&&this._items[c-1].after(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)):(this._items[c].before(b),this._items.splice(c,0,b),this._mergers.splice(c,0,1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)),this._items[e]&&this.reset(this._items[e].index()),this.invalidate("items"),this.trigger("added",{content:b,position:c})},e.prototype.remove=function(a){(a=this.normalize(a,!0))!==d&&(this.trigger("remove",{content:this._items[a],position:a}),this._items[a].remove(),this._items.splice(a,1),this._mergers.splice(a,1),this.invalidate("items"),this.trigger("removed",{content:null,position:a}))},e.prototype.preloadAutoWidthImages=function(b){b.each(a.proxy(function(b,c){this.enter("pre-loading"),c=a(c),a(new Image).one("load",a.proxy(function(a){c.attr("src",a.target.src),c.css("opacity",1),this.leave("pre-loading"),!this.is("pre-loading")&&!this.is("initializing")&&this.refresh()},this)).attr("src",c.attr("src")||c.attr("data-src")||c.attr("data-src-retina"))},this))},e.prototype.destroy=function(){this.$element.off(".owl.core"),this.$stage.off(".owl.core"),a(c).off(".owl.core"),!1!==this.settings.responsive&&(b.clearTimeout(this.resizeTimer),this.off(b,"resize",this._handlers.onThrottledResize));for(var d in this._plugins)this._plugins[d].destroy();this.$stage.children(".cloned").remove(),this.$stage.unwrap(),this.$stage.children().contents().unwrap(),this.$stage.children().unwrap(),this.$stage.remove(),this.$element.removeClass(this.options.refreshClass).removeClass(this.options.loadingClass).removeClass(this.options.loadedClass).removeClass(this.options.rtlClass).removeClass(this.options.dragClass).removeClass(this.options.grabClass).attr("class",this.$element.attr("class").replace(new RegExp(this.options.responsiveClass+"-\\S+\\s","g"),"")).removeData("owl.carousel")},e.prototype.op=function(a,b,c){var d=this.settings.rtl;switch(b){case"<":return d?a>c:a<c;case">":return d?a<c:a>c;case">=":return d?a<=c:a>=c;case"<=":return d?a>=c:a<=c}},e.prototype.on=function(a,b,c,d){a.addEventListener?a.addEventListener(b,c,d):a.attachEvent&&a.attachEvent("on"+b,c)},e.prototype.off=function(a,b,c,d){a.removeEventListener?a.removeEventListener(b,c,d):a.detachEvent&&a.detachEvent("on"+b,c)},e.prototype.trigger=function(b,c,d,f,g){var h={item:{count:this._items.length,index:this.current()}},i=a.camelCase(a.grep(["on",b,d],function(a){return a}).join("-").toLowerCase()),j=a.Event([b,"owl",d||"carousel"].join(".").toLowerCase(),a.extend({relatedTarget:this},h,c));return this._supress[b]||(a.each(this._plugins,function(a,b){b.onTrigger&&b.onTrigger(j)}),this.register({type:e.Type.Event,name:b}),this.$element.trigger(j),this.settings&&"function"==typeof this.settings[i]&&this.settings[i].call(this,j)),j},e.prototype.enter=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]===d&&(this._states.current[b]=0),this._states.current[b]++},this))},e.prototype.leave=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]--},this))},e.prototype.register=function(b){if(b.type===e.Type.Event){if(a.event.special[b.name]||(a.event.special[b.name]={}),!a.event.special[b.name].owl){var c=a.event.special[b.name]._default;a.event.special[b.name]._default=function(a){return!c||!c.apply||a.namespace&&-1!==a.namespace.indexOf("owl")?a.namespace&&a.namespace.indexOf("owl")>-1:c.apply(this,arguments)},a.event.special[b.name].owl=!0}}else b.type===e.Type.State&&(this._states.tags[b.name]?this._states.tags[b.name]=this._states.tags[b.name].concat(b.tags):this._states.tags[b.name]=b.tags,this._states.tags[b.name]=a.grep(this._states.tags[b.name],a.proxy(function(c,d){return a.inArray(c,this._states.tags[b.name])===d},this)))},e.prototype.suppress=function(b){a.each(b,a.proxy(function(a,b){this._supress[b]=!0},this))},e.prototype.release=function(b){a.each(b,a.proxy(function(a,b){delete this._supress[b]},this))},e.prototype.pointer=function(a){var c={x:null,y:null};return a=a.originalEvent||a||b.event,a=a.touches&&a.touches.length?a.touches[0]:a.changedTouches&&a.changedTouches.length?a.changedTouches[0]:a,a.pageX?(c.x=a.pageX,c.y=a.pageY):(c.x=a.clientX,c.y=a.clientY),c},e.prototype.isNumeric=function(a){return!isNaN(parseFloat(a))},e.prototype.difference=function(a,b){return{x:a.x-b.x,y:a.y-b.y}},a.fn.owlCarousel=function(b){var c=Array.prototype.slice.call(arguments,1);return this.each(function(){var d=a(this),f=d.data("owl.carousel");f||(f=new e(this,"object"==typeof b&&b),d.data("owl.carousel",f),a.each(["next","prev","to","destroy","refresh","replace","add","remove"],function(b,c){f.register({type:e.Type.Event,name:c}),f.$element.on(c+".owl.carousel.core",a.proxy(function(a){a.namespace&&a.relatedTarget!==this&&(this.suppress([c]),f[c].apply(this,[].slice.call(arguments,1)),this.release([c]))},f))})),"string"==typeof b&&"_"!==b.charAt(0)&&f[b].apply(f,c)})},a.fn.owlCarousel.Constructor=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._interval=null,this._visible=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoRefresh&&this.watch()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={autoRefresh:!0,autoRefreshInterval:500},e.prototype.watch=function(){this._interval||(this._visible=this._core.isVisible(),this._interval=b.setInterval(a.proxy(this.refresh,this),this._core.settings.autoRefreshInterval))},e.prototype.refresh=function(){this._core.isVisible()!==this._visible&&(this._visible=!this._visible,this._core.$element.toggleClass("owl-hidden",!this._visible),this._visible&&this._core.invalidate("width")&&this._core.refresh())},e.prototype.destroy=function(){var a,c;b.clearInterval(this._interval);for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoRefresh=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._loaded=[],this._handlers={"initialized.owl.carousel change.owl.carousel resized.owl.carousel":a.proxy(function(b){if(b.namespace&&this._core.settings&&this._core.settings.lazyLoad&&(b.property&&"position"==b.property.name||"initialized"==b.type)){var c=this._core.settings,e=c.center&&Math.ceil(c.items/2)||c.items,f=c.center&&-1*e||0,g=(b.property&&b.property.value!==d?b.property.value:this._core.current())+f,h=this._core.clones().length,i=a.proxy(function(a,b){this.load(b)},this);for(c.lazyLoadEager>0&&(e+=c.lazyLoadEager,c.loop&&(g-=c.lazyLoadEager,e++));f++<e;)this.load(h/2+this._core.relative(g)),h&&a.each(this._core.clones(this._core.relative(g)),i),g++}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={lazyLoad:!1,lazyLoadEager:0},e.prototype.load=function(c){var d=this._core.$stage.children().eq(c),e=d&&d.find(".owl-lazy");!e||a.inArray(d.get(0),this._loaded)>-1||(e.each(a.proxy(function(c,d){var e,f=a(d),g=b.devicePixelRatio>1&&f.attr("data-src-retina")||f.attr("data-src")||f.attr("data-srcset");this._core.trigger("load",{element:f,url:g},"lazy"),f.is("img")?f.one("load.owl.lazy",a.proxy(function(){f.css("opacity",1),this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("src",g):f.is("source")?f.one("load.owl.lazy",a.proxy(function(){this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("srcset",g):(e=new Image,e.onload=a.proxy(function(){f.css({"background-image":'url("'+g+'")',opacity:"1"}),this._core.trigger("loaded",{element:f,url:g},"lazy")},this),e.src=g)},this)),this._loaded.push(d.get(0)))},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this._core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Lazy=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(c){this._core=c,this._previousHeight=null,this._handlers={"initialized.owl.carousel refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&this.update()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&"position"===a.property.name&&this.update()},this),"loaded.owl.lazy":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&a.element.closest("."+this._core.settings.itemClass).index()===this._core.current()&&this.update()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._intervalId=null;var d=this;a(b).on("load",function(){d._core.settings.autoHeight&&d.update()}),a(b).resize(function(){d._core.settings.autoHeight&&(null!=d._intervalId&&clearTimeout(d._intervalId),d._intervalId=setTimeout(function(){d.update()},250))})};e.Defaults={autoHeight:!1,autoHeightClass:"owl-height"},e.prototype.update=function(){var b=this._core._current,c=b+this._core.settings.items,d=this._core.settings.lazyLoad,e=this._core.$stage.children().toArray().slice(b,c),f=[],g=0;a.each(e,function(b,c){f.push(a(c).height())}),g=Math.max.apply(null,f),g<=1&&d&&this._previousHeight&&(g=this._previousHeight),this._previousHeight=g,this._core.$stage.parent().height(g).addClass(this._core.settings.autoHeightClass)},e.prototype.destroy=function(){var a,b;for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoHeight=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._videos={},this._playing=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.register({type:"state",name:"playing",tags:["interacting"]})},this),"resize.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.video&&this.isInFullScreen()&&a.preventDefault()},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.is("resizing")&&this._core.$stage.find(".cloned .owl-video-frame").remove()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"===a.property.name&&this._playing&&this.stop()},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find(".owl-video");c.length&&(c.css("display","none"),this.fetch(c,a(b.content)))}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._core.$element.on("click.owl.video",".owl-video-play-icon",a.proxy(function(a){this.play(a)},this))};e.Defaults={video:!1,videoHeight:!1,videoWidth:!1},e.prototype.fetch=function(a,b){var c=function(){return a.attr("data-vimeo-id")?"vimeo":a.attr("data-vzaar-id")?"vzaar":"youtube"}(),d=a.attr("data-vimeo-id")||a.attr("data-youtube-id")||a.attr("data-vzaar-id"),e=a.attr("data-width")||this._core.settings.videoWidth,f=a.attr("data-height")||this._core.settings.videoHeight,g=a.attr("href");if(!g)throw new Error("Missing video URL.");if(d=g.match(/(http:|https:|)\/\/(player.|www.|app.)?(vimeo\.com|youtu(be\.com|\.be|be\.googleapis\.com|be\-nocookie\.com)|vzaar\.com)\/(video\/|videos\/|embed\/|channels\/.+\/|groups\/.+\/|watch\?v=|v\/)?([A-Za-z0-9._%-]*)(\&\S+)?/),d[3].indexOf("youtu")>-1)c="youtube";else if(d[3].indexOf("vimeo")>-1)c="vimeo";else{if(!(d[3].indexOf("vzaar")>-1))throw new Error("Video URL not supported.");c="vzaar"}d=d[6],this._videos[g]={type:c,id:d,width:e,height:f},b.attr("data-video",g),this.thumbnail(a,this._videos[g])},e.prototype.thumbnail=function(b,c){var d,e,f,g=c.width&&c.height?"width:"+c.width+"px;height:"+c.height+"px;":"",h=b.find("img"),i="src",j="",k=this._core.settings,l=function(c){e='<div class="owl-video-play-icon"></div>',d=k.lazyLoad?a("<div/>",{class:"owl-video-tn "+j,srcType:c}):a("<div/>",{class:"owl-video-tn",style:"opacity:1;background-image:url("+c+")"}),b.after(d),b.after(e)};if(b.wrap(a("<div/>",{class:"owl-video-wrapper",style:g})),this._core.settings.lazyLoad&&(i="data-src",j="owl-lazy"),h.length)return l(h.attr(i)),h.remove(),!1;"youtube"===c.type?(f="//img.youtube.com/vi/"+c.id+"/hqdefault.jpg",l(f)):"vimeo"===c.type?a.ajax({type:"GET",url:"//vimeo.com/api/v2/video/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a[0].thumbnail_large,l(f)}}):"vzaar"===c.type&&a.ajax({type:"GET",url:"//vzaar.com/api/videos/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a.framegrab_url,l(f)}})},e.prototype.stop=function(){this._core.trigger("stop",null,"video"),this._playing.find(".owl-video-frame").remove(),this._playing.removeClass("owl-video-playing"),this._playing=null,this._core.leave("playing"),this._core.trigger("stopped",null,"video")},e.prototype.play=function(b){var c,d=a(b.target),e=d.closest("."+this._core.settings.itemClass),f=this._videos[e.attr("data-video")],g=f.width||"100%",h=f.height||this._core.$stage.height();this._playing||(this._core.enter("playing"),this._core.trigger("play",null,"video"),e=this._core.items(this._core.relative(e.index())),this._core.reset(e.index()),c=a('<iframe frameborder="0" allowfullscreen mozallowfullscreen webkitAllowFullScreen ></iframe>'),c.attr("height",h),c.attr("width",g),"youtube"===f.type?c.attr("src","//www.youtube.com/embed/"+f.id+"?autoplay=1&rel=0&v="+f.id):"vimeo"===f.type?c.attr("src","//player.vimeo.com/video/"+f.id+"?autoplay=1"):"vzaar"===f.type&&c.attr("src","//view.vzaar.com/"+f.id+"/player?autoplay=true"),a(c).wrap('<div class="owl-video-frame" />').insertAfter(e.find(".owl-video")),this._playing=e.addClass("owl-video-playing"))},e.prototype.isInFullScreen=function(){var b=c.fullscreenElement||c.mozFullScreenElement||c.webkitFullscreenElement;return b&&a(b).parent().hasClass("owl-video-frame")},e.prototype.destroy=function(){var a,b;this._core.$element.off("click.owl.video");for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Video=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this.core=b,this.core.options=a.extend({},e.Defaults,this.core.options),this.swapping=!0,this.previous=d,this.next=d,this.handlers={"change.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&(this.previous=this.core.current(),this.next=a.property.value)},this),"drag.owl.carousel dragged.owl.carousel translated.owl.carousel":a.proxy(function(a){a.namespace&&(this.swapping="translated"==a.type)},this),"translate.owl.carousel":a.proxy(function(a){a.namespace&&this.swapping&&(this.core.options.animateOut||this.core.options.animateIn)&&this.swap()},this)},this.core.$element.on(this.handlers)};e.Defaults={animateOut:!1,
animateIn:!1},e.prototype.swap=function(){if(1===this.core.settings.items&&a.support.animation&&a.support.transition){this.core.speed(0);var b,c=a.proxy(this.clear,this),d=this.core.$stage.children().eq(this.previous),e=this.core.$stage.children().eq(this.next),f=this.core.settings.animateIn,g=this.core.settings.animateOut;this.core.current()!==this.previous&&(g&&(b=this.core.coordinates(this.previous)-this.core.coordinates(this.next),d.one(a.support.animation.end,c).css({left:b+"px"}).addClass("animated owl-animated-out").addClass(g)),f&&e.one(a.support.animation.end,c).addClass("animated owl-animated-in").addClass(f))}},e.prototype.clear=function(b){a(b.target).css({left:""}).removeClass("animated owl-animated-out owl-animated-in").removeClass(this.core.settings.animateIn).removeClass(this.core.settings.animateOut),this.core.onTransitionEnd()},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this.core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Animate=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._call=null,this._time=0,this._timeout=0,this._paused=!0,this._handlers={"changed.owl.carousel":a.proxy(function(a){a.namespace&&"settings"===a.property.name?this._core.settings.autoplay?this.play():this.stop():a.namespace&&"position"===a.property.name&&this._paused&&(this._time=0)},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoplay&&this.play()},this),"play.owl.autoplay":a.proxy(function(a,b,c){a.namespace&&this.play(b,c)},this),"stop.owl.autoplay":a.proxy(function(a){a.namespace&&this.stop()},this),"mouseover.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"mouseleave.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.play()},this),"touchstart.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"touchend.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this.play()},this)},this._core.$element.on(this._handlers),this._core.options=a.extend({},e.Defaults,this._core.options)};e.Defaults={autoplay:!1,autoplayTimeout:5e3,autoplayHoverPause:!1,autoplaySpeed:!1},e.prototype._next=function(d){this._call=b.setTimeout(a.proxy(this._next,this,d),this._timeout*(Math.round(this.read()/this._timeout)+1)-this.read()),this._core.is("interacting")||c.hidden||this._core.next(d||this._core.settings.autoplaySpeed)},e.prototype.read=function(){return(new Date).getTime()-this._time},e.prototype.play=function(c,d){var e;this._core.is("rotating")||this._core.enter("rotating"),c=c||this._core.settings.autoplayTimeout,e=Math.min(this._time%(this._timeout||c),c),this._paused?(this._time=this.read(),this._paused=!1):b.clearTimeout(this._call),this._time+=this.read()%c-e,this._timeout=c,this._call=b.setTimeout(a.proxy(this._next,this,d),c-e)},e.prototype.stop=function(){this._core.is("rotating")&&(this._time=0,this._paused=!0,b.clearTimeout(this._call),this._core.leave("rotating"))},e.prototype.pause=function(){this._core.is("rotating")&&!this._paused&&(this._time=this.read(),this._paused=!0,b.clearTimeout(this._call))},e.prototype.destroy=function(){var a,b;this.stop();for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.autoplay=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(b){this._core=b,this._initialized=!1,this._pages=[],this._controls={},this._templates=[],this.$element=this._core.$element,this._overrides={next:this._core.next,prev:this._core.prev,to:this._core.to},this._handlers={"prepared.owl.carousel":a.proxy(function(b){b.namespace&&this._core.settings.dotsData&&this._templates.push('<div class="'+this._core.settings.dotClass+'">'+a(b.content).find("[data-dot]").addBack("[data-dot]").attr("data-dot")+"</div>")},this),"added.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,0,this._templates.pop())},this),"remove.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,1)},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&this.draw()},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&!this._initialized&&(this._core.trigger("initialize",null,"navigation"),this.initialize(),this.update(),this.draw(),this._initialized=!0,this._core.trigger("initialized",null,"navigation"))},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._initialized&&(this._core.trigger("refresh",null,"navigation"),this.update(),this.draw(),this._core.trigger("refreshed",null,"navigation"))},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers)};e.Defaults={nav:!1,navText:['<span aria-label="Previous">&#x2039;</span>','<span aria-label="Next">&#x203a;</span>'],navSpeed:!1,navElement:'button type="button" role="presentation"',navContainer:!1,navContainerClass:"owl-nav",navClass:["owl-prev","owl-next"],slideBy:1,dotClass:"owl-dot",dotsClass:"owl-dots",dots:!0,dotsEach:!1,dotsData:!1,dotsSpeed:!1,dotsContainer:!1},e.prototype.initialize=function(){var b,c=this._core.settings;this._controls.$relative=(c.navContainer?a(c.navContainer):a("<div>").addClass(c.navContainerClass).appendTo(this.$element)).addClass("disabled"),this._controls.$previous=a("<"+c.navElement+">").addClass(c.navClass[0]).html(c.navText[0]).prependTo(this._controls.$relative).on("click",a.proxy(function(a){this.prev(c.navSpeed)},this)),this._controls.$next=a("<"+c.navElement+">").addClass(c.navClass[1]).html(c.navText[1]).appendTo(this._controls.$relative).on("click",a.proxy(function(a){this.next(c.navSpeed)},this)),c.dotsData||(this._templates=[a('<button role="button">').addClass(c.dotClass).append(a("<span>")).prop("outerHTML")]),this._controls.$absolute=(c.dotsContainer?a(c.dotsContainer):a("<div>").addClass(c.dotsClass).appendTo(this.$element)).addClass("disabled"),this._controls.$absolute.on("click","button",a.proxy(function(b){var d=a(b.target).parent().is(this._controls.$absolute)?a(b.target).index():a(b.target).parent().index();b.preventDefault(),this.to(d,c.dotsSpeed)},this));for(b in this._overrides)this._core[b]=a.proxy(this[b],this)},e.prototype.destroy=function(){var a,b,c,d,e;e=this._core.settings;for(a in this._handlers)this.$element.off(a,this._handlers[a]);for(b in this._controls)"$relative"===b&&e.navContainer?this._controls[b].html(""):this._controls[b].remove();for(d in this.overides)this._core[d]=this._overrides[d];for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},e.prototype.update=function(){var a,b,c,d=this._core.clones().length/2,e=d+this._core.items().length,f=this._core.maximum(!0),g=this._core.settings,h=g.center||g.autoWidth||g.dotsData?1:g.dotsEach||g.items;if("page"!==g.slideBy&&(g.slideBy=Math.min(g.slideBy,g.items)),g.dots||"page"==g.slideBy)for(this._pages=[],a=d,b=0,c=0;a<e;a++){if(b>=h||0===b){if(this._pages.push({start:Math.min(f,a-d),end:a-d+h-1}),Math.min(f,a-d)===f)break;b=0,++c}b+=this._core.mergers(this._core.relative(a))}},e.prototype.draw=function(){var b,c=this._core.settings,d=this._core.items().length<=c.items,e=this._core.relative(this._core.current()),f=c.loop||c.rewind;this._controls.$relative.toggleClass("disabled",!c.nav||d),c.nav&&(this._controls.$previous.toggleClass("disabled",!f&&e<=this._core.minimum(!0)),this._controls.$next.toggleClass("disabled",!f&&e>=this._core.maximum(!0))),this._controls.$absolute.toggleClass("disabled",!c.dots||d),c.dots&&(b=this._pages.length-this._controls.$absolute.children().length,c.dotsData&&0!==b?this._controls.$absolute.html(this._templates.join("")):b>0?this._controls.$absolute.append(new Array(b+1).join(this._templates[0])):b<0&&this._controls.$absolute.children().slice(b).remove(),this._controls.$absolute.find(".active").removeClass("active"),this._controls.$absolute.children().eq(a.inArray(this.current(),this._pages)).addClass("active"))},e.prototype.onTrigger=function(b){var c=this._core.settings;b.page={index:a.inArray(this.current(),this._pages),count:this._pages.length,size:c&&(c.center||c.autoWidth||c.dotsData?1:c.dotsEach||c.items)}},e.prototype.current=function(){var b=this._core.relative(this._core.current());return a.grep(this._pages,a.proxy(function(a,c){return a.start<=b&&a.end>=b},this)).pop()},e.prototype.getPosition=function(b){var c,d,e=this._core.settings;return"page"==e.slideBy?(c=a.inArray(this.current(),this._pages),d=this._pages.length,b?++c:--c,c=this._pages[(c%d+d)%d].start):(c=this._core.relative(this._core.current()),d=this._core.items().length,b?c+=e.slideBy:c-=e.slideBy),c},e.prototype.next=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!0),b)},e.prototype.prev=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!1),b)},e.prototype.to=function(b,c,d){var e;!d&&this._pages.length?(e=this._pages.length,a.proxy(this._overrides.to,this._core)(this._pages[(b%e+e)%e].start,c)):a.proxy(this._overrides.to,this._core)(b,c)},a.fn.owlCarousel.Constructor.Plugins.Navigation=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(c){this._core=c,this._hashes={},this.$element=this._core.$element,this._handlers={"initialized.owl.carousel":a.proxy(function(c){c.namespace&&"URLHash"===this._core.settings.startPosition&&a(b).trigger("hashchange.owl.navigation")},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find("[data-hash]").addBack("[data-hash]").attr("data-hash");if(!c)return;this._hashes[c]=b.content}},this),"changed.owl.carousel":a.proxy(function(c){if(c.namespace&&"position"===c.property.name){var d=this._core.items(this._core.relative(this._core.current())),e=a.map(this._hashes,function(a,b){return a===d?b:null}).join();if(!e||b.location.hash.slice(1)===e)return;b.location.hash=e}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers),a(b).on("hashchange.owl.navigation",a.proxy(function(a){var c=b.location.hash.substring(1),e=this._core.$stage.children(),f=this._hashes[c]&&e.index(this._hashes[c]);f!==d&&f!==this._core.current()&&this._core.to(this._core.relative(f),!1,!0)},this))};e.Defaults={URLhashListener:!1},e.prototype.destroy=function(){var c,d;a(b).off("hashchange.owl.navigation");for(c in this._handlers)this._core.$element.off(c,this._handlers[c]);for(d in Object.getOwnPropertyNames(this))"function"!=typeof this[d]&&(this[d]=null)},a.fn.owlCarousel.Constructor.Plugins.Hash=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){function e(b,c){var e=!1,f=b.charAt(0).toUpperCase()+b.slice(1);return a.each((b+" "+h.join(f+" ")+f).split(" "),function(a,b){if(g[b]!==d)return e=!c||b,!1}),e}function f(a){return e(a,!0)}var g=a("<support>").get(0).style,h="Webkit Moz O ms".split(" "),i={transition:{end:{WebkitTransition:"webkitTransitionEnd",MozTransition:"transitionend",OTransition:"oTransitionEnd",transition:"transitionend"}},animation:{end:{WebkitAnimation:"webkitAnimationEnd",MozAnimation:"animationend",OAnimation:"oAnimationEnd",animation:"animationend"}}},j={csstransforms:function(){return!!e("transform")},csstransforms3d:function(){return!!e("perspective")},csstransitions:function(){return!!e("transition")},cssanimations:function(){return!!e("animation")}};j.csstransitions()&&(a.support.transition=new String(f("transition")),a.support.transition.end=i.transition.end[a.support.transition]),j.cssanimations()&&(a.support.animation=new String(f("animation")),a.support.animation.end=i.animation.end[a.support.animation]),j.csstransforms()&&(a.support.transform=new String(f("transform")),a.support.transform3d=j.csstransforms3d())}(window.Zepto||window.jQuery,window,document);(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();

$(document).ready(function () {

  try{
        /* Versions Pagination*/
      $('.pagination_big').owlCarousel({
        margin:10,
        nav:true,
        dots:false,
        responsive:{
            0:{
                items:3
            },
            400:{
                items:4
            },
            500:{
                items:6
            },
            1600:{
                items:11
            }
        }
    });
  } catch(e){}

});

</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div> <span id="year"></span> John Snow Labs Inc.
        <a href="https://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="https://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demomenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*OPen by URL*/
jQuery(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

try{
  //Accordion demos categories
  let acc = document.getElementsByClassName("acc-top"),
    isResizeble = false;

  if(!isResizeble && document.querySelector(".acc-top")) {
      let accBody = document.querySelector('.acc-body li.active');
      accBody.parentElement.style.maxHeight = accBody.parentElement.scrollHeight + 20 + "px";
      accBody.parentElement.classList.add('open');
      accBody.parentElement.previousElementSibling.classList.add('active');
      isResizeble = true;
  }

for (let i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.maxHeight) {
      panel.style.maxHeight = null;
      panel.classList.remove('open');
    } else {
      panel.style.maxHeight = panel.scrollHeight + 20 + "px";
      panel.classList.add('open');
    }
  });
}
} catch(e){}


try {
  //Show more in demos description
  let tabDescription = document.querySelectorAll('.tab-description');

  tabDescription.forEach(element => {
    let tabDescriptionInner = element.querySelector('.tab-description-inner');
    if(element.offsetHeight < tabDescriptionInner.offsetHeight) {
      element.classList.add('big-descr');
    }
  });

  let showMore = document.querySelectorAll('.show_more');

  showMore.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
      this.parentElement.parentElement.classList.remove('big-descr');
      this.parentElement.parentElement.classList.add('big-descr-close');
    });
  });
} catch(e){}


try{
  //disable Colab link
  let btnDisable = document.querySelectorAll('.btn.disable');

  btnDisable.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
    });
  });
} catch(e){}


try {
  // Ancor click
const anchors = [].slice.call(document.querySelectorAll('.btn-box-install a')),
animationTime = 300,
framesCount = 20;

anchors.forEach(function(item) {
item.addEventListener('click', function(e) {
  e.preventDefault();
  let coordY = document.querySelector(item.getAttribute('href')).getBoundingClientRect().top + window.pageYOffset -100;

  let scroller = setInterval(function() {
      let scrollBy = coordY / framesCount;

if(scrollBy > window.pageYOffset - coordY && window.innerHeight + window.pageYOffset < document.body.offsetHeight) {
    window.scrollBy(0, scrollBy);
} else {
          window.scrollTo(0, coordY);
  clearInterval(scroller);
}
  }, animationTime / framesCount);
});
}); 
} catch(e){}


try {
  //Pagination active
  let paginationItems = document.querySelectorAll('.pagination_big li'),
      nextVersionContainer = document.querySelector('#nextver'),
      previosVersionContainer = document.querySelector('#previosver'),
      currentVersionContainer = document.querySelector('#currversion'),
      currentPageTitle = document.querySelector('#section').innerText;

  // Set active page and update version containers
  for (let i = 0; i < paginationItems.length; i++) {
    const item = paginationItems[i];
    const itemTitle = item.firstElementChild.innerHTML;
    if (itemTitle === currentPageTitle) {
      item.classList.add('active');
      currentVersionContainer.textContent = itemTitle;       
      if(item.previousElementSibling) {
        previosVersionContainer.textContent = item.previousElementSibling.innerText; 
        previosVersionContainer.parentElement.href += item.previousElementSibling.innerText.replaceAll('.', '_');
      } else {
        previosVersionContainer.parentElement.parentElement.classList.add('hide');
      }
      if(item.nextElementSibling) {
        nextVersionContainer.textContent = item.nextElementSibling.innerText;
        nextVersionContainer.parentElement.href += item.nextElementSibling.innerText.replaceAll('.', '_');
      } else {
        nextVersionContainer.parentElement.parentElement.classList.add('hide');
      }         
      break;
    }
  }
} catch(e){}


try{
  // copy to clipboard
  let btnCopy = document.querySelectorAll('.button-copy-s3');

  btnCopy.forEach((element) => {
    //add span Copied!
    element.insertAdjacentHTML('beforeend', '<span>Copied!</span>');

    element.addEventListener('click', function (e) {
      e.preventDefault();
      element.classList.add('copied');
      setTimeout(function () {
        element.classList.remove('copied');
      }, 3000);
      navigator.clipboard.writeText(element.href);
    });
  });
} catch(e){}

document.getElementById("year").innerHTML = new Date().getFullYear();

</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3',  container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

        

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName')
              .toLowerCase() + ' ' + $this.prop('className'))
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>